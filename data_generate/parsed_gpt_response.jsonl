{"Question_Number": "Q1", "Question_Description": "한 회사가 여러 대륙의 도시들에서 온도, 습도, 대기압 데이터를 수집하고 있습니다. 각 사이트에서 매일 수집하는 평균 데이터 볼륨은 500GB입니다. 각 사이트는 고속 인터넷 연결을 보유하고 있습니다. 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 가능한 한 빠르게 집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["글로벌 사이트", "500GB", "고속 인터넷", "운영 복잡성", "Amazon S3", "S3 Transfer Acceleration", "Multipart Upload"], "Terms": ["S3 Transfer Acceleration", "Multipart Upload", "S3 Cross-Region Replication", "AWS Snowball Edge", "Amazon EBS", "EBS Snapshot"], "Commentary": "이 문제는 전 세계 지점에서 발생하는 대규모 데이터를 단일 Amazon S3 버킷으로 빠르고 간편하게 업로드하는 방법을 묻고 있습니다. S3 Transfer Acceleration을 사용하면 네트워크 지연을 줄이고, Multipart Upload로 대용량 데이터를 병렬 전송하여 업로드 속도를 높이는 최적의 해법을 구현할 수 있습니다.", "Selections": {"SelectA": {"Select": "대상 S3 버킷에서 S3 Transfer Acceleration을 활성화하고, Multipart Upload를 사용해 사이트 데이터를 직접 업로드합니다.", "Commentary": "S3 Transfer Acceleration은 글로벌 Edge Location을 통해 빠른 업로드를 가능하게 하며, Multipart Upload와 결합하면 대용량 파일도 병렬로 효과적으로 업로드할 수 있어 요구사항을 가장 잘 충족합니다."}, "SelectB": {"Select": "가장 가까운 리전의 S3 버킷에 데이터를 업로드하고, S3 Cross-Region Replication으로 대상 S3 버킷에 복제한 후 원본 버킷에서 데이터를 제거합니다.", "Commentary": "중간 S3 버킷을 활용한 복제 프로세스는 추가 단계가 많아 운영이 복잡해지며, 복제 지연이 발생해 데이터를 즉시 집계하기 어려워집니다."}, "SelectC": {"Select": "AWS Snowball Edge Storage Optimized 디바이스를 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송하고, S3 Cross-Region Replication으로 대상 버킷에 복제합니다.", "Commentary": "Snowball Edge는 물리적 장비 운송이 필요해 시간이 오래 걸리며 이미 고속 인터넷이 있는 환경에서는 오버엔지니어링으로 운영 복잡성이 커집니다."}, "SelectD": {"Select": "가장 가까운 리전의 Amazon EC2 인스턴스에 데이터를 업로드하고, Amazon EBS 볼륨에 저장합니다. 정기적으로 EBS 스냅샷을 생성해 대상 S3 버킷이 있는 리전으로 복사하고 필요 시 EBS 볼륨을 복원합니다.", "Commentary": "EC2, EBS, 스냅샷 복사 등 단계가 많아 복잡하며, 바로 S3에 업로드하는 것보다 지연이 늘어나고 관리 부담이 커집니다."}}}
{"Question_Number": "Q2", "Question_Description": "한 회사는 자체 애플리케이션의 로그 파일을 분석해야 합니다. 로그는 JSON 형식으로 Amazon S3 버킷에 저장되어 있습니다. 쿼리는 간단하며 필요할 때마다 실행될 예정입니다. 솔루션스 아키텍트는 기존 아키텍처에 최소한의 변경으로 분석을 수행해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하려면 어떻게 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3", "3.5"], "Keywords": ["Amazon S3", "JSON 로그", "분석", "운영 오버헤드 최소화", "온디맨드 쿼리"], "Terms": ["Amazon Redshift", "Amazon CloudWatch Logs", "Amazon Athena", "AWS Glue", "Apache Spark", "Amazon EMR", "SQL 쿼리", "JSON"], "Commentary": "이 문제는 Amazon S3에 저장된 JSON 로그 데이터를 최소한의 변경으로 즉시 분석해야 하는 시나리오입니다. Athena를 사용하면 추가 인프라 구성 없이 S3에 직접 쿼리를 실행할 수 있고, 서버리스 방식으로 운영 오버헤드가 매우 적습니다. 따라서 각 선택지 중 가장 간단하고 효율적인 해법을 제공하는 C가 정답입니다.", "Selections": {"SelectA": {"Select": "Amazon Redshift를 사용해 모든 데이터를 한 곳으로 로드하고, 필요할 때 SQL 쿼리를 실행합니다.", "Commentary": "Redshift 클러스터 구성, 관리, 로드 작업이 필요해 운영 오버헤드가 높고 초기 설정이 복잡합니다."}, "SelectB": {"Select": "Amazon CloudWatch Logs에 로그를 저장하고, 콘솔에서 SQL 쿼리를 필요할 때 실행합니다.", "Commentary": "CloudWatch Logs는 로그 수집 및 모니터링에 적합하지만, S3에 이미 저장된 JSON을 직접 분석하기엔 적합하지 않습니다."}, "SelectC": {"Select": "Amazon Athena를 사용해 Amazon S3에 직접 쿼리를 실행합니다.", "Commentary": "서버리스 기반으로, 기존 데이터가 저장된 S3에 대해 바로 SQL 쿼리를 수행할 수 있어 설정과 운영이 간단하며, 필요할 때만 비용이 발생하는 가장 효율적인 방법입니다."}, "SelectD": {"Select": "AWS Glue로 로그를 카탈로그하고, Amazon EMR의 일시적 Apache Spark 클러스터로 필요 시 SQL 쿼리를 실행합니다.", "Commentary": "EMR 클러스터를 설정하고 Glue 카탈로그와 연동하는 과정이 필요하며, Athena보다 운영 부담과 비용이 높습니다."}}}
{"Question_Number": "Q3", "Question_Description": "한 회사가 여러 부서별로 다른 AWS 계정을 관리하기 위해 AWS Organizations를 사용하고 있습니다. 관리 계정에는 프로젝트 보고서가 들어 있는 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 오직 조직 내 계정(=AWS Organizations에 속한 계정)의 사용자만 접근할 수 있도록 제한하고자 합니다. 가장 적은 운영 오버헤드를 들이면서 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["S3 버킷 접근 제한", "AWS Organizations", "aws:PrincipalOrgID", "조직 내 계정", "운영 오버헤드 최소화"], "Terms": ["AWS Organizations", "Amazon S3", "aws:PrincipalOrgID", "aws:PrincipalOrgPaths", "AWS CloudTrail", "aws:PrincipalTag"], "Commentary": "이 문제는 여러 AWS 계정으로 구성된 조직에서 특정 S3 버킷을 오직 조직 내 계정만 접근하도록 설정하는 방법을 묻습니다. 조직 ID를 활용해 S3 버킷 정책에서 aws:PrincipalOrgID 키를 사용하면, 심플하고 효율적으로 조직 내 모든 계정 사용자에게만 접근을 허용할 수 있습니다. 다른 옵션들은 조직 구조 변경, CloudTrail 이벤트 모니터링, 사용자 태깅 등 추가 관리 작업이 많아 운영 오버헤드가 증가합니다.", "Selections": {"SelectA": {"Select": "S3 버킷 정책에 aws:PrincipalOrgID 글로벌 컨디션 키를 조직 ID로 참조하도록 추가합니다.", "Commentary": "조직 내 계정임을 쉽게 검증하므로 유지보수가 최소화되고 접근 제어가 간편합니다. 정답입니다."}, "SelectB": {"Select": "각 부서별로 조직 단위(OU)를 만들고, aws:PrincipalOrgPaths 글로벌 컨디션 키를 S3 버킷 정책에 추가합니다.", "Commentary": "OU를 세분화하고 정책을 관리해야 하므로 추가 설정과 관리 비용이 늘어납니다."}, "SelectC": {"Select": "AWS CloudTrail로 CreateAccount, InviteAccountToOrganization, LeaveOrganization, RemoveAccountFromOrganization 이벤트를 모니터링하고 버킷 정책을 그때그때 업데이트합니다.", "Commentary": "계정 변동이 발생할 때마다 직접 정책을 수정해야 하므로 운영이 복잡해집니다."}, "SelectD": {"Select": "S3 버킷 접근이 필요한 각 사용자를 태깅하고, aws:PrincipalTag 글로벌 컨디션 키를 S3 버킷 정책에 추가합니다.", "Commentary": "필요 사용자마다 태그를 꾸준히 관리해야 하므로 계정이 늘어날수록 오버헤드가 커집니다."}}}
{"Question_Number": "Q4", "Question_Description": "한 애플리케이션이 VPC 내의 Amazon EC2 인스턴스에서 실행 중입니다. 해당 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 접근해야 합니다. Amazon S3에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["EC2 인스턴스", "인터넷 없이", "프라이빗 네트워크 연결", "Amazon S3", "VPC Endpoint"], "Terms": ["Amazon EC2", "VPC", "Amazon S3", "Gateway VPC endpoint", "CloudWatch Logs", "Instance profile", "Amazon API Gateway"], "Commentary": "이 문제는 VPC 내 EC2 인스턴스가 인터넷 없이 Amazon S3 버킷에 접근해야 하는 상황입니다. Gateway VPC endpoint를 사용하면 사설 경로를 통해 S3와 안전하게 통신할 수 있으므로 비용 부담도 적고 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "S3 버킷에 대한 Gateway VPC endpoint를 생성합니다.", "Commentary": "Gateway VPC endpoint는 S3에 대한 사설 경로를 제공하여 인터넷 연결 없이도 버킷에 안전하게 액세스할 수 있습니다."}, "SelectB": {"Select": "Amazon CloudWatch Logs로 로그를 스트리밍한 뒤, 이를 S3 버킷에 내보냅니다.", "Commentary": "CloudWatch Logs는 로그 집계에 유용하지만, S3와의 직접적인 사설 연결을 제공하지 않아 요구사항을 충족하기 어렵습니다."}, "SelectC": {"Select": "Amazon EC2 인스턴스에 Instance profile을 생성하여 S3 접근을 허용합니다.", "Commentary": "Instance profile은 권한만 부여할 뿐, 인터넷 없이 S3 버킷에 연결할 프라이빗 경로를 제공하지 않습니다."}, "SelectD": {"Select": "Amazon API Gateway API를 사용해 S3 엔드포인트에 대한 프라이빗 링크를 만듭니다.", "Commentary": "API Gateway는 S3에 대한 직접적이고 효율적인 사설 연결 방식이 아니므로 적절한 선택지가 아닙니다."}}}
{"Question_Number": "Q5", "Question_Description": "회사는 단일 Amazon EC2 인스턴스를 사용하여 웹 애플리케이션을 AWS에서 호스팅하고 있으며, 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 동일한 아키텍처를 복제하여 두 번째 EC2 인스턴스와 EBS 볼륨을 다른 Availability Zone에 생성하고, 둘 다 Application Load Balancer 뒤에 배치했습니다. 이 변경을 마친 후, 사용자가 웹사이트를 새로고침할 때마다 어느 순간에는 특정 문서 집합만 보이고, 다른 순간에는 다른 문서 집합만 보이지만 동시에 모든 문서를 볼 수는 없다고 보고했습니다. 사용자가 모든 문서를 한꺼번에 볼 수 있도록 하기 위해 솔루션스 아키텍트는 어떤 제안을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["다중 AZ", "공유 스토리지", "Amazon EBS", "Amazon EFS", "문서 접근", "가용성", "확장성"], "Terms": ["Amazon EC2", "Amazon EBS", "Application Load Balancer", "Availability Zone", "Amazon EFS"], "Commentary": "이 문제는 다중 AZ 환경에서 여러 EC2 인스턴스가 동일한 파일에 접근해야 할 때 공유 스토리지가 필요한 상황을 묻습니다. Amazon EFS를 사용하면 모든 인스턴스에서 실시간으로 동일한 데이터를 볼 수 있어 문제를 해결할 수 있습니다.", "Selections": {"SelectA": {"Select": "두 EBS 볼륨 모두 모든 문서를 포함하도록 데이터를 복사합니다.", "Commentary": "각 볼륨의 데이터를 계속 동기화해야 하므로 운영이 복잡하며, 새 문서가 추가될 때마다 실시간 일관성을 보장하기 어렵습니다."}, "SelectB": {"Select": "Application Load Balancer가 문서를 갖고 있는 서버로 사용자를 보내도록 구성합니다.", "Commentary": "사용자를 문서를 가진 서버로만 연결해도 두 서버의 문서가 각각 다르다면 모든 문서를 동시에 보는 문제는 해결되지 않습니다."}, "SelectC": {"Select": "두 EBS 볼륨의 데이터를 Amazon EFS로 복사하고, 애플리케이션이 새 문서를 Amazon EFS에 저장하도록 수정합니다.", "Commentary": "Amazon EFS는 여러 AZ에서 동시에 접근할 수 있는 공유 파일 시스템이므로, 모든 인스턴스에서 동일한 데이터를 즉시 볼 수 있어 근본적인 문제를 해결하는 최적의 방법입니다."}, "SelectD": {"Select": "Application Load Balancer가 요청을 두 서버로 모두 보내도록 구성하고, 각 서버에서 적절한 문서를 반환합니다.", "Commentary": "두 서버가 가진 문서를 합쳐 보여주려 해도 실시간 동기화 없이 서로 다른 볼륨에 분산된 데이터를 동시에 일관성 있게 제공하기는 어렵습니다."}}}
{"Question_Number": "Q6", "Question_Description": "한 회사가 사내 NFS(Network File System)를 사용하여 대용량 동영상 파일을 저장하고 있습니다. 각 동영상 파일은 1MB부터 500GB까지 다양하며, 총 70TB의 스토리지가 있고 더 이상 증가하지 않습니다. 회사는 이 동영상 파일들을 가능한 한 빨리, 그리고 네트워크 대역폭 사용을 최소화하면서 Amazon S3로 마이그레이션하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["NFS", "동영상 파일", "70TB", "Amazon S3", "마이그레이션", "네트워크 대역폭 최소화", "최대한 빠른 전송", "AWS Snowball Edge"], "Terms": ["NFS", "Amazon S3", "AWS Snowball Edge", "IAM role", "AWS CLI", "S3 File Gateway", "AWS Direct Connect", "NFS file share", "on-premises"], "Commentary": "이 문제는 온프레미스 NFS 스토리지에 보관된 대용량 데이터를 짧은 시간 안에, 그리고 네트워크 사용량을 최소화해서 Amazon S3로 옮기는 방법을 묻습니다. 네트워크 활용도를 고려하면 물리적 장비를 통한 오프라인 전송이 유리하며, Snowball Edge를 통해 대규모 데이터를 효율적으로 마이그레이션할 수 있습니다. 직접 Network 연결 방식인 Direct Connect나 S3 File Gateway를 통한 온라인 전송은 대역폭을 많이 소모하거나 전송 시간이 길어질 수 있으므로, 오프라인 전송이 최적의 선택입니다.", "Selections": {"SelectA": {"Select": "S3 버킷을 생성합니다. S3 버킷에 쓸 수 있는 IAM role을 생성합니다. AWS CLI를 사용하여 모든 파일을 로컬에서 S3 버킷으로 복사합니다.", "Commentary": "70TB 규모를 인터넷으로 직접 전송하면 대역폭 사용이 큽니다. 빠른 전송 방식으로 보기 어렵습니다."}, "SelectB": {"Select": "AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 디바이스를 수령한 후 Snowball Edge 클라이언트를 사용하여 데이터를 디바이스로 옮깁니다. 이후 디바이스를 반환해 AWS에서 Amazon S3로 데이터를 가져오도록 합니다.", "Commentary": "물리적인 장비를 사용하여 대규모 데이터를 오프라인으로 전송하므로 네트워크 대역폭 사용을 최소화하면서도 빠른 전송이 가능합니다. 정답입니다."}, "SelectC": {"Select": "온프레미스에 S3 File Gateway를 배포합니다. 공용 서비스 엔드포인트로 S3 File Gateway에 접속합니다. S3 버킷을 생성한 후, S3 File Gateway에 새 NFS file share를 생성하고 해당 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 File Gateway로 데이터를 전송합니다.", "Commentary": "인터넷을 통한 온라인 전송으로 70TB를 전송하는 데 오랜 시간이 걸리며, 네트워크 대역폭을 크게 소모합니다."}, "SelectD": {"Select": "온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 File Gateway를 배포하고, public VIF를 생성해 S3 File Gateway와 연결합니다. S3 버킷을 생성한 뒤, S3 File Gateway에 새 NFS file share를 만들고 해당 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 File Gateway로 데이터를 전송합니다.", "Commentary": "Direct Connect를 활용해 전송 속도를 높일 수 있지만, 여전히 온라인 전송으로 70TB 전송 시 대역폭 사용이 상당하며 오프라인보다 시간이 더 오래 걸릴 수 있습니다."}}}
{"Question_Number": "Q7", "Question_Description": "한 회사는 들어오는 메시지를 수집하는 애플리케이션을 운영하고 있습니다. 수십 개의 다른 애플리케이션과 마이크로서비스가 이 메시지들을 빠르게 소비합니다. 메시지의 양은 크게 변동하며 때때로 초당 100,000개로 갑자기 증가하기도 합니다. 회사는 솔루션을 느슨하게 결합하고 확장성을 높이기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["메시지", "느슨한 결합", "확장성", "100,000건", "SNS", "SQS"], "Terms": ["Amazon Kinesis Data Analytics", "Amazon Kinesis Data Streams", "Auto Scaling group", "Amazon DynamoDB", "Amazon SNS", "Amazon SQS", "AWS Lambda"], "Commentary": "이 문제는 메시지의 폭발적인 증가에도 빠르게 확장하면서 마이크로서비스들이 동시에 소비할 수 있는 구조, 즉 느슨하게 결합된 아키텍처를 설계하는 방법을 묻습니다. Amazon SNS와 Amazon SQS 조합을 사용하면 게시된 메시지를 여러 큐로 분산하여 처리 가능하며, 높은 확장성을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Kinesis Data Analytics에 메시지를 저장한 뒤, 컨슈머 애플리케이션들이 메시지를 읽고 처리하도록 구성합니다.", "Commentary": "Kinesis Data Analytics는 실시간 분석 용도로 적합하지만, 메시지를 빠르게 분산/수신하는 데는 SNS+SQS 같은 단순 큐 방식이 더 적절합니다."}, "SelectB": {"Select": "Amazon EC2 Auto Scaling 그룹에서 애플리케이션을 배포하고 CPU 지표에 따라 EC2 인스턴스 수를 확대/축소합니다.", "Commentary": "EC2 Auto Scaling만으로는 메시지 처리 로직을 분산하지 못해 느슨한 결합 구조를 확보하기 어렵고, 갑작스러운 트래픽 변화에도 유연성이 제한적입니다."}, "SelectC": {"Select": "단일 shard로 설정된 Amazon Kinesis Data Streams에 메시지를 기록하고, AWS Lambda로 전처리하여 Amazon DynamoDB에 저장합니다. 이후 컨슈머 애플리케이션들이 DynamoDB에서 메시지를 읽어 처리하도록 구성합니다.", "Commentary": "단일 shard는 초당 처리량에 한계가 있어 100,000건 이상의 급증 상황에 대응하기 어렵습니다."}, "SelectD": {"Select": "Amazon SNS 토픽에 메시지를 게시하고, 여러 Amazon SQS 구독을 설정합니다. 컨슈머 애플리케이션들은 각 큐로부터 메시지를 받아 처리하도록 구성합니다.", "Commentary": "SNS+SQS 구조는 높은 확장성과 느슨한 결합을 동시에 달성할 수 있어 급격한 메시지 증가에도 유연하게 대응할 수 있는 최적의 솔루션입니다."}}}
{"Question_Number": "Q8", "Question_Description": "한 회사가 분산된 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 가변적인 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨트 노드에 걸쳐 작업을 조정하는 기본 서버로 구성됩니다. 회사는 복원력과 확장성을 최대화하는 솔루션으로 애플리케이션을 현대화하고자 합니다. 어떻게 설계해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["분산된 애플리케이션", "가변적인 워크로드", "기본 서버", "여러 컴퓨트 노드", "복원력", "확장성", "Amazon SQS", "Amazon EC2", "Auto Scaling 그룹", "큐 크기 기반 스케일링"], "Terms": ["Amazon Simple Queue Service (Amazon SQS)", "Amazon EC2", "Auto Scaling group", "EC2 Auto Scaling", "AWS CloudTrail", "Amazon EventBridge (Amazon CloudWatch Events)"], "Commentary": "이 문제는 레거시 환경에서 기본 서버가 여러 노드를 관리하던 구조를 AWS 서비스로 현대화해, 변동이 큰 워크로드를 효율적으로 처리하고 복원력을 극대화하는 방법을 묻습니다. Amazon SQS를 통해 작업을 큐에 넣고, 큐 크기에 따라 Auto Scaling 그룹의 EC2 인스턴스를 동적으로 확대·축소하는 방식이 가장 적절한 해결책입니다.", "Selections": {"SelectA": {"Select": "Amazon SQS 큐를 작업 전송 대상으로 구성합니다. Amazon EC2 인스턴스로 구성된 컴퓨트 노드를 Auto Scaling group으로 관리하고, EC2 Auto Scaling에서 예약 기반 스케일링을 구성합니다.", "Commentary": "예약 스케일링은 실제 부하와 무관하게 정해진 시점에만 스케일링되어, 가변적인 워크로드를 대응하기엔 유연성이 부족합니다."}, "SelectB": {"Select": "Amazon SQS 큐를 작업 전송 대상으로 구성합니다. Amazon EC2 인스턴스로 구성된 컴퓨트 노드를 Auto Scaling group으로 관리하고, EC2 Auto Scaling에서 큐 크기에 따라 스케일링하도록 설정합니다.", "Commentary": "큐의 길이에 따라 자동으로 인스턴스 수를 조절하는 유연한 아키텍처로, 가변적인 워크로드와 높은 복원성을 모두 만족하는 최적의 솔루션입니다."}, "SelectC": {"Select": "기본 서버와 컴퓨트 노드를 모두 Amazon EC2 인스턴스로 구성하여 Auto Scaling group으로 관리합니다. AWS CloudTrail을 작업 전송 대상으로 구성하고, EC2 Auto Scaling에서 기본 서버의 부하를 기준으로 스케일링합니다.", "Commentary": "CloudTrail은 API 호출 기록 용도로, 작업 대기열로 쓰기에 적합하지 않습니다. 또한 기본 서버와 컴퓨트 노드를 같은 그룹으로 묶으면 계층 분리가 깨져 확장성이 떨어집니다."}, "SelectD": {"Select": "기본 서버와 컴퓨트 노드를 모두 Amazon EC2 인스턴스로 구성하여 Auto Scaling group으로 관리합니다. Amazon EventBridge(Amazon CloudWatch Events)를 작업 전송 대상으로 구성하고, EC2 Auto Scaling에서 컴퓨트 노드의 부하를 기준으로 스케일링합니다.", "Commentary": "EventBridge는 이벤트 라우팅 서비스로, 작업 부하를 처리하기에는 적합하지 않습니다. 기본 서버와 컴퓨트 노드를 분리하지 않아 확장성과 복원성을 모두 극대화하기 어렵습니다."}}}
{"Question_Number": "Q9", "Question_Description": "한 회사가 데이터 센터에서 SMB file server를 운영하고 있습니다. 이 file server는 대용량 파일을 저장하며, 생성 후 처음 며칠 동안 자주 액세스됩니다. 7일이 지나면 파일은 거의 액세스되지 않습니다. 전체 데이터 용량이 꾸준히 증가하여 회사의 스토리지 한계에 도달하고 있습니다. 솔루션스 아키텍트는 최근에 액세스된 파일에 대한 저지연 액세스를 유지하면서도 사용 가능한 스토리지를 확장해야 합니다. 또한, future storage issues를 피하기 위해 파일 lifecycle management도 제공해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["SMB file server", "저지연 액세스", "lifecycle management", "스토리지 용량 확장", "S3 Glacier Deep Archive"], "Terms": ["AWS DataSync", "Amazon S3 File Gateway", "S3 Lifecycle policy", "S3 Glacier Deep Archive", "Amazon FSx for Windows File Server", "Amazon S3"], "Commentary": "이 문제는 기존 온프레미스 SMB file server와 연동하면서 자주 액세스되는 파일에 대한 낮은 지연 시간을 유지하고, 오래된 파일을 자동으로 아카이빙해 비용을 절감하는 솔루션을 찾는 것입니다. Amazon S3 File Gateway를 통해 확장 가능하고 저비용의 클라우드 스토리지를 연동한 뒤, Lifecycle policy로 오래된 파일을 S3 Glacier Deep Archive로 옮겨 효율적인 파일 수명 관리를 달성할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS DataSync를 사용하여 7일 이상 지난 데이터를 SMB file server에서 AWS로 복사합니다.", "Commentary": "단순 복사만 제공하므로 파일을 자주 액세스해야 하는 시나리오에 대한 저지연 액세스 보장이 부족하고, Lifecycle policy 연동도 명시되지 않아 요구사항에 부합하지 않습니다."}, "SelectB": {"Select": "Amazon S3 File Gateway를 생성하여 회사의 스토리지를 확장합니다. 7일 후 데이터를 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle policy를 만듭니다.", "Commentary": "SMB file server와 투명하게 연동해 자주 액세스되는 파일에는 로컬 캐싱으로 저지연을 제공하고, 오래된 파일은 자동으로 저비용 스토리지로 옮겨 요구사항을 충족합니다."}, "SelectC": {"Select": "Amazon FSx for Windows File Server 파일 시스템을 생성하여 회사의 스토리지를 확장합니다.", "Commentary": "Windows 기반 파일 서버를 간단히 확장하지만, 오래된 파일의 자동 아카이빙이나 비용 최적화 관리가 부족하므로 적합하지 않습니다."}, "SelectD": {"Select": "모든 사용자 컴퓨터에 유틸리티를 설치해 Amazon S3에 접근하게 합니다. 7일 후 데이터를 S3 Glacier Flexible Retrieval로 전환하는 S3 Lifecycle policy를 만듭니다.", "Commentary": "각 사용자 측에서 별도 프로그램을 사용해야 하고, File Gateway처럼 SMB 프로토콜과 연동되지 않아 저지연 액세스 제공이 번거로우며 운영 복잡성이 큽니다."}}}
{"Question_Number": "Q10", "Question_Description": "한 회사가 AWS에서 전자상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 새 주문 정보를 처리하기 위해 Amazon API Gateway REST API로 보냅니다. 회사는 주문이 도착한 순서대로 처리되도록 보장하고자 합니다. 이 요구사항을 충족할 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["Amazon API Gateway", "REST API", "Amazon SQS FIFO queue", "AWS Lambda", "주문 처리 순서 보장"], "Terms": ["Amazon API Gateway", "REST API", "Amazon SNS", "AWS Lambda", "Amazon SQS FIFO queue", "Amazon SQS standard queue", "API Gateway authorizer"], "Commentary": "이 문제는 주문이 들어오는 순서대로 처리해야 하는 시나리오에서 적합한 메커니즘을 찾는 것입니다. Amazon SQS FIFO queue는 메시지의 순서를 보장하므로 요구사항을 충족합니다. API Gateway를 통해 메시지를 FIFO 큐로 보내고, AWS Lambda가 순차적으로 메시지를 처리하도록 설정하면 안정적이고 확장 가능한 구조를 구현할 수 있습니다.", "Selections": {"SelectA": {"Select": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다. AWS Lambda 함수를 토픽 구독자로 설정해 주문을 처리합니다.", "Commentary": "Amazon SNS는 메시지 브로드캐스트에 적합하며, 순서 보장은 제공하지 않으므로 요구사항과 맞지 않습니다."}, "SelectB": {"Select": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Queue Service(SQS) FIFO queue에 메시지를 보냅니다. 해당 SQS FIFO queue가 AWS Lambda 함수를 호출하도록 구성해 주문을 처리합니다.", "Commentary": "FIFO 큐는 메시지 순서를 엄격하게 보장하므로 주문을 처리하는 순서를 유지해야 하는 상황에 최적의 선택입니다."}, "SelectC": {"Select": "API Gateway authorizer를 사용하여 애플리케이션이 한 주문을 처리하는 동안 모든 요청을 차단합니다.", "Commentary": "전체 요청을 차단하는 방식은 순서 보장보다는 진입 자체를 제한하는 방법이며, 운영상 비효율적이고 요구사항을 충족하지 못합니다."}, "SelectD": {"Select": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Queue Service(SQS) standard queue로 메시지를 보냅니다. 해당 SQS standard queue가 AWS Lambda 함수를 호출하도록 구성해 주문을 처리합니다.", "Commentary": "SQS standard queue는 높은 처리량을 제공하지만 메시지 순서를 보장하지 않습니다. FIFO 큐와 달리 순서 제어가 불가능합니다."}}}
{"Question_Number": "Q11", "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있으며, Amazon Aurora 데이터베이스를 사용하고 있습니다. EC2 인스턴스는 로컬 파일에 저장된 사용자 이름과 비밀번호를 이용하여 데이터베이스에 접속합니다. 회사는 자격 증명 관리에 대한 운영 오버헤드를 최소화하고 싶어 합니다. 이 목표를 달성하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["Amazon EC2", "Amazon Aurora", "자격 증명 관리", "운영 오버헤드 최소화", "AWS Secrets Manager", "automatic rotation"], "Terms": ["Amazon EC2", "Amazon Aurora", "AWS Secrets Manager", "AWS Systems Manager Parameter Store", "Amazon S3", "AWS Key Management Service (AWS KMS)", "Amazon Elastic Block Store (Amazon EBS)"], "Commentary": "이 문제는 로컬 파일에 저장된 데이터베이스 자격 증명을 안전하게 관리하고 자동으로 갱신할 방법을 찾는 보안 설계 문제입니다. AWS Secrets Manager는 자동 자격 증명 로테이션 기능을 제공하여 운영 오버헤드를 크게 줄여주므로 효과적인 솔루션입니다.", "Selections": {"SelectA": {"Select": "AWS Secrets Manager를 사용하고, automatic rotation을 활성화합니다.", "Commentary": "AWS Secrets Manager는 관리형 비밀번호 로테이션을 지원하므로 자격 증명을 안전하게 보관하고 자동으로 갱신할 수 있어 운영 오버헤드를 최소화합니다."}, "SelectB": {"Select": "AWS Systems Manager Parameter Store를 사용하고, automatic rotation을 활성화합니다.", "Commentary": "Parameter Store는 기본적으로 자동 로테이션을 제공하지 않으므로, 자체 로직이 필요해 관리 비용이 더 큽니다."}, "SelectC": {"Select": "AWS KMS 암호화 키로 암호화된 객체를 저장하는 Amazon S3 버킷을 생성하고, 자격 증명 파일을 마이그레이션하여 애플리케이션이 S3 버킷을 사용하도록 합니다.", "Commentary": "S3 버킷에 자격 증명을 저장해도 자동 로테이션 기능이 없고, 애플리케이션 호출 방식이 복잡해져 운영 오버헤드를 줄이기 어렵습니다."}, "SelectD": {"Select": "각 Amazon EC2 인스턴스에 암호화된 Amazon EBS 볼륨을 생성하고 연결한 뒤, 자격 증명 파일을 옮기고 애플리케이션이 이를 사용하도록 합니다.", "Commentary": "이 방식은 단순히 저장 매체를 암호화하는 것이므로 자동 자격 증명 갱신 기능이 없어 원하는 운영 간소화를 달성하기 어렵습니다."}}}
{"Question_Number": "Q12", "Question_Description": "한 글로벌 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 웹 애플리케이션은 정적 데이터와 동적 데이터를 모두 사용하며, 정적 데이터는 Amazon S3 버킷에 저장됩니다. 회사는 정적 데이터와 동적 데이터의 성능을 개선하고 지연 시간을 줄이고 싶어 합니다. 또한 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다. 이러한 요구 사항을 충족하기 위한 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["정적 데이터", "동적 데이터", "지연 시간 감소", "AWS Global Accelerator", "Amazon CloudFront", "Application Load Balancer", "Amazon S3"], "Terms": ["Amazon Route 53", "Amazon EC2", "Amazon S3", "Application Load Balancer", "Amazon CloudFront", "AWS Global Accelerator"], "Commentary": "이 문제에서는 정적 콘텐츠(S3)와 동적 콘텐츠(ALB) 양쪽 모두의 지연 시간을 줄이고 성능을 높이기 위한 최적의 분산 전략을 묻습니다. Amazon CloudFront는 글로벌 엣지를 활용하여 정적·동적 콘텐츠 모두의 전송 속도를 향상시킬 수 있고, Route 53으로 트래픽을 라우팅해 간단히 구성할 수 있습니다. AWS Global Accelerator는 주로 비HTTP 프로토콜, 혹은 정적 IP가 필요한 특정 사례에 더욱 적합합니다. 따라서 S3와 ALB를 동시에 Origin으로 사용하는 CloudFront 배포가 운영 복잡도와 성능 개선 면에서 최적의 해답입니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront distribution을 생성하고 S3 버킷과 ALB를 각각 Origin으로 설정합니다. Route 53에서 이 CloudFront distribution으로 트래픽을 라우팅하도록 구성합니다.", "Commentary": "정적·동적 콘텐츠를 동일한 CloudFront distribution에서 제공함으로써 네트워크 엣지에서 캐싱과 가속을 동시에 수행해 지연 시간을 효과적으로 줄입니다."}, "SelectB": {"Select": "ALB를 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. AWS Global Accelerator standard accelerator를 생성하고, S3 버킷을 endpoint로 합니다. 그리고 Route 53에서 CloudFront distribution으로 트래픽을 라우팅합니다.", "Commentary": "정적 콘텐츠를 Global Accelerator로, 동적 콘텐츠를 CloudFront로 분리하므로 구성 복잡도가 높아집니다. HTTP 환경에서 Global Accelerator를 꼭 써야 할 이유가 부족합니다."}, "SelectC": {"Select": "S3 버킷을 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. ALB와 CloudFront distribution을 endpoint로 하는 AWS Global Accelerator standard accelerator를 생성합니다. Accelerator DNS에 연결된 커스텀 도메인을 만들어 웹 애플리케이션 엔드포인트로 사용합니다.", "Commentary": "Global Accelerator와 CloudFront를 동시에 사용해 이중 구성을 구성하므로 운영 복잡도가 높아집니다. 필요한 요구사항을 초과해 복잡성을 증가시킵니다."}, "SelectD": {"Select": "ALB를 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. AWS Global Accelerator standard accelerator를 생성하고 S3 버킷을 endpoint로 합니다. 두 개의 도메인 이름을 만들어 하나는 동적 콘텐츠용 CloudFront, 다른 하나는 정적 콘텐츠용 accelerator DNS에 매핑합니다.", "Commentary": "정적·동적 콘텐츠를 각기 다른 경로로 분리하여 도메인까지 이원화합니다. 관리가 복잡해지고 CloudFront 단일 사용 시 얻을 수 있는 이점을 놓칩니다."}}}
{"Question_Number": "Q13", "Question_Description": "한 회사가 AWS 인프라에 대해 매달 정기 유지 보수를 수행합니다. 이 유지 보수 기간 중, 회사는 여러 AWS Region에 걸쳐 있는 Amazon RDS for MySQL 데이터베이스의 자격 증명을 회전해야 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["정기 유지 보수", "Amazon RDS for MySQL", "자격 증명 회전", "여러 AWS Region", "운영 오버헤드 최소화", "AWS Secrets Manager"], "Terms": ["Amazon RDS for MySQL", "AWS Secrets Manager", "AWS Systems Manager", "multi-Region replication", "Amazon S3", "server-side encryption (SSE)", "Amazon EventBridge (Amazon CloudWatch Events)", "AWS Lambda", "AWS Key Management Service (AWS KMS)", "Amazon DynamoDB global table"], "Commentary": "이 문제는 여러 AWS Region에 분산된 Amazon RDS for MySQL 자격 증명을 매달 회전하는 방법을 묻습니다. 가장 간단하고 자동화된 방식으로 자격 증명을 안전하게 관리해야 하므로, AWS Secrets Manager의 자동 회전 기능을 활용하는 것이 최소의 운영 오버헤드를 제공합니다.", "Selections": {"SelectA": {"Select": "AWS Secrets Manager에 자격 증명을 secrets로 저장합니다. 필요한 Region에 대해 multi-Region secret replication을 구성합니다. Secrets Manager를 통해 스케줄에 따라 secrets를 회전하도록 설정합니다.", "Commentary": "AWS Secrets Manager는 RDS 자격 증명 회전에 특화된 자동화 기능과 multi-Region replication 기능을 제공하므로, 관리 부담이 최소화되는 최적의 솔루션입니다."}, "SelectB": {"Select": "AWS Systems Manager의 secure string 매개변수로 자격 증명을 저장합니다. 필요한 Region에 대해 multi-Region secret replication을 구성합니다. Systems Manager를 통해 스케줄에 따라 secrets를 회전하도록 설정합니다.", "Commentary": "Parameter Store도 보안 저장을 지원하지만, RDS 자격 증명 회전에 대한 자동화 기능은 Secrets Manager만큼 완비되어 있지 않아 운영 편의성이 떨어집니다."}, "SelectC": {"Select": "서버 사이드 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용해 AWS Lambda 함수를 호출하여 자격 증명을 회전합니다.", "Commentary": "S3 버킷과 Lambda를 이용한 자체 회전 로직 구현은 운영 복잡도가 높고, 별도의 스크립팅과 관리가 필요합니다."}, "SelectD": {"Select": "AWS Key Management Service(AWS KMS) multi-Region 고객 관리형 키로 자격 증명을 암호화해서 Amazon DynamoDB 글로벌 테이블에 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB에서 secrets를 가져오고 RDS API를 호출해 자격 증명을 회전합니다.", "Commentary": "직접 암호화, DynamoDB 글로벌 테이블, Lambda를 결합한 방안은 구성 요소가 많아 운영 부담이 증가하며, 별도 로직 구현이 필요합니다."}}}
{"Question_Number": "Q14", "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스 기반의 전자상거래 애플리케이션을 운영하고 있습니다. 이 인스턴스들은 여러 가용 영역에 분산된 Amazon EC2 Auto Scaling 그룹에서 실행되며, CPU 사용률 지표를 기준으로 확장됩니다. 전자상거래 애플리케이션은 거래 데이터를 MySQL 8.0 데이터베이스(대형 EC2 인스턴스에 호스팅)로 저장하는데, 애플리케이션 부하가 증가함에 따라 데이터베이스 성능이 급격히 저하되고 있습니다. 애플리케이션은 쓰기 트랜잭션보다 읽기 요청이 더 많은 상황입니다. 회사는 예측하기 어려운 읽기 워크로드 수요를 자동으로 충족하고, 동시에 고가용성을 유지하기 위한 솔루션을 원합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족할까요?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon EC2 Auto Scaling", "MySQL 8.0", "읽기 워크로드", "고가용성", "Amazon Aurora"], "Terms": ["Amazon Redshift", "Amazon RDS", "Amazon Aurora", "Aurora Auto Scaling", "Aurora Replica", "Multi-AZ Deployment", "Amazon ElastiCache", "Memcached", "EC2 Spot Instances"], "Commentary": "이 문제는 읽기 트래픽이 많은 MySQL 기반 전자상거래 애플리케이션에서 데이터베이스를 자동으로 확장하고 고가용성을 유지해야 하는 상황입니다. Amazon Aurora의 Multi-AZ 배포와 Aurora Auto Scaling 기능을 사용하면 요구 사항을 충족하면서 뛰어난 성능과 내결함성을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Redshift를 단일 노드로 구성하여 리더와 컴퓨팅 기능을 동시에 수행합니다.", "Commentary": "Redshift는 주로 데이터 웨어하우징 및 분석(OLAP)용이며, 트랜잭션 데이터베이스 활용 및 자동 확장 요구 사항에 적합하지 않아 성능 저하가 발생할 수 있습니다."}, "SelectB": {"Select": "Amazon RDS를 Single-AZ 배포로 사용하고, Amazon RDS에서 다른 가용 영역에 읽기 전용 인스턴스를 추가하도록 구성합니다.", "Commentary": "Single-AZ 배포는 가용 영역 장애 시 접속 불가 가능성이 있으며, 읽기 트래픽 폭주에 유연하게 대응하기에도 제한이 큽니다."}, "SelectC": {"Select": "Amazon Aurora를 Multi-AZ 배포로 구성하고, Aurora Replicas에 대해 Aurora Auto Scaling을 설정합니다.", "Commentary": "Aurora는 MySQL 호환이 가능하며 Multi-AZ 환경으로 고가용성을 제공하고, 자동 확장을 통해 증가하는 읽기 요청에도 빠르게 대처할 수 있어 정답입니다."}, "SelectD": {"Select": "Amazon ElastiCache for Memcached를 EC2 Spot Instances와 함께 사용합니다.", "Commentary": "Memcached는 읽기 캐싱에 도움이 될 수 있지만, 트랜잭션이 필요한 DB 자체를 대체하기 어렵고 EC2 Spot Instances는 예측 불가능성이 높아 핵심 DB로 적절치 않습니다."}}}
{"Question_Number": "Q15", "Question_Description": "한 회사가 최근 AWS로 마이그레이션을 완료했고, 프로덕션 VPC 내부 및 외부로 흐르는 트래픽을 보호하기 위한 솔루션을 구현하려고 합니다. 이 회사는 온프레미스 데이터 센터에서 점검 서버를 운용하며 트래픽 흐름 분석과 트래픽 필터링을 수행해 왔습니다. 회사는 AWS Cloud에서도 동일한 기능을 갖추길 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["트래픽 보호", "프로덕션 VPC", "트래픽 점검", "트래픽 필터링", "AWS Network Firewall"], "Terms": ["VPC", "트래픽 인바운드/아웃바운드", "Amazon GuardDuty", "Traffic Mirroring", "AWS Network Firewall", "AWS Firewall Manager", "AWS Cloud", "트래픽 흐름 분석"], "Commentary": "이 문제는 기존 온프레미스 점검 서버가 담당하던 트래픽 점검 및 필터링 기능을 AWS 환경에서 어떻게 구현할지를 묻습니다. VPC 내부와 외부 트래픽을 보안 정책에 따라 제어하고, 운영 방식이 간단하며 확장성이 있어야 합니다. AWS Network Firewall은 상태 기반 점검과 규칙 기반 필터링을 제공하여 이러한 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "프로덕션 VPC에서 Amazon GuardDuty를 사용하여 트래픽 점검 및 트래픽 필터링을 수행합니다.", "Commentary": "Amazon GuardDuty는 위협 탐지 서비스로서 자체 필터링 기능을 제공하지 않으므로 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "Traffic Mirroring을 사용하여 프로덕션 VPC의 트래픽을 미러링해 점검 및 필터링을 수행합니다.", "Commentary": "Traffic Mirroring은 트래픽을 복사하여 분석 도구로 보내는 기능만 제공하며, 직접적인 필터링을 수행하지 않습니다."}, "SelectC": {"Select": "AWS Network Firewall을 사용하여 프로덕션 VPC를 위한 트래픽 점검 및 트래픽 필터링 규칙을 생성합니다.", "Commentary": "AWS Network Firewall은 상태 기반 방화벽과 규칙 기반 필터링을 지원해 요구사항을 모두 충족하는 올바른 솔루션입니다."}, "SelectD": {"Select": "AWS Firewall Manager를 사용하여 프로덕션 VPC에 필요한 트래픽 점검 및 필터링 규칙을 생성합니다.", "Commentary": "AWS Firewall Manager는 보안 규칙을 중앙에서 관리하는 서비스로, 트래픽 필터링 엔진을 자체 제공하지 않아 요구사항에 부합하지 않습니다."}}}
{"Question_Number": "Q16", "Question_Description": "한 회사가 AWS에서 Data Lake를 운영하고 있습니다. 이 Data Lake는 Amazon S3와 Amazon RDS for PostgreSQL에 저장된 데이터를 포함합니다. 회사에서는 모든 Data Lake의 데이터 소스를 활용해 데이터 시각화가 가능한 보고 솔루션을 원합니다. 경영진만 모든 시각화 자료에 대해 완전한 접근 권한을 가져야 하며, 그 외 직원들은 제한된 접근 권한만 가져야 합니다. 이러한 요구사항을 충족시키는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["데이터 시각화", "제한된 접근 권한", "Amazon QuickSight", "경영진 전용"], "Terms": ["Amazon QuickSight", "Amazon S3", "Amazon RDS for PostgreSQL", "AWS Glue", "Amazon Athena Federated Query", "Amazon Athena", "S3 bucket policies", "ETL job"], "Commentary": "이 문제는 데이터 레이크 내 여러 데이터 소스로부터 시각화 대시보드를 생성하고, 사용자별(특히 경영진과 일반 직원) 접근 권한을 구분하는 요구사항을 해결하는 방안을 찾는 것입니다. Amazon QuickSight는 다양한 데이터 소스를 연결하고, 사용자와 그룹별 권한관리를 통해 접근 통제 기능을 간편하게 설정할 수 있어 조건을 만족합니다.", "Selections": {"SelectA": {"Select": "Amazon QuickSight에서 Analysis를 생성하고 모든 데이터 소스를 연결해 신규 데이터셋을 만듭니다. 대시보드를 게시하고 적절한 IAM 역할과 공유합니다.", "Commentary": "IAM 역할 기준으로 공유는 가능하나, 세부 사용자/그룹별 접근 제한 설정이 까다롭습니다."}, "SelectB": {"Select": "Amazon QuickSight에서 Analysis를 생성하고 모든 데이터 소스를 연결해 신규 데이터셋을 만듭니다. 대시보드를 게시하고 적절한 사용자와 그룹과 공유합니다.", "Commentary": "사용자와 그룹 기반으로 보다 세밀하고 직관적인 접근 제어가 가능해 요구사항을 충족하는 최적의 솔루션입니다."}, "SelectC": {"Select": "AWS Glue 테이블과 크롤러로 Amazon S3 데이터를 수집하고, AWS Glue ETL 작업을 통해 리포트를 생성하여 Amazon S3에 게시합니다. S3 버킷 정책으로 접근을 제한합니다.", "Commentary": "ETL 기반 리포트 생성은 시각화 기능이 부족하며, 즉각적인 대시보드 공유에 대한 세밀한 권한 제어가 어렵습니다."}, "SelectD": {"Select": "AWS Glue 테이블과 크롤러로 Amazon S3 데이터를 수집하고, Amazon Athena Federated Query를 사용해 Amazon RDS for PostgreSQL 데이터를 조회합니다. Athena로 리포트를 생성하고 Amazon S3에 게시합니다. S3 버킷 정책으로 접근을 제한합니다.", "Commentary": "표준 쿼리와 파일 형태로 결과를 제공하므로 실시간 대시보드 기능과 사용 권한 세분화 측면에서 QuickSight 대비 제한적입니다."}}}
{"Question_Number": "Q17", "Question_Description": "한 회사에서 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되며, 문서 저장소로 Amazon S3 버킷을 사용합니다. 솔루션스 아키텍트는 EC2 인스턴스가 S3 버킷에 접근할 수 있도록 보장해야 합니다. 이를 위해 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["비즈니스 애플리케이션", "EC2 인스턴스", "S3 버킷", "IAM Role", "문서 저장소"], "Terms": ["Amazon EC2", "Amazon S3", "IAM role", "IAM policy", "IAM group", "IAM user"], "Commentary": "이 문제는 Amazon EC2 인스턴스가 Amazon S3 버킷에 접근할 수 있도록 권한을 설정하는 방법에 관한 것입니다. 가장 안전하고 권장되는 방법은 IAM role을 생성해 인스턴스에 연결하는 것이며, 이를 통해 보안 자격 증명 없이도 S3에 안전하게 액세스 가능합니다.", "Selections": {"SelectA": {"Select": "S3 버킷에 대한 액세스를 부여하는 IAM role을 생성하고, 해당 role을 EC2 인스턴스에 연결합니다.", "Commentary": "IAM role을 통해 EC2 인스턴스가 자격 증명 없이 안전하게 S3에 접근할 수 있으며, AWS 모범 사례에 부합하는 가장 적절한 솔루션입니다."}, "SelectB": {"Select": "S3 버킷에 대한 액세스를 부여하는 IAM policy를 생성하고, 이를 EC2 인스턴스에 직접 연결합니다.", "Commentary": "IAM policy는 role이나 user 등에 적용해야 하며, 인스턴스에 직접 부착하는 방식은 존재하지 않으므로 올바르지 않습니다."}, "SelectC": {"Select": "S3 버킷에 대한 액세스를 부여하는 IAM group을 생성하고, 해당 group을 EC2 인스턴스에 연결합니다.", "Commentary": "IAM group은 사용자 계정을 모아 권한을 부여하는 용도로, 인스턴스에 직접 적용할 수 없어 적절한 방법이 아닙니다."}, "SelectD": {"Select": "S3 버킷에 대한 액세스를 부여하는 IAM user를 생성하고, 이 user 계정을 EC2 인스턴스에 연결합니다.", "Commentary": "EC2 인스턴스가 user 자격 증명을 직접 사용하도록 구성하는 것은 관리와 보안 면에서 권장되지 않는 방식입니다."}}}
{"Question_Number": "Q18", "Question_Description": "애플리케이션 개발 팀이 대용량 이미지를 작은 압축 이미지로 변환하는 마이크로서비스를 설계하고 있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면, 해당 이미지는 Amazon S3 버킷에 저장되고, AWS Lambda 함수를 통해 처리 및 압축된 후 별도의 S3 버킷에 압축된 형태로 저장되어야 합니다. 솔루션 아키텍트는 내구성 있고 무상태(stateless)인 구성 요소를 사용하여 이미지를 자동으로 처리할 수 있는 솔루션을 설계해야 합니다. 다음 중 어떤 조합을 구성하면 이 요구사항을 충족할 수 있습니까? (2개를 선택하세요)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["마이크로서비스", "이미지 압축", "S3 버킷", "AWS Lambda", "무상태 컴포넌트", "자동 처리"], "Terms": ["Amazon S3", "AWS Lambda", "Amazon Simple Queue Service (Amazon SQS)", "Amazon SNS", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon EC2"], "Commentary": "이 문제는 무상태이면서 내구성이 뛰어난 구조로 이미지를 자동 처리하는 방안을 묻습니다. S3로부터 업로드 이벤트를 Amazon SQS 큐로 전달하고, AWS Lambda가 큐 메시지를 트리거로 이미지를 압축 처리하는 방식이 가장 단순하고 안정적입니다.", "Selections": {"SelectA": {"Select": "Amazon Simple Queue Service(Amazon SQS) 큐를 생성합니다. Amazon S3 버킷이 이미지를 업로드할 때, 해당 S3 버킷에서 SQS 큐로 알림을 보내도록 구성합니다.", "Commentary": "S3 업로드 이벤트를 SQS 큐에 전달하여 이벤트를 내구성 있게 보관하고, 무상태 구조를 유지하는 핵심 단계입니다. 정답에 필요한 요소입니다."}, "SelectB": {"Select": "AWS Lambda 함수를 Amazon SQS 큐를 호출 소스로 사용하도록 구성합니다. SQS 메시지가 정상 처리되면, 큐에서 메시지를 삭제합니다.", "Commentary": "Lambda 함수를 SQS로부터 직접 트리거해 메시지가 처리될 때마다 자동으로 이미지를 압축 처리하고, 처리 후 메시지를 제거함으로써 중복 수행을 방지합니다. 정답에 필요한 요소입니다."}, "SelectC": {"Select": "AWS Lambda 함수를 S3 버킷의 신규 업로드를 모니터하도록 구성합니다. 업로드된 이미지가 감지되면, 파일 이름을 텍스트 파일(메모리)에 기록하고, 이 파일을 사용해 처리된 이미지를 추적합니다.", "Commentary": "직접 S3 이벤트로 Lambda를 호출할 수 있지만, 문제에서 요구하는 내구성과 무상태 구조를 확보하기 위해서는 SQS를 통해 이벤트를 비동기로 분리하는 것이 적합합니다."}, "SelectD": {"Select": "Amazon EC2 인스턴스를 실행하여 Amazon SQS 큐를 모니터링합니다. 큐에 아이템이 추가될 때마다, EC2 인스턴스에서 파일 이름을 텍스트 파일로 기록하고 Lambda 함수를 호출합니다.", "Commentary": "EC2 인스턴스를 별도로 운영해야 하므로 무상태 아키텍처 요구사항에 부합하지 않으며, 불필요한 운영 복잡성이 증가합니다."}, "SelectE": {"Select": "Amazon EventBridge(Amazon CloudWatch Events)를 구성하여 S3 버킷을 모니터합니다. 이미지가 업로드되면, Amazon SNS 주제로 알림을 전송하여 해당 이메일 구독자에게 알립니다.", "Commentary": "SNS 알림을 이메일로 보내는 방식은 사람이 후속 작업을 진행해야 하므로 자동 처리 요건에 맞지 않습니다."}}}
{"Question_Number": "Q20", "Question_Description": "회사는 동일한 AWS Region 내에서 대규모 프로덕션 데이터를 테스트 환경으로 복제하는 시간을 단축하고 싶어 합니다. 데이터는 Amazon EC2 인스턴스의 Amazon EBS 볼륨에 저장되어 있으며, 복제된 데이터가 변경되더라도 프로덕션 환경에 영향을 주어서는 안 됩니다. 또한 이 데이터를 사용하는 소프트웨어는 항상 높은 I/O 성능을 필요로 합니다. 솔루션 아키텍트는 프로덕션 데이터를 테스트 환경으로 최소한의 시간으로 복제해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["프로덕션 데이터 복제", "테스트 환경", "Amazon EBS", "EBS Snapshot", "Fast Snapshot Restore", "고성능 I/O"], "Terms": ["Amazon EC2", "Amazon EBS", "EBS Multi-Attach", "EBS Snapshot", "EC2 Instance Store", "Fast Snapshot Restore", "I/O 성능"], "Commentary": "이 문제는 프로덕션 환경의 EBS 데이터를 신속하게 테스트 환경에 복사하면서도 높은 I/O 성능과 운영 분리를 달성해야 합니다. Fast Snapshot Restore를 사용하면 스냅샷에서 생성되는 볼륨이 즉시 최대 성능을 제공하므로 복제 시간을 크게 단축할 수 있습니다.", "Selections": {"SelectA": {"Select": "프로덕션 EBS 볼륨의 스냅샷을 생성한 후, 해당 스냅샷을 테스트 환경의 EC2 Instance Store 볼륨에 복원합니다.", "Commentary": "Instance Store는 일시적 스토리지이며 스냅샷 복원 시간이 오래 걸릴 수 있어 운영 분리와 빠른 복제, 고성능 I/O 요구 사항에 모두 부합하기 어렵습니다."}, "SelectB": {"Select": "프로덕션 EBS 볼륨에 EBS Multi-Attach 기능을 구성하고 스냅샷을 생성합니다. 그 후 프로덕션 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.", "Commentary": "Multi-Attach로 같은 볼륨을 동시에 사용하면 프로덕션 데이터가 영향을 받을 가능성이 있으므로, 완전한 환경 분리를 보장하기 어렵습니다."}, "SelectC": {"Select": "프로덕션 EBS 볼륨의 스냅샷을 생성합니다. 새 EBS 볼륨을 만들고 초기화한 후, 프로덕션 EBS 스냅샷을 복원하기 전에 이를 테스트 환경의 EC2 인스턴스에 연결합니다.", "Commentary": "일반적인 스냅샷 복원은 볼륨을 처음 사용할 때 데이터 블록을 로드하는 지연이 발생해 전체 복원 시간이 길어질 수 있습니다."}, "SelectD": {"Select": "프로덕션 EBS 볼륨의 스냅샷을 생성합니다. 해당 스냅샷에 EBS Fast Snapshot Restore 기능을 활성화한 뒤, 새 EBS 볼륨으로 복원하여 테스트 환경의 EC2 인스턴스에 연결합니다.", "Commentary": "Fast Snapshot Restore를 활성화하면 새 볼륨이 생성 즉시 최대 성능을 제공하므로 복제 시간을 단축하고 고성능 I/O를 보장합니다."}}}
{"Question_Number": "Q21", "Question_Description": "한 전자상거래(ecommerce) 회사가 AWS에서 하루에 하나의 특별 할인 상품(one-deal-a-day)을 제공하는 웹사이트를 론칭하려고 합니다. 매일 정확히 하나의 상품이 24시간 동안 판매됩니다. 이 회사는 피크 시간대에 밀리초(ms) 단위의 지연 시간으로 시간당 수백만 건의 요청을 처리할 수 있기를 바랍니다. 가장 적은 운영 오버헤드(operational overhead)로 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.2", "3.3", "3.4"], "Keywords": ["하루에 하나의 특별 할인 상품", "24시간 판매", "수백만 건의 요청", "밀리초 단위 지연 시간", "운영 오버헤드 최소화"], "Terms": ["Amazon S3", "Amazon CloudFront", "Amazon EC2", "Auto Scaling", "Application Load Balancer (ALB)", "Amazon EKS", "Kubernetes Cluster Autoscaler", "Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB", "Amazon RDS for MySQL"], "Commentary": "이 문제는 하루에 하나의 상품을 매우 짧은 지연 시간으로 대규모 트래픽에 대응해야 하는 시나리오입니다. 정적 콘텐츠는 Amazon S3와 CloudFront로 빠르고 확장 가능하게 제공할 수 있으며, 백엔드는 API Gateway와 Lambda 같은 서버리스로 구성해 자동 확장과 운영 단순화를 제공합니다. 데이터베이스 계층도 DynamoDB를 사용하여 높은 처리량과 낮은 지연 시간을 확보할 수 있어, 요구사항을 가장 효율적으로 만족할 수 있습니다.", "Selections": {"SelectA": {"Select": "Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3.", "Commentary": "전체 웹사이트를 S3에서 호스팅하지만 동적 요청 처리와 데이터 관리가 부족합니다. 단순 파일 호스팅 용도로는 좋지만, 초당 대량 트랜잭션 처리를 위한 서버리스 백엔드 구성이 마련되어 있지 않습니다."}, "SelectB": {"Select": "Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website traffic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL.", "Commentary": "EC2 인스턴스와 확장형 RDS 구성은 충분한 성능을 낼 수 있지만, 서버 운영과 Auto Scaling 관리 등 운영 오버헤드가 큽니다. 밀리초 단위 지연에 대응하기 위해서는 인프라 관리가 복잡해집니다."}, "SelectC": {"Select": "Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in traffic. Store the data in Amazon RDS for MySQL.", "Commentary": "EKS로 컨테이너를 자동 확장할 수 있지만, Kubernetes 관리와 클러스터 운영은 여전히 복잡합니다. 서버리스보다 운영 부담이 크며, 데이터베이스도 RDS로 유지 시 오버헤드가 적지 않습니다."}, "SelectD": {"Select": "Use an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB.", "Commentary": "정적 콘텐츠는 S3와 CloudFront, 동적 처리는 API Gateway와 Lambda, 데이터는 DynamoDB에 저장하여 무한 확장성과 낮은 지연 시간을 확보할 수 있습니다. 운영 오버헤드를 최소화하며 고성능을 달성하는 최적의 서버리스 아키텍처입니다."}}}
{"Question_Number": "Q22", "Question_Description": "한 Solutions Architect가 새로운 디지털 미디어 애플리케이션의 스토리지 아키텍처를 Amazon S3로 설계하고 있습니다. 매체 파일은 하나의 가용 영역 상실에도 견딜 수 있어야 하며, 파일들은 어떤 것은 자주 액세스되고 어떤 것은 거의 액세스되지 않을 수 있지만 그 패턴이 예측 불가능합니다. 이 때 파일을 저장하고 검색하는 데 드는 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["디지털 미디어 애플리케이션", "가용 영역 상실", "예측 불가능한 액세스 패턴", "비용 최소화", "S3 Intelligent-Tiering"], "Terms": ["Amazon S3", "S3 Standard", "S3 Intelligent-Tiering", "S3 Standard-Infrequent Access (S3 Standard-IA)", "S3 One Zone-Infrequent Access (S3 One Zone-IA)"], "Commentary": "이 문제는 예측하기 어려운 액세스 패턴을 가진 파일을 안정적으로 보관하고, 비용을 절감해야 하는 상황에서 올바른 S3 스토리지 클래스를 선택하는 것입니다. 가용 영역 상실에도 견딜 수 있어야 하므로 최소 3개의 Availability Zone에 데이터를 저장하는 클래스여야 하며, 접근 빈도의 예측이 어렵다면 S3 Intelligent-Tiering을 고려해야 합니다.", "Selections": {"SelectA": {"Select": "S3 Standard", "Commentary": "S3 Standard는 다중 AZ 내구성을 제공하지만, 자주 액세스되지 않는 객체에도 동일 요율이 부과되어 비용 최적화 효과가 떨어집니다."}, "SelectB": {"Select": "S3 Intelligent-Tiering", "Commentary": "자주 액세스되는 객체와 드물게 액세스되는 객체를 자동으로 계층화하고 비용을 절감하면서도 다중 AZ 내구성을 제공하는 최적의 솔루션입니다."}, "SelectC": {"Select": "S3 Standard-Infrequent Access (S3 Standard-IA)", "Commentary": "다중 AZ 내구성을 제공하지만, 불규칙한 액세스에 적합하지 않고 검색 패턴이 불투명할 경우 비용이 더 들 수 있습니다."}, "SelectD": {"Select": "S3 One Zone-Infrequent Access (S3 One Zone-IA)", "Commentary": "한 개의 AZ에만 데이터를 보관하여 가용 영역 상실에 대응할 수 없어 내구성 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q23", "Question_Description": "한 회사가 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 해당 파일들은 1개월 동안은 자주 액세스되지만 이후로는 거의 액세스되지 않습니다. 또한 회사는 이 파일들을 무기한 보관해야 합니다. 비용 효율성을 최대화하기 위해 사용할 수 있는 가장 적절한 스토리지 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["백업 파일", "무기한 보관", "비용 효율성", "1개월 후 비액세스", "S3 Glacier Deep Archive"], "Terms": ["Amazon S3 Standard", "S3 Intelligent-Tiering", "S3 Glacier Deep Archive", "S3 Standard-IA", "S3 One Zone-IA", "S3 Lifecycle Configuration"], "Commentary": "이 문제는 1개월 후에 더 이상 조회되지 않는 백업 파일을 무기한 보관해야 하므로 장기 보관 및 비용 효율성에 중점을 두는 것이 핵심입니다. Amazon S3 Glacier Deep Archive는 매우 저렴한 비용으로 데이터를 보관할 수 있는 스토리지 클래스이므로, 1개월 후에는 이 클래스로 자동 전환되도록 S3 Lifecycle Policy를 설정하는 것이 가장 비용 효과적입니다.", "Selections": {"SelectA": {"Select": "S3 Intelligent-Tiering을 구성하여 객체를 자동으로 마이그레이션합니다.", "Commentary": "S3 Intelligent-Tiering은 엑세스 패턴이 불규칙할 때 유용하지만, 장기적으로 거의 액세스가 없는 백업 파일에는 Deep Archive만큼 저렴하지 않습니다."}, "SelectB": {"Select": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 Glacier Deep Archive로 전환하도록 설정합니다.", "Commentary": "백업 파일을 1개월 동안 S3 Standard에서 유지한 뒤, 거의 액세스가 없을 때 극도로 저렴한 Deep Archive로 자동 전환해 비용을 크게 절감하는 최적의 선택입니다."}, "SelectC": {"Select": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 Standard-IA로 전환하도록 설정합니다.", "Commentary": "S3 Standard-IA도 저렴하지만, 최장 유지 비용면에서 Deep Archive보다 비싸므로 장기 보관에는 부적합합니다."}, "SelectD": {"Select": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 One Zone-Infrequent Access로 전환하도록 설정합니다.", "Commentary": "One Zone-IA는 내구성 측면에서 여러 AZ를 활용하지 않으므로 백업 파일용으로 안전성이 떨어지며, 장기 보관에서는 Deep Archive만큼 비용 효율적이지 않습니다."}}}
{"Question_Number": "Q24", "Question_Description": "한 회사가 최근 청구서를 확인하던 중 Amazon EC2 비용이 증가한 것을 발견했습니다. 청구 담당 부서에서는 몇 개의 EC2 인스턴스가 원치 않게 인스턴스 유형을 상향(Vertical Scaling)했다는 점을 파악했습니다. 솔루션스 아키텍트는 지난 2개월 간 EC2 비용을 비교하는 그래프를 생성하고, 이러한 상향 조정의 근본 원인을 찾기 위해 심층 분석을 수행해야 합니다. 가장 적은 운영 오버헤드로 정보를 생성하려면 어떻게 해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["인스턴스 유형", "EC2 비용", "비용 비교", "운영 오버헤드 최소화"], "Terms": ["AWS Budgets", "Cost Explorer", "AWS Billing and Cost Management", "AWS Cost and Usage Reports", "Amazon QuickSight", "Amazon S3"], "Commentary": "이 문제는 EC2 인스턴스 유형 변경으로 인한 비용 증가의 원인을 파악하는 방법을 묻습니다. 가장 간단하면서 분석 기능이 뛰어난 Cost Explorer의 필터링 기능을 활용하면, 인스턴스 타입별로 지난 2개월간의 비용 변화를 직관적으로 분석할 수 있습니다. 이 방식이 추가적인 인프라 구성 없이 운영 부담을 최소화하는 데 최적입니다.", "Selections": {"SelectA": {"Select": "AWS Budgets를 사용하여 예산 보고서를 생성하고 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.", "Commentary": "AWS Budgets는 예산 모니터링 및 알림에 강점이 있으나, 세부적인 비용 분석 기능은 제한적입니다."}, "SelectB": {"Select": "Cost Explorer의 세분화된 필터링 기능을 사용하여 인스턴스 유형별 EC2 비용에 대해 심층 분석을 수행합니다.", "Commentary": "Cost Explorer는 인스턴스 유형 별 비용을 직관적으로 비교할 수 있고, 추가 설정이 없어 운영 오버헤드를 크게 줄이는 최적의 선택입니다."}, "SelectC": {"Select": "AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2개월 간 인스턴스 유형별 EC2 비용을 비교합니다.", "Commentary": "대시보드의 그래프 비교는 기본적인 정보를 제공하지만, 원하는 수준의 세밀한 필터링 및 분석 기능이 제한됩니다."}, "SelectD": {"Select": "AWS Cost and Usage Reports를 생성하여 Amazon S3 버킷에 전송하고, Amazon QuickSight로 S3를 소스로 사용하여 인스턴스 유형 기반 인터랙티브 그래프를 생성합니다.", "Commentary": "이 방법은 강력한 시각화가 가능하지만, QuickSight와 S3 설정 등 추가 구성이 필요해 운영 오버헤드가 커집니다."}}}
{"Question_Number": "Q25", "Question_Description": "한 회사가 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 Amazon API Gateway를 통해 정보를 받아 Amazon Aurora PostgreSQL 데이터베이스에 저장하기 위해 AWS Lambda 함수를 사용합니다. 개념 증명 단계에서, 회사는 대규모 데이터를 데이터베이스에 로드하기 위해 Lambda 할당량을 크게 늘려야 했습니다. 솔루션스 아키텍트는 확장성을 높이고 구성 노력을 최소화할 수 있는 새로운 설계를 제안해야 합니다. 어떤 솔루션이 이 요구사항을 만족합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["Lambda 확장성", "Aurora PostgreSQL", "대규모 데이터 로드", "구성 노력 최소화", "애플리케이션 설계"], "Terms": ["AWS Lambda", "Amazon API Gateway", "Amazon Aurora PostgreSQL", "Amazon EC2", "Apache Tomcat", "JDBC", "Amazon DynamoDB", "DynamoDB Accelerator(DAX)", "Amazon SNS", "Amazon SQS"], "Commentary": "이 문제는 API Gateway로 받은 대규모 데이터를 Aurora PostgreSQL에 저장하는 과정에서 Lambda 한도 증가가 필요한 상황을 해결해야 합니다. 기본 Lambda 구조를 무리하게 확장하기보다, 두 개의 Lambda 함수를 두고 Amazon SQS로 분리하면 수신과 적재를 느슨하게 결합해 확장성 및 가용성을 높일 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 리팩터링합니다. 데이터베이스는 JDBC 드라이버를 사용해 연결합니다.", "Commentary": "코드 리팩터링과 EC2 환경 구성에 많은 작업이 필요해 구성 노력이 크고, 서버 관리 부담이 높아집니다."}, "SelectB": {"Select": "Amazon Aurora에서 Amazon DynamoDB로 플랫폼을 변경하고, DynamoDB Accelerator(DAX) 클러스터를 프로비저닝합니다. DAX 클라이언트 SDK를 사용해 기존 DynamoDB API 호출을 DAX 클러스터로 지정합니다.", "Commentary": "Aurora(관계형)에서 DynamoDB(비관계형)로 마이그레이션이 필요해 설계 변경 폭이 크고, SQL을 NoSQL로 바꾸는 데도 큰 노력이 들어갑니다."}, "SelectC": {"Select": "두 개의 Lambda 함수를 구성합니다. 하나는 정보를 수신하고, 다른 하나는 데이터를 데이터베이스에 로드합니다. Amazon Simple Notification Service(Amazon SNS)를 사용해 두 Lambda 함수를 통합합니다.", "Commentary": "SNS 알림으로 데이터를 전달하지만, 대량 전송 시 동시에 많은 이벤트가 발생해 여전히 부하 제어가 어렵습니다."}, "SelectD": {"Select": "두 개의 Lambda 함수를 구성합니다. 하나는 정보를 수신하고, 다른 하나는 데이터를 데이터베이스에 로드합니다. Amazon Simple Queue Service(Amazon SQS) 큐를 사용해 두 Lambda 함수를 통합합니다.", "Commentary": "SQS를 통해 비동기 큐 기반 구조로 확장성과 안정성을 확보하며, 대규모 데이터도 효율적으로 처리할 수 있는 가장 적합한 솔루션입니다."}}}
{"Question_Number": "Q26", "Question_Description": "한 회사가 Amazon S3 버킷의 구성 변경 사항을 검토하여 무단으로 변경된 부분이 없는지 확인해야 합니다. 이를 달성하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon S3", "구성 변경", "무단 변경 방지", "AWS Config"], "Terms": ["AWS Config", "AWS Trusted Advisor", "Amazon Inspector", "Amazon S3 server access logging", "Amazon EventBridge (Amazon CloudWatch Events)"], "Commentary": "이 문제는 S3 버킷 설정이 무단으로 변경되지 않도록 모니터링 및 감사가 가능한 솔루션을 찾는 상황입니다. AWS Config를 통해 S3 버킷 구성 변경 이력을 추적하고 평가 규칙을 적용하면 무단 변경 사항을 빠르게 식별하고 대응할 수 있어, 가장 적절한 해법입니다.", "Selections": {"SelectA": {"Select": "AWS Config를 활성화하고 적절한 규칙을 설정합니다.", "Commentary": "AWS Config는 리소스의 구성 상태를 지속적으로 모니터링하고 기록할 수 있어 무단 변경 사항을 자동으로 감지하고 보고할 수 있습니다."}, "SelectB": {"Select": "AWS Trusted Advisor를 활성화하고 적절한 체크를 설정합니다.", "Commentary": "Trusted Advisor는 모범 사례 관점에서 권장 사항을 제시하지만, 실시간 구성 변경 추적이나 감시 기능은 제한적입니다."}, "SelectC": {"Select": "Amazon Inspector를 활성화하고 적절한 평가 템플릿을 설정합니다.", "Commentary": "Amazon Inspector는 주로 EC2 인스턴스 및 애플리케이션 보안을 평가하는 도구로, S3 버킷 구성 변경 모니터링 용도와는 맞지 않습니다."}, "SelectD": {"Select": "Amazon S3 server access logging을 활성화하고, Amazon EventBridge를 구성합니다.", "Commentary": "서버 액세스 로그와 EventBridge를 사용하면 액세스 및 이벤트 정보를 모니터링할 수 있으나, 직접적이고 체계적인 구성 변경 추적에는 AWS Config가 더 적합합니다."}}}
{"Question_Number": "Q30", "Question_Description": "한 개발 팀이 Performance Insights가 활성화된 general purpose Amazon RDS for MySQL DB instance에서 매월 리소스를 많이 사용하는 테스트를 실행합니다. 이 테스트는 한 달에 한 번, 48시간 동안만 진행되며, 이 데이터베이스를 사용하는 유일한 프로세스입니다. 해당 팀은 DB 인스턴스의 컴퓨팅 및 메모리 사양은 유지하면서, 테스트를 실행하는 비용을 절감하고 싶어 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["RDS", "MySQL", "Performance Insights", "스냅샷", "비용 절감"], "Terms": ["Amazon RDS for MySQL", "Performance Insights", "Snapshot", "귀중(High) Compute", "메모리 사양", "DB instance"], "Commentary": "테스트에만 사용되는 DB를 상시로 유지하면 비용이 많이 듭니다. 스냅샷을 생성 후 DB 인스턴스를 종료하면 월 대부분의 시간에 비용을 절약하면서 필요 시 동일 사양으로 복원할 수 있어 가장 효율적입니다.", "Selections": {"SelectA": {"Select": "테스트가 완료되면 DB 인스턴스를 중지합니다. 필요할 때 DB 인스턴스를 다시 시작합니다.", "Commentary": "인스턴스를 중지해도 저장소 비용은 계속 들고, 7일 제한 등의 제약이 있어 월 1회 장기 중지 시 운용상 불편이 큽니다."}, "SelectB": {"Select": "DB 인스턴스를 사용하는 Auto Scaling policy를 적용하여, 테스트가 완료되면 자동으로 스케일 다운합니다.", "Commentary": "Amazon RDS for MySQL에 직접적인 Auto Scaling 정책이 적용되지 않으며, 테스트 외 시간에도 RDS 인스턴스가 계속 동작해 비용을 절감하기 어렵습니다."}, "SelectC": {"Select": "테스트가 끝나면 스냅샷을 생성합니다. DB 인스턴스를 종료한 뒤, 필요할 때 해당 스냅샷을 복원합니다.", "Commentary": "인스턴스를 완전히 종료해 사용 시간이 없을 때 인스턴스 비용이 들지 않아 가장 비용 효율적입니다. 스냅샷 복원으로 동일 사양을 빠르고 손쉽게 재생성 가능합니다."}, "SelectD": {"Select": "테스트가 완료되면 DB 인스턴스를 소용량 인스턴스로 변경합니다. 필요할 때 다시 원래 사양으로 변경합니다.", "Commentary": "DB 인스턴스 스펙 변경은 원하는 컴퓨팅·메모리를 유지해야 한다는 요구사항과 어긋나며, 변경 과정에서도 추가 비용과 시간이 소요됩니다."}}}
{"Question_Number": "Q31", "Question_Description": "한 회사가 AWS에서 웹 애플리케이션을 호스팅 중이며, 모든 Amazon EC2 인스턴스, Amazon RDS DB 인스턴스, Amazon Redshift 클러스터가 태그(Tag)로 구성되어 있는지 확인하고자 합니다. 이 확인 작업의 구성과 운영 부담을 최소화하려면 어떻게 해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2", "4.3"], "Keywords": ["Amazon EC2", "Amazon RDS", "Amazon Redshift", "태그", "운영 부담 최소화"], "Terms": ["AWS Config", "Cost Explorer", "AWS Lambda", "CloudWatch"], "Commentary": "AWS 리소스의 태그 상태를 자동으로 검사하고 싶다면 AWS Config가 가장 간단하고 효율적인 방법입니다. 수동이나 자체 코드 대신 관리형 규칙을 사용하면 운영 부담이 크게 줄어듭니다.", "Selections": {"SelectA": {"Select": "AWS Config 규칙을 사용하여 태그가 올바르게 설정되지 않은 리소스를 정의하고 감지합니다.", "Commentary": "AWS Config는 자동 규칙으로 미태그 자원을 식별하고 모니터링하므로 운영 부담을 줄이는 최적의 솔루션입니다."}, "SelectB": {"Select": "Cost Explorer를 사용해 태그가 잘못된 리소스를 표시하고 수동으로 태그를 구성합니다.", "Commentary": "Cost Explorer로 확인은 가능하지만 태그 반영 과정이 전부 수동이므로 운영 부담이 높습니다."}, "SelectC": {"Select": "적절한 태그 할당을 확인하는 API 호출을 작성하고, 이를 EC2 인스턴스에서 주기적으로 실행합니다.", "Commentary": "별도 코드 유지와 스케줄 관리가 필요해 운영 복잡성이 큽니다."}, "SelectD": {"Select": "API 호출을 작성해 태그 할당을 확인하고, AWS Lambda 함수를 CloudWatch로 스케줄링해 주기적으로 실행합니다.", "Commentary": "Lambda를 통해 자동화 가능하지만 자체 코드 작성과 유지가 필요해 AWS Config보다 부담이 큽니다."}}}
{"Question_Number": "Q32", "Question_Description": "한 개발 팀이 다른 팀이 접속할 웹사이트를 호스팅해야 합니다. 웹사이트의 콘텐츠는 HTML, CSS, client-side JavaScript, 그리고 images로 구성됩니다. 가장 비용 효율적인 웹사이트 호스팅 방법은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["비용 효율적인 웹사이트 호스팅", "정적 웹사이트", "Amazon S3", "HTML", "client-side JavaScript"], "Terms": ["AWS Fargate", "Amazon S3", "Amazon EC2", "Application Load Balancer", "AWS Lambda", "Express.js", "HTML", "CSS", "client-side JavaScript", "images"], "Commentary": "이 문제는 정적 콘텐츠로만 구성된 웹사이트를 가장 저렴하고 간단하게 호스팅하는 방안을 묻습니다. Amazon S3의 정적 웹 호스팅 기능은 서버나 컨테이너에 비용이 들지 않으므로, 소규모 팀 환경에서 특히 비용 효율적입니다.", "Selections": {"SelectA": {"Select": "웹사이트를 컨테이너로 만든 뒤 AWS Fargate에서 호스팅합니다.", "Commentary": "정적 웹사이트를 컨테이너로 운영하면 불필요한 운영 및 컴퓨팅 비용이 추가되어 최적의 비용 효율이 아닙니다."}, "SelectB": {"Select": "Amazon S3 버킷을 생성하고 그곳에서 웹사이트를 호스팅합니다.", "Commentary": "HTML, CSS, client-side JavaScript 등의 정적 파일은 Amazon S3에서 매우低 운영 비용으로 손쉽게 제공할 수 있으므로 가장 비용 효율적입니다."}, "SelectC": {"Select": "웹 서버를 Amazon EC2 인스턴스에 배포하여 웹사이트를 호스팅합니다.", "Commentary": "EC2 인스턴스를 임대하는 비용이 발생하며, 서버 유지 관리도 필요하므로 정적 사이트 호스팅으로는 효율이 떨어집니다."}, "SelectD": {"Select": "Application Load Balancer를 설정하고 AWS Lambda에서 Express.js 프레임워크를 사용하는 대상으로 연결합니다.", "Commentary": "Lambda와 ALB 구성이 가능하긴 하나, 정적 콘텐츠 제공만을 위해서는 과도하며 복잡도와 비용이 증가합니다."}}}
{"Question_Number": "Q33", "Question_Description": "한 회사가 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 운영하고 있습니다. 피크 시간대에는 수십만 명의 사용자를 지원합니다. 이 회사는 여러 내부 애플리케이션에 수백만 건의 금융 거래 정보를 거의 실시간(near-real-time)으로 공유할 수 있는 확장 가능한 솔루션이 필요합니다. 또한 트랜잭션을 document database에 낮은 지연 시간으로 저장하기 전에 민감한 데이터를 제거해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 구성을 추천해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3", "3.5"], "Keywords": ["온라인 마켓플레이스", "near-real-time", "수백만 건의 금융 거래", "민감한 데이터 제거", "document database", "낮은 지연 시간"], "Terms": ["Amazon DynamoDB", "DynamoDB Streams", "Amazon Kinesis Data Firehose", "Amazon Kinesis Data Streams", "AWS Lambda", "Amazon S3"], "Commentary": "이 문제는 수백만 건의 금융 거래를 거의 실시간으로 여러 내부 애플리케이션에 전달하고, 동시에 민감한 데이터를 제거하여 문서형 데이터베이스에 저장해야 하는 고속·확장성 아키텍처를 설계하는 상황입니다. Amazon Kinesis Data Streams와 AWS Lambda를 조합하면 실시간 처리가 가능하며, Lambda 함수로 민감한 데이터를 제거 후 Amazon DynamoDB에 저장할 수 있습니다. 다른 애플리케이션들은 Kinesis Data Streams로부터 직접 데이터를 구독함으로써 확장성을 유지하면서도 지연 시간을 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon DynamoDB에 트랜잭션 데이터를 저장하고, DynamoDB에 쓰여질 때 민감한 데이터를 제거하도록 설정합니다. DynamoDB Streams를 사용하여 다른 애플리케이션과 데이터를 공유합니다.", "Commentary": "DynamoDB에 쓰기 시점에서 자동 필터링 규칙을 적용하는 기능은 기본적으로 제공되지 않아 원하는 대로 민감 정보를 완전히 제거하기 어렵습니다."}, "SelectB": {"Select": "트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB와 Amazon S3에 저장합니다. AWS Lambda 통합으로 민감한 데이터를 제거합니다. 다른 애플리케이션들은 Amazon S3에 저장된 데이터를 사용합니다.", "Commentary": "Kinesis Data Firehose는 DynamoDB를 직접 대상으로 지원하지 않으므로, 요구사항인 near-real-time DynamoDB 삽입이 어렵습니다."}, "SelectC": {"Select": "트랜잭션 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 통해 각 트랜잭션에서 민감한 데이터를 제거한 후 Amazon DynamoDB에 저장합니다. 다른 애플리케이션들은 Kinesis 스트림에서 데이터를 소비합니다.", "Commentary": "Kinesis Data Streams와 Lambda의 조합은 최소 지연으로 대량 데이터를 처리하고 민감 정보를 필터링하기 적합하며 DynamoDB 저장으로 저지연 읽기도 가능합니다."}, "SelectD": {"Select": "배치된 트랜잭션 데이터를 Amazon S3에 파일 형태로 저장합니다. AWS Lambda로 각 파일을 처리하여 민감한 데이터를 제거한 다음, 파일을 업데이트하고 Amazon DynamoDB에 저장합니다. 다른 애플리케이션들은 S3에 저장된 파일을 사용합니다.", "Commentary": "배치 파일 처리 방식이므로 실시간성이 떨어지고, 민감 정보 제거-재업로드 과정도 복잡해 요구사항과 맞지 않습니다."}}}
{"Question_Number": "Q34", "Question_Description": "한 회사가 AWS에서 다중 계층 애플리케이션을 호스팅하고 있습니다. 컴플라이언스, 거버넌스, 감사, 보안 목적상 AWS 리소스에 대한 구성 변경 사항을 추적하고 이 리소스들에 대한 API 호출 이력을 기록해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["다중 계층 애플리케이션", "컴플라이언스", "구성 변경 사항", "API 호출 이력", "AWS Config", "AWS CloudTrail"], "Terms": ["AWS Config", "AWS CloudTrail", "Amazon CloudWatch", "Configuration changes", "API calls", "Compliance", "Governance", "Auditing", "Security"], "Commentary": "이 문제는 AWS 리소스에 대한 구성 변경 사항과 API 호출 이력을 동시에 추적해야 하는 상황입니다. AWS Config는 리소스 변경 내역을 지속적으로 모니터링하고, AWS CloudTrail은 사용자 및 서비스 API 호출 정보를 기록하여 보안, 감사, 거버넌스 요구 사항을 모두 충족합니다.", "Selections": {"SelectA": {"Select": "AWS CloudTrail을 사용하여 구성 변경 사항을 추적하고 AWS Config를 사용하여 API 호출을 기록합니다.", "Commentary": "각 서비스의 역할이 반대로 설정되어 있어 요구 사항을 충족하지 못합니다."}, "SelectB": {"Select": "AWS Config를 사용하여 구성 변경 사항을 추적하고 AWS CloudTrail을 사용하여 API 호출을 기록합니다.", "Commentary": "정답입니다. 각 서비스가 맡은 역할과 기능이 정확히 부합해 보안과 감사 요구 사항을 모두 충족합니다."}, "SelectC": {"Select": "AWS Config를 사용하여 구성 변경 사항을 추적하고 Amazon CloudWatch를 사용하여 API 호출을 기록합니다.", "Commentary": "Amazon CloudWatch는 로그 모니터링을 주로 담당하며, API 호출 기록 기능은 CloudTrail이 제공하므로 적절하지 않습니다."}, "SelectD": {"Select": "AWS CloudTrail을 사용하여 구성 변경 사항을 추적하고 Amazon CloudWatch를 사용하여 API 호출을 기록합니다.", "Commentary": "CloudTrail이 API 호출 로깅을 담당해야 하므로, 이 조합은 요구 사항을 충족하지 못합니다."}}}
{"Question_Number": "Q36", "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 개의 AWS Region에 있는 Amazon S3 버킷에 데이터를 저장할 예정입니다. 회사는 모든 데이터를 AWS Key Management Service(AWS KMS)의 Customer managed key로 암호화해야 합니다. 또한 두 버킷에 있는 모든 데이터가 동일한 KMS key로 암호화 및 복호화되어야 하며, 두 Region 각각에 데이터와 해당 KMS key가 존재해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["AWS KMS", "Customer managed key", "S3 버킷", "다른 Region", "암호화"], "Terms": ["Multi-Region KMS key", "SSE-KMS", "SSE-S3", "Client-side Encryption", "Server-side Encryption", "Replication"], "Commentary": "이 문제는 동일한 Customer managed key를 두 개의 Region에서 모두 활용해야 하는 조건을 만족하면서 운영 오버헤드를 최소화하는 KMS 암호화 방안을 묻습니다. Multi-Region KMS key를 사용해야 Region별 동일 키 운용이 가능합니다.", "Selections": {"SelectA": {"Select": "각 Region에 S3 버킷을 생성하고, Amazon S3 managed encryption keys(SSE-S3)로 서버측 암호화를 활성화합니다. 그런 다음 두 버킷 간에 복제를 구성합니다.", "Commentary": "SSE-S3는 고객이 관리하는 KMS key가 아니라서 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "Multi-Region KMS key로 Customer managed key를 생성합니다. 각 Region에 S3 버킷을 생성하고, 버킷 간 복제를 구성합니다. 애플리케이션은 이 KMS key를 사용해 클라이언트 측 암호화를 수행합니다.", "Commentary": "Multi-Region KMS key를 사용해 두 Region에서 동일한 키를 운용할 수 있으므로 요구사항을 충족하며 운영이 간단합니다."}, "SelectC": {"Select": "각 Region에 Customer managed KMS key와 S3 버킷을 생성합니다. 버킷을 SSE-S3로 서버측 암호화하도록 설정합니다. 두 버킷 간 복제를 구성합니다.", "Commentary": "KMS key는 생성했지만 실제 버킷 암호화는 SSE-S3를 사용하므로 Customer managed key 요구사항에 부합하지 않습니다."}, "SelectD": {"Select": "각 Region에 Customer managed KMS key와 S3 버킷을 생성합니다. 버킷을 AWS KMS keys(SSE-KMS)로 서버측 암호화하도록 설정합니다. 두 버킷 간 복제를 구성합니다.", "Commentary": "일반적인 KMS key는 Region 간 공유가 불가능하므로 동일한 키로 암호화·복호화한다는 조건을 만족하기 어렵습니다."}}}
{"Question_Number": "Q37", "Question_Description": "한 회사가 최근에 본인의 AWS account에서 Amazon EC2 인스턴스 위에 다양한 신규 워크로드를 시작했습니다. 회사는 이러한 인스턴스에 원격으로 안전하게 접속하고 관리하기 위한 전략이 필요합니다. 이 프로세스는 반복 가능해야 하고, 네이티브 AWS 서비스를 활용하며, AWS Well-Architected Framework를 준수해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon EC2 인스턴스", "원격 액세스", "보안 관리", "반복 가능한 프로세스", "AWS Well-Architected Framework", "운영 오버헤드 최소화", "IAM role", "Session Manager"], "Terms": ["Amazon EC2", "AWS account", "EC2 serial console", "IAM role", "AWS Systems Manager Session Manager", "SSH key pair", "bastion host", "AWS Site-to-Site VPN", "AWS Well-Architected Framework"], "Commentary": "이 문제는 Amazon EC2 인스턴스에 대한 원격 액세스를 안전하고 반복 가능하게 설계하는 방법을 묻습니다. AWS Systems Manager Session Manager를 사용하면 인바운드 포트를 열 필요가 없고, SSH 키나 bastion host 관리 부담을 줄여 운영 오버헤드를 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "각 인스턴스의 EC2 serial console을 사용하여 직접 터미널 인터페이스에 접근해 관리합니다.", "Commentary": "serial console은 긴급 상황에서 유용하지만 개별 인스턴스마다 직접 접근해야 해 대규모 운영에는 비효율적입니다."}, "SelectB": {"Select": "모든 기존 및 신규 인스턴스에 적절한 IAM role을 연결하고, AWS Systems Manager Session Manager로 원격 SSH 세션을 설정합니다.", "Commentary": "Session Manager는 인바운드 포트나 SSH 키 관리가 필요 없어 운영 부담이 크지 않으며, 보안과 확장성을 동시에 만족합니다."}, "SelectC": {"Select": "관리용 SSH key pair를 생성하고 공용 키를 각각의 EC2 인스턴스에 로드합니다. 퍼블릭 서브넷에 bastion host를 두어 터널링 방식으로 인스턴스를 관리합니다.", "Commentary": "bastion host 운영과 SSH 키 관리를 지속해야 하므로 운영 절차가 복잡하고 오버헤드가 높습니다."}, "SelectD": {"Select": "AWS Site-to-Site VPN 연결을 설정하고, 온프레미스 머신에서 SSH 키를 이용해 VPN 터널로 인스턴스에 직접 접속하도록 안내합니다.", "Commentary": "VPN 구성과 SSH 키 관리, 별도의 네트워크 설정 등이 추가로 필요하여 운영 부담이 높아집니다."}}}
{"Question_Number": "Q38", "Question_Description": "한 회사가 Amazon S3를 통해 정적 웹사이트를 호스팅하고, DNS로 Amazon Route 53을 사용하고 있습니다. 전 세계적으로 웹사이트 트래픽이 증가해 사용자 접속 시 지연 시간(latency)을 줄여야 합니다. 가장 비용 효율적인 해결책은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["정적 웹사이트", "지연 시간 감소", "비용 효율", "Amazon S3", "Amazon Route 53", "Amazon CloudFront"], "Terms": ["Amazon S3", "Amazon Route 53", "AWS Global Accelerator", "Amazon CloudFront", "S3 Transfer Acceleration", "Geolocation Routing", "DNS", "Static Website"], "Commentary": "이 문제는 전 세계 사용자에게 정적 웹사이트를 빠르게 제공하고 비용을 최소화하기 위한 방안을 묻습니다. Amazon CloudFront를 사용하면 글로벌 엣지 로케이션에 콘텐츠를 캐싱하여 지연 시간을 낮추고, 별도의 복잡한 복제나 추가 인프라가 없어 가장 비용 효율적으로 성능을 개선할 수 있습니다.", "Selections": {"SelectA": {"Select": "웹사이트를 담고 있는 S3 버킷을 모든 AWS 리전에 복제합니다. Route 53 지리 위치(geolocation) 라우팅 규칙을 추가합니다.", "Commentary": "모든 리전에 버킷 복제와 geolocation 라우팅 설정은 비용도 높고 구성도 복잡해져 비효율적입니다."}, "SelectB": {"Select": "AWS Global Accelerator를 프로비저닝하고 제공된 IP 주소를 해당 S3 버킷과 연결합니다. Route 53 레코드를 Accelerator IP로 수정합니다.", "Commentary": "Global Accelerator는 추가 인프라와 비용이 늘어나며 CloudFront와 유사한 가속 기능을 중복으로 제공합니다."}, "SelectC": {"Select": "S3 버킷 앞에 Amazon CloudFront distribution을 추가하고, Route 53 레코드를 CloudFront distribution으로 수정합니다.", "Commentary": "CloudFront의 글로벌 캐싱과 엣지 로케이션을 통해 지연 시간을 줄이고 운영 복잡성과 비용도 절감하는 최적의 솔루션입니다."}, "SelectD": {"Select": "S3 Transfer Acceleration을 활성화하고, Route 53 레코드를 새로운 엔드포인트로 수정합니다.", "Commentary": "Transfer Acceleration은 주로 업로드 가속에 유리하며, 정적 웹사이트 전달 지연 시간 개선에는 제한적입니다."}}}
{"Question_Number": "Q39", "Question_Description": "한 회사는 웹사이트에서 검색 가능한 아이템 저장소를 운영하고 있습니다. 이 데이터는 1천만 건이 넘는 레코드를 담은 Amazon RDS for MySQL 데이터베이스 테이블에 저장되어 있으며, General Purpose SSD 스토리지를 2TB 사용 중입니다. 회사 웹사이트를 통해 매일 수백만 건의 업데이트가 이루어지는데, 일부 insert 연산이 10초 이상 걸리는 현상을 발견했습니다. 데이터베이스 스토리지 성능이 문제로 확인되었습니다. 다음 중 이 성능 문제를 해결할 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.3"], "Keywords": ["Amazon RDS for MySQL", "General Purpose SSD", "Provisioned IOPS SSD", "insert 연산 지연", "스토리지 성능 문제"], "Terms": ["Amazon RDS for MySQL", "General Purpose SSD", "Provisioned IOPS SSD", "memory optimized instance class", "burstable performance instance class", "Multi-AZ RDS", "MySQL native asynchronous replication", "RDS read replicas"], "Commentary": "이 문제는 스토리지 I/O 성능이 병목이 되어 insert 연산이 지연되는 상황입니다. 높은 IOPS를 보장하는 Provisioned IOPS SSD로 전환하면 일관적이고 예측 가능한 스토리지 성능을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "스토리지 타입을 Provisioned IOPS SSD로 변경합니다.", "Commentary": "Provisioned IOPS SSD는 높은 IOPS를 보장하여 저장 연산 지연을 줄이는 데 가장 효과적입니다."}, "SelectB": {"Select": "DB 인스턴스를 memory optimized instance class로 변경합니다.", "Commentary": "메모리 증가로 캐싱 효과를 기대할 수 있지만, 스토리지 I/O 병목 자체를 해결하지 못하므로 근본적 대안이 아닙니다."}, "SelectC": {"Select": "DB 인스턴스를 burstable performance instance class로 변경합니다.", "Commentary": "버스팅 기능은 주로 CPU 성능 확장에 유리하며, 스토리지 성능 문제 해결과는 직접적인 관련이 없습니다."}, "SelectD": {"Select": "Multi-AZ RDS read replicas를 MySQL native asynchronous replication으로 활성화합니다.", "Commentary": "읽기 성능 확장에는 도움이 되지만, 기본 DB에 대한 쓰기(insert) 성능 개선에는 도움이 되지 않습니다."}}}
{"Question_Number": "Q40", "Question_Description": "한 회사는 수천 대의 엣지 디바이스에서 매일 총 1TB의 상태 알림(status alerts)을 생성합니다. 각 알림은 약 2KB 정도의 크기입니다. 이제 솔루션스 아키텍트는 추후 분석을 위해 이러한 알림을 수집하고 저장하는 솔루션을 구축해야 합니다. 회사는 고가용성(highly available)을 원하면서도 비용을 최소화하고 추가 인프라 관리를 원치 않습니다. 또한 14일 동안은 데이터를 즉시 분석하기 위해 사용 가능해야 하며, 14일이 지난 데이터는 보관(archive)해야 합니다. 이 요구사항을 만족하면서 가장 운영 효율적인(MOST operationally efficient) 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1", "2.2"], "Keywords": ["엣지 디바이스", "알림 데이터", "고가용성", "코스트 최소화", "데이터 수집", "14일 보관", "장기 보관"], "Terms": ["Amazon Kinesis Data Firehose", "Amazon S3", "S3 Lifecycle", "Amazon S3 Glacier", "Amazon EC2", "Elastic Load Balancer", "Amazon OpenSearch Service", "Amazon Simple Queue Service (Amazon SQS)"], "Commentary": "이 문제는 대규모 엣지 디바이스에서 생성되는 상태 알림을 자동으로 수집하고, 14일 동안은 신속하게 분석하며, 이후에는 저비용 스토리지로 보관하는 방안을 찾는 것입니다. Kinesis Data Firehose를 사용하면 완전 관리형 스트리밍 서비스로 알림을 안전하게 S3에 저장하고, Lifecycle 정책을 통해 데이터를 자동으로 Glacier로 이전할 수 있어 운영 효율성과 비용 절감을 모두 달성할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Kinesis Data Firehose delivery stream을 생성하여 알림을 수집합니다. Kinesis Data Firehose 스트림에서 Amazon S3 버킷으로 알림을 전송하도록 구성합니다. 그리고 S3 Lifecycle 설정을 통해 14일 이후 데이터를 Amazon S3 Glacier로 이전하도록 구성합니다.", "Commentary": "완전 관리형 스트리밍 서비스인 Kinesis Data Firehose와 S3 Lifecycle 설정만으로 구축 가능해 운영이 간소화되고, 비용도 절감됩니다."}, "SelectB": {"Select": "두 개의 가용 영역(Availability Zone)에 Amazon EC2 인스턴스를 띄우고, Elastic Load Balancer 뒤에 두어 알림을 수집합니다. EC2 인스턴스에 스크립트를 만들어 알림을 Amazon S3 버킷에 저장하도록 합니다. 14일 이후에는 S3 Lifecycle 정책을 통해 S3 Glacier로 이전합니다.", "Commentary": "EC2 인스턴스 관리와 확장, 로드 밸런서 구성 등 추가 인프라가 필요해 운영 복잡도가 높아집니다."}, "SelectC": {"Select": "Amazon Kinesis Data Firehose delivery stream을 생성하여 알림을 수집합니다. Kinesis Data Firehose 스트림이 Amazon OpenSearch Service(이전 Amazon Elasticsearch Service) 클러스터로 알림을 전송하도록 구성합니다. OpenSearch Service 클러스터는 매일 수동 스냅샷을 찍고, 14일 이상 된 데이터는 클러스터에서 삭제합니다.", "Commentary": "OpenSearch Service를 활용하면 검색과 분석이 쉽지만, 14일 이전 데이터 보관을 위해 수동으로 스냅샷을 관리해야 하므로 운영 부담이 큽니다."}, "SelectD": {"Select": "Amazon Simple Queue Service(Amazon SQS) 표준 큐를 생성하여 알림을 수집하고, 메시지 보존 기간을 14일로 설정합니다. 컨슈머는 SQS 큐를 폴링하면서 메시지의 연령을 확인해 필요 시 분석하고, 14일이 지난 메시지는 Amazon S3에 복사 후 큐에서 삭제합니다.", "Commentary": "개발자가 메시지 연령 및 보관 처리를 직접 구현해야 하므로 코드와 인프라 관리가 까다롭습니다."}}}
{"Question_Number": "Q41", "Question_Description": "어떤 회사의 애플리케이션은 여러 SaaS(Software-as-a-Service) 소스와 연동되어 데이터를 수집합니다. 회사는 Amazon EC2 인스턴스를 사용하여 데이터를 수신하고 Amazon S3 버킷으로 업로드한 뒤 분석에 활용합니다. 또한 같은 EC2 인스턴스가 업로드 완료 시점에 사용자에게 알림을 발송합니다. 현재 애플리케이션 성능이 저하되어 이를 최대한 개선하고자 합니다. 운영 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2"], "Keywords": ["EC2 인스턴스", "S3 버킷", "알림", "성능 향상", "운영 오버헤드", "Auto Scaling group", "S3 event notification", "Amazon SNS"], "Terms": ["Amazon EC2", "Amazon S3", "Amazon SNS", "Auto Scaling group", "Amazon AppFlow", "Amazon EventBridge", "Docker container", "Amazon ECS", "Amazon CloudWatch Container Insights"], "Commentary": "이 문제는 SaaS 소스로부터 데이터를 수집해 S3에 업로드하고, 업로드 후 사용자에게 알리는 과정을 성능 저하 없이 진행하려면 어떻게 할지 묻습니다. 이미 Amazon EC2에 구현된 워크로드를 Auto Scaling group으로 확장하고, 알림 로직을 S3 event notification+Amazon SNS로 분리해 병목을 최소화하는 것이 가장 단순하고 효과적인 방법입니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스가 확장 가능하도록 Auto Scaling group을 구성합니다. Amazon S3 버킷으로 업로드가 완료되면 Amazon S3 event notification을 통해 Amazon SNS 토픽으로 이벤트를 전송하도록 설정합니다.", "Commentary": "기존 EC2 인스턴스를 유지하면서 확장성을 제공하고, 알림 단계를 S3 event notification으로 분리해 부하를 줄여 성능을 높이는 가장 간단하고 효과적인 솔루션입니다."}, "SelectB": {"Select": "각 SaaS 소스와 S3 버킷 간 데이터 전송을 위해 Amazon AppFlow 플로우를 생성합니다. S3 버킷으로 업로드가 완료되면 Amazon S3 event notification으로 Amazon SNS 토픽에 알림을 전송하도록 구성합니다.", "Commentary": "Amazon AppFlow를 새로 구성하고 장애 시 처리를 고려해야 하므로 운영 오버헤드가 늘어납니다. 이미 있는 EC2 기반 워크로드 확장보다 설정과 관리가 복잡합니다."}, "SelectC": {"Select": "각 SaaS 소스별로 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 설정해 데이터를 S3 버킷으로 전송합니다. S3 업로드 완료 시점을 감지하도록 두 번째 EventBridge 규칙을 생성하고, Amazon SNS 토픽을 대상으로 설정합니다.", "Commentary": "EventBridge 규칙을 소스별로 설정하고 업로드 후 알림을 위한 이중 규칙을 구성해야 하므로, 새로운 인프라 구성이 많아집니다. 운영 오버헤드가 증가합니다."}, "SelectD": {"Select": "Docker 컨테이너를 만들어 Amazon EC2 인스턴스 대신 사용하고, Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. 업로드 완료 알림은 Amazon CloudWatch Container Insights로 Amazon SNS 토픽에 전달되도록 설정합니다.", "Commentary": "기존 인스턴스를 폐기하고 컨테이너 기반으로 전환하며 추가 모니터링을 구성해야 하므로, 아키텍처 전체를 크게 변경하는 방안입니다. 요구사항 대비 과도하게 복잡합니다."}}}
{"Question_Number": "Q42", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 고가용성 이미지 처리 애플리케이션을 단일 VPC 내부에서 운영하고 있습니다. EC2 인스턴스들은 여러 가용 영역에 걸쳐 다양한 서브넷에 배치되어 있으며, 서로 간에는 통신하지 않습니다. 그러나 모든 EC2 인스턴스는 단일 NAT Gateway를 통해 Amazon S3로부터 이미지를 다운로드하고, Amazon S3로 이미지를 업로드합니다. 회사는 발생하는 데이터 전송 요금에 대해 우려하고 있습니다. 가장 비용 효율적인 방식으로 리전 간 데이터 전송 요금을 회피하기 위해서는 어떤 방법을 사용해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["데이터 전송 요금", "NAT Gateway", "Amazon S3", "Gateway VPC Endpoint"], "Terms": ["Amazon EC2", "VPC", "NAT Gateway", "Gateway VPC Endpoint for Amazon S3", "EC2 Dedicated Host"], "Commentary": "이 문제는 NAT Gateway를 통해 S3로 데이터를 전송할 때 발생하는 비용을 최소화하는 방법을 찾는 것입니다. Gateway VPC Endpoint를 사용하면 VPC와 S3 간 트래픽이 인터넷으로 나가지 않아 전송 요금이 발생하지 않습니다. 따라서 S3에 대한 접근에 있어 가장 비용 효율적인 방식입니다.", "Selections": {"SelectA": {"Select": "각 가용 영역마다 NAT Gateway를 생성합니다.", "Commentary": "가용 영역마다 NAT Gateway를 배포하면 중복성과 가용성은 높아지지만, NAT Gateway 요금이 여러 개로 늘어나 오히려 비용이 더 증가합니다."}, "SelectB": {"Select": "NAT Gateway 대신 NAT Instance를 사용합니다.", "Commentary": "NAT Instance가 NAT Gateway보다 저렴할 수 있지만, 여전히 인터넷 트래픽 경로가 필요해 데이터 전송 요금 자체를 없애지는 못합니다."}, "SelectC": {"Select": "Amazon S3용 Gateway VPC Endpoint를 배포합니다.", "Commentary": "S3로의 데이터 전송이 인터넷 경로를 거치지 않고 내부 통신으로 처리되어 전송 요금이 발생하지 않으므로 가장 비용 효율적인 솔루션입니다."}, "SelectD": {"Select": "EC2 Dedicated Host를 프로비저닝합니다.", "Commentary": "Dedicated Host는 물리 서버 전용 사용을 위한 옵션으로, 데이터 전송 요금과는 무관하여 비용 절감 효과가 거의 없습니다."}}}
{"Question_Number": "Q43", "Question_Description": "한 회사에는 온프레미스 애플리케이션이 있으며 이 애플리케이션은 대규모 시간 민감형 데이터를 생성하여 Amazon S3로 백업합니다. 최근 애플리케이션이 확장되면서 내부 사용자들이 인터넷 대역폭 제약에 대해 불만을 제기하고 있습니다. 솔루션스 아키텍트는 인터넷 연결에 미치는 영향을 최소화하면서도 Amazon S3로 신속하게 백업할 수 있는 장기 솔루션을 설계해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["온프레미스 백업", "시간 민감 데이터", "인터넷 대역폭 제약", "Amazon S3", "AWS Direct Connect"], "Terms": ["AWS VPN", "VPC Gateway Endpoint", "AWS Direct Connect", "AWS Snowball", "S3 Service Limits", "Internet Bandwidth"], "Commentary": "이 문제는 대규모 데이터를 S3로 꾸준히 백업하면서, 내부 네트워크 혼잡을 줄이고 백업 속도를 확보하는 방안을 찾는 것입니다. VPN은 여전히 공용 인터넷에 의존하고, Snowball 매일 주문은 효율이 떨어집니다. S3 서비스 제한 해제 역시 대역폭 문제를 해결하지 못합니다. 따라서 전용 네트워크 연결 방식인 AWS Direct Connect가 장기적이고 안정적인 솔루션이 됩니다.", "Selections": {"SelectA": {"Select": "AWS VPN 연결을 구축하고 모든 트래픽을 VPC Gateway Endpoint를 통해 프록시합니다.", "Commentary": "VPN은 여전히 인터넷을 사용하여 내부 대역폭 문제를 해결하지 못합니다."}, "SelectB": {"Select": "새로운 AWS Direct Connect 연결을 구축하고 백업 트래픽을 이 연결로 전송합니다.", "Commentary": "전용 회선을 통해 인터넷을 우회하여 빠르고 안정적으로 백업이 가능하므로 요구사항을 충족합니다."}, "SelectC": {"Select": "매일 AWS Snowball 디바이스를 주문하여 데이터를 Snowball에 적재 후 AWS로 반환합니다.", "Commentary": "매일 디바이스를 교환하는 방식은 장기적인 운영 측면에서 비효율적입니다."}, "SelectD": {"Select": "AWS Management Console에서 지원 티켓을 제출하여 계정의 S3 서비스 제한을 제거해 달라고 요청합니다.", "Commentary": "S3 제한 설정을 풀어도 인터넷 대역폭 문제는 해결되지 않습니다."}}}
{"Question_Number": "Q44", "Question_Description": "한 회사가 중요한 데이터를 저장한 Amazon S3 버킷을 보유합니다. 회사는 해당 데이터를 실수로 삭제하는 상황을 막아야 합니다. 이를 달성하기 위해 솔루션스 아키텍트는 어떤 두 단계를 수행해야 합니까? (2개 선택)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2", "1.3"], "Keywords": ["Amazon S3 버킷", "실수로 인한 삭제 방지", "Versioning", "MFA Delete", "중요 데이터 보호"], "Terms": ["S3 Versioning", "MFA Delete", "S3 Bucket Policy", "Default Encryption", "Lifecycle Policy"], "Commentary": "Versioning 활성화와 MFA Delete를 통한 2중 안전장치가 실수로 인한 객체 삭제를 방지하는 핵심 전략입니다. 다른 설정들은 보안이나 관리에는 도움이 되지만 삭제 방지를 완벽히 대체하지 못합니다.", "Selections": {"SelectA": {"Select": "S3 버킷에서 Versioning을 활성화합니다.", "Commentary": "Versioning을 통해 객체의 이전 버전을 보관해 간단히 복원할 수 있습니다."}, "SelectB": {"Select": "S3 버킷에서 MFA Delete를 활성화합니다.", "Commentary": "삭제 시 추가 인증을 요구해 실수 혹은 무단 삭제를 예방합니다."}, "SelectC": {"Select": "S3 버킷에 Bucket Policy를 생성합니다.", "Commentary": "접근을 세분화할 수 있으나 삭제 방지 기능 자체는 제공하지 않습니다."}, "SelectD": {"Select": "S3 버킷에서 기본 암호화를 활성화합니다.", "Commentary": "데이터 암호화는 보안을 향상하지만 삭제 방지와 직접적 연관이 없습니다."}, "SelectE": {"Select": "S3 버킷의 객체에 대해 Lifecycle Policy를 생성합니다.", "Commentary": "객체 이동 및 만료 관리를 위한 것이며, 실수 삭제 방지 목적과는 다릅니다."}}}
{"Question_Number": "Q45", "Question_Description": "한 회사는 다음과 같은 데이터 인제스트 워크플로우를 운영하고 있습니다:\n• 새로운 데이터 전달에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽\n• 데이터를 처리하고 메타데이터를 기록하기 위한 AWS Lambda 함수\n\n회사는 네트워크 연결 문제로 인해 인제스트 워크플로우가 간헐적으로 실패하는 것을 관찰했습니다. 이러한 실패가 발생하면, 회사가 수동으로 작업을 다시 실행하지 않는 이상 해당 Lambda 함수는 해당 데이터를 처리하지 않습니다.\n앞으로 Lambda 함수가 모든 데이터를 누락 없이 인제스트하도록 보장하기 위해 솔루션스 아키텍트가 취해야 할 조치 조합은 무엇입니까? (2개를 고르시오.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["데이터 인제스트", "네트워크 연결 문제", "Amazon SNS", "AWS Lambda", "Amazon SQS", "재시도", "큐 기반 아키텍처"], "Terms": ["Amazon Simple Notification Service (Amazon SNS)", "AWS Lambda", "Amazon Simple Queue Service (Amazon SQS)", "Availability Zones", "CPU", "Memory", "Provisioned Throughput"], "Commentary": "이 문제는 네트워크 장애로 인한 알림 누락을 방지하기 위해 SNS와 Lambda 사이에 SQS를 도입하고, Lambda가 SQS에서 메시지를 읽도록 설계해 데이터 유실 없이 안정적으로 처리하도록 하는 것입니다.", "Selections": {"SelectA": {"Select": "Lambda 함수를 여러 Availability Zone에 배포합니다.", "Commentary": "Lambda는 이미 다중 AZ로 고가용성을 제공하므로 추가적인 다중 AZ 배포로 네트워크 연결 문제를 근본적으로 해결하기 어렵습니다."}, "SelectB": {"Select": "Amazon Simple Queue Service(Amazon SQS) 큐를 생성하고, 해당 큐를 SNS 토픽에 구독시킵니다.", "Commentary": "SNS에서 온 메시지를 SQS에 저장함으로써 네트워크 장애 시에도 데이터가 큐에 적재되어 유실 없이 처리할 수 있습니다."}, "SelectC": {"Select": "Lambda 함수에 할당된 CPU와 메모리를 늘립니다.", "Commentary": "CPU와 메모리를 늘려도 네트워크 연결 문제 자체를 해결할 수 없으므로 근본적인 대안이 아닙니다."}, "SelectD": {"Select": "Lambda 함수의 프로비저닝된 처리량을 늘립니다.", "Commentary": "프로비저닝된 처리량은 Lambda를 더 자주 혹은 빠르게 실행하기 위한 방식이며, 네트워크 장애로 인한 실패에는 직접적인 해결 효과가 없습니다."}, "SelectE": {"Select": "Lambda 함수를 수정하여 Amazon SQS 큐에서 메시지를 읽도록 합니다.", "Commentary": "Lambda를 SQS 트리거로 동작하도록 구성하면, 장애 발생 시에도 큐에 쌓인 데이터를 재시도할 수 있어 안정적인 데이터 처리 환경을 확보할 수 있습니다."}}}
{"Question_Number": "Q46", "Question_Description": "한 회사가 매장에서 발생하는 이전 구매 기록을 기반으로 마케팅 서비스를 제공하는 애플리케이션을 운영하고 있습니다. 매장들은 SFTP를 통해 거래 데이터를 회사로 업로드하며, 업로드된 데이터는 분석 및 처리되어 새로운 마케팅 제안을 생성합니다. 일부 파일은 200GB를 초과할 수 있습니다. 최근, 몇몇 매장에서 포함되어서는 안 될 개인정보(PII)가 업로드된 사실이 확인되었습니다. 회사는 PII가 다시 업로드될 경우 관리자에게 알림을 보내고, 자동으로 조치가 수행되기를 원합니다. 가장 적은 개발 작업으로 이를 만족시키려면 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["SFTP", "Amazon Macie", "PII", "자동화된 조치", "S3 Lifecycle"], "Terms": ["SFTP", "Amazon S3", "Amazon Inspector", "Amazon Macie", "AWS Lambda", "Amazon Simple Notification Service (Amazon SNS)", "Amazon Simple Email Service (Amazon SES)", "S3 Lifecycle policy"], "Commentary": "이 문제는 외부 매장에서 업로드되는 대형 파일에 포함된 PII를 자동으로 탐지하고, 최소한의 개발 노력으로 보안 위협을 방지하는 방법을 묻습니다. Amazon Macie는 S3 객체를 자동으로 스캔하여 PII를 식별할 수 있고, SNS 알림을 통해 관리자가 빠르게 대응할 수 있습니다. 별도의 맞춤 알고리즘 설계 없이 간단히 설정 가능하므로 개발 부담이 적습니다.", "Selections": {"SelectA": {"Select": "Amazon S3 버킷을 안전한 전송 지점으로 사용하고, Amazon Inspector로 버킷의 객체를 스캔합니다. PII가 포함된 객체가 발견되면 S3 Lifecycle policy로 해당 객체를 제거하도록 합니다.", "Commentary": "Amazon Inspector는 취약점 스캐닝 서비스로 PII 탐지를 지원하지 않습니다. 요구사항에 부합하지 않습니다."}, "SelectB": {"Select": "Amazon S3 버킷을 안전한 전송 지점으로 사용하고, Amazon Macie로 버킷의 객체를 스캔합니다. PII가 포함되어 있으면 Amazon SNS로 관리자에게 알림을 보내고, 관리자가 해당 객체를 제거합니다.", "Commentary": "Amazon Macie로 PII를 손쉽게 탐지하고 SNS 알림을 자동화하며, 추가 개발이 최소화됩니다. 자동화된 탐지와 알림으로 신속 대응이 가능합니다."}, "SelectC": {"Select": "AWS Lambda 함수에 맞춤형 스캐닝 알고리즘을 구현하고, 객체가 버킷에 업로드될 때 이를 트리거합니다. PII가 포함된 경우 Amazon SNS를 통해 관리자에게 알림을 보내 해당 객체를 제거합니다.", "Commentary": "직접 스캐너를 개발해야 하므로 개발 노력이 많이 들며, 자동으로 제거가 이뤄지지 않습니다."}, "SelectD": {"Select": "AWS Lambda 함수에 맞춤형 스캐닝 알고리즘을 구현하고, 객체가 버킷에 업로드될 때 이를 트리거합니다. PII가 포함된 경우 Amazon SES로 관리자에게 알림을 보내고, S3 Lifecycle policy를 통해 해당 객체를 제거합니다.", "Commentary": "맞춤 알고리즘 구현과 SES 연동이 필요해 개발 부담이 크며, Macie 활용 대비 간단하지 않습니다."}}}
{"Question_Number": "Q47", "Question_Description": "한 회사가 다가오는 1주일간의 이벤트를 위해 특정 AWS Region 내의 세 Availability Zones에서 Amazon EC2 용량을 보장받아야 합니다. 어떤 방법을 사용해야 Amazon EC2 용량을 보장할 수 있습니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Amazon EC2", "AWS Region", "Availability Zones", "On-Demand Capacity Reservation", "Reserved Instances"], "Terms": ["Amazon EC2", "Availability Zone", "AWS Region", "On-Demand Capacity Reservation", "Reserved Instances"], "Commentary": "이 문제는 짧은 기간(1주일) 동안 특정 AWS Region과 세 Availability Zones에서 확실하게 Amazon EC2 용량을 확보하는 방법을 묻습니다. Reserved Instances는 장기적으로 비용을 절감하는 옵션이지만, 즉각적인 용량 보장을 위해서는 On-Demand Capacity Reservation이 적합합니다. 원하는 Region과 Availability Zones를 지정해두면 해당 기간 동안 필요한 EC2 용량이 고정적으로 예약되어 이벤트 트래픽을 안정적으로 처리할 수 있습니다.", "Selections": {"SelectA": {"Select": "해당 Region만 지정한 Reserved Instances를 구매합니다.", "Commentary": "Reserved Instances는 장기 사용 시 비용 절감에 초점이 있어, 기간 한정 이벤트에서 특정 AZ 용량 보장을 확실히 제공하지 못합니다."}, "SelectB": {"Select": "해당 Region만 지정한 On-Demand Capacity Reservation을 생성합니다.", "Commentary": "Region만 지정하면 특정 AZ별로 할당이 보장되지 않아 원하는 세 Availability Zones 모두에 대한 용량을 확실히 보장하기 어렵습니다."}, "SelectC": {"Select": "해당 Region과 세 Availability Zones를 지정한 Reserved Instances를 구매합니다.", "Commentary": "Reserved Instances로 AZ까지 지정은 가능하나, 일반적으로 1주일과 같은 단기 이벤트에는 장기 계약인 Reserved Instances가 비효율적입니다."}, "SelectD": {"Select": "해당 Region과 세 Availability Zones를 지정한 On-Demand Capacity Reservation을 생성합니다.", "Commentary": "정확히 필요한 기간과 AZ를 지정해 필요한 EC2 용량을 즉시 예약하고, 원하는 기간 동안 안정적으로 용량을 확보할 수 있는 최적의 방법입니다."}}}
{"Question_Number": "Q48", "Question_Description": "한 회사의 웹사이트는 카탈로그를 Amazon EC2 instance store에 저장하고 있습니다. 회사는 해당 카탈로그를 고가용성으로 유지하고 내구성 높은 위치에 저장하고자 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["카탈로그", "고가용성", "내구성", "Amazon EFS"], "Terms": ["Amazon EC2 instance store", "Amazon EFS", "Amazon ElastiCache for Redis", "Amazon S3 Glacier Deep Archive"], "Commentary": "이 문제는 EC2 instance store가 휘발성 스토리지이므로 카탈로그 데이터를 안정적이고 내구성 있는, 그리고 고가용성을 지원하는 스토리지로 이전해야 하는 시나리오입니다. 정답이 Amazon EFS인 이유는 EFS가 멀티 AZ 환경에서의 내구성과 고가용성을 보장하기 때문입니다.", "Selections": {"SelectA": {"Select": "카탈로그를 Amazon ElastiCache for Redis로 이전합니다.", "Commentary": "ElastiCache는 인메모리 캐시 서비스로, 영구 저장용도가 아니어서 카탈로그를 내구적으로 보존하기 어렵습니다."}, "SelectB": {"Select": "인스턴스 스토리지가 더 큰 EC2 인스턴스로 배포합니다.", "Commentary": "인스턴스 스토리지는 EC2 인스턴스가 중단될 경우 데이터가 사라질 수 있는 휘발성 스토리지입니다."}, "SelectC": {"Select": "인스턴스 스토어의 카탈로그를 Amazon S3 Glacier Deep Archive로 이전합니다.", "Commentary": "S3 Glacier Deep Archive는 장기 보관에 적합하지만, 즉시 접근이 어려워 고가용성 요구사항에 부합하지 않습니다."}, "SelectD": {"Select": "카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이전합니다.", "Commentary": "EFS는 멀티 AZ를 통해 뛰어난 내구성과 고가용성을 제공하므로 카탈로그 저장에 가장 적합한 선택입니다."}}}
{"Question_Number": "Q49", "Question_Description": "한 회사에서 매달 콜 녹취 파일을 저장하고 있습니다. 사용자들은 콜 후 1년 이내에는 이 파일들을 무작위로 자주 액세스하지만, 1년 이후에는 거의 액세스하지 않습니다. 회사는 1년 미만 된 파일들을 가능한 한 빠르게 조회하고 가져올 수 있도록 최적화하면서, 오래된 파일을 가져오는 데 지연이 있어도 괜찮은 솔루션을 원합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있습니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["콜 녹취 파일", "1년 이내 빈번한 조회", "1년 후 드문 조회", "비용 효율", "S3 Intelligent-Tiering", "S3 Glacier Flexible Retrieval", "Amazon Athena", "S3 Glacier Select"], "Terms": ["S3 Glacier Instant Retrieval", "S3 Glacier Flexible Retrieval", "S3 Glacier Deep Archive", "S3 Intelligent-Tiering", "S3 Lifecycle", "Amazon Athena", "S3 Glacier Select", "Amazon RDS"], "Commentary": "이 문제는 1년 이내에는 자주 접근하고, 이후에는 드물게 접근하는 콜 녹취 파일의 저장 비용을 최적화하는 방법을 묻습니다. S3 Intelligent-Tiering을 활용하면 자동 티어 조정이 가능하고, 1년 뒤에는 S3 Glacier Flexible Retrieval로 전환하여 비용을 절감할 수 있습니다. 특히 필요 시 Amazon Athena나 S3 Glacier Select로 데이터 조회가 가능해 빠른 액세스와 저렴한 보관비용을 모두 만족합니다.", "Selections": {"SelectA": {"Select": "Amazon S3 Glacier Instant Retrieval에 각 파일을 태그와 함께 저장하고, 태그를 조회하여 파일을 S3 Glacier Instant Retrieval에서 가져옵니다.", "Commentary": "Instant Retrieval은 검색 속도는 빠르지만 1년 이내 자주 조회되는 데이터에 대해서는 S3 Intelligent-Tiering보다 비용 효율이 떨어집니다."}, "SelectB": {"Select": "Amazon S3 Intelligent-Tiering에 각 파일을 저장합니다. 1년 후에는 S3 Lifecycle 정책을 사용하여 S3 Glacier Flexible Retrieval로 객체를 이동시킵니다. Amazon Athena로 S3에 있는 파일을 조회하고, S3 Glacier Select로 Glacier에 있는 파일을 조회합니다.", "Commentary": "예측이 어려운 액세스 패턴에서 Intelligent-Tiering은 자동으로 비용 최적화 효과를 제공하며, 1년 후 Glacier Flexible Retrieval로 이동하여 가장 효율적입니다."}, "SelectC": {"Select": "Amazon S3 Standard 스토리지에 각 파일을 태그와 함께 저장하고, 각 파일의 검색 메타데이터를 Amazon S3 Standard에 별도로 보관합니다. 1년 후에는 S3 Lifecycle 정책을 통해 파일을 S3 Glacier Instant Retrieval로 이동합니다. Amazon S3에서 메타데이터를 검색해 파일을 조회 및 가져옵니다.", "Commentary": "메타데이터를 이중 관리해야 해서 복잡도가 높고, Glacier Instant Retrieval은 Intelligent-Tiering에 비해 가격이 더 부담됩니다."}, "SelectD": {"Select": "Amazon S3 Standard에 각 파일을 저장합니다. 1년 후에는 S3 Glacier Deep Archive로 파일을 이동하도록 S3 Lifecycle 정책을 설정합니다. 검색 메타데이터를 Amazon RDS에 저장합니다. RDS에서 파일을 조회하고 S3 Glacier Deep Archive에서 파일을 가져옵니다.", "Commentary": "Deep Archive는 보관 비용은 저렴하지만 검색 시 복원 시간이 길고, 별도의 DB를 이용해 메타데이터를 관리해야 해 운영 부담이 큽니다."}}}
{"Question_Number": "Q51", "Question_Description": "한 회사가 REST API로 조회할 수 있는 주문 배송 통계 애플리케이션을 개발하고 있습니다. 회사는 매일 아침 정해진 시간에 주문 배송 통계를 추출하여, 데이터를 읽기 쉬운 HTML 형식으로 정리하고 여러 이메일 주소로 보고서를 전송하려고 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계를 조합해서 수행해야 합니까? (2개를 선택하세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["주문 배송 통계", "HTML 보고서", "이메일 전송", "EventBridge", "Lambda", "SES"], "Terms": ["Amazon Kinesis Data Firehose", "Amazon Simple Email Service (Amazon SES)", "Amazon EventBridge (Amazon CloudWatch Events)", "AWS Glue", "AWS Lambda", "Amazon S3", "Amazon Simple Notification Service (Amazon SNS)"], "Commentary": "매일 일정 시간에 REST API로부터 데이터를 조회하고, HTML로 변환 후 여러 이메일로 전송해야 합니다. 이를 위해 Amazon EventBridge를 사용해 스케줄링하고, AWS Lambda로 데이터를 불러온 뒤 Amazon SES로 HTML 형식 보고서를 전송하는 구성이 간단하고 효과적입니다.", "Selections": {"SelectA": {"Select": "애플리케이션에서 Amazon Kinesis Data Firehose로 데이터를 전송하도록 구성합니다.", "Commentary": "Kinesis Data Firehose는 실시간 스트리밍 데이터를 저장·변환할 때 유용하지만, 매일 아침 정기 보고서 전송에는 적합하지 않습니다."}, "SelectB": {"Select": "Amazon Simple Email Service(Amazon SES)를 사용하여 데이터를 HTML로 형식화하고 이메일로 보고서를 전송합니다.", "Commentary": "HTML 형식 보고서 전송을 간편하게 구현할 수 있는 핵심 구성요소이며, 여러 이메일 주소로 동시 전송도 간단합니다. (정답)"}, "SelectC": {"Select": "Amazon EventBridge(Amazon CloudWatch Events) 스케줄 이벤트를 생성하여 AWS Glue 작업이 애플리케이션의 API에서 데이터를 조회하도록 합니다.", "Commentary": "AWS Glue는 주로 데이터베이스나 S3 크롤링 및 ETL에 활용됩니다. 단순 API 조회에는 Lambda가 더 간편합니다."}, "SelectD": {"Select": "Amazon EventBridge(Amazon CloudWatch Events) 스케줄 이벤트를 생성하여 AWS Lambda 함수를 호출해 애플리케이션의 API에서 데이터를 조회합니다.", "Commentary": "Lambda를 사용하면 매일 특정 시간에 API에서 데이터를 가져와 HTML 보고서 생성을 위한 준비를 쉽게 할 수 있습니다. (정답)"}, "SelectE": {"Select": "애플리케이션 데이터를 Amazon S3에 저장합니다. S3 이벤트 대상로 Amazon SNS 토픽을 생성하여 이메일로 보고서를 전송합니다.", "Commentary": "S3 이벤트 트리거나 SNS만으로는 HTML 형식 변환과 스케줄링 시간이 맞춰진 전송을 구현하기 어렵습니다."}}}
{"Question_Number": "Q52", "Question_Description": "한 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 수십 GB부터 수백 TB까지 다양한 크기의 출력 파일을 생성합니다. 애플리케이션 데이터는 표준 파일 시스템 구조로 저장되어야 합니다. 회사는 자동 확장, 고가용성, 최소한의 운영 오버헤드를 요구하는 솔루션을 찾고 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["마이그레이션", "표준 파일 시스템", "자동 확장", "고가용성", "운영 오버헤드 최소화"], "Terms": ["Amazon ECS", "Amazon EKS", "Amazon EC2", "Amazon EBS", "Amazon EFS", "Auto Scaling group", "Multi-AZ"], "Commentary": "이 문제는 온프레미스 애플리케이션을 AWS로 이전하면서 수십 GB~수백 TB 규모의 데이터를 표준 파일 시스템 형태로 보관해야 하는 상황입니다. Amazon EFS는 파일 시스템 구조를 제공하면서 자동 확장 및 Multi-AZ 고가용성을 지원하므로, 운영 부담을 줄이기에 가장 적합합니다.", "Selections": {"SelectA": {"Select": "애플리케이션을 Amazon ECS 컨테이너로 마이그레이션하고, Amazon S3를 스토리지로 사용합니다.", "Commentary": "S3는 객체 스토리지로, 표준 파일 시스템 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "애플리케이션을 Amazon EKS 컨테이너로 마이그레이션하고, Amazon EBS를 스토리지로 사용합니다.", "Commentary": "EBS는 EC2 인스턴스에 종속적이며, 대규모 자동 확장이나 Multi-AZ 가용성 보장 측면에서 제한적입니다."}, "SelectC": {"Select": "애플리케이션을 Multi-AZ Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행하고, Amazon EFS를 스토리지로 사용합니다.", "Commentary": "표준 파일 시스템 구조, Multi-AZ 고가용성, 자동 확장을 모두 지원하므로 요구사항에 부합하는 최적의 솔루션입니다."}, "SelectD": {"Select": "애플리케이션을 Multi-AZ Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행하고, Amazon EBS를 스토리지로 사용합니다.", "Commentary": "EBS는 인스턴스 단위로 볼륨을 관리하므로 확장성과 고가용성 면에서 EFS보다 제한적입니다."}}}
{"Question_Number": "Q53", "Question_Description": "한 회사가 회계 데이터를 Amazon S3에 저장해야 합니다. 이 데이터는 1년 동안 즉시 접근 가능해야 하며, 이후 9년 동안은 장기 보관해야 합니다. 또한 회사 내 관리자 계정과 root 계정을 포함하여 10년의 전체 보존 기간 동안 아무도 데이터를 삭제할 수 없어야 합니다. 그리고 이 데이터는 최대한 높은 내구성을 가지는 스토리지에 저장되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["회계 데이터 저장", "10년 보존", "즉시 접근 1년", "장기 보관 9년", "S3 Object Lock", "compliance mode", "S3 Glacier Deep Archive"], "Terms": ["Amazon S3", "S3 Glacier", "S3 Intelligent-Tiering", "S3 Glacier Deep Archive", "S3 Object Lock", "compliance mode", "governance mode", "S3 Lifecycle policy", "IAM policy"], "Commentary": "이 문제는 회계 데이터에 대한 장기 보존 정책과 삭제 방지 요구사항을 충족해야 하므로, S3 Object Lock의 compliance mode와 Lifecycle 정책을 활용하는 방법이 핵심입니다.", "Selections": {"SelectA": {"Select": "S3 Glacier에 10년 전체 기간 동안 레코드를 저장합니다. 10년 동안 레코드 삭제를 거부하도록 하는 access control policy를 사용합니다.", "Commentary": "S3 Glacier만 사용하고 policy로만 삭제를 막는 방식은 root나 관리자 권한을 완전히 제한할 수 없고, 1년간 즉시 접근 요건에도 부적합합니다."}, "SelectB": {"Select": "S3 Intelligent-Tiering을 사용하여 레코드를 저장합니다. IAM policy로 10년 동안 삭제를 거부한 뒤, 10년 후 정책을 변경합니다.", "Commentary": "IAM policy만으로는 최상위 권한 계정의 삭제 방지를 완벽히 보장하기 어렵고, 별도의 장기 보관 방식도 고려되지 않아 요구사항에 부합하지 않습니다."}, "SelectC": {"Select": "1년 후 S3 Standard에서 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle policy를 설정하고, S3 Object Lock의 compliance mode를 10년간 적용합니다.", "Commentary": "compliance mode는 root나 관리자도 삭제 못 하게 하며, 1년 즉시 접근 후 9년 장기 보관 요구사항을 모두 만족시키는 올바른 솔루션입니다."}, "SelectD": {"Select": "1년 후 S3 Standard에서 S3 One Zone-Infrequent Access로 전환하는 S3 Lifecycle policy를 사용하고, S3 Object Lock의 governance mode를 10년간 적용합니다.", "Commentary": "governance mode는 적절한 권한을 가진 사용자가 삭제를 해제할 수 있어, root 계정 등도 삭제를 막지 못하는 위험이 있어 요구사항에 부합하지 않습니다."}}}
{"Question_Number": "Q54", "Question_Description": "한 회사가 AWS에서 여러 Windows 워크로드를 운영하고 있습니다. 회사의 직원들은 두 개의 Amazon EC2 인스턴스에 호스팅된 Windows file shares를 사용합니다. 해당 file share들은 서로 간 데이터를 동기화하며 중복 사본을 유지하고 있습니다. 회사는 현재 사용자가 파일에 접근하는 방식을 유지하면서, 고가용성(High Availability)과 내구성(Durability)을 갖춘 스토리지 솔루션을 원합니다. 이를 만족하기 위한 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Windows file shares", "고가용성", "내구성", "FSx for Windows File Server", "Multi-AZ"], "Terms": ["Amazon EC2", "Windows file shares", "Amazon S3", "IAM", "S3 File Gateway", "Amazon FSx for Windows File Server", "Multi-AZ", "Amazon EFS"], "Commentary": "이 문제는 Windows 환경 특유의 SMB 기반 파일 공유 방식을 유지하면서, 고가용성과 내구성을 높이는 스토리지를 선택하는 것입니다. Amazon FSx for Windows File Server는 Windows 네이티브 프로토콜을 완벽히 지원하므로 요구사항을 모두 충족합니다.", "Selections": {"SelectA": {"Select": "모든 데이터를 Amazon S3로 마이그레이션하고 사용자가 파일에 접근할 수 있도록 IAM 인증을 설정합니다.", "Commentary": "S3는 Windows의 SMB 프로토콜을 그대로 지원하지 않으므로 사용자 측 접근 방식을 유지하기 어렵습니다."}, "SelectB": {"Select": "Amazon S3 File Gateway를 설정하고, 기존 EC2 인스턴스에 S3 File Gateway를 마운트합니다.", "Commentary": "S3 File Gateway는 파일 공유를 위한 일부 기능을 제공하지만, Windows ACL 등 완전한 Windows 파일 공유 호환성을 보장하지 못합니다."}, "SelectC": {"Select": "Amazon FSx for Windows File Server 환경을 Multi-AZ로 확장하고, 모든 데이터를 FSx for Windows File Server로 마이그레이션합니다.", "Commentary": "Amazon FSx for Windows File Server는 Windows 네이티브 파일 시스템과 호환되어 고가용성과 내구성을 제공하므로 요구사항에 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "Amazon Elastic File System(Amazon EFS)에 Multi-AZ 구성을 추가하고, 모든 데이터를 EFS로 마이그레이션합니다.", "Commentary": "Amazon EFS는 Linux 기반 파일 시스템으로, Windows 파일 공유 방식(SMB)에 대한 지원이 불가능하므로 적합하지 않습니다."}}}
{"Question_Number": "Q55", "Question_Description": "한 솔루션스 아키텍트가 여러 서브넷을 포함하는 VPC 아키텍처를 설계하고 있습니다. 이 아키텍처는 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 사용하며, 두 개의 가용 영역(Availability Zone)에 걸쳐 총 6개의 서브넷으로 구성됩니다. 각 가용 영역에는 Public Subnet, Private Subnet, Database용 전용 Subnet이 각각 존재합니다. Private Subnet에서 실행 중인 EC2 인스턴스만이 RDS Database에 액세스할 수 있어야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["VPC 아키텍처", "Amazon EC2", "Amazon RDS", "서브넷 구성", "Private Subnet", "데이터베이스 접근 제어"], "Terms": ["VPC", "EC2", "RDS", "Security Group", "Route Table", "CIDR block", "VPC Peering"], "Commentary": "이 문제는 서로 다른 서브넷 간 트래픽을 제어하여 Private Subnet에서만 RDS DB에 접근하도록 하는 방법을 묻습니다. 보안 그룹(Security Group)은 기본적으로 허용 규칙만 설정 가능하며, 원하는 소스(Private Subnet의 인스턴스)에 대해서만 Inbound 허용 규칙을 생성하여 트래픽을 제한하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "Public Subnet의 CIDR 블록으로 가는 라우트를 제외한 새로운 Route Table을 생성하고, Database Subnet에 연결합니다.", "Commentary": "Route Table만으로는 Database Subnet의 Inbound 흐름 제어를 완전히 해결하지 못하므로 적절한 접근 제한에 부족합니다."}, "SelectB": {"Select": "Public Subnet에 할당된 인스턴스의 Security Group으로부터 들어오는 트래픽을 거부하는 Security Group을 생성하고, DB 인스턴스에 할당합니다.", "Commentary": "Security Group에서는 거부(Deny) 규칙이 불가능하므로 이 방법은 구현할 수 없습니다."}, "SelectC": {"Select": "Private Subnet에 할당된 인스턴스의 Security Group으로부터 들어오는 트래픽을 허용하는 Security Group을 생성하고, DB 인스턴스에 할당합니다.", "Commentary": "Security Group은 기본적으로 허용 규칙만 설정 가능하므로, Private Subnet 인스턴스만 접근 허용 규칙을 두면 요구 사항을 충족합니다."}, "SelectD": {"Select": "Public Subnet과 Private Subnet 간 새로운 Peering Connection을 생성하고, Private Subnet과 Database Subnet 간 별도의 Peering Connection을 생성합니다.", "Commentary": "VPC Peering은 주로 서로 다른 VPC 간 트래픽을 연결하기 위한 것이며, 같은 VPC 내 Subnet 간 트래픽 제어에는 적합하지 않습니다."}}}
{"Question_Number": "Q56", "Question_Description": "한 회사가 Amazon Route 53을 통해 도메인 이름을 등록했습니다. 회사는 ca-central-1 리전에서 Amazon API Gateway를 퍼블릭 인터페이스로 사용하여 백엔드 마이크로서비스 API를 제공하고 있으며, 서드파티 서비스들이 보안 연결을 통해 API를 소비하고 있습니다. 회사는 서드파티 서비스가 HTTPS를 사용할 수 있도록, 회사의 도메인 이름과 해당 인증서를 사용해 API Gateway URL을 구성하고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["API Gateway", "도메인 이름", "ACM 인증서", "HTTPS", "Regional 엔드포인트"], "Terms": ["Amazon Route 53", "Amazon API Gateway", "ca-central-1 Region", "AWS Certificate Manager (ACM)", "Route 53 DNS records", "Regional API Gateway endpoint", "Stage variables", "Public certificate", "HTTPS", "A record", "Alias record"], "Commentary": "API Gateway에 커스텀 도메인 이름과 HTTPS를 적용하려면, 동일한 리전 내 ACM 인증서와 Regional 엔드포인트를 사용해야 합니다. 그 후 Route 53 레코드를 통해 트래픽을 해당 도메인으로 라우팅하면 HTTPS 연결이 완성됩니다.", "Selections": {"SelectA": {"Select": "API Gateway에서 Name=\"Endpoint-URL\"와 Value=\"Company Domain Name\"을 갖는 Stage Variable을 생성하여 기본 URL을 덮어씁니다. 회사 도메인 이름에 대한 Public Certificate를 AWS Certificate Manager (ACM)에 Import합니다.", "Commentary": "Stage Variable만으로 API Gateway에 커스텀 도메인을 설정할 수 없으므로 올바른 설정 방식이 아닙니다."}, "SelectB": {"Select": "회사 도메인 이름을 사용해 Route 53 DNS 레코드를 생성합니다. Alias 레코드를 Regional API Gateway 스테이지 엔드포인트로 지정합니다. 회사 도메인 이름 관련 Public Certificate를 us-east-1 리전의 AWS Certificate Manager (ACM)에 Import합니다.", "Commentary": "Regional 엔드포인트이지만 인증서를 us-east-1 리전에 배포하면 ca-central-1 리전의 API Gateway와 정상 연동이 어려워 잘못된 접근입니다."}, "SelectC": {"Select": "Regional API Gateway 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사 도메인 이름과 연결합니다. 동일 리전에서 회사 도메인 이름에 대한 Public Certificate를 AWS Certificate Manager (ACM)에 Import하고, 이를 API Gateway 엔드포인트에 연결합니다. Route 53을 구성하여 트래픽을 API Gateway 엔드포인트로 라우팅합니다.", "Commentary": "동일 리전의 ACM 인증서와 Regional 엔드포인트가 필요하며, Route 53을 통해 트래픽을 연결하는 설정으로 요구사항을 충족합니다."}, "SelectD": {"Select": "Regional API Gateway 엔드포인트를 생성합니다. 회사 도메인 이름과 엔드포인트를 연결합니다. 회사 도메인 이름에 대한 Public Certificate를 us-east-1 리전의 AWS Certificate Manager (ACM)에 Import하고, 이를 API Gateway에 연결합니다. 회사 도메인 이름으로 A 레코드를 생성하여 해당 도메인으로 지정합니다.", "Commentary": "인증서를 API Gateway 엔드포인트와 동일한 리전에 배포해야 하는데, us-east-1에 Import하면 ca-central-1 엔드포인트와 호환되지 않습니다."}}}
{"Question_Number": "Q57", "Question_Description": "한 회사에서 인기가 높은 소셜 미디어 웹사이트를 운영 중이며, 사용자가 다른 사용자와 공유할 이미지를 업로드할 수 있는 기능을 제공합니다. 회사는 이러한 이미지에 부적절한 콘텐츠가 포함되지 않도록 사전에 확인하고자 합니다. 또한, 개발 노력을 최소화할 수 있는 솔루션을 원합니다. 이를 충족하는 방법으로 어떤 것을 선택해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["소셜 미디어", "이미지 업로드", "부적절한 콘텐츠", "개발 노력 최소화", "Amazon Rekognition"], "Terms": ["Amazon Comprehend", "Amazon Rekognition", "Amazon SageMaker", "AWS Fargate", "Ground Truth", "Human Review"], "Commentary": "이 문제는 사용자가 업로드하는 사진을 자동으로 점검해 부적절한 콘텐츠를 걸러내는 요구 사항에 관한 것입니다. Amazon Rekognition은 이미지를 기반으로 한 콘텐츠 모더레이션 기능을 이미 갖추고 있어 개발 부담을 최소화하며 정확도를 높일 수 있는 최적의 서비스입니다.", "Selections": {"SelectA": {"Select": "Amazon Comprehend를 사용해 부적절한 내용을 감지하고, 신뢰도가 낮은 예측에 대해서는 인적 리뷰를 진행", "Commentary": "Comprehend는 주로 텍스트 분석에 특화되어 있으므로 이미지 부적절성 검출에는 적합하지 않습니다."}, "SelectB": {"Select": "Amazon Rekognition을 사용해 부적절한 내용을 감지하고, 신뢰도가 낮은 예측에 대해서는 인적 리뷰를 진행", "Commentary": "이미지 분석에 최적화된 Amazon Rekognition을 사용하면 최소한의 개발 노력으로 정확하고 빠른 콘텐츠 모더레이션을 구현할 수 있는 최적의 선택입니다."}, "SelectC": {"Select": "Amazon SageMaker로 부적절한 내용을 감지하고, Ground Truth를 사용해 신뢰도가 낮은 예측에 라벨을 지정", "Commentary": "직접 모델을 개발하고 학습해야 하므로 개발 과정이 복잡하고 시간과 비용이 많이 듭니다."}, "SelectD": {"Select": "AWS Fargate에 맞춤형 머신 러닝 모델을 배포해 부적절한 내용을 감지하고, Ground Truth를 사용해 신뢰도가 낮은 예측에 라벨을 지정", "Commentary": "커스텀 모델을 배포해 운영하려면 상당한 개발 및 유지보수 노력이 필요하며, 요구 사항인 개발 노력 최소화에 부적합합니다."}}}
{"Question_Number": "Q58", "Question_Description": "한 회사가 컨테이너로 크리티컬 애플리케이션을 구동하여 확장성과 가용성 요구사항을 충족하고자 합니다. 회사는 크리티컬 애플리케이션 유지보수에만 집중하기를 원하며, 컨테이너화된 워크로드가 동작하는 기본 인프라를 프로비저닝하고 관리하는 책임을 지고 싶어 하지 않습니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["크리티컬 애플리케이션", "컨테이너", "확장성", "가용성", "서버리스", "AWS Fargate"], "Terms": ["AWS Fargate", "Amazon ECS", "Amazon EC2", "Docker", "Amazon Machine Image (AMI)"], "Commentary": "이 문제는 확장성과 고가용성을 위해 컨테이너화된 애플리케이션을 운영하면서, 인프라 관리까지 맡지 않으려는 상황에 대한 해결책을 찾는 것입니다. AWS Fargate는 서버리스 방식으로 기본 인프라 관리를 자동화하고, 애플리케이션 유지보수에 집중할 수 있도록 지원하기 때문에 적합합니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스를 사용하고, 인스턴스에 Docker를 설치합니다.", "Commentary": "서버 설정 및 Docker 설치·관리가 필요하여 인프라 관리를 전담해야 하므로 요구사항에 부적합합니다."}, "SelectB": {"Select": "Amazon ECS를 Amazon EC2 worker 노드에서 사용합니다.", "Commentary": "EC2 노드를 직접 관리해야 하므로 인프라 관리 부담이 그대로 남아있어 요구사항에 맞지 않습니다."}, "SelectC": {"Select": "Amazon ECS를 AWS Fargate에서 사용합니다.", "Commentary": "서버리스 환경으로 인프라 관리가 자동화되어 크리티컬 애플리케이션 유지보수에만 집중할 수 있는 최적의 해법입니다."}, "SelectD": {"Select": "Amazon ECS 최적화 Amazon Machine Image (AMI)를 사용하여 Amazon EC2 인스턴스에서 구동합니다.", "Commentary": "AMI를 사용해도 EC2 인스턴스 프로비저닝·관리가 필요해 요구사항을 충분히 만족시키지 못합니다."}}, "Reference": "AWS Fargate는 서버리스를 통해 컨테이너 관리 부담을 줄이고, 애플리케이션 유지보수에 집중할 수 있도록 해줍니다."}
{"Question_Number": "Q59", "Question_Description": "한 회사가 300개 이상의 글로벌 웹사이트와 애플리케이션을 운영하고 있습니다. 이 회사는 매일 30TB 이상의 clickstream 데이터를 분석할 플랫폼이 필요합니다. 솔루션스 아키텍트는 이러한 clickstream 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3", "3.5"], "Keywords": ["글로벌 웹사이트", "애플리케이션", "clickstream 데이터", "데이터 분석", "Amazon Kinesis Data Streams", "Amazon Kinesis Data Firehose", "Amazon S3", "Amazon Redshift"], "Terms": ["AWS Data Pipeline", "Amazon EMR", "Auto Scaling group", "Amazon EC2", "Amazon CloudFront", "AWS Lambda", "Amazon Kinesis Data Streams", "Amazon Kinesis Data Firehose", "Amazon S3 data lake", "Amazon Redshift"], "Commentary": "이 문제는 대규모(30TB 이상) clickstream 데이터를 매일 빠르고 안정적으로 수집, 전송, 처리, 분석해야 하는 시나리오입니다. Amazon Kinesis Data Streams와 Kinesis Data Firehose를 사용하면 실시간 스트리밍 데이터 수집 및 저장소 전송이 용이하고, Amazon Redshift를 통해 대규모 데이터 웨어하우징과 분석을 수행할 수 있습니다. 이는 고성능 아키텍처 설계를 위한 핵심 전략입니다.", "Selections": {"SelectA": {"Select": "AWS Data Pipeline을 설계하여 Amazon S3 버킷에 데이터를 보관하고 Amazon EMR 클러스터에서 분석을 진행합니다.", "Commentary": "AWS Data Pipeline과 Amazon EMR은 배치 기반 분석에는 적합하지만, 대규모 실시간 clickstream 처리를 위한 전송 및 스트리밍 측면에서 적절하지 않습니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스로 구성된 Auto Scaling group에서 데이터를 처리하고 Amazon S3 data lake로 전송한 뒤 Amazon Redshift로 분석합니다.", "Commentary": "EC2를 통한 직접 처리는 확장성 및 실시간 처리 측면에서 추가 설정이 복잡하고 대규모 스트리밍 처리 효율이 떨어질 수 있습니다."}, "SelectC": {"Select": "데이터를 Amazon CloudFront에 캐싱하고 Amazon S3 버킷에 저장합니다. 객체가 S3 버킷에 올라오면 AWS Lambda 함수를 실행해 분석용으로 처리합니다.", "Commentary": "CloudFront 캐싱은 주로 콘텐츠 전달을 위한 기능이며, 매일 30TB 이상의 실시간 clickstream 데이터를 효과적으로 스트리밍 처리하기에는 적합하지 않습니다."}, "SelectD": {"Select": "Amazon Kinesis Data Streams에서 데이터를 수집하고 Amazon Kinesis Data Firehose를 사용해 데이터를 Amazon S3 data lake로 전송합니다. 데이터를 Amazon Redshift에 로드하여 분석을 수행합니다.", "Commentary": "대규모 실시간 스트리밍 처리에 특화된 Amazon Kinesis와 확장성이 뛰어난 Kinesis Data Firehose 전송, 그리고 분석을 위한 Amazon Redshift 결합은 가장 효율적인 솔루션입니다."}}}
{"Question_Number": "Q61", "Question_Description": "한 회사가 AWS에서 2티어 웹 애플리케이션을 개발 중입니다. 이 회사의 개발자들은 백엔드 Amazon RDS 데이터베이스와 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩하면 안 되며, 정기적으로 데이터베이스 자격 증명을 자동으로 로테이션하는 솔루션을 구현해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["데이터베이스 자격 증명", "자동 로테이션", "Amazon EC2", "Amazon RDS", "운영 오버헤드 최소화", "AWS Secrets Manager"], "Terms": ["Amazon EC2", "Amazon RDS", "AWS Lambda", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon S3", "AWS Secrets Manager", "AWS Systems Manager Parameter Store", "자동 로테이션 (Automatic Rotation)", "인스턴스 메타데이터"], "Commentary": "이 문제는 애플리케이션 코드에 하드코딩 없이 데이터베이스 자격 증명을 안전하게 관리하고, 정기적으로 인증 정보를 갱신하기 위한 접근 방안을 묻습니다. AWS Secrets Manager는 자격 증명 보안을 자동화하여 처리하며, 자동 로테이션까지 제공해 운영 오버헤드를 크게 줄일 수 있으므로 가장 적합한 솔루션입니다.", "Selections": {"SelectA": {"Select": "데이터베이스 자격 증명을 인스턴스 메타데이터에 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용해 예약된 AWS Lambda 함수를 실행하여 RDS 자격 증명과 인스턴스 메타데이터를 동시에 업데이트합니다.", "Commentary": "인스턴스 메타데이터에 자격 증명을 저장하는 것은 보안상 위험이 높습니다. 또한 EventBridge와 Lambda를 사용해 수동으로 로테이션 로직을 구현해야 하므로 운영 부담이 큽니다."}, "SelectB": {"Select": "암호화된 Amazon S3 버킷의 설정 파일에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용해 예약된 AWS Lambda 함수를 실행하여 RDS 자격 증명과 설정 파일 내 자격 증명을 동시에 업데이트합니다. S3 Versioning으로 이전 버전 복구 기능을 보장합니다.", "Commentary": "S3에 직접 자격 증명을 저장하면 자동 로테이션을 위한 로직을 추가로 개발해야 하므로 운영 오버헤드가 큽니다. Versioning으로 이전 상태 복구가 가능하지만, 별도의 구성과 유지 비용이 발생합니다."}, "SelectC": {"Select": "데이터베이스 자격 증명을 AWS Secrets Manager의 시크릿으로 저장합니다. 시크릿 자동 로테이션을 활성화합니다. EC2 역할에 해당 시크릿에 대한 액세스 권한을 부여합니다.", "Commentary": "AWS Secrets Manager는 자동으로 RDS 자격 증명을 로테이션하며, EC2 역할에 권한만 부여하면 되므로 운영 오버헤드가 매우 적습니다. 보안 및 편의성 모두를 만족하는 솔루션입니다."}, "SelectD": {"Select": "데이터베이스 자격 증명을 AWS Systems Manager Parameter Store의 암호화된 파라미터로 저장합니다. 암호화된 파라미터에 대한 자동 로테이션을 활성화합니다. EC2 역할에 해당 파라미터들에 대한 액세스 권한을 부여합니다.", "Commentary": "Parameter Store는 기본적으로 자격 증명 자동 로테이션 기능을 제공하지 않거나 제한적이므로, Secrets Manager처럼 간편하고 완전한 자동 로테이션을 지원하지 않아 운영 부담이 늘어납니다."}}}
{"Question_Number": "Q62", "Question_Description": "한 회사가 새로운 Public Web Application을 AWS에 배포하려고 합니다. 이 Application은 Application Load Balancer(ALB) 뒤에서 동작합니다. 외부 Certificate Authority(CA)가 발급한 SSL/TLS Certificate를 사용하여 엣지에서 암호화해야 하며, 해당 Certificate는 만료 전에 매년 교체(Rotate)되어야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["Application Load Balancer(ALB)", "SSL/TLS Certificate", "외부 Certificate Authority(CA)", "만료 전 교체", "ACM Import", "Amazon EventBridge"], "Terms": ["Application Load Balancer(ALB)", "SSL/TLS Certificate", "External Certificate Authority(CA)", "AWS Certificate Manager(ACM)", "ACM Private Certificate Authority", "Amazon EventBridge(Amazon CloudWatch Events)", "Managed Renewal"], "Commentary": "이 문제는 외부 CA가 발급한 SSL/TLS 인증서를 ALB에 적용해야 하며, 자동 갱신이 불가능하다는 점이 핵심입니다. AWS가 직접 관리하지 않는 제3자 인증서는 만료 알림을 받은 뒤 수동으로 교체해야 하므로, EventBridge를 통한 알림 후 수동 갱신이 유일한 실현 방법입니다.", "Selections": {"SelectA": {"Select": "AWS Certificate Manager(ACM)을 사용하여 SSL/TLS Certificate를 발급받습니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 자동으로 인증서를 교체합니다.", "Commentary": "AWS 자체 인증서를 활용하므로 외부 CA 요구사항을 충족하지 못하며, 3rd party 인증서는 자동 갱신 대상이 아닙니다."}, "SelectB": {"Select": "AWS Certificate Manager(ACM)을 사용하여 SSL/TLS Certificate를 발급받고, 키 재질을 가져옵니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 자동으로 인증서를 교체합니다.", "Commentary": "역시 ACM이 발급한 인증서이므로, 외부 CA에서 발급된 인증서를 자동 갱신하는 방식이 아닙니다."}, "SelectC": {"Select": "AWS Certificate Manager(ACM) Private Certificate Authority를 사용하여 루트 CA로부터 SSL/TLS Certificate를 발급받습니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 인증서를 자동 교체합니다.", "Commentary": "ACM Private CA를 사용하면 내부 CA가 되므로, 외부 CA를 요구하는 시나리오와 맞지 않습니다."}, "SelectD": {"Select": "AWS Certificate Manager(ACM)에 외부 SSL/TLS Certificate를 Import합니다. ALB에 해당 인증서를 적용합니다. 그리고 Amazon EventBridge(Amazon CloudWatch Events)를 통해 인증서 만료가 가까워지면 알림을 받고 수동으로 인증서를 교체합니다.", "Commentary": "외부 CA에서 발급된 인증서는 AWS가 자동 갱신할 수 없습니다. EventBridge 알림으로 만료 시점을 파악하여 직접 교체하는 방식이 유일한 방법이므로 정답입니다."}}}
{"Question_Number": "Q63", "Question_Description": "회사는 AWS에서 인프라를 운영하고 있으며, 문서 관리 애플리케이션을 사용 중인 700,000명의 사용자 기반을 보유하고 있습니다. 회사는 큰 용량의 .pdf 파일을 .jpg 이미지 파일로 변환하는 제품을 만들 계획입니다. .pdf 파일은 평균적으로 5MB 정도의 크기를 갖습니다. 회사는 원본 파일과 변환된 파일을 모두 저장해야 합니다. 한 Solutions Architect는 빠르게 증가하는 수요를 수용할 수 있는 확장 가능한 솔루션을 설계해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1", "4.2"], "Keywords": ["PDF 파일 변환", "비용 효율성", "대규모 사용자", "Amazon S3", "AWS Lambda", "S3 PUT event", "원본 파일 저장", "확장 가능한 솔루션"], "Terms": ["Amazon S3", "AWS Lambda", "S3 PUT event", "DynamoDB", "DynamoDB Streams", "AWS Elastic Beanstalk", "Amazon EC2", "Amazon EBS", "Amazon EFS", "Auto Scaling"], "Commentary": "이 문제는 많은 사용자의 대규모 PDF 파일을 JPG로 변환하고, 원본과 변환본을 모두 저장해야 하는 상황에서 가장 비용 효율적이면서도 확장성이 높은 방법을 묻습니다. Amazon S3에 업로드 시 S3 PUT event로 트리거되는 AWS Lambda 함수를 통해 파일을 변환하고 S3에 재저장하는 방식이 서버 관리 부담 없이 비용 또한 절감할 수 있어 정답이 됩니다. DynamoDB나 Elastic Beanstalk 등을 사용하는 방식은 파일 크기와 비용 효율성 측면에서 적합하지 않습니다.", "Selections": {"SelectA": {"Select": "Amazon S3에 .pdf 파일을 저장합니다. S3 PUT event를 통해 파일이 업로드될 때마다 AWS Lambda 함수를 호출하여 .jpg로 변환하고, 변환된 파일을 다시 Amazon S3에 저장합니다.", "Commentary": "Lambda와 S3를 사용하면 파일 변환을 이벤트 기반으로 처리하고, 서버less 구조로 관리 부담 없이 비용 효율적인 스토리지와 컴퓨팅 환경을 확보할 수 있습니다."}, "SelectB": {"Select": "DynamoDB에 .pdf 파일을 저장합니다. DynamoDB Streams 기능을 사용해 AWS Lambda 함수를 호출하여 파일을 .jpg로 변환하고, 변환된 파일을 다시 DynamoDB에 저장합니다.", "Commentary": "DynamoDB는 대규모 파일 저장에 적합하지 않으며, 파일을 직접 저장하면 비용이 크게 증가할 수 있습니다."}, "SelectC": {"Select": "AWS Elastic Beanstalk 애플리케이션(EC2 인스턴스, Amazon EBS 스토리지, Auto Scaling 포함)에 .pdf 파일을 업로드합니다. EC2 인스턴스에서 프로그램을 사용해 .jpg로 변환한 뒤, .pdf와 .jpg 파일을 EBS에 저장합니다.", "Commentary": "EC2와 EBS를 이용하면 서버와 스토리지를 직접 관리해야 하며, 확장성과 비용 효율성 측면에서 Lambda+S3 조합보다 부담이 큽니다."}, "SelectD": {"Select": "AWS Elastic Beanstalk 애플리케이션(EC2 인스턴스, Amazon EFS 스토리지, Auto Scaling 포함)에 .pdf 파일을 업로드합니다. EC2 인스턴스에서 프로그램을 사용해 .jpg로 변환한 뒤, .pdf와 .jpg 파일을 EBS에 저장합니다.", "Commentary": "Elastic Beanstalk와 EFS, EBS를 혼합 사용하면 관리와 운영 비용이 늘어나며, 서버리스 아키텍처 대비 확장성과 비용 최적화 측면에서 비효율적입니다."}}}
{"Question_Number": "Q64", "Question_Description": "한 회사는 온프레미스에서 Windows 파일 서버를 통해 5TB 이상의 파일 데이터를 보유하고 있습니다. 사용자와 애플리케이션은 매일 해당 데이터에 액세스합니다. 회사는 Windows 워크로드를 AWS로 이전하고 있으며, 이전 과정 중에도 AWS와 온프레미스 환경 모두에서 최소 지연으로 파일 스토리지에 접근해야 합니다. 운영 오버헤드를 최소화하고 기존 파일 액세스 방식을 크게 변경하지 않는 솔루션이 필요합니다. 이 회사는 AWS와의 연결을 위해 AWS Site-to-Site VPN을 사용 중입니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["Windows 파일 서버", "온프레미스", "Amazon FSx for Windows File Server", "FSx File Gateway", "파일 액세스 패턴", "운영 오버헤드 최소화"], "Terms": ["Amazon FSx for Windows File Server", "Amazon S3 File Gateway", "FSx File Gateway", "VPN", "SMB 프로토콜"], "Commentary": "이 문제는 온프레미스 Windows 파일 서버를 AWS로 마이그레이션하면서도 기존 SMB 기반 파일 액세스 방식을 그대로 유지하고, 지연을 최소화하려는 상황입니다. Amazon FSx for Windows File Server와 FSx File Gateway를 결합하면 클라우드와 온프레미스에서 동일한 파일 서버 인터페이스를 사용하도록 구성할 수 있어, 운영 오버헤드와 애플리케이션 변경을 최소화합니다.", "Selections": {"SelectA": {"Select": "Amazon FSx for Windows File Server를 AWS에 배포 및 구성합니다. 온프레미스 파일 데이터를 FSx로 이전하고, 워크로드를 FSx 서비스로 재구성하여 사용합니다.", "Commentary": "온프레미스에서 직접 FSx로 접속하므로 VPN 대역폭과 지연이 문제가 될 수 있고, 온프레미스에 대한 캐시나 게이트웨이가 없어 기존 패턴을 유지하기 어렵습니다."}, "SelectB": {"Select": "온프레미스에 Amazon S3 File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 S3 File Gateway로 이전하고, 온프레미스와 클라우드 워크로드 모두에서 S3 File Gateway를 사용하도록 재구성합니다.", "Commentary": "S3를 사용하는 파일 게이트웨이는 SMB가 아닌 객체 스토리지 인터페이스를 사용하므로, Windows 파일 서버 패턴과 맞지 않아 큰 변경이 필요합니다."}, "SelectC": {"Select": "온프레미스에 Amazon S3 File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 Amazon S3로 이전합니다. 각 워크로드의 위치에 따라 Amazon S3 또는 S3 File Gateway를 직접 사용하도록 재구성합니다.", "Commentary": "이 역시 S3 기반 접근이므로 파일 서버 방식(SMB)과 달라 애플리케이션과 사용자 측면에서 많은 변경이 필요합니다."}, "SelectD": {"Select": "AWS에 Amazon FSx for Windows File Server를 배포 및 구성합니다. 온프레미스에 Amazon FSx File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 FSx File Gateway로 마이그레이션하고, 클라우드 워크로드는 FSx를, 온프레미스 워크로드는 FSx File Gateway를 사용하도록 설정합니다.", "Commentary": "FSx File Gateway를 통해 온프레미스 환경에서도 로컬 SMB 형태로 접근이 가능하며, 클라우드에서는 FSx를 직접 활용하므로 최소 변화를 유지하면서 지연을 줄일 수 있는 최적의 솔루션입니다."}}}
{"Question_Number": "Q65", "Question_Description": "한 병원이 Amazon API Gateway와 AWS Lambda를 사용하여 RESTful API를 최근에 배포했습니다. 이 병원은 PDF 형식과 JPEG 형식의 보고서를 업로드하기 위해 API Gateway와 Lambda를 사용하고 있습니다. 병원은 보고서 내의 Protected Health Information(PHI)을 식별하기 위해 Lambda 코드를 수정해야 합니다. 가장 낮은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["PHI 식별", "Amazon Textract", "Amazon Comprehend Medical", "PDF/JPEG 보고서", "운영 오버헤드 최소화"], "Terms": ["Amazon API Gateway", "AWS Lambda", "RESTful API", "PDF", "JPEG", "Protected Health Information(PHI)", "Python libraries", "Amazon Textract", "Amazon SageMaker", "Amazon Comprehend Medical", "Amazon Rekognition"], "Commentary": "이 문제는 의료 보고서에서 PHI를 식별하기 위한 가장 간단하고 직관적인 접근 방식을 찾는 것입니다. 문서에서 텍스트를 정확히 추출하고, 의료 특화 엔티티 식별에 최적화된 서비스를 활용해야 운영 오버헤드를 줄일 수 있습니다. Amazon Textract는 PDF·JPEG 등 다양한 문서 포맷에서 텍스트를 추출하고, Amazon Comprehend Medical은 의료 텍스트에 대한 PHI 식별 기능을 완전관리형으로 제공합니다.", "Selections": {"SelectA": {"Select": "기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고, 추출된 텍스트에서 PHI를 식별합니다.", "Commentary": "직접 라이브러리를 선택·구현·유지보수해야 하므로 추가 코드 작업과 관리 부담이 커져, 운영 오버헤드가 높을 수 있습니다."}, "SelectB": {"Select": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker를 사용하여 추출된 텍스트에서 PHI를 식별합니다.", "Commentary": "Textract로 텍스트 추출은 편리하지만, SageMaker로 PHI 식별 모델을 직접 구축·운영해야 하므로 관리 부담이 큽니다."}, "SelectC": {"Select": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다.", "Commentary": "문서 텍스트 추출과 의료 특화 PHI 식별에 최적화된 완전관리형 서비스들을 연계하여, 유지보수가 간단하고 운영 오버헤드가 최소화됩니다."}, "SelectD": {"Select": "Amazon Rekognition을 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다.", "Commentary": "Rekognition의 OCR 기능은 주로 이미지 분석에 초점이 맞춰져 있어, 문서 텍스트 추출에는 Textract 대비 적합성이 낮습니다."}}}
{"Question_Number": "Q66", "Question_Description": "어떤 회사는 대략 5MB 크기의 파일을 대량으로 생성하는 애플리케이션을 운영하고 있습니다. 이 파일들은 Amazon S3에 저장되며, 회사 정책상 4년 동안 삭제할 수 없습니다. 이 파일들은 재생산이 어려운 중요한 비즈니스 데이터가 포함되어 있어 항상 즉시 액세스할 수 있어야 합니다. 객체 생성 후 첫 30일 동안은 자주 액세스되지만, 그 이후에는 드물게 액세스됩니다. 이러한 요구사항을 만족하면서 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["파일 즉시 액세스", "4년 보관", "30일 이후 드문 액세스", "비용 효율성"], "Terms": ["Amazon S3", "S3 Standard", "S3 Standard-Infrequent Access (S3 Standard-IA)", "S3 One Zone-Infrequent Access (S3 One Zone-IA)", "S3 Glacier", "Lifecycle policy"], "Commentary": "이 문제의 핵심은 일정 기간 자주 액세스된 후 드물게 참조되는 데이터를 비용 효율적으로 장기 보관하면서도, ‘언제든 즉시 액세스해야 한다’는 요구사항을 충족하는 방식입니다. S3 Glacier는 저렴하지만 즉시 액세스가 불가능하므로 부적합합니다. S3 One Zone-IA는 멀티 AZ 저장을 제공하지 않아 중요 데이터에 대한 내구성과 가용성을 모두 보장하기 어렵습니다. 반면 S3 Standard-IA는 멀티 AZ를 유지하며 즉시 액세스가 가능하고 드문 액세스 시 더 낮은 요금을 제공합니다. 따라서 30일 후 S3 Standard-IA로 전환하고, 4년 후 제거하는 것이 최적의 선택입니다.", "Selections": {"SelectA": {"Select": "객체 생성 30일 후 S3 Standard에서 S3 Glacier로 이동하고, 4년 후 삭제", "Commentary": "S3 Glacier로 이동 시 저렴하지만 즉시 액세스가 불가능하여 요구사항에 부합하지 않습니다."}, "SelectB": {"Select": "객체 생성 30일 후 S3 Standard에서 S3 One Zone-IA로 이동하고, 4년 후 삭제", "Commentary": "One Zone-IA는 멀티 AZ가 아니므로 중요한 데이터에 대한 내구성 및 가용성 면에서 위험도가 높습니다."}, "SelectC": {"Select": "객체 생성 30일 후 S3 Standard에서 S3 Standard-IA로 이동하고, 4년 후 삭제", "Commentary": "중요 데이터를 멀티 AZ에 안전하게 보관하면서도 접근이 적은 시점부터 더 낮은 요금으로 즉시 액세스를 지원해 가장 적합합니다."}, "SelectD": {"Select": "객체 생성 30일 후 S3 Standard에서 S3 Standard-IA로 이동하고, 4년 후 S3 Glacier로 이동", "Commentary": "어차피 4년 후에 삭제할 파일을 Glacier로 옮기는 것은 불필요한 단계를 거치게 되어 비용과 운영 복잡성을 증가시킵니다."}}}
{"Question_Number": "Q67", "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon SQS 큐에서 메시지를 받아 처리한 뒤, Amazon RDS 테이블에 기록하고, 큐에서 메시지를 삭제합니다. 가끔 Amazon RDS 테이블에 중복된 레코드가 발견되지만, Amazon SQS 큐에는 중복 메시지가 존재하지 않습니다. 메시지가 한 번만 처리되도록 보장하려면 솔루션스 아키텍트는 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["메시지 중복 방지", "Visibility Timeout", "Amazon SQS", "Amazon EC2", "Amazon RDS"], "Terms": ["Amazon EC2", "Amazon RDS", "Amazon SQS", "CreateQueue API", "AddPermission API", "ReceiveMessage API", "ChangeMessageVisibility API", "Visibility Timeout"], "Commentary": "이 문제는 Amazon SQS 큐를 사용하는 다중 소비자 환경에서 중복 처리를 방지하는 방법을 묻습니다. 메시지를 처리하는 동안 다른 인스턴스가 해당 메시지를 다시 가져가지 못하도록 적절한 Visibility Timeout을 설정해주는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "CreateQueue API 호출을 사용하여 새 큐를 생성합니다.", "Commentary": "새 큐를 만든다고 기존 중복 문제가 해결되지는 않아 오답입니다."}, "SelectB": {"Select": "AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.", "Commentary": "권한 설정은 보안 및 접근 제어 목적이며, 메시지 중복 처리 문제를 해결하지 못합니다."}, "SelectC": {"Select": "ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.", "Commentary": "대기 시간(WaitTimeSeconds)은 메시지 수신 방식에 영향을 주지만, 중복 처리를 방지하려면 Visibility Timeout 조정이 필요하므로 오답입니다."}, "SelectD": {"Select": "ChangeMessageVisibility API 호출을 사용하여 visibility timeout을 늘립니다.", "Commentary": "메시지가 처리 중일 때 충분히 숨겨 다른 인스턴스에서 재처리되지 않도록 visibility timeout을 늘려야 하므로 정답입니다."}}}
{"Question_Number": "Q68", "Question_Description": "한 솔루션스 아키텍트가 회사의 온프레미스 인프라를 AWS로 확장하기 위한 새로운 하이브리드 아키텍처를 설계하고 있습니다. 회사는 AWS Region으로 가는 고가용성 및 일관된 저지연 연결을 요구합니다. 또한 총 비용을 최소화하고자 하며, 기본 연결(Direct Connect)이 실패했을 때는 더 느린 트래픽 전송을 수용할 수 있습니다. 이러한 요구사항을 충족하려면 어떤 구성을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["하이브리드 아키텍처", "고가용성", "저지연", "비용 최소화", "AWS Direct Connect", "VPN connection"], "Terms": ["AWS Direct Connect", "VPN connection", "AWS Region", "Direct Connect failover attribute"], "Commentary": "이 문제는 온프레미스 인프라와 AWS를 연결하는 하이브리드 아키텍처에서 고가용성과 낮은 지연을 유지하면서도 장애 시 비용을 아끼고 느린 트래픽을 수용할 수 있는 대안을 묻습니다. 주 연결로 Direct Connect를 사용하고, 백업으로 VPN connection을 두어 장애 시에도 서비스 연속성과 비용 효율성을 모두 달성하는 구성이 최적입니다.", "Selections": {"SelectA": {"Select": "AWS Direct Connect를 Region에 프로비저닝합니다. 기본 Direct Connect 장애에 대비해 VPN connection을 백업으로 구성합니다.", "Commentary": "Direct Connect로 일관된 저지연을 보장하고, 장애 시 VPN으로 전환하여 비용 부담 없이 고가용성을 유지할 수 있는 최적 구성입니다."}, "SelectB": {"Select": "Region에 대한 private connectivity를 위해 VPN tunnel connection을 프로비저닝합니다. 기본 VPN 연결이 실패할 경우를 대비해 추가 VPN tunnel을 구성합니다.", "Commentary": "VPN만 두 개 구성하면 일관된 저지연을 보장하기 어려워 회사의 요구사항을 충족하기 힘듭니다."}, "SelectC": {"Select": "Region에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 장애에 대비해 동일 Region에 두 번째 Direct Connect 연결을 구성합니다.", "Commentary": "Direct Connect를 이중화하면 고가용성이지만, 비용이 높고 장애 시에도 VPN 같은 저비용 대안이 없어 요구사항과 맞지 않습니다."}, "SelectD": {"Select": "Region에 AWS Direct Connect를 프로비저닝합니다. 기본 Direct Connect 장애 시 AWS CLI의 Direct Connect failover attribute를 사용해 자동으로 백업 연결을 생성하도록 구성합니다.", "Commentary": "AWS CLI만으로 자동 백업 연결을 즉시 생성하는 기능은 없으며, 별도의 물리적 이중화가 필요하므로 적절한 솔루션이 아닙니다."}}, "Reference": "Direct Connect + VPN best of both"}
{"Question_Number": "Q69", "Question_Description": "한 회사가 비즈니스 크리티컬 웹 애플리케이션을 Amazon EC2 인스턴스에서 Application Load Balancer 뒤에서 운영 중입니다. 이 EC2 인스턴스들은 Auto Scaling group으로 구성되어 있습니다. 애플리케이션은 단일 Availability Zone에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 사용하고 있습니다. 회사는 최소한의 다운타임과 데이터 손실로 애플리케이션을 고가용성으로 운영하기를 원합니다. 이 요구사항을 최소한의 운영 노력으로 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["고가용성", "최소 다운타임", "최소 데이터 손실", "Auto Scaling group", "Multi-AZ", "Amazon RDS Proxy"], "Terms": ["Amazon EC2", "Application Load Balancer", "Auto Scaling group", "Amazon Aurora PostgreSQL", "Multi-AZ", "Amazon RDS Proxy", "Amazon Route 53", "AWS Lambda", "Amazon S3", "S3 Event Notifications"], "Commentary": "이 문제는 웹 애플리케이션과 데이터베이스 모두에서 단일 AZ 문제 발생 시에도 운영이 중단되지 않는 구성을 요구합니다. 다중 AZ를 사용하는 Auto Scaling group과 Multi-AZ로 구성된 Amazon Aurora PostgreSQL, 그리고 Amazon RDS Proxy를 사용하면 다운타임과 데이터 손실을 최소화하면서 자동으로 장애조치 되어 고가용성을 달성할 수 있습니다.", "Selections": {"SelectA": {"Select": "EC2 인스턴스들을 서로 다른 AWS Region에 배치합니다. Amazon Route 53 헬스 체크를 사용해 트래픽을 리다이렉션합니다. Aurora PostgreSQL Cross-Region Replication을 사용합니다.", "Commentary": "멀티 리전 구성과 Cross-Region Replication은 설정과 운영이 복잡하며, 단일 AZ 장애 대비보다는 과도한 솔루션입니다."}, "SelectB": {"Select": "Auto Scaling group을 다중 Availability Zone에서 동작하도록 구성합니다. 데이터베이스를 Multi-AZ로 구성합니다. 데이터베이스용 Amazon RDS Proxy 인스턴스를 설정합니다.", "Commentary": "다중 AZ와 Multi-AZ 구성, 그리고 RDS Proxy를 통해 다운타임 시에도 즉시 대체 인스턴스로 전환 가능하여 고가용성과 최소 데이터 손실을 구현합니다."}, "SelectC": {"Select": "Auto Scaling group을 단일 Availability Zone에서 사용하도록 설정합니다. 데이터베이스 스냅샷을 시간 단위로 생성합니다. 장애 시 스냅샷에서 복구합니다.", "Commentary": "스냅샷 복구는 시간이 오래 걸리며, 데이터 손실 가능성도 있어 비즈니스 크리티컬 환경에는 적합하지 않습니다."}, "SelectD": {"Select": "Auto Scaling group을 여러 AWS Region에서 동작하도록 구성합니다. 애플리케이션에서 생성되는 데이터를 Amazon S3로 쓰고, S3 Event Notifications로 AWS Lambda 함수를 트리거하여 데이터베이스에 기록합니다.", "Commentary": "멀티 리전 구성과 Lambda 트리거로 데이터베이스 동기화를 구성하는 것은 운영 복잡도가 높으며, 다운타임은 줄여도 즉각적인 DB 장애 조치는 어렵습니다."}}}
{"Question_Number": "Q70", "Question_Description": "회사의 HTTP 애플리케이션이 Network Load Balancer(NLB) 뒤에 위치해 있으며, 이 NLB의 대상 그룹은 여러 Amazon EC2 인스턴스가 포함된 Amazon EC2 Auto Scaling 그룹으로 구성되어 웹 서비스를 실행하고 있습니다. 회사는 애플리케이션에서 발생하는 HTTP 오류를 NLB가 감지하지 못하고 있으며, 이 오류가 발생할 때마다 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 재시작해야 하는 상황입니다. 회사는 커스텀 스크립트나 코드를 작성하지 않고도 애플리케이션의 가용성을 높이고자 합니다. 이러한 요구 사항을 만족하기 위해서는 어떤 조치를 취해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["HTTP 애플리케이션", "NLB", "EC2 Auto Scaling", "가용성 개선", "HTTP 오류 감지"], "Terms": ["Network Load Balancer(NLB)", "Application Load Balancer(ALB)", "Amazon EC2", "Amazon EC2 Auto Scaling", "HTTP Health Check", "Amazon CloudWatch"], "Commentary": "NLB는 주로 TCP 또는 제한적인 계층 4 수준의 헬스 체크를 지원하여 특정 HTTP URL 상태 확인에는 적합하지 않습니다. ALB는 계층 7에서 HTTP 상태 코드를 확인할 수 있어, 애플리케이션 레벨의 오류를 감지하고 문제가 있는 인스턴스를 자동으로 교체하도록 설정할 수 있습니다.", "Selections": {"SelectA": {"Select": "NLB에서 HTTP 헬스 체크를 활성화하고 회사 애플리케이션의 URL을 입력합니다.", "Commentary": "NLB는 기본적으로 HTTP/HTTPS 헬스 체크를 지원하지만, 특정 URL 기반의 정교한 헬스 체크 기능이 제한적이어서 문제 해결에 적합하지 않습니다."}, "SelectB": {"Select": "EC2 인스턴스에 cron 작업을 추가하여 로컬 애플리케이션 로그를 분마다 확인하고, HTTP 오류가 관찰되면 애플리케이션을 재시작합니다.", "Commentary": "이는 커스텀 스크립트 작성과 설정이 필요하여 운영 복잡도가 높습니다. 자동 확장 및 교체가 이루어지지 않아 가용성 향상에 한계가 있습니다."}, "SelectC": {"Select": "NLB를 Application Load Balancer(ALB)로 교체하고, 회사 애플리케이션의 URL을 제공하여 HTTP 헬스 체크를 활성화합니다. Auto Scaling 액션을 구성하여 비정상 인스턴스를 자동으로 교체합니다.", "Commentary": "ALB는 계층 7 기반 헬스 체크를 지원하여 HTTP 오류를 세밀하게 감지할 수 있으며, Auto Scaling과 연동해 불량 인스턴스를 자동으로 교체하여 가용성을 크게 향상시키는 최적의 해법입니다."}, "SelectD": {"Select": "NLB에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon CloudWatch Alarm을 생성합니다. 경보가 ALARM 상태가 되면 비정상 인스턴스를 교체하도록 Auto Scaling 액션을 구성합니다.", "Commentary": "UnhealthyHostCount는 TCP 수준 헬스 체크만 감지하기 때문에 HTTP 레이어에서의 세부적인 오류 식별이 어렵습니다. 근본 해결책이 되지 못합니다."}}}
{"Question_Number": "Q71", "Question_Description": "한 회사는 Amazon DynamoDB를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 운영하고 있습니다. 데이터가 손상될 경우를 대비해, 솔루션스 아키텍트는 복구 시점 목표(RPO)를 15분, 복구 시간 목표(RTO)를 1시간으로 충족하는 솔루션을 설계해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["DynamoDB", "RPO 15분", "RTO 1시간", "Point-in-time recovery", "백업 및 복원"], "Terms": ["Amazon DynamoDB", "RPO", "RTO", "DynamoDB Global Tables", "DynamoDB Point-in-time recovery", "Amazon S3 Glacier", "Amazon EBS Snapshot"], "Commentary": "이 문제는 짧은 RPO와 RTO를 만족하기 위해 DynamoDB 데이터를 빠르고 정확하게 백업하고 복원하는 방안을 찾는 것입니다. Point-in-time recovery(PITR)는 DynamoDB에서 연속 백업을 제공해 원하는 시점으로 바로 복원이 가능하므로 15분 이내의 RPO와 1시간 내 RTO를 충족하기에 적합합니다.", "Selections": {"SelectA": {"Select": "DynamoDB Global Tables를 구성합니다. RPO 복구 시, 애플리케이션을 다른 AWS 리전으로 지정합니다.", "Commentary": "Global Tables는 리전 간 데이터 동기화에 유용하지만, 데이터 손상이 여러 리전에 그대로 복제될 수 있어 백업/복원 시점 제어가 어렵습니다."}, "SelectB": {"Select": "DynamoDB Point-in-time recovery를 구성합니다. RPO 복구 시, 원하는 시점으로 복원합니다.", "Commentary": "PITR을 통해 최대 35일 이내 어떤 시점으로든 손쉽게 복원할 수 있어, 15분 RPO와 1시간 RTO 목표를 만족합니다."}, "SelectC": {"Select": "DynamoDB 데이터를 매일 Amazon S3 Glacier로 내보냅니다. RPO 복구 시, S3 Glacier로부터 DynamoDB로 데이터를 가져옵니다.", "Commentary": "하루에 한 번 백업은 15분 RPO 요구사항을 충족하지 못하고 S3 Glacier 복원 속도도 느려 RTO 충족이 어렵습니다."}, "SelectD": {"Select": "Amazon EBS 스냅샷을 15분 간격으로 예약 실행합니다. RPO 복구 시, 이 EBS 스냅샷을 사용해 DynamoDB 테이블을 복원합니다.", "Commentary": "DynamoDB는 서버리스 서비스이므로 EBS 스냅샷 기반 복원이 불가능하며, 해당 접근 방식은 적용할 수 없습니다."}}}
{"Question_Number": "Q72", "Question_Description": "한 회사가 사진 처리 애플리케이션을 운영하는데, 동일한 AWS Region에 위치한 Amazon S3 버킷들로부터 자주 이미지를 업로드하고 다운로드해야 합니다. 솔루션스 아키텍트는 데이터 전송 비용이 증가하고 있음을 확인했고, 이를 절감할 수 있는 솔루션을 구현해야 합니다. 어떤 접근 방식이 이 요구 사항을 충족할 수 있습니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["동일한 AWS Region", "데이터 전송 비용", "Amazon S3 버킷", "S3 VPC gateway endpoint"], "Terms": ["Amazon S3", "S3 VPC gateway endpoint", "NAT gateway", "Internet gateway", "Amazon API Gateway", "endpoint policy", "퍼블릭 서브넷", "VPC"], "Commentary": "이 문제는 같은 Region 내에서 빈번하게 발생하는 S3 트래픽을 어떻게 내부 경로로 라우팅해 데이터 전송 비용을 줄일지 묻습니다. S3 VPC gateway endpoint를 사용하면 인터넷을 거치지 않아 비용이 크게 절감됩니다.", "Selections": {"SelectA": {"Select": "퍼블릭 서브넷에 Amazon API Gateway를 배포하고, 라우트 테이블을 조정하여 S3 호출을 이를 통해 라우팅합니다.", "Commentary": "API Gateway로 트래픽을 우회하면 내부 통신을 활용하지 못하고 외부 흐름을 유발하므로, 비용 절감에 효과적이지 않습니다."}, "SelectB": {"Select": "퍼블릭 서브넷에 NAT gateway를 배포하고, S3 버킷 액세스를 허용하는 endpoint policy를 연결합니다.", "Commentary": "NAT gateway를 경유하면 인터넷 트래픽으로 처리되어 추가 전송 비용이 발생하므로, VPC endpoint보다 비용 효율성이 떨어집니다."}, "SelectC": {"Select": "애플리케이션을 퍼블릭 서브넷에 배포하고, Internet gateway를 통해 S3 버킷에 접근하도록 라우팅을 허용합니다.", "Commentary": "Internet gateway를 통한 액세스는 인터넷을 거치는 방식이므로, 전송 비용 절감 효과가 충분히 크지 않습니다."}, "SelectD": {"Select": "VPC에 S3 VPC gateway endpoint를 배포하고, S3 버킷 액세스를 허용하는 endpoint policy를 연결합니다.", "Commentary": "S3 VPC gateway endpoint를 이용하면 VPC 내부 트래픽으로 연결되어 데이터 전송 비용을 절감하고, endpoint policy로 세부 권한 제어도 가능합니다."}}}
{"Question_Number": "Q73", "Question_Description": "한 회사가 최근 Amazon EC2의 private subnet에 Linux 기반 애플리케이션 인스턴스를, VPC의 public subnet에 Linux 기반 bastion host를 런칭했습니다. 이 솔루션스 아키텍트는 온프레미스 네트워크에서 회사의 인터넷 연결을 통해 bastion host로, 그리고 애플리케이션 서버들로 연결해야 합니다. 이 솔루션스 아키텍트는 모든 EC2 인스턴스의 보안 그룹이 해당 액세스를 허용하도록 해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트가 취해야 하는 단계의 조합은 무엇입니까? (2개를 선택하십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["bastion host", "private subnet", "public subnet", "on-premises network", "security group", "접근 허용", "external IP range", "private IP", "SSH"], "Terms": ["Amazon EC2", "bastion host", "security group", "private subnet", "public subnet", "SSH", "inbound access", "IP range"], "Commentary": "온프레미스 외부 IP에서 bastion host로 접속하고, 그 bastion host의 private IP만 애플리케이션 서버에 SSH를 허용하도록 보안 그룹을 구성해야 합니다.", "Selections": {"SelectA": {"Select": "현재 bastion host의 보안 그룹을 애플리케이션 인스턴스에서만 들어오는 액세스를 허용하도록 교체하십시오.", "Commentary": "bastion host가 온프레미스에서 접근 가능해야 하므로 잘못된 구성입니다."}, "SelectB": {"Select": "현재 bastion host의 보안 그룹을 회사 내부 IP 범위에서만 들어오는 액세스를 허용하도록 교체하십시오.", "Commentary": "온프레미스 연결이지만 외부 인터넷 IP를 통한 연결도 필요한 경우가 많으므로 제한적입니다."}, "SelectC": {"Select": "현재 bastion host의 보안 그룹을 회사의 외부 IP 범위에서만 들어오는 액세스를 허용하도록 교체하십시오.", "Commentary": "bastion host에 외부 IP(온프레미스)에서 SSH 접근을 허용해야 하므로 옳은 선택입니다."}, "SelectD": {"Select": "현재 애플리케이션 인스턴스의 보안 그룹을 bastion host의 private IP 주소에서만 SSH로 들어오는 액세스를 허용하도록 교체하십시오.", "Commentary": "같은 VPC 내에서 bastion host는 private IP로 애플리케이션 서버에 연결하므로 옳은 선택입니다."}, "SelectE": {"Select": "현재 애플리케이션 인스턴스의 보안 그룹을 bastion host의 public IP 주소에서만 SSH로 들어오는 액세스를 허용하도록 교체하십시오.", "Commentary": "동일 VPC에서는 private IP를 활용하므로 public IP 접근은 비효율적입니다."}}}
{"Question_Number": "Q74", "Question_Description": "한 솔루션스 아키텍트가 2티어 웹 애플리케이션을 설계하고 있습니다. 웹 계층은 public subnet에 위치한 Amazon EC2에 호스팅되어 있으며, 데이터베이스 계층은 Microsoft SQL Server가 구동되는 Amazon EC2가 private subnet에 위치합니다. 회사에서는 보안을 매우 중요하게 생각합니다. 이러한 상황에서 security group을 어떻게 구성해야 할까요? (정답은 2개를 고르십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["2티어 웹 애플리케이션", "Amazon EC2", "public subnet", "private subnet", "Microsoft SQL Server", "security group", "포트 443", "포트 1433"], "Terms": ["Amazon EC2", "Microsoft SQL Server", "public subnet", "private subnet", "security group", "inbound traffic", "outbound traffic", "port 443", "port 1433", "0.0.0.0/0"], "Commentary": "이 문제는 웹 계층(프론트엔드)과 데이터베이스 계층(백엔드)을 각각 다른 subnet에 두고, 서로 다른 security group을 올바르게 구성하여 보안을 강화하는 방법을 묻습니다. 웹 계층에서는 HTTPS(443)로 외부에서 접근 가능해야 하고, 데이터베이스 계층에서는 오직 웹 계층 security group에서 오는 1433 포트 트래픽만 허용해야 합니다. 이를 통해 공용 인터넷에서 직접 접근이 불가능하도록 하면서도 애플리케이션이 정상적으로 동작하게끔 보안 구성을 설정합니다.", "Selections": {"SelectA": {"Select": "웹 계층 security group을 0.0.0.0/0에서 포트 443으로의 인바운드 트래픽을 허용하도록 설정합니다.", "Commentary": "HTTPS 접속을 위해 외부로부터 443 포트를 열어둬야 하므로 필수적인 설정입니다. 따라서 정답에 해당합니다."}, "SelectB": {"Select": "웹 계층 security group을 0.0.0.0/0에서 포트 443으로의 아웃바운드 트래픽을 허용하도록 설정합니다.", "Commentary": "일반적으로 웹 서버에서의 아웃바운드 443은 서버가 외부로 접속할 때 필요한 규칙이지만, 질문에서 요구하는 필수적인 보안 구성 사항은 아닙니다."}, "SelectC": {"Select": "데이터베이스 계층 security group에서 웹 계층 security group으로부터 포트 1433 인바운드 트래픽을 허용하도록 설정합니다.", "Commentary": "웹 계층(프론트엔드)에서 백엔드 DB(Microsoft SQL Server)에 연결하기 위한 포트를 열어주어야 하므로 정답입니다."}, "SelectD": {"Select": "데이터베이스 계층 security group에서 웹 계층 security group으로 포트 443과 1433에 대한 아웃바운드 트래픽을 허용하도록 설정합니다.", "Commentary": "DB 계층에서 웹 계층으로 443이나 1433을 보낼 필요는 없습니다. 주로 웹 계층 → DB 계층으로 연결이 필요하므로 불필요한 설정입니다."}, "SelectE": {"Select": "데이터베이스 계층 security group에서 웹 계층 security group으로부터 포트 443과 1433 인바운드 트래픽을 허용하도록 설정합니다.", "Commentary": "DB 계층에는 1433만 열면 되고 443은 필요하지 않으므로 과도한 허용 규칙입니다."}}}
{"Question_Number": "Q75", "Question_Description": "한 회사가 애플리케이션의 성능을 개선하기 위해 온프레미스 환경에서 AWS Cloud로 다중 계층(multi-tiered) 애플리케이션을 이전하려고 합니다. 이 애플리케이션은 RESTful 서비스를 통해 서로 통신하는 여러 계층으로 구성되며, 한 계층이 과부하되면 트랜잭션이 누락되는 문제가 발생합니다. 솔루션 아키텍트는 이 문제를 해결하고 애플리케이션을 모던화할 방안을 설계해야 합니다. 이러한 요구사항을 만족하면서 가장 운영 효율적인 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["다중 계층 애플리케이션", "성능 개선", "RESTful 서비스", "모던화", "Amazon API Gateway", "AWS Lambda", "Amazon SQS"], "Terms": ["AWS Cloud", "Amazon API Gateway", "AWS Lambda", "Amazon Simple Queue Service (Amazon SQS)", "Amazon CloudWatch", "Amazon Simple Notification Service (Amazon SNS)", "Amazon EC2", "Auto Scaling group"], "Commentary": "이 문제는 과부하로 인해 트랜잭션이 누락되는 전통적 계층 구조를 클라우드 환경에서 현대화하는 시나리오입니다. 병목 해소와 성능 개선을 위해 서버리스 구조(AWS Lambda)와 메시징(Amazon SQS)을 활용해 느슨하게 결합된 확장형 아키텍처를 구성하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "Amazon API Gateway를 사용하여 트랜잭션을 AWS Lambda 함수(애플리케이션 계층)로 직접 연결하고, 애플리케이션 서비스 간 통신 계층으로 Amazon SQS를 사용합니다.", "Commentary": "서버리스(Lambda)와 SQS를 활용한 메시지 처리로 계층 간 과부하를 방지하고 완전관리형 환경을 통해 운영 부담을 크게 줄이는 최적의 솔루션입니다."}, "SelectB": {"Select": "Amazon CloudWatch 지표를 사용해 애플리케이션 성능 기록을 분석한 뒤, 문제 발생 시점의 서버 피크 사용량에 맞추어 Amazon EC2 인스턴스 크기를 늘립니다.", "Commentary": "서버 사양 증설은 트래픽 급증에 대비하지만, 과부하 발생 시점을 근본적으로 해결하지 못하고 운영 복잡도가 상대적으로 높아집니다."}, "SelectC": {"Select": "Amazon EC2 Auto Scaling 그룹으로 동작하는 애플리케이션 서버 간 메시징에 Amazon SNS를 사용하고, Amazon CloudWatch로 SNS 대기열 길이를 모니터링해 필요 시 확장합니다.", "Commentary": "SNS는 주로 브로드캐스트 성격의 알림에 적합하며, SQS만큼 강력한 큐잉 기능을 제공하지 않아 트랜잭션 누락 문제를 완전히 해결하기 어렵습니다."}, "SelectD": {"Select": "Amazon EC2 Auto Scaling 그룹으로 동작하는 애플리케이션 서버 간 메시징에 Amazon SQS를 사용하고, Amazon CloudWatch로 SQS 대기열 길이를 모니터링한 뒤 통신 장애가 감지되면 확장합니다.", "Commentary": "대기열 모니터링을 통한 확장은 가능하지만, 애플리케이션 계층을 서버리스로 전환하지 않아 민첩성과 운영 효율성이 A에 비해 떨어집니다."}}}
{"Question_Number": "Q76", "Question_Description": "한 회사는 단일 공장 안에 있는 여러 기계로부터 매일 10TB의 계측 데이터를 받습니다. 이 데이터는 공장 내부 온프레미스 데이터 센터의 SAN(Storage Area Network)에 JSON 파일 형태로 저장되어 있습니다. 회사는 이 데이터를 Amazon S3로 전송하여 여러 추가 시스템이 거의 실시간 분석을 수행하도록 하길 원합니다. 데이터는 민감 정보이므로 안전한 전송이 필수적입니다. 이러한 요구사항을 만족하는 가장 신뢰도 높은 데이터 전송 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["AWS DataSync", "AWS Direct Connect", "JSON 파일", "10TB", "SAN", "민감 데이터", "Amazon S3"], "Terms": ["AWS DataSync", "AWS Direct Connect", "AWS Database Migration Service (AWS DMS)", "SAN(Storage Area Network)", "JSON", "on-premises data center", "public internet"], "Commentary": "이 문제는 공장 내 SAN에 저장된 대규모 JSON 파일을 Amazon S3로 빠르고 안전하게 전송하는 방법을 묻습니다. AWS DataSync에 AWS Direct Connect를 사용하면 전용 네트워크로 안정성과 보안을 모두 충족합니다.", "Selections": {"SelectA": {"Select": "AWS DataSync over public internet", "Commentary": "인터넷 기반 전송은 지연 및 보안 이슈가 발생할 수 있어 신뢰도가 떨어집니다."}, "SelectB": {"Select": "AWS DataSync over AWS Direct Connect", "Commentary": "전용 네트워크 연결을 사용해 안정적이고 안전한 전송이 가능하므로 대규모 민감 데이터 전송에 최적입니다."}, "SelectC": {"Select": "AWS Database Migration Service (AWS DMS) over public internet", "Commentary": "DMS는 주로 데이터베이스 마이그레이션용으로 JSON 파일 전송에 적합하지 않으며, 공용 인터넷은 신뢰성이 낮습니다."}, "SelectD": {"Select": "AWS Database Migration Service (AWS DMS) over AWS Direct Connect", "Commentary": "DMS 자체는 데이터베이스 마이그레이션에 집중된 서비스이므로 JSON 파일 전송 요구사항에는 부적절합니다."}}}
{"Question_Number": "Q77", "Question_Description": "한 회사가 애플리케이션에 대해 실시간 데이터 수집 아키텍처를 구성해야 합니다. 회사는 API가 필요하고, 스트리밍되는 동안 데이터를 변환하는 프로세스가 필요하며, 데이터를 저장할 스토리지 솔루션이 필요합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["실시간 데이터 스트리밍", "API", "데이터 변환", "저장", "Kinesis Data Firehose", "Lambda", "Amazon S3", "운영 오버헤드 최소화"], "Terms": ["Amazon EC2", "Amazon API Gateway", "Amazon Kinesis Data Streams", "Amazon Kinesis Data Firehose", "AWS Lambda", "Amazon S3", "AWS Glue"], "Commentary": "이 문제는 애플리케이션에서 실시간으로 유입되는 데이터를 가져와 변환하고 저장하기 위한 아키텍처 구성에 대한 것입니다. Amazon API Gateway와 Amazon Kinesis Data Streams, Kinesis Data Firehose, AWS Lambda를 결합하여 데이터를 실시간으로 처리하고 Amazon S3에 저장하면 운영 부담을 크게 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스를 배포하여 API를 호스팅하고, 데이터를 Amazon Kinesis data stream으로 전송합니다. Amazon Kinesis Data Firehose를 생성하여 해당 data stream을 데이터 소스로 사용합니다. AWS Lambda 함수를 사용해 데이터를 변환하고, 변환된 데이터를 Kinesis Data Firehose를 통해 Amazon S3로 전송합니다.", "Commentary": "별도의 EC2 배포가 필요하므로 운영 오버헤드가 증가합니다. 전체 흐름은 유사하나 API를 EC2에서 호스팅해야 하므로 관리가 복잡해집니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스를 배포하여 API를 호스팅하고 AWS Glue로 데이터를 전송합니다. EC2 인스턴스에서 소스/대상 확인을 해제합니다. AWS Glue를 사용하여 데이터를 변환하고 Amazon S3로 전송합니다.", "Commentary": "EC2와 AWS Glue를 결합한 방식으로 실시간 스트리밍에는 적합하지 않으며, 운영 오버헤드가 큽니다."}, "SelectC": {"Select": "Amazon API Gateway API를 구성하여 데이터를 Amazon Kinesis data stream으로 전송합니다. Amazon Kinesis Data Firehose를 생성하여 해당 data stream을 데이터 소스로 사용합니다. AWS Lambda 함수를 사용해 데이터를 변환하고, Kinesis Data Firehose를 통해 Amazon S3로 데이터를 전송합니다.", "Commentary": "API Gateway와 Kinesis, Lambda, Firehose를 연계하여 실시간 데이터를 처리하고 S3에 저장하며, EC2가 필요 없어 운영 오버헤드를 최소화하는 최적의 솔루션입니다."}, "SelectD": {"Select": "Amazon API Gateway API를 구성하여 데이터를 AWS Glue로 전송합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. AWS Glue를 사용하여 데이터를 Amazon S3로 전송합니다.", "Commentary": "AWS Glue는 주로 배치 데이터 처리에 사용되며, API Gateway를 통한 실시간 스트리밍 처리와는 맞지 않아 비효율적입니다."}}}
{"Question_Number": "Q78", "Question_Description": "한 회사가 Amazon DynamoDB 테이블에 사용자 트랜잭션 데이터를 보관해야 합니다. 이 회사는 데이터를 7년 동안 유지해야 합니다. 이 요구사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Amazon DynamoDB", "7년 보관", "운영 효율성", "백업 일정", "AWS Backup"], "Terms": ["Amazon DynamoDB", "Point-in-time recovery (PITR)", "On-demand backup", "AWS Backup", "Amazon S3", "S3 Lifecycle", "Amazon EventBridge", "AWS Lambda"], "Commentary": "이 문제는 DynamoDB에 저장된 데이터를 7년간 유지하면서 운영 복잡도를 최소화하는 백업 전략을 찾는 것입니다. 단순한 PITR(Point-in-time recovery)로는 최대 35일까지 복원이 가능해 장기 보관 요건을 충족하지 못합니다. On-demand 백업과 S3 라이프사이클 등 수동 관리 방식은 오퍼레이션 부담이 큽니다. 반면 AWS Backup을 사용하면 백업 일정 관리와 보존 정책을 한 번에 지정할 수 있어 가장 운영 효율적인 솔루션이 됩니다.", "Selections": {"SelectA": {"Select": "DynamoDB 테이블에 대해 point-in-time recovery를 사용하여 연속 백업을 수행합니다.", "Commentary": "PITR은 최대 35일까지 복원이 가능하므로 7년 보관을 충족하지 않습니다."}, "SelectB": {"Select": "AWS Backup을 사용하여 백업 일정과 테이블의 보존 정책을 생성합니다.", "Commentary": "AWS Backup으로 장기 백업 일정 및 보존 정책을 중앙에서 자동 관리할 수 있어 운영 효율성이 매우 높습니다."}, "SelectC": {"Select": "DynamoDB 콘솔에서 테이블의 온디맨드 백업을 생성하고, 이를 Amazon S3 버킷에 저장합니다. S3 Lifecycle 구성으로 관리합니다.", "Commentary": "수동으로 백업 스케줄을 설정해야 하므로 장기적으로 운영 부담이 큽니다."}, "SelectD": {"Select": "Amazon EventBridge 규칙로 AWS Lambda 함수를 호출하여 테이블을 백업하고, Amazon S3 버킷에 저장합니다. 이후 S3 Lifecycle을 설정합니다.", "Commentary": "별도의 Lambda 및 EventBridge 설정이 필요해 운영 절차가 복잡하기 때문에 가장 효율적인 방법이 아닙니다."}}}
{"Question_Number": "Q79", "Question_Description": "한 회사가 Amazon DynamoDB 테이블을 사용하여 데이터 저장을 계획하고 있습니다. 회사는 비용 최적화에 대해 우려하고 있습니다. 이 테이블은 대부분의 아침 시간대에는 사용되지 않을 것입니다. 저녁 시간대에는 읽기 및 쓰기 트래픽이 종종 예측하기 힘들 것입니다. 트래픽 급증이 발생하면 매우 빠르게 일어납니다. 솔루션스 아키텍트는 어떤 방안을 권장해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["비용 최적화", "아침 시간대 미사용", "저녁 예측 불가능 트래픽", "트래픽 급증", "on-demand capacity mode"], "Terms": ["Amazon DynamoDB", "on-demand capacity mode", "provisioned capacity", "auto scaling", "global table", "global secondary index"], "Commentary": "이 문제는 일정하지 않고 예측하기 어려운 트래픽 패턴과 비용 최적화를 동시에 해결해야 합니다. on-demand capacity mode를 사용하면 사용량 급증 시 자동으로 확장되고, 사용한 만큼만 비용을 지불해 무활성 시간대 비용을 절감할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon DynamoDB 테이블을 on-demand capacity mode로 생성하십시오.", "Commentary": "필요할 때 자동으로 확장되며, 사용량이 적을 때는 비용도 줄어듭니다. 트래픽 급변 상황에서도 프로비저닝 설정 없이 즉시 대응 가능해 비용 최적화에 가장 적합합니다."}, "SelectB": {"Select": "글로벌 보조 인덱스(global secondary index)가 포함된 DynamoDB 테이블을 생성하십시오.", "Commentary": "글로벌 보조 인덱스는 조회 패턴 확장에 유용하지만 예측 불가능한 트래픽과 비용 최적화 문제 자체를 해결해 주지는 못합니다."}, "SelectC": {"Select": "프로비저닝된 용량(provisioned capacity)과 auto scaling이 설정된 DynamoDB 테이블을 생성하십시오.", "Commentary": "auto scaling은 트래픽 변화에 대응할 수 있지만 예측치 설정이 필요하며, 급격한 급증에 대한 즉각 대응과 비사용 시간대 비용 절감에서 on-demand만큼 유연하지 않습니다."}, "SelectD": {"Select": "프로비저닝된 용량 모드로 DynamoDB 테이블을 생성하고, 이를 글로벌 테이블(global table)로 구성하십시오.", "Commentary": "글로벌 테이블을 통한 다중 리전 동기화는 가용성과 지연 시간 개선에 도움을 주지만, 비용 최적화와预测 불가 트래픽에 대한 신속 대응 면에서는 on-demand 모드가 더 적합합니다."}}}
{"Question_Number": "Q80", "Question_Description": "한 회사는 최근 애플리케이션 마이그레이션 이니셔티브를 지원하기 위해 AWS Managed Service Provider(MSP) Partner와 계약을 체결했습니다. 한 Solutions Architect는 기존 AWS 계정의 Amazon Machine Image(AMI)를 MSP Partner의 AWS 계정과 공유해야 합니다. 해당 AMI는 Amazon Elastic Block Store(Amazon EBS) 기반이며, EBS 볼륨 스냅샷 암호화를 위해 AWS Key Management Service(AWS KMS)의 customer managed key를 사용합니다. 가장 보안성이 높은 방식으로 AMI를 MSP Partner의 AWS 계정과 공유하려면 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["AWS Managed Service Provider(MSP) Partner", "Amazon Machine Image(AMI)", "암호화된 AMI 공유", "AWS KMS customer managed key", "EBS 볼륨 스냅샷"], "Terms": ["Amazon Machine Image (AMI)", "AWS Managed Service Provider (MSP)", "Amazon EBS", "AWS KMS", "customer managed key", "EBS volume snapshots", "Key Policy", "launchPermission"], "Commentary": "이 문제는 KMS customer managed key로 암호화된 Amazon EBS 기반 AMI를 외부 AWS 계정(MSP Partner)과 공유할 때의 보안적인 방법을 묻습니다. 공유 대상 계정이 스냅샷을 복호화하고 AMI를 정상적으로 사용할 수 있도록, launchPermission과 KMS 키 정책을 적절히 설정해야 합니다. 퍼블릭 공유나 Export 절차 등은 불필요하거나 보안 위험, 운영 복잡성을 유발하므로 피해야 합니다.", "Selections": {"SelectA": {"Select": "암호화된 AMI와 스냅샷을 퍼블릭하게 만듭니다. 키 정책을 수정하여 MSP Partner의 AWS 계정이 해당 키를 사용할 수 있도록 허용합니다.", "Commentary": "AMI와 스냅샷을 퍼블릭하게 하면 보안을 크게 약화시키므로, 필요 계정 이외에는 공개하지 않는 것이 안전합니다."}, "SelectB": {"Select": "AMI의 launchPermission 속성을 수정합니다. AMI를 MSP Partner의 AWS 계정과만 공유합니다. 키 정책을 수정하여 MSP Partner의 AWS 계정이 키를 사용할 수 있도록 허용합니다.", "Commentary": "AMI를 특정 계정만 접근 가능하도록 설정하고, KMS 키 정책을 통해 해당 계정이 암호화된 스냅샷을 복호화할 수 있게 해주는 가장 보안적이고 간결한 접근입니다."}, "SelectC": {"Select": "AMI의 launchPermission 속성을 수정합니다. AMI를 MSP Partner의 AWS 계정과만 공유합니다. 새로 MSP Partner가 소유한 KMS 키가 암호화에 신뢰되도록 키 정책을 수정합니다.", "Commentary": "기존 KMS 키가 아닌 다른 키를 쓰려면 재암호화가 필요할 수 있어 운영 복잡성이 상당히 높아집니다."}, "SelectD": {"Select": "소스 계정에서 AMI를 MSP Partner의 AWS 계정 내 Amazon S3 버킷으로 Export합니다. 해당 S3 버킷을 MSP Partner가 소유한 새로운 KMS 키로 암호화합니다. 그런 다음 AMI를 MSP Partner의 AWS 계정에서 복사 및 실행합니다.", "Commentary": "Export 후 다시 Import하는 과정이 늘어나고 재암호화도 필수여서 절차가 복잡해집니다. 기존 KMS 키를 활용해 직접 공유하는 것보다 효율성이 떨어집니다."}}}
{"Question_Number": "Q81", "Question_Description": "한 솔루션스 아키텍트가 새로운 애플리케이션을 AWS에 배포하기 위해 클라우드 아키텍처를 설계하고 있습니다. 이 프로세스는 병렬로 실행되며, 처리해야 할 작업(job)의 수에 따라 애플리케이션 노드를 추가하거나 제거할 수 있어야 합니다. 프로세서 애플리케이션(processor application)은 무상태(stateless)입니다. 솔루션스 아키텍트는 애플리케이션이 느슨하게 결합되어 있고, 작업 항목(job items)이 영구적으로(durably) 저장되도록 해야 합니다. 이러한 요구사항을 충족하는 설계는 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["병렬 처리", "무상태 애플리케이션", "느슨한 결합", "durably stored", "Amazon SQS", "Auto Scaling"], "Terms": ["Amazon SNS", "Amazon SQS", "Amazon Machine Image (AMI)", "Launch Configuration", "Launch Template", "Auto Scaling group", "Scaling policy", "Stateless"], "Commentary": "이 문제는 대규모 병렬 처리가 필요한 무상태 애플리케이션을 효율적으로 확장하고 작업을 안정적으로 저장하는 방법을 묻습니다. 느슨한 결합을 위해 Amazon SQS 같은 Queue 서비스 활용이 핵심이며, 처리량에 따라 Auto Scaling group을 동적으로 조정해야 합니다.", "Selections": {"SelectA": {"Select": "처리할 작업을 Amazon SNS 토픽을 통해 전송합니다. 프로세서 애플리케이션이 포함된 Amazon Machine Image(AMI)를 생성합니다. 해당 AMI를 사용하는 Launch Configuration을 만들고, Auto Scaling group을 생성합니다. Auto Scaling group은 CPU 사용률에 따라 노드를 조정합니다.", "Commentary": "SNS는 주로 알림·푸시 기반 서비스로 내재적 메시지 보관 기능이 제한적입니다. 상태 저장과 내구성(durability)을 보장하기 어렵고 CPU 사용량만으로 처리가 필요한 작업 수를 제대로 반영하기 어렵습니다."}, "SelectB": {"Select": "처리할 작업을 저장할 Amazon SQS 큐를 만듭니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Configuration을 구성하고, Auto Scaling group을 만듭니다. 네트워크 사용량을 기준으로 노드를 조정하도록 설정합니다.", "Commentary": "SQS를 이용해 내구성 있는 큐를 사용하지만, 네트워크 사용량을 기준으로 확장하면 작업 수와 직접 연관되지 않아 과소 혹은 과다 확장이 일어날 수 있습니다."}, "SelectC": {"Select": "처리할 작업을 저장할 Amazon SQS 큐를 만듭니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Template을 생성하고, Auto Scaling group을 구성합니다. SQS 큐의 항목 수에 따라 노드를 추가하거나 제거하도록 설정합니다.", "Commentary": "SQS 큐는 메시지를 내구성 있게 저장해 느슨한 결합을 실현하며, 큐 항목 수에 따라 수평 확장을 자동으로 조정할 수 있어 요구사항을 완벽히 충족합니다."}, "SelectD": {"Select": "처리할 작업을 Amazon SNS 토픽에 전송합니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Template을 생성하고, Auto Scaling group을 만듭니다. SNS 토픽에 게시되는 메시지 수를 기준으로 노드를 조정합니다.", "Commentary": "SNS 토픽은 알림 기반이며 큐 자체가 없으므로 작업의 내구성 보장이 어렵습니다. 게시 메시지 수만으로는 실제 큐잉 기반 처리와 달리 안정적인 확장을 보장하기 어렵습니다."}}}
{"Question_Number": "Q82", "Question_Description": "한 회사가 AWS Cloud에서 웹 애플리케이션을 호스팅하고 있습니다. 이 회사는 Elastic Load Balancer가 AWS Certificate Manager (ACM)에 가져온 인증서를 사용하도록 구성했습니다. 회사의 보안 팀은 각 인증서가 만료되기 30일 전에 반드시 알림을 받아야 합니다. 이 요구 사항을 충족하기 위해 Solutions Architect는 무엇을 권장해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["AWS Cloud", "Elastic Load Balancer", "AWS Certificate Manager (ACM)", "인증서 만료", "30일 전 알림"], "Terms": ["AWS Certificate Manager (ACM)", "Elastic Load Balancer", "AWS Config", "acm-certificate-expiration-check", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon Simple Notification Service (Amazon SNS)", "AWS Lambda", "AWS Trusted Advisor"], "Commentary": "이 문제는 ACM에 등록된 인증서가 만료되기 전에 어떻게 미리 알림을 보낼 수 있는가에 대한 보안 운용 시나리오입니다. AWS Certificate Manager 자체에는 만료 알림을 직접 Scheduler 형태로 구성하는 기능이 없으므로, 만료 30일 전에 자동으로 리소스를 검사하고 알림을 보낼 수 있는 기능이 필요합니다. AWS Config는 acm-certificate-expiration-check라는 관리형 규칙을 제공하며, 이 규칙을 기반으로 인증서 만료 시점을 모니터링할 수 있습니다. EventBridge 규칙과 Amazon SNS 알림을 연계하여 보안 팀에 자동으로 알림을 전송하도록 설정할 수 있으므로 운영 복잡성 없이 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "ACM에서 30일 전부터 매일 Amazon Simple Notification Service (Amazon SNS) 토픽으로 커스텀 메시지를 게시하는 규칙을 추가합니다.", "Commentary": "ACM 자체에 이러한 규칙을 직접 추가할 수 없기에 부적절합니다."}, "SelectB": {"Select": "AWS Config에서 만료 30일 이내의 인증서를 검사하는 규칙을 생성하고, Amazon EventBridge (Amazon CloudWatch Events)와 SNS를 연동하여 비준수 리소스가 보고되면 경고를 발송합니다.", "Commentary": "AWS Config의 acm-certificate-expiration-check 관리형 규칙을 사용하여 간단히 해결 가능합니다."}, "SelectC": {"Select": "AWS Trusted Advisor로 30일 이내에 만료될 인증서를 확인하고, Trusted Advisor의 상태 변경 지표를 기반으로 Amazon CloudWatch 알람을 생성해 SNS로 커스텀 알림을 전송합니다.", "Commentary": "Trusted Advisor는 일부 인증서 점검을 제공하지만 즉시적이고 세밀한 만료 알림에는 AWS Config가 더 적합합니다."}, "SelectD": {"Select": "Amazon EventBridge (Amazon CloudWatch Events) 규칙을 생성해 30일 이내에 만료될 인증서를 감지하고, AWS Lambda 함수를 호출하여 SNS를 통해 커스텀 알림을 전송합니다.", "Commentary": "직접 증분 로직을 구현해야 하므로, 이미 관리형 규칙이 있는 AWS Config 방식보다 복잡합니다."}}}
{"Question_Number": "Q83", "Question_Description": "한 회사의 동적 웹사이트가 미국에 있는 on-premises 서버를 사용해 호스팅되고 있습니다. 이 회사는 유럽에서 제품 출시를 앞두고, 새롭게 유럽 지역 사용자들의 사이트 로딩 시간을 최적화하고자 합니다. 하지만 웹사이트 백엔드는 계속 미국에 유지되어야 하며, 제품은 며칠 뒤 출시 예정이므로 즉시 구현 가능한 솔루션이 필요합니다. 솔루션스 아키텍트는 어떤 해결책을 제안해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["동적 웹사이트", "on-premises 서버", "유럽 사용자", "사이트 로딩 시간 최적화", "즉시 솔루션", "Amazon CloudFront", "custom origin"], "Terms": ["Amazon CloudFront", "on-premises", "Amazon EC2", "Amazon S3", "Cross-Region Replication", "Amazon Route 53 geoproximity routing"], "Commentary": "이 문제는 유럽 사용자들의 웹사이트 로딩 시간을 개선하면서 백엔드는 미국에 그대로 두고, 빠르게 구현 가능한 방안을 찾는 것이 핵심입니다. CloudFront를 사용해 on-premises 서버를 custom origin으로 설정하면, 전 세계 Edge Location에서 콘텐츠를 캐싱해 유럽 사용자에게 신속하게 전달할 수 있습니다.", "Selections": {"SelectA": {"Select": "us-east-1에 Amazon EC2 인스턴스를 실행하고 사이트를 해당 인스턴스로 마이그레이션합니다.", "Commentary": "사이트를 EC2로 이전해도 물리적 거리가 멀어 유럽 사용자의 지연 시간이 크게 개선되지 않고, 즉시 사용하기에도 시간이 더 소요됩니다."}, "SelectB": {"Select": "웹사이트를 Amazon S3로 이전합니다. 리전 간 Cross-Region Replication을 사용합니다.", "Commentary": "정적 콘텐츠에는 적절하지만, 동적 웹사이트와 미국에 있는 on-premises 백엔드를 그대로 활용하는 요구사항에는 부적합합니다."}, "SelectC": {"Select": "Amazon CloudFront를 사용하고, on-premises 서버를 custom origin으로 지정합니다.", "Commentary": "CloudFront의 CDN 기능으로 전 세계 Edge Location에서 콘텐츠를 제공해 유럽 사용자에게 빠른 응답 속도를 보장하므로 즉각적 해결책입니다."}, "SelectD": {"Select": "Amazon Route 53 geoproximity 라우팅 정책을 사용하여 on-premises 서버로 트래픽을 라우팅합니다.", "Commentary": "지리적 위치에 따라 트래픽을 분산하지만, 미국에 있는 백엔드 자체를 그대로 두면서 유럽에서의 지연을 낮추기 위해서는 CloudFront와 같은 CDN 방식이 더 적합합니다."}}}
{"Question_Number": "Q84", "Question_Description": "한 회사가 기존의 3티어 웹 아키텍처 비용을 절감하려고 합니다. 웹, 애플리케이션, 데이터베이스 서버는 개발, 테스트, 프로덕션 환경에서 Amazon EC2 인스턴스로 실행되고 있습니다. EC2 인스턴스는 피크 시간대에 평균 30% CPU 활용률, 비피크 시간대에 평균 10% CPU 활용률을 보입니다. 프로덕션 EC2 인스턴스는 하루 24시간 실행되며, 개발 및 테스트 EC2 인스턴스는 매일 최소 8시간씩 실행됩니다. 회사는 사용 중이 아닐 때 개발 및 테스트 EC2 인스턴스를 중지하도록 자동화를 구현하려고 합니다. 회사 요구사항을 가장 비용 효율적으로 충족하는 EC2 인스턴스 구매 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["비용 절감", "Amazon EC2", "Reserved Instances", "On-Demand Instances", "Spot Instances", "Spot blocks", "개발 환경", "테스트 환경", "프로덕션 환경"], "Terms": ["CPU Utilization", "Three-tier web architecture", "Reserved Instances", "On-Demand Instances", "Spot Instances", "Spot blocks"], "Commentary": "이 문제는 프로덕션에서는 24시간 상시 실행이 필요하므로 미리 예약해 두어 할인 혜택이 적용되는 Reserved Instances가 적합합니다. 개발과 테스트는 사용하지 않을 때 자동으로 중지할 수 있어 가변적인 시간만큼 비용을 지불하는 On-Demand Instances가 합리적입니다. Spot blocks는 현재 제공되지 않고, 상시 가용성이 필요한 프로덕션에 Spot Instances를 사용하는 것은 적합하지 않습니다.", "Selections": {"SelectA": {"Select": "Spot Instances를 프로덕션 EC2 인스턴스에 사용하고, Reserved Instances를 개발 및 테스트 인스턴스에 사용합니다.", "Commentary": "프로덕션은 24시간 안정적으로 실행되어야 하므로 중단될 수 있는 Spot Instances는 적절하지 않습니다."}, "SelectB": {"Select": "Reserved Instances를 프로덕션 EC2 인스턴스에 사용하고, On-Demand Instances를 개발 및 테스트 인스턴스에 사용합니다.", "Commentary": "프로덕션은 상시 실행이 필요하므로 Reserved Instances로 장기 비용 절감이 가능하며, 개발 및 테스트는 On-Demand Instances로 필요 시간만큼만 비용을 지불할 수 있어 가장 효율적입니다."}, "SelectC": {"Select": "Spot blocks를 프로덕션 EC2 인스턴스에 사용하고, Reserved Instances를 개발 및 테스트 인스턴스에 사용합니다.", "Commentary": "Spot blocks는 현재 이용할 수 없으며, 프로덕션의 안정적인 가동에도 적합하지 않습니다."}, "SelectD": {"Select": "On-Demand Instances를 프로덕션 EC2 인스턴스에 사용하고, Spot blocks를 개발 및 테스트 인스턴스에 사용합니다.", "Commentary": "Spot blocks는 더 이상 제공되지 않으며, 자동 중지와 재시작이 가능한 On-Demand가 아닌 다른 방식으로는 개발/테스트의 탄력성을 제대로 살리기 어렵습니다."}}}
{"Question_Number": "Q85", "Question_Description": "한 회사는 프로덕션 웹 애플리케이션을 운영 중이며, 웹 인터페이스나 모바일 앱을 통해 사용자가 문서를 업로드합니다. 새로운 규제 요구사항에 따르면, 업로드된 문서는 저장 후 수정하거나 삭제할 수 없습니다. 이 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["프로덕션 웹 애플리케이션", "문서 업로드", "규제 요구사항", "변경 불가능", "Amazon S3", "S3 Object Lock", "S3 Versioning"], "Terms": ["S3 Object Lock", "WORM", "S3 Versioning", "S3 Lifecycle Policy", "ACL", "Amazon EFS"], "Commentary": "이 문제는 규제 요구사항을 만족하기 위해 문서를 저장한 후 변경 또는 삭제가 불가능하도록 해야 하는 시나리오입니다. 정답은 Amazon S3에서 S3 Object Lock과 S3 Versioning을 함께 활성화하여 WORM(Write-Once-Read-Many) 보관 모델을 구현하는 것입니다. 이를 통해 업로드된 문서를 일정 기간 또는 무기한 동안 삭제나 덮어쓰기를 방지하고, 규제 요구사항을 충족할 수 있습니다.", "Selections": {"SelectA": {"Select": "업로드된 문서를 S3 Versioning과 S3 Object Lock이 활성화된 Amazon S3 버킷에 저장합니다.", "Commentary": "S3 Object Lock을 통해 저장된 객체를 변경 또는 삭제할 수 없는 WORM 모드를 구현할 수 있으므로 규제 요구사항을 충족합니다."}, "SelectB": {"Select": "업로드된 문서를 Amazon S3 버킷에 저장하고, 주기적으로 S3 Lifecycle 정책을 구성해 아카이빙합니다.", "Commentary": "Lifecycle 정책은 객체를 다른 스토리지 클래스로 이동 또는 만료시키는 기능으로, 수정·삭제 방지를 보장하지 못합니다."}, "SelectC": {"Select": "S3 Versioning이 활성화된 Amazon S3 버킷에 업로드하고, ACL를 통해 읽기 전용 권한으로 제한합니다.", "Commentary": "ACL만으로는 사용자가 객체를 수정하거나 삭제하지 못하게 완전히 막을 수 없으며, 규제 수준의 변경 불가 상태를 구현하기 어렵습니다."}, "SelectD": {"Select": "Amazon EFS 볼륨에 문서를 저장하고, read-only 모드로 볼륨을 마운트하여 데이터를 액세스합니다.", "Commentary": "read-only 모드만으로는 EFS 데이터 변경을 영구적으로 금지하는 보장을 하지 못하고, WORM 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q86", "Question_Description": "한 회사는 여러 웹 서버에서 공용 Amazon RDS MySQL Multi-AZ DB 인스턴스에 자주 액세스해야 합니다. 회사는 안전한 방법으로 웹 서버가 데이터베이스에 연결할 수 있기를 원하며, 사용자 자격 증명을 자주 교체(회전)해야 한다는 보안 요구사항을 충족해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon RDS MySQL Multi-AZ", "사용자 자격 증명 교체", "AWS Secrets Manager", "IAM 권한", "웹 서버 안전 연결"], "Terms": ["Amazon RDS MySQL Multi-AZ", "AWS Secrets Manager", "IAM", "AWS Systems Manager OpsCenter", "Amazon S3", "AWS Key Management Service (AWS KMS)"], "Commentary": "이 문제는 웹 서버가 Amazon RDS MySQL Multi-AZ DB 인스턴스에 안전하게 연결하면서 자격 증명을 자주 교체해야 하는 상황을 다룹니다. AWS Secrets Manager를 사용하면 자격 증명을 안전하게 저장하고, 자동으로 회전시킬 수 있어 보안과 운영 편의성을 모두 충족합니다. 이를 통해 하드코딩된 비밀번호 위험을 최소화하고, 규칙적인 자격 증명 교체가 가능합니다.", "Selections": {"SelectA": {"Select": "데이터베이스 사용자 자격 증명을 AWS Secrets Manager에 저장합니다. 웹 서버가 AWS Secrets Manager에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.", "Commentary": "AWS Secrets Manager는 자격 증명 저장 및 자동 회전을 제공하여 보안을 크게 강화합니다. 웹 서버에서는 IAM 권한을 통해 동적으로 자격 증명을 받아 안전하게 DB에 연결할 수 있습니다."}, "SelectB": {"Select": "데이터베이스 사용자 자격 증명을 AWS Systems Manager OpsCenter에 저장합니다. 웹 서버가 OpsCenter에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.", "Commentary": "OpsCenter는 운영 이벤트 관리를 주 목적으로 하며, Secrets Manager처럼 전문적으로 자격 증명을 자동 회전해 주는 기능이 별도로 제공되지 않습니다."}, "SelectC": {"Select": "데이터베이스 사용자 자격 증명을 보안 설정된 Amazon S3 버킷에 저장합니다. 필요한 IAM 권한을 부여하여 웹 서버가 자격 증명을 조회하고 DB에 액세스하도록 합니다.", "Commentary": "S3 버킷을 사용할 경우 자격 증명 자동 회전을 지원하지 않아 수동 관리가 필요하며, 보안 및 운영 측면에서 추가 부담이 생깁니다."}, "SelectD": {"Select": "데이터베이스 사용자 자격 증명을 AWS KMS로 암호화된 파일 형태로 웹 서버 파일 시스템에 저장합니다. 웹 서버가 이 파일을 복호화하여 DB에 액세스하도록 합니다.", "Commentary": "웹 서버 내에 직접 자격 증명을 저장하면 보안 리스크가 높고, 자격 증명 교체 시 운영 절차가 복잡해집니다. 자동 교체도 지원되지 않습니다."}}}
{"Question_Number": "Q87", "Question_Description": "한 회사는 Amazon API Gateway API에 의해 호출되는 AWS Lambda 함수를 사용하여 애플리케이션을 호스팅하고 있습니다. Lambda 함수는 고객 데이터를 Amazon Aurora MySQL 데이터베이스에 저장합니다. 회사가 데이터베이스를 업그레이드할 때마다 업그레이드가 완료될 때까지 Lambda 함수가 데이터베이스 연결을 수립하지 못하게 되어, 이벤트 중 일부 고객 데이터가 기록되지 않는 문제가 발생합니다. 솔루션 아키텍트는 데이터베이스가 업그레이드되는 동안 생성되는 고객 데이터를 저장할 방안을 설계해야 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["AWS Lambda", "Amazon API Gateway", "Amazon Aurora MySQL", "Database Upgrade", "SQS FIFO Queue", "고객 데이터 보존"], "Terms": ["Amazon RDS Proxy", "Lambda local storage", "Amazon SQS FIFO", "Retry mechanism", "Aurora MySQL 업그레이드", "Amazon RDS", "Lambda 함수"], "Commentary": "이 문제는 데이터베이스 업그레이드 시점에 데이터베이스 연결이 일시적으로 끊겨 고객 데이터가 손실되는 상황을 방지하고자 하는 요구사항을 다룹니다. 업그레이드 중에도 데이터를 안전하게 저장한 뒤, 데이터베이스가 정상화되면 다시 처리할 수 있는 구조가 핵심입니다. 정답은 Amazon SQS FIFO 큐를 통해 데이터가 유실되지 않고 큐에 보관되도록 하여, 이후 새로운 Lambda 함수가 해당 데이터를 데이터베이스에 정상 반영하도록 하는 방식입니다.", "Selections": {"SelectA": {"Select": "Amazon RDS Proxy를 설정하여 Lambda 함수와 데이터베이스 사이에 두고, Lambda 함수가 RDS Proxy로 연결하도록 구성합니다.", "Commentary": "RDS Proxy는 데이터베이스 장애나 재시작 시 연결 풀을 관리해 failover 시간을 단축하지만, 업그레이드 중 데이터베이스가 완전히 오프라인이면 여전히 요청이 실패할 수 있어 업그레이드 동안 생성되는 데이터를 보관하는 데에는 한계가 있습니다."}, "SelectB": {"Select": "Lambda 함수 실행 시간을 최대로 늘리고, 고객 데이터를 데이터베이스에 저장하는 코드에 재시도 메커니즘을 구현합니다.", "Commentary": "재시도 로직만으로는 데이터베이스가 업그레이드로 인해 길게 다운되는 상황에서 요청이 계속 실패할 가능성이 높아, 데이터 손실을 완전히 방지하기 어렵습니다."}, "SelectC": {"Select": "Lambda local storage에 고객 데이터를 저장합니다. 그리고 새 Lambda 함수를 구성하여 local storage에 저장된 데이터를 데이터베이스에 저장하도록 합니다.", "Commentary": "Lambda 함수의 local storage는 영구적이지 않고 함수별 격리 영역이 달라서 업그레이드 기간 동안의 데이터를 안정적으로 보관하기 적합하지 않습니다."}, "SelectD": {"Select": "Amazon Simple Queue Service(Amazon SQS) FIFO 큐에 고객 데이터를 저장합니다. 새로운 Lambda 함수를 생성하여 큐에서 메시지를 폴링하여 데이터베이스에 저장하도록 합니다.", "Commentary": "데이터베이스가 업그레이드 중이더라도 SQS가 데이터를 안전하게 보관하고, 데이터베이스가 정상화되면 큐에서 메시지를 읽어 처리할 수 있어 데이터 손실을 방지하고 서비스의 복원력을 높입니다."}}}
{"Question_Number": "Q88", "Question_Description": "한 설문 회사가 미국 지역에서 여러 해 동안 수집한 데이터를 Amazon S3 버킷에 저장하고 있으며, 현재 크기는 3TB이고 계속 증가하고 있습니다. 이 회사는 유럽에 있는 마케팅 회사와 데이터를 공유하기 시작했으며, 마케팅 회사 또한 S3 버킷을 가지고 있습니다. 회사는 자신의 데이터 전송 비용을 최대한 낮게 유지하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["데이터 전송 비용", "Amazon S3", "Requester Pays", "Cross-Region Replication", "S3 Intelligent-Tiering"], "Terms": ["Requester Pays", "S3 Cross-Region Replication", "Cross-account access", "S3 Intelligent-Tiering", "Amazon S3 버킷"], "Commentary": "이 문제는 기업이 보유한 S3 데이터를 해외 파트너에게 공유할 때 발생하는 데이터 전송 비용을 최소화하기 위한 방법을 묻습니다. Requester Pays를 사용하면 다운로드 비용을 요청 측(마케팅 회사)으로 전가하여, 데이터 제공 회사(미국 회사) 측의 트래픽 비용을 최소화할 수 있습니다. 다른 옵션들은 회사 측에 각종 전송 및 복제 비용이 발생하거나 단순 스토리지 비용 절감에 머물기 때문에, 문제의 요구사항인 '자사의 전송 비용 최소화' 핵심에 부합하지 않습니다.", "Selections": {"SelectA": {"Select": "회사의 S3 버킷에서 Requester Pays 기능을 구성합니다.", "Commentary": "Requester Pays 사용 시, 데이터 요청자(마케팅 회사)가 전송 요금을 부담하여 회사의 전송 비용을 최소화할 수 있습니다."}, "SelectB": {"Select": "회사의 S3 버킷에서 마케팅 회사의 S3 버킷으로 S3 Cross-Region Replication을 구성합니다.", "Commentary": "회사 측이 복제 비용과 전송 비용을 부담하므로, 전송 비용 절감 목표에 부합하지 않습니다."}, "SelectC": {"Select": "Cross-account access를 구성하여 마케팅 회사가 회사의 S3 버킷에 접근하도록 설정합니다.", "Commentary": "접근 권한만 부여할 뿐 전송 비용은 여전히 회사가 부담할 가능성이 크므로 요구사항에 맞지 않습니다."}, "SelectD": {"Select": "회사의 S3 버킷을 S3 Intelligent-Tiering으로 설정하고, 해당 버킷을 마케팅 회사의 S3 버킷과 동기화합니다.", "Commentary": "S3 Intelligent-Tiering은 스토리지 비용을 자동 관리하지만, 전송 비용 절감에는 직접적인 도움이 되지 않습니다."}}}
{"Question_Number": "Q89", "Question_Description": "한 회사가 Amazon S3를 사용하여 기밀 감사 문서를 저장하고 있습니다. 해당 S3 버킷은 감사 팀 IAM 사용자 자격 증명에 대해 최소 권한 원칙에 따라 접근을 제한하기 위해 버킷 정책을 사용합니다. 회사의 관리자들은 S3 버킷에 있는 문서가 실수로 삭제되는 상황을 우려하며, 더 안전한 솔루션을 원하고 있습니다. 문서를 안전하게 보호하기 위해 Solutions Architect가 해야 할 작업은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["기밀 감사 문서", "실수로 삭제", "S3 버킷 보안", "Versioning", "MFA Delete"], "Terms": ["Amazon S3", "IAM", "Versioning", "MFA Delete", "Multi-factor authentication(MFA)", "S3 Lifecycle policy", "s3:DeleteObject", "AWS Key Management Service(AWS KMS)"], "Commentary": "이 문제는 S3에 저장된 감사 문서를 실수로 삭제하지 않도록 안전하게 보호하는 방법을 묻습니다. 단순히 IAM 사용자에게 MFA를 적용하는 것만으로는 실수로 인한 삭제를 막을 수 없습니다. 대신 Versioning을 활성화하고 MFA Delete를 적용하면 버킷에서 객체를 완전히 삭제하기 전 추가적인 MFA 검증이 필요해, 실수 혹은 권한 남용으로 인한 영구 삭제를 예방할 수 있습니다.", "Selections": {"SelectA": {"Select": "S3 버킷에서 Versioning과 MFA Delete 기능을 활성화합니다.", "Commentary": "Versioning과 MFA Delete를 함께 사용하면 객체가 잘못 삭제되더라도 복원이 가능하며, 영구 삭제 전에 추가 MFA 확인이 필요해 보안을 크게 강화합니다."}, "SelectB": {"Select": "각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 Multi-factor authentication(MFA)을 활성화합니다.", "Commentary": "사용자 인증 자체에 MFA를 적용하는 것은 유용하나, 객체 삭제시 별도의 MFA 확인을 거치지 않으므로 실수로 인한 영구 삭제를 근본적으로 방지하지 못합니다."}, "SelectC": {"Select": "감사 팀 IAM 사용자 계정에 대해 S3 Lifecycle 정책을 추가하여 감사 기간 동안 s3:DeleteObject 작업을 거부하도록 설정합니다.", "Commentary": "감사 기간에만 삭제를 막는 정책으로, 기간 외에는 실수 삭제가 여전히 가능하고 다른 운영 상 제약이 발생하므로 최적의 솔루션이 아닙니다."}, "SelectD": {"Select": "AWS Key Management Service(AWS KMS)를 사용해 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 접근하지 못하도록 제한합니다.", "Commentary": "데이터 암호화는 기밀성을 높일 수 있으나, 실수로 삭제되는 자체 문제를 해결하지 못하므로 요구사항에 부합하지 않습니다."}}}
{"Question_Number": "Q90", "Question_Description": "한 회사는 공개적으로 접근 가능한 영화 데이터를 저장하기 위해 SQL database를 사용하고 있습니다. 이 database는 Amazon RDS Single-AZ DB instance에서 실행 중입니다. 매일 불규칙한 간격으로 스크립트가 실행되어 database에 새로 추가된 영화의 개수를 기록합니다. 이 스크립트는 업무 시간 동안 최종 집계 결과를 보고해야 합니다. 회사의 개발팀은 스크립트가 실행되고 있을 때 database 성능이 개발 업무에 충분하지 않다고 판단했습니다. 솔루션스 아키텍트는 이 문제를 해결하는 솔루션을 권장해야 합니다. 가장 낮은 운영 오버헤드로 이 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["SQL database", "Amazon RDS Single-AZ DB instance", "새로 추가된 영화", "개발팀 성능 문제", "read replica"], "Terms": ["Amazon RDS Single-AZ", "Multi-AZ deployment", "Read Replica", "Amazon ElastiCache"], "Commentary": "이 문제는 주기적으로 실행되는 스크립트가 읽기 부하를 유발해 개발팀 업무에 영향을 주는 상황입니다. read replica를 사용하면 최소한의 추가 설정으로 성능 저하 문제를 효과적으로 해결할 수 있습니다.", "Selections": {"SelectA": {"Select": "DB instance를 Multi-AZ로 변경합니다.", "Commentary": "Multi-AZ는 장애 복구나 고가용성에는 좋지만 읽기 부담을 분산시키지 못해 스크립트로 인한 성능 문제는 크게 해소되지 않습니다."}, "SelectB": {"Select": "데이터베이스의 read replica를 생성하고 스크립트가 오직 해당 read replica만 조회하도록 구성합니다.", "Commentary": "스크립트로 인한 읽기 부하를 본 DB에서 분리해 성능 문제를 해결할 수 있으며, 추가 작업이 적어 운영 오버헤드가 낮은 최적의 방법입니다."}, "SelectC": {"Select": "개발팀에 매일 말에 데이터베이스 항목들을 수동으로 export하도록 지시합니다.", "Commentary": "사람이 직접 수행해야 하므로 운영 오버헤드가 높고, 실수 가능성도 있어서 자동화되지 않은 비효율적인 방법입니다."}, "SelectD": {"Select": "Amazon ElastiCache를 사용해 스크립트가 자주 실행하는 쿼리 결과를 캐싱합니다.", "Commentary": "ElastiCache는 반복 조회에 유용하지만, 새로 추가된 영화 수를 매번 조회하는 경우 캐시 이점이 적어 근본적인 해결책이 되기 어렵습니다."}}}
{"Question_Number": "Q91", "Question_Description": "한 회사에서 Amazon EC2 인스턴스가 있는 VPC에서 애플리케이션을 운영하고 있습니다. 그중 하나의 애플리케이션에서는 Amazon S3 API를 호출해 객체를 저장하고 읽어야 합니다. 회사의 보안 규정에 따르면 애플리케이션에서 발생하는 어떠한 트래픽도 인터넷을 통과해서는 안 됩니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["VPC", "Amazon EC2", "Amazon S3", "보안 규정", "인터넷 통신 제한", "S3 Gateway Endpoint"], "Terms": ["S3 Gateway Endpoint", "NAT Gateway", "VPC", "Amazon EC2", "Amazon S3", "Private Subnet"], "Commentary": "이 문제는 VPC 내의 EC2 인스턴스에서 S3로의 통신이 인터넷을 거치지 않도록 하는 보안 액세스 설계가 핵심입니다. NAT Gateway나 Internet Gateway 등 외부 연결을 사용하지 않으려면 S3 Gateway Endpoint를 설정하여 프라이빗 네트워크 환경에서 S3에 직접 연결하도록 구성하는 것이 최선의 방법입니다. 이를 통해 EC2 인스턴스 트래픽이 인터넷으로 노출되지 않고 S3 접근이 가능해집니다.", "Selections": {"SelectA": {"Select": "S3 Gateway Endpoint를 구성합니다.", "Commentary": "S3 Gateway Endpoint를 사용하면 VPC 내에서 인터넷을 통하지 않고 Amazon S3에 안전하게 연결할 수 있습니다. 회사의 보안 규정에도 부합합니다."}, "SelectB": {"Select": "Private Subnet에 S3 버킷을 생성합니다.", "Commentary": "S3는 기본적으로 리전 기반의 글로벌 서비스라 Private Subnet에 직접 버킷을 생성하는 개념이 없습니다. 보안 요구사항도 충족할 수 없습니다."}, "SelectC": {"Select": "EC2 인스턴스와 동일한 AWS Region에 S3 버킷을 생성합니다.", "Commentary": "동일 리전에 버킷을 생성해도 기본적으로 인터넷 경로를 통한 통신이 발생할 수 있어 보안 규정을 만족하지 못합니다."}, "SelectD": {"Select": "EC2 인스턴스와 동일 서브넷에 NAT Gateway를 구성합니다.", "Commentary": "NAT Gateway를 구성하면 인터넷을 통해서 S3와 통신하므로 회사의 ‘인터넷을 거치면 안 된다’는 규정에 어긋납니다."}}}
{"Question_Number": "Q92", "Question_Description": "한 회사가 민감한 사용자 정보를 Amazon S3 버킷에 저장하고 있습니다. 회사는 VPC 내부에서 동작하는 Amazon EC2 인스턴스 애플리케이션 계층에서 이 버킷에 안전하게 액세스하기를 원합니다. 이를 달성하기 위해 솔루션스 아키텍트가 취해야 하는 단계 조합은 어떤 것인가요? (2개를 고르십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["민감한 사용자 정보", "Amazon S3 버킷", "VPC 내부 EC2", "안전한 액세스", "VPC Gateway Endpoint", "Bucket Policy"], "Terms": ["Amazon S3", "Amazon EC2", "VPC", "VPC Gateway Endpoint", "Bucket Policy", "NAT instance", "IAM user", "S3 Access Policy"], "Commentary": "이 문제는 VPC 내부 EC2 인스턴스가 Amazon S3 버킷에 직접적이고 안전하게 접근하도록 설계하는 방법입니다. VPC Gateway Endpoint를 사용하면 내부 망을 통해서만 S3와 통신할 수 있어 외부 노출이 줄어듭니다. 또한 Bucket Policy로 특정 VPC 리소스만 접근 가능하도록 제한해 보안을 강화합니다.", "Selections": {"SelectA": {"Select": "VPC 내부에 Amazon S3용 VPC Gateway Endpoint를 구성합니다.", "Commentary": "VPC Gateway Endpoint를 사용하면 S3 트래픽이 인터넷으로 나가지 않고 내부 경로로만 전송되어 안전성과 성능이 향상됩니다."}, "SelectB": {"Select": "S3 버킷의 객체를 공개로 설정하는 Bucket Policy를 생성합니다.", "Commentary": "버킷을 ‘public’으로 설정하면 민감 데이터가 노출될 위험이 커지므로 안전한 구성에 부적합합니다."}, "SelectC": {"Select": "VPC에서 동작하는 애플리케이션 계층에만 액세스를 제한하는 Bucket Policy를 생성합니다.", "Commentary": "Bucket Policy를 통해 특정 VPC 리소스에서만 접근이 가능하도록 설정하면 민감한 데이터 보호에 효과적입니다."}, "SelectD": {"Select": "IAM 사용자와 S3 액세스 정책을 만들고 이 자격 증명을 EC2 인스턴스에 복사합니다.", "Commentary": "IAM 사용자 자격 증명을 직접 인스턴스에 복사하는 방식은 관리가 어렵고 보안에 취약하므로 모범 사례가 아닙니다."}, "SelectE": {"Select": "NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 통해 S3 버킷에 액세스하도록 합니다.", "Commentary": "NAT 인스턴스 사용은 인터넷 게이트웨이를 통한 통신을 전제로 하므로 민감 데이터에 대한 내부 전송 요구사항에 적합하지 않습니다."}}}
{"Question_Number": "Q93", "Question_Description": "회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 운영하고 있습니다. 애플리케이션의 탄력성(elasticity)과 가용성을 높이기 위해 AWS로 마이그레이션하려고 합니다. 현재 아키텍처는 정상 운영 시 데이터베이스에 대한 무거운 읽기 부하가 있습니다. 또한 4시간마다 운영 환경 데이터베이스를 전체 export하여 스테이징 환경에 구성하고 있는데, 이 과정에서 사용자들은 애플리케이션 지연을 겪으며, 개발팀도 export가 끝날 때까지 스테이징 환경을 사용할 수 없습니다. 솔루션스 아키텍트는 이 애플리케이션 지연 문제를 완화하고, 개발팀이 지연 없이 스테이징 환경을 꾸준히 사용할 수 있도록 하는 대체 아키텍처를 제안해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["온프레미스 MySQL", "높은 읽기 부하", "4시간마다 전체 export", "스테이징 환경", "애플리케이션 지연", "Amazon Aurora MySQL", "Multi-AZ Aurora Replicas", "database cloning"], "Terms": ["Amazon Aurora MySQL", "Multi-AZ Aurora Replicas", "Amazon RDS for MySQL", "read replicas", "mysqldump", "database cloning", "standby instance"], "Commentary": "이 문제는 MySQL 기반 온프레미스 환경에서 AWS로 이전하여, 데이터베이스 부하와 스테이징 환경 동시 사용 이슈를 해결하려는 상황입니다. Amazon Aurora MySQL의 database cloning을 활용해 큰 부하 없이 스테이징 환경을 구성하고, Multi-AZ Aurora Replicas로 가용성과 성능을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Aurora MySQL with Multi-AZ Aurora Replicas를 운영 환경으로 사용합니다. mysqldump 유틸리티를 사용하는 백업/복원 프로세스로 스테이징 데이터베이스를 채웁니다.", "Commentary": "mysqldump 활용 시 운영 DB에 큰 부하가 발생하고, 스테이징 환경 준비에도 시간이 오래 걸려 기존 문제를 해결하기에 충분치 않습니다."}, "SelectB": {"Select": "Amazon Aurora MySQL with Multi-AZ Aurora Replicas를 운영 환경으로 사용합니다. database cloning을 적용하여 필요 시 스테이징 데이터베이스를 온디맨드로 생성합니다.", "Commentary": "Aurora database cloning은 운영 DB를 빠르고 효율적으로 복제해 초기화 시간을 단축하고 부하를 최소화하므로 요구사항을 충족하는 최적의 솔루션입니다."}, "SelectC": {"Select": "Amazon RDS for MySQL Multi-AZ 배포와 read replicas를 운영 환경으로 사용합니다. 스탠바이 인스턴스를 스테이징 데이터베이스로 활용합니다.", "Commentary": "Multi-AZ 스탠바이는 장애 복구용으로 동기화되어 있어 자유로운 스테이징 환경 구성에 제약이 크고, read replica만으로는 완전한 스테이징 구축이 어렵습니다."}, "SelectD": {"Select": "Amazon RDS for MySQL Multi-AZ 배포와 read replicas를 운영 환경으로 사용합니다. mysqldump 유틸리티를 사용하는 백업/복원 프로세스로 스테이징 데이터베이스를 구성합니다.", "Commentary": "mysqldump로 생성·복원 시 운영에 부하가 커 문제 해결에 적합하지 않으며, 스테이징 환경 준비 과정이 지연되므로 요구사항을 만족시키기 어렵습니다."}}}
{"Question_Number": "Q94", "Question_Description": "한 회사에서 사용자가 작은 파일을 Amazon S3에 업로드하는 애플리케이션을 설계하고 있습니다. 사용자가 파일을 업로드하면, 그 파일은 한 번의 간단한 처리를 통해 데이터를 변환하고 이후 분석을 위해 JSON 형식으로 저장되어야 합니다. 파일은 업로드되자마자 가능한 한 빨리 처리되어야 하며, 수요는 날짜에 따라 매우 많이 업로드될 수도 있고 거의 업로드되지 않을 수도 있습니다. 이때 운영 오버헤드를 최소화하면서 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["S3 업로드", "JSON 변환", "단일 처리", "가변적인 수요", "최소 운영 오버헤드"], "Terms": ["Amazon S3", "Amazon EMR", "Amazon Aurora", "Amazon Simple Queue Service (Amazon SQS)", "AWS Lambda", "Amazon EC2", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon Kinesis Data Streams", "Amazon DynamoDB"], "Commentary": "이 문제는 사용자의 가변적인 업로드 빈도에 실시간으로 대응하면서 파일을 신속하게 처리하고, 운영상의 복잡함을 최소화하는 아키텍처를 구현하는 방법을 묻습니다. 서버나 클러스터 관리가 필요 없는 서버리스 기반 이벤트 구독 방식(Amazon S3 이벤트 → Amazon SQS → AWS Lambda)이 운영 오버헤드를 크게 줄이고 자동 확장에 유리합니다. 또한 결과를 NoSQL 기반인 Amazon DynamoDB에 JSON 형식으로 저장하면 구조화 과정이 간편하고 확장성도 뛰어납니다.", "Selections": {"SelectA": {"Select": "Amazon EMR을 구성하여 Amazon S3에서 텍스트 파일을 읽고, 스크립트를 실행해 데이터를 변환한 뒤 Amazon Aurora DB cluster에 JSON 파일을 저장합니다.", "Commentary": "EMR 클러스터 관리와 오케스트레이션이 필요해 운영 오버헤드가 높으며, 간단한 처리를 위해 과도한 솔루션입니다."}, "SelectB": {"Select": "Amazon S3 이벤트 알림을 Amazon SQS 큐로 전송합니다. Amazon EC2 인스턴스가 큐를 읽고 데이터를 처리하여 JSON 파일을 Amazon DynamoDB에 저장합니다.", "Commentary": "EC2 인스턴스 운영 및 스케일링 관리가 필요해 서버리스보다 오버헤드가 큽니다."}, "SelectC": {"Select": "Amazon S3 이벤트 알림을 Amazon SQS 큐로 전송합니다. AWS Lambda 함수가 큐에서 메시지를 읽어 데이터를 처리하고, JSON 파일을 Amazon DynamoDB에 저장합니다.", "Commentary": "서버리스 아키텍처로 자동 확장과 이벤트 기반 처리가 가능하여 운영 오버헤드가 가장 적은 최적 솔루션입니다."}, "SelectD": {"Select": "Amazon EventBridge(Amazon CloudWatch Events)를 구성하여 새 파일이 업로드될 때 Amazon Kinesis Data Streams로 이벤트를 전송합니다. AWS Lambda 함수가 스트림 이벤트를 처리하고, Amazon Aurora DB cluster에 JSON 파일을 저장합니다.", "Commentary": "Kinesis 스트림 설정과 Aurora 관리가 필요해 처리 흐름이 복잡하며, 단순 처리 요구 사항에 비해 과도한 구성입니다."}}}
{"Question_Number": "Q95", "Question_Description": "한 회사의 본사 사용자들이 제품 데이터에 액세스할 수 있는 애플리케이션이 있습니다. 이 제품 데이터는 Amazon RDS MySQL DB instance에 저장되어 있습니다. 운영 팀은 애플리케이션 성능 저하 문제를 찾아내었고, 읽기 트래픽과 쓰기 트래픽을 분리하고자 합니다. 솔루션스 아키텍트는 애플리케이션 성능을 빠르게 최적화해야 합니다. 어떤 조치를 권장해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon RDS MySQL", "애플리케이션 성능", "읽기 트래픽", "쓰기 트래픽", "Read Replica", "Multi-AZ"], "Terms": ["Amazon RDS MySQL", "DB instance", "Multi-AZ", "Read Replica", "Primary Availability Zone", "Secondary Availability Zone"], "Commentary": "이 문제는 Amazon RDS 환경에서읽기 트래픽을 효율적으로 분산해 애플리케이션 성능을 빠르게 높이는 방법을 묻습니다. Multi-AZ는 고가용성 목적이므로, Read Replica를 동일 리소스로 구성해 읽기 요청을 분산해야 합니다.", "Selections": {"SelectA": {"Select": "기존 데이터베이스를 Multi-AZ 배포로 변경합니다. 읽기 요청은 기본 가용 영역에서 처리합니다.", "Commentary": "Multi-AZ는 주로 장애 대비용이며, 기본 가용 영역에서 읽기를 처리하면 여전히 트래픽 부담이 높아집니다."}, "SelectB": {"Select": "기존 데이터베이스를 Multi-AZ 배포로 변경합니다. 읽기 요청은 보조 가용 영역에서 처리합니다.", "Commentary": "Multi-AZ 보조 노드는 장애 발생 시에만 활성화되므로, 일반 상황에서 읽기 요청 처리에 적합하지 않습니다."}, "SelectC": {"Select": "데이터베이스에 대해 Read Replica를 생성합니다. Read Replica에는 원본 DB의 절반 크기의 컴퓨트와 스토리지 리소스를 구성합니다.", "Commentary": "읽기 부하 분산은 가능하지만, 리소스가 부족하면 대규모 동시 읽기 요청 처리에 한계가 있습니다."}, "SelectD": {"Select": "데이터베이스에 대해 Read Replica를 생성합니다. Read Replica에 원본 DB와 동일한 컴퓨트와 스토리지 리소스를 구성합니다.", "Commentary": "Read Replica를 충분한 리소스로 구성해 읽기 트래픽을 안정적으로 분산함으로써, 빠르게 성능을 개선할 수 있습니다."}}}
{"Question_Number": "Q96", "Question_Description": "한 Amazon EC2 관리자가 여러 사용자가 포함된 IAM 그룹에 다음 정책을 연결했습니다. 이 정책에는 특정 리전과 소스 IP 조건이 설정되어 있습니다. 이 정책의 효과는 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["us-east-1 리전", "EC2 인스턴스 종료", "소스 IP 주소", "IAM 정책"], "Terms": ["Amazon EC2", "IAM 그룹", "Policy", "소스 IP", "us-east-1 Region", "TerminateInstance"], "Commentary": "이 문제는 IAM Policy의 조건(Context Keys) 설정을 통해 EC2 인스턴스 종료 권한을 제한하는 방법을 묻습니다. 정책에서는 us-east-1 리전 내에서, 소스 IP가 10.100.100.254인 경우에만 EC2 인스턴스 종료를 허용하고 다른 리전에서는 종료를 허용하지 않습니다. 따라서 이 정책의 실제 효과를 바르게 파악해야 합니다.", "Selections": {"SelectA": {"Select": "사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다.", "Commentary": "정책 해석과 반대되는 설명입니다. 정책은 오직 us-east-1 리전에서만 종료를 허용합니다."}, "SelectB": {"Select": "사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1인 EC2 인스턴스를 종료할 수 있습니다.", "Commentary": "정책에서 요구하는 소스 IP는 10.100.100.254이며, 10.100.100.1은 조건에 부합하지 않습니다."}, "SelectC": {"Select": "사용자의 소스 IP가 10.100.100.254일 때, us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다.", "Commentary": "정책에서 us-east-1 리전과 소스 IP가 10.100.100.254인 경우에만 종료를 허용하므로, 이 설명이 정확한 정책의 효과입니다."}, "SelectD": {"Select": "사용자의 소스 IP가 10.100.100.254일 때, us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다.", "Commentary": "정책은 소스 IP가 10.100.100.254이고 리전이 us-east-1일 경우에 종료를 허용하므로, 이 설명은 틀립니다."}}}
{"Question_Number": "Q97", "Question_Description": "한 회사는 온프레미스에서 대규모 Microsoft SharePoint를 운영 중이며, Microsoft Windows 공유 파일 스토리지가 필요합니다. 이 워크로드를 AWS Cloud로 마이그레이션하려고 하며, 여러 스토리지 옵션을 검토 중입니다. 스토리지 솔루션은 고가용성을 갖추고, 액세스 제어를 위해 Active Directory와 통합되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Microsoft SharePoint", "Microsoft Windows 공유 파일 스토리지", "Active Directory", "고가용성", "Amazon FSx for Windows File Server"], "Terms": ["Amazon EFS", "AWS Storage Gateway", "SMB", "Amazon S3", "Amazon FSx for Windows File Server", "Active Directory", "고가용성"], "Commentary": "이 문제는 Windows 기반 워크로드(SharePoint)를 AWS로 마이그레이션하면서, 고가용성이 보장되고 Active Directory를 통한 인증이 필요한 공유 파일 스토리지를 설계하는 방법을 묻습니다. 네이티브 Windows 파일 시스템 통합과 SMB 프로토콜, AD 연동이 필수적이므로, Amazon FSx for Windows File Server가 가장 적합합니다.", "Selections": {"SelectA": {"Select": "Amazon EFS 스토리지를 구성하고 Active Directory 도메인을 인증용으로 설정합니다.", "Commentary": "Amazon EFS는 Linux 기반 NFS 프로토콜을 주로 사용하므로 Windows 환경 및 SMB 기반 공유에는 최적화되어 있지 않습니다."}, "SelectB": {"Select": "두 개의 가용 영역(AZ)에 AWS Storage Gateway 파일 게이트웨이로 SMB 파일 공유를 생성합니다.", "Commentary": "파일 게이트웨이는 온프레미스와의 하이브리드 환경에 유용하지만, 완전한 AD 통합 및 고가용성 측면에서 FSx보다 부족합니다."}, "SelectC": {"Select": "Amazon S3 버킷을 생성하고 Microsoft Windows Server에서 이를 볼륨으로 마운트하도록 구성합니다.", "Commentary": "Windows 서버에서 S3 버킷을 직접 파일 공유로 쓰기는 제한적이며, 대비해 SMB 및 AD 통합 지원이 부족합니다."}, "SelectD": {"Select": "AWS에서 Amazon FSx for Windows File Server 파일 시스템을 생성하고, 인증용으로 Active Directory 도메인을 설정합니다.", "Commentary": "SMB 프로토콜과 AD 통합을 기본 제공하며, 고가용성을 확보하기 위해 여러 AZ에 데이터를 복제하므로 요구사항을 모두 충족합니다."}}}
{"Question_Number": "Q98", "Question_Description": "한 이미지 처리 회사에서는 사용자가 이미지를 업로드할 수 있는 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon S3 버킷에 이미지를 업로드합니다. 회사는 Amazon Simple Queue Service(Amazon SQS) 스탠다드 큐로 객체 생성 이벤트를 게시하기 위해 S3 event notifications을 설정했습니다. 이 SQS 큐는 이미지를 처리하고 처리 결과를 이메일로 사용자에게 전송하는 AWS Lambda 함수의 이벤트 소스로 동작합니다.\n\n사용자들은 업로드된 각 이미지마다 여러 개의 이메일이 도착하고 있다고 보고했습니다. 솔루션스 아키텍트는 SQS 메시지가 Lambda 함수를 여러 번 호출하여 중복 이메일이 발생한다는 사실을 확인했습니다.\n\n가장 적은 운영 오버헤드로 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["중복 메시지", "Lambda 함수", "visibility timeout", "이메일 중복", "운영 오버헤드 최소화"], "Terms": ["Amazon S3", "S3 event notifications", "Amazon Simple Queue Service (Amazon SQS)", "SQS standard queue", "AWS Lambda", "visibility timeout", "SQS FIFO queue", "long polling", "function timeout", "batch window timeout", "message deduplication ID"], "Commentary": "이 문제는 SQS 메시지가 Lambda 함수의 처리 시간보다 일찍 다시 큐로 돌아와 중복 처리가 발생하는 상황을 해결하는 방법을 묻습니다. Lambda가 메시지를 정상적으로 처리할 수 있도록 visibility timeout을 충분히 늘리면, 메시지가 재전송되지 않아 중복 메일이 방지됩니다. 이는 운영적인 부담이 적고 가장 직접적인 해결책입니다.", "Selections": {"SelectA": {"Select": "SQS 큐에 long polling을 설정하기 위해 ReceiveMessage 대기 시간을 30초로 늘립니다.", "Commentary": "long polling은 메시지 수신 빈도를 줄일 뿐, Lambda 처리 시간 초과로 인한 중복 메시지 문제는 근본적으로 해결하지 못합니다."}, "SelectB": {"Select": "SQS 스탠다드 큐를 SQS FIFO 큐로 변경합니다. 메시지 deduplication ID를 사용해 중복 메시지를 제거합니다.", "Commentary": "FIFO 큐로 바꾸면 메시지 순서 및 Deduplication 기능이 있지만, 애플리케이션 구조를 변경해야 하고 스루풋 제한도 있어 운영 오버헤드가 증가할 수 있습니다."}, "SelectC": {"Select": "Lambda 함수 타임아웃 및 배치 윈도우 타임아웃의 합보다 큰 값을 SQS 큐의 visibility timeout으로 설정합니다.", "Commentary": "Lambda가 메시지를 완전히 처리하기 전에 메시지가 다시 큐로 돌아오지 않도록 visibility timeout을 충분히 늘려 한 번만 처리되게 하는 최적의 솔루션입니다."}, "SelectD": {"Select": "Lambda 함수가 메시지를 읽자마자 메시지를 처리하기 전에 SQS 큐에서 메시지를 삭제하도록 수정합니다.", "Commentary": "처리 전에 메시지를 삭제하면 Lambda 함수 오류 발생 시 메시지를 잃을 위험이 큽니다. 신뢰성을 저해하는 좋지 않은 방식입니다."}}}
{"Question_Number": "Q99", "Question_Description": "한 회사가 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 구현하려고 합니다. 이 회사는 Lustre 클라이언트를 사용하여 데이터를 액세스할 수 있는 기능이 필요하며, 이 솔루션은 완전관리형(Fully Managed)이어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["공유 스토리지", "완전관리형", "Lustre 클라이언트", "온프레미스 데이터 센터", "게임 애플리케이션"], "Terms": ["Amazon FSx for Lustre", "Amazon EFS", "AWS Storage Gateway", "Windows file share role", "Lustre", "Shared Storage"], "Commentary": "이 문제는 Lustre 클라이언트를 활용해야 하며 완전관리형 서비스가 필수적입니다. FSx for Lustre는 HPC 환경에서 자주 사용되는 Lustre 파일 시스템을 완전관리형으로 제공하므로 정답입니다.", "Selections": {"SelectA": {"Select": "AWS Storage Gateway file gateway를 생성하고 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 생성한 후, 해당 애플리케이션 서버를 연결합니다.", "Commentary": "AWS Storage Gateway는 Lustre 클라이언트를 직접 지원하지 않으므로 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "Amazon EC2 Windows 인스턴스를 생성하고 Windows file share role을 설치·구성합니다. 애플리케이션 서버를 해당 파일 공유에 연결합니다.", "Commentary": "Windows 기반 파일 공유는 Lustre 프로토콜을 지원하지 않아 요구사항에 부합하지 않습니다."}, "SelectC": {"Select": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하여 Lustre 지원으로 구성한 뒤 원본 서버와 연결하고, 애플리케이션 서버를 파일 시스템에 연결합니다.", "Commentary": "Amazon EFS는 Lustre 프로토콜을 기본적으로 지원하지 않아 요구사항을 충족하기 어렵습니다."}, "SelectD": {"Select": "Amazon FSx for Lustre 파일 시스템을 생성하고 이를 원본 서버에 연결합니다. 애플리케이션 서버를 해당 파일 시스템에 연결합니다.", "Commentary": "Amazon FSx for Lustre는 Lustre를 완전관리형으로 제공하며 고성능 공유 스토리지를 구현하기에 적합한 정답입니다."}}}
{"Question_Number": "Q100", "Question_Description": "한 회사의 컨테이너화된 애플리케이션이 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 다른 비즈니스 애플리케이션과 통신하기 전에 보안 인증서를 다운로드해야 합니다. 회사는 보안 인증서를 실시간에 가깝게 암호화 및 복호화할 수 있는 고도로 안전한 솔루션을 원합니다. 또한 암호화된 후의 데이터를 고가용성 스토리지에 저장해야 하며, 운용상 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 가장 적은 운영 복잡도로 충족할 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["컨테이너화된 애플리케이션", "보안 인증서", "암호화", "복호화", "고가용성 스토리지", "운영 오버헤드"], "Terms": ["AWS Secrets Manager", "IAM", "AWS Lambda", "AWS Key Management Service (AWS KMS)", "Customer Managed Key", "Amazon EC2", "Amazon S3", "Amazon EBS"], "Commentary": "이 문제는 EC2 상에서 실행되는 컨테이너화된 애플리케이션이 보안 인증서를 안전하고 빠르게 다루는 방법을 묻습니다. 실시간에 가까운 암호화·복호화가 필요하며, 암호화된 데이터를 고가용성 스토리지에 저장해야 합니다. 가장 효율적이고 운영 부담이 적은 방식은 AWS KMS를 사용하여 데이터를 암호화하고, Amazon S3와 결합해 보관하는 것입니다.", "Selections": {"SelectA": {"Select": "AWS Secrets Manager에 보안 인증서를 암호화된 형태로 저장하고, 필요할 때 수동으로 인증서를 업데이트합니다. 세분화된 IAM 액세스를 사용하여 데이터에 대한 접근을 제어합니다.", "Commentary": "Secrets Manager를 통해 인증서 관리를 할 수 있으나, 실시간에 가까운 암호화·복호화가 큰 규모로 요구될 때는 수동 업데이트가 오버헤드를 증가시키고 실시간 처리에 제약이 있을 수 있습니다."}, "SelectB": {"Select": "Python cryptography 라이브러리를 사용하는 AWS Lambda 함수를 생성하여 암호화 작업을 수행합니다. 해당 함수를 Amazon S3 버킷에 저장합니다.", "Commentary": "직접 암호화 라이브러리를 관리하고 Lambda의 배포·버전을 관리해야 하므로 운영 복잡도가 상대적으로 높아집니다. 완전관리형 KMS보다 실시간 처리나 보안 관리 면에서 비효율적일 수 있습니다."}, "SelectC": {"Select": "AWS KMS Customer Managed Key를 생성하고, EC2 역할이 이 KMS 키를 암호화 작업에 사용할 수 있도록 허용합니다. 암호화된 데이터를 Amazon S3에 저장합니다.", "Commentary": "KMS를 통해 안전하고 실시간에 가까운 암호화·복호화를 수행하고, Amazon S3에 저장함으로써 고가용성과 낮은 운영 부담을 동시에 달성할 수 있으므로 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "AWS KMS Customer Managed Key를 생성하고, EC2 역할이 이 KMS 키를 암호화 작업에 사용할 수 있도록 허용합니다. 암호화된 데이터를 Amazon EBS 볼륨에 저장합니다.", "Commentary": "Amazon EBS는 인스턴스 기반 스토리지로, Amazon S3 대비 고가용성이 낮으며 추가적인 백업 및 확장 구성이 필요해 운영 오버헤드가 더 큽니다."}}}
{"Question_Number": "Q101", "Question_Description": "한 솔루션스 아키텍트가 IPv4 CIDR 블록을 사용하는 VPC를 설계하고 있으며, 공용 서브넷과 사설 서브넷을 구성하려고 합니다. 고가용성을 위해 3개의 AZ 각각에 공용 서브넷 1개, 사설 서브넷 1개씩 배치합니다. 공용 서브넷에는 인터넷 게이트웨이를 사용하여 인터넷 접속을 제공합니다. 사설 서브넷은 Amazon EC2 인스턴스에서 소프트웨어 업데이트를 다운로드하기 위해 인터넷에 접근해야 합니다. 사설 서브넷에서 인터넷에 접속하기 위해서는 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["사설 서브넷 인터넷 액세스", "공용 서브넷", "NAT Gateway", "고가용성"], "Terms": ["NAT Gateway", "NAT Instance", "Egress-Only Internet Gateway", "인터넷 게이트웨이(IGW)", "공용 서브넷", "사설 서브넷", "VPC", "Route Table"], "Commentary": "이 문제는 사설 서브넷에서 패치나 업데이트를 위해 외부 인터넷에 접근해야 하는 구조를 어떻게 고가용성으로 구성할지 묻습니다. 가장 모범 사례는 각 AZ의 공용 서브넷에 NAT Gateway를 생성하고, 각 사설 서브넷의 라우팅을 해당 NAT Gateway로 보내는 것입니다. NAT Instance 대신 NAT Gateway를 권장하며, NAT Gateway는 반드시 공용 서브넷에 생성해야 합니다.", "Selections": {"SelectA": {"Select": "각 AZ 내 공용 서브넷에 NAT Gateway를 하나씩 생성하고, 각 AZ에 대한 사설 라우트 테이블을 생성하여 VPC 외부 트래픽을 해당 AZ의 NAT Gateway로 포워딩합니다.", "Commentary": "NAT Gateway는 공용 서브넷에 위치해야 하며, 사설 라우트 테이블에서 0.0.0.0/0을 NAT Gateway로 라우팅함으로써 사설 서브넷 인스턴스가 인터넷 통신을 안전하고 간단하게 수행할 수 있습니다."}, "SelectB": {"Select": "각 AZ 내 사설 서브넷에 NAT Instance를 하나씩 생성하고, 각 AZ에 대한 사설 라우트 테이블을 생성하여 VPC 외부 트래픽을 해당 AZ의 NAT Instance로 포워딩합니다.", "Commentary": "NAT Instance는 공용 서브넷에 있어야 인터넷 게이트웨이를 통해 외부와 통신할 수 있습니다. 사설 서브넷에 직접 배치하면 인터넷 접근이 불가능하므로 올바르지 않습니다."}, "SelectC": {"Select": "사설 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성하고, 사설 서브넷의 라우트 테이블을 변경하여 VPC 외부 트래픽을 새 인터넷 게이트웨이로 포워딩합니다.", "Commentary": "인터넷 게이트웨이는 VPC 단위로만 연결되며 서브넷마다 별도로 설치할 수 없습니다. 게다가 한 VPC에는 한 개의 인터넷 게이트웨이만 연결 가능합니다."}, "SelectD": {"Select": "공용 서브넷 중 하나에 Egress-Only Internet Gateway를 생성하고, 사설 서브넷의 라우트 테이블을 변경하여 VPC 외부 트래픽을 Egress-Only Internet Gateway로 포워딩합니다.", "Commentary": "Egress-Only Internet Gateway는 IPv6 전용 트래픽에 사용되므로, IPv4 기반 사설 서브넷의 인터넷 다운로드 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q102", "Question_Description": "한 회사가 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 해당 데이터 센터에는 SFTP 서버가 있으며, 이 서버는 NFS 기반 파일 시스템에 데이터를 저장하고 있습니다. 현재 서버에는 전송해야 할 데이터가 200GB 있습니다. 이 서버는 Amazon EFS 파일 시스템을 사용하는 Amazon EC2 인스턴스에서 호스팅되어야 합니다. 이 작업을 자동화하기 위해 솔루션스 아키텍트는 어떤 단계 조합을 수행해야 합니까? (2개를 선택하십시오.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["온프레미스 데이터 센터 마이그레이션", "SFTP 서버", "NFS 기반 파일 시스템", "Amazon EC2 인스턴스", "Amazon EFS", "AWS DataSync"], "Terms": ["SFTP server", "NFS-based file system", "Amazon EC2", "Amazon EFS", "AWS DataSync", "DataSync agent", "Amazon EBS"], "Commentary": "이 문제는 온프레미스 SFTP 서버의 데이터를 Amazon EFS로 자동 전송하는 방안을 묻습니다. AWS DataSync agent를 온프레미스에 설치한 뒤, SFTP 서버 위치를 DataSync로 설정해 자동화 전송을 구현하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "EC2 인스턴스를 EFS 파일 시스템과 동일한 Availability Zone에 Launch합니다.", "Commentary": "EFS는 여러 AZ에 걸쳐 사용할 수 있어 같은 AZ에 EC2를 배치할 필요가 없으며, 자동화 전송과 직접적인 연관성이 적습니다."}, "SelectB": {"Select": "온프레미스 데이터 센터에 AWS DataSync agent를 설치합니다.", "Commentary": "자동화된 데이터 전송을 위해서는 온프레미스측에 DataSync agent가 필요하며, 이를 통해 대량 데이터를 안전하게 AWS로 이동할 수 있습니다."}, "SelectC": {"Select": "EC2 인스턴스에 데이터를 저장할 보조 Amazon EBS 볼륨을 생성합니다.", "Commentary": "Amazon EFS를 이미 사용할 예정이므로, 추가적인 EBS 볼륨은 필요 없으며 자동화 전송과도 직접 연관이 없습니다."}, "SelectD": {"Select": "수동으로 운영체제 copy 명령어를 사용해 데이터를 EC2 인스턴스로 전송합니다.", "Commentary": "수동 복사는 자동화되지 않고, 대규모 데이터 이전에 비효율적이므로 문제 요구사항에 부합하지 않습니다."}, "SelectE": {"Select": "AWS DataSync를 사용해 온프레미스 SFTP 서버에 대한 적절한 location 구성을 생성합니다.", "Commentary": "SFTP 서버에서 EFS로 자동으로 데이터를 이동하려면 DataSync location 구성이 필수이므로, 이는 자동화 전송을 위한 핵심 단계입니다."}}}
{"Question_Number": "Q103", "Question_Description": "한 회사가 매일 같은 시간에 실행되는 AWS Glue ETL 작업을 보유하고 있습니다. 이 작업은 Amazon S3 버킷에 저장된 XML 데이터를 처리합니다. 매일 새 데이터가 S3 버킷에 추가되지만, 솔루션스 아키텍트는 AWS Glue가 매번 모든 데이터를 다시 처리하고 있음을 발견했습니다. 이전에 처리된 데이터를 재처리하지 않도록 하려면 어떻게 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["AWS Glue", "ETL 작업", "XML 데이터", "S3 버킷", "재처리 방지", "job bookmark"], "Terms": ["AWS Glue", "Amazon S3", "ETL", "Job Bookmark", "FindMatches", "NumberOfWorkers", "XML Data"], "Commentary": "AWS Glue Job Bookmark 기능을 사용하면 이전 실행에서 처리한 데이터를 기록해 반복 처리를 방지할 수 있습니다. 이를 적용하면 매일 추가되는 새로운 데이터만 효율적으로 처리할 수 있어 불필요한 리소스 사용과 시간을 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Edit the job to use job bookmarks.", "Commentary": "Job Bookmark을 사용하면 이전에 처리된 데이터를 건너뛰고 새로 추가된 데이터만 처리할 수 있어 효율적입니다."}, "SelectB": {"Select": "Edit the job to delete data after the data is processed.", "Commentary": "데이터 삭제는 재처리를 방지할 수 있지만, 보관 및 분석 목적으로 기존 데이터가 필요할 수 있어 권장되지 않습니다."}, "SelectC": {"Select": "Edit the job by setting the NumberOfWorkers field to 1.", "Commentary": "작업자 수를 변경해도 이전 데이터 재처리를 막지는 못합니다. 성능 조정과 관련됩니다."}, "SelectD": {"Select": "Use a FindMatches machine learning (ML) transform.", "Commentary": "FindMatches는 유사 레코드를 식별하는 용도로, 이전 데이터 재처리 방지와는 직접적으로 관련이 없습니다."}}}
{"Question_Number": "Q104", "Question_Description": "한 솔루션스 아키텍트가 웹사이트의 고가용성 인프라를 설계해야 합니다. 이 웹사이트는 Amazon EC2 인스턴스에서 동작하는 Windows 웹 서버에 의해 제공됩니다. 솔루션스 아키텍트는 수천 개의 IP 주소에서 발생하는 대규모 DDoS 공격을 완화할 수 있는 솔루션을 구현해야 합니다. 웹사이트에 다운타임이 발생하면 안 됩니다. 이러한 공격으로부터 웹사이트를 보호하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["고가용성 웹사이트", "대규모 DDoS 공격", "AWS Shield Advanced", "Amazon CloudFront", "Downtime 방지"], "Terms": ["AWS Shield Advanced", "Amazon GuardDuty", "Amazon CloudFront", "AWS Lambda", "VPC Network ACL", "EC2 Spot Instances", "Auto Scaling", "Target Tracking Scaling Policy"], "Commentary": "이 문제는 대규모 DDoS 공격으로부터 웹사이트를 보호해야 하며, 다운타임이 허용되지 않는 상황을 다룹니다. AWS Shield Advanced는 L3/L4를 포함한 다양한 계층에서의 보호를 제공하며, Amazon CloudFront는 트래픽을 분산시켜 공격 규모를 줄입니다. 보안 관점에서 효율적인 방어와 동시에 고가용성을 유지하려면 이 두 가지를 함께 활용하는 전략이 최적입니다.", "Selections": {"SelectA": {"Select": "AWS Shield Advanced를 사용하여 DDoS 공격을 중단합니다.", "Commentary": "AWS Shield Advanced는 대규모 DDoS 공격 방어에 최적화된 서비스이며, 고급 모니터링과 자동 완화 기능을 제공합니다. 다운타임 방지에 매우 효과적입니다."}, "SelectB": {"Select": "Amazon GuardDuty를 구성하여 공격자를 자동으로 차단합니다.", "Commentary": "Amazon GuardDuty는 위협 탐지 서비스로, 공격 발생 사실을 알려주지만 직접적으로 DDoS 트래픽을 차단하지는 않습니다. 완전한 방어책에 적합하지 않습니다."}, "SelectC": {"Select": "웹사이트를 정적 및 동적 콘텐츠 모두 Amazon CloudFront를 통해 제공하도록 구성합니다.", "Commentary": "Amazon CloudFront는 엣지 로케이션을 통해 전 세계 트래픽을 분산시켜 공격을 완화하고, 지연 시간을 줄여 고가용성을 유지하는 데 도움이 됩니다."}, "SelectD": {"Select": "AWS Lambda 함수를 사용하여 공격자 IP 주소를 자동으로 VPC Network ACL에 추가합니다.", "Commentary": "일시적으로는 도움이 되지만 공격 IP가 수천 개에 달할 수 있어 관리 복잡성이 증가합니다. 대규모 공격에 즉각적으로 대응하기엔 한계가 있습니다."}, "SelectE": {"Select": "EC2 Spot Instances를 Auto Scaling group에서 CPU 사용률 80%로 목표 추적 확장 정책과 함께 사용합니다.", "Commentary": "확장 정책은 트래픽 급증 시 임시적으로 대응할 수는 있지만, 근본적인 DDoS 방어책이 아니며 Spot 특성상 인스턴스가 회수될 위험도 있습니다."}}}
{"Question_Number": "Q105", "Question_Description": "한 회사가 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. Solutions Architect는 AWS Lambda function을 실행할 최소 권한 원칙(Principle of Least Privilege)을 준수하도록 권한을 설정해야 합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙이 이 함수를 호출합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["AWS Lambda", "EventBridge", "최소 권한 원칙", "Resource-based policy"], "Terms": ["AWS Lambda", "Amazon EventBridge (Amazon CloudWatch Events)", "lambda:InvokeFunction", "Service: events.amazonaws.com", "Resource-based policy", "Execution role", "Least Privilege"], "Commentary": "이 문제는 EventBridge가 AWS Lambda 함수를 호출할 때 필요한 권한 설정을 최소 권한 원칙에 맞춰 구성하는 방법을 묻습니다. EventBridge가 함수를 직접 호출하려면 함수에 Resource-based policy를 부여하여 events.amazonaws.com에 lambda:InvokeFunction 액션만 허용하면 됩니다. 이는 Role보다 직접적인 방식으로 외부 서비스가 함수를 호출할 수 있도록 허용하며, 필요 이상으로 광범위한 권한을 부여하지 않습니다.", "Selections": {"SelectA": {"Select": "함수에 실행 역할을 추가하고, 작업을 lambda:InvokeFunction, Principal을 * 로 설정합니다.", "Commentary": "Principal 값이 * 로 설정되면 누구나 함수 호출이 가능해져 최소 권한 원칙을 위배하므로 적절하지 않습니다."}, "SelectB": {"Select": "함수에 실행 역할을 추가하고, 작업을 lambda:InvokeFunction, Principal을 Service: lambda.amazonaws.com 로 설정합니다.", "Commentary": "lambda.amazonaws.com은 Lambda 자체 서비스에 대한 Principal입니다. EventBridge가 함수를 호출하려면 events.amazonaws.com에 대한 권한이 필요합니다."}, "SelectC": {"Select": "함수에 Resource-based policy를 추가하고, 작업을 lambda:* 로, Principal을 Service: events.amazonaws.com 로 설정합니다.", "Commentary": "lambda:* 는 InvokeFunction 이상의 권한을 포함할 수 있어 최소 권한 원칙에 맞지 않습니다."}, "SelectD": {"Select": "함수에 Resource-based policy를 추가하고, 작업을 lambda:InvokeFunction, Principal을 Service: events.amazonaws.com 로 설정합니다.", "Commentary": "EventBridge 이벤트가 함수를 호출하기 위해 필요한 정확한 액션(lambda:InvokeFunction)과 Principal(events.amazonaws.com)만 허용하므로 최소 권한 원칙을 준수합니다."}}}
{"Question_Number": "Q106", "Question_Description": "한 회사가 기밀 데이터를 Amazon S3에 저장하려고 합니다. 컴플라이언스 요건상 데이터는 저장 시점에서 암호화되어야 하며, 암호화 키 사용 내역이 감사 목적으로 로깅되어야 합니다. 또한 키는 매년 교체(회전)되어야 합니다. 이 요구 사항을 충족하며 운영 효율성이 가장 높은 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon S3", "기밀 데이터", "암호화", "키 사용 로깅", "연간 키 회전", "SSE-KMS", "자동 키 교체"], "Terms": ["Server-side encryption", "SSE-C", "SSE-S3", "SSE-KMS", "AWS KMS", "Key Rotation", "자동 키 회전", "Manual Rotation"], "Commentary": "이 문제는 S3에 저장되는 기밀 정보를 암호화하고, 키 사용 이력을 로깅하며, 매년 키를 교체해야 하는 요구 사항을 만족해야 합니다. SSE-KMS 자동 키 회전은 로깅과 연간 회전을 자동화해 운영 부담을 최소화합니다.", "Selections": {"SelectA": {"Select": "Server-side encryption with customer-provided keys (SSE-C)", "Commentary": "고객이 직접 키를 관리해야 하며, 연간 회전과 로깅도 직접 처리해야 합니다. 운영 효율성이 떨어집니다."}, "SelectB": {"Select": "Server-side encryption with Amazon S3 managed keys (SSE-S3)", "Commentary": "S3가 자체 관리하는 키지만, 키 사용 로깅과 연간 키 교체 제어가 제한적이라 감사 요건 충족이 어렵습니다."}, "SelectC": {"Select": "Server-side encryption with AWS KMS keys (SSE-KMS) with manual rotation", "Commentary": "AWS KMS로 키 사용을 로깅할 수 있지만, 키 회전을 사람이 직접 수행해야 하므로 운영 비용이 증가합니다."}, "SelectD": {"Select": "Server-side encryption with AWS KMS keys (SSE-KMS) with automatic rotation", "Commentary": "키 사용 로깅이 자동으로 제공되고, 연간 키 회전도 자동화되어 운영 복잡도를 최소화하는 최적의 솔루션입니다."}}}
{"Question_Number": "Q107", "Question_Description": "한 자전거 공유 회사가 피크 시간대에 자전거 위치를 추적하기 위한 멀티 계층 아키텍처를 개발하고 있습니다. 회사는 이 위치 데이터 포인트를 기존 애널리틱스 플랫폼에서 활용하려고 합니다. 솔루션스 아키텍트는 이 아키텍처를 지원하기 위한 가장 적합한 멀티 계층 방안을 결정해야 합니다. 위치 데이터 포인트는 REST API를 통해 액세스 가능해야 합니다. 이러한 요구사항을 충족하기 위해 위치 데이터를 저장하고 조회하기 위한 방법은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["자전거 위치 추적", "멀티 계층 아키텍처", "피크 시간대", "기존 애널리틱스 플랫폼", "REST API", "위치 데이터"], "Terms": ["Amazon Athena", "Amazon S3", "Amazon API Gateway", "AWS Lambda", "Amazon QuickSight", "Amazon Redshift", "Amazon Kinesis Data Analytics", "REST API"], "Commentary": "이 문제는 REST API를 통해 빠르게 위치 데이터를 수집하고, 기존 분석 플랫폼에서 활용하기 위한 멀티 계층 아키텍처를 구성하는 방법을 묻습니다. 빠른 호출과 간단한 연동이 가능한 Amazon API Gateway와 AWS Lambda를 사용하는 것이 핵심 포인트입니다.", "Selections": {"SelectA": {"Select": "Amazon Athena와 Amazon S3를 사용합니다.", "Commentary": "단순 스토리지와 쿼리 서비스로 REST API 접근을 제공하기 어렵습니다. 저장은 가능하나 실시간 처리나 API 호출과의 연계가 부족합니다."}, "SelectB": {"Select": "Amazon API Gateway와 AWS Lambda를 사용합니다.", "Commentary": "REST API 엔드포인트와 Lambda 함수를 통해 실시간으로 위치 데이터를 수집하고 빠르게 분석 플랫폼으로 전달할 수 있는 가장 적합한 솔루션입니다."}, "SelectC": {"Select": "Amazon QuickSight와 Amazon Redshift를 사용합니다.", "Commentary": "분석 및 시각화 용도로 적합하지만, 실시간 REST API 접근성을 위한 멀티 계층 아키텍처로 사용하기에는 제한적입니다."}, "SelectD": {"Select": "Amazon API Gateway와 Amazon Kinesis Data Analytics를 사용합니다.", "Commentary": "Kinesis Data Analytics는 스트리밍 데이터 분석을 위한 서비스이지만, 기존 플랫폼에 데이터를 즉시 연결하는 데는 과도하며 필요 이상으로 복잡합니다."}}}
{"Question_Number": "Q108", "Question_Description": "한 회사가 자동차 판매 웹사이트를 운영하며, Amazon RDS에 데이터베이스를 두고 자동차 매물 정보를 저장하고 있습니다. 어떤 자동차가 판매되면 이 매물은 웹사이트에서 제거되어야 하며, 해당 데이터는 여러 대상 시스템으로 전송되어야 합니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 어떤 설계를 추천해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["자동차 판매 웹사이트", "매물 삭제", "다중 대상 시스템 전송", "데이터베이스 업데이트", "Amazon RDS"], "Terms": ["Amazon RDS", "AWS Lambda", "Amazon Simple Queue Service (Amazon SQS)", "Amazon Simple Notification Service (Amazon SNS)", "RDS event notification", "FIFO queue", "fanout"], "Commentary": "이 문제는 RDS 데이터를 다른 여러 시스템으로 동시에 전달해야 하며, RDS 자체 이벤트로는 데이터 업데이트를 감지할 수 없다는 점이 핵심입니다. 따라서 Lambda 함수를 통해 DB 변경 시점을 애플리케이션 계층에서 감지하고 SQS를 이용해 비동기적으로 여러 목표 시스템에 데이터를 전송하는 방식이 적절합니다.", "Selections": {"SelectA": {"Select": "데이터베이스(Amazon RDS)가 업데이트될 때 트리거되는 AWS Lambda 함수를 만들어, 해당 정보를 Amazon Simple Queue Service(Amazon SQS) 큐에 전송하여 대상들이 소비하도록 구성합니다.", "Commentary": "DB 업데이트 시 직접 Lambda를 호출하여 SQS에 메시지를 전달하면, 여러 시스템에 비동기적으로 분산할 수 있어 확장성과 작업 분리를 모두 달성할 수 있으므로 올바른 솔루션입니다."}, "SelectB": {"Select": "데이터베이스(Amazon RDS)가 업데이트될 때 트리거되는 AWS Lambda 함수를 만들어, Amazon Simple Queue Service(Amazon SQS) FIFO 큐에 정보를 전송하여 대상들이 소비하도록 구성합니다.", "Commentary": "FIFO 큐가 필요한 순서 보장이 요구되지 않으며, 단순한 이벤트 전파에 불필요한 과도한 기능으로 오히려 처리량과 확장성에 제약이 생길 수 있으므로 적합하지 않습니다."}, "SelectC": {"Select": "RDS 이벤트 알림에 가입하고 Amazon Simple Queue Service(Amazon SQS) 큐를 여러 Amazon Simple Notification Service(Amazon SNS) 토픽으로 퍼나르게 구성합니다. 그 후 AWS Lambda 함수를 사용하여 대상들을 업데이트합니다.", "Commentary": "RDS 이벤트 알림은 데이터 자체 변경(INSERT, UPDATE, DELETE)을 지원하지 않아 이를 활용한 팬아웃 구조는 의미가 없어 요구사항을 충족하지 못합니다."}, "SelectD": {"Select": "RDS 이벤트 알림에 가입하고 Amazon Simple Notification Service(Amazon SNS) 토픽을 여러 Amazon Simple Queue Service(Amazon SQS) 큐로 퍼나르게 구성합니다. 그 후 AWS Lambda 함수를 사용하여 대상들을 업데이트합니다.", "Commentary": "마찬가지로 RDS 이벤트 알림에서 DB 내부 데이터 변경 이벤트를 제공하지 않으므로, SNS와 SQS를 통한 팬아웃이 구현되지 않아 목적을 달성할 수 없습니다."}}}
{"Question_Number": "Q109", "Question_Description": "한 회사가 Amazon S3에 데이터를 저장해야 하며, 데이터가 변경되지 않도록 해야 합니다. 회사는 Amazon S3에 업로드되는 새 객체가 회사가 객체를 수정하기로 결정할 때까지 불특정 기간 변경 불가능하게 유지되길 원합니다. 또한 회사의 AWS 계정에서 오직 특정 사용자만 해당 객체를 삭제할 수 있도록 해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon S3", "S3 Object Lock", "불특정 기간 변경 불가", "Legal hold", "특정 사용자 삭제 권한", "Versioning"], "Terms": ["S3 Glacier vault", "WORM (Write-Once, Read-Many) vault lock policy", "S3 Object Lock", "Versioning", "Retention period", "Governance mode", "Legal hold", "AWS CloudTrail", "s3:PutObjectLegalHold", "IAM policy"], "Commentary": "이 문제는 Amazon S3에 업로드된 객체가 회사가 의도하기 전까지 수정·삭제되지 않도록 설정하는 방법을 묻습니다. S3 Object Lock의 Legal hold는 만료 기간 없이 객체를 잠그고, 특정 권한을 가진 사용자만 해제할 수 있어 요구 사항에 부합합니다. 버저닝과 함께 사용하면 기존 객체가 변경되더라도 이전 버전을 보존할 수 있습니다.", "Selections": {"SelectA": {"Select": "S3 Glacier vault를 생성하고 WORM vault lock policy를 적용합니다.", "Commentary": "Vault lock 정책은 확대 적용되며, 특정 사용자만 삭제 권한을 갖도록 세분화하기가 용이하지 않습니다."}, "SelectB": {"Select": "S3 Object Lock을 활성화한 S3 버킷과 100년 보존기간을 설정하고 governance mode로 기본 모드를 설정합니다.", "Commentary": "명확히 정해진 보존 기간(100년)이 필요하므로, 불특정 기간 보존 요구사항에는 맞지 않습니다."}, "SelectC": {"Select": "S3 버킷을 생성하고, AWS CloudTrail로 모든 S3 API 이벤트를 추적한 뒤 변경 사실이 있으면 백업에서 복원합니다.", "Commentary": "변경 발생 후 복원 방식이므로 객체가 아예 변경되지 않도록 막는 요구사항과 맞지 않습니다."}, "SelectD": {"Select": "S3 Object Lock을 활성화한 S3 버킷을 생성하고, 버저닝을 활성화한 뒤 객체에 legal hold를 추가합니다. s3:PutObjectLegalHold IAM 권한을 부여받은 사용자만 해당 객체를 삭제할 수 있게 합니다.", "Commentary": "Legal hold는 별도 기간 없이 객체를 잠글 수 있으며 특정 IAM 권한을 통해서만 해제가 가능하므로 요구사항을 충족하는 가장 적합한 옵션입니다."}}}
{"Question_Number": "Q110", "Question_Description": "한 소셜 미디어 회사는 사용자가 웹사이트에 이미지를 업로드하도록 허용합니다. 웹사이트는 Amazon EC2 인스턴스에서 동작합니다. 업로드 요청 중 웹사이트는 이미지를 표준 크기로 리사이즈한 뒤 Amazon S3에 저장합니다. 현재 사용자들은 업로드 요청이 느리다고 호소하고 있습니다. 회사는 애플리케이션 내 결합도를 낮추고 웹사이트 성능을 향상해야 합니다. 솔루션스 아키텍트는 이미지 업로드 과정을 가장 운영 효율적으로 설계해야 합니다. 이 요구사항을 충족하기 위해 필요한 조치의 조합은 무엇입니까? (두 개를 선택하세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["이미지 업로드", "웹사이트 성능", "느슨한 결합", "Amazon S3", "AWS Lambda"], "Terms": ["Amazon EC2", "Amazon S3", "S3 Glacier", "AWS Lambda", "S3 Event Notifications", "Amazon EventBridge (Amazon CloudWatch Events)", "Pre-Signed URL"], "Commentary": "이 문제는 이미지 업로드 시 동기적 리사이즈로 인해 웹 서버에 부하가 집중되고, 이 과정이 애플리케이션과 강하게 결합되어 있어 성능이 저하되는 상황입니다. Pre-Signed URL을 통해 브라우저가 직접 Amazon S3로 이미지를 업로드하도록 분산하면 웹 서버의 부담이 크게 감소합니다. 이후 S3 Event Notifications를 사용해 AWS Lambda 함수로 비동기 이미지 리사이즈를 수행하면 애플리케이션의 결합도가 낮아지고, 업로드 성능과 확장성을 효과적으로 높일 수 있습니다.", "Selections": {"SelectA": {"Select": "애플리케이션이 이미지를 S3 Glacier로 업로드하도록 설정합니다.", "Commentary": "S3 Glacier는 장기 보관용 스토리지 클래스로, 업로드 시점에 쓰기에는 부적합하며 실시간 접근성과 성능 개선에도 도움이 되지 않습니다."}, "SelectB": {"Select": "웹 서버가 원본 이미지를 Amazon S3로 업로드하도록 설정합니다.", "Commentary": "웹 서버에서 직접 업로드하면 일부 개선은 가능하지만, 여전히 웹 서버가 관여하여 결합을 완전히 해소하지 못하고 부하가 남아있습니다."}, "SelectC": {"Select": "Pre-Signed URL을 사용하여 각 사용자의 브라우저에서 Amazon S3로 직접 이미지를 업로드하도록 애플리케이션을 설정합니다.", "Commentary": "정답. 이렇게 하면 웹 서버의 중간 처리 없이 브라우저가 직접 업로드하여 결합을 줄이고 웹 서버 부하를 크게 낮출 수 있습니다."}, "SelectD": {"Select": "이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 Event Notifications를 구성하고, 해당 함수에서 이미지를 리사이즈합니다.", "Commentary": "정답. 업로드 후 비동기적으로 이미지를 리사이즈하므로, 웹 서버 성능을 개선하고 애플리케이션 결합도를 줄이는 효과가 있습니다."}, "SelectE": {"Select": "Amazon EventBridge (Amazon CloudWatch Events) 룰을 만들어 일정에 따라 AWS Lambda 함수를 호출하여 업로드된 이미지를 리사이즈합니다.", "Commentary": "스케줄 기반 처리는 실시간으로 이미지를 리사이즈하기 어려워 사용자의 즉각적 경험을 만족시키기 어렵고, 진정한 애플리케이션 결합 해소에도 한계가 있습니다."}}}
{"Question_Number": "Q111", "Question_Description": "한 회사가 최근 메시지 처리 시스템을 AWS로 마이그레이션했습니다. 이 시스템은 Amazon EC2에서 실행되는 ActiveMQ 큐를 통해 메시지를 수신하고, Amazon EC2에서 실행되는 consumer 애플리케이션이 메시지를 처리하여 Amazon EC2에서 구동되는 MySQL 데이터베이스에 결과를 기록합니다. 회사는 낮은 운영 복잡도로 높은 가용성을 달성하기를 원합니다. 다음 중 가장 높은 가용성을 제공하는 아키텍처는 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["메시지 처리", "가용성", "운영 복잡도", "Multi-AZ", "Auto Scaling group"], "Terms": ["Amazon EC2", "ActiveMQ", "consumer 애플리케이션", "Amazon MQ", "active/standby brokers", "MySQL", "Amazon RDS for MySQL", "Multi-AZ", "Auto Scaling group"], "Commentary": "이 문제는 메시지 큐, 애플리케이션, 데이터베이스를 모두 이중화하거나 관리형 서비스를 사용하여 운영 복잡도를 줄이면서 고가용성을 달성하는 방법을 묻습니다. 관리형 Amazon MQ, Auto Scaling group, 그리고 Amazon RDS for MySQL Multi-AZ로 구성된 D안이 가장 높은 가용성을 보장합니다.", "Selections": {"SelectA": {"Select": "ActiveMQ 서버를 추가로 다른 Availability Zone에 배포하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 두며, MySQL 데이터베이스를 다른 Availability Zone으로 복제합니다.", "Commentary": "직접 ActiveMQ와 MySQL 복제를 구성해야 하므로 관리 오버헤드가 크고, RDS Multi-AZ 활용이 없어 고가용성 수준이 떨어집니다."}, "SelectB": {"Select": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 배포합니다. MySQL 데이터베이스는 다른 Availability Zone으로만 복제합니다.", "Commentary": "Amazon MQ는 관리형이지만 MySQL은 RDS Multi-AZ가 아니므로, 수동 복제가 필요해 운영 복잡성이 있고 완전한 고가용성을 보장하기 어렵습니다."}, "SelectC": {"Select": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 배포합니다. MySQL 데이터베이스는 Multi-AZ를 활성화한 Amazon RDS for MySQL을 사용합니다.", "Commentary": "DB와 MQ는 고가용성 옵션이지만 consumer EC2 인스턴스가 단순 이중화만 되어 Auto Scaling group이 없어 장애 시 자동 복구가 제한적입니다."}, "SelectD": {"Select": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, Auto Scaling group을 통해 두 개의 Availability Zone 전반에 consumer EC2 인스턴스를 배포합니다. MySQL 데이터베이스는 Multi-AZ를 활성화한 Amazon RDS for MySQL을 사용합니다.", "Commentary": "MQ, DB, 그리고 consumer 인스턴스 모두 관리형 고가용성 구성을 적용해, 장애에 즉시 대응하면서 운영 복잡도를 최소화하는 가장 완벽한 솔루션입니다."}}}
{"Question_Number": "Q112", "Question_Description": "한 회사가 내부 데이터 센터의 서버 여러 대에서 컨테이너화된 웹 애플리케이션을 운영하여 들어오는 요청을 처리하고 있습니다. 요청 수가 빠르게 증가하여 내부 서버들이 더 이상 늘어난 요청을 감당하지 못하고 있습니다. 회사는 애플리케이션 코드를 최소한으로 수정하고 개발 노력을 최소화하면서 AWS로 이전하고자 합니다. 이러한 요구사항을 충족하며 오퍼레이셔널 오버헤드를 가장 적게 소모하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["컨테이너화된 웹 애플리케이션", "오퍼레이셔널 오버헤드", "AWS로 이전", "AWS Fargate", "Service Auto Scaling", "Application Load Balancer"], "Terms": ["AWS Fargate", "Amazon ECS", "Service Auto Scaling", "Application Load Balancer", "Amazon EC2", "AWS Lambda", "Amazon API Gateway", "AWS ParallelCluster"], "Commentary": "이 문제는 내부 서버에서 운영 중인 컨테이너화된 웹 애플리케이션을 최소한의 코드 변경으로 AWS로 이전하는 상황입니다. AWS Fargate를 사용하면 EC2 인스턴스 관리를 생략해 오퍼레이셔널 오버헤드가 줄어들고, Service Auto Scaling과 ALB로 높은 확장성을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Fargate를 사용하는 Amazon ECS에서 컨테이너화된 웹 애플리케이션을 실행하고 Service Auto Scaling을 설정합니다. Application Load Balancer를 통해 요청을 분산합니다.", "Commentary": "AWS Fargate는 서버 관리를 대신 처리하므로 운영 부담이 낮고, Service Auto Scaling과 ALB를 통해 손쉽게 확장성을 확보할 수 있어 요구사항에 가장 적합합니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스 두 대를 사용해 컨테이너화된 웹 애플리케이션을 배포하고 Application Load Balancer로 트래픽을 분산합니다.", "Commentary": "EC2 인스턴스 관리가 필요하여 운영 부담이 늘어나고, 트래픽 증가 시 인스턴스 증설 등의 추가 작업이 필요해 오퍼레이셔널 오버헤드가 커집니다."}, "SelectC": {"Select": "AWS Lambda에서 지원되는 언어 중 하나로 새 코드를 작성하고 여러 Lambda function을 생성하여 부하를 처리합니다. Amazon API Gateway를 엔드포인트로 사용합니다.", "Commentary": "기존 컨테이너 애플리케이션을 완전히 재개발해야 하므로 개발 노력이 상당하며, 최소한의 코드 변경이라는 목표에 맞지 않습니다."}, "SelectD": {"Select": "AWS ParallelCluster를 사용해 HPC 클러스터를 구성하고 증가하는 요청을 처리할 수 있도록 고성능 환경을 설정합니다.", "Commentary": "HPC 클러스터는 대규모 과학 계산 등에 적합하며, 웹 트래픽 처리에는 과도한 설정과 복잡도가 추가되어 오퍼레이셔널 오버헤드가 커집니다."}}}
{"Question_Number": "Q113", "Question_Description": "한 회사는 보고 용도로 50TB의 데이터를 사용하고 있습니다. 이 회사는 온프레미스에서 이 데이터를 AWS로 이전하려고 합니다. 회사 데이터 센터에는 매주 데이터 변환 작업을 수행하는 맞춤형 애플리케이션이 있으며, 회사는 데이터 전송 완료 후 최대한 빠르게 이 전송 작업을 시작하고자 합니다. 하지만 데이터 센터에는 추가 작업 부하를 처리할 만한 네트워크 대역폭이 없습니다. 솔루션스 아키텍트는 데이터를 전송하고 이 변환 작업을 AWS Cloud에서 계속 실행할 수 있도록 구성해야 합니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["50TB", "데이터 전송", "온프레미스", "Snowball Edge", "AWS Glue"], "Terms": ["AWS DataSync", "AWS Glue", "AWS Snowcone", "Amazon EC2", "Snowball Edge", "Storage Optimized", "ETL"], "Commentary": "이 문제는 온프레미스에서 50TB 대규모 데이터를 빠른 시일 내에 전송해야 하며, 추가 네트워크 사용이 어려운 상황입니다. Snowball Edge Storage Optimized 디바이스를 이용해 물리적으로 데이터를 전송함과 동시에 AWS Glue로 자동화된 변환 작업을 구성하면, 운영 부담을 최소화하고 빠르게 문제를 해결할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS DataSync를 사용하여 데이터를 전송하고 AWS Glue를 사용하여 맞춤형 변환 작업을 생성합니다.", "Commentary": "DataSync는 추가 네트워크 대역폭이 필요한데 데이터 센터에 여유가 없으므로 적절하지 않습니다."}, "SelectB": {"Select": "AWS Snowcone 디바이스를 주문하여 데이터를 전송하고, 변환 애플리케이션을 해당 디바이스에 배포합니다.", "Commentary": "Snowcone은 최대 약 14TB 용량으로 50TB 데이터를 모두 담기에 부족합니다."}, "SelectC": {"Select": "AWS Snowball Edge Storage Optimized 디바이스를 주문하고 데이터를 디바이스에 복사합니다. AWS Glue를 사용해 맞춤형 변환 작업을 생성합니다.", "Commentary": "대용량 Snowball Edge 디바이스를 통해 빠른 물리 전송이 가능하며, 서버리스 AWS Glue로 변환 작업을 수행하므로 운영 오버헤드가 가장 적은 해결책입니다."}, "SelectD": {"Select": "Amazon EC2 컴퓨팅이 포함된 AWS Snowball Edge Storage Optimized 디바이스를 주문하고 데이터를 디바이스에 복사합니다. AWS에서 새 EC2 인스턴스를 생성해 변환 애플리케이션을 실행합니다.", "Commentary": "EC2 인스턴스 배포와 유지 관리가 필요해 운영 부담이 증가하며, C 옵션보다 오버헤드가 큽니다."}}}
{"Question_Number": "Q114", "Question_Description": "한 회사가 사용자들이 사진을 업로드하고 자신의 이미지에 사진 테두리를 추가할 수 있는 이미지 분석 애플리케이션을 만들었습니다. 사용자는 이미지를 업로드하고, 어떤 사진 테두리를 추가할지 표시하기 위한 메타데이터도 함께 업로드합니다. 현재 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon DynamoDB를 사용하여 메타데이터를 저장하고 있습니다. 그러나 애플리케이션의 인기가 높아지면서 사용자 수가 증가하고, 하루 중 특정 시간대나 요일에 따라 동시 사용자 수가 크게 달라질 수 있습니다. 이 회사는 증가하는 사용자 수요를 충족하기 위해 애플리케이션이 확장 가능해야 함을 요구합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["이미지 분석 애플리케이션", "사진 업로드", "메타데이터", "동시 사용자 확장", "AWS Lambda", "Amazon S3", "Amazon DynamoDB"], "Terms": ["Amazon EC2", "Amazon DynamoDB", "AWS Lambda", "Amazon S3", "Amazon Kinesis Data Firehose", "Amazon EBS (io2)"], "Commentary": "이 문제는 애플리케이션이 동시 사용자 수 증가에 맞춰 유연하고 자동으로 확장할 수 있는 구조를 구성해야 하는 상황을 다룹니다. 이미지를 데이터베이스에 직접 저장하는 것은 비효율적이며, Lambda 등 서버리스 기반의 확장성과 저비용 스토리지인 Amazon S3를 조합해 아키텍처를 구성하는 것이 일반적인 모범 사례입니다. 따라서 이미지 처리를 Lambda로 수행하고 사진은 S3에 두며 메타데이터만 DynamoDB에 저장하면 쉽고 효과적으로 확장할 수 있습니다.", "Selections": {"SelectA": {"Select": "Use AWS Lambda to process the photos. Store the photos and metadata in DynamoDB.", "Commentary": "이미지를 직접 DynamoDB에 저장하면 비용이 많이 들고 확장성 측면에서 비효율적이므로 적절하지 않습니다."}, "SelectB": {"Select": "Use Amazon Kinesis Data Firehose to process the photos and to store the photos and metadata.", "Commentary": "Kinesis Data Firehose는 스트리밍 데이터 수집에 적합하지만, 이미지 파일 자체를 저장하고 처리하기엔 구조가 복잡하고 적절치 않습니다."}, "SelectC": {"Select": "Use AWS Lambda to process the photos. Store the photos in Amazon S3. Retain DynamoDB to store the metadata.", "Commentary": "Lambda가 자동으로 확장되며, S3에 이미지를 저장해 비용과 확장성 문제를 해결하고, DynamoDB에는 메타데이터만 저장하여 가볍고 탄력적인 아키텍처를 구성하므로 정답입니다."}, "SelectD": {"Select": "Increase the number of EC2 instances to three. Use Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volumes to store the photos and metadata.", "Commentary": "EC2 인스턴스 수를 늘리고 EBS를 사용하는 방식은 서버 관리를 직접 해야 하고, 빠르게 달라지는 수요에 따라 자동 확장이 제한적이므로 적절하지 않습니다."}}}
{"Question_Number": "Q115", "Question_Description": "한 의료 기록 회사가 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon S3에 저장된 고객 데이터 파일을 처리합니다. 현재 EC2 인스턴스는 public subnets에 위치해 있으며, 인터넷을 통해 Amazon S3에 액세스하고 있습니다. 그러나 EC2 인스턴스에는 그 외 다른 네트워크 액세스가 필요하지는 않습니다. 새로운 요구사항으로 인해 파일 전송에 대한 네트워크 트래픽은 인터넷이 아닌 사설 경로를 통해서만 전송되어야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 네트워크 아키텍처에 어떤 변경 사항을 권장해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["파일 전송", "사설 경로", "public subnets", "private subnets", "Amazon EC2", "Amazon S3", "VPC endpoint", "internet gateway"], "Terms": ["Amazon EC2", "Amazon S3", "public subnets", "private subnets", "VPC endpoint", "NAT gateway", "internet gateway", "security group", "S3 prefix list", "AWS Direct Connect", "route table"], "Commentary": "이 문제는 EC2 인스턴스에서 Amazon S3로의 파일 전송을 퍼블릭 인터넷을 거치지 않고 사설 경로로 전송하게끔 네트워크를 재설계하는 방법을 묻습니다. 정답은 private subnets로 옮긴 뒤 VPC endpoint를 사용하여 트래픽이 인터넷에 노출되지 않는 경로로 전송하는 것입니다.", "Selections": {"SelectA": {"Select": "NAT gateway를 생성합니다. public subnets의 route table을 구성하여 Amazon S3로의 트래픽을 NAT gateway를 통해 전송하도록 설정합니다.", "Commentary": "NAT gateway는 사설 서브넷에서 아웃바운드 인터넷 접속을 제공할 때 사용되며, 여전히 인터넷을 통한 연결이 필요하므로 사설 경로 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "EC2 인스턴스에 대한 security group을 설정하여 아웃바운드 트래픽을 S3 prefix list로의 트래픽만 허용하도록 제한합니다.", "Commentary": "Security group 규칙만으로는 인터넷을 우회하는 사설 경로를 확보할 수 없습니다. 트래픽 경로 자체가 여전히 인터넷을 포함하게 됩니다."}, "SelectC": {"Select": "EC2 인스턴스를 private subnets로 이동합니다. Amazon S3에 대한 VPC endpoint를 생성하고, 이 endpoint를 private subnets의 route table에 연결합니다.", "Commentary": "EC2 인스턴스를 사설 서브넷에 배치하고 S3 VPC endpoint를 사용하면, 인터넷을 거치지 않고도 내부 경로를 통해 안전하게 S3에 접근할 수 있으므로 요구사항을 모두 만족시킵니다."}, "SelectD": {"Select": "VPC에서 internet gateway를 제거합니다. AWS Direct Connect 연결을 설정하고, Amazon S3로 가는 트래픽을 Direct Connect 연결을 통해 전송합니다.", "Commentary": "Direct Connect는 온프레미스 환경과 AWS 간 사설 연결에 주로 사용되며, 이 문제에서는 사설 경로 확보에 과도한 솔루션으로 운영 복잡도와 비용이 증가합니다."}}}
{"Question_Number": "Q116", "Question_Description": "한 회사가 인기 있는 CMS(콘텐츠 관리 시스템)를 사용해 기업 웹사이트를 운영하고 있었으나, 패치 및 유지보수에 대한 부담이 큽니다. 회사는 웹사이트를 새로 설계하려고 하며, 연 4회 업데이트만 필요하고 동적으로 생성되는 콘텐츠도 필요 없습니다. 이 솔루션은 높은 확장성과 보안을 제공해야 하며, 운영 오버헤드를 최소화해야 합니다. 다음 중 이러한 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션 조합은 무엇입니까? (2개를 선택하세요.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["기업 웹사이트", "CMS 부담", "정적 사이트", "높은 확장성", "보안 강화", "운영 오버헤드 최소화"], "Terms": ["Amazon CloudFront", "AWS WAF web ACL", "AWS Lambda", "Amazon S3", "Auto Scaling group", "Amazon EC2", "Application Load Balancer", "HTTPS"], "Commentary": "이 문제는 정적 콘텐츠를 활용해 운영 부담을 줄이고, 동시에 높은 확장성과 보안을 구현하는 것이 핵심입니다. CloudFront와 S3 정적 웹 호스팅을 결합하면 손쉽게 HTTPS 접근과 전 세계적 콘텐츠 캐싱이 가능하여, 관리해야 할 인프라가 줄어들고 패치 부담도 없어집니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront를 웹사이트 앞단에 구성하여 HTTPS 기능을 사용하도록 합니다.", "Commentary": "CloudFront를 통해 전 세계 엣지 로케이션에서 캐싱하며 HTTPS 설정도 간단해, 보안과 확장성 모두를 향상시키는 효과적인 방식입니다."}, "SelectB": {"Select": "AWS WAF web ACL을 웹사이트 앞단에 배포해 HTTPS 기능을 제공합니다.", "Commentary": "AWS WAF는 HTTPS를 직접 제공하지 않고, 주로 웹 공격 방어를 위한 보안 계층이므로 HTTPS 자체 제공 목적에는 적합하지 않습니다."}, "SelectC": {"Select": "웹사이트 콘텐츠를 관리하고 제공하기 위해 AWS Lambda 함수를 생성 후 배포합니다.", "Commentary": "Lambda를 사용해 정적 콘텐츠를 서빙하려면 별도의 설정과 코드가 필요해 운영 복잡도가 오히려 증가합니다."}, "SelectD": {"Select": "새로운 웹사이트를 Amazon S3 버킷에 생성하고, 정적 웹사이트 호스팅을 활성화하여 웹사이트를 배포합니다.", "Commentary": "정적 웹사이트 호스팅으로 S3를 이용하면 관리 서버 없이 확장성과 저비용을 달성할 수 있어 운영 부담이 크게 줄어듭니다."}, "SelectE": {"Select": "새로운 웹사이트를 생성 후, Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹을 통해 웹사이트를 배포합니다.", "Commentary": "EC2 인스턴스와 Auto Scaling, 로드 밸런서 등을 설정해야 하므로 관리가 복잡해지고 오버헤드가 크게 증가합니다."}}}
{"Question_Number": "Q117", "Question_Description": "한 회사가 Amazon CloudWatch Logs log group에 애플리케이션 로그를 저장하고 있습니다. 새로운 정책에 따라, 회사는 모든 애플리케이션 로그를 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 저장해야 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["애플리케이션 로그", "CloudWatch Logs", "Amazon OpenSearch Service(Amazon Elasticsearch Service)", "운영 오버헤드", "거의 실시간"], "Terms": ["CloudWatch Logs subscription", "Amazon OpenSearch Service(Amazon Elasticsearch Service)", "Kinesis Data Firehose", "Amazon Kinesis Data Streams", "AWS Lambda", "Amazon Kinesis Agent"], "Commentary": "이 문제는 CloudWatch Logs log group에 저장된 애플리케이션 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 실시간에 가깝게 전달하는 방안을 묻습니다. 가장 운영 오버헤드가 적은 방법은 CloudWatch Logs 자체 기능을 사용하여 로그를 직접 스트리밍하는 것입니다. 별도의 추가 구성(예: Kinesis Data Firehose나 Lambda 함수, Kinesis Agent 설치 등)을 최소화함으로써 운영 비용과 복잡도를 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "CloudWatch Logs 구독(subscription)을 구성하여 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍합니다.", "Commentary": "CloudWatch Logs에서 제공하는 기본 구독 기능을 통해 추가 인프라 없이 거의 실시간으로 로그를 전송할 수 있어 가장 적은 운영 오버헤드를 제공합니다."}, "SelectB": {"Select": "AWS Lambda 함수를 생성합니다. log group으로 함수를 호출하여 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 기록합니다.", "Commentary": "Lambda 함수를 사용하면 실시간 처리가 가능하지만, 함수 코드 유지보수와 트리거 구성 등 추가적 운영 부담이 생깁니다."}, "SelectC": {"Select": "Amazon Kinesis Data Firehose delivery stream을 생성합니다. log group을 소스로 구성하고, Amazon OpenSearch Service(Amazon Elasticsearch Service)를 대상로 구성합니다.", "Commentary": "Kinesis Data Firehose는 실시간에 가까운 데이터 전송이 가능하지만, 별도 스트리밍 리소스 설정과 관리가 필요해 오버헤드가 더 높습니다."}, "SelectD": {"Select": "각 애플리케이션 서버에 Amazon Kinesis Agent를 설치하고 Kinesis Data Streams로 로그를 전송합니다. 그리고 Kinesis Data Streams를 통해 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 전송합니다.", "Commentary": "Kinesis Agent 설치와 Data Streams 관리가 모두 필요하므로 구성과 운영이 복잡하며, 실시간에 가깝게 전송 가능하지만 운영 오버헤드가 매우 커집니다."}}}
{"Question_Number": "Q118", "Question_Description": "한 회사에서 여러 Availability Zone에 분산된 Amazon EC2 인스턴스 위에서 실행되는 웹 기반 애플리케이션을 구축하고 있습니다. 이 웹 애플리케이션은 총 900TB에 달하는 텍스트 문서 저장소에 대한 접근 기능을 제공합니다. 회사는 웹 애플리케이션이 높은 트래픽을 경험할 시기가 있을 것으로 예상하며, 솔루션스 아키텍트는 텍스트 문서를 저장하는 스토리지가 언제나 애플리케이션의 수요를 충족할 수 있도록 확장 가능해야 한다고 요구합니다. 또한 회사는 전체 솔루션에 대한 비용 문제를 우려하고 있습니다. 이 요구사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1", "2.1"], "Keywords": ["웹 기반 애플리케이션", "텍스트 문서", "900TB", "확장 가능", "비용 효율"], "Terms": ["Amazon EC2", "Availability Zone", "Amazon Elastic Block Store (Amazon EBS)", "Amazon Elastic File System (Amazon EFS)", "Amazon OpenSearch Service (Amazon Elasticsearch Service)", "Amazon S3"], "Commentary": "이 문제는 대용량(900TB) 텍스트 문서를 저장하면서, 높은 트래픽 부담에도 확장 가능하고 비용을 최소화해야 하는 시나리오입니다. Amazon S3는 저렴한 가격 구조와 탄력적 확장이 가능해 요구사항을 모두 충족합니다.", "Selections": {"SelectA": {"Select": "Amazon EBS", "Commentary": "블록 스토리지로서 고성능이지만 단일 AZ 기반이고 비용이 높아 대규모 데이터 저장에는 비효율적입니다."}, "SelectB": {"Select": "Amazon EFS", "Commentary": "파일 스토리지 서비스로 확장성은 좋지만, S3에 비해 GB당 비용이 높아 900TB 규모의 데이터에는 부담이 큽니다."}, "SelectC": {"Select": "Amazon OpenSearch Service (Amazon Elasticsearch Service)", "Commentary": "실시간 검색 및 분석용 서비스로, 대규모 단순 데이터 저장에는 부적합하며 비용 또한 높습니다."}, "SelectD": {"Select": "Amazon S3", "Commentary": "비용이 저렴하고 무제한에 가까운 확장성을 제공하므로, 대규모 텍스트 문서 저장 요구사항에 가장 적합합니다."}}}
{"Question_Number": "Q119", "Question_Description": "글로벌 회사가 us-east-1 리전과 ap-southeast-2 리전에서 운영되는 Amazon API Gateway로 REST API를 설계하고 있습니다. 여러 AWS 계정에서 이 API를 사용하고 있으며, SQL injection과 cross-site scripting 공격으로부터 안전하게 보호해야 합니다. Solutions Architect는 관리 오버헤드를 최소화하면서 API Gateway에서 이러한 공격을 방어할 수 있는 방법을 설계해야 합니다. 다음 중 어떤 솔루션이 최소한의 관리 노력으로 요구 사항을 충족합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["API Gateway", "SQL injection", "cross-site scripting", "관리 오버헤드 최소화"], "Terms": ["Amazon API Gateway", "AWS WAF", "AWS Firewall Manager", "AWS Shield", "Regional web ACL", "API stage", "REST API"], "Commentary": "이 문제는 여러 리전과 계정에 걸쳐 운영되는 API를 공격으로부터 보호하면서, 관리 노력도 최소화해야 합니다. AWS Firewall Manager를 사용하면 여러 계정과 리전에서 중앙 집중식으로 AWS WAF 구성을 관리할 수 있어 SQL injection, XSS 같은 공격을 효율적으로 방어하고 자동화된 보호까지 가능하도록 해줍니다.", "Selections": {"SelectA": {"Select": "두 리전에서 AWS WAF를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.", "Commentary": "모든 리전에 개별적으로 WAF를 설정해야 하므로 계정 단위의 관리가 여전히 복잡합니다."}, "SelectB": {"Select": "두 리전에서 AWS Firewall Manager를 설정하고, 중앙에서 AWS WAF 규칙을 구성합니다.", "Commentary": "AWS Firewall Manager로 여러 계정과 리전을 일괄 관리할 수 있어 노력과 복잡도가 크게 줄어듭니다."}, "SelectC": {"Select": "두 리전에서 AWS Shield를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.", "Commentary": "AWS Shield는 주로 DDoS 방어에 특화되어 있고, SQL injection 및 XSS 방어를 위해선 WAF 구성이 별도로 필요합니다."}, "SelectD": {"Select": "한 리전에서만 AWS Shield를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.", "Commentary": "DDoS 방어 위주 솔루션이며 전 세계적으로 SQL injection과 XSS를 다루기엔 효과적이지 못합니다."}}}
{"Question_Number": "Q120", "Question_Description": "한 회사가 us-west-2 리전에 위치한 Network Load Balancer(NLB) 뒤의 Amazon EC2 인스턴스 3대를 활용하여 자체 관리 DNS 솔루션을 구성했습니다. 이 회사의 대부분 사용자들은 미국과 유럽에 분포해 있으며, 성능과 가용성을 더욱 개선하고자 합니다. 회사는 eu-west-1 리전에도 EC2 인스턴스 3대를 추가로 구축하고 새로운 NLB의 대상으로 등록했습니다. 모든 EC2 인스턴스로 트래픽을 라우팅하기 위해 어떤 솔루션을 사용할 수 있습니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["성능", "가용성", "Network Load Balancer", "AWS Global Accelerator", "라우팅"], "Terms": ["Amazon EC2", "Network Load Balancer(NLB)", "AWS Global Accelerator", "Endpoint groups", "Amazon Route 53", "Geolocation routing policy", "Latency routing policy", "Application Load Balancer(ALB)", "Amazon CloudFront", "Elastic IP addresses"], "Commentary": "이 문제는 여러 리전에 분산된 EC2 인스턴스를 사용해 자체 관리 DNS를 제공할 때, 성능과 가용성을 높이는 방안을 묻습니다. 답은 AWS Global Accelerator를 사용해 us-west-2와 eu-west-1 두 리전에 걸쳐 엔드포인트 그룹을 생성한 뒤, 각각의 NLB를 엔드포인트로 추가하는 방법입니다. 이렇게 하면 글로벌 사용자가 물리적 위치와 관계없이 가장 빠른 네트워크 경로를 통해 DNS 서비스에 접근할 수 있어 성능과 가용성이 모두 개선됩니다.", "Selections": {"SelectA": {"Select": "Amazon Route 53 지리 위치(geolocation) 라우팅 정책을 만들어 두 NLB 중 하나로 요청을 전달합니다. 그런 다음 Amazon CloudFront 배포를 생성하고, Route 53 레코드를 배포의 오리진으로 사용합니다.", "Commentary": "지리 위치 라우팅은 지역을 기준으로 트래픽을 나누지만, 글로벌 사용자의 가장 빠른 경로 제공을 보장하지 못합니다. CloudFront 배포를 추가하더라도 NLB 선택에 있어 지역 구분만 사용하므로 성능 향상이 제한적입니다."}, "SelectB": {"Select": "AWS Global Accelerator 표준 가속기를 생성합니다. us-west-2와 eu-west-1 리전에 엔드포인트 그룹을 만들고, 두 NLB를 엔드포인트로 추가합니다.", "Commentary": "AWS Global Accelerator를 사용하면 전 세계 사용자에게 단일 고정 진입점을 제공하고, 글로벌 AWS 네트워크를 통해 가장 빠른 경로로 트래픽을 라우팅하므로 성능과 가용성이 크게 향상됩니다. 정답입니다."}, "SelectC": {"Select": "6대의 EC2 인스턴스 각각에 Elastic IP 주소를 할당합니다. Amazon Route 53 지리 위치 라우팅 정책으로 6대 중 하나로 트래픽을 전달하게 구성합니다. 그리고 Amazon CloudFront 배포를 생성하고, 해당 Route 53 레코드를 CloudFront의 오리진으로 사용합니다.", "Commentary": "개별 EC2 인스턴스에 직접 트래픽을 전달하면 로드 밸런서를 통한 확장성, 고가용성 이점을 활용하기 어렵고, 관리 복잡성도 높아집니다."}, "SelectD": {"Select": "두 NLB를 두 Application Load Balancer(ALB)로 교체합니다. Amazon Route 53 지연 시간(latency) 라우팅 정책을 생성하여 두 ALB 중 하나로 요청을 전송합니다. 그런 다음 Amazon CloudFront 배포를 만들고, Route 53 레코드를 배포의 오리진으로 사용합니다.", "Commentary": "지연 시간 라우팅을 사용해도, AWS Global Accelerator가 제공하는 전용 글로벌 백본을 통한 성능 이점을 활용하기는 어렵습니다. ALB 교체 및 CloudFront 연동 또한 필요한 단계를 늘려 운영 부담이 커집니다."}}}
{"Question_Number": "Q121", "Question_Description": "한 회사가 온라인 트랜잭션 처리(OLTP) 워크로드를 AWS에서 운영하고 있습니다. 이 워크로드는 Multi-AZ 배포 구성의 암호화되지 않은 Amazon RDS DB 인스턴스를 사용하며, 매일 이 인스턴스에서 데이터베이스 스냅샷을 생성하고 있습니다. 앞으로 데이터베이스와 스냅샷을 항상 암호화하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon RDS", "Multi-AZ", "암호화", "DB 스냅샷", "AWS KMS", "OLTP"], "Terms": ["Amazon RDS DB instance", "Multi-AZ deployment", "Daily database snapshots", "AWS Key Management Service (AWS KMS)", "Unencrypted DB instance", "SSE-KMS", "Amazon EBS volume", "Restore"], "Commentary": "기존에 암호화되지 않은 DB 인스턴스는 직접 암호화를 활성화할 수 없습니다. 대신 먼저 최신 DB 스냅샷의 암호화 복사본을 만들고, 해당 스냅샷을 복원하여 암호화된 새 DB 인스턴스를 생성하면 이후 모든 스냅샷도 자동으로 암호화됩니다.", "Selections": {"SelectA": {"Select": "최신 DB 스냅샷의 암호화 복사본을 생성한 뒤, 해당 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다.", "Commentary": "암호화된 DB 스냅샷을 생성 후 이를 복원해 새 인스턴스를 만들면 암호화가 적용된 인스턴스를 확보해 이후 스냅샷도 모두 암호화됩니다. 이 접근이 올바른 해결책입니다."}, "SelectB": {"Select": "새로운 암호화된 Amazon EBS 볼륨을 생성하고, 기존 스냅샷을 그 볼륨에 복사합니다. 이후 DB 인스턴스에 암호화를 활성화합니다.", "Commentary": "RDS 인스턴스는 생성 시점에만 암호화 설정이 가능하므로, 단순히 EBS 볼륨을 암호화해도 현재 DB 인스턴스를 바로 암호화할 수 없어서 적합하지 않습니다."}, "SelectC": {"Select": "스냅샷을 복사하면서 AWS KMS를 사용해 암호화를 활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스에 복원합니다.", "Commentary": "암호화된 스냅샷은 기존 DB 인스턴스에 직접 복원될 수 없고, 새 인스턴스로 복원해야 실제로 암호화 인스턴스를 얻을 수 있으므로 이 방식은 부적절합니다."}, "SelectD": {"Select": "스냅샷을 AWS KMS 관리 암호화(SSE-KMS)가 적용된 Amazon S3 버킷으로 복사합니다.", "Commentary": "스냅샷을 S3로 암호화해 보관해도 원래의 RDS 인스턴스를 암호화 상태로 전환하지 못하므로, 이후 DB 스냅샷 자동 암호화에도 영향을 주지 못합니다."}}}
{"Question_Number": "Q122", "Question_Description": "회사는 애플리케이션에서 데이터를 암호화해야 하는 개발자들을 지원하기 위해 스케일러블한 키 관리 인프라스트럭처를 구축하려고 합니다. 솔루션스 아키텍트의 운영 부담을 줄이기 위한 최적의 방안은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["스케일러블 키 관리", "암호화", "애플리케이션", "운영 부담 최소화", "AWS KMS"], "Terms": ["AWS Key Management Service (AWS KMS)", "IAM policy", "AWS Certificate Manager (ACM)", "Multi-factor authentication (MFA)", "Encryption keys"], "Commentary": "이 문제는 암호화 키를 안전하고 확장 가능하게 관리해야 하는 상황입니다. AWS KMS는 중앙 집중식 키 생성, 로테이션, 접근 제어 등을 자동화하여 운영 부담을 크게 줄여 줍니다.", "Selections": {"SelectA": {"Select": "Multi-factor authentication (MFA)를 사용하여 Encryption keys를 보호합니다.", "Commentary": "MFA는 계정 보호에는 유용하나, 자체적으로 스케일러블한 키 관리 인프라스트럭처를 제공하지 못합니다."}, "SelectB": {"Select": "AWS Key Management Service (AWS KMS)를 사용하여 Encryption keys를 보호합니다.", "Commentary": "AWS KMS는 암호화 키를 안전하게 저장, 관리, 자동 로테이션할 수 있어 운영 부담과 라이선스 비용을 모두 줄일 수 있는 최적의 솔루션입니다."}, "SelectC": {"Select": "AWS Certificate Manager (ACM)을 사용하여 Encryption keys를 생성, 저장 및 할당합니다.", "Commentary": "ACM은 주로 SSL/TLS 인증서 관리에 특화되어 있으며, 일반적인 데이터 암호화를 위한 키 관리에는 적합하지 않습니다."}, "SelectD": {"Select": "IAM policy로 Encryption keys에 대한 액세스 권한 범위를 제한합니다.", "Commentary": "IAM policy로 접근을 제어하는 것은 중요하지만, 키를 직접 관리하고 자동화할 수 있는 기능은 제공하지 못해 운영 부담을 충분히 줄이지 못합니다."}}}
{"Question_Number": "Q123", "Question_Description": "한 회사가 두 대의 Amazon EC2 인스턴스에 동적 웹 애플리케이션을 호스팅하고 있습니다. 회사는 자체 SSL certificate를 보유하고 있으며, 각 인스턴스에서 SSL termination을 수행하고 있습니다. 최근 트래픽이 증가하여 운영팀은 SSL 암호화·복호화 작업이 웹 서버의 컴퓨팅 용량을 최대치로 사용한다고 판단했습니다. 애플리케이션 성능을 높이기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["SSL certificate", "SSL termination", "AWS Certificate Manager", "Application Load Balancer", "EC2", "HTTPS", "웹 서버 성능"], "Terms": ["SSL certificate", "SSL termination", "AWS Certificate Manager (ACM)", "Application Load Balancer", "Amazon EC2", "Amazon S3", "Proxy server", "HTTPS listener"], "Commentary": "이 문제의 핵심은 SSL 암복호화로 인한 서버 부하를 줄여 애플리케이션 성능을 높이는 것입니다. 인스턴스에서 SSL termination을 수행하면 CPU 사용량이 크게 증가하므로, AWS Certificate Manager에 SSL certificate를 등록하고 ALB(HTTPS listener)에서 암복호화를 처리하도록 오프로딩하는 방식이 최적의 해결책입니다.", "Selections": {"SelectA": {"Select": "AWS Certificate Manager (ACM)에서 새로운 SSL certificate를 생성하고, 각 인스턴스에 설치합니다.", "Commentary": "각 EC2 인스턴스에서 SSL termination을 계속 수행하므로 암복호화 부담이 여전히 남아 있습니다."}, "SelectB": {"Select": "Amazon S3 버킷을 생성하고 SSL certificate를 마이그레이션한 후, EC2 인스턴스가 해당 버킷을 참조하도록 설정합니다.", "Commentary": "S3 버킷은 SSL termination 기능을 제공하지 않으므로 서버 부하 문제를 해결할 수 없습니다."}, "SelectC": {"Select": "프록시 서버용 새 EC2 인스턴스를 생성하고, SSL certificate를 마이그레이션하여 기존 EC2 인스턴스에 연결되도록 구성합니다.", "Commentary": "프록시 서버에서 SSL termination을 수행하지만, EC2 인스턴스를 하나 더 두어 직접 관리해야 하므로 운영 복잡도가 증가합니다."}, "SelectD": {"Select": "SSL certificate를 AWS Certificate Manager (ACM)에 가져옵니다. ACM의 SSL certificate를 사용하는 HTTPS listener가 있는 Application Load Balancer를 생성합니다.", "Commentary": "ALB에서 SSL 암복호화를 담당하게 하여 웹 서버의 부하를 줄이고, 관리 편의성과 보안성을 모두 높이는 최적의 방법입니다."}}}
{"Question_Number": "Q124", "Question_Description": "한 회사는 매우 동적인 배치 처리 작업을 수행하기 위해 여러 Amazon EC2 인스턴스를 사용하고 있습니다. 이 작업은 상태 정보가 없으므로 언제든지 중지 및 재시작해도 문제가 없으며, 보통 전체 수행 시간은 60분 이상 걸립니다. 회사는 이 작업의 요구 사항을 충족하면서 확장 가능하고 비용 효율적인 솔루션을 설계해 달라고 Solutions Architect에게 요청했습니다. 어떤 솔루션을 권장해야 할까요?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["동적인 배치 처리", "stateless", "확장 가능", "비용 효율적인 솔루션", "60분 이상", "EC2 Spot Instances"], "Terms": ["Amazon EC2", "EC2 Spot Instances", "EC2 Reserved Instances", "EC2 On-Demand Instances", "AWS Lambda"], "Commentary": "이 문제는 배치 작업을 간헐적으로 중단·재시작해도 무방한 특성을 활용해, 중단 허용 워크로드에 최적화된 저비용 실행 방안을 찾는 것입니다. EC2 Spot Instances는 일반 온디맨드 대비 매우 저렴하며, 작업이 중단되어도 문제가 없는 배치 처리를 수행하기에 안성맞춤입니다. On-Demand Instances는 유연성이 있으나 비용이 더 높고, Reserved Instances는 장기 약정이 필요해 유연성이 떨어집니다. AWS Lambda는 실행 시간 제한(최대 15분)이 있어 60분 이상의 작업에는 적합하지 않습니다.", "Selections": {"SelectA": {"Select": "EC2 Spot Instances를 구현합니다.", "Commentary": "Spot은 중단될 가능성이 있지만, 유연한 배치 작업에는 저비용으로 적합한 선택입니다."}, "SelectB": {"Select": "EC2 Reserved Instances를 구매합니다.", "Commentary": "장기 약정으로 비용은 줄일 수 있으나, 동적 배치 작업을 수시로 중지/재시작하기에는 적합하지 않습니다."}, "SelectC": {"Select": "EC2 On-Demand Instances를 구현합니다.", "Commentary": "온디맨드는 유연하지만 Spot 대비 비용이 높아 대규모 배치 작업의 비용 절감에는 한계가 있습니다."}, "SelectD": {"Select": "AWS Lambda에서 작업을 처리합니다.", "Commentary": "Lambda의 최대 실행 시간이 15분이라 60분 이상 소요되는 배치 작업에는 맞지 않습니다."}}}
{"Question_Number": "Q125", "Question_Description": "한 회사가 AWS에서 2티어 전자상거래 웹사이트를 운영하고 있습니다. 웹 티어는 로드 밸런서를 통해 Amazon EC2 인스턴스로 트래픽을 전송합니다. 데이터베이스 티어는 Amazon RDS DB 인스턴스를 사용합니다. EC2 인스턴스와 RDS DB 인스턴스는 퍼블릭 인터넷에 노출되어서는 안 됩니다. 하지만 EC2 인스턴스는 서드파티 웹 서비스를 통한 결제 처리를 위해 인터넷 액세스가 필요합니다. 또한 애플리케이션은 고가용성을 유지해야 합니다. 이러한 요구사항을 충족하는 구성 옵션의 조합은 무엇입니까? (정답으로 2개를 고르세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["1.1", "2.2"], "Keywords": ["2티어 전자상거래", "EC2 인스턴스", "RDS DB 인스턴스", "NAT Gateway", "퍼블릭 인터넷 노출 방지", "고가용성"], "Terms": ["Amazon EC2", "Amazon RDS", "Multi-AZ", "Auto Scaling group", "VPC", "Public Subnet", "Private Subnet", "NAT Gateway", "Application Load Balancer"], "Commentary": "이 문제는 인터넷에 직접 노출되지 않는 EC2 인스턴스와 RDS DB 인스턴스를 구성하면서도, EC2 인스턴스가 외부 결제 서비스를 위해 아웃바운드 인터넷 액세스를 갖도록 해야 하며, 동시에 고가용성을 보장해야 합니다. EC2와 RDS를 모두 Private Subnet에 배치하고, Public Subnet에는 NAT Gateway와 Application Load Balancer를 다중 AZ로 구성함으로써 이러한 요구사항을 충족할 수 있습니다. 따라서 Auto Scaling group으로 Private Subnet에 EC2를 생성하고 Multi-AZ로 RDS를 구성하며, Public Subnet에 배포된 NAT Gateway와 ALB를 통해 인터넷 액세스와 외부 트래픽 수용을 동시에 만족시킬 수 있는 (A)와 (E)가 정답입니다.", "Selections": {"SelectA": {"Select": "Auto Scaling group을 사용하여 EC2 인스턴스를 Private Subnet에 생성합니다. RDS Multi-AZ DB 인스턴스를 Private Subnet에 배포합니다.", "Commentary": "EC2와 RDS 모두 Private Subnet에서 운영하며, Multi-AZ 구성으로 고가용성을 지원합니다. EC2는 NAT Gateway를 통해 인터넷에 접근할 수 있게 됩니다."}, "SelectB": {"Select": "두 개의 Private Subnet과 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Private Subnet에 배포합니다.", "Commentary": "ALB가 Private Subnet에 위치하면 외부에서 직접 접근이 불가하여 웹 트래픽 수용이 불가능하므로 요구사항을 충족하지 못합니다."}, "SelectC": {"Select": "Auto Scaling group을 사용하여 EC2 인스턴스를 두 개의 Availability Zone에 걸쳐 Public Subnet에 생성합니다. RDS Multi-AZ DB 인스턴스를 Private Subnet에 배포합니다.", "Commentary": "EC2 인스턴스가 Public Subnet에 위치하여 퍼블릭 인터넷에 노출되므로, 보안 요구사항에 어긋납니다."}, "SelectD": {"Select": "하나의 Public Subnet과 하나의 Private Subnet, 그리고 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Public Subnet에 배포합니다.", "Commentary": "Public Subnet이 단 하나뿐이라 가용 영역을 둘 이상 활용하기 어렵고, 고가용성 구성에 부합하지 않습니다."}, "SelectE": {"Select": "두 개의 Public Subnet, 두 개의 Private Subnet, 그리고 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Public Subnet들에 배포합니다.", "Commentary": "각 AZ에 Public Subnet과 Private Subnet을 모두 두고, ALB를 Public Subnet에 배치해 외부 트래픽을 처리합니다. EC2와 RDS는 Private Subnet에 배치해 인터넷 노출을 방지하면서 NAT Gateway를 통해 필요한 아웃바운드 액세스를 보장합니다. 다중 AZ 구성을 통해 높은 가용성을 달성할 수 있습니다."}}}
{"Question_Number": "Q126", "Question_Description": "한 솔루션즈 아키텍트가 회사의 스토리지 비용 절감을 위해 솔루션을 구현해야 합니다. 회사의 모든 데이터는 Amazon S3 Standard 스토리지 클래스로 저장되어 있습니다. 회사는 최소 25년 동안 모든 데이터를 보관해야 합니다. 가장 최근 2년간의 데이터는 높은 가용성과 즉시 검색이 가능해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["25년 보관", "2년 즉시 검색", "Amazon S3 Standard", "S3 Glacier Deep Archive", "스토리지 비용 절감"], "Terms": ["Amazon S3 Standard", "S3 Lifecycle policy", "S3 Glacier Deep Archive", "S3 Intelligent-Tiering", "S3 One Zone-Infrequent Access (S3 One Zone-IA)"], "Commentary": "데이터를 2년간은 Amazon S3 Standard로 유지해 즉시 액세스를 보장하고, 이후에는 S3 Glacier Deep Archive로 전환하여 비용을 크게 절감할 수 있습니다.", "Selections": {"SelectA": {"Select": "객체를 S3 Glacier Deep Archive로 즉시 전환하도록 S3 Lifecycle policy를 설정합니다.", "Commentary": "즉시 전환 시 2년 동안 필요한 즉시 검색 요구를 충족할 수 없어 부적합합니다."}, "SelectB": {"Select": "객체를 2년 후에 S3 Glacier Deep Archive로 전환하도록 S3 Lifecycle policy를 설정합니다.", "Commentary": "정답. 먼저 2년간 Amazon S3 Standard로 즉시 접근성을 보장하고 이후 장기 보관을 위해 S3 Glacier Deep Archive로 전환해 비용을 절감합니다."}, "SelectC": {"Select": "S3 Intelligent-Tiering을 사용합니다. archiving option을 활성화하여 S3 Glacier Deep Archive에 데이터가 보관되도록 합니다.", "Commentary": "archiving option 활성 시 2년 이내 데이터도 아카이빙될 수 있으므로, 필요한 즉시 검색 요구사항을 충족하기 어렵습니다."}, "SelectD": {"Select": "객체를 즉시 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 전환하고, 2년 후에는 S3 Glacier Deep Archive로 전환하도록 S3 Lifecycle policy를 설정합니다.", "Commentary": "One Zone-IA는 가용성이 낮고, 2년간의 높은 가용성 및 즉시 검색 요구에도 부합하지 않습니다."}}}
{"Question_Number": "Q127", "Question_Description": "한 미디어 회사가 시스템을 AWS 클라우드로 이전하는 방안을 검토하고 있습니다. 회사는 비디오 처리용으로 최대한의 I/O 성능을 제공해야 하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 매우 내구성 있는 스토리지, 그리고 이미 사용되지 않는 아카이브 미디어 보관을 위한 900TB의 스토리지가 필요합니다. 이 요구 사항을 충족하기 위해 솔루션스 아키텍트가 권장해야 할 서비스 조합은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["비디오 처리", "최대 I/O 성능", "내구성 높은 스토리지", "아카이브 스토리지"], "Terms": ["Amazon EC2 Instance Store", "Amazon S3", "Amazon S3 Glacier", "Amazon EBS", "Amazon EFS"], "Commentary": "이 문제는 각각의 스토리지 요구 사항에 맞춰 가장 적합한 AWS 스토리지 서비스를 선택하는 상황입니다. 높은 I/O 성능을 위해 Instance Store를 활용하고, 내구성이 필요한 300TB는 Amazon S3에 저장하며, 사용하지 않는 900TB 데이터는 S3 Glacier로 아카이빙하는 구성이 최적 해법입니다.", "Selections": {"SelectA": {"Select": "Amazon EBS로 최대 성능을 확보하고, Amazon S3로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현", "Commentary": "EBS는 상당히 높은 성능을 제공하지만 Instance Store에 비해 최대 I/O 성능이 제한적이라 요구 사항을 최적화하기에 부족합니다."}, "SelectB": {"Select": "Amazon EBS로 최대 성능을 확보하고, Amazon EFS로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현", "Commentary": "EFS는 파일 스토리지로 유연하나 대규모 300TB를 비용 효율적으로 저장하기에는 S3만큼 적합하지 않습니다."}, "SelectC": {"Select": "Amazon EC2 Instance Store로 최대 성능을 확보하고, Amazon EFS로 내구성 있는 스토리지를 제공하며, Amazon S3로 아카이브 스토리지 구현", "Commentary": "Instance Store로 I/O 성능은 충족하나, 900TB의 아카이브 데이터를 S3에만 보관하면 장기 아카이빙 용도에 적합한 Glacier를 활용하지 못합니다."}, "SelectD": {"Select": "Amazon EC2 Instance Store로 최대 성능을 확보하고, Amazon S3로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현", "Commentary": "Instance Store가 EBS 대비 더 높은 최대 I/O 성능을 제공하고, 300TB의 내구성 높은 스토리지로 Amazon S3를 활용하며, 900TB의 장기 보관 데이터는 비용 효율적인 S3 Glacier로 아카이빙하는 가장 적절한 방안입니다."}}}
{"Question_Number": "Q128", "Question_Description": "한 회사가 AWS Cloud에서 컨테이너로 애플리케이션을 실행하려고 합니다. 이 애플리케이션들은 stateless하며 기본 인프라의 중단을 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 어떤 방법이 이 요구사항을 충족할까요?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["컨테이너", "stateless", "중단 견딤", "비용 최적화", "운영 오버헤드", "Spot Instances", "On-Demand Instances"], "Terms": ["Amazon EC2 Auto Scaling group", "Amazon EKS", "Spot Instances", "On-Demand Instances", "Managed node group"], "Commentary": "이 문제는 컨테이너 기반의 애플리케이션을 중단에 견딜 수 있을 만큼 유연하게 설계하고, 동시에 비용과 운영 부담을 줄이는 방법을 묻습니다. Stateless 특성으로 인해 Spot Instances의 중단 위험을 감내할 수 있어 온디맨드 대비 매우 저렴한 비용으로 운영 가능합니다. 따라서 Spot Instances를 사용하는 것이 최적의 선택입니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 Auto Scaling group에서 Spot Instances를 사용하여 애플리케이션 컨테이너를 실행합니다.", "Commentary": "Stateless 애플리케이션 환경에서는 Spot 중단도 쉽게 복구할 수 있어 비용을 크게 줄이고 운영 오버헤드도 최소화할 수 있는 최적의 방법입니다."}, "SelectB": {"Select": "Spot Instances를 Amazon Elastic Kubernetes Service(Amazon EKS) managed node group에서 사용합니다.", "Commentary": "EKS를 사용하면 컨트롤 플레인 및 관리 비용이 추가되어 운영 오버헤드가 증가하므로 요구사항에 비해 비효율적입니다."}, "SelectC": {"Select": "Amazon EC2 Auto Scaling group에서 On-Demand Instances를 사용하여 애플리케이션 컨테이너를 실행합니다.", "Commentary": "On-Demand Instances는 유연하나, Spot 대비 비용이 더 높기 때문에 비용 최소화 목표에 부합하지 않습니다."}, "SelectD": {"Select": "On-Demand Instances를 Amazon Elastic Kubernetes Service(Amazon EKS) managed node group에서 사용합니다.", "Commentary": "On-Demand와 EKS 조합은 비용 절감 효과가 적고, EKS 운영 오버헤드도 추가되어 요구사항을 만족하기 어렵습니다."}}}
{"Question_Number": "Q129", "Question_Description": "한 회사가 온프레미스 환경에서 멀티 티어 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 컨테이너화되어 있으며, 사용자 레코드를 포함하는 PostgreSQL 데이터베이스와 연결된 여러 Linux 호스트에서 동작합니다. 인프라 유지관리와 용량 계획에 대한 운영 오버헤드가 회사의 성장을 제한하고 있어, 솔루션스 아키텍트는 애플리케이션 인프라를 개선해야 합니다. 이러한 요구사항을 달성하기 위해 솔루션스 아키텍트가 취해야 할 조합은 무엇입니까? (2개를 고르세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["온프레미스", "멀티 티어 웹 애플리케이션", "컨테이너화", "PostgreSQL", "사용자 레코드", "운영 오버헤드", "용량 계획", "인프라 개선"], "Terms": ["Amazon Aurora", "AWS Fargate", "Amazon Elastic Container Service (Amazon ECS)", "Amazon CloudFront", "Amazon EC2", "Amazon ElastiCache", "PostgreSQL"], "Commentary": "운영 오버헤드와 용량 계획 문제를 해소하려면 완전관리형 서비스로 마이그레이션하는 것이 효과적입니다. Amazon Aurora로 데이터베이스를 이전하면 고가용성 및 확장성을 쉽게 확보할 수 있고, AWS Fargate를 통해 컨테이너 오케스트레이션 환경을 자동으로 관리할 수 있어 인프라 관리 부담이 크게 줄어듭니다.", "Selections": {"SelectA": {"Select": "PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.", "Commentary": "Amazon Aurora는 높은 확장성, 관리 편의성을 제공하므로 운영 오버헤드를 줄이고 고가용성을 보장하는 데 적합합니다."}, "SelectB": {"Select": "웹 애플리케이션을 Amazon EC2 인스턴스에서 호스팅하도록 마이그레이션합니다.", "Commentary": "Amazon EC2는 직접 인스턴스를 관리해야 하므로, 인프라 관리 부담이 여전히 남아 문제 개선 효과가 제한적입니다."}, "SelectC": {"Select": "웹 애플리케이션 콘텐츠를 위해 Amazon CloudFront 배포를 설정합니다.", "Commentary": "CloudFront는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하여 성능을 개선하지만, 근본적인 인프라 운영 오버헤드 문제 해결과 직접적인 연관이 적습니다."}, "SelectD": {"Select": "웹 애플리케이션과 PostgreSQL 데이터베이스 사이에 Amazon ElastiCache를 설정합니다.", "Commentary": "ElastiCache는 데이터 접근 속도를 개선하나, DB 인프라 유지관리 및 용량 계획 오버헤드를 근본적으로 줄이는 데에는 제한적입니다."}, "SelectE": {"Select": "AWS Fargate와 Amazon Elastic Container Service(Amazon ECS)를 사용하여 웹 애플리케이션을 호스팅하도록 마이그레이션합니다.", "Commentary": "AWS Fargate는 서버 관리가 필요 없어 애플리케이션 컨테이너 운영 부담을 최소화하고 자동 확장을 지원하기 때문에 운영 오버헤드를 크게 완화합니다."}}}
{"Question_Number": "Q130", "Question_Description": "어떤 애플리케이션이 여러 Availability Zone에 걸쳐 Amazon EC2 인스턴스에서 실행되고 있으며, 이들 인스턴스는 한 Application Load Balancer 뒤에 위치한 Amazon EC2 Auto Scaling group 내에 있습니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 약 40%일 때 최고의 성능을 발휘합니다. 솔루션스 아키텍트가 Auto Scaling group 내 모든 인스턴스에서 원하는 성능을 유지하기 위해서는 어떻게 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2"], "Keywords": ["Auto Scaling", "CPU 사용률 40%", "Application Load Balancer", "Amazon EC2"], "Terms": ["Amazon EC2", "Auto Scaling group", "Availability Zone", "Application Load Balancer", "CPU utilization", "AWS Lambda", "scheduled scaling"], "Commentary": "이 문제는 애플리케이션이 특정 CPU 사용률(약 40%)을 유지할 때 가장 효율적이라는 점에 주목하여, Auto Scaling group을 동적으로 조정하는 최적의 방법을 찾는 문제입니다. Target Tracking Scaling은 설정된 지표(여기서는 CPU 사용률)를 기준으로 자동으로 인스턴스 규모를 조정하므로, 정확한 목표 값을 유지하며 성능을 극대화할 수 있습니다.", "Selections": {"SelectA": {"Select": "simple scaling policy를 사용하여 Auto Scaling group을 동적으로 확장하도록 설정합니다.", "Commentary": "simple scaling policy는 한 번의 지표 평가 후 단순 규칙로 확장하거나 축소하지만, CPU 사용률을 일정하게 유지하기에는 유연성이 부족합니다."}, "SelectB": {"Select": "target tracking policy를 사용하여 Auto Scaling group을 동적으로 확장하도록 설정합니다.", "Commentary": "Target Tracking Scaling은 CPU 사용률 목표치를 40%로 설정하면 이를 자동으로 유지하도록 확장/축소를 수행하므로 문제 요구사항에 가장 적합합니다."}, "SelectC": {"Select": "AWS Lambda 함수를 사용하여 원하는 Auto Scaling group 용량을 업데이트합니다.", "Commentary": "Lambda 함수를 통해 직접 용량을 조정하면 추가적인 로직과 관리가 필요하여 실시간 유연 조정에 비효율적입니다."}, "SelectD": {"Select": "scheduled scaling을 사용하여 정해진 시간에 Auto Scaling group을 확장 및 축소합니다.", "Commentary": "스케줄 기반 확장은 CPU 사용률 변동에 실시간 대응이 어려워 필요 시점에 적절한 규모를 유지하기 어렵습니다."}}}
{"Question_Number": "Q131", "Question_Description": "한 회사가 파일 공유 애플리케이션을 개발 중이며, 이 애플리케이션은 Amazon S3 버킷을 스토리지로 사용할 예정입니다. 회사는 모든 파일을 Amazon CloudFront distribution을 통해 제공하고자 합니다. 또한 S3 URL로 직접 접근하는 것을 허용하고 싶지 않습니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["파일 공유 애플리케이션", "Amazon S3 버킷", "Amazon CloudFront distribution", "S3 URL 직접 접근 차단", "origin access identity (OAI)"], "Terms": ["Amazon S3", "Amazon CloudFront", "origin access identity (OAI)", "IAM", "S3 Bucket Policy", "Principal", "Amazon Resource Name (ARN)"], "Commentary": "이 문제는 S3 객체를 직접 URL로 접근할 수 없도록 보호하면서도 CloudFront를 통해 파일을 제공하는 아키텍처를 설계하는 방법을 묻습니다. 가장 효율적이자 권장되는 방식은 CloudFront의 origin access identity(OAI)를 생성하고, 이를 통해서만 S3 버킷에 대한 읽기 권한을 부여하여 S3 URL에 직접 접근이 불가능하게 만드는 것입니다.", "Selections": {"SelectA": {"Select": "각 S3 버킷에 대해 개별 정책을 작성하고, CloudFront에만 읽기 권한을 부여한다.", "Commentary": "CloudFront에서 버킷별로 정책을 따로 설정할 수 있지만, 버킷 정책이 복잡해지고 실수 가능성이 커 비효율적입니다."}, "SelectB": {"Select": "IAM 사용자를 생성하고, 해당 사용자에게 S3 버킷 객체에 대한 읽기 권한을 부여합니다. 그리고 CloudFront에 이 사용자를 할당합니다.", "Commentary": "CloudFront가 IAM 사용자 자격 증명을 직접 사용하는 방식은 일반적이지 않으며 보안 및 관리 측면에서도 권장되지 않습니다."}, "SelectC": {"Select": "S3 버킷 정책에서 CloudFront distribution ID를 Principal로 지정하고 대상 S3 버킷을 ARN으로 지정합니다.", "Commentary": "distribution ID만으로는 접근을 완전히 제어하기 어렵고, 추천되는 표준 접근 방식(Origin Access Identity)을 사용하지 않았습니다."}, "SelectD": {"Select": "origin access identity (OAI)를 생성하고, 이를 CloudFront distribution에 할당합니다. S3 버킷 권한을 OAI가 읽기 권한을 갖도록만 구성합니다.", "Commentary": "OAI를 통해 CloudFront만이 S3 버킷에 접근하도록 제한할 수 있어, 직접 S3 URL 접근을 차단하고 안전하게 콘텐츠를 제공하는 최적의 방법입니다."}}}
{"Question_Number": "Q132", "Question_Description": "회사의 웹사이트는 사용자에게 다운로드 가능한 과거 성능 보고서를 제공합니다. 이 웹사이트는 전 세계적으로 확장 가능해야 하며, 비용 효율적이고 인프라 리소스 프로비저닝을 최소화하면서 가능한 한 가장 빠른 응답 시간을 제공해야 합니다. 어떤 솔루션 조합을 사용하면 이 요구사항을 충족할 수 있습니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["글로벌 확장", "정적 콘텐츠", "비용 효율", "빠른 응답 시간", "Amazon CloudFront", "Amazon S3"], "Terms": ["Amazon CloudFront", "Amazon S3", "AWS Lambda", "Amazon DynamoDB", "Application Load Balancer", "Amazon EC2 Auto Scaling", "Amazon Route 53", "Internal Application Load Balancer"], "Commentary": "이 문제는 전 세계 사용자에게 정적 파일을 빠르고 효율적으로 제공하기 위한 최적의 방법을 묻습니다. Amazon CloudFront와 Amazon S3를 조합하면 글로벌 Edge Location을 통한 빠른 전송과 무제한 확장이 가능하여 최소 인프라로도 요구사항을 충족할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront와 Amazon S3를 사용합니다.", "Commentary": "정적 콘텐츠를 S3에 저장하고, CloudFront Edge Location을 통해 글로벌 사용자에게 빠르게 제공할 수 있어 비용과 운영 복잡도를 모두 줄이면서 매우 빠른 응답 시간을 얻을 수 있습니다."}, "SelectB": {"Select": "AWS Lambda와 Amazon DynamoDB를 사용합니다.", "Commentary": "Lambda+DynamoDB는 서버리스 환경이지만 정적 파일 전달에 적합하지 않으며, 대규모 다운로드 트래픽 처리에 불리합니다."}, "SelectC": {"Select": "Application Load Balancer와 Amazon EC2 Auto Scaling을 사용합니다.", "Commentary": "EC2 인스턴스 기반 확장은 정적 콘텐츠 제공에는 불필요하게 복잡하며, S3+CloudFront 대비 비용 효율과 글로벌 가속 측면이 떨어집니다."}, "SelectD": {"Select": "Amazon Route 53과 내부 Application Load Balancers를 사용합니다.", "Commentary": "내부 ALB는 내부 트래픽 처리용으로 적합하며, 전 세계 정적 파일 배포와는 직접적으로 연관이 없습니다."}}}
{"Question_Number": "Q133", "Question_Description": "한 회사가 온프레미스에서 Oracle 데이터베이스를 운영하고 있습니다. 회사의 AWS 마이그레이션의 일환으로, 해당 데이터베이스를 최신 버전으로 업그레이드하려고 합니다. 또한 데이터베이스에 대한 재해 복구(DR)도 설정해야 합니다. 회사는 운영 오버헤드를 최소화하면서 데이터베이스 기반 운영 체제에 대한 액세스를 유지하고 싶어 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Oracle 데이터베이스", "AWS 마이그레이션", "최신 버전 업그레이드", "DR", "운영 오버헤드", "OS 접근", "Amazon RDS Custom for Oracle"], "Terms": ["Amazon EC2", "Amazon RDS for Oracle", "Amazon RDS Custom for Oracle", "OS 접근", "Read Replica", "Cross-Region Automated Backups", "Standby Database", "DR", "온프레미스"], "Commentary": "이 문제는 온프레미스의 Oracle DB를 최신 버전으로 업그레이드함과 동시에 재해 복구 환경을 구축해야 합니다. 운영 오버헤드를 낮추고 OS 접근성을 유지하려면 Amazon RDS Custom for Oracle이 최적이며, 다른 리전에 Read Replica를 생성하면 DR을 쉽고 안정적으로 구성할 수 있습니다.", "Selections": {"SelectA": {"Select": "Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하고, 다른 AWS 리전에 데이터베이스 복제를 설정합니다.", "Commentary": "OS 접근이 가능하나, DR 구성과 패치·백업 등 전반적인 관리 부담이 커서 운영 오버헤드가 증가합니다."}, "SelectB": {"Select": "Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션하고, 자동화된 Cross-Region 백업을 활성화하여 다른 AWS 리전으로 스냅샷을 복제합니다.", "Commentary": "RDS 제공 기능으로 관리 오버헤드는 낮지만, OS 접근 권한을 제공하지 않으므로 요구 사항을 충족하지 못합니다."}, "SelectC": {"Select": "Oracle 데이터베이스를 Amazon RDS Custom for Oracle로 마이그레이션하고, 다른 AWS 리전에 데이터베이스의 Read Replica를 생성합니다.", "Commentary": "RDS Custom은 OS 접근 권한을 허용하며, DR을 위한 Read Replica 구성을 통해 운영 오버헤드를 낮추면서 재해 복구 요건도 충족합니다."}, "SelectD": {"Select": "Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션하고, 다른 가용 영역(AZ)에 대기(Standby) 데이터베이스를 생성합니다.", "Commentary": "Multi-AZ 대기는 같은 리전에 속해 있으므로 광역 재해에 대한 대비가 부족하고, OS 접근 또한 불가능합니다."}}}
{"Question_Number": "Q134", "Question_Description": "한 회사가 애플리케이션을 서버리스 솔루션으로 이전하려고 합니다. 서버리스 솔루션은 기존 및 신규 데이터를 SL을 사용하여 분석해야 합니다. 회사는 Amazon S3 버킷에 데이터를 저장하고 있으며, 이 데이터는 암호화를 필요로 하고, 다른 AWS Region으로 복제되어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["서버리스 솔루션", "기존 및 신규 데이터 분석", "암호화", "Amazon S3", "S3 Cross-Region Replication", "SSE-KMS", "SSE-S3", "Amazon Athena", "Amazon RDS"], "Terms": ["Amazon S3", "S3 Cross-Region Replication (CRR)", "AWS KMS multi-Region keys (SSE-KMS)", "Amazon S3 managed encryption keys (SSE-S3)", "Amazon Athena", "Amazon RDS"], "Commentary": "이 문제에서는 데이터를 Amazon S3에 두고, 암호화와 Cross-Region 복제를 동시에 충족해야 합니다. 또한 서버리스 방식으로 기존·신규 데이터를 분석하려면 관리 부담이 낮은 Amazon Athena 사용이 적합합니다. SSE-KMS는 추가적인 AWS KMS 설정이 필요해 오버헤드가 크지만, SSE-S3는 자동 관리가 가능해 운영 상 더 간편합니다.", "Selections": {"SelectA": {"Select": "새로운 S3 버킷을 생성 후 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 AWS KMS multi-Region keys (SSE-KMS)를 사용합니다. Amazon Athena로 데이터를 쿼리합니다.", "Commentary": "SSE-KMS 구성은 유연하지만 추가 설정이 필요해 운영 오버헤드가 늘어날 수 있습니다. 버킷도 새로 생성해야 하므로 최소 오버헤드 요건에 부합하지 않습니다."}, "SelectB": {"Select": "새로운 S3 버킷을 생성 후 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 AWS KMS multi-Region keys (SSE-KMS)를 사용합니다. Amazon RDS로 데이터를 쿼리합니다.", "Commentary": "이 옵션 역시 SSE-KMS 구성이 필요하고, 분석용으로 RDS를 사용하여 서버 관리를 직접 해야 하므로 서버리스 목표와 어긋납니다."}, "SelectC": {"Select": "기존 S3 버킷에 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 Amazon S3 managed encryption keys (SSE-S3)를 사용합니다. Amazon Athena로 데이터를 쿼리합니다.", "Commentary": "SSE-S3 사용 시 자동 키 관리를 통해 오버헤드가 적으며, Athena는 서버리스로 운영 부담이 낮습니다. Cross-Region Replication도 바로 구성 가능해 요구 사항을 가장 간단히 충족합니다."}, "SelectD": {"Select": "기존 S3 버킷에 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 Amazon S3 managed encryption keys (SSE-S3)를 사용합니다. Amazon RDS로 데이터를 쿼리합니다.", "Commentary": "SSE-S3는 간편하지만 RDS는 서버리스가 아니기 때문에 관리 오버헤드가 증가하고, Athena만큼 손쉽게 데이터를 분석하기 어렵습니다."}}}
{"Question_Number": "Q135", "Question_Description": "한 회사가 AWS에서 워크로드를 운영하고 있습니다. 외부 공급자의 service에 연결해야 합니다. 해당 service는 공급자의 VPC에 호스팅되어 있습니다. 회사 보안 팀은 연결이 사설로만 이루어져야 하고, 오직 target service에만 한정되어야 한다고 요구합니다. 또한 연결은 오직 회사의 VPC에서만 시작되어야 합니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["사설 연결", "target service 제한", "AWS PrivateLink", "VPC endpoint", "VPC Peering", "NAT Gateway"], "Terms": ["AWS PrivateLink", "VPC Peering", "NAT Gateway", "VPC Endpoint", "Virtual Private Gateway"], "Commentary": "이 문제는 외부 공급자의 VPC에 있는 target service에 대해 사설 연결을 구성해야 하는 상황입니다. VPC Peering은 광범위한 통신을 허용해 보안 요건을 만족하기 어렵고, NAT Gateway는 트래픽이 인터넷을 거쳐 이동하게 됩니다. 따라서 PrivateLink 기반의 VPC Endpoint를 사용하면 특정 service만 사설로 접근할 수 있고, 연결은 오직 회사 VPC에서 시작되므로 요구사항에 부합합니다.", "Selections": {"SelectA": {"Select": "회사의 VPC와 공급자의 VPC 간에 VPC peering connection을 생성하고, 라우팅 테이블을 수정하여 target service로 연결합니다.", "Commentary": "VPC Peering은 VPC 간의 양방향 연결을 제공합니다. target service만으로 트래픽을 한정하기 어려우며, 공급자 측에서의 접근 제한도 복잡해집니다."}, "SelectB": {"Select": "공급자에게 VPC 내에 virtual private gateway를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 target service에 연결합니다.", "Commentary": "Virtual private gateway는 일반적으로 site-to-site VPN 용도입니다. PrivateLink를 이용하려면 VPC Endpoint가 필요하며, 이 방식은 잘못된 구성입니다."}, "SelectC": {"Select": "회사의 VPC 퍼블릭 서브넷에 NAT Gateway를 생성하고, 라우팅 테이블을 수정하여 target service로 연결합니다.", "Commentary": "NAT Gateway를 통한 트래픽은 인터넷을 경유하게 됩니다. 이는 사설 연결 및 특정 service만으로 제한한다는 요건을 충족하지 않습니다."}, "SelectD": {"Select": "공급자에게 target service에 대한 VPC endpoint를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 target service에 연결합니다.", "Commentary": "AWS PrivateLink 기반의 VPC Endpoint를 사용하면 오직 지정된 service로만 사설 연결이 이루어지고, 연결이 회사 VPC에서만 시작되도록 보장할 수 있습니다."}}}
{"Question_Number": "Q136", "Question_Description": "한 회사가 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하려고 합니다. 마이그레이션 중에도 온프레미스 데이터베이스는 온라인 상태로 접근 가능해야 합니다. 또한 Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 작업 조합은 무엇입니까? (정답은 두 개를 고르십시오.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["온프레미스 PostgreSQL", "Amazon Aurora PostgreSQL", "AWS DMS", "온라인 상태", "동기화", "마이그레이션"], "Terms": ["AWS Database Migration Service (AWS DMS)", "Ongoing Replication Task", "AWS DMS Replication Server", "AWS Schema Conversion Tool (AWS SCT)", "Amazon EventBridge"], "Commentary": "AWS DMS를 사용하면 온프레미스 데이터베이스를 온라인 상태로 유지하면서 Aurora PostgreSQL과 실시간 동기화가 가능합니다. Replication Server를 생성하고 Ongoing Replication Task를 설정해 최소 다운타임으로 마이그레이션할 수 있습니다.", "Selections": {"SelectA": {"Select": "Create an ongoing replication task.", "Commentary": "DMS에서 지속적인 동기화를 수행하는 핵심 설정입니다. 온라인 상태로 데이터가 계속 복제되어 온프레미스와 Aurora 간 최신 상태를 유지합니다."}, "SelectB": {"Select": "Create a database backup of the on-premises database.", "Commentary": "백업은 단발성 작업이므로 실시간 동기화에는 적합하지 않습니다. 온라인 동작을 위한 지속적 업데이트 기능이 제공되지 않습니다."}, "SelectC": {"Select": "Create an AWS Database Migration Service (AWS DMS) replication server.", "Commentary": "DMS 동작에 필요한 컴퓨팅 리소스로, 원본·타깃 간 실시간 복제를 진행하려면 반드시 구성해야 하는 핵심 요소입니다."}, "SelectD": {"Select": "Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT).", "Commentary": "엔진 유형이 동일(동종 마이그레이션)인 경우 필수적이지 않을 수 있습니다. 필요 시 사용하지만 실시간 동기화 자체에는 영향이 적습니다."}, "SelectE": {"Select": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization.", "Commentary": "EventBridge 규칙은 이벤트 알림용으로, 실시간 데이터 복제를 해주지는 않습니다. 동기화 작업 자체와는 직접 관련이 없습니다."}}}
{"Question_Number": "Q137", "Question_Description": "한 회사는 AWS Organizations를 사용하여 각 사업부별로 전용 AWS account를 생성하여, 사업부 계정 요청 시 독립적으로 관리하고 있습니다. 어느 한 계정의 root user email 주소로 전송된 알림을 해당 root 사용자가 놓친 일이 있었고, 회사는 앞으로 모든 알림을 놓치지 않도록 하면서도 이러한 알림이 계정 관리자에게만 제한적으로 전달되기를 원합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["AWS Organizations", "AWS account", "root user email 주소", "account administrators", "distribution list", "alternate contact"], "Terms": ["AWS Organizations", "AWS account", "root user email address", "account administrators", "alternate contacts", "distribution list", "management account root user"], "Commentary": "이 문제는 root user email 주소로 갈 알림을 놓치지 않으면서도, 계정 관리자에게만 이메일이 전달되도록 모범적인 설정 방안을 묻습니다. 각 계정별로 distribution list를 두고 alternate contact를 설정하면, 중요한 알림이 제대로 전달되면서 오남용을 방지할 수 있어 요구사항을 만족합니다.", "Selections": {"SelectA": {"Select": "회사 이메일 서버를 구성하여 AWS account root user email address로 전송되는 알림 이메일을 조직의 모든 사용자에게 전달하도록 설정합니다.", "Commentary": "알림이 전체 조직에 전달되므로 계정 관리자에게만 제한된 전달이라는 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "모든 AWS account root user email 주소를 몇몇 관리자에게만 전달되는 distribution list로 구성하고, AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS account alternate contacts를 설정합니다.", "Commentary": "소수 관리자에게만 알림이 전달되고 alternate contact를 통해 추가적으로 관리할 수 있어, 알림 누락 없이 계정 관리자만 확인하도록 제한할 수 있는 가장 적합한 방법입니다."}, "SelectC": {"Select": "모든 AWS account root user email 메시지를 한 명의 관리자에게만 보내도록 구성하고, 이 관리자가 알림을 모니터링하여 적절한 그룹에 전달하도록 합니다.", "Commentary": "단일 관리자에게만 의존하면 알림 누락 위험이 높아지고, 적절한 담당자 구분이 복잡해집니다."}, "SelectD": {"Select": "모든 기존 AWS account와 새로 생성되는 계정이 동일한 root user email 주소를 사용하도록 설정합니다. 그리고 AWS Organizations 콘솔 또는 프로그래밍 방식을 통해 AWS account alternate contact를 구성합니다.", "Commentary": "모든 계정이 동일한 이메일을 사용하면 관리 범위가 과도하게 넓어지고, 계정별 관리자 제한 전달이라는 조건을 충족하기 어렵습니다."}}}
{"Question_Number": "Q138", "Question_Description": "한 회사는 AWS 상에서 전자상거래 애플리케이션을 운영하고 있습니다. 새로운 주문이 발생할 때마다 해당 주문은 단일 Availability Zone에서 실행 중인 Amazon EC2 인스턴스의 RabbitMQ queue에 메시지로 게시됩니다. 이 메시지들은 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션이 처리하며, 이 애플리케이션은 정보를 또 다른 EC2 인스턴스에 있는 PostgreSQL database에 저장합니다. 현재 모든 EC2 인스턴스는 동일한 Availability Zone에 있습니다. 회사는 높은 가용성과 최소한의 운영 오버헤드를 제공하도록 아키텍처를 재설계해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["RabbitMQ queue", "Amazon MQ", "Amazon RDS for PostgreSQL", "Multi-AZ", "Availability Zone", "운영 오버헤드", "고가용성", "Auto Scaling group", "PostgreSQL", "Amazon EC2"], "Terms": ["Amazon MQ", "RabbitMQ", "Auto Scaling group", "Multi-AZ", "Amazon RDS for PostgreSQL", "Amazon EC2", "Availability Zone", "PostgreSQL"], "Commentary": "이 문제는 RabbitMQ 메시지 처리와 PostgreSQL database를 사용하는 전자상거래 애플리케이션을 어떻게 고가용성과 낮은 운영 부담으로 재구성할지 묻습니다. Amazon MQ로 마이그레이션하면 Queue 운영 부담을 줄일 수 있고, Database를 Amazon RDS for PostgreSQL Multi-AZ로 이전하면 관리가 간소화되면서도 가용성을 높일 수 있습니다. 따라서 큐와 DB 모두 완전관리형 혹은 최소 관리로 전환해 운영 오버헤드를 최소화하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "Amazon MQ에서 RabbitMQ를 active/standby로 구성된 이중화 인스턴스로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. PostgreSQL database를 호스팅하는 다른 EC2 인스턴스에도 Multi-AZ Auto Scaling group을 생성합니다.", "Commentary": "Database를 직접 EC2에 Multi-AZ로 구성하면 운영 측면에서 여전히 부담이 높습니다."}, "SelectB": {"Select": "Amazon MQ에서 RabbitMQ를 active/standby로 구성된 이중화 인스턴스로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. Database를 Multi-AZ Amazon RDS for PostgreSQL로 마이그레이션합니다.", "Commentary": "큐와 DB 모두 완전관리형 또는 최소한의 관리로 구성해 고가용성과 낮은 운영 오버헤드를 확보하는 최적의 솔루션입니다."}, "SelectC": {"Select": "RabbitMQ queue를 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. 애플리케이션을 호스팅하는 다른 EC2 인스턴스에도 Multi-AZ Auto Scaling group을 생성합니다. Database는 Multi-AZ Amazon RDS for PostgreSQL로 마이그레이션합니다.", "Commentary": "RabbitMQ를 직접 EC2에서 Multi-AZ로 운영하면 관리가 복잡해지고, 오버헤드가 큽니다."}, "SelectD": {"Select": "RabbitMQ queue를 호스팅하는 EC2 인스턴스, 애플리케이션을 호스팅하는 EC2 인스턴스, PostgreSQL database를 호스팅하는 EC2 인스턴스 각각에 대해 모두 Multi-AZ Auto Scaling group을 생성합니다.", "Commentary": "큐와 DB 모두 EC2 기반 Multi-AZ로 구성하면 운영 부담이 크고 관리가 복잡해집니다."}}}
{"Question_Number": "Q139", "Question_Description": "보고 팀은 매일 Amazon S3 버킷에 업로드되는 파일들을 수령합니다. 현재는 보고 팀이 매일 같은 시각에 이 초기 S3 버킷에서 파일을 검토하고, Amazon QuickSight에 활용하기 위해 분석용 S3 버킷으로 수동 복사하고 있습니다. 하지만 추가 팀들이 더 많은 용량의 파일들을 초기 S3 버킷으로 전송하기 시작했습니다. 보고 팀은 파일이 초기 S3 버킷에 업로드되는 즉시 자동으로 분석용 S3 버킷에 복사되도록 원합니다. 또한 AWS Lambda 함수를 이용해 복사된 데이터에 대해 패턴 매칭 코드를 실행하고 싶으며, 파일들을 Amazon SageMaker Pipelines에도 전달하기를 원합니다. 최소한의 운영 오버헤드로 이를 만족하려면 어떤 솔루션을 구현해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["분석용 S3 버킷 자동 복사", "AWS Lambda 패턴 매칭", "S3 Replication", "Amazon SageMaker Pipelines", "최소 운영 오버헤드"], "Terms": ["Amazon S3", "S3 Replication", "AWS Lambda", "Amazon SageMaker Pipelines", "Amazon EventBridge (Amazon CloudWatch Events)", "S3 이벤트 알림", "s3:ObjectCreated:Put"], "Commentary": "S3 Replication을 사용하면 초기 S3 버킷에서 분석용 S3 버킷으로 파일 복사를 자동화할 수 있어 운영 부담이 크게 줄어듭니다. 또한 분석용 버킷에서의 객체 생성 이벤트를 Amazon EventBridge와 연계하면 Lambda로 패턴 매칭 함수를 호출하고 SageMaker Pipelines로 데이터를 전달할 수 있어 가장 간단하고 확장성이 뛰어납니다.", "Selections": {"SelectA": {"Select": "Lambda 함수를 생성하여 파일을 분석용 S3 버킷으로 복사합니다. 분석용 S3 버킷에 S3 이벤트 알림을 설정하고, Lambda와 SageMaker Pipelines를 이벤트 알림 대상으로 구성합니다. 이벤트 유형은 s3:ObjectCreated:Put으로 설정합니다.", "Commentary": "Lambda로 수동 복사 과정을 대체하지만, 복제 로직을 직접 유지·관리해야 하므로 운영 오버헤드가 높아집니다."}, "SelectB": {"Select": "Lambda 함수를 만들어 파일을 분석용 S3 버킷으로 복사합니다. 분석용 S3 버킷에서 Amazon EventBridge(CloudWatch Events)로 이벤트 알림을 보내도록 설정합니다. EventBridge(CloudWatch Events)에 ObjectCreated 규칙을 생성하고, Lambda와 SageMaker Pipelines를 대상으로 구성합니다.", "Commentary": "A와 마찬가지로 파일 복사를 Lambda가 직접 처리해야 하므로, 코드를 유지·관리하는 부담이 여전히 큽니다."}, "SelectC": {"Select": "두 S3 버킷 간에 S3 Replication을 구성합니다. 분석용 S3 버킷에 S3 이벤트 알림을 설정하여 Lambda와 SageMaker Pipelines를 이벤트 대상로 구성하고, 이벤트 유형은 s3:ObjectCreated:Put으로 설정합니다.", "Commentary": "파일 복사는 자동화되지만 S3 이벤트 알림에서 SageMaker Pipelines를 직접 대상으로 삼기가 번거로울 수 있습니다. 다른 AWS 서비스 중개가 필요해 추가 설정이 늘어날 수 있습니다."}, "SelectD": {"Select": "두 S3 버킷 간에 S3 Replication을 구성합니다. 분석용 S3 버킷에서 Amazon EventBridge(CloudWatch Events)로 이벤트 알림을 보내도록 설정합니다. EventBridge(CloudWatch Events)에서 ObjectCreated 규칙을 생성하고, Lambda와 SageMaker Pipelines를 대상으로 구성합니다.", "Commentary": "S3 Replication으로 파일 복사를 자동화하고, EventBridge로 이벤트를 중앙에서 처리하여 Lambda와 SageMaker Pipelines를 유연하게 호출할 수 있습니다. 운영 오버헤드가 가장 적고 확장성도 뛰어납니다."}}}
{"Question_Number": "Q140", "Question_Description": "한 솔루션스 아키텍트가 AWS 상에서 애플리케이션을 실행하는 비용을 최적화하도록 회사에 조언해야 합니다. 이 애플리케이션은 Amazon EC2, AWS Fargate, AWS Lambda를 사용합니다. EC2 인스턴스는 데이터 수집 계층을 실행하며 사용량이 산발적이고 예측할 수 없습니다. 해당 워크로드는 언제든 중단될 수 있습니다. 애플리케이션의 프런트엔드는 Fargate에서 실행되고, Lambda는 API 계층을 제공합니다. 프런트엔드와 API 계층의 사용량은 향후 1년 동안 예측 가능합니다. 이 애플리케이션을 가장 비용 효율적으로 호스팅하기 위해 어떤 구매 옵션 조합을 사용해야 합니까? (2개를 선택하세요)", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["비용 최적화", "EC2", "Fargate", "Lambda", "Spot Instances", "Compute Savings Plan"], "Terms": ["Amazon EC2", "AWS Fargate", "AWS Lambda", "Spot Instances", "On-Demand Instances", "Compute Savings Plan", "EC2 instance Savings Plan", "All Upfront Reserved Instances"], "Commentary": "이 문제는 산발적이고 예측 불가능한 워크로드와 예측 가능한 워크로드를 분리해 비용 최적화 전략을 찾는 것입니다. 데이터 수집 계층에는 Spot을 활용하여 비용을 절감하고, 예측 가능한 Fargate와 Lambda에는 Compute Savings Plan을 적용해 최대한 유연성을 확보하면서 비용 효율을 높일 수 있습니다.", "Selections": {"SelectA": {"Select": "데이터 수집 계층에 Spot Instances를 사용합니다.", "Commentary": "Spot Instances는 필요 시 언제든 중단될 수 있는 불규칙적 워크로드에 매우 저렴하게 적합합니다."}, "SelectB": {"Select": "데이터 수집 계층에 On-Demand Instances를 사용합니다.", "Commentary": "On-Demand Instances는 유연하지만 비용이 더 높아, 산발적인 워크로드에는 비효율적입니다."}, "SelectC": {"Select": "프런트엔드와 API 계층에 1년 Compute Savings Plan을 구매합니다.", "Commentary": "Compute Savings Plan은 Fargate, Lambda, 그리고 EC2 모든 서비스에 적용되므로 예측 가능한 워크로드에 효과적입니다."}, "SelectD": {"Select": "데이터 수집 계층에 1년 All Upfront Reserved Instances를 구매합니다.", "Commentary": "Reserved Instances는 예측 불가능한 워크로드에 적합하지 않고, 중단 위험이 큰 환경에서 유연성이 떨어집니다."}, "SelectE": {"Select": "프런트엔드와 API 계층에 1년 EC2 instance Savings Plan을 구매합니다.", "Commentary": "EC2 instance Savings Plan은 EC2 인스턴스에만 적용되어 Fargate와 Lambda에서는 혜택을 받지 못합니다."}}}
{"Question_Number": "Q141", "Question_Description": "한 회사가 전 세계 사용자들에게 글로벌 속보, 지역 알림, 날씨 업데이트를 제공하는 웹 기반 포털을 운영합니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합해 각 사용자에게 맞춤화된 화면을 제공합니다. 콘텐츠는 Application Load Balancer(ALB) 뒤에서 동작하는 Amazon EC2 인스턴스 상의 API 서버를 통해 HTTPS로 제공됩니다. 회사는 전 세계 모든 사용자에게 가능한 한 지연 없이 빠른 콘텐츠 제공을 원합니다. 가장 낮은 지연 시간을 보장하기 위해 솔루션스 아키텍트는 애플리케이션을 어떻게 설계해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["전 세계 사용자", "정적 콘텐츠", "동적 콘텐츠", "낮은 지연 시간", "Application Load Balancer", "Amazon CloudFront"], "Terms": ["Amazon CloudFront", "Application Load Balancer (ALB)", "Amazon EC2", "Amazon Route 53", "latency routing policy", "geolocation routing policy", "AWS Region", "HTTPS"], "Commentary": "이 문제는 전 세계 대상으로 개인화된 정적·동적 콘텐츠를 빠르게 제공해야 하는 상황에서, 지연 시간을 최소화하는 네트워크 아키텍처를 설계하는 방법을 묻습니다. Amazon CloudFront는 정적 및 동적 콘텐츠 전송 시 Edge Location을 통해 전 세계 곳곳에서 발생하는 요청에 대해 빠른 응답을 제공합니다. ALB를 직접 오리진으로 두면 동적 콘텐츠도 CloudFront 배포를 통해 캐시 이점과 네트워크 가속을 누릴 수 있어 최소 지연 응답이 가능합니다. 따라서 단일 Region에 배포하고 CloudFront를 활용하는 구성이 가장 효율적입니다.", "Selections": {"SelectA": {"Select": "AWS 리전 하나에 애플리케이션 스택을 배포하고, ALB를 origin으로 설정한 Amazon CloudFront를 통해 모든 정적 및 동적 콘텐츠를 서빙합니다.", "Commentary": "전 세계 Edge Location을 활용해 모든 콘텐츠를 빠르고 일관되게 제공하는 최적의 솔루션입니다."}, "SelectB": {"Select": "애플리케이션 스택을 두 개의 AWS 리전에 배포하고, Amazon Route 53 latency routing policy를 사용해 가장 가까운 리전의 ALB에서 콘텐츠를 제공하도록 합니다.", "Commentary": "복수 리전 배포로 글로벌 성능을 높일 수 있지만, 관리 복잡성이 증가하고 CloudFront의 광범위한 캐싱 및 가속 이점을 활용하지 못해 A보다 효율이 낮습니다."}, "SelectC": {"Select": "애플리케이션 스택을 단일 AWS 리전에 배포하고, 정적 콘텐츠는 Amazon CloudFront로, 동적 콘텐츠는 ALB에서 직접 서빙합니다.", "Commentary": "동적 콘텐츠의 지연이 증가할 수 있어 최소 지연을 보장하기 어렵습니다."}, "SelectD": {"Select": "애플리케이션 스택을 두 개의 AWS 리전에 배포하고, Amazon Route 53 geolocation routing policy를 사용해 가장 가까운 리전의 ALB에서 모든 콘텐츠를 제공합니다.", "Commentary": "지리적 정책은 특정 국가 또는 지역별 라우팅에 유용하지만, 네트워크 지연을 최적으로 줄이지 못해 A보다 성능이 떨어집니다."}}}
{"Question_Number": "Q142", "Question_Description": "한 게임 회사가 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 동작하며 UDP 기반 트래픽만 지원합니다. 회사는 프론트엔드 계층이 가능한 최고의 사용자 경험을 제공하기를 원합니다. 이 계층은 지연 시간이 낮아야 하며, 가장 가까운 엣지 로케이션으로 트래픽을 라우팅해야 하고, 애플리케이션 엔드포인트에 진입하기 위한 고정 IP 주소를 제공해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2", "3.4"], "Keywords": ["고가용성 아키텍처", "UDP 기반 트래픽", "지연 시간 최소화", "엣지 로케이션", "고정 IP 주소", "AWS Global Accelerator", "Network Load Balancer", "Amazon EC2", "EC2 Auto Scaling"], "Terms": ["AWS Global Accelerator", "Amazon CloudFront", "Amazon EC2", "EC2 Auto Scaling", "Network Load Balancer", "Application Load Balancer", "Amazon Route 53", "AWS Lambda", "AWS Application Auto Scaling", "Amazon API Gateway"], "Commentary": "이 문제는 UDP 트래픽을 지원하는 게임 애플리케이션을 전 세계적으로 빠르고 안정적으로 서비스하기 위해 어떤 프론트엔드 구성을 사용해야 하는지를 묻습니다. AWS Global Accelerator는 UDP 같은 비 HTTP 트래픽에도 최적화되어 있고, 전용 엣지 네트워크를 통해 트래픽을 가장 가까운 리전으로 라우팅하며, 고정 IP 주소를 제공할 수 있어 요구사항을 가장 잘 충족합니다.", "Selections": {"SelectA": {"Select": "Amazon Route 53을 구성하여 요청을 Application Load Balancer로 포워딩합니다. AWS Lambda를 AWS Application Auto Scaling에서 애플리케이션으로 사용합니다.", "Commentary": "Application Load Balancer는 HTTP/HTTPS를 주로 처리하고 UDP 트래픽을 직접 지원하지 않으므로 적절하지 않습니다."}, "SelectB": {"Select": "Amazon CloudFront를 구성하여 요청을 Network Load Balancer로 포워딩합니다. AWS Lambda를 AWS Application Auto Scaling 그룹에서 애플리케이션으로 사용합니다.", "Commentary": "CloudFront는 주로 HTTP 기반 콘텐츠 캐싱과 전달에 최적화되어 있어 UDP 트래픽 및 고정 IP 제공 측면에서 부적합합니다."}, "SelectC": {"Select": "AWS Global Accelerator를 구성하여 요청을 Network Load Balancer로 포워딩합니다. 애플리케이션에는 EC2 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다.", "Commentary": "AWS Global Accelerator가 UDP 트래픽, 고정 IP, 지연 시간 최소화를 모두 지원해 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "Amazon API Gateway를 구성하여 요청을 Application Load Balancer로 포워딩합니다. 애플리케이션에는 EC2 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다.", "Commentary": "API Gateway는 REST 또는 WebSocket 등 HTTP 기반 API 호출에 최적화되어 있어 UDP 트래픽에는 적합하지 않습니다."}}}
{"Question_Number": "Q143", "Question_Description": "한 회사가 기존의 온프레미스 모놀리식(monolithic) 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 회사는 기존 프론트엔드 코드와 백엔드 코드를 최대한 유지하면서, 애플리케이션을 더 작은 규모의 애플리케이션들로 분할하고자 합니다. 각 애플리케이션은 서로 다른 팀에서 관리할 예정입니다. 또한 높은 확장성을 갖추고 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2"], "Keywords": ["모놀리식 애플리케이션", "AWS 마이그레이션", "Amazon ECS", "마이크로서비스", "운영 오버헤드 최소화"], "Terms": ["AWS Lambda", "Amazon API Gateway", "AWS Amplify", "Amazon EC2", "Application Load Balancer", "Auto Scaling group", "Amazon Elastic Container Service (Amazon ECS)"], "Commentary": "이 문제는 기존 모놀리식 애플리케이션을 분할해 각 팀이 관리 가능하도록 마이크로서비스 형태로 전환하면서, 높은 확장성과 낮은 운영 부담을 원하는 시나리오입니다. Amazon ECS를 사용하면 컨테이너로 각각의 서비스를 분리해 관리가 용이하며, Application Load Balancer와 결합해 탄력적인 확장이 가능합니다.", "Selections": {"SelectA": {"Select": "AWS Lambda에서 애플리케이션을 호스팅하고, Amazon API Gateway와 연동합니다.", "Commentary": "서버리스 환경이지만, 기존 코드를 크게 수정해야 할 수 있고, 모놀리식 구조를 그대로 유지하기에는 Lambda로의 전체 마이그레이션이 복잡할 수 있습니다."}, "SelectB": {"Select": "AWS Amplify로 애플리케이션을 호스팅하고, Amazon API Gateway와 연동된 AWS Lambda에 연결합니다.", "Commentary": "Amplify는 프론트엔드 호스팅에 적합하지만, 이미 완성된 백엔드를 크게 분할하기에는 제약이 많아 전체 요구사항을 만족하기 어렵습니다."}, "SelectC": {"Select": "Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Application Load Balancer와 Auto Scaling group으로 구성합니다.", "Commentary": "EC2 기반 구성은 직접 서버를 관리해야 하므로 운영 오버헤드가 높으며, 마이크로서비스로 자유롭게 분할하기에도 관리 부담이 큽니다."}, "SelectD": {"Select": "Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Application Load Balancer를 Amazon ECS 대상 그룹으로 설정합니다.", "Commentary": "컨테이너 기반으로 각 서비스를 분리해 팀별 관리가 가능하며, ECS가 인프라 관리를 상당 부분 자동화하여 확장성과 운영 편의성을 모두 확보할 수 있습니다."}}, "Reference": "‘monolithic’을 ‘microservices’로 전환 시 Amazon ECS 사용이 흔히 추천됩니다."}
{"Question_Number": "Q144", "Question_Description": "한 회사가 글로벌 eCommerce 애플리케이션의 데이터 스토어로 Amazon Aurora를 사용하기 시작했습니다. 대규모 리포트를 실행할 때 개발자들은 eCommerce 애플리케이션이 성능 저하를 겪고 있다고 보고했습니다. Amazon CloudWatch의 지표를 살펴본 결과, 월간 리포트가 실행될 때 ReadIOPS와 CPUUtilization 지표가 급증한다는 사실을 솔루션스 아키텍트가 확인했습니다. 가장 비용 효율적인 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["글로벌 eCommerce 애플리케이션", "Amazon Aurora", "월간 리포트", "성능 저하", "비용 효율", "Aurora Replica"], "Terms": ["Amazon Aurora", "Amazon Redshift", "Aurora Replica", "Amazon CloudWatch", "ReadIOPS", "CPUUtilization", "Provisioned IOPS", "DB instance class"], "Commentary": "이 문제는 월간 리포트 실행 시 발생하는 높은 읽기 부하로 인해 Aurora 메인 DB에 성능 저하가 일어나는 상황을 해결하면서도 비용 효율을 달성해야 하는 시나리오입니다. Aurora Replica를 활용하면 보고서 트래픽을 오프로딩해 메인 DB의 부하를 줄이면서 추가적인 인프라나 IOPS 비용을 과도하게 발생시키지 않아, 가장 합리적인 선택입니다.", "Selections": {"SelectA": {"Select": "월간 리포팅을 Amazon Redshift로 마이그레이션합니다.", "Commentary": "데이터 웨어하우스 솔루션이지만 마이그레이션과 운영 복잡도가 높고, 규모에 따라 추가 비용이 발생할 수 있어 가장 비용 효율적이지 않습니다."}, "SelectB": {"Select": "월간 리포팅을 Aurora Replica로 마이그레이션합니다.", "Commentary": "리포트 실행 시 읽기 부하를 Replica로 분산해 메인 DB 성능 저하를 최소화하고, 필요한 만큼만 용량을 확장해 비용 효율을 높입니다."}, "SelectC": {"Select": "Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다.", "Commentary": "즉각적인 성능 향상을 기대할 수 있으나, 인스턴스 비용이 지속해서 증가하여 장기적으로는 비용 효율적이지 않습니다."}, "SelectD": {"Select": "Aurora 인스턴스의 Provisioned IOPS를 증가시킵니다.", "Commentary": "IO 성능은 향상되지만 CPUUtilization 문제는 여전히 남을 수 있으며, 프로비저닝된 IOPS 비용이 높아질 수 있습니다."}}}
{"Question_Number": "Q145", "Question_Description": "한 회사가 웹사이트 분석 애플리케이션을 단일 Amazon EC2 On-Demand Instance에서 호스팅하고 있습니다. 이 분석 소프트웨어는 PHP로 작성되었으며, MySQL 데이터베이스를 사용합니다. PHP를 제공하는 웹 서버와 데이터베이스 서버 모두 EC2 인스턴스 안에 함께 배포되어 있습니다. 현재 애플리케이션은 트래픽이 많은 시간대에 성능 저하와 5xx 오류를 보이고 있으며, 회사는 애플리케이션이 끊김 없이 확장되도록 만들고자 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["EC2 On-Demand Instance", "Amazon Aurora MySQL DB instance", "AMI", "Auto Scaling group", "Spot Fleet", "Application Load Balancer", "비용 효율", "5xx 오류", "무중단 확장"], "Terms": ["Amazon EC2 On-Demand Instance", "MySQL", "Amazon RDS for MySQL", "Amazon Aurora MySQL", "PHP", "Application Load Balancer", "AWS Lambda", "Amazon CloudWatch alarm", "AMIs", "Auto Scaling group", "Spot Fleet", "Amazon Route 53"], "Commentary": "이 문제는 단일 EC2 인스턴스에 모든 구성 요소가 모노리틱하게 배포되어 생기는 확장 한계를 해결하고, 트래픽 급증 시 발생하는 성능 저하와 5xx 오류를 방지하려는 상황입니다. 데이터베이스를 Amazon Aurora MySQL로 분리해 성능을 높이고, Auto Scaling group과 Spot Fleet을 활용하여 무중단으로 인스턴스를 확장·축소함으로써 비용 효율성과 확장성을 동시에 달성하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "데이터베이스를 Amazon RDS for MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션을 AMI로 생성한 뒤 두 번째 EC2 On-Demand Instance를 시작합니다. Application Load Balancer로 각 EC2 인스턴스에 부하를 분산합니다.", "Commentary": "RDS로 DB를 이전하고 인스턴스를 2대로 늘려도 자동 확장이 어렵고 On-Demand만 이용해 비용 면에서 최적이 아닙니다."}, "SelectB": {"Select": "데이터베이스를 Amazon RDS for MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션을 AMI로 생성한 뒤 두 번째 EC2 On-Demand Instance를 시작합니다. Amazon Route 53 가중 라우팅을 사용해 두 EC2 인스턴스 간 트래픽을 분산합니다.", "Commentary": "가중 라우팅으로 부하를 분산하지만 Auto Scaling 지원이 없어 사용량 증감 시 유연한 확장이 어렵습니다."}, "SelectC": {"Select": "데이터베이스를 Amazon Aurora MySQL DB instance로 마이그레이션합니다. AWS Lambda 함수를 작성해 EC2 인스턴스를 정지 후 인스턴스 유형을 변경하도록 합니다. CPU 사용률이 75%를 초과하면 Amazon CloudWatch alarm으로 Lambda 함수를 호출합니다.", "Commentary": "수동에 가까운 인스턴스 유형 변경 방식이라 실시간 트래픽 증가에 부하 대응이 원활하지 않고 운영 부담이 큽니다."}, "SelectD": {"Select": "데이터베이스를 Amazon Aurora MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션 AMI를 생성한 뒤 Launch Template에 적용합니다. 해당 Launch Template로 Auto Scaling group을 구성하고 Spot Fleet을 사용하도록 설정합니다. Application Load Balancer를 Auto Scaling group에 연결합니다.", "Commentary": "Aurora로 DB를 분리해 성능을 확보하고, Spot Fleet 및 Auto Scaling으로 무중단 확장과 비용 효율을 동시에 달성하는 최적의 방법입니다."}}}
{"Question_Number": "Q146", "Question_Description": "회사는 Application Load Balancer 뒤에 Amazon EC2 On-Demand Instances 그룹에서 무상태 웹 애플리케이션을 프로덕션으로 운영하고 있습니다. 애플리케이션은 매 영업일에 8시간 동안 높은 사용량을 기록하고, 야간에는 보통 수준의 일정한 사용량을 유지하며, 주말에는 낮은 사용량을 보입니다. 회사는 애플리케이션 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["비용 최소화", "애플리케이션 가용성", "EC2", "Spot Instances", "Reserved Instances", "On-Demand Instances"], "Terms": ["Amazon EC2 On-Demand Instances", "Reserved Instances", "Spot Instances", "Dedicated Instances", "Application Load Balancer", "Stateless Web Application"], "Commentary": "이 문제는 수요가 크게 변동하는 웹 애플리케이션 환경에서 비용을 절감하면서 가용성을 유지하는 방법을 묻습니다. 기본 사용량은 Reserved Instances로 확보하고, 추가 수요는 Spot Instances로 처리함으로써 예측 가능한 운영 비용 절감과 높은 가용성을 모두 달성할 수 있습니다.", "Selections": {"SelectA": {"Select": "전체 워크로드를 Spot Instances로 사용합니다.", "Commentary": "Spot 용량은 회수될 수 있어 가용성을 보장하기 어렵고, 고정적으로 필요한 사용량을 덮기에는 위험도가 높아 적합하지 않습니다."}, "SelectB": {"Select": "기본적인 사용량 수준에 대해서는 Reserved Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 Spot Instances를 사용합니다.", "Commentary": "기본적으로 일정량의 사용량을 안정적으로 확보하면서도 필요 시 Spot Instances로 유연하게 대처하여 비용 최적화와 가용성을 모두 달성할 수 있으므로 적합한 솔루션입니다."}, "SelectC": {"Select": "기본적인 사용량 수준에 대해서는 On-Demand Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 Spot Instances를 사용합니다.", "Commentary": "On-Demand Instances만으로 기본 사용량을 처리하면 비용 절감이 제한적입니다. Reserved Instances보다 상대적으로 비용이 높아 최적의 방법은 아닙니다."}, "SelectD": {"Select": "기본적인 사용량 수준에 대해서는 Dedicated Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 On-Demand Instances를 사용합니다.", "Commentary": "Dedicated Instances는 물리적 서버 전용 사용으로 비용이 높아 기본 사용량을 처리하기에 비효율적이며, 전반적인 비용 절감에 부적합합니다."}}}
{"Question_Number": "Q147", "Question_Description": "한 회사에서 중요한 애플리케이션의 로그 파일을 10년 동안 보관해야 합니다. 이 애플리케이션 팀은 최근 1개월 이내의 로그는 자주 문제 해결을 위해 접근하지만, 1개월이 지난 로그는 거의 접근하지 않습니다. 애플리케이션은 매달 10TB 이상의 로그를 생성합니다. 비용 효율성을 최대화하면서 이러한 요구 사항을 충족시키는 스토리지 옵션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["로그 보관", "10년 보관", "코스트 최적화", "한 달 지난 로그", "저장 비용"], "Terms": ["Amazon S3", "AWS Backup", "S3 Glacier Deep Archive", "S3 Lifecycle policy", "Amazon CloudWatch Logs"], "Commentary": "이 문제는 주로 월간 10TB 규모의 방대한 로그를 10년 동안 보존하는 동시에 최근 한 달간은 빈번히 조회되는 특성을 고려한 방법을 묻습니다. S3 Lifecycle policy를 활용하면 오래된 로그를 저비용 스토리지인 S3 Glacier Deep Archive로 자동 전환하여 운영 과정과 비용을 모두 효율화할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon S3에 로그를 저장하고, 1개월 지난 로그는 AWS Backup을 사용하여 S3 Glacier Deep Archive로 이동합니다.", "Commentary": "AWS Backup은 S3 Glacier Deep Archive 직접 전환을 지원하지 않으므로 요구 사항을 충족하기 어렵습니다."}, "SelectB": {"Select": "Amazon S3에 로그를 저장하고, S3 Lifecycle policy를 통해 1개월 지난 로그를 S3 Glacier Deep Archive로 이동합니다.", "Commentary": "S3 Lifecycle policy로 자동 전환을 설정하면 장기 보관 비용이 크게 절감되고 운영 부담도 최소화되어 가장 적합한 솔루션입니다."}, "SelectC": {"Select": "Amazon CloudWatch Logs에 로그를 저장하고, 1개월 지난 로그는 AWS Backup을 사용하여 S3 Glacier Deep Archive로 이동합니다.", "Commentary": "AWS Backup이 CloudWatch Logs에 직접 적용되지 않으며, Glacier Deep Archive 전환을 지원하지 않아 비효율적입니다."}, "SelectD": {"Select": "Amazon CloudWatch Logs에 로그를 저장하고, Amazon S3 Lifecycle policy를 사용하여 1개월 지난 로그를 S3 Glacier Deep Archive로 이동합니다.", "Commentary": "CloudWatch Logs에서 직접 S3 Lifecycle policy를 설정할 수 없으므로 요구 사항을 만족하지 못합니다."}}}
{"Question_Number": "Q148", "Question_Description": "한 회사는 다음과 같은 컴포넌트로 구성된 데이터 수집 워크플로우를 사용하고 있습니다:\n1) 새로운 데이터가 도착했을 때 알림을 받는 Amazon Simple Notification Service(Amazon SNS) topic\n2) 데이터를 처리하고 저장하는 AWS Lambda function\n\n해당 워크플로우는 가끔 네트워크 연결 문제로 인해 실패가 발생합니다. 한 번 실패가 발생하면, 회사가 수동으로 작업을 재실행하지 않는 이상 데이터가 수집되지 않습니다. 모든 알림이 최종적으로 처리되도록 하려면 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["네트워크 연결 문제", "데이터 수집 실패", "모든 알림 최종 처리", "on-failure 대상", "SQS 큐"], "Terms": ["Amazon SNS", "AWS Lambda", "Amazon SQS", "on-failure destination", "SNS topic’s retry strategy", "네트워크 연결 문제"], "Commentary": "이 문제는 일시적인 네트워크 장애가 발생했을 때도 데이터가 유실되지 않도록 알림을 안정적으로 처리하는 방법에 대한 것입니다. SNS에서 Lambda로 직접 전달이 실패했을 때 재시도 또는 보조 경로가 필요합니다. Amazon SQS 큐를 on-failure 대상(DLQ)으로 구성하면 재처리를 자동화하여 모든 알림이 결국 처리되도록 보장할 수 있습니다.", "Selections": {"SelectA": {"Select": "Lambda function을 여러 가용 영역에 배포하도록 구성합니다.", "Commentary": "Lambda function 자체의 고가용성을 높이지만, 네트워크 문제로 인한 처리 누락을 막지는 못하므로 적절한 해법이 아닙니다."}, "SelectB": {"Select": "Lambda function 설정을 수정하여 CPU와 메모리 할당량을 늘립니다.", "Commentary": "더 많은 리소스를 할당해도 네트워크 장애로 인해 호출 자체가 실패하면 데이터를 재처리할 방법이 없으므로 효과적이지 않습니다."}, "SelectC": {"Select": "SNS topic의 재시도 전략을 구성하여 재시도 횟수와 재시도 간 대기 시간을 늘립니다.", "Commentary": "일정 횟수 이상 실패 시 장기 보관 및 추후 재처리가 어려울 수 있으므로, 근본적으로 알림을 모아두고 재처리할 보조 경로(DLQ)가 필요합니다."}, "SelectD": {"Select": "Amazon Simple Queue Service(Amazon SQS) 큐를 on-failure 대상으로 구성하고, Lambda function이 해당 큐에 있는 메시지를 처리하도록 수정합니다.", "Commentary": "SNS에서 Lambda 호출이 실패하면 알림이 SQS 큐에 쌓여 재처리할 수 있으므로 결국 모든 알림을 놓치지 않고 처리할 수 있는 가장 안정적인 방법입니다."}}}
{"Question_Number": "Q149", "Question_Description": "한 회사에는 이벤트 데이터를 생성하는 서비스가 있습니다. 이 회사는 수신되는 즉시 AWS를 통해 이벤트 데이터를 처리하고자 합니다. 데이터는 특정 순서로 작성되며, 이 순서를 처리 전 과정에서 반드시 유지해야 합니다. 회사는 운영 오버헤드를 최소화할 수 있는 솔루션을 구현하고자 합니다. 솔루션스 아키텍트는 이를 어떻게 달성해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["이벤트 데이터", "FIFO 큐", "메시지 순서 유지", "운영 오버헤드 최소화", "Lambda"], "Terms": ["Amazon SQS FIFO queue", "Amazon SQS standard queue", "Amazon SNS topic", "AWS Lambda", "메시지 순서 보장"], "Commentary": "이 문제는 이벤트 데이터가 작성된 순서를 반드시 지켜야 하며 운영을 단순화해야 하는 상황입니다. Amazon SQS FIFO 큐는 메시지 순서를 보장하고, AWS Lambda를 사용하면 서버 관리 없이 메시지를 자동으로 처리할 수 있어 운영 오버헤드가 최소화됩니다.", "Selections": {"SelectA": {"Select": "Amazon Simple Queue Service(Amazon SQS) FIFO 큐를 생성해 메시지를 저장합니다. 그리고 AWS Lambda 함수를 설정해 해당 큐에서 메시지를 처리하도록 합니다.", "Commentary": "FIFO 큐는 순서를 보장하며, Lambda로 자동 처리하면 운영이 간단해집니다. 정답입니다."}, "SelectB": {"Select": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하여 처리할 페이로드를 포함하는 알림을 전송합니다. AWS Lambda 함수를 구독자로 설정합니다.", "Commentary": "SNS는 메시지 순서 보장이 어렵습니다. 순서 유지가 필수이므로 적합하지 않습니다."}, "SelectC": {"Select": "Amazon Simple Queue Service(Amazon SQS) standard 큐를 생성해 메시지를 저장합니다. 그리고 AWS Lambda 함수를 설정해 해당 큐의 메시지를 독립적으로 처리하도록 합니다.", "Commentary": "standard 큐는 순서를 보장하지 않으므로 이벤트 데이터 순서가 어긋날 수 있습니다."}, "SelectD": {"Select": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하여 처리할 페이로드를 포함하는 알림을 전송합니다. 구독자로 Amazon Simple Queue Service(Amazon SQS) 큐를 설정합니다.", "Commentary": "SNS와 standard 큐 조합은 순서를 강제할 수 없으므로 요구 사항을 충족하지 못합니다."}}}
{"Question_Number": "Q150", "Question_Description": "한 회사가 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션 중입니다. 마이그레이션 설계 요구 사항으로, 솔루션스 아키텍트는 인프라 메트릭 알람을 구현해야 합니다. 이 회사는 CPU Utilization이 50%를 짧게 초과하는 상황에는 조치를 취할 필요가 없지만, CPU Utilization이 50%를 초과하고 동시에 디스크의 Read IOPS가 높아지는 경우 즉시 대응해야 합니다. 또한 오탐(거짓 경보)을 줄여야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Amazon EC2", "CPU Utilization", "Read IOPS", "오탐 감소", "인프라 메트릭 알람"], "Terms": ["Amazon EC2", "CloudWatch Composite Alarms", "CloudWatch Dashboards", "CloudWatch Synthetics", "CloudWatch Metric Alarms", "CPU Utilization", "read IOPS", "on-premises"], "Commentary": "이 문제는 여러 지표를 결합해 오탐을 줄이고 즉시 필요한 상황에만 알람을 받도록 구성하는 방법에 관한 것입니다. CPU가 50%를 넘고 Read IOPS가 동시에 높은 상황을 한 번에 감지해야 하므로, CloudWatch Composite Alarms를 사용해 조건을 결합하고 필요시 한 번에 알람을 보낼 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon CloudWatch Composite Alarms를 이용해 가능한 곳에서 알람을 생성합니다.", "Commentary": "Composite Alarms를 사용하면 여러 지표 알람을 결합해 CPU와 디스크 사용이 동시에 높을 때만 알람을 보내므로 오탐을 줄이고 즉각적인 대응이 가능합니다."}, "SelectB": {"Select": "Amazon CloudWatch Dashboards를 생성해 지표를 시각화하고 신속히 대응합니다.", "Commentary": "대시보드를 통해 지표를 직관적으로 파악할 수 있지만, 필요한 알람 메커니즘을 줄여주지는 않아 조건 결합이나 오탐 감소 요구 사항을 충족하지 못합니다."}, "SelectC": {"Select": "Amazon CloudWatch Synthetics Canaries를 생성해 애플리케이션을 모니터링하고 알람을 발생시킵니다.", "Commentary": "Synthetics는 주로 애플리케이션 엔드포인트를 모니터링하는 도구로, 인프라 지표인 CPU, IOPS에 대한 결합 알람에는 적합하지 않습니다."}, "SelectD": {"Select": "가능한 곳에서 다중 지표 임계값(single metric alarm)으로 Amazon CloudWatch 알람을 생성합니다.", "Commentary": "단일 메트릭 알람은 특정 지표 한 가지에 대해서만 동작하므로, 여러 지표를 동시에 모니터링하고 조건이 모두 충족될 때만 알람을 발생시키는 요구사항에 부합하지 않습니다."}}}
{"Question_Number": "Q151", "Question_Description": "한 회사가 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 회사의 컴플라이언스 요구사항에 따라, 오직 ap-northeast-3 Region만 사용할 수 있습니다. 또한 VPC를 인터넷에 연결하는 것은 허용되지 않습니다. 이 요구사항을 충족하는 솔루션은 어떤 것입니까? (두 개를 고르십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["마이그레이션", "컴플라이언스", "ap-northeast-3 Region", "VPC", "인터넷 차단", "AWS Control Tower", "AWS Organizations"], "Terms": ["AWS Control Tower", "AWS Organizations", "Service Control Policies (SCPs)", "VPC", "Internet Access", "ap-northeast-3 Region", "Network ACL", "IAM Policy", "AWS WAF", "AWS Config"], "Commentary": "이 문제는 특정 Region 사용과 인터넷 연결을 차단해야 하는 보안 정책 설정 요구사항을 다룹니다. 컴플라이언스 상 ap-northeast-3 Region만 사용할 수 있으며, VPC에서 인터넷 연결이 차단되어야 합니다. 따라서 조직 단위의 강력한 제어(예: SCP)를 통해 Region 접근 및 인터넷 액세스를 막는 방안이 핵심입니다.", "Selections": {"SelectA": {"Select": "AWS Control Tower를 사용하여 data residency guardrails를 구현하고, 인터넷 액세스를 거부하며 ap-northeast-3 이외의 모든 AWS Region에 대한 액세스를 거부합니다.", "Commentary": "AWS Control Tower를 통해 조직 전반에 걸쳐 Region 제한과 인터넷 차단 정책을 쉽게 구성할 수 있어 요구사항을 충족시키는 올바른 솔루션입니다."}, "SelectB": {"Select": "AWS WAF에서 인터넷 액세스를 차단하는 규칙을 사용합니다. AWS 계정 설정에서 ap-northeast-3를 제외한 모든 AWS Region에 대한 액세스를 차단합니다.", "Commentary": "AWS WAF는 주로 웹 트래픽을 제어하며, Region 전체 사용 제한 기능을 직접 제공하지 않으므로 요구사항을 완전히 만족시키지 못합니다."}, "SelectC": {"Select": "AWS Organizations에서 SCP를 구성하여 VPC의 인터넷 액세스를 방지합니다. ap-northeast-3 외 모든 AWS Region에 대한 액세스를 거부합니다.", "Commentary": "조직 단위의 SCP를 통해 특정 Region 외의 사용을 원천적으로 차단하고, VPC가 인터넷에 연결되지 않도록 통제하여 요구사항을 만족시킵니다."}, "SelectD": {"Select": "각 VPC에 대하여 Network ACL의 아웃바운드 규칙으로 0.0.0.0/0로부터의 모든 트래픽을 차단합니다. 각 사용자에 대해 ap-northeast-3 이외의 Region 사용을 막는 IAM Policy를 생성합니다.", "Commentary": "부분적인 NACL 및 IAM 정책 작업이며, 조직 전체 차원의 강제력이 떨어져 관리가 복잡해질 수 있습니다."}, "SelectE": {"Select": "AWS Config를 사용하여 internet gateway를 탐지 및 경고하고, ap-northeast-3 밖에서 생성되는 새 리소스에 대해 탐지 및 경고하는 Managed Rules를 활성화합니다.", "Commentary": "AWS Config 알림은 사후 감지에 가깝고, 근본적으로 Region 또는 인터넷 연결 자체를 막는 직접적인 제어 기능이 부족합니다."}}}
{"Question_Number": "Q152", "Question_Description": "한 회사가 신규 직원 교육을 제공하는 3계층 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 하루에 12시간만 접근되며, Amazon RDS for MySQL DB instance를 사용하여 정보를 저장합니다. 회사는 비용을 최소화하고자 합니다. 이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["Amazon RDS for MySQL", "비용 절감", "시간대별 접근", "DB 자동 시작/중지", "Lambda", "EventBridge"], "Terms": ["Amazon RDS for MySQL", "AWS Systems Manager Session Manager", "Amazon ElastiCache for Redis", "Amazon EC2", "IAM role", "AWS Lambda", "Amazon EventBridge", "cron job"], "Commentary": "이 문제는 사용 시간이 제한된 DB instance를 자동으로 중지하여 비용을 절감하는 방법을 찾는 것입니다. AWS Lambda와 EventBridge를 활용한 DB 시작/중지 스케줄링이 AWS 권장 방식이며 운영 오버헤드가 가장 낮습니다.", "Selections": {"SelectA": {"Select": "AWS Systems Manager Session Manager에 대한 IAM 정책을 구성하고, 해당 정책을 가진 IAM role을 생성해 트러스트 관계를 업데이트합니다. 그리고 DB instance에 대한 자동 시작과 중지를 설정합니다.", "Commentary": "Session Manager만으로는 DB 인스턴스 자동 스케줄링이 적합하지 않습니다. 자동화 기능을 제대로 지원하지 않아 요구사항을 충족하기 어렵습니다."}, "SelectB": {"Select": "Amazon ElastiCache for Redis 캐시 클러스터를 생성해 DB instance가 중지되어도 캐시에서 데이터를 제공하도록 합니다. DB instance가 시작되면 캐시를 무효화합니다.", "Commentary": "캐시를 사용해도 DB instance 비용 절감을 위한 효율적인 자동 중지/시작 기능을 제공하지 못하며 ElastiCache 추가 비용이 발생합니다."}, "SelectC": {"Select": "Amazon EC2 인스턴스를 생성하고, Amazon RDS에 액세스 권한을 부여하는 IAM role을 부착합니다. cron job을 구성해 원하는 일정에 EC2 인스턴스를 통해 RDS를 시작 및 중지합니다.", "Commentary": "EC2 인스턴스를 별도로 운영해야 하므로 오버헤드가 늘어나고, 단순 자동화에 비해 구성과 유지보수가 복잡합니다."}, "SelectD": {"Select": "AWS Lambda 함수를 생성해 DB instance를 시작 및 중지하도록 합니다. Amazon EventBridge(또는 Amazon CloudWatch Events)에서 예약 규칙을 생성해 Lambda 함수를 호출하고, 해당 Lambda 함수를 이벤트 대상로 설정합니다.", "Commentary": "Lambda와 EventBridge 조합은 DB 인스턴스의 자동 시작/중지를 간단하게 스케줄링해 비용 절감을 최적화하는 AWS 모범 사례입니다."}}}
{"Question_Number": "Q153", "Question_Description": "한 회사가 인기 있는 노래의 클립으로 만든 벨소리를 판매하고 있습니다. 이 벨소리 파일들은 Amazon S3 Standard에 저장되어 있으며, 각 파일은 최소 128KB 이상의 크기를 갖습니다. 회사에는 수백만 개의 파일이 있지만, 90일이 지난 벨소리들은 다운로드 빈도가 매우 낮습니다. 회사는 가장 자주 사용되는 파일은 사용자에게 즉시 제공하면서도, 스토리지 비용을 절감해야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하기 위해 어떤 조치를 취해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["벨소리 파일", "스토리지 비용 절감", "S3 Standard", "S3 Standard-Infrequent Access (S3 Standard-IA)", "S3 Intelligent-Tiering", "S3 Lifecycle Policy", "90일 이후"], "Terms": ["Amazon S3 Standard", "S3 Standard-Infrequent Access (S3 Standard-IA)", "S3 Intelligent-Tiering", "S3 Lifecycle Policy", "S3 inventory"], "Commentary": "이 문제는 벨소리 파일을 저장할 때 자주 액세스되는 파일은 빠르게 제공하고, 90일 이후에는 다운로드 빈도가 낮아지므로 S3 Standard-Infrequent Access (S3 Standard-IA) 같은 저비용 스토리지로 자동 전환하여 비용을 절감하는 방법에 대한 것입니다. 90일 이전에는 S3 Standard에 두어 자주 액세스되는 파일을 효율적으로 제공하고, 이후에는 S3 Lifecycle Policy를 통해 자동으로 S3 Standard-IA로 이동시켜서 스토리지 비용을 크게 절감할 수 있습니다. 이는 관리 오버헤드를 최소화하고, 자주 사용되는 파일들은 그대로 빠르게 접근 가능하도록 유지하는 데 적합한 솔루션입니다.", "Selections": {"SelectA": {"Select": "객체의 초기 스토리지 계층으로 S3 Standard-Infrequent Access(S3 Standard-IA)를 구성합니다.", "Commentary": "파일이 처음부터 S3 Standard-IA에 있으면 자주 액세스되는 90일 미만 파일에 대한 비용이 더 많이 들 수 있으므로 적절치 않습니다."}, "SelectB": {"Select": "파일을 S3 Intelligent-Tiering으로 이동하고, 90일 후에 비용이 더 저렴한 스토리지 계층으로 옮기도록 구성합니다.", "Commentary": "S3 Intelligent-Tiering 자체도 자동 최적화를 제공하지만, 90일 이후로 액세스가 현저히 낮아지는 패턴이 명확할 경우 S3 Lifecycle Policy가 더 단순하고 비용 면에서도 유리합니다."}, "SelectC": {"Select": "S3 inventory를 구성하여 객체를 관리하고, 90일 후에 S3 Standard-Infrequent Access(S3 Standard-IA)로 수동 이동합니다.", "Commentary": "S3 inventory는 객체 목록을 제공하기 위한 도구이며, 이를 통해 수동으로 객체를 옮기는 것은 관리 작업이 더 많아집니다. 자동화된 Lifecycle Policy가 더 효율적입니다."}, "SelectD": {"Select": "S3 Lifecycle 정책을 사용해 90일 후 객체를 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하도록 합니다.", "Commentary": "자동으로 90일 이전에는 S3 Standard에 두어 빈번히 사용되는 파일에 빠른 액세스를 제공하고, 90일이 지나면 비용이 저렴한 S3 Standard-IA로 이동시키는 최적의 솔루션입니다."}}}
{"Question_Number": "Q154", "Question_Description": "한 회사가 의료 시험 결과를 Amazon S3 저장소에 저장해야 합니다. 이 저장소에는 몇몇 과학자만 새 파일을 추가할 수 있어야 하고, 그 외 모든 사용자는 읽기 전용 권한만 가져야 합니다. 또한 누구도 이미 업로드된 파일을 수정하거나 삭제할 수 없어야 하며, 생성일로부터 최소 1년 동안 모든 파일이 보존되어야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["Amazon S3", "1년 보관", "파일 수정 삭제 방지", "S3 Object Lock", "compliance mode", "의료 시험 결과", "읽기 전용 접근"], "Terms": ["S3 Object Lock", "Governance mode", "Compliance mode", "Retention period", "Legal hold", "IAM role", "S3 bucket policy", "AWS Lambda"], "Commentary": "이 문제는 의료 시험 결과를 Amazon S3에 안전하게 보관하면서, 특정 사용자만 파일 추가가 가능하고 파일의 수정·삭제는 절대 허용되지 않도록 설계해야 합니다. 생성된 파일을 1년 이상 보관하려면 S3 Object Lock의 Compliance mode를 사용하면 됩니다. Compliance mode는 어떤 사용자든지 Lock을 무시하거나 파일을 삭제할 수 없게 보장하므로 가장 적절한 솔루션입니다.", "Selections": {"SelectA": {"Select": "S3 Object Lock을 governance mode로 설정하고 1년간 legal hold를 적용합니다.", "Commentary": "Governance mode는 관리자 권한을 통해 해제할 수 있어 완전한 불변성을 보장하지 못합니다. 따라서 수정·삭제를 완전히 방지할 수 없습니다."}, "SelectB": {"Select": "S3 Object Lock을 compliance mode로 설정하고 보존 기간을 365일로 지정합니다.", "Commentary": "Compliance mode에서는 어떤 사용자도 Lock을 해제할 수 없어, 파일 수정·삭제가 불가능하며 1년 보존 요구사항도 충족합니다."}, "SelectC": {"Select": "특정 IAM role을 사용해 S3 버킷에서 객체 삭제·변경을 제한하고, S3 버킷 정책으로 오직 이 IAM role만을 허용합니다.", "Commentary": "IAM role과 버킷 정책만으로는 객체에 대한 절대적 보호(수정·삭제 불가)와 보존 기간 강제 기능을 완전히 보장하기 어렵습니다."}, "SelectD": {"Select": "S3 버킷에 객체가 추가될 때마다 AWS Lambda 함수를 호출해서 해시를 추적하고, 변경된 객체를 표시하도록 구성합니다.", "Commentary": "객체 변경 여부만 표시할 뿐, 실제 수정·삭제를 방지하거나 1년 보존을 강제할 수 없기 때문에 요구 사항을 충족하지 못합니다."}}}
{"Question_Number": "Q155", "Question_Description": "한 대형 미디어 회사가 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 회사는 전 세계 사용자가 기밀 미디어 파일을 안정적으로 액세스할 수 있도록 파일을 캐싱하고자 합니다. 컨텐츠는 Amazon S3 버킷에 저장되어 있으며, 지리적 위치에 상관없이 빠른 속도로 데이터를 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["기밀 미디어 파일", "글로벌 캐싱", "전 세계 사용자", "빠른 콘텐츠 전송"], "Terms": ["Amazon S3", "AWS DataSync", "AWS Global Accelerator", "Amazon CloudFront", "Amazon Simple Queue Service (Amazon SQS)", "CloudFront edge server"], "Commentary": "글로벌 사용자에게 기밀 콘텐츠를 빠르게 전송하기 위해서는 네트워크 엣지에서 캐싱하여 지연을 최소화하는 것이 핵심입니다. Amazon CloudFront는 분산된 엣지 서버를 통해 전 세계적 저지연 접근을 보장하므로 적합한 솔루션입니다.", "Selections": {"SelectA": {"Select": "AWS DataSync를 사용하여 S3 버킷을 웹 애플리케이션과 연결합니다.", "Commentary": "DataSync는 주로 파일 서버 간 대규모 파일 전송을 자동화하는 서비스로, 글로벌 지연을 줄이는 캐싱 솔루션으로는 적합하지 않습니다."}, "SelectB": {"Select": "AWS Global Accelerator를 배포하여 S3 버킷을 웹 애플리케이션과 연결합니다.", "Commentary": "Global Accelerator는 주로 TCP/UDP 트래픽 성능 향상을 위한 서비스이며, 객체 캐싱 기능을 제공하지 않아 미디어 파일 캐시에 부적합합니다."}, "SelectC": {"Select": "Amazon CloudFront를 배포하여 S3 버킷을 CloudFront 엣지 서버와 연결합니다.", "Commentary": "글로벌 엣지에서 파일을 캐싱하여 지연을 최소화하고, 사용자가 어디서 요청하든 빠른 미디어 제공이 가능합니다. 정답입니다."}, "SelectD": {"Select": "Amazon Simple Queue Service (Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션과 연결합니다.", "Commentary": "SQS는 메시지 큐 서비스로, 캐싱 기능이나 콘텐츠 전송 가속 기능을 제공하지 않습니다."}}}
{"Question_Number": "Q156", "Question_Description": "한 회사는 여러 데이터베이스에서 생성되는 배치 데이터와 네트워크 센서 및 애플리케이션 API에서 오는 실시간 스트림 데이터를 모두 다룹니다. 회사는 이 모든 데이터를 하나의 위치에 통합하여 비즈니스 분석을 수행해야 합니다. 들어오는 데이터를 처리한 후 여러 Amazon S3 버킷에 단계별로 저장해야 하며, 이후 팀이 일회성 쿼리를 실행하고 해당 데이터를 비즈니스 인텔리전스 도구로 가져와 KPI(주요 성과 지표)를 시각화하려고 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하려면 다음 중 어떤 조합을 선택해야 합니까? (두 가지를 고르시오.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["배치 데이터", "실시간 스트림 데이터", "비즈니스 분석", "Amazon S3", "일회성 쿼리", "비즈니스 인텔리전스(KPI)", "운영 오버헤드 최소화"], "Terms": ["Amazon Athena", "Amazon QuickSight", "Kinesis Data Analytics", "AWS Lambda", "Amazon Redshift", "AWS Glue", "ETL", "JSON", "Amazon OpenSearch Service (Amazon Elasticsearch Service)", "AWS Lake Formation", "Crawler", "Apache Parquet", "Operational Overhead"], "Commentary": "이 문제는 다양한 소스에서 들어오는 배치 및 실시간 데이터를 효율적으로 처리하고 Amazon S3에 저장해 향후 분석에 활용하는 방법을 묻습니다. 정답 선택지들은 최소한의 관리 부담으로 데이터 레이크를 구성하고, 일회성 쿼리와 대시보드 생성을 손쉽게 지원하는 데 초점을 둡니다.", "Selections": {"SelectA": {"Select": "Amazon Athena로 일회성 쿼리를 실행하고, Amazon QuickSight로 KPI 대시보드를 생성합니다.", "Commentary": "서버리스 방식의 Athena로 스키마 없는 쿼리를 수행하고, QuickSight를 통해 시각화할 수 있어 운영 오버헤드를 크게 줄일 수 있으므로 적합합니다."}, "SelectB": {"Select": "Amazon Kinesis Data Analytics로 일회성 쿼리를 실행하고, Amazon QuickSight로 KPI 대시보드를 생성합니다.", "Commentary": "Kinesis Data Analytics는 스트리밍 데이터 실시간 분석에 최적화된 서비스로, 일회성 쿼리에 사용하기에는 오버헤드가 더 높아 맞지 않습니다."}, "SelectC": {"Select": "각 데이터베이스의 개별 레코드를 사용자 정의 AWS Lambda 함수로 가져와 Amazon Redshift 클러스터로 전송합니다.", "Commentary": "Lambda 함수를 직접 작성해 Redshift로 매번 전송하면 관리 및 코드 유지가 복잡해져서 운영 오버헤드가 증가하므로 비효율적입니다."}, "SelectD": {"Select": "AWS Glue ETL 작업을 사용하여 데이터를 JSON 형식으로 변환한 뒤, 여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 로드합니다.", "Commentary": "OpenSearch Service를 분석 기본 대상으로 사용하는 것은 로그 검색 등 특수 케이스에 적합하며, 여기서는 BI 도구로의 연계와 운영 간소화 측면에서 부적합합니다."}, "SelectE": {"Select": "AWS Lake Formation의 블루프린트를 사용해 가져올 수 있는 데이터를 식별하고, AWS Glue를 사용해 소스를 크롤링하여 데이터를 추출한 뒤 Apache Parquet 형식으로 Amazon S3에 적재합니다.", "Commentary": "Lake Formation과 Glue를 이용해 데이터 레이크를 쉽게 구성하고, Parquet 형식으로 S3에 저장하여 쿼리와 시각화를 위한 기반을 마련하므로 운영 오버헤드가 낮습니다."}}}
{"Question_Number": "Q157", "Question_Description": "한 회사가 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장하고 있습니다. 이 회사는 모든 데이터를 5년 동안 보관해야 하며, 5년 후에는 모든 데이터를 삭제해야 합니다. 또한 데이터베이스 내에서 수행되는 작업에 대한 감사 로그(audit logs)를 무기한으로 보관해야 합니다. 현재 회사는 Aurora에 대해 자동 백업을 구성해 두었습니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계를 결합해서 수행해야 합니까? (2개를 선택하세요.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["DB 클러스터 데이터 5년 보관", "무기한 감사 로그", "Amazon Aurora PostgreSQL", "AWS Backup", "CloudWatch Logs export"], "Terms": ["Amazon Aurora PostgreSQL", "자동 백업(automated backups)", "manual snapshot", "AWS Backup", "Amazon CloudWatch Logs export", "lifecycle policy"], "Commentary": "이 문제는 5년 동안의 데이터 보존과 만료 시 삭제, 그리고 감사 로그를 무기한 보관해야 하는 요구사항을 동시에 충족하는 방법을 묻습니다. Aurora의 자동 백업 보존 기간은 최대 35일로 제한되므로, 장기 보관을 위해서는 AWS Backup을 사용해야 합니다. 또한 감사 로그는 Amazon CloudWatch Logs로 내보내어 무기한으로 저장할 수 있습니다.", "Selections": {"SelectA": {"Select": "DB cluster에 대한 manual snapshot을 생성합니다.", "Commentary": "수동 스냅샷은 필요 시점마다 따로 생성해야 하므로, 5년 동안 자동으로 보관·삭제를 관리하기 어렵습니다."}, "SelectB": {"Select": "자동 백업에 대해 lifecycle policy를 생성합니다.", "Commentary": "Aurora 자동 백업의 최대 보존 기간은 35일이므로 5년 보관 요구사항을 충족할 수 없습니다."}, "SelectC": {"Select": "자동화된 백업 보존(backup retention)을 5년으로 설정합니다.", "Commentary": "Aurora 자동 백업은 보존 기간 상한이 35일이므로 5년 보관 설정은 불가능합니다."}, "SelectD": {"Select": "DB cluster에 대한 Amazon CloudWatch Logs export를 구성합니다.", "Commentary": "CloudWatch Logs를 통해 감사 로그를 무기한 보관할 수 있으므로 로그 보관 요구사항을 충족합니다."}, "SelectE": {"Select": "AWS Backup을 사용하여 백업을 수행하고, 5년 동안 해당 백업을 보관합니다.", "Commentary": "AWS Backup을 이용하면 백업을 장기간(5년) 자동으로 보관하고, 만료 시 자동 삭제도 지원합니다."}}}
{"Question_Number": "Q158", "Question_Description": "한 솔루션스 아키텍트가 곧 열릴 음악 이벤트를 위해 웹사이트를 최적화하고 있습니다. 공연 영상은 실시간 스트리밍된 후 주문형으로도 제공될 예정입니다. 이번 이벤트는 전 세계 온라인 시청자를 끌어모을 것으로 예상됩니다. 실시간과 주문형 스트리밍 모두의 성능을 향상하려면 어떤 서비스를 사용해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["전 세계 온라인 시청자", "실시간 스트리밍", "주문형 스트리밍", "Amazon CloudFront", "성능 최적화"], "Terms": ["Amazon CloudFront", "AWS Global Accelerator", "Amazon Route 53", "Amazon S3 Transfer Acceleration", "VOD (Video on Demand)", "실시간 스트리밍"], "Commentary": "이 문제는 전 세계적으로 시청되는 실시간 및 주문형 스트리밍 영상의 전달 속도와 품질을 높이기 위한 방안을 묻습니다. 라이브 스트리밍과 VOD 모두 HTTP 기반으로 제공되므로, 글로벌 CDN 기능을 갖춘 Amazon CloudFront가 가장 효율적이며 빠른 솔루션입니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront", "Commentary": "Amazon CloudFront는 전 세계 엣지 로케이션을 통해 실시간 및 주문형 스트리밍을 빠르고 안정적으로 전달합니다. HTTP 프로토콜을 활용한 라이브와 VOD 서비스 모두에 적합하여 성능 향상에 최적입니다."}, "SelectB": {"Select": "AWS Global Accelerator", "Commentary": "AWS Global Accelerator는 주로 UDP 기반 서비스를 포함한 비-HTTP 애플리케이션 또는 고정 IP가 필요한 HTTP 트래픽에 적합합니다. 단순 스트리밍 속도 개선 목적에는 CloudFront보다 최적이 아닙니다."}, "SelectC": {"Select": "Amazon Route 53", "Commentary": "Amazon Route 53은 주로 DNS 라우팅 서비스로, 사용자가 가장 가까운 리소스로 연결되도록 돕지만 CDN 기능은 제공하지 않습니다. 스트리밍의 직접적인 품질 향상에는 한계가 있습니다."}, "SelectD": {"Select": "Amazon S3 Transfer Acceleration", "Commentary": "Amazon S3 Transfer Acceleration은 S3 버킷으로 객체를 업로드할 때 전송 속도를 높이기 위한 기능입니다. 스트리밍 자체의 속도와 품질 개선에는 적합하지 않습니다."}}}
{"Question_Number": "Q159", "Question_Description": "한 회사가 Amazon API Gateway와 AWS Lambda를 사용해 외부에 공개된 Serverless 애플리케이션을 운영하고 있습니다. 최근 트래픽이 봇넷에서 발생하는 악의적인 요청 때문에 급증했습니다. 솔루션스 아키텍트는 무단 사용자 요청을 차단하기 위해 어떤 단계를 수행해야 합니까? (2개를 고르세요)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["API Gateway", "AWS Lambda", "AWS WAF", "API Key", "봇넷"], "Terms": ["Amazon API Gateway", "AWS Lambda", "AWS WAF", "Usage Plan", "API Key", "Private API"], "Commentary": "이 문제는 봇넷으로부터 발생하는 악의적인 요청을 효과적으로 차단하고, 합법적인 사용자의 정상 트래픽만 처리하기 위한 보안 전략에 대한 내용입니다. AWS WAF를 사용하면 미리 정의된 룰셋을 통해 의심스러운 요청이나 악의적인 요청을 자동으로 식별 후 차단할 수 있고, API Key를 통한 Usage Plan 설정으로 인증되지 않은 사용자의 접근을 제한할 수 있습니다. 이 두 가지 방법을 결합하면 서버리스 애플리케이션을 무단 접근으로부터 보다 안전하게 보호할 수 있습니다.", "Selections": {"SelectA": {"Select": "진짜 사용자들과만 공유되는 API Key를 포함한 Usage Plan을 생성합니다.", "Commentary": "API Key를 이용하면 무단 사용자는 요청을 보낼 수 없어 트래픽을 필터링할 수 있습니다. 완벽한 보안은 아니지만 인증 체계를 강화하는데 유효하므로 정답입니다."}, "SelectB": {"Select": "AWS Lambda 함수 내부 로직을 통해 악성 IP 주소에서 오는 요청을 무시하도록 만듭니다.", "Commentary": "Lambda 함수 내부에서 동적으로 IP를 식별하고 차단하는 것은 관리와 유지보수가 복잡하므로 비효율적입니다. 올바른 접근 방법이 아닙니다."}, "SelectC": {"Select": "AWS WAF 룰을 구현하여 악의적인 요청을 식별하고 필터링하는 액션을 트리거합니다.", "Commentary": "AWS WAF로 봇넷 악의적 트래픽을 지능적으로 차단할 수 있어 정답입니다."}, "SelectD": {"Select": "기존의 Public API를 Private API로 변경하고 DNS 레코드를 새 API 엔드포인트로 리다이렉션합니다.", "Commentary": "Private API로 변경하면 내부 네트워크용 엔드포인트가 되어 원하는 접근 차단이 가능하나, 이미 공개 애플리케이션이라면 구조가 크게 바뀌어 운영 복잡성이 증가합니다."}, "SelectE": {"Select": "API에 접근하려는 각 사용자별로 IAM 역할을 생성하고, API 호출 시 해당 역할을 할당하도록 합니다.", "Commentary": "IAM 역할은 사용자 권한 위임 구조로, 외부 무단 요청 차단과 직접적인 연관이 없으며 복잡성만 높아집니다."}}}
{"Question_Number": "Q160", "Question_Description": "한 전자상거래 회사가 AWS Cloud에서 애널리틱스 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 매달 약 300MB의 데이터를 생성합니다. 데이터는 JSON 형식으로 저장됩니다. 회사는 재해 복구 솔루션을 검토 중이며, 데이터를 백업하려고 합니다. 필요 시 밀리초(ms) 이내로 액세스가 가능해야 하고, 데이터는 30일간 보관되어야 합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["전자상거래", "매달 300MB", "JSON", "밀리초(ms) 이내 액세스", "30일 보관", "비용 효율"], "Terms": ["Amazon OpenSearch Service (Amazon Elasticsearch Service)", "Amazon S3 Glacier", "Amazon S3 Standard", "Amazon RDS for PostgreSQL"], "Commentary": "이 문제는 짧은 보존 기간(30일) 동안 밀리초 단위로 데이터를 즉시 가져와야 하며 비용 최적화도 고려해야 합니다. Amazon S3 Standard는 즉시 액세스가 가능하고 저렴한 비용 구조를 제공해 요구사항에 가장 부합하는 솔루션입니다.", "Selections": {"SelectA": {"Select": "Amazon OpenSearch Service (Amazon Elasticsearch Service)", "Commentary": "데이터를 실시간 분석하기에는 유리하지만, 백업 목적에는 비용과 운영 부담이 더 클 수 있습니다."}, "SelectB": {"Select": "Amazon S3 Glacier", "Commentary": "저장 비용은 저렴하지만 밀리초 단위 액세스가 불가능하여 요구사항을 만족하지 못합니다."}, "SelectC": {"Select": "Amazon S3 Standard", "Commentary": "밀리초 이내로 즉시 액세스가 가능하고 30일 보관에도 적절한 비용 모델로 최적의 솔루션입니다."}, "SelectD": {"Select": "Amazon RDS for PostgreSQL", "Commentary": "관계형 데이터베이스로 JSON 백업을 관리하기에는 비용과 관리가 복잡해집니다."}}}
{"Question_Number": "Q161", "Question_Description": "한 회사는 JSON 문서를 처리하고 그 결과를 온프레미스 SQL 데이터베이스에 저장하는 소규모 Python 애플리케이션을 보유하고 있습니다. 이 애플리케이션은 하루에도 수천 번 실행됩니다. 회사는 이 애플리케이션을 AWS Cloud로 이전하여 높은 가용성을 보장하고 확장성을 극대화하며 운영 오버헤드를 최소화할 수 있는 솔루션을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["Python 애플리케이션", "JSON 문서 처리", "운영 오버헤드 최소화", "고가용성", "확장성", "Amazon S3", "AWS Lambda", "Amazon Aurora"], "Terms": ["Python", "JSON", "Amazon S3", "AWS Lambda", "Amazon Aurora DB cluster", "Amazon EC2", "Amazon EBS", "EBS Multi-Attach", "Amazon RDS", "Amazon SQS", "Amazon ECS", "Container"], "Commentary": "이 문제는 JSON 문서를 하루 수천 회 처리하는 애플리케이션을 AWS 환경으로 이전할 때, 고가용성과 확장성, 운영 부담 최소화를 달성하는 방안을 묻습니다. S3 이벤트를 트리거로 Lambda를 활용해 자동으로 확장하고, 결과를 Amazon Aurora에 저장하는 서버리스 방식을 사용하는 B가 정답입니다.", "Selections": {"SelectA": {"Select": "JSON 문서를 Amazon S3 bucket에 저장합니다. 여러 Amazon EC2 instance에서 Python 코드를 실행하여 문서를 처리합니다. 결과를 Amazon Aurora DB cluster에 저장합니다.", "Commentary": "EC2 인스턴스를 직접 운영하면 스케일링과 장애 관리를 별도로 해야 하므로 운영 오버헤드가 증가합니다."}, "SelectB": {"Select": "JSON 문서를 Amazon S3 bucket에 저장합니다. AWS Lambda 함수를 만들어 S3 버킷으로 문서가 전송될 때 Python 코드를 실행하여 처리하도록 합니다. 처리 결과는 Amazon Aurora DB cluster에 저장합니다.", "Commentary": "S3 이벤트가 Lambda를 자동 트리거하여 확장성과 가용성을 극대화하고, 운영 부담을 최소화하는 서버리스 구성이므로 정답입니다."}, "SelectC": {"Select": "JSON 문서를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. EBS Multi-Attach 기능을 이용해 여러 Amazon EC2 instance에 볼륨을 연결합니다. EC2 인스턴스에서 Python 코드를 실행하여 문서를 처리하고 결과를 Amazon RDS DB instance에 저장합니다.", "Commentary": "EBS를 직접 관리해야 하며 EC2 인스턴스 운영도 필요해 운영 오버헤드가 큽니다."}, "SelectD": {"Select": "JSON 문서를 Amazon SQS 큐에 메시지 형태로 저장합니다. Python 코드를 컨테이너로 묶어 Amazon ECS(EC2 런치 타입)에 배포하고, 컨테이너가 SQS 메시지를 처리합니다. 결과는 Amazon RDS DB instance에 저장합니다.", "Commentary": "SQS와 ECS는 확장성은 좋지만 Lambda 기반 서버리스 방안보다 운영 관리 측면에서 복잡성이 더 높습니다."}}}
{"Question_Number": "Q162", "Question_Description": "한 회사가 금융 리스크 모델링을 위해 AWS에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 합니다. 회사의 HPC 워크로드는 Linux에서 실행되며, 각 HPC 워크플로우는 수백 대의 Amazon EC2 Spot 인스턴스에서 짧게 구동되고, 최종적으로 분석 및 장기 보관을 위해 영구 스토리지에 저장되는 수천 개의 출력 파일을 생성합니다. 회사는 모든 EC2 인스턴스에서 처리할 수 있도록 온프레미스 데이터를 장기 영구 스토리지로 복사하며, 데이터셋과 출력 파일을 읽고 쓸 수 있는 고성능 파일 시스템으로 통합된 클라우드 스토리지 솔루션을 원합니다. 이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.2"], "Keywords": ["HPC", "금융 리스크 모델링", "EC2 Spot Instances", "고성능 파일 시스템", "영구 스토리지"], "Terms": ["Amazon FSx for Lustre", "Amazon S3", "Amazon FSx for Windows File Server", "Amazon EBS", "Amazon S3 Glacier", "VPC Endpoint"], "Commentary": "이 문제는 여러 대의 Linux 기반 EC2 Spot 인스턴스를 사용해 대규모 HPC 워크로드를 처리하고, 결과를 영구 스토리지로 안전하게 보존하는 고성능 파일 시스템 구성을 찾는 것입니다. HPC 환경에서는 Lustre 파일 시스템이 고성능 병렬 I/O 처리를 지원하므로, Amazon S3와 연동되는 Amazon FSx for Lustre가 가장 적합한 해법입니다.", "Selections": {"SelectA": {"Select": "Amazon FSx for Lustre를 Amazon S3와 통합해 사용합니다.", "Commentary": "Linux 기반 HPC 워크로드에서 Lustre 파일 시스템은 고성능 병렬 I/O를 지원하며, S3와 연동해 결과 파일을 영구적으로 저장할 수 있어 요구 사항에 부합합니다."}, "SelectB": {"Select": "Amazon FSx for Windows File Server를 Amazon S3와 통합해 사용합니다.", "Commentary": "Windows 환경에 최적화된 파일 시스템으로, Linux 기반 HPC 워크로드에 적합하지 않으며 높은 병렬 처리를 위한 Lustre의 장점을 살릴 수 없습니다."}, "SelectC": {"Select": "Amazon S3 Glacier를 Amazon EBS와 통합해 사용합니다.", "Commentary": "S3 Glacier는 아카이빙 용도로 저비용 장기 보관에 적합하지만, HPC 환경에서 즉시 고성능 파일 접근이 어려워 부적합합니다."}, "SelectD": {"Select": "Amazon S3 버킷에 VPC Endpoint를 연결하고 Amazon EBS General Purpose SSD(gp2) 볼륨과 통합해 사용합니다.", "Commentary": "EBS 볼륨과 S3만으로는 Lustre와 같은 HPC 전용 파일 시스템의 고성능 병렬 I/O 기능을 구현하기 어렵습니다."}}}
{"Question_Number": "Q163", "Question_Description": "한 회사가 온프레미스에서 컨테이너화된 애플리케이션을 구축 중이며, 이를 AWS로 이전하기로 결정했습니다. 애플리케이션은 배포 직후 수천 명의 사용자가 접속할 예정입니다. 회사는 대규모 컨테이너 배포를 어떻게 관리할지 확신이 없으며, 높은 가용성을 제공하면서도 운영 오버헤드를 최소화하는 아키텍처로 컨테이너화된 애플리케이션을 배포해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["컨테이너화된 애플리케이션", "수천 명의 사용자", "고가용성", "운영 오버헤드 최소화", "자동 확장"], "Terms": ["Amazon Elastic Container Registry (Amazon ECR)", "Amazon Elastic Container Service (Amazon ECS)", "AWS Fargate", "Amazon EC2 launch type", "Auto Scaling", "Amazon CloudWatch", "Availability Zone", "AMI"], "Commentary": "온프레미스 컨테이너 애플리케이션을 AWS로 이전할 때, 높은 가용성과 자동 확장을 위한 완전관리형 서비스 활용이 핵심입니다. AWS Fargate를 사용하면 EC2 인스턴스 관리 없이 컨테이너를 실행할 수 있어 운영 부담이 크게 줄어듭니다. 또한 Target Tracking 기반 오토 스케일링을 통해 사용자 증가에 유연하게 대응 가능합니다. 따라서 SelectA가 정답입니다.", "Selections": {"SelectA": {"Select": "Amazon ECR 리포지토리에 컨테이너 이미지를 저장합니다. AWS Fargate launch type을 사용하는 Amazon ECS 클러스터에서 컨테이너를 실행합니다. Target Tracking으로 수요에 맞춰 자동 확장합니다.", "Commentary": "EC2 관리가 필요 없는 Fargate를 통해 운영 오버헤드를 낮추고, Target Tracking으로 컨테이너를 자동 스케일링하여 고가용성을 만족하므로 요구사항에 가장 적합한 방식입니다."}, "SelectB": {"Select": "Amazon ECR 리포지토리에 컨테이너 이미지를 저장합니다. Amazon EC2 launch type을 사용하는 Amazon ECS 클러스터에서 컨테이너를 실행합니다. Target Tracking으로 수요에 맞춰 자동 확장합니다.", "Commentary": "EC2 인스턴스 프로비저닝 및 관리를 직접 해야 하므로 운영 부담이 늘어납니다. Fargate보다 오버헤드가 크고 고가용성 확보에 추가 작업이 필요합니다."}, "SelectC": {"Select": "Amazon EC2 인스턴스에서 동작하는 리포지토리에 이미지를 저장합니다. 여러 Availability Zone에 분산된 EC2 인스턴스에서 컨테이너를 실행하고, Amazon CloudWatch로 평균 CPU 사용률을 모니터링하여 필요한 경우 EC2 인스턴스를 추가로 실행합니다.", "Commentary": "이미지 저장소부터 컨테이너 실행, 확장까지 모두 직접 관리해야 하므로 운영 복잡도가 높고, 확장 자동화 설정도 추가 구성이 필요해 요구사항에 부합하지 않습니다."}, "SelectD": {"Select": "컨테이너 이미지를 포함하는 AMI를 생성합니다. 여러 Availability Zone에 걸쳐 Auto Scaling 그룹으로 EC2 인스턴스를 실행합니다. Amazon CloudWatch 알람을 사용하여 평균 CPU 사용률 임계값 초과 시 스케일 아웃합니다.", "Commentary": "AMI 업데이트 및 EC2 인스턴스 관리가 필요한 방식으로, Fargate 대신 직접 서버를 구성하므로 운영 부담이 커지고, 컨테이너 관리 효율이 떨어집니다."}}}
{"Question_Number": "Q164", "Question_Description": "한 회사에는 메시지의 페이로드를 전송하는 sender 애플리케이션과, 이 메시지의 페이로드를 처리하도록 설계된 processor 애플리케이션이 있습니다. 이 회사는 두 애플리케이션 간 메시지를 처리하기 위해 AWS 서비스를 도입하고자 합니다. sender 애플리케이션은 시간당 약 1,000개 메시지를 전송할 수 있으며, 메시지를 처리하는 데 최대 2일이 걸릴 수 있습니다. 메시지 처리에 실패한 경우 남은 메시지의 처리를 방해하지 않도록 해당 실패 메시지를 유지해야 합니다. 이러한 요구사항을 만족하면서 가장 운영 효율적인 방안은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["메시지 처리", "Dead-letter Queue(DLQ)", "느슨한 결합", "메시지 유실 방지"], "Terms": ["Amazon SQS", "Dead-letter Queue", "Amazon SNS", "Kinesis Data Stream", "Kinesis Client Library (KCL)", "Redis on Amazon EC2"], "Commentary": "이 문제는 메시지 지연, 재시도, 실패 메시지 보존 등을 고려해 안정적이고 느슨하게 결합된 아키텍처를 설계하는 것이 목적입니다. Amazon SQS는 메시지 보존 기간 및 Dead-letter Queue 기능을 제공해 최대 14일 동안 메시지를 유지하고, 실패 메시지를 안전하게 격리할 수 있어 운영 부담을 최소화합니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스에서 Redis 데이터베이스를 구동하고, 두 애플리케이션이 이를 사용하도록 설정해 메시지를 저장, 처리, 삭제합니다.", "Commentary": "직접 Redis를 운영하면 모니터링, 스케일링, 장애 복구 등 추가 관리가 필요해 운영적 부담이 커집니다."}, "SelectB": {"Select": "Amazon Kinesis data stream을 사용하여 sender 애플리케이션에서 메시지를 수신하고, Kinesis Client Library(KCL)를 사용해 processor 애플리케이션을 통합합니다.", "Commentary": "Kinesis는 실시간 스트리밍 처리에 유리하지만 장시간(최대 2일) 메시지 보관이나 메시지 실패 격리에 특화되지 않아 요구사항을 완전히 충족하기 어렵습니다."}, "SelectC": {"Select": "Amazon Simple Queue Service(Amazon SQS) 큐에 sender, processor 애플리케이션을 통합하고, 실패한 메시지를 수집할 수 있도록 dead-letter queue(DLQ)를 구성합니다.", "Commentary": "SQS는 메시지 보존기간 설정과 DLQ 기능을 통해 실패 메시지를 격리하고, 최대 14일 동안 메시지를 유실 없이 유지할 수 있어 가장 운영 효율적입니다."}, "SelectD": {"Select": "Amazon Simple Notification Service(Amazon SNS) 토픽에 processor 애플리케이션을 구독하고, sender 애플리케이션은 해당 SNS 토픽에 메시지를 게시합니다.", "Commentary": "SNS는 메시지를 여러 구독자에게 전송하는 데 적합하나, 개별 메시지의 장기 보존 및 실패 처리 격리에 적합하지 않습니다."}}}
{"Question_Number": "Q165", "Question_Description": "한 솔루션스 아키텍트는 Amazon S3 오리진과 함께 Amazon CloudFront를 사용하여 정적 웹사이트를 저장하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹사이트 트래픽은 반드시 AWS WAF로 검사되어야 합니다. 이러한 요구 사항을 만족하려면 솔루션스 아키텍트는 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon CloudFront", "Amazon S3", "static website", "AWS WAF", "Origin Access Identity(OAI)"], "Terms": ["S3 bucket policy", "AWS WAF Amazon Resource Name(ARN)", "CloudFront distribution", "Security Group", "Origin Access Identity(OAI)"], "Commentary": "CloudFront에서 Origin Access Identity(OAI)로 Amazon S3를 보호하고, CloudFront 배포에 AWS WAF를 적용하면 외부 트래픽을 안전하게 검사할 수 있습니다. 이렇게 하면 S3 버킷이 직접 노출되지 않고 모든 트래픽이 WAF를 거쳐 처리되어 안전한 아키텍처를 구현할 수 있습니다.", "Selections": {"SelectA": {"Select": "S3 버킷 정책을 구성하여 AWS WAF Amazon Resource Name(ARN)에서 오는 요청만 수락하도록 설정합니다.", "Commentary": "WAF ARN만 허용하는 방식은 S3 버킷 측면 제어에 그치며, CloudFront 배포와의 직접적인 연동이 제대로 이루어지지 않아 전체 아키텍처 요구를 충족하기 어렵습니다."}, "SelectB": {"Select": "Amazon CloudFront를 구성하여 S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF로 전달하도록 합니다.", "Commentary": "CloudFront 자체에서 활성화된 WAF가 아니라 ‘WAF를 먼저 호출 후 S3 요청’ 형태로만 설명되어 있습니다. 단순한 요청 전달만으로는 S3 접근 통제나 안전한 아키텍처 구성이 충분치 않습니다."}, "SelectC": {"Select": "Amazon CloudFront IP 주소만 Amazon S3에 액세스하도록 허용하는 Security Group을 구성합니다. AWS WAF를 CloudFront와 연결합니다.", "Commentary": "Security Group을 통한 IP 기반 접근 제어만으로는 S3 버킷 자체에 대한 직접 접근 제한을 완벽하게 보장하기 어렵습니다. OAI를 활용한 접근 제어가 권장됩니다."}, "SelectD": {"Select": "Amazon CloudFront와 Amazon S3가 Origin Access Identity(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 구성합니다. 배포에서 AWS WAF를 활성화합니다.", "Commentary": "정답입니다. OAI로 S3 버킷을 직접 노출하지 않고 CloudFront만 접근 가능하게 하며, AWS WAF가 CloudFront 배포에 적용되어 모든 트래픽을 검사할 수 있습니다."}}}
{"Question_Number": "Q166", "Question_Description": "글로벌 이벤트 주최 측은 매일 보고서를 정적 HTML 페이지 형태로 온라인에 게시하려고 합니다. 전 세계 사용자들이 수백만 건의 조회수를 발생시킬 것으로 예상됩니다. 파일들은 Amazon S3 버킷에 저장되어 있습니다. 솔루션스 아키텍트는 효율적이면서 효과적인 솔루션을 설계해야 합니다. 이를 달성하기 위해 어떤 조치를 취해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["글로벌 이벤트", "정적 HTML 페이지", "수백만 건의 조회수", "Amazon S3", "Amazon CloudFront"], "Terms": ["Amazon S3", "Presigned URL", "Cross-Region Replication", "Amazon Route 53 (Geoproximity)", "Amazon CloudFront"], "Commentary": "이 문제는 전 세계적으로 많은 사용자가 동시에 정적 콘텐츠(HTML 페이지)에 접근할 때, 빠르고 효율적으로 콘텐츠를 제공하는 방법을 묻습니다. Amazon CloudFront를 사용하면 글로벌 엣지 로케이션을 통해 사용자와 가까운 위치에서 콘텐츠를 제공하기 때문에 대규모 트래픽도 원활히 처리하고 지연 시간을 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Presigned URL을 생성합니다.", "Commentary": "Presigned URL은 제한된 권한으로 객체에 접근하도록 할 수 있지만, 글로벌 캐싱 및 트래픽 분산 측면에서 CloudFront만큼 효율적이지 않습니다."}, "SelectB": {"Select": "모든 리전에 Cross-Region Replication을 적용합니다.", "Commentary": "여러 리전으로 데이터를 복제해도 각 리전에서 직접 데이터를 제공하는 데에는 여전히 지연이 발생할 수 있고 관리가 복잡합니다."}, "SelectC": {"Select": "Amazon Route 53의 Geoproximity 기능을 활용합니다.", "Commentary": "Geoproximity를 이용해 트래픽을 분산할 수도 있지만, 정적 콘텐츠 제공을 최적화하고 캐싱 효과를 극대화하기에는 CloudFront가 더 적합합니다."}, "SelectD": {"Select": "Amazon CloudFront를 사용하고, 원본으로 해당 S3 버킷을 지정합니다.", "Commentary": "CloudFront는 글로벌 엣지 로케이션을 통해 정적 콘텐츠를 캐싱하고, 대규모 조회 트래픽도 빠르고 안정적으로 제공할 수 있어 가장 효율적인 솔루션입니다."}}}
{"Question_Number": "Q167", "Question_Description": "한 회사가 Amazon EC2 인스턴스 집합에서 운영 환경 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 Amazon SQS 큐에서 데이터를 읽고, 메시지를 병렬로 처리합니다. 메시지 볼륨은 예측 불가능하며 종종 간헐적으로 트래픽이 발생합니다. 이 애플리케이션은 다운타임 없이 메시지를 계속 처리해야 합니다. 가장 비용 효율적으로 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["Amazon EC2", "Amazon SQS", "간헐적 트래픽", "비용 효율성", "다운타임 없는 처리"], "Terms": ["Production Application", "Amazon SQS", "Amazon EC2", "Reserved Instances", "Spot Instances", "On-Demand Instances", "Baseline Capacity", "Additional Capacity"], "Commentary": "이 문제는 예측 불가능한 트래픽에 대응하면서 비용 최적화가 중요한 상황에서 Amazon EC2 컴퓨팅 자원을 어떻게 할당할지를 묻습니다. 애플리케이션은 다운타임 없이 상시 메시지를 처리해야 하며, 메시지 양이 급증하거나 줄어드는 상황을 고려해야 합니다. 가장 좋은 접근 방식은 안정적으로 필요한 최소한의 용량(베이스라인)은 Reserved Instances로 확보하고, 예기치 않은 추가 트래픽은 저렴하고 탄력적인 Spot Instances로 처리하여 비용을 절감하면서도 서비스 중단 없이 처리 용량을 확장하는 것입니다.", "Selections": {"SelectA": {"Select": "Spot Instances만 사용하여 필요한 최대 용량을 처리합니다.", "Commentary": "Spot 환경이 회수될 위험이 있어 다운타임 우려가 크며, 안정적인 처리에 적합하지 않습니다."}, "SelectB": {"Select": "Reserved Instances만 사용하여 필요한 최대 용량을 처리합니다.", "Commentary": "고정 비용이 매우 커지며, 트래픽 변동이 심할 때 비효율적이며 비용 부담이 큽니다."}, "SelectC": {"Select": "베이스라인 용량은 Reserved Instances로 확보하고, 추가 용량은 Spot Instances로 처리합니다.", "Commentary": "필요 최소량은 Reserved Instances로 안정성을 확보하고, 변동분은 Spot Instances로 비용 효율을 극대화해 최적의 조합입니다."}, "SelectD": {"Select": "베이스라인 용량은 Reserved Instances로 확보하고, 추가 용량은 On-Demand Instances로 처리합니다.", "Commentary": "On-Demand는 유연성이 있지만 Spot 대비 비용이 높아, 급증하는 트래픽 처리 시 더 비싸집니다."}}}
{"Question_Number": "Q168", "Question_Description": "한 보안 팀은 팀의 모든 AWS 계정에서 특정 서비스나 작업에 대한 액세스를 제한하려고 합니다. 이 계정들은 모두 AWS Organizations를 사용하는 대규모 조직에 속해 있습니다. 솔루션은 확장 가능해야 하며, 권한을 한 곳에서만 유지하고 관리할 수 있어야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["AWS Organizations", "Service Control Policy", "권한 관리", "단일 지점", "특정 서비스 또는 작업 제한"], "Terms": ["ACL", "Security Group", "Cross-account roles", "Service Control Policy(SCP)", "Root Organizational Unit"], "Commentary": "이 문제는 여러 AWS 계정에 걸쳐 특정 서비스 또는 작업에 대한 액세스를 제한하여 조직의 거버넌스를 일원화하고자 할 때 가장 적합한 방안을 묻습니다. SCP(Service Control Policy)를 사용하면 조직 전체의 최대 권한 범위를 중앙에서 정의하여, 모든 계정의 접근 권한을 일괄적으로 제어할 수 있습니다.", "Selections": {"SelectA": {"Select": "ACL을 만들어 해당 서비스나 작업에 대한 액세스를 제공하십시오.", "Commentary": "ACL은 주로 리소스 수준 접근 제어를 위한 방식이며, 여러 계정을 중앙에서 제어하기에는 적합하지 않습니다."}, "SelectB": {"Select": "Security Group을 생성하여 계정들을 허용하고 사용자 그룹에 연결하십시오.", "Commentary": "Security Group은 네트워크 트래픽을 제어하는 보안 경계로, 서비스나 작업에 대한 IAM 기반 제한과는 다른 목적의 기능입니다."}, "SelectC": {"Select": "각 계정에서 cross-account roles를 생성하여 해당 서비스나 작업을 거부하십시오.", "Commentary": "각 계정별로 cross-account roles를 설정하는 것은 관리 지점이 분산되어 확장성과 단일 관리 포인트 요구사항을 충족하지 못합니다."}, "SelectD": {"Select": "Root Organizational Unit에 Service Control Policy를 생성하여 서비스나 작업에 대한 액세스를 거부하십시오.", "Commentary": "조직 루트의 SCP로 모든 계정에 대해 중앙 집중형 권한 제한이 가능하며, 확장성 및 단일 지점 관리 요구사항을 충족하는 유일한 솔루션입니다."}}}
{"Question_Number": "Q169", "Question_Description": "회사는 최근 웹 공격으로 인해 퍼블릭 웹 애플리케이션의 보안에 대해 우려하고 있습니다. 애플리케이션은 Application Load Balancer(ALB)를 사용하고 있습니다. 솔루션스 아키텍트는 애플리케이션에 대한 DDoS 공격 위험을 줄여야 합니다. 다음 중 이 요구사항을 충족하는 것은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["Application Load Balancer", "DDoS 공격", "AWS Shield Advanced"], "Terms": ["Application Load Balancer (ALB)", "DDoS", "Amazon Inspector", "Amazon Macie", "AWS Shield Advanced", "Amazon GuardDuty"], "Commentary": "이 문제는 퍼블릭 웹 애플리케이션을 보호하기 위해 DDoS 공격 위험을 낮추는 방법을 묻습니다. AWS Shield Advanced는 Application Load Balancer와 같은 리소스에 대해 더 강력한 DDoS 방어를 제공하므로 가장 적합한 해법입니다. 다른 서비스들은 각각 보안 검사, 데이터 식별, 이상 징후 모니터링 용도로 주로 사용되므로 DDoS 완화에는 직접적인 도움이 되지 않습니다.", "Selections": {"SelectA": {"Select": "ALB에 Amazon Inspector 에이전트를 추가합니다.", "Commentary": "Amazon Inspector는 애플리케이션 보안 취약점을 검사하는 데 사용되지만, DDoS 완화와는 직접적인 연관이 없어 요구사항에 부합하지 않습니다."}, "SelectB": {"Select": "Amazon Macie를 구성하여 공격을 방지합니다.", "Commentary": "Amazon Macie는 S3 내 민감 정보 탐지나 데이터 보안 관리에 초점을 둔 서비스로, DDoS 공격 방어와는 무관합니다."}, "SelectC": {"Select": "AWS Shield Advanced를 활성화하여 공격을 방지합니다.", "Commentary": "AWS Shield Advanced는 ALB 및 기타 리소스에 대한 DDoS 공격을 감지하고 완화하는 강력한 기능을 제공하므로 요구사항에 가장 적합합니다."}, "SelectD": {"Select": "Amazon GuardDuty를 구성하여 ALB를 모니터링합니다.", "Commentary": "Amazon GuardDuty는 악성 활동을 감지하고 알람을 제공하나, 공격을 직접 차단하거나 완화하는 기능은 없어 DDoS 방어 역할을 수행하기 어렵습니다."}}}
{"Question_Number": "Q170", "Question_Description": "한 회사의 웹 애플리케이션이 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스에서 구동 중입니다. 회사는 최근 정책을 변경하여, 이제 해당 애플리케이션이 오직 한 특정 국가에서만 액세스되도록 해야 합니다. 이를 만족하는 구성은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["특정 국가", "Application Load Balancer", "Amazon EC2", "AWS WAF", "네트워크 ACL"], "Terms": ["Security Group", "Application Load Balancer", "AWS WAF", "Geo Match Condition", "Network ACL"], "Commentary": "이 문제는 애플리케이션에 대한 접근을 특정 국가로 제한하기 위한 보안 구성이 핵심입니다. Security Group이나 Network ACL은 IP 주소 기반 제어가 주가 되어 국가 제한에 비효율적입니다. 반면 AWS WAF의 Geo Match Condition을 사용하면 지리적 위치로 접근 제한이 가능하여 요구사항을 간단히 충족할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스에 대한 Security Group을 구성합니다.", "Commentary": "Security Group은 IP 주소 또는 포트 기반의 제한만 가능해 국가 기준의 접근 제어에는 적합하지 않습니다."}, "SelectB": {"Select": "Application Load Balancer에 대한 Security Group을 구성합니다.", "Commentary": "역시 IP 주소 기반으로만 제한이 가능해 특정 국가를 선택적으로 허용하기에는 한계가 있습니다."}, "SelectC": {"Select": "VPC 내 Application Load Balancer에 AWS WAF를 구성합니다.", "Commentary": "AWS WAF의 Geo Match Condition을 이용해 특정 국가에서만 접근을 허용할 수 있어 요구사항을 정확히 충족하는 정답입니다."}, "SelectD": {"Select": "Amazon EC2 인스턴스가 포함된 서브넷의 Network ACL을 구성합니다.", "Commentary": "Network ACL 역시 IP 주소 범위를 통한 제한만 가능하므로, 국가별 트래픽 제한에 적합하지 않습니다."}}}
{"Question_Number": "Q171", "Question_Description": "한 회사는 사용자들에게 item 가격을 기반으로 세금 계산을 자동화하는 API를 제공합니다. 이 회사는 연휴 시즌에만 폭주하는 문의로 인해 응답 시간이 느려집니다. Solutions Architect는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다. 이를 달성하기 위해 어떤 작업을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["자동화된 세금 계산", "API", "연휴 시즌", "확장 가능", "탄력적 솔루션", "Amazon API Gateway", "AWS Lambda"], "Terms": ["Amazon API Gateway", "AWS Lambda", "Amazon EC2", "Application Load Balancer"], "Commentary": "연휴 시즌에 급증하는 트래픽을 자동으로 처리하려면 서버리스 구조를 고려해야 합니다. Amazon API Gateway와 AWS Lambda는 이벤트 기반 확장으로 탄력적이며, 운영 부담과 비용 절감에도 유리합니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스에서 호스팅되는 API를 제공하고, API 요청 시 해당 EC2 인스턴스가 계산을 수행합니다.", "Commentary": "단일 Amazon EC2 인스턴스는 자동 확장이 어려워 트래픽 폭주 시 성능 저하가 발생할 수 있습니다."}, "SelectB": {"Select": "Amazon API Gateway로 REST API를 설계하여 item 이름을 받고, API Gateway가 AWS Lambda로 세금 계산을 전달합니다.", "Commentary": "서버리스 기반으로 이벤트 발생 시 Lambda가 자동 확장하므로, 높은 트래픽에도 안정적으로 대응하고 비용 효율적입니다."}, "SelectC": {"Select": "Application Load Balancer 뒤에 두 개의 Amazon EC2 인스턴스를 배치하여 item 이름을 받고 세금을 계산합니다.", "Commentary": "EC2 인스턴스를 둘로 늘렸으나 여전히 수동 확장 설정이 필요해 트래픽 급증에 유연하게 대응하기 어렵습니다."}, "SelectD": {"Select": "Amazon API Gateway로 REST API를 설계하고, Amazon EC2 인스턴스에서 호스팅된 API에 연결해 item 이름을 전달합니다.", "Commentary": "API Gateway 뒤의 EC2 인스턴스는 서버리스가 아니어서 자동 확장이 어렵고, Lambda를 사용하는 방식보다 탄력성과 비용 효율이 떨어집니다."}}}
{"Question_Number": "Q172", "Question_Description": "한 솔루션스 아키텍트가 애플리케이션을 위해 새로운 Amazon CloudFront distribution을 생성하고 있습니다. 사용자들이 제출하는 정보 중 일부는 민감합니다. 애플리케이션은 HTTPS를 사용하지만 추가적인 보안 계층이 필요합니다. 이 민감한 정보는 애플리케이션 스택 전반에서 보호되어야 하며, 특정 애플리케이션만 이 정보에 액세스할 수 있어야 합니다. 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2", "1.3"], "Keywords": ["민감한 정보", "애플리케이션 스택 보호", "HTTPS", "CloudFront", "Field-level encryption"], "Terms": ["Amazon CloudFront", "CloudFront Distribution", "HTTPS", "Signed URL", "Signed Cookie", "Field-level Encryption", "Origin Protocol Policy"], "Commentary": "민감 데이터는 단순히 HTTPS로만 보호하기에는 부족합니다. ‘CloudFront field-level encryption’을 사용하면 특정 필드를 선택적으로 암호화하여, 필요한 권한이 있는 서비스만 해당 데이터를 복호화할 수 있습니다. 이는 애플리케이션 스택 전역에서 데이터를 안전하게 유지하고, 특정 애플리케이션으로만 접근을 제한하기 위한 핵심 솔루션입니다.", "Selections": {"SelectA": {"Select": "CloudFront signed URL을 구성합니다.", "Commentary": "민감 정보를 직접 필드 단위로 보호하지 않고, 리소스 접근 제한을 위한 방법이므로 요구사항을 만족하지 못합니다."}, "SelectB": {"Select": "CloudFront signed cookie를 구성합니다.", "Commentary": "Signed cookie 역시 접근 제한 중심이므로, 애플리케이션 스택 전반에서의 민감 데이터 암호화에는 충분하지 않습니다."}, "SelectC": {"Select": "CloudFront field-level encryption profile을 구성합니다.", "Commentary": "민감 정보를 edge에서부터 암호화하여, 해당 데이터를 복호화할 수 있는 권한이 있는 애플리케이션만 접근 가능하게 하는 최적의 솔루션입니다."}, "SelectD": {"Select": "CloudFront를 구성하고 Origin Protocol Policy를 Viewer Protocol Policy에서 HTTPS Only로 설정합니다.", "Commentary": "HTTPS 통신으로 전송 구간 암호화만 수행하지만, 필드 단위 암호화까지 제공하지 않아 개별 민감 정보 보호 요구사항을 만족하지 못합니다."}}, "Reference": "Field-level encryption allows users to encrypt sensitive information at the edge and keep it encrypted throughout the entire application stack, ensuring only authorized applications with the credentials can decrypt it."}
{"Question_Number": "Q173", "Question_Description": "한 게임 회사가 AWS에서 브라우저 기반 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션 사용자는 Amazon S3에 저장된 대량의 동영상과 이미지를 소비합니다. 이 컨텐츠는 모든 사용자에게 동일합니다. 애플리케이션의 인기가 높아져 전 세계 수백만 명의 사용자가 이 미디어 파일에 액세스하고 있습니다. 회사는 원본에 대한 부하를 줄이면서 사용자에게 파일을 제공하려고 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["브라우저 기반 애플리케이션", "Amazon S3", "동영상과 이미지", "원본 부하 감소", "비용 효율", "전 세계 사용자", "Amazon CloudFront"], "Terms": ["AWS Global Accelerator", "Amazon CloudFront", "Amazon ElastiCache for Redis", "Amazon ElastiCache for Memcached", "Amazon S3"], "Commentary": "이 문제는 대규모 사용자에게 동일한 정적 콘텐츠(동영상, 이미지)를 효율적으로 전 세계로 배포하는 방법을 묻습니다. CloudFront는 Amazon S3 원본에 대한 부하를 줄이면서 빠른 콘텐츠 전송을 가능하게 합니다. 또한 요청이 집중되는 글로벌 엣지 로케이션을 이용해 지연을 최소화하고, 캐싱 기능으로 비용 효율을 높일 수 있습니다. 다른 옵션들보다 확장성과 경제성을 동시에 충족하기 때문에 가장 적합한 해법입니다.", "Selections": {"SelectA": {"Select": "웹 서버 앞단에 AWS Global Accelerator를 배포합니다.", "Commentary": "AWS Global Accelerator는 TCP/UDP 트래픽 가속에 유리하나, 정적 콘텐츠를 전 세계에 캐싱하여 비용을 절감하기에는 적절하지 않습니다."}, "SelectB": {"Select": "S3 버킷 앞단에 Amazon CloudFront 웹 배포를 구성합니다.", "Commentary": "정적 콘텐츠를 캐싱해 전 세계에 빠르게 전달하고, 원본 부하도 줄일 수 있는 가장 비용 효율적 솔루션입니다."}, "SelectC": {"Select": "웹 서버 앞단에 Amazon ElastiCache for Redis를 배포합니다.", "Commentary": "Redis는 빠른 인메모리 캐시지만, 글로벌 캐시에 적합하지 않고 다중 리전에 분산 서비스하기에는 비용이나 구성 측면에서 비효율적입니다."}, "SelectD": {"Select": "웹 서버 앞단에 Amazon ElastiCache for Memcached를 배포합니다.", "Commentary": "Memcached 역시 내부 애플리케이션 캐싱용으로 적합하지만, 전 세계 사용자에게 S3 콘텐츠를 제공하는 CDN 역할은 수행하기 어렵습니다."}}}
{"Question_Number": "Q174", "Question_Description": "한 회사가 단일 Availability Zone 내에 있는 Application Load Balancer(ALB) 뒤에서, Amazon EC2 Auto Scaling 그룹에 속한 6대의 프론트엔드 웹 서버를 사용하는 다중 계층 애플리케이션을 운영하고 있습니다. 솔루션스 아키텍트는 애플리케이션을 수정하지 않고도 인프라를 고가용성으로 만들기를 원합니다. 이러한 고가용성을 제공하기 위한 아키텍처는 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["고가용성", "Amazon EC2 Auto Scaling", "Application Load Balancer", "Availability Zone", "다중 AZ"], "Terms": ["Amazon EC2", "Auto Scaling group", "Application Load Balancer(ALB)", "Availability Zone", "Region"], "Commentary": "이 문제는 단일 AZ에 집중된 웹 서버를 다중 AZ로 확장하여 고가용성을 확보하는 방법을 묻고 있습니다. Auto Scaling 그룹과 ALB를 두 개 이상의 AZ로 확장하면, 한 AZ에 장애가 발생하더라도 다른 AZ에서 트래픽을 처리할 수 있어 중단 없이 서비스를 유지할 수 있습니다. 따라서 다중 AZ를 활용하는 것이 핵심 포인트입니다.", "Selections": {"SelectA": {"Select": "두 개의 Region에 각각 3개 인스턴스를 사용하는 Auto Scaling 그룹을 생성합니다.", "Commentary": "Auto Scaling 그룹은 일반적으로 단일 Region 내에서만 구성 가능합니다. Region 단위로 인스턴스를 분산하는 것은 운영상 복잡하며, 간단한 AZ 단위 확장으로도 충분한 고가용성을 확보할 수 있습니다."}, "SelectB": {"Select": "Auto Scaling 그룹을 수정하여 두 개의 Availability Zone에 각각 3개의 인스턴스를 사용하도록 설정합니다.", "Commentary": "두 개의 AZ로 인스턴스를 분산 배치하면, 한 AZ에서 문제가 발생해도 다른 AZ에서 트래픽 처리가 가능해 고가용성을 달성할 수 있는 가장 적합한 방법입니다."}, "SelectC": {"Select": "빠르게 다른 Region에서 더 많은 인스턴스를 생성할 수 있도록 Auto Scaling 템플릿을 작성합니다.", "Commentary": "Region을 넘나드는 구성보다 다중 AZ 구성이 훨씬 간단하고 효율적입니다. 템플릿만으로는 자동으로 다중 AZ 고가용성을 보장할 수 없습니다."}, "SelectD": {"Select": "Amazon EC2 인스턴스 앞단의 ALB를 라운드 로빈으로 설정하여 웹 계층으로 트래픽을 분산합니다.", "Commentary": "기존에 이미 ALB가 존재하므로 라운드 로빈 설정만으로는 여러 AZ로 인스턴스를 분산하지 않습니다. AZ 간 분산 배치를 해야 진정한 고가용성을 확보할 수 있습니다."}}}
{"Question_Number": "Q175", "Question_Description": "한 이커머스 회사는 Amazon API Gateway와 AWS Lambda function을 사용하는 주문 처리 애플리케이션을 운영하고 있습니다. 애플리케이션은 데이터를 Amazon Aurora PostgreSQL 데이터베이스에 저장합니다. 최근 할인 행사 기간에 고객 주문이 급증하여 일부 고객들은 타임아웃을 겪었고, 이 고객들의 주문은 처리되지 않았습니다. 솔루션스 아키텍트는 데이터베이스에 열려 있는 연결이 매우 많아 CPU 및 메모리 사용량이 높다는 사실을 파악했습니다. 솔루션스 아키텍트는 애플리케이션에 대한 변경을 최소화하면서 타임아웃 오류를 방지해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["이커머스", "주문 처리", "타임아웃", "CPU 및 메모리 사용량", "연결 과부하", "Amazon Aurora PostgreSQL"], "Terms": ["Amazon API Gateway", "AWS Lambda", "Amazon Aurora PostgreSQL", "Amazon RDS Proxy", "Amazon DynamoDB", "AWS Database Migration Service (AWS DMS)", "글로벌 데이터베이스", "Read Replica"], "Commentary": "이 문제에서는 주문이 급증할 때 다수의 데이터베이스 연결로 인해 발생하는 과부하를 해결해야 합니다. Amazon RDS Proxy를 사용하면 데이터베이스 연결 풀을 제공하여 Lambda function이 불필요하게 많은 연결을 생성하는 상황을 방지하고, 성능과 확장성을 높일 수 있습니다. 최소한의 애플리케이션 변경으로 타임아웃 문제를 해결할 수 있기 때문에 Amazon RDS Proxy를 사용하는 것이 가장 적절한 방법입니다.", "Selections": {"SelectA": {"Select": "Lambda function에 대해 Provisioned Concurrency를 구성합니다. 데이터베이스를 여러 AWS 리전에 걸친 글로벌 데이터베이스로 수정합니다.", "Commentary": "Provisioned Concurrency는 Lambda의 실행 시작 지연 문제를 줄여주지만, 데이터베이스 연결 수 문제를 직접 해결해주지 못합니다. 또한 글로벌 데이터베이스로 변경하는 것은 복잡하며, 연결 폭주 자체를 완화하는 핵심 대안이 아닙니다."}, "SelectB": {"Select": "Amazon RDS Proxy를 사용하여 데이터베이스 프록시를 생성합니다. Lambda function이 데이터베이스 엔드포인트 대신 RDS Proxy 엔드포인트를 사용하도록 수정합니다.", "Commentary": "RDS Proxy를 사용하면 연결 풀이 가능해져, 데이터베이스 연결 과부하를 완화하고 CPU/메모리 사용량을 줄일 수 있습니다. 애플리케이션 수정이 최소화되며, 타임아웃 문제를 가장 효과적으로 해결합니다."}, "SelectC": {"Select": "다른 AWS 리전에 데이터베이스 Read Replica를 생성합니다. API Gateway에서 쿼리 스트링 파라미터를 사용하여 트래픽을 해당 Read Replica로 라우팅합니다.", "Commentary": "Read Replica는 읽기 요청을 분산시키지만, 주문 처리는 쓰기 작업이 포함됩니다. 쓰기 트래픽은 그대로 원본 DB로 집중되므로 연결 급증 문제의 근본적 해결책이 되지 못합니다."}, "SelectD": {"Select": "AWS Database Migration Service (AWS DMS)를 사용해 Aurora PostgreSQL 데이터를 Amazon DynamoDB로 마이그레이션합니다. Lambda function이 DynamoDB 테이블을 사용하도록 수정합니다.", "Commentary": "DynamoDB로 이전하면 스케일 이점을 얻을 수 있지만, 데이터베이스 구조 변경이 크고 애플리케이션 수정도 많아집니다. 문제에서 요구하는 ‘최소한의 변경’에는 부합하지 않습니다."}}}
{"Question_Number": "Q176", "Question_Description": "어플리케이션이 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되고 있습니다. 이 어플리케이션은 Amazon DynamoDB 테이블에 액세스해야 합니다. 트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 가장 안전하게 테이블에 액세스하려면 어떤 방법을 선택해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["프라이빗 서브넷", "DynamoDB 테이블", "트래픽 보호", "AWS 네트워크", "Amazon EC2"], "Terms": ["Amazon EC2", "Amazon DynamoDB", "VPC endpoint", "NAT gateway", "NAT instance", "Internet gateway", "private subnet", "public subnet"], "Commentary": "이 문제는 프라이빗 서브넷에서 실행되는 EC2 인스턴스가 DynamoDB에 직접 접근해야 할 때, 해당 트래픽을 AWS 내부에서만 처리하여 보안을 강화하는 방안을 묻습니다. VPC endpoint는 외부 인터넷을 거치지 않고도 DynamoDB에 액세스할 수 있어 가장 안전하고 효율적인 해결책입니다.", "Selections": {"SelectA": {"Select": "VPC endpoint를 사용하여 DynamoDB에 액세스합니다.", "Commentary": "트래픽이 외부 인터넷을 거치지 않고 AWS 네트워크 내부에서 안전하게 처리됩니다. 가장 권장되는 방법입니다."}, "SelectB": {"Select": "퍼블릭 서브넷에 있는 NAT gateway를 사용합니다.", "Commentary": "NAT gateway는 사용 시 인터넷 경유가 발생하므로 트래픽이 AWS 네트워크를 벗어날 수 있어 보안 측면에서 비효율적입니다."}, "SelectC": {"Select": "프라이빗 서브넷에 NAT 인스턴스를 사용합니다.", "Commentary": "NAT 인스턴스도 인터넷을 통해 DynamoDB에 연결하게 되므로 트래픽이 AWS 네트워크를 벗어납니다."}, "SelectD": {"Select": "VPC에 연결된 internet gateway를 사용합니다.", "Commentary": "internet gateway는 직접 퍼블릭 인터넷으로 연결되므로 안전하게 내부 통신만 사용하는 방법이 아닙니다."}}}
{"Question_Number": "Q177", "Question_Description": "한 엔터테인먼트 회사가 미디어 메타데이터를 저장하기 위해 Amazon DynamoDB를 사용하고 있습니다. 애플리케이션이 읽기 중심적이며 지연이 발생하고 있습니다. 이 회사에는 추가 운영 오버헤드를 처리할 인력이 없으며, 애플리케이션을 재구성하지 않고 DynamoDB의 성능 효율을 개선해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["성능 효율", "읽기 지연", "DynamoDB", "DAX"], "Terms": ["Amazon DynamoDB", "Amazon ElastiCache for Redis", "Amazon DynamoDB Accelerator (DAX)", "DynamoDB global tables", "Amazon ElastiCache for Memcached", "In-memory cache", "Auto Discovery"], "Commentary": "이 문제는 DynamoDB에서 읽기 지연이 발생하는 상황에서, 애플리케이션 재구성 없이 빠른 응답 시간을 확보할 수 있는 캐싱 솔루션을 찾는 것입니다. 완전관리형 인메모리 캐시인 Amazon DAX가 DynamoDB와 밀접하게 연동되어 운영 부담을 최소화하면서 읽기 성능을 크게 향상시킵니다.", "Selections": {"SelectA": {"Select": "Amazon ElastiCache for Redis를 사용하십시오.", "Commentary": "Redis는 범용 인메모리 데이터 스토어로서 빠른 성능을 제공하지만, DynamoDB와 직접 연동하려면 애플리케이션 코드 변경 및 추가 구성 작업이 필요합니다."}, "SelectB": {"Select": "Amazon DynamoDB Accelerator (DAX)를 사용하십시오.", "Commentary": "DAX는 DynamoDB 전용 완전관리형 인메모리 캐시 솔루션으로, 애플리케이션 변경을 최소화하면서 읽기 요청의 지연을 극적으로 개선할 수 있습니다."}, "SelectC": {"Select": "DynamoDB Global Tables를 사용하여 데이터를 복제하십시오.", "Commentary": "글로벌 테이블은 다중 리전에 걸친 데이터 복제로 고가용성과 지연 감소에 기여하지만, 단순 캐싱 문제 해결보다는 더 복잡한 구성을 요구합니다."}, "SelectD": {"Select": "Auto Discovery가 활성화된 Amazon ElastiCache for Memcached를 사용하십시오.", "Commentary": "Memcached 역시 캐싱 솔루션이지만, DynamoDB와 직접 연동되는 DAX보다 운영 편의성과 호환성 측면에서 이점이 적습니다."}}}
{"Question_Number": "Q178", "Question_Description": "한 회사가 단일 AWS Region 내 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성된 인프라를 운영하고 있습니다. 이 회사는 별도의 Region에도 데이터를 백업하려고 합니다. 가장 낮은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Amazon EC2 인스턴스", "Amazon RDS DB", "별도 Region 백업", "AWS Backup", "운영 오버헤드"], "Terms": ["AWS Backup", "Amazon Data Lifecycle Manager (Amazon DLM)", "Amazon Machine Images (AMIs)", "Read Replica", "Amazon EBS Snapshot", "S3 Cross-Region Replication (CRR)"], "Commentary": "단일 Region에서 운영되는 EC2와 RDS 데이터를 별도 Region으로 백업하는 방법을 묻는 문제로, 자동화와 운영 복잡도 최소화가 핵심 포인트입니다. AWS Backup은 교차 Region 백업 자동화를 제공하여 최소한의 작업으로 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "AWS Backup을 사용하여 EC2 백업과 RDS 백업을 별도 Region으로 복사합니다.", "Commentary": "AWS Backup은 백업 자동화와 교차 Region 복사를 모두 지원해 추가 설정이 적고 운영 오버헤드가 가장 낮습니다."}, "SelectB": {"Select": "Amazon Data Lifecycle Manager(Amazon DLM)을 사용하여 EC2 백업과 RDS 백업을 별도 Region으로 복사합니다.", "Commentary": "Amazon DLM은 주로 EC2 스냅샷 용도로 사용되며, RDS 백업 교차 Region 복사는 직접 지원하지 않아 운영이 복잡해집니다."}, "SelectC": {"Select": "EC2 인스턴스의 AMI를 생성하고 이를 별도 Region으로 복사합니다. RDS DB 인스턴스의 리드 레플리카를 별도 Region에 생성합니다.", "Commentary": "AMI 복사와 별도 리드 레플리카 구성은 자동화가 제한적이고 단계가 많아 운영 오버헤드가 증가합니다."}, "SelectD": {"Select": "Amazon EBS 스냅샷을 생성해 별도 Region으로 복사하고, RDS 스냅샷을 만들어 Amazon S3로 내보낸 뒤, S3 Cross-Region Replication(CRR)을 설정합니다.", "Commentary": "EBS 스냅샷 복사, RDS 스냅샷 내보내기와 CRR 구성 등 단계가 많아 운영 복잡도가 높아집니다."}}}
{"Question_Number": "Q179", "Question_Description": "한 솔루션스 아키텍트는 Amazon RDS DB instance에 액세스하기 위해 애플리케이션이 사용하는 데이터베이스 사용자 이름과 비밀번호를 안전하게 저장해야 합니다. 데이터베이스에 액세스하는 애플리케이션은 Amazon EC2 instance에서 실행됩니다. 솔루션스 아키텍트는 AWS Systems Manager Parameter Store에 보안을 갖춘 파라미터를 생성하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["Amazon RDS DB instance", "Amazon EC2 instance", "AWS Systems Manager Parameter Store", "데이터베이스 사용자 이름", "비밀번호를 안전하게 저장", "IAM role", "AWS Key Management Service(AWS KMS)", "암호화"], "Terms": ["AWS Systems Manager Parameter Store", "Amazon RDS DB instance", "Amazon EC2 instance", "AWS Key Management Service (AWS KMS)", "IAM role", "Decrypt", "IAM trust relationship"], "Commentary": "이 문제는 Parameter Store에서 중요한 자격 정보를 안전하게 관리하면서 Amazon EC2 instance가 해당 정보를 정상적으로 읽어올 수 있도록 하는 방법을 묻습니다. 적절한 보안 액세스와 KMS를 통한 암호화를 적용해야 하며, IAM role을 활용하여 EC2 instance가 필요한 권한만 부여받도록 구성하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "IAM role을 생성하여 Parameter Store 파라미터에 대한 읽기 권한을 부여하고, 해당 파라미터 암호화에 사용되는 AWS KMS key에 대해 Decrypt 권한을 허용합니다. 이 IAM role을 EC2 instance에 할당합니다.", "Commentary": "정답입니다. EC2 instance에 할당된 IAM role이 필요 권한을 가진 상태로 Parameter Store와 KMS를 안전하게 사용합니다."}, "SelectB": {"Select": "Parameter Store 파라미터에 대해 읽기 권한을 허용하는 IAM policy를 생성하고, 이 파라미터 암호화에 사용되는 AWS KMS key에 대해 Decrypt 권한을 허용합니다. 이 IAM policy를 EC2 instance에 할당합니다.", "Commentary": "IAM policy만 생성하여 인스턴스에 직접 할당하는 것은 일반적으로 사용하지 않는 방식이며, Instance Profile을 통한 IAM role 할당이 모범 사례입니다."}, "SelectC": {"Select": "Parameter Store 파라미터와 EC2 instance 간 IAM trust relationship을 생성하고, Amazon RDS를 트러스트 정책의 주체로 지정합니다.", "Commentary": "Amazon RDS를 주체로 지정할 이유가 없으며, Parameter Store 파라미터와 EC2 간에 직접적인 신뢰 관계를 구성하는 방식도 적절하지 않습니다."}, "SelectD": {"Select": "DB instance와 EC2 instance 간 IAM trust relationship을 생성하고, Systems Manager를 트러스트 정책의 주체로 지정합니다.", "Commentary": "DB instance와 EC2 사이의 신뢰 관계 설정은 본 문제의 요구사항인 Parameter Store 파라미터 및 KMS 활용과는 관련이 없습니다."}}}
{"Question_Number": "Q180", "Question_Description": "한 회사가 API 기반의 클라우드 통신 플랫폼을 설계하고 있습니다. 애플리케이션은 Network Load Balancer(NLB) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 회사는 Amazon API Gateway를 통해 외부 사용자들에게 애플리케이션에 대한 접근을 제공합니다. 회사는 SQL injection과 같은 웹 공격을 방어하고, 대규모·고도화된 DDoS 공격을 탐지 및 완화하기를 원합니다. 이러한 요구사항을 가장 효과적으로 충족하는 솔루션 조합은 무엇입니까? (2개를 선택하세요.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["Network Load Balancer", "Amazon API Gateway", "AWS WAF", "SQL injection", "DDoS", "AWS Shield Advanced"], "Terms": ["Amazon EC2", "Network Load Balancer(NLB)", "Amazon API Gateway", "AWS WAF", "AWS Shield Advanced", "AWS Shield Standard", "Amazon GuardDuty", "SQL injection", "DDoS"], "Commentary": "이 문제는 웹 공격(SQL injection)과 대규모 DDoS 공격을 모두 방어하려면 어떤 조합이 필요한지 묻습니다. AWS WAF는 애플리케이션 계층(레이어 7)에서 SQL injection 등 웹 공격을 차단하고, AWS Shield Advanced는 규모가 큰 고도화된 DDoS 공격에 대해 자동 완화와 지원(비용 보호, SRT 연계)을 제공합니다. NLB는 레이어 4에서 동작하기 때문에 웹 계층의 공격 방어를 위해서는 별도로 API Gateway에 WAF를 적용해야 합니다. 따라서 웹 취약점 방어를 위해 AWS WAF를 API Gateway에 적용하고, DDoS에 대한 최상의 방어를 위해 AWS Shield Advanced를 NLB 또는 Gateway에 적용하는 것이 가장 효과적입니다.", "Selections": {"SelectA": {"Select": "Use AWS WAF to protect the NLB.", "Commentary": "NLB는 레이어 4 로드 밸런싱이므로 AWS WAF를 직접 적용하기 어렵습니다. 따라서 웹 공격(SQL injection) 방어에 적절하지 않습니다."}, "SelectB": {"Select": "Use AWS Shield Advanced with the NLB.", "Commentary": "대규모·고도화된 DDoS 공격에 대한 가장 강력한 보호 기능을 제공하며, 비용 보호 및 전문가 지원을 받을 수 있어 올바른 선택입니다."}, "SelectC": {"Select": "Use AWS WAF to protect Amazon API Gateway.", "Commentary": "AWS WAF가 웹 계층 공격(SQL injection 등)을 효과적으로 차단할 수 있어, API Gateway에 적용하는 것은 적절한 선택입니다."}, "SelectD": {"Select": "Use Amazon GuardDuty with AWS Shield Standard.", "Commentary": "Amazon GuardDuty는 보안 위협 모니터링에 유용하나, Shield Standard만으로는 고도화된 대규모 DDoS 공격에 대한 완전한 보호가 어렵습니다."}, "SelectE": {"Select": "Use AWS Shield Standard with Amazon API Gateway.", "Commentary": "Shield Standard는 기본적인 DDoS 완화 기능만을 제공하므로, 더욱 강력한 보호가 필요한 시나리오에 적합하지 않습니다."}}}
{"Question_Number": "Q181", "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 실행되는 레거시 데이터 처리 애플리케이션을 사용하고 있습니다. 데이터는 순차적으로 처리되지만 결과 순서는 중요하지 않습니다. 현재 monolithic 아키텍처를 사용하며, 수요 증가 시 인스턴스 크기를 키우는 방식으로만 확장해 왔습니다. 이제 개발자들은 애플리케이션을 Amazon ECS 기반의 microservices 아키텍처로 재작성하려 합니다. 이때 마이크로서비스 간 통신을 위해 Solutions Architect가 권장해야 할 방법은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["Amazon EC2 인스턴스", "monolithic 아키텍처", "microservices 아키텍처", "Amazon ECS", "Amazon SQS", "스케일링", "비동기 통신"], "Terms": ["Amazon Simple Queue Service (Amazon SQS)", "Amazon Simple Notification Service (Amazon SNS)", "AWS Lambda", "Amazon DynamoDB", "DynamoDB Streams", "메시지 큐", "pub/sub"], "Commentary": "microservices 간에는 느슨한 결합과 비동기 메시징이 핵심입니다. Amazon SQS는 메시지 순서가 중요하지 않은 환경에서 훌륭한 확장성과 유연성을 제공합니다.", "Selections": {"SelectA": {"Select": "Amazon SQS 큐를 생성합니다. 데이터 프로듀서 코드에서 큐로 메시지를 전송하고, 데이터 컨슈머 코드에서 큐에서 메시지를 처리하도록 합니다.", "Commentary": "마이크로서비스를 느슨하게 결합하고, 순서가 중요치 않은 비동기 처리에 적합한 방법입니다."}, "SelectB": {"Select": "Amazon SNS 토픽을 생성합니다. 프로듀서 코드에서 토픽으로 알림을 발행하고, 컨슈머 코드에서 해당 토픽을 구독합니다.", "Commentary": "SNS는 1:N 형태에 적합한 pub/sub 모델로, 특정 컨슈머 간의 점대점 메시징에 맞지 않습니다."}, "SelectC": {"Select": "AWS Lambda 함수를 생성하여 메시지를 전달합니다. 프로듀서 코드에서 Lambda 함수를 호출해 데이터를 넘기고, 컨슈머 코드에서 Lambda가 전달하는 데이터를 받습니다.", "Commentary": "직접 Lambda 함수를 호출해야 하므로 완전히 비동기적이지 않고, 마이크로서비스 간 분리도가 낮아집니다."}, "SelectD": {"Select": "Amazon DynamoDB 테이블을 만들고 DynamoDB Streams를 활성화합니다. 프로듀서 코드에서 테이블에 데이터를 삽입하고, 컨슈머 코드에서 Streams API를 통해 새 항목을 감지해 처리합니다.", "Commentary": "데이터 처리를 위해 주기적으로 Streams를 확인해야 하므로 큐 기반 비동기 방식에 비해 단순성이 떨어집니다."}}}
{"Question_Number": "Q182", "Question_Description": "한 회사가 온프레미스의 MySQL 데이터베이스를 AWS로 마이그레이션하려고 합니다. 이 회사는 최근에 데이터베이스 장애가 발생하여 비즈니스에 큰 영향을 받았습니다. 이를 다시 겪지 않도록, 회사는 트랜잭션을 최소 두 개 노드에 저장하며 데이터 손실을 최소화하는 안정적인 AWS 기반 데이터베이스 솔루션을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["MySQL 데이터베이스 마이그레이션", "데이터 손실 최소화", "트랜잭션", "Multi-AZ", "동기 복제", "Amazon RDS"], "Terms": ["RDS MySQL DB instance", "Multi-AZ", "Synchronous Replication", "Read Replica", "Amazon EC2", "AWS Lambda", "노드", "트랜잭션"], "Commentary": "이 문제의 핵심은 최소 두 노드에 트랜잭션을 동기 복제하여 데이터 손실 위험을 극도로 낮추는 고가용성 아키텍처를 구축하는 것입니다. Amazon RDS for MySQL에서 Multi-AZ를 활성화하면, 기본 노드와 스탠바이 노드 간에 동기 복제가 이루어져 장애 시에도 데이터 손실을 최소화할 수 있습니다. 이 표준 방식은 AWS가 자동으로 관리해주므로 운영 부담도 적고 안정성이 높습니다.", "Selections": {"SelectA": {"Select": "Amazon RDS DB 인스턴스를 생성하고, 세 개의 가용 영역(Availability Zones)에 동기 복제를 설정합니다.", "Commentary": "기본 RDS MySQL 구성만으로는 세 AZ로의 동기 복제는 보장되지 않습니다. 일반적으로 Multi-AZ는 두 AZ 구성이며, 세 AZ는 별도의 구성 또는 Amazon Aurora와 같은 다른 서비스를 고려해야 합니다."}, "SelectB": {"Select": "Amazon RDS MySQL DB 인스턴스를 생성하고, Multi-AZ 기능을 활성화하여 데이터를 동기 복제합니다.", "Commentary": "Multi-AZ 기능은 기본 노드와 스탠바이 노드 간 동기 복제를 제공하여 장애 시 즉시 전환이 가능하고 데이터 손실이 거의 없는 고가용성 솔루션이므로 요구사항에 부합합니다."}, "SelectC": {"Select": "Amazon RDS MySQL DB 인스턴스를 생성한 후, 별도의 AWS 리전에 리드 레플리카를 생성하여 데이터를 동기 복제합니다.", "Commentary": "리드 레플리카는 비동기 복제이므로 동기 복제가 필수인 이 시나리오에 적합하지 않습니다. 데이터 손실 위험이 남아 있습니다."}, "SelectD": {"Select": "MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성하고, AWS Lambda 함수를 트리거하여 Amazon RDS MySQL DB 인스턴스로 데이터를 동기 복제합니다.", "Commentary": "직접 동기 복제를 구현하기 위해 여러 서비스를 연동하는 방식으로 복잡도가 매우 높고, 자동화된 고가용성 기능을 제공하지 않으므로 권장되지 않습니다."}}}
{"Question_Number": "Q183", "Question_Description": "한 회사가 새로운 동적 Ordering 웹사이트를 구축하려고 합니다. 이 회사는 서버 유지 관리와 패치를 최소화하고자 합니다. 웹사이트는 고가용성을 가져야 하며, 사용자 수요 변화에 따라 읽기 및 쓰기 용량을 빠르게 확장할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["동적 Ordering 웹사이트", "서버 유지 관리 최소화", "고가용성", "빠른 읽기/쓰기 확장", "Amazon S3", "Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB on-demand", "Amazon Aurora", "Amazon CloudFront"], "Terms": ["Amazon S3", "Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB", "On-demand capacity", "Amazon Aurora", "Aurora Auto Scaling", "Amazon EC2", "Auto Scaling group", "Application Load Balancer", "Provisioned write capacity", "Amazon CloudFront"], "Commentary": "이 문제는 서버 관리를 최소화하면서 고가용성 및 빠른 확장을 요구하는 웹 애플리케이션 아키텍처를 묻습니다. 정답은 서버리스와 Amazon DynamoDB on-demand로 즉시 스케일링이 가능한 A입니다.", "Selections": {"SelectA": {"Select": "static content를 Amazon S3에 호스팅합니다. dynamic content는 Amazon API Gateway와 AWS Lambda를 사용합니다. 데이터베이스로 Amazon DynamoDB(on-demand capacity)를 사용합니다. Amazon CloudFront를 구성하여 웹사이트 콘텐츠를 전달합니다.", "Commentary": "서버리스 기반 구성으로 서버 유지 관리가 없고, Amazon DynamoDB on-demand로 읽기/쓰기를 즉시 확장하여 고가용성과 민첩성을 모두 만족합니다."}, "SelectB": {"Select": "static content를 Amazon S3에 호스팅합니다. dynamic content는 Amazon API Gateway와 AWS Lambda를 사용합니다. 데이터베이스로 Amazon Aurora와 Aurora Auto Scaling을 사용합니다. Amazon CloudFront를 구성하여 웹사이트 콘텐츠를 전달합니다.", "Commentary": "Aurora Auto Scaling은 읽기 복제본 확장 위주여서 쓰기 확장에는 제한이 있어 요구사항을 충분히 충족하지 못합니다."}, "SelectC": {"Select": "모든 웹사이트 콘텐츠를 Amazon EC2 인스턴스에서 호스팅합니다. Auto Scaling group을 생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer로 트래픽을 분산합니다. 데이터베이스로 Amazon DynamoDB(provisioned write capacity)를 사용합니다.", "Commentary": "EC2 인스턴스는 서버 유지 관리와 패치 부담이 크고, provisioned 용량 모드는 빠른 수요 변화 대응에 제약이 생깁니다."}, "SelectD": {"Select": "모든 웹사이트 콘텐츠를 Amazon EC2 인스턴스에서 호스팅합니다. Auto Scaling group을 생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer로 트래픽을 분산합니다. 데이터베이스로 Amazon Aurora와 Aurora Auto Scaling을 사용합니다.", "Commentary": "EC2 인스턴스 기반으로 서버 패치 부담이 있고, Aurora Auto Scaling은 읽기 위주 확장만 가능하며 쓰기 확장에는 제한이 있어 요구사항 충족이 어렵습니다."}}}
{"Question_Number": "Q184", "Question_Description": "한 회사가 소프트웨어 엔지니어링을 위해 사용하는 AWS account가 있습니다. 이 AWS account는 두 개의 AWS Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 접속할 수 있습니다. 모든 non-VPC 트래픽은 virtual private gateway로 라우팅됩니다. 최근 개발 팀이 console을 통해 AWS Lambda function을 생성했습니다. 이 Lambda function이 회사 데이터 센터의 private subnet에서 실행 중인 데이터베이스에 접근할 수 있게 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["AWS account", "AWS Direct Connect", "AWS Lambda function", "private subnet", "virtual private gateway", "security group", "route table"], "Terms": ["AWS account", "AWS Direct Connect", "VPC", "virtual private gateway", "AWS Lambda", "private subnet", "security group", "route table", "VPN", "Elastic IP", "elastic network interface(ENI)", "console"], "Commentary": "Lambda function이 온프레미스 DB에 안전하게 연결되려면, 이미 설정된 AWS Direct Connect 및 virtual private gateway를 활용해 VPC 내부에서 실행해야 합니다. 보안 그룹과 VPC 설정을 통해 트래픽을 제어하고 안정적으로 연결할 수 있습니다.", "Selections": {"SelectA": {"Select": "Lambda function을 해당 VPC에서 실행하도록 설정하고, 적절한 security group을 구성합니다.", "Commentary": "함수를 VPC 내부에 두면 기존 Direct Connect 연결을 활용하여 안전하고 직접적으로 온프레미스 DB에 접근할 수 있습니다."}, "SelectB": {"Select": "AWS에서 data center로의 VPN connection을 설정하고, Lambda function 트래픽을 VPN을 통해 전달합니다.", "Commentary": "이미 Direct Connect가 구성되어 있어 추가 VPN 연결은 불필요하며, 복잡도와 비용만 증가시킵니다."}, "SelectC": {"Select": "VPC의 route table을 업데이트하여 Lambda function이 Direct Connect를 통해 온프레미스 데이터 센터에 접근하도록 허용합니다.", "Commentary": "Route table만 수정해도 Lambda function이 기본적으로 VPC 내에서 실행되지 않으면 온프레미스 DB에 접근할 수 없습니다."}, "SelectD": {"Select": "Elastic IP address를 생성하고, Lambda function이 elastic network interface 없이 해당 Elastic IP address를 통해 트래픽을 전송하도록 구성합니다.", "Commentary": "Lambda function은 자체적으로 ENI를 사용해 VPC와 통신하므로 Elastic IP만으로는 온프레미스 DB 연결이 불가능합니다."}}}
{"Question_Number": "Q185", "Question_Description": "한 회사가 Amazon ECS를 사용하여 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 원본 이미지를 리사이즈한 후, Amazon S3 API 콜을 통해 리사이즈된 이미지를 Amazon S3에 저장합니다. 솔루션스 아키텍트는 어떻게 해야 애플리케이션에 Amazon S3에 대한 접근 권한을 부여할 수 있습니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon ECS", "Amazon S3", "IAM role", "리사이즈 이미지"], "Terms": ["Amazon ECS", "Amazon S3", "IAM role", "AWS Identity and Access Management(IAM)", "taskRoleArn", "Security Group"], "Commentary": "이 문제는 ECS 컨테이너가 S3에 직접 접근할 수 있도록 IAM 역할을 올바르게 설정하는 방법을 묻습니다. 가장 단순하고 안전한 방식은 IAM 역할을 생성하여 필요한 권한을 부여한 뒤, 해당 역할을 ECS 태스크 정의에 설정하는 것입니다.", "Selections": {"SelectA": {"Select": "AWS IAM에서 S3 role을 업데이트하여 Amazon ECS의 읽기/쓰기 권한을 허용하고, 컨테이너를 다시 시작합니다.", "Commentary": "S3 role만 수정해서는 ECS 태스크에 자동으로 권한이 부여되지 않습니다. 또한 재시작만으로 태스크별 역할이 반영되지 않습니다."}, "SelectB": {"Select": "S3 권한을 가진 IAM role을 생성한 뒤, 해당 role을 태스크 정의의 taskRoleArn으로 지정합니다.", "Commentary": "IAM 역할을 태스크에 직접 할당하면 컨테이너가 Amazon S3 API 호출을 안전하게 수행할 수 있어 요구사항을 충족합니다."}, "SelectC": {"Select": "Amazon ECS에서 Amazon S3로의 액세스를 허용하는 Security Group을 만들고, ECS 클러스터에서 사용하는 런치 구성에 반영합니다.", "Commentary": "Security Group은 네트워크 트래픽 제어용이며, S3 API 자격 증명 권한 부여와는 직접 관련이 없어 권한 문제를 해결하지 못합니다."}, "SelectD": {"Select": "S3 권한이 있는 IAM user를 생성하고, 해당 계정으로 로그인한 상태에서 ECS 클러스터용 Amazon EC2 인스턴스를 재시작합니다.", "Commentary": "EC2 인스턴스 수준 계정을 사용하는 것은 비효율적이고 보안 모범 사례에 어긋나며, 컨테이너 단위 IAM 권한 관리를 지원하지 못합니다."}}}
{"Question_Number": "Q186", "Question_Description": "한 회사가 Windows 기반 애플리케이션을 AWS로 마이그레이션해야 합니다. 이 애플리케이션은 여러 가용 영역(Availability Zone)에 배포된 여러 Amazon EC2 Windows 인스턴스에 공유 Windows 파일 시스템을 연결해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Windows 기반 애플리케이션", "공유 Windows 파일 시스템", "Amazon EC2 Windows 인스턴스", "Amazon FSx for Windows File Server", "Amazon EFS", "AWS Storage Gateway", "Amazon EBS"], "Terms": ["AWS Storage Gateway", "Volume Gateway mode", "Amazon FSx for Windows File Server", "SMB 프로토콜", "Amazon EFS", "NFS 프로토콜", "Amazon EBS", "멀티 AZ"], "Commentary": "이 문제는 Windows 환경에서 여러 AZ에 걸친 공유 파일 시스템이 필요할 때 올바른 AWS 서비스 선택을 묻습니다. Amazon FSx for Windows File Server는 SMB 기반 공유 파일 시스템을 제공하므로, Windows 애플리케이션이 요구하는 파일 잠금 및 권한 관리를 제대로 지원합니다. EFS는 Linux용 NFS 기반이므로 부적합하며, EBS는 단일 AZ 자원이기 때문에 다수의 인스턴스에서 동시 사용이 어렵습니다.", "Selections": {"SelectA": {"Select": "AWS Storage Gateway를 volume gateway 모드로 설정하고 각 Windows 인스턴스에 해당 볼륨을 마운트합니다.", "Commentary": "Storage Gateway는 온프레미스와 클라우드 통합 시 주로 사용되고, Windows 인스턴스에 대한 네이티브 SMB 공유를 제공하지 않아 요구 사항에 부적합합니다."}, "SelectB": {"Select": "Amazon FSx for Windows File Server를 구성하고, 각 Windows 인스턴스에 Amazon FSx 파일 시스템을 마운트합니다.", "Commentary": "FSx for Windows File Server는 SMB 기반 공유 파일 시스템을 제공하며, 멀티 AZ 환경에서도 고가용성과 Windows 파일 잠금을 지원하는 최적의 솔루션입니다."}, "SelectC": {"Select": "Amazon Elastic File System(Amazon EFS)을 구성하고 각 Windows 인스턴스에 해당 EFS 파일 시스템을 마운트합니다.", "Commentary": "EFS는 NFS 기반으로 Linux 워크로드에 최적화되어 Windows 인스턴스에서 SMB를 활용해야 하는 요구 사항을 충족하지 못합니다."}, "SelectD": {"Select": "필요한 크기의 Amazon EBS 볼륨을 생성한 뒤 각 EC2 인스턴스에 연결하고, 각 Windows 인스턴스에서 볼륨 내 파일 시스템을 마운트합니다.", "Commentary": "EBS는 단일 가용 영역 리소스이므로 여러 인스턴스가 동시에 공유하기 어렵고, 원하는 공유 파일 시스템 요구를 만족시키기 곤란합니다."}}}
{"Question_Number": "Q187", "Question_Description": "회사는 로드밸런싱된 프론트엔드, 컨테이너 기반 애플리케이션, 관계형 데이터베이스로 구성된 전자상거래 애플리케이션을 개발 중입니다. 솔루션스 아키텍트는 운영자의 수동 개입이 최소화된 상태로 고가용성을 달성해야 합니다. 다음 중 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (두 가지를 고르십시오.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["로드밸런싱", "컨테이너 기반 애플리케이션", "관계형 데이터베이스", "고가용성", "수동 개입 최소화", "Multi-AZ", "Amazon ECS", "Fargate"], "Terms": ["Amazon RDS", "Multi-AZ", "Read Replica", "Amazon ECS", "AWS Fargate", "Docker", "Amazon EC2"], "Commentary": "이 문제는 전자상거래 애플리케이션에서 고가용성을 구현하고 운영 부담을 최소화하는 방안을 묻습니다. Amazon RDS Multi-AZ 배포를 통해 장애 조치 시 자동화된 복구가 이루어지므로 낮은 수동 개입으로 고가용성을 보장할 수 있습니다. 또한 Amazon ECS를 Fargate launch type으로 사용하면 서버 인프라를 직접 관리할 필요가 없어 운영자가 개입할 부분을 크게 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Create an Amazon RDS DB instance in Multi-AZ mode.", "Commentary": "Multi-AZ 모드는 장애 발생 시 자동으로 대기 인스턴스로 전환되어 DB 가용성을 높이고 수동 개입을 최소화합니다."}, "SelectB": {"Select": "Create an Amazon RDS DB instance and one or more replicas in another Availability Zone.", "Commentary": "Read Replica는 장애 시 수동으로 프로모션해야 하므로 자동화와 즉각적인 장애 조치가 어렵습니다."}, "SelectC": {"Select": "Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load.", "Commentary": "EC2 인스턴스에서 Docker 클러스터를 직접 운영하면 인프라 관리 부담이 크고 수동 개입 필요성이 증가합니다."}, "SelectD": {"Select": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load.", "Commentary": "AWS Fargate는 서버 관리가 필요 없는 완전관리형 컨테이너 환경이므로, 동적으로 확장 가능하며 수동 개입을 크게 줄입니다."}, "SelectE": {"Select": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load.", "Commentary": "EC2 launch type은 사용자 측에서 클러스터와 EC2 인스턴스를 직접 관리해야 하므로 자동화 측면에서 덜 유리합니다."}}}
{"Question_Number": "Q188", "Question_Description": "한 회사는 Amazon S3를 데이터 레이크로 사용하고 있습니다. 회사에는 새로운 파트너가 있으며, 이 파트너는 SFTP를 통해 데이터 파일을 업로드해야 합니다. 솔루션스 아키텍트는 고가용성 SFTP 솔루션을 구현하면서 운영 오버헤드를 최소화할 필요가 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["SFTP", "고가용성", "운영 오버헤드 최소화", "AWS Transfer Family", "Amazon S3"], "Terms": ["AWS Transfer Family", "Amazon S3 File Gateway", "Amazon EC2", "Network Load Balancer", "cron job script", "VPN", "SFTP"], "Commentary": "이 문제는 새 파트너와의 SFTP 데이터 전송을 지원하면서도 운영 복잡성을 줄이고 고가용성을 확보해야 하는 상황을 다룹니다. AWS Transfer Family는 별도 인프라 생성 없이 간단히 SFTP 서버를 구성하고 Amazon S3와 직접 연동하여 고가용성을 자동으로 제공하므로 운영 오버헤드를 최소화할 수 있는 최적의 솔루션입니다.", "Selections": {"SelectA": {"Select": "AWS Transfer Family를 사용해 SFTP 활성 서버를 구성하고, 공개적으로 접근 가능한 엔드포인트를 설정합니다. Amazon S3 data lake를 대상으로 지정합니다.", "Commentary": "AWS Transfer Family는 별도 EC2 서버나 로드 밸런서 구성이 필요 없고, Amazon S3로 바로 전송 가능해 운영 비용과 복잡성을 대폭 줄입니다."}, "SelectB": {"Select": "Amazon S3 File Gateway를 SFTP 서버로 사용합니다. S3 File Gateway 엔드포인트 URL을 파트너에게 노출하고 공유합니다.", "Commentary": "S3 File Gateway는 SFTP를 직접 지원하지 않아 추가 설정이 필요하며, 운영 과정도 더 복잡해 최적의 솔루션이 아닙니다."}, "SelectC": {"Select": "Amazon EC2 인스턴스를 VPC의 사설 서브넷에 배포하고, 파트너가 VPN으로 접속해 파일을 업로드하도록 합니다. EC2 인스턴스 상의 cron job 스크립트를 통해 S3로 데이터를 전송합니다.", "Commentary": "VPN 설정과 EC2 유지보수가 필요하며, 고가용성을 위해서는 추가 구성이 복잡해 운영 오버헤드가 크게 늘어납니다."}, "SelectD": {"Select": "VPC의 사설 서브넷에 여럿의 Amazon EC2 인스턴스를 띄우고, Network Load Balancer(NLB)를 앞단에 배치해 SFTP 리스너 포트를 엽니다. NLB 호스트네임을 파트너에게 공유한 뒤, cron job으로 S3에 업로드합니다.", "Commentary": "NLB와 EC2 인스턴스 다중화로 고가용성은 가능하지만, 서버 유지 및 스크립트 작업으로 인한 운영 오버헤드가 크므로 Transfer Family에 비해 비효율적입니다."}}}
{"Question_Number": "Q189", "Question_Description": "한 회사에서 계약 문서를 저장해야 합니다. 계약은 5년 동안 유효하며, 이 기간 동안 문서를 절대 덮어쓰거나 삭제할 수 없어야 합니다. 또한 문서는 저장 시점에 암호화되어야 하고, 매년 암호화 키를 자동으로 교체해야 합니다. 회사는 이 모든 요구사항을 충족하면서 운영 오버헤드를 최소화하기를 원합니다. 어떤 솔루션 조합을 선택해야 합니까? (2개를 선택하십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["계약 문서", "S3 Object Lock", "compliance mode", "암호화", "매년 키 회전", "운영 오버헤드 최소화"], "Terms": ["Amazon S3", "S3 Object Lock", "governance mode", "compliance mode", "AWS Key Management Service (AWS KMS)", "SSE-S3", "SSE-KMS", "Customer Managed Keys", "Imported Keys", "WORM(Write Once Read Many)"], "Commentary": "S3 Object Lock의 compliance mode로 문서의 변경 및 삭제를 막고, AWS KMS Customer Managed Key 자동 키 회전을 통해 매년 보안 요구사항을 만족하면서 운영 부담을 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "문서를 Amazon S3에 저장하고, S3 Object Lock을 governance mode로 사용합니다.", "Commentary": "governance mode는 관리자 권한으로 잠금 설정을 해제할 수 있어 완전한 불변 보장을 제공하지 않아 요구 사항을 충족하기 어렵습니다."}, "SelectB": {"Select": "문서를 Amazon S3에 저장하고, S3 Object Lock을 compliance mode로 사용합니다.", "Commentary": "compliance mode는 관리자 권한이 있어도 삭제나 덮어쓰기가 불가능해 5년 보존을 완전히 보장합니다. 요구 사항에 부합합니다."}, "SelectC": {"Select": "Amazon S3 서버 사이드 암호화(SSE-S3)를 사용하고, 키 회전을 구성합니다.", "Commentary": "SSE-S3는 AWS가 키를 자동으로 교체하지만 정확히 매년 회전 일자를 보장하지 않아 요구 사항 충족에 불확실성이 있습니다."}, "SelectD": {"Select": "AWS KMS Customer Managed Keys를 사용한 서버 사이드 암호화(SSE-KMS)를 적용하고, 키 회전을 구성합니다.", "Commentary": "KMS Customer Managed Key에 대해 1년 주기의 자동 키 회전을 설정할 수 있어 요구 사항을 만족합니다. 운영 오버헤드도 상대적으로 적습니다."}, "SelectE": {"Select": "AWS KMS Customer Provided(Imported) Keys를 사용한 서버 사이드 암호화를 적용하고, 키 회전을 구성합니다.", "Commentary": "사용자 제공 키를 직접 관리해야 하므로 오버헤드가 증가하며, 매년 키 교체 절차를 직접 진행해야 하므로 구현이 복잡합니다."}}}
{"Question_Number": "Q190", "Question_Description": "한 회사에 Java와 PHP 기반의 웹 애플리케이션이 있습니다. 회사는 이 애플리케이션을 온프레미스 환경에서 AWS로 이전하려고 합니다. 사이트의 새로운 기능을 자주 테스트해야 하며, 고가용성을 갖추고 운영 오버헤드가 최소화된 매니지드 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["Java", "PHP", "고가용성", "매니지드 솔루션", "자주 기능 테스트", "최소 운영 오버헤드", "AWS Elastic Beanstalk", "URL swapping"], "Terms": ["Amazon S3", "Static web hosting", "AWS Lambda", "AWS Elastic Beanstalk", "URL swapping", "Amazon EC2", "Auto Scaling group", "Application Load Balancer", "AWS Load Balancer Controller"], "Commentary": "이 문제에서는 Java와 PHP 기반 웹 애플리케이션을 AWS로 이전하면서, 기능 테스트를 자주 하더라도 운영 오버헤드를 최소화하고 고가용성을 유지할 수 있는 서비스를 찾는 것이 핵심입니다. AWS Elastic Beanstalk은 관리형 서비스로 인프라 설정과 운영을 추상화해 주어 운영 오버헤드가 적고, URL swapping 기능으로 여러 환경을 손쉽게 전환하여 새로운 기능을 테스트할 수 있습니다. 다른 선택지는 관리나 설정이 더 복잡하거나, Java와 PHP 기반 웹 애플리케이션을 신속히 테스트하고 운영하기에는 적절치 않습니다.", "Selections": {"SelectA": {"Select": "Amazon S3 버킷을 생성하고 static web hosting을 활성화합니다. 정적 컨텐츠를 S3 버킷에 업로드하고, 동적 컨텐츠 처리를 위해 AWS Lambda를 사용합니다.", "Commentary": "Java와 PHP 웹 애플리케이션에 필요한 동적 처리와 유지 보수 기능을 충분히 제공하지 못합니다. 정적 웹 호스팅에 Lambda만으로 동적 로직을 구현하기에는 제약이 많습니다."}, "SelectB": {"Select": "웹 애플리케이션을 AWS Elastic Beanstalk 환경에 배포합니다. 기능 테스트를 위해 여러 Elastic Beanstalk 환경 간 URL swapping을 사용합니다.", "Commentary": "고가용성을 기본으로 제공하며 인프라 운영 부담이 작습니다. URL swapping 기능을 통해 새로운 기능 테스트를 원활히 진행할 수 있어 요구 사항을 충족합니다."}, "SelectC": {"Select": "Java와 PHP가 구성된 Amazon EC2 인스턴스에 웹 애플리케이션을 배포합니다. Auto Scaling group과 Application Load Balancer로 웹사이트 가용성을 관리합니다.", "Commentary": "직접 EC2 인스턴스를 관리해야 하므로 운영 오버헤드가 늘고, 테스트 환경 전환도 수동 설정이 필요해 요구 조건을 만족하기 어렵습니다."}, "SelectD": {"Select": "웹 애플리케이션을 컨테이너화하고 Amazon EC2 인스턴스에 배포합니다. AWS Load Balancer Controller를 사용해 새로운 기능 컨테이너로 트래픽을 동적으로 라우팅합니다.", "Commentary": "컨테이너 오케스트레이션 및 관리에 대한 추가 부담이 커집니다. 운영 오버헤드가 커져서 요구 사항인 최소화된 운영 부담에 맞지 않습니다."}}}
{"Question_Number": "Q191", "Question_Description": "한 회사가 Amazon RDS for MySQL을 사용하여 고객 정보를 저장하는 주문 애플리케이션을 운영하고 있습니다. 업무 시간 동안 직원들이 보고를 위해 일회성 쿼리를 실행하고 있는데, 이 쿼리들이 오래 걸려서 주문 처리를 진행하는 애플리케이션에서 timeout이 발생하고 있습니다. 회사는 직원들이 쿼리를 실행할 수 없게 막지 않으면서도 timeout을 제거해야 합니다. 이러한 요구사항을 충족하기 위한 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon RDS for MySQL", "주문 애플리케이션", "보고(Reporting) 쿼리", "timeout", "read replica"], "Terms": ["Amazon RDS for MySQL", "Read Replica", "Amazon DynamoDB", "On-demand Capacity"], "Commentary": "이 문제는 주문 처리 트랜잭션과 보고(Reporting)용 쿼리를 분리하여 DB 부하와 타임아웃을 해소하는 방법을 묻습니다. 일회성 분석 쿼리 때문에 본 DB에 부하가 가중되어 타임아웃이 발생하므로, 별도의 Read Replica를 사용해 읽기 쿼리를 처리하는 게 효과적입니다.", "Selections": {"SelectA": {"Select": "Read Replica를 생성하고, 보고(Reporting) 쿼리를 Read Replica로 이동합니다.", "Commentary": "글로벌하게 사용 가능한 Amazon RDS for MySQL의 Read Replica 기능을 활용해 트랜잭션과 읽기 부하를 분리함으로써 시간 초과를 방지하고 보고 쿼리도 계속 수행할 수 있습니다."}, "SelectB": {"Select": "Read Replica를 생성합니다. 주문 애플리케이션을 기본 DB 인스턴스와 Read Replica 모두에서 운영합니다.", "Commentary": "주문 애플리케이션을 Read Replica에서 운영하면 쓰기 연산에 문제가 생길 수 있고, 이는 주된 목적(트랜잭션 처리와 읽기 분리)에 적합하지 않습니다."}, "SelectC": {"Select": "주문 애플리케이션을 Amazon DynamoDB로 마이그레이션하고, On-demand Capacity 모드를 사용합니다.", "Commentary": "RDB 기반의 애플리케이션을 즉시 DynamoDB로 옮기는 것은 구조적 변경이 크며, 문제의 요구사항(쿼리 분리)과 직접적인 해결책이 아닙니다."}, "SelectD": {"Select": "보고(Reporting) 쿼리를 비사용 시간대로 예약하여 실행합니다.", "Commentary": "비사용 시간대로 보고 쿼리를 옮기면 어느 정도 효과가 있을 수 있으나, 업무 시간 동안 보고 쿼리가 필요한 경우에는 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q192", "Question_Description": "한 병원이 방대한 과거 문서 기록을 디지털 사본으로 만들고자 합니다. 매일 수백 건의 새 문서가 계속 추가될 예정이며, 병원의 데이터 팀은 스캔된 문서를 AWS Cloud에 업로드합니다. 솔루션스 아키텍트는 이 문서들을 분석하고, 의료 정보를 추출하며, 애플리케이션이 해당 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 저장해야 합니다. 솔루션은 확장성과 운영 효율성을 극대화해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조합의 단계를 수행해야 합니까? (2개를 고르세요.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["디지털 사본", "문서 분석", "의료 정보 추출", "SQL 쿼리", "확장성", "운영 효율성"], "Terms": ["Amazon EC2", "MySQL", "Amazon S3", "Amazon Athena", "Auto Scaling group", "AWS Lambda", "Amazon Rekognition", "Amazon Transcribe Medical", "Amazon Textract", "Amazon Comprehend Medical"], "Commentary": "이 문제는 의료 문서 스캔 파일에 대한 텍스트 추출과 의료 정보 파싱, 그리고 SQL 기반 조회가 가능하도록 데이터를 저장하는 확장 가능한 아키텍처를 설계하는 방법을 묻습니다. Amazon Textract와 Amazon Comprehend Medical을 사용해 문서에서 텍스트와 의료 정보를 자동 추출하고, Amazon S3 및 Amazon Athena를 통해 손쉽게 SQL 쿼리를 수행할 수 있습니다.", "Selections": {"SelectA": {"Select": "MySQL 데이터베이스가 실행 중인 Amazon EC2 인스턴스에 문서 정보를 기록합니다.", "Commentary": "EC2와 MySQL 기반 접근은 초기 규모가 커질 때 확장성 및 관리 부담이 높아지므로 비효율적입니다."}, "SelectB": {"Select": "Amazon S3 버킷에 문서 정보를 저장하고, Amazon Athena를 사용하여 해당 데이터를 쿼리합니다.", "Commentary": "S3와 Athena를 이용해 스케일이 큰 데이터도 손쉽게 수집·분석 가능한 구조를 제공하므로 적합합니다. (정답)"}, "SelectC": {"Select": "스캔 파일을 처리하고 의료 정보를 추출하는 커스텀 애플리케이션 실행을 위한 Amazon EC2 Auto Scaling group을 생성합니다.", "Commentary": "직접 애플리케이션을 개발해 EC2 규모 확장을 관리하면 운영 복잡성이 커져서 덜 효율적입니다."}, "SelectD": {"Select": "새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 만들고, Amazon Rekognition으로 문서를 텍스트로 변환 후 Amazon Transcribe Medical로 의료 정보를 추출합니다.", "Commentary": "Amazon Rekognition은 주로 이미지·영상 분석에, Transcribe Medical은 음성 인식에 특화되어 적합하지 않습니다."}, "SelectE": {"Select": "새 문서 업로드 시 실행되는 AWS Lambda 함수를 만들고, Amazon Textract로 문서를 텍스트로 변환한 뒤 Amazon Comprehend Medical을 사용해 의료 정보를 추출합니다.", "Commentary": "Textract로 텍스트를 정확히 추출하고 Comprehend Medical로 의료 정보를 파악하는 자동화된 확장형 솔루션입니다. (정답)"}}}
{"Question_Number": "Q193", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 배치 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 여러 Amazon RDS 데이터베이스로 구성된 백엔드를 포함하고 있습니다. 현재 이 애플리케이션은 데이터베이스에 매우 많은 읽기 요청을 발생시키고 있습니다. 솔루션스 아키텍트는 고가용성을 보장하면서 데이터베이스 읽기 부하를 줄여야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["배치 애플리케이션", "Amazon EC2", "Amazon RDS", "읽기 부하 감소", "고가용성"], "Terms": ["Amazon EC2", "Amazon RDS", "read replicas", "Amazon ElastiCache for Redis", "Amazon Route 53", "Amazon ElastiCache for Memcached"], "Commentary": "이 문제는 데이터베이스에 걸리는 과도한 읽기 부하를 완화하면서 고가용성을 유지해야 하는 시나리오입니다. Redis는 멀티 AZ 구성과 자동 장애 조치(automatic failover)를 제공하여, 읽기 성능 향상과 고가용성을 모두 충족시킬 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon RDS read replicas를 추가합니다.", "Commentary": "읽기 전용 복제본이 읽기 부담을 낮출 수 있지만, 자체 캐싱 솔루션만큼 효율적이거나 간단하지 않으며, 고가용성 측면에서도 Redis의 자동 장애 조치 대비 제한적입니다."}, "SelectB": {"Select": "Amazon ElastiCache for Redis를 사용합니다.", "Commentary": "Redis는 멀티 AZ를 지원하고, 빈번한 읽기를 캐싱해 RDS 부하를 크게 줄이면서 복제 및 장애 조치를 통해 고가용성을 달성할 수 있어 최적의 선택입니다."}, "SelectC": {"Select": "Amazon Route 53 DNS 캐싱을 사용합니다.", "Commentary": "DNS 캐싱은 데이터베이스 읽기 부하를 줄이는 직접적인 방법이 아니므로, 문제 해결에 적합하지 않습니다."}, "SelectD": {"Select": "Amazon ElastiCache for Memcached를 사용합니다.", "Commentary": "Memcached는 고성능 캐싱을 제공하지만 멀티 AZ 지원과 자동 장애 조치 기능면에서 Redis만큼 고가용성을 보장하지 못합니다."}}}
{"Question_Number": "Q194", "Question_Description": "한 회사가 중요한 애플리케이션을 AWS에서 운영해야 합니다. 회사는 애플리케이션의 데이터베이스용으로 Amazon EC2를 사용해야 합니다. 데이터베이스는 고가용성을 갖춰야 하며, 장애가 발생할 경우 자동으로 장애 조치가 이루어져야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["데이터베이스 고가용성", "자동 장애조치", "EC2 인스턴스 클러스터링", "Availability Zone", "Amazon EC2"], "Terms": ["Amazon EC2", "Availability Zone", "Amazon Machine Image (AMI)", "AWS CloudFormation", "EC2 automatic recovery", "database replication"], "Commentary": "이 문제는 Amazon EC2로 구축한 데이터베이스에 대해 고가용성과 자동 장애조치 기능을 요구하고 있습니다. 단일 AZ나 Region 간 복제만으로는 신속한 자동 장애조치를 모두 충족하기 어렵습니다. 동일 Region 내 서로 다른 Availability Zone에 여러 인스턴스를 클러스터로 구성하고 데이터베이스를 복제하는 방식이 보다 안정적입니다. 이에 따라 서로 다른 AZ에서 장애가 발생해도 자동으로 다른 인스턴스가 즉시 역할을 넘겨받아 서비스 중단을 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "두 개의 EC2 인스턴스를 동일 AWS Region 내 서로 다른 Availability Zone에 각각 실행합니다. 각 EC2 인스턴스에 데이터베이스를 설치하고 클러스터 구성 및 데이터베이스 복제를 설정합니다.", "Commentary": "고가용성을 위해 서로 다른 AZ에서 인스턴스를 클러스터로 구성해 자동 장애조치를 가능케 하며 요구 사항을 충족하는 최적의 방법입니다."}, "SelectB": {"Select": "한 Availability Zone에 EC2 인스턴스를 실행하고 데이터베이스를 설치합니다. Amazon Machine Image(AMI)를 사용하여 데이터를 백업하고, AWS CloudFormation으로 장애 발생 시 인스턴스를 자동 프로비저닝합니다.", "Commentary": "자동 프로비저닝은 가능하지만 다른 AZ에 즉시 대기 중인 인스턴스가 없어 자동 장애조치 요구사항이 완벽히 충족되지 않습니다."}, "SelectC": {"Select": "서로 다른 AWS Region에 두 개의 EC2 인스턴스를 각각 실행하고, 데이터베이스를 설치한 뒤 복제를 설정합니다. 두 번째 Region으로 데이터베이스를 장애조치합니다.", "Commentary": "Region 간 장애조치는 가능하지만 대기 시간이 길 수 있고, 단순 멀티-AZ 구성보다 운영 복잡도가 높아 즉시 자동 장애조치 측면에서 비효율적입니다."}, "SelectD": {"Select": "한 Availability Zone에 EC2 인스턴스를 실행하고 데이터베이스를 설치합니다. Amazon Machine Image(AMI)로 데이터를 백업합니다. EC2 automatic recovery를 사용하여 장애가 발생하면 인스턴스를 복구합니다.", "Commentary": "automatic recovery는 동일 AZ 내에서 하드웨어 이슈와 같은 문제를 복구할 수 있으나, AZ 자체 장애 시 자동 장애조치가 보장되지 않아 고가용성을 만족하기 어렵습니다."}}}
{"Question_Number": "Q195", "Question_Description": "한 회사의 주문 시스템은 고객으로부터 Amazon EC2 인스턴스로 요청을 전송합니다. EC2 인스턴스는 주문을 처리한 후 Amazon RDS 데이터베이스에 저장합니다. 사용자는 시스템 장애가 발생할 때마다 주문을 다시 처리해야 한다고 보고했습니다. 회사는 시스템 장애가 발생해도 주문을 자동으로 처리할 수 있는 복원력 있는 솔루션을 원합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["Auto Scaling group", "Amazon SQS", "주문 처리", "복원력", "내결함성"], "Terms": ["Amazon EC2", "Amazon RDS", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon Elastic Container Service (Amazon ECS)", "Auto Scaling group", "Application Load Balancer (ALB)", "Amazon Simple Queue Service (Amazon SQS)", "Amazon Simple Notification Service (Amazon SNS)", "AWS Lambda", "AWS Systems Manager Run Command"], "Commentary": "이 문제는 주문 처리를 EC2 인스턴스만으로 담당할 때 장애가 발생하면 주문이 유실되어 재처리가 필요한 상황을 해결하려는 것입니다. Amazon SQS를 통해 주문을 비동기적으로 관리하면, 인스턴스가 장애가 나도 메시지는 큐에 남아 복구 후 자동으로 처리될 수 있어 복원력과 내결함성을 갖추게 됩니다. Auto Scaling group으로 EC2 인스턴스를 운영하면 장애나 트래픽 급증에도 자동으로 대체 인스턴스를 확보하고, 큐에 남은 주문들을 차례로 처리할 수 있어 안정적인 서비스가 가능합니다.", "Selections": {"SelectA": {"Select": "EC2 인스턴스를 Auto Scaling group으로 이동하고, Amazon EventBridge (Amazon CloudWatch Events) 규칙을 생성하여 Amazon ECS 태스크를 대상으로 설정합니다.", "Commentary": "EventBridge + ECS 태스크만으로는 주문을 안전하게 큐잉해두는 메커니즘이 없어, 장애 발생 시 주문을 재처리해야 하는 문제가 여전히 남습니다."}, "SelectB": {"Select": "EC2 인스턴스를 Auto Scaling group 뒤의 Application Load Balancer(ALB)에 배치하고, 주문 시스템이 ALB 엔드포인트로 메시지를 전송하도록 업데이트합니다.", "Commentary": "ALB로 트래픽을 분산할 순 있지만 메시지가 큐에 저장되지 않아, 인스턴스 장애 시 주문이 유실될 수 있습니다."}, "SelectC": {"Select": "EC2 인스턴스를 Auto Scaling group으로 이동합니다. 주문 시스템이 Amazon Simple Queue Service(Amazon SQS) 큐로 메시지를 보내도록 구성하고, EC2 인스턴스가 큐에서 메시지를 소비하도록 설정합니다.", "Commentary": "Amazon SQS를 활용해 주문을 비동기 처리하면 인스턴스 장애 시에도 큐에 메시지가 남아 자동 재처리가 가능해 복원력이 뛰어난 아키텍처를 구현할 수 있습니다."}, "SelectD": {"Select": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하고, AWS Lambda 함수를 만들어 SNS 토픽에 구독시킵니다. 주문 시스템이 SNS 토픽으로 메시지를 전송하도록 구성한 후, AWS Systems Manager Run Command를 사용해 EC2 인스턴스가 메시지를 처리하도록 지시합니다.", "Commentary": "SNS를 사용하면 메시지 전달은 가능하지만 메시지 자동 재처리가 어렵고, EC2 인스턴스로의 처리 연결도 복잡해 장애 대비가 충분치 않습니다."}}}
{"Question_Number": "Q196", "Question_Description": "한 회사가 대규모 Amazon EC2 인스턴스 군에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon DynamoDB 테이블에 데이터를 읽고 쓰며, DynamoDB 테이블의 크기는 지속적으로 커지고 있습니다. 그러나 애플리케이션은 최근 30일의 데이터만 필요합니다. 회사는 비용과 개발 노력을 최소화하는 솔루션이 필요합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["DynamoDB", "30일 데이터 유지", "비용 최소화", "개발 노력 최소화", "TTL"], "Terms": ["Amazon EC2", "Amazon DynamoDB", "AWS CloudFormation", "DynamoDB Streams", "AWS Lambda", "Time to Live (TTL)", "AWS Marketplace"], "Commentary": "이 문제는 DynamoDB 테이블에서 최근 30일 데이터만 유지해야 할 때, 운영 효율성과 비용 측면에서 가장 적절한 방법을 찾는 것입니다. DynamoDB TTL 기능은 지정한 만료 시간이 지나면 항목을 자동으로 삭제해 추가 개발이나 운영 인프라를 거의 요구하지 않아 비용과 노력을 모두 절감할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS CloudFormation 템플릿을 사용해 전체 솔루션을 배포하고, 30일마다 CloudFormation 스택을 재배포 후 원본 스택을 삭제합니다.", "Commentary": "주기적으로 스택을 재배포하는 것은 관리가 복잡하고 비용이나 개발 노력이 더 들기 때문에 비효율적입니다."}, "SelectB": {"Select": "AWS Marketplace에서 제공되는 모니터링 애플리케이션이 설치된 EC2 인스턴스를 사용합니다. 이 모니터링 애플리케이션으로 DynamoDB Streams를 통해 항목 생성 시점을 기록하고, 30일 이상 지난 항목을 삭제하는 스크립트를 실행합니다.", "Commentary": "EC2 인스턴스 유지와 자체 스크립트 실행이 필요해 운영과 관리가 복잡해지고 비용도 추가됩니다."}, "SelectC": {"Select": "DynamoDB Streams를 구성하여 테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출합니다. Lambda 함수를 통해 30일 이상 된 항목을 삭제하도록 설정합니다.", "Commentary": "Lambda 함수 구성으로 어느 정도 자동화할 수 있지만, 불필요한 호출과 로직 작성이 필요해 관리 부담이 남아 있습니다."}, "SelectD": {"Select": "새로운 항목이 생성될 때 현재 시각에 30일을 더한 타임스탬프를 속성으로 추가합니다. DynamoDB에서 이 속성을 TTL로 사용하도록 구성합니다.", "Commentary": "TTL 기능을 활용하면 30일이 지난 항목을 DynamoDB가 자동으로 삭제해, 비용과 운영 노력이 가장 적으며 요구사항을 충족하는 최적의 솔루션입니다."}}}
{"Question_Number": "Q197", "Question_Description": "한 회사는 온프레미스 Windows Server에서 실행되는 Microsoft .NET 애플리케이션을 보유하고 있으며, 이 애플리케이션은 Oracle Database Standard Edition 서버를 사용하여 데이터를 저장하고 있습니다. 회사는 AWS로 마이그레이션을 계획하고 있으며, 애플리케이션 이전 시 개발 변경을 최소화하고자 합니다. 또한 AWS 애플리케이션 환경은 고가용성을 유지해야 합니다. 이러한 요구사항을 충족하기 위해 취해야 할 조치를 두 가지 고르시오.", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["개발 변경 최소화", "고가용성", "AWS Elastic Beanstalk", "Oracle on Amazon RDS", "AWS Database Migration Service", "멀티 AZ"], "Terms": ["AWS Elastic Beanstalk", ".NET", "Windows Server", "AWS Lambda", "Amazon EC2", "Amazon Linux AMI", "AWS Database Migration Service (AWS DMS)", "Oracle Database Standard Edition", "Amazon DynamoDB", "Oracle on Amazon RDS", "Multi-AZ 배포"], "Commentary": "이 문제는 .NET 애플리케이션과 Oracle Database Standard Edition을 AWS로 마이그레이션할 때, 최소한의 개발 변경과 고가용성을 어떻게 달성할지를 묻습니다. AWS Elastic Beanstalk에 .NET 플랫폼으로 리호스팅하면 애플리케이션 코드를 거의 수정하지 않고도 고가용성 환경(Multi-AZ)을 쉽게 구성할 수 있습니다. 데이터베이스의 경우, Oracle에서 Oracle on Amazon RDS로 마이그레이션하면 기존 Oracle 기술을 유지하면서 AWS에서 제공하는 Multi-AZ 배포를 통해 높은 가용성을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Lambda에서 .NET Core로 서버리스 방식으로 애플리케이션을 리팩터링합니다.", "Commentary": "서버리스로 리팩터링하는 것은 코드 변경이 많아지고 구성도 복잡해져, ‘개발 변경 최소화’ 요구사항에 적합하지 않습니다."}, "SelectB": {"Select": "AWS Elastic Beanstalk의 .NET 플랫폼으로 애플리케이션을 리호스트하고 멀티 AZ로 배포합니다.", "Commentary": "애플리케이션 코드 변경을 최소화하면서 고가용성 환경을 쉽게 구성할 수 있어 요구사항을 충족합니다."}, "SelectC": {"Select": "Amazon Linux AMI를 사용하는 Amazon EC2에서 애플리케이션을 리플랫폼합니다.", "Commentary": "Windows 기반 .NET 애플리케이션을 Linux 환경으로 이전하면 코드 변경이 많을 수 있어, 요구사항에 적합하지 않습니다."}, "SelectD": {"Select": "AWS DMS를 사용하여 Oracle DB를 Amazon DynamoDB로 멀티 AZ로 마이그레이션합니다.", "Commentary": "Oracle에서 DynamoDB로의 마이그레이션은 스키마 및 코드 변경이 많아져, ‘개발 변경 최소화’ 요구사항에 부합하지 않습니다."}, "SelectE": {"Select": "AWS DMS를 사용하여 Oracle DB를 멀티 AZ로 구성된 Amazon RDS의 Oracle로 마이그레이션합니다.", "Commentary": "Oracle 기술을 그대로 유지하면서 AWS RDS의 멀티 AZ 기능으로 고가용성을 확보할 수 있어, 요구사항을 충족합니다."}}}
{"Question_Number": "Q198", "Question_Description": "한 회사는 온프레미스 데이터 센터의 Kubernetes 클러스터에서 컨테이너형 애플리케이션을 운영하고 있으며, MongoDB 데이터베이스를 사용하고 있습니다. 현재 코드 수정이나 배포 방법 변경 없이 AWS로 일부 환경을 마이그레이션하려고 합니다. 이 때 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["Kubernetes 기반 컨테이너 마이그레이션", "MongoDB", "운영 오버헤드 최소화", "AWS Fargate", "Amazon EKS", "Amazon DocumentDB"], "Terms": ["Amazon Elastic Container Service (Amazon ECS)", "Amazon EC2", "AWS Fargate", "Amazon DynamoDB", "Amazon Elastic Kubernetes Service (Amazon EKS)", "Amazon DocumentDB (with MongoDB compatibility)", "Kubernetes", "MongoDB"], "Commentary": "이 문제는 온프레미스 Kubernetes 환경에서 MongoDB를 사용하는 애플리케이션을 AWS로 이전하되, 코드나 배포 방식을 바꾸지 않고 운영 오버헤드를 최소화해야 하는 시나리오입니다. MongoDB 호환성을 유지하려면 Amazon DocumentDB를 사용하는 것이 적절하며, Kubernetes 오케스트레이션을 그대로 활용하기 위해 Amazon EKS를 사용하는 것이 가장 간편합니다. 또한, AWS Fargate를 사용하면 워커 노드를 직접 관리할 필요가 없어 운영 부담이 줄어듭니다.", "Selections": {"SelectA": {"Select": "Amazon ECS를 Amazon EC2 워커 노드와 함께 사용하고, MongoDB를 EC2에 직접 설치하여 운영합니다.", "Commentary": "EC2에서 MongoDB를 직접 구성해야 하므로 서버와 DB 모두를 관리해야 합니다. 운영 오버헤드가 커지며, Kubernetes 환경을 그대로 활용하지 못합니다."}, "SelectB": {"Select": "Amazon ECS를 AWS Fargate로 사용하고, 데이터 스토리지로 Amazon DynamoDB를 사용합니다.", "Commentary": "MongoDB 코드 기반을 DynamoDB로 바꾸어야 하므로 코드 변경이 필요합니다. 또한 Kubernetes 사용 방식과도 달라 운영 방식을 크게 변경해야 합니다."}, "SelectC": {"Select": "Amazon EKS를 Amazon EC2 워커 노드로 사용하고, 데이터 스토리지로 Amazon DynamoDB를 사용합니다.", "Commentary": "Kubernetes 사용은 그대로 가능하지만, MongoDB 코드 기반을 DynamoDB로 전환해야 하므로 코드 변경이 요구되며, EC2 노드 관리도 필요해 운영 부담이 큽니다."}, "SelectD": {"Select": "Amazon EKS를 AWS Fargate로 사용하고, 데이터 스토리지로 Amazon DocumentDB(MongoDB 호환)를 사용합니다.", "Commentary": "Kubernetes 배포 방식을 유지하면서 MongoDB 호환성을 제공하는 DocumentDB를 사용해 코드 변경이 불필요합니다. Fargate로 노드 관리 부담이 사라져 운영 오버헤드를 최소화할 수 있어 정답입니다."}}}
{"Question_Number": "Q199", "Question_Description": "한 텔레마케팅 회사가 AWS 상에서 고객 콜 센터 기능을 설계하고 있습니다. 회사는 다중 화자 인식을 제공하고, 대화 녹취록(transcript) 파일을 생성할 수 있는 솔루션이 필요합니다. 회사는 녹취록 파일을 쿼리하여 비즈니스 패턴을 분석하고자 합니다. 또한 이 녹취록 파일들은 감사(auditing) 목적으로 7년 동안 보관되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["콜 센터", "다중 화자 인식", "녹취록 파일", "Amazon Transcribe", "Amazon Athena", "장기간 보관", "비즈니스 패턴 분석"], "Terms": ["Amazon Rekognition", "Amazon S3", "Amazon Transcribe", "Amazon Athena", "Amazon Translate", "Amazon Redshift", "Amazon Textract", "SQL"], "Commentary": "이 문제는 음성을 자동으로 텍스트로 변환하고(Transcribe), 다중 화자를 구분하여 녹취록을 생성해야 합니다. 생성된 녹취록은 7년 동안 Amazon S3에 저장하며, Amazon Athena로 손쉽게 분석할 수 있습니다. Rekognition, Translate, Textract 등은 음성 인식 대신 시각 자료 분석 혹은 텍스트 번역/추출을 처리하므로 요구 사항에 부합하지 않습니다.", "Selections": {"SelectA": {"Select": "Amazon Rekognition을 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon S3에 저장합니다. 녹취록 파일 분석에는 machine learning models를 사용합니다.", "Commentary": "Amazon Rekognition은 이미지·영상 분석 서비스로 음성 녹취 생성 기능이 없어 요구 사항을 만족시키지 못합니다."}, "SelectB": {"Select": "Amazon Transcribe를 사용하여 다중 화자 인식을 수행합니다. Amazon Athena를 사용하여 녹취록 파일을 분석합니다.", "Commentary": "음성 인식 및 다중 화자 구분은 Transcribe가 제공하며, S3에 저장된 데이터는 Athena로 SQL 쿼리 분석이 가능해 요구 사항에 완벽히 부합합니다."}, "SelectC": {"Select": "Amazon Translate를 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon Redshift에 저장합니다. SQL 쿼리를 통해 녹취록 파일을 분석합니다.", "Commentary": "Amazon Translate는 텍스트 번역 서비스여서 음성 인식에 적합하지 않고, Redshift까지 사용할 필요도 없어 비효율적입니다."}, "SelectD": {"Select": "Amazon Rekognition을 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon S3에 저장합니다. Amazon Textract를 사용하여 녹취록 파일을 분석합니다.", "Commentary": "Rekognition과 Textract는 시각 자료 분석용 서비스로, 음성 녹취 생성 및 분석 요구 사항에 부합하지 않습니다."}}}
{"Question_Number": "Q200", "Question_Description": "한 회사가 AWS 환경에서 애플리케이션을 호스팅하고 있습니다. 사용자는 Amazon Cognito를 통해 관리되며, 로그인을 하면 Amazon API Gateway에 호스팅된 REST API를 호출하여 Amazon DynamoDB에서 필요한 데이터를 가져옵니다. 이 때, 개발 노력을 줄이기 위해 AWS에서 제공하는 관리형 솔루션을 활용하여 REST API 접근 제어를 구현하고자 합니다. 가장 낮은 운영 오버헤드를 가지는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon Cognito", "사용자 인증", "REST API 접근 제어", "Amazon API Gateway", "Least operational overhead"], "Terms": ["Amazon Cognito", "User Pool Authorizer", "Amazon DynamoDB", "AWS Lambda Authorizer", "Amazon API Gateway", "API Key", "REST API"], "Commentary": "이 문제는 인증 절차를 간소화하면서 REST API에 대한 접근을 안전하게 제어하려는 시나리오입니다. 가장 관리가 용이한 방식은 Amazon Cognito User Pool Authorizer를 API Gateway와 직접 연동하는 것으로, 별도의 인증 로직이나 추가 인프라가 필요하지 않아 운영 오버헤드를 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "API Gateway에서 AWS Lambda 함수를 Authorizer로 설정하여 요청을 보낸 사용자를 검증합니다.", "Commentary": "Lambda Authorizer를 직접 구현하면 검증 로직과 함수를 별도로 관리해야 하므로 운영 및 개발 오버헤드가 증가합니다."}, "SelectB": {"Select": "각 사용자에게 API Key를 발급하여 매 요청 시 전달하도록 하고, AWS Lambda 함수를 통해 키를 검증합니다.", "Commentary": "API Key를 사용자별로 관리하고 검증 로직도 구현해야 하므로 오버헤드와 복잡성이 높아집니다."}, "SelectC": {"Select": "매 요청 시 사용자의 이메일 주소를 헤더에 담아 전송하고, 이 이메일 계정이 올바른지 AWS Lambda 함수로 검증합니다.", "Commentary": "이메일 정보를 헤더로 직접 전달하는 것은 보안 측면에서 취약할 수 있으며, Lambda 함수로 검증 로직을 계속 관리해야 하므로 비효율적입니다."}, "SelectD": {"Select": "API Gateway에서 Amazon Cognito User Pool Authorizer를 설정하여 Amazon Cognito가 각 요청을 검증하도록 구성합니다.", "Commentary": "Cognito User Pool Authorizer를 사용하면 추가적인 인증 로직이나 인프라가 필요 없고, AWS가 인증 과정을 관리하므로 운영 오버헤드를 크게 줄일 수 있습니다."}}}
{"Question_Number": "Q201", "Question_Description": "회사는 모바일 앱 사용자를 대상으로 하는 마케팅 커뮤니케이션 서비스를 개발 중입니다. 이 회사는 사용자들에게 SMS(Short Message Service)로 확인 메시지를 보낼 필요가 있습니다. 또한 사용자가 이 SMS 메시지에 회신할 수 있어야 하며, 회신된 메시지를 1년간 저장하여 분석해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["SMS", "Amazon Pinpoint", "Kinesis Data Stream", "마케팅 커뮤니케이션", "분석 및 보관"], "Terms": ["Amazon Connect", "AWS Lambda", "Amazon Pinpoint", "Amazon Kinesis data stream", "Amazon SQS", "Amazon SNS FIFO"], "Commentary": "SMS 발송과 회신 저장 및 분석의 요구사항을 동시에 충족하려면 Amazon Pinpoint로 캠페인을 구성하고, Kinesis로 이벤트를 전달하여 1년간 데이터 보관 및 분석을 수행할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Connect를 사용해 컨택트 플로우를 만들고 SMS를 전송합니다. 그리고 AWS Lambda를 이용해 회신을 처리합니다.", "Commentary": "Amazon Connect는 주로 콜센터 시나리오에 최적화되어 있으며, 대량 마케팅 메시지와 장기 분석 목적에는 적합하지 않습니다."}, "SelectB": {"Select": "Amazon Pinpoint Journey를 구축합니다. Amazon Pinpoint가 이벤트를 Amazon Kinesis data stream으로 전송하도록 구성하여 분석 및 보관합니다.", "Commentary": "마케팅 메시지 전송과 회신 분석에 특화된 Amazon Pinpoint를 활용하며, Kinesis를 통해 데이터를 실시간으로 전송해 장기간 보관 및 분석이 가능합니다."}, "SelectC": {"Select": "Amazon Simple Queue Service(Amazon SQS)를 사용해 SMS를 분산하고, AWS Lambda를 이용해 회신을 처리합니다.", "Commentary": "SQS는 메시지 대기열 서비스로 회신 관리에 적합하지 않으며, 마케팅 메시지 설정 및 장기 저장 기능이 부족합니다."}, "SelectD": {"Select": "Amazon Simple Notification Service(Amazon SNS) FIFO 토픽을 생성합니다. Amazon Kinesis data stream을 SNS 토픽에 구독시켜 분석 및 보관합니다.", "Commentary": "SNS를 이용하면 일대다 메시지 전달은 가능하지만, 회신 기능과 마케팅 흐름 관리가 제한적입니다."}}}
{"Question_Number": "Q202", "Question_Description": "한 회사가 데이터를 Amazon S3 버킷으로 이전하려고 합니다. 이 데이터는 S3 버킷에 저장될 때 암호화되어야 하며, 암호화 키는 매년 자동으로 교체되어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["데이터 암호화", "자동 키 교체", "운영 오버헤드 최소화", "서버 사이드 암호화", "SSE-S3"], "Terms": ["Amazon S3", "SSE-S3", "AWS Key Management Service (AWS KMS)", "Customer managed key", "S3 bucket’s default encryption", "Customer key material", "Server-side encryption", "Key rotation"], "Commentary": "이 문제는 Amazon S3에 데이터를 저장할 때 자동으로 키를 교체하며, 운영 오버헤드를 최소화하는 암호화 방법을 고르는 문제입니다. SSE-S3는 AWS가 제공하는 S3 관리형 키를 사용하므로 사용자가 키를 직접 관리하거나 교체할 필요가 없고, 매년 자동으로 키를 교체해 운영 부담을 크게 줄여줍니다.", "Selections": {"SelectA": {"Select": "데이터를 S3 버킷으로 옮기고, 서버 사이드 암호화(Amazon S3 managed encryption keys: SSE-S3)를 사용합니다. SSE-S3의 자동 키 교체 기능을 이용합니다.", "Commentary": "정답입니다. SSE-S3는 아무런 추가 설정 없이도 키를 자동 관리 및 교체하므로 운영 오버헤드가 가장 낮습니다."}, "SelectB": {"Select": "AWS KMS customer managed key를 생성하고 자동 키 교체를 활성화합니다. 해당 KMS 키를 S3 버킷의 기본 암호화 키로 설정한 뒤 데이터를 이동합니다.", "Commentary": "키 관리는 자동 키 교체를 제공하지만, KMS 정책 설정 등 추가 관리가 필요해 상대적으로 운영이 복잡해질 수 있습니다."}, "SelectC": {"Select": "AWS KMS customer managed key를 생성하고 S3 버킷의 기본 암호화 키로 설정합니다. 그 후 데이터를 옮긴 뒤 매년 수동으로 KMS 키를 교체합니다.", "Commentary": "키를 매년 직접 교체해야 하므로 운영 비용이 증가하고 자동화 수준이 낮습니다."}, "SelectD": {"Select": "버킷에 옮기기 전 데이터를 고객 키 소재로 암호화합니다. 그 후 키 소재가 없는 KMS 키를 생성하고, 고객 키 소재를 가져와 자동 키 교체를 활성화합니다.", "Commentary": "고객 키 소재를 자체적으로 준비·관리해야 하므로 운영 절차가 복잡해지고, 요구 사항 대비 오버헤드가 큽니다."}}}
{"Question_Number": "Q203", "Question_Description": "한 금융 회사의 고객들은 재정 상담사와의 약속을 잡기 위해 문자 메시지를 보냅니다. Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션이 약속 요청을 받아들입니다. 문자 메시지는 웹 애플리케이션을 통해 Amazon Simple Queue Service(Amazon SQS) 큐에 게시됩니다. 그런 다음 Amazon EC2 인스턴스에서 실행되는 또 다른 애플리케이션이 고객에게 회의 초대 및 확인 이메일을 발송합니다. 일정이 성공적으로 잡히면 이 애플리케이션은 회의 정보를 Amazon DynamoDB 데이터베이스에 저장합니다. 회사가 확장됨에 따라 고객들은 회의 초대장이 도착하기까지 시간이 오래 걸린다고 보고했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["고객 약속 요청", "Amazon SQS 큐", "회의 초대 지연", "Auto Scaling", "큐 깊이에 따른 확장"], "Terms": ["Amazon EC2", "Amazon SQS", "Amazon DynamoDB", "DynamoDB Accelerator (DAX)", "Amazon API Gateway", "Amazon CloudFront", "Auto Scaling group"], "Commentary": "이 문제는 메시지가 증가하면서 초대장을 전달하는 애플리케이션 리소스가 부족해 지연이 발생하는 상황입니다. 수요에 따라 애플리케이션을 자동으로 확장해 처리 성능을 높이는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "DynamoDB 데이터베이스 앞에 DynamoDB Accelerator(DAX) 클러스터를 추가합니다.", "Commentary": "데이터베이스 조회 성능 향상에 초점을 맞춘 해결책이므로, 초대장 전송 처리 지연 문제 해결에는 직접적인 도움이 되지 않습니다."}, "SelectB": {"Select": "약속 요청을 받는 웹 애플리케이션 앞에 Amazon API Gateway API를 추가합니다.", "Commentary": "API Gateway는 요청 처리를 표준화하고 보안을 강화하지만, 초대장 전송 애플리케이션 자체의 처리 속도 문제를 해결하지 못합니다."}, "SelectC": {"Select": "Amazon CloudFront 배포를 추가하고, 약속 요청을 받는 웹 애플리케이션을 오리진으로 설정합니다.", "Commentary": "CloudFront는 콘텐츠 캐싱을 제공하나, 데이터 처리를 가속하는 데 직접 관여하지 않아 초대장 지연 문제를 해결하기 어렵습니다."}, "SelectD": {"Select": "회의 초대를 전송하는 애플리케이션에 대한 Auto Scaling group을 추가하고, SQS 큐 깊이에 따라 확장되도록 구성합니다.", "Commentary": "큐에 메시지가 많아질 때 자동으로 인스턴스 수를 늘려 처리 능력을 높이므로, 초대장 지연 문제를 가장 효과적으로 해결합니다."}}}
{"Question_Number": "Q204", "Question_Description": "한 온라인 소매 회사에는 5천만 명 이상의 활성 고객이 있으며, 매일 25,000건 이상의 주문이 접수됩니다. 회사는 고객의 구매 데이터를 Amazon S3에 저장하고, 추가 고객 정보는 Amazon RDS에 저장하고 있습니다. 회사는 이 모든 데이터를 다양한 팀에서 분석할 수 있도록 제공하려고 합니다. 이때 데이터에 대한 세분화된 권한 관리를 구현해야 하며, 운영 오버헤드를 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["5천만 명의 활성 고객", "25,000건 주문", "Amazon S3", "Amazon RDS", "데이터 분석", "세분화된 접근 권한", "운영 오버헤드 최소화"], "Terms": ["Amazon S3", "Amazon RDS", "AWS Lake Formation", "AWS Glue", "Amazon Athena", "Amazon Redshift", "AWS Lambda", "Data Lake"], "Commentary": "이 문제는 대규모 고객 데이터(구매 정보와 추가 정보)를 여러 팀이 분석할 수 있도록 제공하면서 데이터에 대한 정교한 권한 제어를 구현하는 방법을 묻습니다. 정답인 AWS Lake Formation은 S3 기반 데이터 레이크를 손쉽게 구축하고, Lake Formation Access Control을 통해 각 팀별로 세분화된 권한 관리를 수행할 수 있습니다. 또한, Glue를 통한 카탈로그 관리와 JDBC 연결로 RDS 데이터까지 통합하여 운영 오버헤드를 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "구매 데이터를 Amazon RDS에 직접 쓰도록 마이그레이션하고, RDS 접근 제어를 사용하여 액세스를 제한합니다.", "Commentary": "모든 데이터를 RDS로 옮기는 것은 비효율적이고 RDS 스케일 부담이 큽니다. 또한 객체 스토리지에서의 세분화된 권한 관리를 구현하기 어렵습니다."}, "SelectB": {"Select": "AWS Lambda 함수를 주기적으로 실행하여 Amazon RDS 데이터를 Amazon S3로 복사합니다. AWS Glue 크롤러를 생성하고, Amazon Athena로 데이터를 쿼리합니다. S3 정책으로 접근을 제한합니다.", "Commentary": "Lambda와 Athena, S3 정책만으로 세분화된 권한 제어가 가능하긴 하지만, Lake Formation의 통합적 정책 관리 기능만큼 편의성과 세분화 수준이 높지 않습니다."}, "SelectC": {"Select": "AWS Lake Formation을 사용하여 Data Lake를 생성합니다. Amazon RDS로의 AWS Glue JDBC 연결을 설정하고, S3 버킷을 Lake Formation에 등록합니다. Lake Formation의 접근 제어를 사용하여 권한을 제한합니다.", "Commentary": "Lake Formation이 세분화된 접근 권한을 쉽게 관리하고, S3와 RDS 데이터를 통합 분석할 수 있어 운영 오버헤드를 줄이면서 요구사항을 충족하는 최적 솔루션입니다."}, "SelectD": {"Select": "Amazon Redshift 클러스터를 생성합니다. AWS Lambda 함수를 주기적으로 실행하여 Amazon S3 및 Amazon RDS 데이터를 Amazon Redshift로 복사합니다. Amazon Redshift 접근 제어를 사용하여 액세스를 제한합니다.", "Commentary": "Redshift로 모두 통합하면 대량의 임포트 작업과 관리 오버헤드가 증가합니다. 또한 세분화된 권한 요구사항을 만족하기 위해서는 추가 설정이 복잡해집니다."}}}
{"Question_Number": "Q205", "Question_Description": "한 회사가 온프레미스 데이터 센터에서 마케팅 웹사이트를 호스팅하고 있습니다. 이 웹사이트는 정적 문서로 구성되며 단일 서버에서 동작합니다. 관리자는 웹사이트 콘텐츠를 자주 업데이트하지 않고, 새로운 문서를 업로드할 때는 SFTP 클라이언트를 사용합니다. 회사는 이 웹사이트를 AWS로 이전하고 Amazon CloudFront를 사용하기로 결정했습니다. 솔루션스 아키텍트는 CloudFront의 오리진으로 사용할 웹사이트 호스팅에 대해 가장 비용 효율적이고 복원력 있는 아키텍처를 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["온프레미스 데이터 센터", "마케팅 웹사이트", "정적 문서", "SFTP 클라이언트", "Amazon CloudFront", "비용 효율성", "복원력 있는 아키텍처", "오리진"], "Terms": ["SFTP", "Amazon CloudFront", "Amazon S3", "Origin Access Identity (OAI)", "AWS CLI", "Amazon EC2", "AWS Auto Scaling", "Application Load Balancer", "Amazon Lightsail", "AWS Transfer for SFTP", "Website Hosting"], "Commentary": "이 문제는 정적 웹사이트의 오리진을 CloudFront로 구성하면서 비용 최적화와 복원성을 모두 달성해야 하는 시나리오입니다. 전통적인 서버 기반 솔루션보다 Amazon S3와 Origin Access Identity(OAI)를 사용하는 방식이 가장 저렴하고 안정성이 높습니다. 특히 사이트 콘텐츠가 자주 변경되지 않는 정적 파일이므로 서버를 직접 운영하지 않아도 되고, S3의 내구성과 가용성을 활용하여 아키텍처를 단순화하면서 비용을 절감할 수 있습니다. 또한 CloudFront를 통해 전 세계 엣지 로케이션에서 빠른 콘텐츠 전송이 가능합니다. SFTP 사용 요구사항을 완전히 유지해야 한다면 AWS Transfer for SFTP를 고려할 수 있으나, 보안성과 관리 측면에서는 S3와 OAI 구성에 CLI 업로드 방식을 사용하는 것이 일반적인 권장사항입니다.", "Selections": {"SelectA": {"Select": "Amazon Lightsail 인스턴스를 생성하고 웹 서버를 구성합니다. SFTP 클라이언트를 사용하여 웹사이트 콘텐츠를 업로드합니다.", "Commentary": "Lightsail은 서버 운영 및 관리가 필요한 방식으로, 정적 컨텐츠를 호스팅하기에는 과도한 비용과 유지보수 부담이 생길 수 있습니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스용 AWS Auto Scaling 그룹을 생성하고, Application Load Balancer를 사용합니다. SFTP 클라이언트를 이용해 웹사이트 콘텐츠를 업로드합니다.", "Commentary": "EC2 Auto Scaling과 Load Balancer 구성은 가용성과 확장성은 제공하지만, 정적 파일 호스팅에는 불필요하게 복잡하고 비용이 높아집니다."}, "SelectC": {"Select": "비공개 Amazon S3 버킷을 생성하고, CloudFront Origin Access Identity(OAI)를 사용하도록 버킷 정책을 구성합니다. AWS CLI를 통해 웹사이트 콘텐츠를 업로드합니다.", "Commentary": "비용을 최소화하고 높은 내구성을 제공하며, 서버 없이 정적 웹사이트를 호스팅하기에 가장 적합한 솔루션입니다. OAI를 통해 S3 버킷을 안전하게 보호하면서 CloudFront가 콘텐츠를 제공하도록 할 수 있습니다."}, "SelectD": {"Select": "공개 Amazon S3 버킷을 생성하고 AWS Transfer for SFTP를 구성합니다. S3 버킷을 웹사이트 호스팅으로 설정하고, SFTP 클라이언트를 사용하여 웹사이트 콘텐츠를 업로드합니다.", "Commentary": "SFTP를 그대로 쓰는 방법이지만, S3 버킷 자체가 공개로 설정되어 있어야 하고 CloudFront Origin Access Identity 구성도 누락되어 보안 및 비용 측면에서 최적의 접근은 아닙니다."}}}
{"Question_Number": "Q206", "Question_Description": "한 회사가 Amazon Machine Images(AMIs)를 관리하려고 합니다. 현재는 AMI가 생성된 동일한 AWS Region으로만 복사하고 있습니다. 이 회사는 AWS API 호출을 포착하고 회사 계정 내에서 Amazon EC2 CreateImage API 오퍼레이션이 호출될 때마다 알림을 보내는 애플리케이션을 설계해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["Amazon Machine Image(AMI)", "CreateImage API 호출", "AWS API 호출 모니터링", "운영 오버헤드 최소화", "EventBridge 규칙"], "Terms": ["AWS Lambda", "AWS CloudTrail", "Amazon Simple Notification Service (SNS)", "Amazon Athena", "Amazon EventBridge (Amazon CloudWatch Events)", "Amazon Simple Queue Service (Amazon SQS)", "Amazon EC2 CreateImage API", "AMI"], "Commentary": "이 문제는 AMI 생성에 관련된 API 호출을 실시간으로 감시하고 알림을 보내는 방법을 묻습니다. CreateImage API 이벤트를 자동으로 포착하여 SNS 등으로 알림을 보내기 위해서는, 로그 파일을 직접 스캔하거나 여러 단계를 거치는 방식보다 EventBridge 규칙을 활용하는 방식이 가장 간단하고 운영 오버헤드가 적습니다. EventBridge에서 정확히 CreateImage API 호출 이벤트를 인식하고 바로 알림을 전송할 수 있기 때문입니다.", "Selections": {"SelectA": {"Select": "AWS Lambda 함수를 생성하여 AWS CloudTrail 로그를 주기적으로 쿼리하고 CreateImage API 호출이 감지되면 알림을 전송합니다.", "Commentary": "로그 쿼리를 위한 Lambda 구성과 주기적 실행 설정이 필요해 운영 오버헤드가 큽니다."}, "SelectB": {"Select": "AWS CloudTrail을 설정해 업데이트된 로그가 Amazon S3에 전송될 때 Amazon SNS 알림을 활성화합니다. 그리고 Amazon Athena로 CreateImage API 호출을 쿼리합니다.", "Commentary": "S3 업로드 후 Athena 쿼리까지 단계를 거쳐야 해 구성과 관리가 복잡합니다."}, "SelectC": {"Select": "Amazon EventBridge(Amazon CloudWatch Events)에서 CreateImage API 호출을 트리거로 하는 규칙을 생성합니다. 대상(Target)으로 Amazon SNS 토픽을 구성해 API 호출이 감지될 때 알림을 전송합니다.", "Commentary": "EventBridge 규칙로 특정 API 이벤트를 직접 감지하고 SNS에 알림을 보내므로 구성과 관리가 단순하며 운영 오버헤드가 최소화됩니다."}, "SelectD": {"Select": "Amazon SQS FIFO 대기열을 AWS CloudTrail 로그의 타겟으로 설정합니다. CreateImage API 호출이 감지되면 Lambda 함수를 통해 Amazon SNS 토픽으로 알림을 전송합니다.", "Commentary": "SQS 대기열 생성 및 Lambda 트리거 설정 등 단계가 많아지므로 운영 복잡도가 커집니다."}}}
{"Question_Number": "Q207", "Question_Description": "어떤 회사는 사용자 요청을 수집하기 위한 비동기식 API를 운영하고 있으며, 요청 유형에 맞춰 적절한 마이크로서비스로 요청을 전달합니다. 이 회사는 Amazon API Gateway를 사용해 API 프런트 엔드를 배포하고, AWS Lambda 함수를 이용해 Amazon DynamoDB에 사용자 요청을 저장한 뒤 처리 마이크로서비스로 전달하고 있습니다. 회사는 예산 범위 내에서 DynamoDB 프로비저닝 용량을 최대치로 설정했지만, 여전히 가용성 문제가 발생하여 사용자 요청이 유실되고 있습니다. 기존 사용자들에게 영향을 주지 않으면서 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["비동기식 API", "Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB", "가용성 문제", "기존 사용자 영향 최소화", "Amazon SQS"], "Terms": ["Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB", "DynamoDB Accelerator (DAX)", "Secondary index", "Amazon Simple Queue Service (Amazon SQS)", "Throttling", "Asynchronous API"], "Commentary": "이 문제는 DynamoDB 쓰기 부담으로 인해 요청이 유실되는 상황에서, 기존 API 동작을 방해하지 않고도 확장성과 내결함성을 높이기 위한 설계를 찾는 것이 핵심입니다. 비동기 구조에 적합한 Amazon SQS를 사용해 쓰기 요청을 버퍼링함으로써 DynamoDB의 부하를 완화하고 사용자 요청 유실을 방지할 수 있습니다.", "Selections": {"SelectA": {"Select": "API Gateway에 서버 측 제한(throttling)을 추가합니다.", "Commentary": "throttling을 추가하면 요청이 제한되어 기존 사용자 요청에 영향을 줄 수 있으므로 적합하지 않습니다."}, "SelectB": {"Select": "DynamoDB Accelerator (DAX)와 Lambda를 사용해 DynamoDB로의 쓰기를 버퍼링합니다.", "Commentary": "DAX는 읽기 성능 캐싱 솔루션이므로 쓰기 부담 문제를 해결하기 어렵습니다."}, "SelectC": {"Select": "DynamoDB 테이블에 secondary index를 생성합니다.", "Commentary": "secondary index는 조회 성능 개선에 도움을 줄 수 있지만 쓰기 처리량 이슈에는 직접적인 해결책이 되지 않습니다."}, "SelectD": {"Select": "Amazon SQS 큐와 Lambda를 사용해 DynamoDB로의 쓰기를 버퍼링합니다.", "Commentary": "비동기식 구조 특성을 활용해 요청을 먼저 SQS에 저장한 뒤 DynamoDB로 안정적으로 쓰기를 처리해 유실을 방지합니다."}}}
{"Question_Number": "Q208", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 이동해야 합니다. 회사는 어떤 API 호출이나 데이터도 퍼블릭 인터넷 경로를 통해 라우팅되지 않도록 보장해야 합니다. 오직 Amazon EC2 인스턴스만이 S3 버킷으로 데이터 업로드 권한을 가져야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["VPC Endpoint", "Private 라우팅", "퍼블릭 인터넷 차단", "EC2에서 S3로 데이터 전송", "IAM Role", "Resource Policy"], "Terms": ["Interface VPC Endpoint", "Gateway VPC Endpoint", "Resource Policy", "IAM Role", "Amazon EC2", "Amazon S3", "nslookup", "VPC Route Table", "ip-ranges.json"], "Commentary": "이 문제는 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 안전하게 전송할 때, 퍼블릭 인터넷을 전혀 거치지 않도록 구성하는 방법을 묻습니다. S3에 대한 완전한 사설 연결을 제공하기 위해서는 적절한 타입의 VPC Endpoint를 사용하고, S3 버킷 정책(Resource Policy)에서 특정 IAM Role만 허용하도록 제한해야 합니다. 이를 통해 API 호출 및 데이터 전송이 모두 AWS 내부 경로를 통해서만 이뤄지며, 퍼블릭 인터넷 경로를 사용하지 않게 됩니다.", "Selections": {"SelectA": {"Select": "Amazon S3에 대한 Interface VPC endpoint를 EC2 인스턴스가 위치한 서브넷에 생성합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.", "Commentary": "Interface VPC Endpoint를 사용하면 EC2와 S3 간 통신이 AWS 내부에서만 이뤄집니다. Resource Policy로 IAM Role을 제한해 보안을 강화할 수 있으며, 요구사항을 완벽히 충족합니다."}, "SelectB": {"Select": "Amazon S3에 대한 Gateway VPC endpoint를 EC2 인스턴스가 위치한 가용 영역(Availability Zone)에 생성합니다. 엔드포인트에 적절한 보안 그룹을 연결합니다. 그런 다음 S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.", "Commentary": "Gateway VPC Endpoint는 S3 전용 경로를 제공하지만, 보안 그룹을 직접 Gateway Endpoint에 적용할 수 없으며 문제에서 요구한 방식과 부합하지 않습니다."}, "SelectC": {"Select": "EC2 인스턴스 내부에서 nslookup 도구를 사용해 S3 버킷 서비스 API 엔드포인트의 프라이빗 IP 주소를 확인합니다. VPC 라우트 테이블에 해당 IP 주소로의 경로를 설정합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.", "Commentary": "nslookup으로 특정 IP를 찾아 직접 라우트를 구성하는 것은 신뢰성과 관리 측면에서 복잡하며, 엔드포인트로의 안정적 전송 보장을 위해 권장되지 않습니다."}, "SelectD": {"Select": "AWS에서 제공하는 ip-ranges.json 파일을 사용해 S3 서비스 API 엔드포인트의 프라이빗 IP 주소를 확인합니다. VPC 라우트 테이블에 해당 IP 주소로 라우팅을 설정합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.", "Commentary": "ip-ranges.json은 각 서비스별 퍼블릭 IP 대역 정보이므로, 엔드포인트 통신에 직접 활용하기 어렵고 유지 보수가 복잡해 요구사항을 충족하기 어렵습니다."}}}
{"Question_Number": "Q209", "Question_Description": "한 솔루션스 아키텍트가 새로운 애플리케이션을 AWS Cloud에 배포하기 위한 아키텍처를 설계하고 있습니다. 이 애플리케이션은 Amazon EC2 On-Demand Instances에서 동작하며, 여러 Availability Zone에 걸쳐 자동으로 확장(Scale-out/Scale-in)될 예정입니다. 하루 동안 EC2 인스턴스는 자주 증설되고 축소될 것입니다. Application Load Balancer(ALB)가 트래픽 분산을 처리합니다. 아키텍처는 분산된 세션 데이터 관리를 지원해야 하며, 필요하다면 코드 수정도 가능합니다.\n\n아키텍처가 분산 세션 데이터 관리를 지원하도록 하기 위해서는 솔루션스 아키텍트가 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["분산 세션 데이터", "자동 확장", "다중 AZ", "Application Load Balancer", "Amazon ElastiCache"], "Terms": ["Amazon EC2 On-Demand Instances", "Availability Zone", "Application Load Balancer(ALB)", "세션 데이터 관리", "Amazon ElastiCache", "session affinity(sticky sessions)", "Session Manager", "AWS Systems Manager", "GetSessionToken", "AWS Security Token Service(AWS STS)"], "Commentary": "이 문제는 멀티 AZ 환경에서 자주 확장되는 EC2 인스턴스를 위한 분산 세션 저장 방안을 묻습니다. 세션 정보를 어디에서나 접근 가능하도록 중앙화해 고가용성과 확장성을 보장해야 합니다.", "Selections": {"SelectA": {"Select": "Amazon ElastiCache를 사용하여 세션 데이터를 관리하고 저장합니다.", "Commentary": "Amazon ElastiCache를 활용하면 여러 EC2 인스턴스와 AZ에 걸쳐 세션 정보를 공유할 수 있어 확장성과 고가용성을 모두 달성하는 최적의 방법입니다."}, "SelectB": {"Select": "ALB의 session affinity(sticky sessions)를 사용해 세션 데이터를 관리합니다.", "Commentary": "Sticky sessions는 특정 인스턴스에만 세션을 고정해 다른 인스턴스가 접근하기 어려워집니다. 다중 AZ 확장 시 분산 세션을 보장하기 어렵습니다."}, "SelectC": {"Select": "AWS Systems Manager의 Session Manager를 사용해 세션을 관리합니다.", "Commentary": "Session Manager는 EC2 인스턴스에 접속하기 위한 관리 도구이며, 애플리케이션 세션 데이터 관리 용도와는 무관합니다."}, "SelectD": {"Select": "AWS STS의 GetSessionToken API를 사용하여 세션을 관리합니다.", "Commentary": "STS 토큰은 임시 자격 증명을 위한 것이며, 애플리케이션 세션 저장소 대안이 될 수 없어 분산 세션 관리와 직접 관련이 없습니다."}}}
{"Question_Number": "Q210", "Question_Description": "한 회사가 빠르게 성장 중인 음식 배달 서비스를 제공합니다. 이로 인해 회사의 주문 처리 시스템이 트래픽 피크 시간대에 확장(스케일링) 문제를 겪고 있습니다. 현재 아키텍처는 아래와 같습니다:\n• Amazon EC2 Auto Scaling 그룹에서 동작하는 Amazon EC2 인스턴스 그룹(애플리케이션에서 주문을 수집)\n• Amazon EC2 Auto Scaling 그룹에서 동작하는 또 다른 Amazon EC2 인스턴스 그룹(주문을 처리)\n주문 수집 프로세스는 빠르게 이루어지지만, 주문 처리 프로세스는 더 오래 걸릴 수 있습니다. 스케일링 이벤트로 인해 데이터가 손실되어서는 안 됩니다. 솔루션스 아키텍트는 피크 트래픽 시간대에 주문 수집 프로세스와 주문 처리 프로세스가 모두 적절히 확장 가능하도록 보장해야 합니다. 또한 회사의 AWS 자원 활용을 최적화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["피크 트래픽", "주문 처리", "데이터 손실", "AWS 자원 활용 최적화", "backlog per instance"], "Terms": ["Amazon EC2", "Amazon EC2 Auto Scaling", "Amazon CloudWatch", "Amazon Simple Queue Service (Amazon SQS)", "Amazon Simple Notification Service (Amazon SNS)", "backlog per instance", "scaling event"], "Commentary": "이 문제는 주문 수집과 주문 처리 과정을 각각 확장 가능하게 구성하는 방법이 핵심입니다. 주문이 쌓이는 것(백로그)을 고려해 확장하도록 설계해야 하며, 데이터 손실을 방지하기 위해 풀(Poll) 방식인 Amazon SQS를 활용하는 것이 유리합니다. 특히 ‘backlog per instance’ 지표를 사용하면 인스턴스당 메시지 처리량을 파악해 탄력적인 자동 확장을 구현할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon CloudWatch 지표로 각 Auto Scaling 그룹 인스턴스의 CPU를 모니터링하고, 피크 워크로드 기준으로 최소 용량을 설정합니다.", "Commentary": "CPU 사용량만으로 스케일링하면 주문 처리 지연이나 메시지 누락을 제대로 감지하기 어렵고, 무조건 피크 용량을 유지하는 것은 비효율적입니다."}, "SelectB": {"Select": "Amazon CloudWatch 지표로 각 Auto Scaling 그룹 인스턴스의 CPU를 모니터링하고, CloudWatch 알람이 Amazon SNS를 호출해 필요 시 Auto Scaling 그룹을 추가 생성합니다.", "Commentary": "CPU 기반 알람으로만 확장 그룹을 추가 생성하는 것은 주문 처리 속도에 직접적인 대응이 어렵고, 구성 복잡도와 비용이 증가할 수 있습니다."}, "SelectC": {"Select": "Amazon SQS 큐를 두 개 생성해(하나는 주문 수집, 다른 하나는 주문 처리용) 각 EC2 인스턴스가 해당 큐를 폴링하도록 구성합니다. 큐에서 전송하는 알림을 기반으로 Auto Scaling 그룹을 확장합니다.", "Commentary": "전달되는 알림만으로 스케일링하면 주문이 실제로 얼마나 밀려 있는지 구체적으로 파악하기 어려워, 과소 또는 과다 확장이 발생할 수 있습니다."}, "SelectD": {"Select": "Amazon SQS 큐를 주문 수집용과 주문 처리용으로 각각 두 개 생성합니다. 각 EC2 인스턴스는 자신이 담당하는 큐를 폴링합니다. 인스턴스당 백로그(backlog per instance) 계산을 위한 지표를 만든 뒤, 이 지표를 기준으로 Auto Scaling 그룹을 확장합니다.", "Commentary": "큐의 메시지 수를 인스턴스 수로 나눈 백로그을 모니터링함으로써 정확한 스케일링 조정이 가능합니다. 데이터 손실 없이 유연하게 확장하여 AWS 자원을 효율적으로 활용할 수 있어 정답입니다."}}}
{"Question_Number": "Q211", "Question_Description": "한 회사는 여러 프로덕션 애플리케이션을 운영하고 있습니다. 이 중 한 애플리케이션은 여러 AWS 리전에서 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service(Amazon SNS), Amazon Simple Queue Service(Amazon SQS) 리소스로 구성되어 있습니다. 회사의 모든 리소스에는 태그 이름이 'application'이고, 이 애플리케이션별로 대응되는 값을 가진 태그가 지정되어 있습니다. 솔루션스 아키텍트는 이러한 태그가 설정된 모든 컴포넌트를 가장 빠르게 식별할 수 있는 솔루션을 제시해야 합니다. 어떤 솔루션이 이 요구 사항을 충족합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["프로덕션 애플리케이션", "AWS 리소스", "태그", "application"], "Terms": ["Amazon EC2", "AWS Lambda", "Amazon RDS", "Amazon Simple Notification Service (Amazon SNS)", "Amazon Simple Queue Service (Amazon SQS)", "AWS CloudTrail", "AWS CLI", "Amazon CloudWatch Logs Insights", "AWS Resource Groups Tag Editor"], "Commentary": "이 문제의 핵심은 태그를 기준으로 여러 리전과 서비스를 통합적으로 검색하고자 할 때 가장 빠른 방법을 찾는 것입니다. Resource Groups Tag Editor는 태그를 한 번에 관리, 검색 및 보고할 수 있도록 도와주는 서비스로, 다양한 리전에 걸친 모든 태그 지정 리소스를 빠르고 효율적으로 찾아줍니다. 따라서 가장 신속하고 편리한 솔루션은 Resource Groups Tag Editor를 활용하는 것입니다.", "Selections": {"SelectA": {"Select": "AWS CloudTrail을 사용하여 application 태그가 지정된 리소스 목록을 생성합니다.", "Commentary": "CloudTrail은 주로 API 호출을 로깅하는 서비스이므로 태그가 지정된 리소스를 즉시 통합적으로 파악하기에는 적합하지 않습니다."}, "SelectB": {"Select": "AWS CLI를 사용하여 모든 리전에서 각 서비스를 쿼리해 application 태그가 지정된 컴포넌트를 보고합니다.", "Commentary": "모든 리전에 걸쳐 CLI로 개별 서비스를 일일이 조회해야 하므로 가장 빠르고 간단한 방법이 아닙니다."}, "SelectC": {"Select": "Amazon CloudWatch Logs Insights에서 쿼리를 실행하여 application 태그가 있는 컴포넌트를 보고합니다.", "Commentary": "로그 분석 솔루션으로 직접 태그 지정 리소스만 조회하기에는 적합하지 않으므로 빠른 식별 방법으로는 부족합니다."}, "SelectD": {"Select": "AWS Resource Groups Tag Editor에서 쿼리를 실행하여 application 태그가 지정된 리소스를 전 리전에 걸쳐 보고합니다.", "Commentary": "Resource Groups Tag Editor는 태그 관리 및 검색에 최적화된 서비스로, 여러 리전에 있는 태그 지정 자원을 가장 빠르게 식별할 수 있는 방법입니다."}}}
{"Question_Number": "Q212", "Question_Description": "한 회사가 매일 한 번씩 데이터베이스를 Amazon S3로 내보내야 하며, 다른 팀들이 접근할 수 있어야 합니다. 내보내지는 객체의 크기는 2GB에서 5GB 사이로 다양합니다. S3에 대한 데이터 접근 패턴은 급격히 변하고 불규칙적입니다. 데이터는 즉시 사용 가능해야 하고, 최대 3개월 동안은 접근이 가능해야 합니다. 회사는 데이터 검색 시간을 늘리지 않으면서도 가장 비용 효율적인 솔루션을 원합니다. 어떤 S3 스토리지 클래스를 사용해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["일일 데이터베이스 백업", "즉시 사용 가능", "3개월 보관", "비용 효율", "가변 접근 패턴"], "Terms": ["S3 Intelligent-Tiering", "S3 Glacier Instant Retrieval", "S3 Standard", "S3 Standard-Infrequent Access (S3 Standard-IA)"], "Commentary": "이 문제는 변동이 심한 S3 데이터 접근 패턴에서, 검색 시간을 늘리지 않으면서 비용을 최소화하는 스토리지 클래스를 선택하는 질문입니다. S3 Intelligent-Tiering은 자동으로 액세스 패턴을 모니터링해 자주 접근되지 않는 객체를 저렴한 티어로 옮기면서도 필요 시 즉시 검색할 수 있어, 예측하기 어려운 접근 패턴에 적합합니다.", "Selections": {"SelectA": {"Select": "S3 Intelligent-Tiering", "Commentary": "데이터의 접근 패턴이 자주 변하고, 즉시 검색이 필요한 상황에서 자동으로 적절한 티어로 전환해 주므로 가장 비용 효율적이며 검색 시간에 영향을 주지 않는 솔루션입니다."}, "SelectB": {"Select": "S3 Glacier Instant Retrieval", "Commentary": "Glacier 계열은 주로 아카이빙 용도로 사용됩니다. 즉시 검색이 가능하지만, 빈번한 접근 패턴이 예상된다면 비용 효율이 떨어질 수 있습니다."}, "SelectC": {"Select": "S3 Standard", "Commentary": "즉시 검색이 가능한 일반 스토리지지만, 객체가 자주 접근되지 않을 때 비용 측면에서 최적이라고 보기 어렵습니다."}, "SelectD": {"Select": "S3 Standard-Infrequent Access (S3 Standard-IA)", "Commentary": "자주 액세스하지 않는 객체에 대한 비용 효율성은 우수하나, 접근 빈도가 예측 불가하고 갑작스러운 접근이 잦다면 비용과 성능 면에서 불리할 수 있습니다."}}}
{"Question_Number": "Q213", "Question_Description": "한 회사가 새로운 모바일 앱을 개발하고 있습니다. 이 회사는 Application Load Balancer(ALB)를 크로스 사이트 스크립팅(XSS)이나 SQL 인젝션 같은 대표적인 애플리케이션 레벨 공격으로부터 보호하기 위해 적절한 트래픽 필터링을 구현해야 합니다. 또한 이 회사는 인프라 및 운영 인력이 매우 제한적이므로, 서버를 관리·업데이트·보안 유지하는 책임을 최대한 줄여야 합니다. 이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 어떤 해결책을 권장해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2", "1.3"], "Keywords": ["모바일 앱", "트래픽 필터링", "ALB 보호", "XSS", "SQL 인젝션", "인프라와 운영 최소화", "책임 감소"], "Terms": ["Application Load Balancer(ALB)", "AWS WAF", "Amazon S3", "AWS Shield Advanced", "Amazon EC2", "서드파티 방화벽"], "Commentary": "이 문제는 ALB를 애플리케이션 레벨 공격(예: XSS, SQL 인젝션)에서 보호하려 할 때 가장 간단하고 운영 부담이 적은 방식을 찾는 것입니다. AWS WAF를 ALB에 연동해 두면 기본적으로 제공되는 규칙 세트와 함께 사용해 즉시 보안 정책을 적용할 수 있고, 서버를 직접 운영하거나 업데이트할 필요가 없어 회사의 운영 부담과 책임 범위를 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS WAF 규칙을 구성하고 이를 ALB에 연동합니다.", "Commentary": "AWS WAF를 사용하면 ALB에서 발생하는 애플리케이션 레벨 공격에 대한 트래픽 필터링을 즉시 제공하며, 운영 부담이 낮고 서버 관리 책임도 대폭 줄일 수 있어 요구 사항에 부합합니다."}, "SelectB": {"Select": "Amazon S3를 퍼블릭 호스팅으로 활성화하여 애플리케이션을 배포합니다.", "Commentary": "S3 호스팅만으로는 ALB를 통한 트래픽 제어와 애플리케이션 레벨 보안을 제공하기 어렵습니다. ALB로의 공격 방어를 설정할 수 없으므로 적절한 보호책이 되기 어렵습니다."}, "SelectC": {"Select": "AWS Shield Advanced를 배포하고 ALB를 보호 리소스로 등록합니다.", "Commentary": "AWS Shield Advanced는 주로 DDoS 공격(네트워크/전송 계층)을 보호하기 위한 서비스로, XSS나 SQL 인젝션 같은 애플리케이션 레벨 공격 방어에는 적합하지 않습니다."}, "SelectD": {"Select": "새로운 ALB를 생성하고 트래픽을 서드파티 방화벽이 동작하는 Amazon EC2 인스턴스로 전달한 뒤, 다시 현재 ALB로 전달합니다.", "Commentary": "서드파티 방화벽 운영 및 EC2 인스턴스 관리가 추가되어 인프라와 운영이 복잡해지며, 회사의 책임 범위도 크게 늘어나므로 요구 사항에 부합하지 않습니다."}}}
{"Question_Number": "Q214", "Question_Description": "한 회사의 보고 시스템은 매일 수백 개의 .csv 파일을 Amazon S3 버킷으로 전송합니다. 이 회사는 이 파일들을 Apache Parquet 포맷으로 변환하고, 변환된 파일들을 별도의 변환된 데이터 버킷에 저장해야 합니다. 이러한 작업을 최소한의 개발 노력으로 달성할 수 있는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["CSV 파일", "Apache Parquet 변환", "최소 개발 노력", "Amazon S3 버킷", "변환된 데이터 버킷"], "Terms": ["Amazon EMR", "Apache Spark", "AWS Glue crawler", "AWS Glue ETL job", "AWS Batch", "Bash", "AWS Lambda", "Apache Parquet", "Amazon S3"], "Commentary": "이 문제는 매일 전달되는 CSV 데이터를 Apache Parquet 포맷으로 자동 변환해야 할 때, 가장 손쉽게 구현할 수 있는 방안을 묻습니다. AWS Glue를 활용하면 크롤러와 ETL 기능을 통해 CSV를 Parquet으로 간편하게 변환할 수 있어 개발 부담이 가장 적고 유지보수도 수월합니다.", "Selections": {"SelectA": {"Select": "Amazon EMR 클러스터를 구성하고 Apache Spark를 설치합니다. 데이터를 변환하는 Spark 애플리케이션을 작성하고, EMRFS를 사용해 변환된 데이터를 변환된 데이터 버킷으로 저장합니다.", "Commentary": "Spark 애플리케이션과 EMR 클러스터 구성, 운영 등의 추가 작업이 필요해 개발과 관리 부담이 큽니다."}, "SelectB": {"Select": "AWS Glue crawler를 생성하여 데이터를 탐색합니다. AWS Glue Extract, Transform, and Load(ETL) 작업을 생성해 데이터를 변환합니다. 출력 단계에서 변환된 데이터 버킷을 지정합니다.", "Commentary": "서버리스 기반 Glue를 활용하면 CSV에서 Parquet 변환을 간편하게 자동화할 수 있어 개발 노력이 가장 적은 이상적인 솔루션입니다."}, "SelectC": {"Select": "AWS Batch를 사용하여 Bash 스크립트 문법으로 변환 작업을 정의한 job definition을 만듭니다. 변환된 데이터를 변환된 데이터 버킷에 출력합니다. job 유형으로 배열 작업을 지정해 제출합니다.", "Commentary": "Batch 작업과 Bash 스크립트 작성 및 스케줄링 관리가 필요해 추가적인 개발과 오케스트레이션 부담이 존재합니다."}, "SelectD": {"Select": "AWS Lambda 함수를 생성하여 데이터를 변환하고, 변환된 데이터를 변환된 데이터 버킷으로 출력합니다. S3 버킷에 이벤트 알림을 구성하고 Lambda 함수를 대상 함수로 지정합니다.", "Commentary": "Lambda로 대용량 파일 변환 시 메모리 및 실행 시간 제한 등이 걸림돌이 될 수 있으며, 변환 로직 구현 부담도 커집니다."}}}
{"Question_Number": "Q215", "Question_Description": "한 회사는 데이터 센터 내의 NAS(Network Attached Storage)에 700TB의 백업 데이터를 저장하고 있습니다. 이 백업 데이터는 드문 규제 요청 시 접근이 필요하며, 7년 동안 보관되어야 합니다. 회사는 이 백업 데이터를 1개월 이내에 데이터 센터에서 AWS로 마이그레이션하기로 결정했습니다. 회사는 퍼블릭 인터넷 연결을 통해 500Mbps의 전용 대역폭을 데이터 전송에 사용할 수 있습니다. 비용을 가장 낮게 유지하면서 데이터를 어떻게 마이그레이션하고 저장해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["700TB 백업 데이터", "NAS", "규제 요청", "7년 보관", "1개월 내 마이그레이션", "500Mbps 전용 대역폭", "AWS Snowball", "Amazon S3 Glacier Deep Archive"], "Terms": ["AWS Snowball", "Amazon S3", "Amazon S3 Glacier Deep Archive", "AWS DataSync", "VPN connection", "AWS Direct Connect", "NAS", "Lifecycle policy"], "Commentary": "대규모 온프레미스 데이터를 저렴하게 장기 보관해야 하는 상황입니다. 700TB의 데이터를 1개월 내 전송하려면 물리적인 전송 방법인 AWS Snowball을 사용하는 것이 가장 빠르고, 이후 Amazon S3 Glacier Deep Archive로 전환해 보관 비용을 최소화할 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Snowball 디바이스를 주문해 데이터를 전송하고, Lifecycle policy를 사용해 Amazon S3 Glacier Deep Archive로 파일을 전환합니다.", "Commentary": "Snowball을 통해 대용량 데이터를 빠르게 옮기고, 장기 보관에는 Glacier Deep Archive를 사용해 비용을 절감하는 최적의 선택입니다."}, "SelectB": {"Select": "데이터 센터와 Amazon VPC 간에 VPN 연결을 구성하고, AWS CLI로 온프레미스 데이터를 Amazon S3 Glacier로 복사합니다.", "Commentary": "VPN만으로 700TB를 전송하면 오래 걸리고 대역폭 제약으로 비용과 시간 모두 비효율적입니다."}, "SelectC": {"Select": "500Mbps AWS Direct Connect를 프로비저닝하고, 데이터를 Amazon S3로 전송합니다. 이후 Lifecycle policy로 Amazon S3 Glacier Deep Archive로 전환합니다.", "Commentary": "Direct Connect 구축에는 시간이 걸리고 비용이 높아, 단기 대용량 이전 용도로는 Snowball이 더 경제적입니다."}, "SelectD": {"Select": "AWS DataSync를 사용하여 온프레미스에 DataSync 에이전트를 배포하고, NAS 스토리지에서 곧바로 Amazon S3 Glacier로 파일을 복사합니다.", "Commentary": "DataSync는 네트워크 전송이므로 700TB 전송 시 한 달 내 완료가 어려울 수 있고, 비용도 더 들 수 있습니다."}}}
{"Question_Number": "Q216", "Question_Description": "한 회사가 Amazon S3 bucket에 수백만 개의 객체를 보유한 서버리스 웹사이트를 운영 중이며, 이 S3 bucket을 Amazon CloudFront 배포의 오리진으로 사용하고 있습니다. 회사는 객체를 업로드하기 전 S3 bucket에 암호화를 설정하지 않았습니다. 솔루션스 아키텍트는 기존 객체와 추후 추가될 모든 객체에 대해 암호화를 활성화해야 합니다. 최소한의 노력으로 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["S3 버킷 암호화", "기존 객체", "S3 Inventory", "S3 Batch Operations", "기본 암호화", "서버리스 웹사이트", "CloudFront 오리진"], "Terms": ["Amazon S3", "Amazon CloudFront", "S3 Inventory", "S3 Batch Operations", "AWS Key Management Service (AWS KMS)", "SSE-KMS", "Versioning"], "Commentary": "S3 bucket에서 기존 객체와 새 객체 암호화를 한 번에 처리하려면 S3 Inventory로 비암호화 객체를 식별하고, S3 Batch Operations로 사본을 생성해 암호화하는 방식이 가장 쉽고 효율적입니다.", "Selections": {"SelectA": {"Select": "새로운 S3 bucket을 생성하고 기본 암호화를 활성화한 뒤, 기존 객체를 임시 로컬 스토리지로 다운로드 후 새 버킷으로 업로드합니다.", "Commentary": "기존 객체를 모두 내려받고 새 버킷에 다시 올려야 하므로 번거롭고 시간과 비용이 많이 듭니다."}, "SelectB": {"Select": "기존 S3 bucket의 기본 암호화를 활성화합니다. S3 Inventory 기능으로 비암호화 객체 목록 .csv를 생성하고, S3 Batch Operations의 copy 명령어로 이 객체들을 암호화합니다.", "Commentary": "새 객체에도 자동으로 암호화가 적용되며, 기존 객체는 Batch Job으로 간편하게 일괄 암호화해 가장 효율적인 방법입니다."}, "SelectC": {"Select": "AWS KMS로 새로운 암호화 키를 생성하고, S3 bucket 설정을 SSE-KMS로 변경합니다. 그 후 S3 bucket에 Versioning을 활성화합니다.", "Commentary": "SSE-KMS와 버저닝만으로는 기존 객체에 대한 자동 암호화 적용이 안 돼 추가 작업이 필요합니다."}, "SelectD": {"Select": "AWS Management Console의 Amazon S3에서 S3 bucket 객체 목록을 보고, 암호화 필드로 정렬 후 비암호화 객체를 찾아 Modify 기능으로 기본 암호화를 적용합니다.", "Commentary": "콘솔에서 객체를 일일이 수동 처리해야 하므로 대규모 객체 관리에는 매우 비효율적입니다."}}}
{"Question_Number": "Q217", "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스로 구동되는 글로벌 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon Aurora에 데이터를 저장합니다. 회사는 재해 복구(Disaster Recovery) 솔루션을 구축해야 하며, 30분 정도의 다운타임과 일부 데이터 손실을 수용할 수 있습니다. 또한 주(primary) 인프라가 정상일 때는 부하를 처리할 필요가 없습니다. 이러한 요구 사항을 만족하려면 솔루션스 아키텍트가 어떻게 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["글로벌 웹 애플리케이션", "Amazon EC2", "Application Load Balancer", "Amazon Aurora", "재해 복구", "다운타임 30분", "Route 53", "Active-Passive Failover"], "Terms": ["Amazon EC2", "Application Load Balancer", "Amazon Aurora", "Aurora Replica", "AWS Region", "AWS Backup", "Route 53 Active-Passive Failover", "Active-Active Failover", "두 번째 Primary Instance"], "Commentary": "이 문제는 재해 복구를 위한 대기(active-passive) 환경을 설계하는 상황입니다. 요구 사항에서 주 인프라가 정상일 때 부하 처리가 필요 없으므로, Route 53 Active-Passive 구성을 고려해야 합니다. Aurora Replica를 사용하면 30분 이내 다운타임과 일부 데이터 손실 허용 조건을 충족하면서 복구 시간을 단축할 수 있습니다.", "Selections": {"SelectA": {"Select": "필요한 인프라 요소를 미리 배포하고, Amazon Route 53을 사용해 Active-Passive Failover를 구성합니다. 두 번째 AWS Region에 Aurora Replica를 생성합니다.", "Commentary": "Active-Passive 패턴과 Aurora Replica를 이용해 DR 요구사항을 충족합니다. 주 인프라가 정상일 때는 부하를 처리하지 않아도 되어 운영 비용도 절감됩니다."}, "SelectB": {"Select": "두 번째 AWS Region에 축소된 형태의 애플리케이션을 호스팅합니다. Amazon Route 53으로 Active-Active Failover를 구성합니다. 두 번째 Region에 Aurora Replica를 생성합니다.", "Commentary": "Active-Active는 주 인프라가 정상일 때도 부하를 처리해야 하므로 요구사항과 맞지 않습니다. 불필요한 비용과 복잡도가 증가합니다."}, "SelectC": {"Select": "기존 인프라를 두 번째 AWS Region에 그대로 복제합니다. Amazon Route 53으로 Active-Active Failover를 구성합니다. 최신 스냅샷에서 복원한 Aurora DB를 사용합니다.", "Commentary": "Active-Active 형태로 항상 두 리전 모두 부하를 처리하게 됩니다. 필요 이상의 구성으로, 주 인프라가 정상일 때 부하를 처리하지 않아도 되는 요구사항과 어긋납니다."}, "SelectD": {"Select": "AWS Backup을 사용해 데이터를 백업하고, 이 백업으로 두 번째 AWS Region에서 필요한 인프라를 생성합니다. Amazon Route 53으로 Active-Passive Failover를 구성하고, 두 번째 Region에 Aurora 두 번째 Primary 인스턴스를 생성합니다.", "Commentary": "Aurora 두 번째 Primary 인스턴스를 만드는 것은 과도합니다. 필요한 것은 Replica 수준으로도 충분하며, 백업에서 모든 인프라를 재생성하는 방식은 RTO를 늘릴 수 있습니다."}}}
{"Question_Number": "Q218", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 웹 서버를 구동하고 있습니다. 이 인스턴스는 Elastic IP 주소가 할당된 퍼블릭 서브넷에 위치해 있으며 기본 보안 그룹이 적용되어 있습니다. 또한 기본 Network ACL이 모든 트래픽을 차단하도록 수정된 상태입니다. 솔루션스 아키텍트는 웹 서버를 전 세계 어디에서나 포트 443(HTTPS)으로 접근 가능하도록 구성해야 합니다. 어떤 조치들의 조합이 이를 달성할 수 있습니까? (두 개를 고르십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["웹 서버 접근", "보안 그룹", "Network ACL", "퍼블릭 서브넷", "포트 443"], "Terms": ["Amazon EC2", "Elastic IP", "Security Group", "Network ACL", "TCP 443", "Ephemeral Port (32768-65535)"], "Commentary": "이 문제는 Amazon EC2에 웹 서버를 두고, 기본 Security Group과 Network ACL을 적절히 구성해 HTTPS(443) 포트를 전 세계에서 허용하도록 설정하는 방법을 묻습니다. 루트 원리로, Security Group은 인바운드에서 443을 허용해야 하며, Network ACL은 양방향 트래픽을 모두 처리하기 위해 443과 에페머럴 포트 범위를 열어야 합니다. EC2 인스턴스가 제대로 HTTPS로 접근 가능하려면, 보안 그룹과 Network ACL 양쪽에서 인바운드/아웃바운드를 모두 허용해 주어야 합니다. 따라서 올바른 조합은 Security Group이 443 인바운드를 열고, Network ACL이 443 인바운드와 32768-65535 아웃바운드를 허용하는 것입니다.", "Selections": {"SelectA": {"Select": "Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.", "Commentary": "보안 그룹에서 인바운드 443을 열어 전 세계 접근을 허용해 줍니다. 필수 설정이므로 정답에 포함됩니다."}, "SelectB": {"Select": "Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.", "Commentary": "Security Group 설정이지만 목적지 방향 설정이므로 잘못된 방향(아웃바운드) 규칙입니다."}, "SelectC": {"Select": "Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.", "Commentary": "NACL에서 단순히 443 인바운드만 허용하면 반응 패킷이 반환되지 않아 HTTPS 접근이 제대로 동작하지 않습니다."}, "SelectD": {"Select": "Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.", "Commentary": "NACL에서 443만 열 경우, 에페머럴 포트 범위가 차단되어 실제 통신이 이루어지기 어렵습니다."}, "SelectE": {"Select": "Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0.", "Commentary": "HTTPS 요청 수락(443 인바운드), 반환(에페머럴 포트 아웃바운드)을 모두 열어야 하므로 정답입니다."}}}
{"Question_Number": "Q219", "Question_Description": "한 회사의 애플리케이션에서 성능 문제가 발생하고 있습니다. 이 애플리케이션은 상태를 저장하며 Amazon EC2 인스턴스에서 인메모리 작업을 수행해야 합니다. 해당 회사는 AWS CloudFormation을 사용해 인프라를 배포했고, M5 EC2 인스턴스 패밀리를 사용했습니다. 트래픽이 증가함에 따라 애플리케이션의 성능이 저하되었으며, 사용자는 애플리케이션 접근 시 지연을 보고하고 있습니다. 이 문제를 가장 운영 효율적인 방식으로 해결하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2"], "Keywords": ["인메모리 작업", "EC2 인스턴스 패밀리", "성능 문제", "CloudFormation", "메모리 지표"], "Terms": ["Amazon EC2", "M5 EC2", "T3 EC2", "R5 EC2", "Auto Scaling group", "Amazon CloudWatch", "CloudWatch agent", "AWS Management Console", "in-memory tasks", "AWS CloudFormation"], "Commentary": "인메모리 기반 애플리케이션 성능 저하 문제를 해결하기 위해 메모리 최적화가 필요한 R5 EC2 인스턴스와 CloudWatch agent를 통한 커스텀 지표 확보가 핵심입니다.", "Selections": {"SelectA": {"Select": "T3 EC2 인스턴스로 교체하고 Auto Scaling group을 사용합니다. 변경은 AWS Management Console에서 수행합니다.", "Commentary": "T3 인스턴스는 버스팅 기반이며 메모리를 많이 사용하는 애플리케이션 요구사항을 만족하기 어렵습니다."}, "SelectB": {"Select": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 Auto Scaling group에서 실행합니다. 필요 시 Auto Scaling group의 Desired 및 Maximum capacity를 수동으로 증가시킵니다.", "Commentary": "Auto Scaling은 확장에 유리하나 메모리 최적화 문제가 해결되지 않아 성능 병목이 해소되지 않습니다."}, "SelectC": {"Select": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 R5 EC2로 교체합니다. Amazon CloudWatch의 기본 EC2 메모리 지표를 사용해 향후 용량 계획에 대비합니다.", "Commentary": "기본 메모리 지표는 기본적으로 지원되지 않으므로 정확한 모니터링이 어렵습니다."}, "SelectD": {"Select": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 R5 EC2로 교체합니다. EC2 인스턴스에 Amazon CloudWatch agent를 배포해 커스텀 애플리케이션 지연 시간 지표를 생성해 향후 용량 계획에 사용합니다.", "Commentary": "메모리 최적화를 위해 R5 패밀리를 사용하고 CloudWatch agent로 세부 지표까지 모니터링해 문제를 효과적으로 해결합니다."}}}
{"Question_Number": "Q220", "Question_Description": "한 솔루션스 아키텍트가 Amazon API Gateway를 사용하여 새로운 API를 설계하고 있습니다. 이 API는 사용자로부터 요청을 받으며, 요청 볼륨이 매우 가변적이어서 몇 시간 동안 요청이 없을 수도 있습니다. 데이터 처리는 비동기적으로 이루어지지만, 요청 후 몇 초 내에 완료되어야 합니다. 가장 낮은 비용으로 이 요구 사항을 충족하기 위해 API가 호출해야 할 Compute 서비스는 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["새로운 API 설계", "비용 최소화", "비동기 처리", "요청 볼륨 변동"], "Terms": ["Amazon API Gateway", "AWS Glue job", "AWS Lambda function", "Amazon EKS", "Amazon ECS", "Amazon EC2"], "Commentary": "이 문제는 요청이 불규칙하게 발생하는 환경에서 비용 효율적이며 빠른 처리가 가능한 컴퓨팅 서비스를 선택하는 것입니다. 서버리스 방식인 AWS Lambda는 사용된 만큼만 비용을 지불하고, 요청이 없을 때는 추가 비용이 들지 않아 요구 사항을 충족합니다.", "Selections": {"SelectA": {"Select": "AWS Glue job", "Commentary": "AWS Glue job은 ETL 작업에 적합하나 실시간 또는 수 초 내 처리를 요구하는 환경에는 부적합합니다."}, "SelectB": {"Select": "AWS Lambda function", "Commentary": "서버리스 아키텍처로 요청 발생 시에만 동작해 비용 효율적이며, 비동기로 빠르게 확장 가능합니다."}, "SelectC": {"Select": "Amazon EKS에 컨테이너 호스팅", "Commentary": "EKS 클러스터는 유연성이 뛰어나지만, 장시간 대기 상태에서도 최소 인프라 비용이 발생할 수 있습니다."}, "SelectD": {"Select": "Amazon EC2에서 Amazon ECS로 컨테이너 호스팅", "Commentary": "EC2 인스턴스 사용에 따른 상시 비용이 부담되며, 요청이 거의 없을 때도 인프라가 유휴 상태가 됩니다."}}}
{"Question_Number": "Q221", "Question_Description": "한 회사는 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 운영하고 있습니다. 규정 준수 상의 이유로 모든 애플리케이션 로그 파일을 7년 동안 보존해야 합니다. 이 로그 파일들은 보고 툴에서 동시에 접근할 수 있어야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["로그 파일", "7년", "동시 접근", "비용효율성", "Amazon S3"], "Terms": ["Amazon Linux EC2", "Amazon EBS", "Amazon EFS", "Amazon EC2 instance store", "Amazon S3"], "Commentary": "이 문제는 규정상 7년 보존해야 하는 로그 파일을 비용효율적으로 저장하면서 동시 접근해야 하는 상황입니다. Amazon S3는 다수 리소스에서 동시에 접근 가능하며 장기 보관에도 가장 저렴한 옵션입니다.", "Selections": {"SelectA": {"Select": "Amazon Elastic Block Store (Amazon EBS)", "Commentary": "Amazon EBS는 블록 스토리지로 성능은 우수하지만 장기간 보관 시 비용이 높고 다중 인스턴스 동시 접근이 어렵습니다."}, "SelectB": {"Select": "Amazon Elastic File System (Amazon EFS)", "Commentary": "Amazon EFS는 여러 EC2 인스턴스 간 공유가 가능하지만 장기 보관 시 Amazon S3 대비 비용이 더 높을 수 있습니다."}, "SelectC": {"Select": "Amazon EC2 instance store", "Commentary": "Instance store는 인스턴스 수명과 함께 데이터가 사라지므로 장기간 보관과 동시 접근에 적합하지 않습니다."}, "SelectD": {"Select": "Amazon S3", "Commentary": "Amazon S3는 비용 효율적이며 다수 리소스에서 동시에 접근 가능해 7년 보관 및 동시 접근 요구사항을 충족합니다."}}}
{"Question_Number": "Q222", "Question_Description": "한 회사가 외부 벤더를 고용하여 회사의 AWS 계정에서 작업을 수행하도록 했습니다. 이 벤더는 벤더가 소유한 AWS 계정에 호스팅된 자동화 툴을 사용합니다. 벤더는 회사의 AWS 계정에 대한 IAM 액세스 권한이 없습니다. 이런 상황에서 솔루션스 아키텍트는 어떻게 벤더에게 접근 권한을 부여해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["외부 벤더", "IAM 역할 부여", "자동화 툴", "보안 액세스"], "Terms": ["IAM Role", "IAM User", "IAM Group", "Identity Provider", "AWS Account", "Trust Relationship"], "Commentary": "이 문제는 회사 외부 벤더가 소유한 AWS 계정의 자동화 툴이 회사 계정의 리소스에 안전하게 접근하도록 권한을 부여하는 방법을 묻고 있습니다. 가장 좋은 방법은 회사 계정에서 IAM Role을 생성하고, 해당 Role을 벤더의 IAM Role에 위임하는 신뢰 관계를 설정하여 필요한 권한을 최소 권한 원칙에 따라 부여하는 것입니다. 이를 통해 자격 증리(크리덴셜) 공유 없이도 안전하고 세분화된 접근이 가능합니다.", "Selections": {"SelectA": {"Select": "회사의 계정에 벤더의 IAM Role에게 위임할 수 있는 IAM Role을 생성하고, 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.", "Commentary": "트러스트 관계를 설정해 벤더의 Role이 회사 계정의 Role을 Assume하여 필요한 리소스에 접속합니다. 보안성과 필요 권한만 부여하는 최소 권한 원칙을 지킵니다."}, "SelectB": {"Select": "회사의 계정에 IAM User를 생성하고, 암호 규칙을 충족하는 비밀번호를 설정합니다. 이후 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.", "Commentary": "IAM User 계정을 만들어 공유하는 것은 보안상 위험이 크고, 자격 증리 노출 우려가 높아 권장되지 않습니다."}, "SelectC": {"Select": "회사의 계정에 IAM Group을 생성하고, 벤더 계정의 IAM User를 그룹에 추가합니다. 이후 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.", "Commentary": "벤더 측 User를 직접 그룹에 추가하면 신뢰 관계 설정 없이 접근이 이뤄져 관리가 복잡하고 안전하지 않습니다."}, "SelectD": {"Select": "IAM 콘솔에서 'AWS account' 유형으로 새 Identity Provider를 생성하고, 벤더의 AWS account ID와 사용자 이름을 입력합니다. 벤더가 필요한 권한을 담은 IAM Policy를 새 Provider에 연결합니다.", "Commentary": "Identity Provider는 주로 외부 IdP 연동(페더레이션)용이며, 단순 권한 위임 목적으로 사용하기에는 적절하지 않습니다."}}}
{"Question_Number": "Q223", "Question_Description": "한 회사가 사설 서브넷에서 Amazon Elastic Kubernetes Service(Amazon EKS)에서 동작하는 파드로 Java Spring Boot 애플리케이션을 배포했습니다. 이 애플리케이션은 Amazon DynamoDB 테이블에 데이터를 써야 합니다. 솔루션스 아키텍트는 인터넷에 트래픽을 노출하지 않고 애플리케이션이 DynamoDB 테이블과 상호 작용하도록 보장해야 합니다. 다음 중 이를 달성하기 위해 솔루션스 아키텍트가 수행해야 할 조합은 무엇입니까? (2개를 선택하십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["Amazon EKS", "Java Spring Boot", "IAM role", "Amazon DynamoDB", "VPC endpoint", "사설 서브넷", "인터넷 비노출"], "Terms": ["Amazon EKS", "Java Spring Boot", "IAM role", "Amazon DynamoDB", "VPC endpoint", "Network ACL"], "Commentary": "이 문제는 사설 서브넷에 있는 EKS 파드가 인터넷을 통하지 않고 DynamoDB에 안전하게 접근하도록 구성하는 방법을 묻습니다. IAM role을 사용해 파드에 권한을 부여하고 VPC endpoint로 사설 경로를 설정하면 인터넷 노출 없이 DynamoDB에 접근할 수 있습니다.", "Selections": {"SelectA": {"Select": "권한이 충분한 IAM role을 EKS 파드에 연결합니다.", "Commentary": "EKS 파드가 DynamoDB에 쓰기 권한을 갖도록 하는 올바른 접근 방식입니다. 하드코딩 없이 안전하게 권한을 부여합니다."}, "SelectB": {"Select": "권한이 충분한 IAM user를 EKS 파드에 연결합니다.", "Commentary": "IAM user 대신 IAM role을 사용하는 것이 모범 사례이므로 적절치 않습니다."}, "SelectC": {"Select": "사설 서브넷의 network ACL을 통해 DynamoDB 테이블로의 아웃바운드 연결을 허용합니다.", "Commentary": "Network ACL을 통한 아웃바운드 허용만으로는 인터넷을 우회해 DynamoDB로 트래픽을 보내는 것을 완전히 보장하지 못합니다."}, "SelectD": {"Select": "DynamoDB용 VPC endpoint를 생성합니다.", "Commentary": "VPC endpoint를 통해 트래픽을 사설 경로로 라우팅하므로 인터넷에 노출되지 않고 DynamoDB에 액세스할 수 있습니다."}, "SelectE": {"Select": "Java Spring Boot 코드에 액세스 키를 하드코딩합니다.", "Commentary": "하드코딩된 액세스 키는 보안상 취약하므로 권장되지 않는 접근 방식입니다."}}}
{"Question_Number": "Q224", "Question_Description": "한 회사가 웹 애플리케이션을 AWS로 마이그레이션하여, 단일 AWS Region의 Amazon EC2 인스턴스에서 애플리케이션을 리호스팅했습니다. 이 회사는 애플리케이션 아키텍처를 고가용성 및 내결함성( fault tolerant )으로 재설계하고자 합니다. 트래픽은 실행 중인 모든 EC2 인스턴스에 무작위로 분산되어야 합니다. 이러한 요구사항을 충족하기 위해 어떤 조합의 단계를 수행해야 합니까? (두 가지를 고르세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["고가용성", "내결함성", "트래픽 무작위 분산", "Amazon EC2", "Amazon Route 53", "multivalue answer routing policy", "Availability Zone"], "Terms": ["Amazon EC2", "Amazon Route 53", "failover routing policy", "weighted routing policy", "multivalue answer routing policy", "Availability Zone"], "Commentary": "이 문제는 EC2 인스턴스를 여러 AZ에 분산 배치하고, 트래픽을 무작위로 분산할 방법을 묻습니다. multivalue answer routing policy를 사용하면 DNS 응답에 여러 IP를 무작위로 반환해 트래픽을 분산할 수 있고, 여러 AZ에 인스턴스를 배포해 고가용성과 내결함성을 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "Create an Amazon Route 53 failover routing policy.", "Commentary": "failover routing은 기본 리소스가 실패했을 때 보조 리소스로 트래픽을 전환하는 용도로, 무작위 분배나 이중화 배포와는 목적이 다릅니다."}, "SelectB": {"Select": "Create an Amazon Route 53 weighted routing policy.", "Commentary": "weighted routing은 가중치에 따라 트래픽을 배분하는 것으로, 난수 방식으로 무작위 배분하기엔 적절하지 않습니다."}, "SelectC": {"Select": "Create an Amazon Route 53 multivalue answer routing policy.", "Commentary": "multivalue answer routing policy를 사용하면 DNS 응답 시 여러 IP들을 무작위 순서로 반환하여 트래픽을 분산할 수 있어 요구사항에 부합합니다."}, "SelectD": {"Select": "Launch three EC2 instances: two instances in one Availability Zone and one instance in another Availability Zone.", "Commentary": "AZ를 이중화한 것은 좋지만, 세 개의 인스턴스만으로는 무작위 분산 시 리소스 활용이 불균형해질 수 있습니다."}, "SelectE": {"Select": "Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.", "Commentary": "두 개의 AZ에 각각 두 개의 인스턴스를 배포하여 고가용성과 부하 분산을 확보하므로 요구사항에 적합합니다."}}}
{"Question_Number": "Q225", "Question_Description": "한 미디어 회사가 온프레미스에서 사용자 활동 데이터를 수집하고 분석해 왔습니다. 이 데이터는 페타바이트(PB) 규모까지 계속 증가할 예정입니다. 회사는 고가용성의 데이터 수집 솔루션을 구축해야 하며, 기존 데이터와 신규 데이터를 SQL로 온디맨드 분석할 수 있어야 합니다. 또한 운영 오버헤드를 최소화해야 합니다. 이 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3", "3.5"], "Keywords": ["미디어 회사", "사용자 활동 데이터", "페타바이트 규모", "고가용성 데이터 수집", "온디맨드 분석", "SQL", "운영 오버헤드 최소화"], "Terms": ["Amazon Kinesis Data Stream", "Amazon Kinesis Data Firehose", "Amazon S3", "Amazon Redshift", "AWS Lambda", "Amazon EC2", "Amazon RDS", "Multi-AZ"], "Commentary": "이 문제는 증가하는 대규모 데이터를 안정적으로 수집하고 곧바로 SQL 기반 분석을 해야 하는 상황에서, 가장 단순하고 자동화된 파이프라인을 구성하는 방안을 묻습니다. Kinesis Data Firehose를 통해 Amazon Redshift로 직접 스트리밍하면 페타바이트 규모의 데이터도 빠르게 적재하고 SQL로 분석이 가능합니다. 완전관리형 서비스 조합으로 운영 오버헤드를 최소화할 수 있다는 점이 핵심입니다.", "Selections": {"SelectA": {"Select": "Amazon Kinesis Data Stream에 활동 데이터를 전송합니다. 스트림을 Amazon S3 버킷으로 전달하도록 구성합니다.", "Commentary": "Kinesis Data Stream을 사용하면 별도의 소비자 애플리케이션 설정이 필요해 운영 부담이 큽니다. 또한 수집 후 SQL 분석 환경(예: Redshift, Athena) 구성이 추가로 필요합니다."}, "SelectB": {"Select": "Amazon Kinesis Data Firehose 스트림에 활동 데이터를 전송합니다. 스트림을 Amazon Redshift 클러스터로 전달하도록 구성합니다.", "Commentary": "Kinesis Data Firehose는 완전관리형으로 데이터를 대규모로 실시간 적재할 수 있고, Redshift를 통해 손쉽게 SQL 분석이 가능합니다. 운영 오버헤드를 크게 줄이는 최적의 솔루션입니다."}, "SelectC": {"Select": "Amazon S3 버킷에 활동 데이터를 저장합니다. 데이터가 도착하면 Amazon S3에서 AWS Lambda 함수를 실행하도록 구성합니다.", "Commentary": "Lambda로 후처리를 할 수 있지만, 바로 SQL 분석을 제공하지 않습니다. 추가 서비스(Athena 등) 구성이 필요하고 실시간 적재 측면에서도 Firehose보다 관리 포인트가 많습니다."}, "SelectD": {"Select": "멀티 AZ에 분산된 Amazon EC2 인스턴스에서 자체 인제션 서비스를 실행하고, 이 서비스를 Amazon RDS Multi-AZ 데이터베이스로 전달되도록 구성합니다.", "Commentary": "EC2 기반 자체 서비스와 대규모 RDS 운영은 복잡도가 높습니다. 페타바이트 규모 데이터에 대한 SQL 분석용으로는 확장성 측면에서 부적합합니다."}}}
{"Question_Number": "Q226", "Question_Description": "한 회사가 RESTful web services 애플리케이션을 Amazon EC2 인스턴스에서 실행하여 수천 대의 원격 디바이스로부터 데이터를 수집하고 있습니다. EC2 인스턴스는 수집된 원시 데이터를 받아 변환하여 Amazon S3 버킷에 저장하고 있습니다. 원격 디바이스의 수가 곧 수백만 대로 증가할 예정이므로, 회사는 운영 오버헤드를 최소화하면서 고도로 확장 가능한 솔루션이 필요합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 단계 조합은 다음 중 무엇일까요? (2개 선택)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["고도로 확장 가능한 솔루션", "운영 오버헤드 최소화", "RESTful 웹 서비스", "Amazon EC2", "Amazon S3"], "Terms": ["AWS Glue", "Amazon Route 53", "Amazon SQS", "Amazon EC2", "Amazon API Gateway", "Amazon Kinesis Data Streams", "Amazon Kinesis Data Firehose", "Amazon S3"], "Commentary": "수집 장치가 대폭 늘어나는 시나리오에서 API Gateway와 Kinesis를 통한 무중단 확장성을 확보하고, 데이터를 S3에 저장한 뒤 Glue로 간편하게 변환하는 방안이 가장 효율적입니다.", "Selections": {"SelectA": {"Select": "AWS Glue를 사용하여 Amazon S3의 원시 데이터를 처리합니다.", "Commentary": "AWS Glue를 통해 S3에 적재된 원시 데이터를 손쉽게 추출·변환·적재(ETL)할 수 있어, 개발 및 운영 부담을 줄이고 자동 확장도 용이합니다."}, "SelectB": {"Select": "Amazon Route 53을 사용하여 다른 EC2 인스턴스로 트래픽을 라우팅합니다.", "Commentary": "Route 53만으로는 확장에 필요한 데이터 처리 파이프라인이 마련되지 않으며, 단순 DNS 라우팅만으로는 운영 오버헤드를 크게 줄이지 못합니다."}, "SelectC": {"Select": "증가하는 데이터 처리를 위해 EC2 인스턴스를 추가 배치합니다.", "Commentary": "EC2 인스턴스를 직접 늘리는 방식은 서버 관리 부담과 확장 한계가 커지므로 운영 오버헤드가 증가합니다."}, "SelectD": {"Select": "Amazon SQS로 원시 데이터를 보내고, EC2 인스턴스로 데이터를 처리합니다.", "Commentary": "SQS만으로 다량의 스트리밍 데이터를 실시간으로 처리하기에는 한계가 있으며, 서버 운영 복잡성을 완전히 해소하지 못합니다."}, "SelectE": {"Select": "Amazon API Gateway를 사용하여 원시 데이터를 Amazon Kinesis Data Streams로 전송하고, Amazon Kinesis Data Firehose를 사용해 데이터를 Amazon S3로 전달하도록 구성합니다.", "Commentary": "API Gateway와 Kinesis를 조합하여 무중단 확장성을 확보하고, Firehose로 실시간 데이터를 안정적으로 S3에 적재할 수 있으므로 운영이 단순해집니다."}}}
{"Question_Number": "Q227", "Question_Description": "한 회사는 AWS CloudTrail logs를 3년 동안 보관해야 합니다. 이 회사는 부모 계정에서 AWS Organizations를 사용해 여러 AWS 계정에 대해 CloudTrail을 강제 적용하고 있습니다. CloudTrail이 기록되는 대상 S3 bucket에는 S3 Versioning이 활성화되어 있으며, 현재 객체에 대해서는 3년 후 삭제되도록 S3 Lifecycle Policy가 설정되어 있습니다. 그런데 4년차가 되었을 때 S3 bucket 메트릭에서 확인해보니, 새로운 CloudTrail logs의 증가량은 동일함에도 불구하고 객체 수가 계속 증가하고 있습니다. 가장 비용 효율적인 방식으로 3년이 지난 객체들을 삭제하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["AWS CloudTrail logs", "S3 Versioning", "S3 Lifecycle Policy", "3년 보관", "비용 효율"], "Terms": ["AWS CloudTrail", "AWS Organizations", "S3 Versioning", "S3 Lifecycle Policy", "S3 bucket", "AWS Lambda", "Object Ownership"], "Commentary": "Versioning이 활성화된 S3에서 3년 후 현재 객체만 삭제하면 이전 버전은 계속 남아 비용이 증가합니다. 따라서 이전 버전까지 제거하도록 Lifecycle Policy를 설정해주는 것이 가장 간단하고 비용 효율적입니다.", "Selections": {"SelectA": {"Select": "조직에서 중앙 집중화된 CloudTrail trail을 구성해 3년 후 객체가 만료되도록 설정합니다.", "Commentary": "CloudTrail trail 설정만으로 이전 버전을 삭제할 수 없으며, Versioning 및 Lifecycle 통합이 필요하므로 적절한 해법이 아닙니다."}, "SelectB": {"Select": "S3 Lifecycle Policy를 이전 버전뿐 아니라 현재 버전도 함께 삭제하도록 구성합니다.", "Commentary": "Versioning이 활성화된 환경에서 이전 버전까지 삭제해주는 Lifecycle Policy 설정이 필요하므로 가장 효율적이고 간단한 해결책입니다."}, "SelectC": {"Select": "3년 이상 된 객체를 Amazon S3에서 열거 후 삭제하는 AWS Lambda 함수를 만듭니다.", "Commentary": "Lambda 함수를 통해 자동화할 수 있지만, 별도의 구축·유지 비용이 들며, S3 Lifecycle Policy에 비해 관리가 복잡합니다."}, "SelectD": {"Select": "배포 계정을 S3 bucket에 전달되는 모든 객체의 소유자로 설정합니다.", "Commentary": "Object Owner를 부모 계정으로 변경해도 이전 버전 삭제 문제는 해결되지 않으므로, 비용 최적화에 직접적인 도움이 되지 않습니다."}}}
{"Question_Number": "Q228", "Question_Description": "한 회사에 모니터링 디바이스로부터 실시간 데이터를 수신하는 API가 있습니다. 이 API는 수집된 데이터를 나중의 분석을 위해 Amazon RDS DB instance에 저장합니다. 모니터링 디바이스에서 전송되는 데이터량은 변동이 있으며, 트래픽이 많은 시기에는 API가 종종 타임아웃 에러를 반환합니다. 로그를 확인한 결과, DB가 API에서 발생하는 대량의 쓰기 트래픽을 처리하지 못하는 것으로 파악되었습니다. 솔루션스 아키텍트는 DB에 대한 연결 수를 최소화하고, 트래픽 급증 시에도 데이터가 손실되지 않도록 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["실시간 데이터", "Amazon RDS", "DB 인스턴스", "트래픽 변동", "쓰기 트래픽", "연결 수 최소화", "데이터 손실 방지"], "Terms": ["Amazon RDS", "Multi-AZ DB", "Amazon SQS", "AWS Lambda", "Amazon SNS"], "Commentary": "이 문제는 트래픽 급증 시 DB 과부하를 막고 데이터 유실을 방지하기 위해 아키텍처를 느슨하게 결합해야 함을 보여줍니다. Amazon SQS가 적절한 버퍼 역할을 하여 DB 연결을 줄이고 메시지를 안전하게 처리할 수 있습니다.", "Selections": {"SelectA": {"Select": "더 많은 메모리를 사용할 수 있는 인스턴스 타입으로 DB 인스턴스 크기를 늘립니다.", "Commentary": "DB 인스턴스 스펙 업그레이드는 일시적 성능 향상을 줄 뿐, 트래픽 스파이크와 연결 수 제한에 근본적인 해답이 되지 못합니다."}, "SelectB": {"Select": "DB 인스턴스를 Multi-AZ로 수정합니다. 애플리케이션을 모든 활성 RDS DB 인스턴스에 쓰도록 구성합니다.", "Commentary": "Multi-AZ 구성은 장애 복원을 위한 것이지 쓰기 처리량 증가나 연결 수 제한을 해결하기에 적합하지 않습니다."}, "SelectC": {"Select": "API가 들어오는 데이터를 Amazon Simple Queue Service(Amazon SQS) 큐에 쓰도록 수정합니다. Amazon SQS에서 AWS Lambda 함수를 호출하여 큐에서 DB로 데이터를 쓰도록 합니다.", "Commentary": "SQS 큐를 사용하여 트래픽 변동을 흡수하고, Lambda 함수로 연결을 단순화해 DB 부하를 줄이며, 데이터 유실을 방지할 수 있는 최적의 솔루션입니다."}, "SelectD": {"Select": "API가 들어오는 데이터를 Amazon Simple Notification Service(Amazon SNS) 토픽에 쓰도록 수정합니다. Amazon SNS에서 AWS Lambda 함수를 호출하여 토픽에서 DB로 데이터를 쓰도록 합니다.", "Commentary": "SNS는 주로 메시지 브로드캐스트(퍼블리시/서브스크라이브) 용도이며, 큐잉 방식이 아니라 트래픽 급증 시 데이터 처리 지연이나 연결 부담이 여전히 발생할 수 있습니다."}}}
{"Question_Number": "Q229", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 MySQL 데이터베이스를 운영하고 있습니다. 현재는 수요 변화에 따라 수동으로 복제와 확장을 관리하고 있습니다. 회사는 필요에 따라 데이터베이스 계층의 컴퓨트 용량을 쉽게 추가하거나 제거할 수 있는 새로운 솔루션이 필요합니다. 또한 운영의 노력은 최소화하면서 성능, 확장성, 내구성을 개선해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon EC2", "MySQL", "복제", "확장성", "성능", "내구성", "Aurora MySQL", "Aurora Serverless"], "Terms": ["Amazon EC2", "MySQL", "Amazon Aurora", "Aurora MySQL", "Aurora PostgreSQL", "Aurora Serverless", "EC2 Auto Scaling"], "Commentary": "이 문제는 자체 EC2 환경에서 MySQL 데이터베이스를 유지하며, 복제와 확장을 수동으로 관리하는 비효율성을 해결하는 목적입니다. 운영 부담을 줄이면서 성능, 확장성, 내구성을 높이는 해법을 찾아야 합니다. 정답인 Amazon Aurora Serverless for Aurora MySQL로 이전하면 자동 확장과 복제를 지원하므로, 수요 변화에 따라 쉽고 빠르게 컴퓨트 용량을 조정할 수 있고, 내장된 고가용성 및 내구성 덕분에 운영적으로 효율적입니다.", "Selections": {"SelectA": {"Select": "Amazon Aurora Serverless for Aurora MySQL로 데이터베이스를 마이그레이션합니다.", "Commentary": "Aurora Serverless for Aurora MySQL은 자동 복제와 자동 확장을 제공하여 운영 복잡성을 최소화하고 성능, 내구성까지 보장하므로 요구사항에 부합합니다."}, "SelectB": {"Select": "Amazon Aurora Serverless for Aurora PostgreSQL로 데이터베이스를 마이그레이션합니다.", "Commentary": "다른 데이터베이스 엔진으로 전환하면 호환성 문제가 발생할 수 있고 코드 수정이 필요하여 요구사항을 만족시키기 어렵습니다."}, "SelectC": {"Select": "모든 데이터베이스를 하나의 대형 MySQL 데이터베이스로 통합하고, 더 큰 EC2 인스턴스를 사용합니다.", "Commentary": "단순히 인스턴스 크기를 늘려도 자동 확장과 복제 측면에서 장점이 부족하고 운영 부담이 계속 높게 유지됩니다."}, "SelectD": {"Select": "데이터베이스 계층을 위한 EC2 Auto Scaling 그룹을 생성하고, 기존 데이터베이스를 새 환경으로 마이그레이션합니다.", "Commentary": "EC2 Auto Scaling만으로는 데이터베이스 복제와 확장을 자동화하기가 어렵고, 여전히 수동 관리가 필요합니다."}}}
{"Question_Number": "Q230", "Question_Description": "회사는 두 개의 NAT instance가 회사 애플리케이션에 필요한 트래픽을 더 이상 처리할 수 없을 것을 우려하고 있습니다. 솔루션스 아키텍트는 고가용성, 내결함성, 자동 확장을 제공하는 솔루션을 구현하려고 합니다. 어떤 방안을 권장해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["NAT instance", "NAT gateway", "고가용성", "내결함성", "자동 확장", "트래픽"], "Terms": ["NAT instance", "NAT gateway", "Auto Scaling group", "Network Load Balancer", "Availability Zone", "Spot Instances", "고가용성", "내결함성", "자동 확장"], "Commentary": "NAT instance 대신 NAT gateway를 사용하면 AWS가 직접 관리하므로 유지 보수 부담이 줄어듭니다. 여러 AZ에 배포하면 장애가 발생해도 서비스가 지속되며 자동 확장까지 지원되어 트래픽 증가를 원활히 처리할 수 있습니다.", "Selections": {"SelectA": {"Select": "두 NAT instance를 제거하고 동일한 AZ에 두 NAT gateway를 배포합니다.", "Commentary": "같은 AZ에만 배포하면 AZ 장애 시 유연성이 제한되어 고가용성을 보장하기 어렵습니다."}, "SelectB": {"Select": "서로 다른 AZ에 NAT instance를 두고 Network Load Balancer와 Auto Scaling group을 구성합니다.", "Commentary": "NAT instance는 직접 관리가 필요하며, 완전관리형 NAT gateway보다 운영 부담이 큽니다."}, "SelectC": {"Select": "두 NAT instance를 제거하고 다른 AZ에 두 NAT gateway를 배포합니다.", "Commentary": "고가용성과 자동 확장을 지원하는 완전관리형 솔루션으로, 여러 AZ에 배포해 내결함성과 확장성을 보장합니다."}, "SelectD": {"Select": "다른 AZ에 Spot Instances로 NAT instance를 대체하고 Network Load Balancer를 배포합니다.", "Commentary": "Spot Instances는 비용 효율적이지만 일시 중단 위험이 있어 안정성과 가용성을 보장하기 어렵습니다."}}}
{"Question_Number": "Q231", "Question_Description": "한 애플리케이션이 VPC A에 있는 Elastic IP 주소를 가진 Amazon EC2 인스턴스에서 실행 중이며, 해당 애플리케이션은 VPC B에 있는 데이터베이스에 액세스해야 합니다. 두 VPC는 동일한 AWS 계정 내에 있습니다. 가장 안전하게 필요한 액세스를 제공할 수 있는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["애플리케이션", "Amazon EC2 인스턴스", "Elastic IP", "VPC A", "VPC B", "데이터베이스", "VPC 피어링 연결"], "Terms": ["Amazon EC2", "Elastic IP", "VPC 피어링(VPC Peering)", "DB 인스턴스", "보안 그룹(Security Group)", "Public IP", "프록시(Proxy)"], "Commentary": "VPC 간 안전한 연결 방법을 묻는 문제로, 같은 AWS 계정 내에서 트래픽이 인터넷을 거치지 않고 직접 통신할 수 있도록 VPC 피어링을 구성하는 것이 가장 보안상 유리합니다. 각 VPC 간 네트워크 트래픽이 내부적으로만 오가므로, 외부 노출 위험 없이 DB 액세스를 안전하게 구성할 수 있습니다.", "Selections": {"SelectA": {"Select": "VPC의 애플리케이션 서버 퍼블릭 IP 주소에서 모든 트래픽을 허용하도록 DB 인스턴스 보안 그룹을 생성합니다.", "Commentary": "퍼블릭 IP를 통한 공개 인터넷 트래픽 허용은 보안상 취약하며, 트래픽이 인터넷을 거치므로 안전하지 않습니다."}, "SelectB": {"Select": "VPC A와 VPC B 간 VPC 피어링 연결을 구성합니다.", "Commentary": "VPC 피어링을 사용하면 인터넷을 거치지 않고 두 VPC 간 직접 통신이 가능하므로, 가장 안전하고 간단한 접근 방식입니다."}, "SelectC": {"Select": "DB 인스턴스를 퍼블릭 액세스가 가능하도록 설정하고, 퍼블릭 IP를 할당합니다.", "Commentary": "DB를 직접 퍼블릭으로 노출하면 매우 위험하며, 공격 표면이 크게 넓어집니다."}, "SelectD": {"Select": "Elastic IP 주소를 가진 Amazon EC2 인스턴스를 VPC B에 추가로 실행하고, 모든 요청을 새 EC2 인스턴스 통해 프록시합니다.", "Commentary": "프록시 서버를 두는 방식은 복잡도가 높고 보안 이점이 적어 비효율적입니다."}}}
{"Question_Number": "Q232", "Question_Description": "한 회사가 고객에게 제공하는 시연 환경을 Amazon EC2 인스턴스에서 운영하고 있습니다. 각 환경은 자체 VPC로 격리되어 있습니다. 회사 운영팀은 어떤 환경에서 RDP나 SSH 액세스가 이루어졌을 때 알림을 받아야 합니다. 이에 대한 올바른 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["EC2 인스턴스", "RDP 접근", "SSH 접근", "VPC 격리", "운영팀 알림"], "Terms": ["VPC Flow Logs", "Amazon CloudWatch Logs", "Amazon CloudWatch Metric Alarm", "EC2 Instance State-change Notification", "Amazon SNS", "IAM Instance Profile", "AmazonSSMManagedInstanceCore", "CloudWatch Application Insights"], "Commentary": "RDP나 SSH 액세스를 확인하려면 네트워크 트래픽을 모니터링하고 해당 이벤트 발생 시 알림을 설정해야 합니다. VPC Flow Logs를 CloudWatch Logs로 전송 후 지표 필터와 알람을 구성하면 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "Amazon CloudWatch Application Insights를 구성하여 RDP나 SSH 액세스가 감지될 때 AWS Systems Manager OpsItems를 생성하도록 설정합니다.", "Commentary": "Application Insights는 애플리케이션 성능 모니터링에 초점이 있어 RDP/SSH 세션 알림에 직접 특화되지 않았습니다."}, "SelectB": {"Select": "AmazonSSMManagedInstanceCore 정책이 연결된 IAM 역할을 가진 IAM 인스턴스 프로파일을 EC2 인스턴스에 구성합니다.", "Commentary": "이는 EC2 인스턴스 관리 및 명령 실행 권한에 대한 설정이므로, RDP나 SSH 세션이 열릴 때 알림을 보내기 위한 직접적인 해결책이 아닙니다."}, "SelectC": {"Select": "VPC Flow Logs를 Amazon CloudWatch Logs로 퍼블리싱합니다. 필요한 Metric Filter를 생성합니다. 그리고 ALARM 상태일 때 알림 동작이 설정된 Amazon CloudWatch Metric Alarm을 생성합니다.", "Commentary": "VPC Flow Logs로 RDP·SSH 트래픽을 감지하고 지표 필터 및 알람을 이용해 운영팀에 즉시 알릴 수 있는 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "EC2 Instance State-change Notification 타입 이벤트를 수신하는 Amazon EventBridge 룰을 구성합니다. Amazon SNS 토픽을 대상으로 지정하고, 운영팀을 구독시킵니다.", "Commentary": "이는 인스턴스의 시작·중지 상태 변화만을 알릴 뿐, RDP/SSH 세션이 성립될 때를 감지·알림하지는 못합니다."}}}
{"Question_Number": "Q233", "Question_Description": "한 솔루션스 아키텍트가 새 AWS 계정을 생성했고, AWS account root user의 액세스를 안전하게 보호해야 합니다. 아래 제시된 조치 중 두 가지를 선택하십시오. (두 가지 선택)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["root user 보안", "강력한 비밀번호", "multi-factor authentication", "AWS 계정 보호"], "Terms": ["AWS account root user", "multi-factor authentication(MFA)", "access key", "Amazon S3", "inline policy document"], "Commentary": "이 문제는 AWS account root user 계정의 불법적 접근을 막기 위해 가장 기본적인 보안 설정을 묻습니다. root user 접근은 강력 비밀번호와 MFA 활성화로 보호해야 하며, IAM 사용자를 생성해 일상 업무에 사용하도록 권장합니다.", "Selections": {"SelectA": {"Select": "root user가 복잡하고 강력한 비밀번호를 사용하도록 설정합니다.", "Commentary": "root user의 비밀번호를 복잡하게 설정하면 계정 탈취 위험을 크게 줄여줘 필수적인 보안 조치입니다. (정답)"}, "SelectB": {"Select": "root user에 multi-factor authentication(MFA)를 활성화합니다.", "Commentary": "MFA를 사용하면 추가 인증 요소가 요구되어 보안이 한층 강화됩니다. (정답)"}, "SelectC": {"Select": "root user access key를 암호화된 Amazon S3 버킷에 저장합니다.", "Commentary": "root user access key 자체 사용을 지양해야 하며, 별도 보관보다는 IAM 권한 관리를 통해 접근 권한을 위임하는 것이 안전합니다."}, "SelectD": {"Select": "관리자 권한이 있는 그룹에 root user를 추가합니다.", "Commentary": "root user는 이미 모든 권한을 가지고 있으므로 추가 권한 부여는 불필요하며 보안상 위험만 가중시킵니다."}, "SelectE": {"Select": "inline policy document를 통해 root user에 필요한 권한을 부여합니다.", "Commentary": "root user에 별도 권한을 부여할 필요가 없으며, IAM 사용자에게 필요한 권한을 부여해 일상 업무를 수행하는 방식이 최선입니다."}}}
{"Question_Number": "Q234", "Question_Description": "한 회사가 새로운 웹 기반 고객 관계 관리 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 Application Load Balancer(ALB) 뒤에서 Amazon EBS 볼륨을 사용하는 여러 Amazon EC2 인스턴스를 사용하고, Amazon Aurora 데이터베이스도 사용할 예정입니다. 이 애플리케이션의 모든 데이터는 저장 시(at rest)와 전송 시(in transit) 모두 암호화되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2", "1.3"], "Keywords": ["EBS 암호화", "Aurora 암호화", "Application Load Balancer", "AWS KMS", "ACM", "전송 중 암호화"], "Terms": ["Amazon EC2", "Amazon EBS", "Application Load Balancer (ALB)", "Amazon Aurora", "AWS Key Management Service (AWS KMS)", "AWS Certificate Manager (ACM)", "BitLocker", "TLS", "SSL"], "Commentary": "이 문제는 애플리케이션 데이터가 저장 시와 전송 시 모두 안전하게 보호되도록 구성하는 방법을 묻습니다. EBS와 Aurora에는 AWS KMS로 암호화를 적용하고, 전송 암호화는 ALB에 ACM 인증서를 적용해야 하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "AWS KMS 인증서를 ALB에 사용하여 전송 시 데이터를 암호화하고, AWS Certificate Manager(ACM)으로 EBS 볼륨과 Aurora 데이터베이스 스토리지를 저장 시 암호화합니다.", "Commentary": "ACM은 주로 인증서 관리를 위한 서비스이며, EBS 암호화에는 적절하지 않습니다. 이 방법은 EBS 암호화 부분이 올바르지 않습니다."}, "SelectB": {"Select": "AWS root 계정으로 AWS Management Console에 로그인한 뒤, 회사의 암호화 인증서를 업로드하고, 루트 계정에서 전체 계정에 대해 저장 시와 전송 시 암호화를 활성화 옵션을 선택합니다.", "Commentary": "루트 계정을 사용하는 것은 보안 모범 사례가 아니며, 계정 전체에 대한 일괄 암호화 활성화 옵션은 존재하지 않습니다."}, "SelectC": {"Select": "AWS Key Management Service(AWS KMS)를 사용하여 EBS 볼륨과 Aurora 데이터베이스 스토리지를 저장 시 암호화합니다. ALB에는 AWS Certificate Manager(ACM) 인증서를 연결하여 전송 시 데이터를 암호화합니다.", "Commentary": "가장 적절한 방법으로, EBS와 Aurora는 KMS로 암호화하고, ALB에 ACM 인증서를 연결해 전송 데이터를 암호화하여 요구 사항을 충족합니다."}, "SelectD": {"Select": "BitLocker로 모든 데이터를 저장 시 암호화합니다. 회사의 TLS 인증서 키를 AWS KMS로 가져와 ALB에 연결하여 전송 시 데이터를 암호화합니다.", "Commentary": "BitLocker는 주로 Windows 기반 운영체제용 암호화 도구이며, AWS EBS 및 Aurora 암호화 용도로 적합하지 않습니다. 인증서 키를 KMS에 직접 연결하여 ALB를 암호화하는 방식도 권장되지 않습니다."}}}
{"Question_Number": "Q235", "Question_Description": "한 회사가 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL로 이전하려고 합니다. 이 데이터베이스에는 동일한 테이블에 데이터를 쓰는 여러 애플리케이션이 있으며, 각 애플리케이션은 한 달 간격으로 하나씩 마이그레이션해야 합니다. 경영진은 해당 데이터베이스가 읽기와 쓰기가 매우 빈번하다는 점에 우려를 표했습니다. 또한 마이그레이션 기간 동안 두 데이터베이스의 데이터는 동기화 상태를 유지해야 합니다. 솔루션스 아키텍트는 어떤 구성을 권장해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["온프레미스 Oracle 데이터베이스", "Amazon Aurora PostgreSQL", "마이그레이션", "동기화 유지", "다수의 읽기·쓰기", "full load plus CDC", "memory optimized replication instance"], "Terms": ["Oracle database", "Amazon Aurora PostgreSQL", "AWS DataSync", "AWS Database Migration Service (AWS DMS)", "AWS Schema Conversion Tool", "change data capture (CDC)", "memory optimized replication instance", "compute optimized replication instance", "full load"], "Commentary": "이 문제는 Oracle에서 Amazon Aurora PostgreSQL로 단계별 마이그레이션을 진행하면서, 대규모 읽기·쓰기가 발생하는 상황에서 두 데이터베이스 간 동기화 상태를 유지해야 하는 시나리오입니다. AWS Schema Conversion Tool로 스키마 변환을 수행하고, AWS DMS를 통해 full load 뒤 CDC 방식으로 변경 내용을 실시간 복제하면 두 DB를 지속적으로 동기화할 수 있습니다. 특히 memory optimized replication instance는 고빈도 트랜잭션 환경에서 빠른 복제를 지원하므로 대규모 I/O 처리에 유리합니다.", "Selections": {"SelectA": {"Select": "초기 마이그레이션에 AWS DataSync를 사용하고, AWS DMS에서 change data capture(CDC) 복제 작업과 테이블 매핑을 생성해 모든 테이블을 선택합니다.", "Commentary": "DataSync로 초기 파일 이동은 가능하지만, CDC만으로는 전체 스키마 변환이 부족합니다. 메모리 최적화 설정도 없어 트랜잭션 처리 부하가 큰 환경에는 적합하지 않습니다."}, "SelectB": {"Select": "초기 마이그레이션에 AWS DataSync를 사용하고, AWS DMS에서 full load plus CDC 복제 작업과 테이블 매핑을 생성해 모든 테이블을 선택합니다.", "Commentary": "파일 기반 마이그레이션 후 full load plus CDC는 어느 정도 동기화를 지원하지만, 스키마 호환성 점검을 위한 AWS Schema Conversion Tool과 메모리 최적화 옵션이 없어 대규모 트랜잭션엔 비효율적입니다."}, "SelectC": {"Select": "AWS Schema Conversion Tool과 AWS DMS를 memory optimized replication instance로 구성합니다. 모든 테이블을 선택해 full load plus CDC 복제 작업을 생성합니다.", "Commentary": "스키마 변환 후 full load plus CDC로 기존 DB와 새 DB를 동기화하며, 메모리 최적화 인스턴스를 사용해 대규모 읽기·쓰기 부하에서도 빠른 복제가 가능합니다."}, "SelectD": {"Select": "AWS Schema Conversion Tool과 AWS DMS를 compute optimized replication instance로 구성합니다. 가장 큰 테이블만 선택해 full load plus CDC 복제 작업을 생성합니다.", "Commentary": "일부 테이블만 복제하면 전반적 동기화가 어려우며, compute optimized 인스턴스는 CPU 중심이어서 빈번한 읽기·쓰기 트랜잭션이 많은 환경에는 부적합합니다."}}}
{"Question_Number": "Q236", "Question_Description": "한 회사가 이미지 공유 용도의 3티어 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 프론트엔드 계층에 Amazon EC2 인스턴스, 애플리케이션 계층에 Amazon EC2 인스턴스, 그리고 MySQL 데이터베이스로 사용되는 또 다른 Amazon EC2 인스턴스로 구성되어 있습니다. 솔루션스 아키텍트는 최소한의 애플리케이션 수정으로도 확장 가능하고 고가용성을 갖춘 솔루션을 설계해야 합니다. 다음 중 어떤 솔루션이 이 요구 사항을 충족합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["3티어 애플리케이션", "이미지 공유", "확장 가능", "고가용성", "애플리케이션 변경 최소화", "AWS Elastic Beanstalk", "Multi-AZ", "Amazon RDS"], "Terms": ["Amazon EC2", "AWS Lambda", "Amazon DynamoDB", "Amazon S3", "AWS Elastic Beanstalk", "Amazon RDS", "Multi-AZ", "read replica", "Auto Scaling group", "MySQL"], "Commentary": "이 문제는 기존 Amazon EC2 기반 3티어 애플리케이션을 크게 수정하지 않고도 확장성과 고가용성을 확보해야 하는 시나리오입니다. Multi-AZ 배포와 Amazon RDS로 데이터베이스 인프라를 구성하거나, AWS Elastic Beanstalk로 계층을 운영함으로써 서비스 중단 위험을 줄이고 자동 확장을 지원할 수 있습니다. 정답은 최소한의 코드 변경으로 이러한 요구 사항을 만족하는 방안을 찾는 데 있습니다.", "Selections": {"SelectA": {"Select": "프론트엔드 계층을 Amazon S3에서 호스팅하고, 애플리케이션 계층은 AWS Lambda를 사용합니다. 데이터베이스는 Amazon DynamoDB 테이블로 이전하며, 사용자 이미지는 Amazon S3에 저장 및 제공하세요.", "Commentary": "Lambda와 DynamoDB로 전환하면 기존 애플리케이션 로직을 대폭 수정해야 하며, MySQL에서 DynamoDB로의 마이그레이션도 부담이 큽니다. 최소 변경이라는 요구 사항에 부합하지 않습니다."}, "SelectB": {"Select": "프론트엔드 계층과 애플리케이션 계층을 로드 밸런싱된 Multi-AZ AWS Elastic Beanstalk 환경으로 구성합니다. 데이터베이스는 여러 read replica가 있는 Amazon RDS DB 인스턴스로 이전하여 사용자 이미지를 제공합니다.", "Commentary": "AWS Elastic Beanstalk를 Multi-AZ로 배포해 애플리케이션 변경을 최소화하면서 자동 확장과 로드 밸런싱을 얻을 수 있습니다. 또한 Amazon RDS DB 인스턴스와 read replica를 활용해 확장성과 가용성을 높일 수 있어 가장 적은 코드 변경으로 목표를 달성하는 솔루션입니다."}, "SelectC": {"Select": "Amazon S3에서 프론트엔드 계층을 호스팅하고, 애플리케이션 계층은 Auto Scaling group에 속한 다수의 Amazon EC2 인스턴스를 사용합니다. 데이터베이스는 메모리 최적화된 인스턴스 유형으로 이전하여 사용자 이미지를 저장하고 제공합니다.", "Commentary": "S3 정적 호스팅으로 프론트엔드 변경이 필요하고, DB 층도 단순히 인스턴스 사양만 변경하기 때문에 고가용성이나 Multi-AZ 구성 측면에서 다소 부족합니다. 기존 애플리케이션 흐름 변경도 필요합니다."}, "SelectD": {"Select": "프론트엔드 계층과 애플리케이션 계층을 로드 밸런싱된 Multi-AZ AWS Elastic Beanstalk 환경으로 구성합니다. 데이터베이스는 Amazon RDS Multi-AZ DB 인스턴스로 이전하고, 사용자 이미지는 Amazon S3에 저장 및 제공하세요.", "Commentary": "Multi-AZ와 S3를 활용해 안정적이고 빠른 이미지 제공이 가능하지만, 기존 MySQL에 이미지를 저장했던 방식을 S3로 옮기려면 추가적인 애플리케이션 코드 변경이 필요해 요구 사항인 ‘최소 변경’에 약간 더 벗어납니다."}}}
{"Question_Number": "Q237", "Question_Description": "Amazon EC2 인스턴스가 위치한 VPC-A에서 다른 AWS 계정의 VPC-B에 있는 EC2 인스턴스에 접근해야 합니다. 두 VPC는 각각 별도의 AWS 계정에 있으며, 보안 방식으로 접근을 구성해야 하고, 단일 장애 지점이나 대역폭 문제가 없어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["VPC 피어링", "EC2 인스턴스 간 접근", "단일 장애 지점 방지", "AWS 계정 간 네트워크"], "Terms": ["VPC Peering", "VPC Gateway Endpoint", "Virtual Private Gateway", "Private Virtual Interface (VIF)"], "Commentary": "이 문제는 서로 다른 AWS 계정에 있는 두 VPC 간 안전하고 고가용성의 네트워크 연결 방안을 묻습니다. VPC Peering은 별도 하드웨어가 필요 없고 단일 장애 지점이 없는 연결 방식이므로, 고가용성과 대역폭 우려 없이 직접 통신이 가능합니다.", "Selections": {"SelectA": {"Select": "VPC-A와 VPC-B 간에 VPC Peering Connection을 설정합니다.", "Commentary": "정답입니다. VPC Peering은 별도의 게이트웨이나 물리적 연결 없이 양방향 통신이 가능하고, 단일 장애 지점이 없어 대역폭 병목이나 가용성 문제를 최소화합니다."}, "SelectB": {"Select": "VPC-B의 EC2 인스턴스에 대해 VPC Gateway Endpoint를 설정합니다.", "Commentary": "Gateway Endpoint는 S3 또는 DynamoDB와 같은 특정 AWS 서비스로의 전용 경로를 구성하기 위한 것입니다. VPC 간 직접 통신 용도로는 적합하지 않습니다."}, "SelectC": {"Select": "VPC-B에 Virtual Private Gateway를 연결하고 VPC-A에서 라우팅을 설정합니다.", "Commentary": "Virtual Private Gateway는 온프레미스 VPN 연결 등의 시나리오에 적합합니다. 별도 VPN 터널이 필요하며 설정이 복잡해지고, 단일 장애 지점 없이 연결하기엔 VPC Peering보다 비효율적입니다."}, "SelectD": {"Select": "VPC-B의 EC2 인스턴스를 위한 Private Virtual Interface를 생성하고, VPC-A에서 적절한 라우트를 추가합니다.", "Commentary": "Private VIF는 AWS Direct Connect를 통해 온프레미스와 VPC를 연결할 때 주로 사용됩니다. VPC 간 네트워크 통신을 단순화하기 위해서는 VPC Peering이 더 적합한 솔루션입니다."}}}
{"Question_Number": "Q238", "Question_Description": "한 회사는 엔지니어 팀을 위해 개별 AWS 계정을 실험적으로 사용하려 합니다. 회사는 특정 달에 각 계정의 Amazon EC2 인스턴스 사용량이 특정 임계값을 초과하면 즉시 알림을 받고 싶어 합니다. 가장 비용 효율적인 방법은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["엔지니어 개별 계정", "Amazon EC2", "월별 사용량 임계값", "비용 초과 알림", "가장 비용 효율적"], "Terms": ["Cost Explorer", "Amazon Simple Email Service (Amazon SES)", "AWS Budgets", "Amazon Simple Notification Service (Amazon SNS)", "AWS Cost and Usage Reports", "Amazon Athena", "Amazon EventBridge"], "Commentary": "각 계정별로 EC2 사용 비용이 월간 임계값을 초과할 경우 즉시 알림을 보내는 요구사항입니다. AWS Budgets를 활용하면 각 계정별로 쉽게 비용 한도를 설정하고 알림을 보낼 수 있어 추가 리소스가 필요 없어 가장 비용 효율적입니다.", "Selections": {"SelectA": {"Select": "Cost Explorer를 사용하여 서비스별 일간 비용 보고서를 생성하고, EC2 인스턴스만 필터링합니다. 임계값 초과 시 Amazon SES 알림을 설정합니다.", "Commentary": "일간 비용 보고서 활용은 가능하나, 자동화된 예산 관리 기능이 없어 알림 설정과 모니터링 면에서 부담이 클 수 있습니다."}, "SelectB": {"Select": "Cost Explorer를 사용하여 서비스별 월간 비용 보고서를 생성하고, EC2 인스턴스만 필터링합니다. 임계값 초과 시 Amazon SES 알림을 설정합니다.", "Commentary": "월간 보고서이지만 예산 기능이 아닌 단순 보고서로, 임계값 알림 비용 관리에 대한 자동화나 세밀한 제어가 부족합니다."}, "SelectC": {"Select": "AWS Budgets를 사용하여 각 계정별로 cost budget을 생성하고, 기간을 월별로 설정합니다. EC2 인스턴스만 대상으로 설정하고 알림 임계값을 지정합니다. 임계값 초과 시 Amazon SNS 토픽으로 알림을 전송하도록 구성합니다.", "Commentary": "AWS Budgets는 개별 계정의 월별 EC2 사용량 모니터링을 자동화하고, 임계값 초과 시 즉시 SNS를 통해 알림을 보내기 때문에 가장 비용 효율적이고 간단한 방법입니다."}, "SelectD": {"Select": "AWS Cost and Usage Reports를 사용해 시간 단위 보고서를 생성하고 Amazon Athena로 통합합니다. Amazon EventBridge를 이용해 Athena 쿼리를 스케줄링하고, 임계값 초과 시 Amazon SNS로 알림을 전송합니다.", "Commentary": "Athena와 EventBridge 등 여러 서비스를 연동해야 하므로 추가 비용 및 복잡도가 증가하여, 가장 비용 효율적이지는 않습니다."}}}
{"Question_Number": "Q239", "Question_Description": "한 솔루션스 아키텍트가 회사의 애플리케이션을 위한 새로운 마이크로서비스를 설계해야 합니다. 클라이언트는 HTTPS 엔드포인트를 통해 마이크로서비스에 접근할 수 있어야 하며, 이 마이크로서비스는 호출을 인증하기 위해 AWS Identity and Access Management(IAM)을 사용해야 합니다. 솔루션스 아키텍트는 Go 1.x로 작성된 단일 AWS Lambda 함수를 이용하여 이 마이크로서비스 로직을 작성하려고 합니다. 이 함수를 가장 운영 효율적으로 배포할 수 있는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["마이크로서비스", "HTTPS 엔드포인트", "AWS IAM", "Lambda 함수"], "Terms": ["Amazon API Gateway", "Lambda function URL", "IAM 인증", "Amazon CloudFront", "Lambda@Edge", "CloudFront Functions"], "Commentary": "이 문제는 HTTPS 엔드포인트가 필요하고, AWS IAM을 통한 인증이 필수적인 마이크로서비스를 운영 효율적으로 배포하는 방법을 묻습니다. API Gateway REST API를 사용하면 HTTPS 엔드포인트와 IAM 인증 설정을 손쉽게 통합하여 운영 복잡도를 줄이고 추가 기능(캐싱, 모니터링 등)까지 활용할 수 있어 효율적입니다. 다른 옵션들은 추가 구성 또는 별도의 배포 단계가 필요해 운영 편의성이 떨어지거나 IAM 인증을 직접 구현해야 하는 부담이 있습니다.", "Selections": {"SelectA": {"Select": "Amazon API Gateway REST API를 생성합니다. 메서드를 이 Lambda 함수로 연동합니다. 그리고 API에 대해 IAM 인증을 활성화합니다.", "Commentary": "API Gateway를 사용하면 HTTPS 엔드포인트를 쉽게 제공하고, IAM 인증 연동도 간편하게 적용할 수 있어 운영 복잡도를 크게 줄일 수 있는 최적의 솔루션입니다."}, "SelectB": {"Select": "해당 함수에 대해 Lambda function URL을 생성합니다. 인증 타입으로 AWS_IAM을 지정합니다.", "Commentary": "Lambda function URL은 간편한 옵션이나, API Gateway 기능(캐싱, 모니터링 등)을 활용하기 어려워 추가 기능 제공 측면에서 다소 제한적입니다."}, "SelectC": {"Select": "Amazon CloudFront 배포를 생성하고, 마이크로서비스 로직을 Lambda@Edge에 배포합니다. Lambda@Edge 함수 내부에 IAM 인증 로직을 통합합니다.", "Commentary": "Lambda@Edge를 사용할 경우 CloudFront를 중간에 두어야 하므로 구성 복잡도가 올라가고, IAM 인증 로직 역시 직접 구현해야 하여 운영 효율이 떨어집니다."}, "SelectD": {"Select": "Amazon CloudFront 배포를 생성하고, 함수를 CloudFront Functions로 배포합니다. 인증 타입으로 AWS_IAM을 지정합니다.", "Commentary": "CloudFront Functions는 Edge에서 가벼운 작업 수행에 초점을 두며, IAM 통합이나 API 엔드포인트로서의 기능이 제약되어 운영면에서 비효율적입니다."}}}
{"Question_Number": "Q240", "Question_Description": "한 회사는 이전에 데이터 웨어하우스 솔루션을 AWS로 마이그레이션했습니다. 이 회사는 AWS Direct Connect도 보유하고 있습니다. 본사 사용자는 시각화 도구를 통해 데이터 웨어하우스를 쿼리합니다. 데이터 웨어하우스에서 반환되는 쿼리 결과의 평균 크기는 50MB이며, 시각화 도구가 전송하는 각 웹페이지는 약 500KB입니다. 데이터 웨어하우스가 반환하는 결과 세트는 캐싱되지 않습니다. 이 회사에 가장 낮은 데이터 전송(egress) 비용을 제공하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["데이터 웨어하우스", "AWS Direct Connect", "시각화 도구", "데이터 전송 비용", "동일 리전", "최소 egress 비용"], "Terms": ["AWS Direct Connect", "On premises", "Data warehouse", "Visualization tool", "Internet egress", "AWS Region", "Egress cost"], "Commentary": "대규모 쿼리 결과(50MB)는 AWS 내부 트래픽으로 처리하고, 외부로 나가는 트래픽을 최소화해야 egress 비용을 줄일 수 있습니다. 시각화 도구와 데이터 웨어하우스를 동일 리전에 두고, Direct Connect를 사용하면 웹페이지 크기만큼만 외부로 전송되어 가장 낮은 비용을 달성합니다.", "Selections": {"SelectA": {"Select": "시각화 도구를 온프레미스에 배포하고, 인터넷을 통해 직접 데이터 웨어하우스를 쿼리합니다.", "Commentary": "50MB 쿼리 결과가 인터넷으로 매번 전송되어 egress 비용이 매우 높아집니다."}, "SelectB": {"Select": "시각화 도구를 데이터 웨어하우스와 동일한 AWS Region에 배포하고, 인터넷으로 접속합니다.", "Commentary": "같은 리전에 있지만 인터넷을 통해 결과를 가져오므로 여전히 데이터 전송 egress 비용이 발생합니다."}, "SelectC": {"Select": "시각화 도구를 온프레미스에 배포하고, 같은 AWS Region에 있는 Direct Connect 연결을 사용해 데이터 웨어하우스를 쿼리합니다.", "Commentary": "쿼리 결과(50MB)를 온프레미스로 전송하므로 egress 비용이 크게 발생합니다."}, "SelectD": {"Select": "시각화 도구를 데이터 웨어하우스와 동일한 AWS Region에 배포하고, 동일 리전의 Direct Connect 위치를 통해 접속합니다.", "Commentary": "큰 쿼리 결과는 내부 트래픽으로 처리되고, 외부로는 웹페이지(500KB)만 전송되어 egress 비용이 최소화됩니다."}}}
{"Question_Number": "Q241", "Question_Description": "한 온라인 학습 회사가 AWS Cloud로 마이그레이션을 진행하려고 합니다. 해당 회사는 학생 기록을 PostgreSQL 데이터베이스에 보관하고 있으며, 여러 AWS Region에 걸쳐 데이터가 항상 온라인 상태로 유지되어야 합니다. 또한 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["다중 리전", "항상 온라인", "운영 오버헤드 최소화", "Amazon RDS for PostgreSQL", "Read Replica"], "Terms": ["PostgreSQL", "AWS Cloud", "Amazon RDS for PostgreSQL", "Multi-AZ", "read replica", "DB snapshot", "Amazon EC2", "운영 오버헤드"], "Commentary": "이 문제는 여러 AWS Region에서 동시 가용성을 보장하고 운영 오버헤드를 최소화하는 RDS 구성을 찾는 것입니다. Multi-AZ는 동일 리전 내 고가용성일 뿐 다중 리전 가용성을 보장하지 않습니다. Cross-Region Read Replica를 활용하면 별도 Region에 대한 읽기 복제를 통해 데이터를 항상 온라인 상태로 유지할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스에서 PostgreSQL 클러스터를 운영합니다.", "Commentary": "EC2 기반 클러스터 구성은 직접 서버와 복제를 관리해야 하므로 운영 오버헤드가 커집니다."}, "SelectB": {"Select": "Amazon RDS for PostgreSQL에서 Multi-AZ 기능을 활성화합니다.", "Commentary": "Multi-AZ는 동일 리전 내에서만 장애 조치가 가능하므로 다중 리전 가용성을 제공하지 못합니다."}, "SelectC": {"Select": "Amazon RDS for PostgreSQL 인스턴스로 마이그레이션 후 다른 Region에 Read Replica를 생성합니다.", "Commentary": "Cross-Region Read Replica를 통해 다른 Region에서도 읽기 트래픽을 처리하고, 실시간에 가까운 복제를 유지하므로 다중 리전 가용성과 낮은 운영 오버헤드를 달성합니다."}, "SelectD": {"Select": "Amazon RDS for PostgreSQL 인스턴스로 마이그레이션 후 다른 Region으로 DB 스냅샷을 복사합니다.", "Commentary": "스냅샷은 주기적 백업이므로 실시간 동기화가 불가능하고, 다중 Region에서 즉각적인 온라인 가용성을 만족시키지 못합니다."}}}
{"Question_Number": "Q242", "Question_Description": "한 회사가 AWS에서 7개의 Amazon EC2 인스턴스로 웹 애플리케이션을 호스팅하고 있습니다. 이 회사는 DNS query에 대해 모든 healthy Amazon EC2 인스턴스의 IP 주소가 반환되길 요구합니다. 어떤 Routing Policy를 사용해야 이 요구사항을 충족할 수 있습니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["DNS query", "IP 주소 반환", "Amazon EC2", "healthy 인스턴스", "Multivalue routing policy"], "Terms": ["Amazon Route 53", "Multivalue routing policy", "Simple routing policy", "Latency routing policy", "Geolocation routing policy", "DNS", "EC2 instances", "IP addresses"], "Commentary": "이 문제는 DNS query에 대해 여러 개의 healthy Amazon EC2 인스턴스 IP 주소를 동시에 반환하는 방법을 묻습니다. Multivalue routing policy는 여러 IP 주소를 무작위 순서로 반환하여 트래픽을 분산시키므로, 고가용성과 분산이 필요한 시나리오에 적합합니다.", "Selections": {"SelectA": {"Select": "Simple routing policy", "Commentary": "단일 IP 주소만 반환하므로 모든 healthy 인스턴스 IP 주소를 같이 제공하지 못해 조건에 부합하지 않습니다."}, "SelectB": {"Select": "Latency routing policy", "Commentary": "지연 시간이 가장 낮은 리전을 기반으로 라우팅하며, 모든 IP 주소를 반환한다는 요구사항과는 맞지 않습니다."}, "SelectC": {"Select": "Multivalue routing policy", "Commentary": "여러 IP 주소를 동시에 반환하며, healthy 상태만 확인해 자동 분산이 가능해 요구사항에 가장 적합합니다."}, "SelectD": {"Select": "Geolocation routing policy", "Commentary": "사용자의 지리적 위치를 기반으로 라우팅하며, 모든 healthy 인스턴스의 IP 주소를 반환하려는 목적과 다릅니다."}}}
{"Question_Number": "Q243", "Question_Description": "한 의료 연구소에서 새로운 연구와 관련된 데이터를 생성합니다. 연구소는 전국에 위치한 온프레미스 파일 기반 애플리케이션을 사용하는 여러 클리닉에게 최소 지연으로 데이터를 제공하고자 합니다. 데이터 파일은 각 클리닉에 대해 read-only 권한이 부여된 Amazon S3 버킷에 저장되어 있습니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 추천해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["의료 연구소", "최소 지연", "Amazon S3", "온프레미스 파일 기반 애플리케이션", "read-only 권한"], "Terms": ["AWS Storage Gateway", "File Gateway", "Volume Gateway", "AWS DataSync", "Amazon EFS", "Amazon S3"], "Commentary": "이 문제는 전국적으로 분산된 클리닉에서 S3 데이터를 파일 형태로 최소 지연으로 이용하고자 할 때, 어떤 AWS 서비스를 사용해 효율적인 액세스를 제공할 수 있는지를 묻습니다. File Gateway를 사용하면 온프레미스에 가상 어플라이언스를 배포하여 장비와 S3 간의 통신을 투명하게 처리하므로, 클리닉들은 파일 기반 애플리케이션 환경에서 간편하고 빠르게 데이터를 읽을 수 있습니다.", "Selections": {"SelectA": {"Select": "각 클리닉의 온프레미스 환경에 AWS Storage Gateway file gateway를 가상 머신(VM)으로 배포합니다.", "Commentary": "AWS Storage Gateway file gateway를 배포하면 S3 버킷의 파일을 온프레미스에 캐싱하여 빠르고 간편하게 접근할 수 있어 최소 지연을 달성하고 read-only 설정을 유지하기 쉽습니다."}, "SelectB": {"Select": "AWS DataSync를 사용하여 파일을 각 클리닉의 온프레미스 애플리케이션으로 마이그레이션합니다.", "Commentary": "DataSync는 대용량 데이터를 신속하게 옮기는 데 유용하지만, 지속적으로 파일 기반 접근을 해야 하는 이 상황에서는 매번 데이터를 옮겨야 하므로 관리가 복잡해집니다."}, "SelectC": {"Select": "각 클리닉의 온프레미스 환경에 AWS Storage Gateway volume gateway를 가상 머신(VM)으로 배포합니다.", "Commentary": "Volume Gateway는 블록 스토리지 기반으로 동작하므로 파일 기반 애플리케이션과의 직접 연동에 적합하지 않아 요구사항에 부적절합니다."}, "SelectD": {"Select": "각 클리닉의 온프레미스 서버에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 연결합니다.", "Commentary": "EFS는 주로 VPC 내에서 사용하며, 온프레미스 환경에서의 직접 연결 시 VPN 등 추가 구성이 필요하여 지연과 구현 복잡도가 증가할 수 있습니다."}}}
{"Question_Number": "Q244", "Question_Description": "회사는 단일 Amazon EC2 인스턴스에서 웹 서버와 데이터베이스 소프트웨어를 모두 구동하는 콘텐츠 관리 시스템을 사용 중입니다. 이 회사는 웹사이트 플랫폼을 고가용성으로 구성해야 하며, 사용자 수요에 맞춰 확장 가능하게 만들어야 합니다. 이를 위해 솔루션스 아키텍트는 어떤 구성을 제안해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["고가용성", "확장성", "Aurora", "AMI", "Auto Scaling", "ALB"], "Terms": ["Amazon EC2", "Amazon RDS", "Amazon Aurora", "Read Replica", "Amazon Machine Image (AMI)", "Application Load Balancer (ALB)", "Auto Scaling group", "Amazon S3"], "Commentary": "이 문제는 단일 EC2 인스턴스에 웹 서버와 DB를 동시 운영 중인 환경을 고가용성과 확장성 있는 구조로 전환하는 요구사항입니다. DB를 Aurora로 분리하고, 다중 AZ에서 ALB와 Auto Scaling을 구성해 장애나 트래픽 증가에도 유연히 대응해야 합니다.", "Selections": {"SelectA": {"Select": "데이터베이스를 Amazon RDS로 이전하고 자동 백업을 활성화합니다. 동일한 가용 영역에 수동으로 다른 EC2 인스턴스를 생성합니다. Application Load Balancer를 구성하고 두 인스턴스를 대상으로 설정합니다.", "Commentary": "하나의 AZ만 사용해 가용성 측면에서 부족하며, 확장 시에도 다중 AZ 구성이 없어 고가용성을 충분히 달성하기 어렵습니다."}, "SelectB": {"Select": "데이터베이스를 Amazon Aurora 인스턴스로 마이그레이션하고, 기존 EC2 인스턴스와 동일한 가용 영역에 리드 레플리카를 둡니다. 동일한 가용 영역에 수동으로 다른 EC2 인스턴스를 생성합니다. Application Load Balancer를 구성하고 두 EC2 인스턴스를 대상으로 설정합니다.", "Commentary": "DB를 Aurora로 이전하더라도 같은 AZ에만 리드 레플리카를 두면 고가용성을 확보하기 어렵고, EC2 확장 역시 수동으로 관리해야 하므로 요구사항을 완벽히 충족하지 못합니다."}, "SelectC": {"Select": "데이터베이스를 Amazon Aurora로 이전하고, 다른 가용 영역에 리드 레플리카를 둡니다. 기존 EC2 인스턴스로부터 Amazon Machine Image(AMI)를 생성합니다. 두 개의 가용 영역에 Application Load Balancer를 구성합니다. 이 AMI를 사용하는 Auto Scaling group을 두 개의 AZ에 걸쳐 배치합니다.", "Commentary": "DB를 다중 AZ Aurora 배포로 구성해 장애 대응력이 높아지고, ALB와 Auto Scaling group으로 웹 서버 레이어도 자동화하며 트래픽 변화에 유연하게 대응 가능합니다. 고가용성과 확장성 요구사항을 모두 충족하므로 정답입니다."}, "SelectD": {"Select": "별도의 EC2 인스턴스에 데이터베이스를 이전하고, Amazon S3로 백업을 스케줄링합니다. 기존 EC2 인스턴스로부터 Amazon Machine Image(AMI)를 생성합니다. 두 개의 가용 영역에 Application Load Balancer를 구성합니다. 이 AMI를 사용하는 Auto Scaling group을 두 개의 AZ에 걸쳐 배치합니다.", "Commentary": "DB를 여전히 EC2에 직접 운영하고 있으므로 전문 DB 관리 서비스인 RDS나 Aurora 대비 관리 부담이 크고 확장성도 낮습니다. 고가용성을 위한 다중 AZ Aurora 구성보다 부족합니다."}}}
{"Question_Number": "Q245", "Question_Description": "한 회사가 AWS에서 애플리케이션을 출시하려고 합니다. 이 애플리케이션은 Application Load Balancer(ALB)를 사용하여 단일 target group에 있는 최소 두 개의 Amazon EC2 인스턴스로 트래픽을 라우팅합니다. 인스턴스들은 각각의 환경에 대해 Auto Scaling group에 속해 있습니다. 회사는 개발 환경과 프로덕션 환경이 필요합니다. 프로덕션 환경은 높은 트래픽이 발생하는 기간이 있을 예정입니다. 개발 환경을 가장 비용 효율적으로 구성하려면 어떤 솔루션을 사용해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["개발 환경", "프로덕션 환경", "비용 효율", "Application Load Balancer", "Amazon EC2", "Auto Scaling group"], "Terms": ["Application Load Balancer(ALB)", "Amazon EC2", "Auto Scaling group", "target group"], "Commentary": "비용을 절감하면서도 개발 환경의 기능을 유지하려면, 개발 환경의 Auto Scaling group에서 인스턴스 사용량을 줄여 필요한 최소 규모만 유지하는 것이 핵심입니다.", "Selections": {"SelectA": {"Select": "개발 환경의 target group을 재구성하여 하나의 Amazon EC2 인스턴스만 target으로 지정합니다.", "Commentary": "최소 두 개 인스턴스를 사용하는 구조 요구사항을 침해할 수 있고, 장애 허용력을 낮추기 때문에 권장되지 않습니다."}, "SelectB": {"Select": "ALB 로드 밸런싱 알고리즘을 'least outstanding requests'로 변경합니다.", "Commentary": "로드 밸런싱 알고리즘을 변경해도 인스턴스 비용이 크게 줄지 않아 비용 최적화 효과가 미미합니다."}, "SelectC": {"Select": "두 환경 모두에서 Amazon EC2 인스턴스의 크기를 줄입니다.", "Commentary": "프로덕션 환경에도 영향을 주어 성능 저하 우려가 있어, 확대 트래픽을 감당하기 어려울 수 있습니다."}, "SelectD": {"Select": "개발 환경의 Auto Scaling group에서 최대 Amazon EC2 인스턴스 수를 줄입니다.", "Commentary": "개발 환경은 낮은 트래픽을 예상하므로, 인스턴스 수를 제한해 불필요한 비용을 절감하며 필요한 기능은 유지할 수 있는 가장 효과적인 방법입니다."}}}
{"Question_Number": "Q246", "Question_Description": "한 회사가 여러 가용 영역(Availability Zone)에 있는 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있습니다. 이 EC2 인스턴스들은 사설 서브넷에 위치해 있습니다. 솔루션스 아키텍트가 인터넷 연결형(Application Load Balancer, ALB)을 구현하고, 대상 그룹으로 해당 EC2 인스턴스들을 지정했지만 인터넷에서 들어오는 트래픽이 EC2 인스턴스에 도달하지 않습니다. 이러한 문제를 해결하기 위해 아키텍처를 어떻게 재구성해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["인터넷 연결형 ALB", "사설 서브넷", "공용 서브넷", "라우팅", "보안 그룹"], "Terms": ["Internet-facing Application Load Balancer(ALB)", "Amazon EC2", "NAT gateway", "Network Load Balancer(NLB)", "Security Group", "Subnet", "Internet Gateway(IGW)", "Route Table"], "Commentary": "이 문제는 ALB를 인터넷에서 직접 연결하기 위해, ALB가 위치한 서브넷이 인터넷 게이트웨이에 연결된 공용 서브넷이어야 함을 묻고 있습니다. EC2 인스턴스는 사설 서브넷에 위치하고, ALB가 공용 서브넷에서 인터넷 트래픽을 수신하여 사설 서브넷의 인스턴스로 전달해야 동작합니다. 따라서 ALB를 공용 서브넷에 배치하고 사설 서브넷과의 로컬 라우팅을 통해 트래픽을 전달하는 구성이 정답입니다.", "Selections": {"SelectA": {"Select": "ALB를 Network Load Balancer로 교체하고, 공용 서브넷에 NAT gateway를 구성하여 인터넷 트래픽을 허용합니다.", "Commentary": "NAT gateway는 인스턴스가 인터넷에 나가는 용도로 사용하며, 수신 트래픽을 허용하는 역할에는 적합하지 않아 문제 해결에 맞지 않습니다."}, "SelectB": {"Select": "EC2 인스턴스들을 공용 서브넷으로 이동하고, EC2 인스턴스들의 보안 그룹에 0.0.0.0/0으로의 아웃바운드 트래픽 허용 규칙을 추가합니다.", "Commentary": "인스턴스를 공용 서브넷으로 직접 노출하면 보안 위험이 커지고, ALB를 통한 트래픽 분산 이점이 줄어듭니다."}, "SelectC": {"Select": "EC2 인스턴스들이 있는 서브넷의 라우트 테이블을 수정하여 0.0.0.0/0 트래픽을 인터넷 게이트웨이로 보내고, 보안 그룹에 0.0.0.0/0 아웃바운드 트래픽 허용 규칙을 추가합니다.", "Commentary": "사설 서브넷에서 직접 인터넷 게이트웨이로 라우팅하면 결국 공용 서브넷처럼 되어버려 사설 서브넷의 이점을 잃습니다."}, "SelectD": {"Select": "각 가용 영역마다 공용 서브넷을 생성하고, 해당 서브넷들을 ALB에 매핑합니다. 공용 서브넷의 라우트 테이블을 사설 서브넷으로 라우팅하도록 업데이트합니다.", "Commentary": "인터넷 연결형 ALB는 공용 서브넷에서 동작해야 하며, 사설 서브넷에 있는 EC2 인스턴스까지 로컬 라우팅으로 연결해 주는 구조가 올바른 해결책입니다."}}}
{"Question_Number": "Q247", "Question_Description": "한 회사가 Amazon RDS for MySQL에 데이터베이스를 배포했습니다. 거래량 증가로 인해 DB 인스턴스에서 읽기 응답이 지연되고 있으며, 데이터베이스 지원 팀은 성능 개선을 위해 Read Replica 추가를 권장하고 있습니다. 이 변경을 구현하기 전에 솔루션스 아키텍트가 취해야 할 조치로 옳은 조합은 무엇일까요? (두 개를 선택하십시오.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon RDS for MySQL", "Read Replica", "자동 백업", "binlog replication", "backup retention"], "Terms": ["Amazon RDS for MySQL", "Read replica", "자동 백업(Backup Retention)", "binlog replication", "소스 DB 인스턴스", "장기 실행 트랜잭션"], "Commentary": "이 문제는 Amazon RDS for MySQL에서 읽기 성능을 확장하기 위해 Read Replica를 설정하기 전에 필요한 조건들을 묻습니다. Read Replica는 MySQL 엔진의 복제(binlog)를 사용하여 데이터를 복제하므로 소스 인스턴스에서 binlog를 활성화해야 합니다. 또한 Read Replica 생성을 위해서는 백업 유지를 위해 Backup Retention Period가 0이 아닌 값으로 설정되어 있어야 합니다.", "Selections": {"SelectA": {"Select": "RDS 기본 노드에서 binlog replication을 활성화합니다.", "Commentary": "MySQL의 읽기 복제는 binlog를 사용하므로 소스 DB 인스턴스에서 binlog가 활성화되어 있어야 Read Replica 생성이 가능합니다."}, "SelectB": {"Select": "소스 DB 인스턴스에 대해 장애 조치 우선순위를 지정합니다.", "Commentary": "Multi-AZ 배포에서 장애 조치(Failover)를 제어하는 옵션이며, Read Replica 구성과 직접적인 연관은 없습니다."}, "SelectC": {"Select": "소스 DB 인스턴스에서 장기 실행 트랜잭션이 완료되도록 합니다.", "Commentary": "장기 실행 트랜잭션이 종료되면 성능에 유리할 수 있지만, Read Replica 생성을 위해 반드시 필요한 사전 조건은 아닙니다."}, "SelectD": {"Select": "글로벌 테이블을 생성하고 테이블을 사용할 AWS 리전을 지정합니다.", "Commentary": "이는 DynamoDB 글로벌 테이블에 관한 설정으로, Amazon RDS MySQL의 Read Replica 구성과 무관합니다."}, "SelectE": {"Select": "소스 인스턴스에서 자동 백업을 활성화하고 백업 보관 기간을 0이 아닌 값으로 설정합니다.", "Commentary": "Read Replica를 만들려면 소스 DB 인스턴스에 자동 백업이 활성화되어야 하므로 백업 보관 기간(Backup Retention Period)을 0이 아닌 값으로 설정해야 합니다."}}}
{"Question_Number": "Q248", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 분석 소프트웨어를 실행하고 있습니다. 이 소프트웨어는 Amazon S3에 업로드된 데이터를 처리하기 위해 사용자로부터 작업 요청을 받습니다. 사용자들은 일부 제출된 데이터가 처리되지 않는다고 보고합니다. Amazon CloudWatch 모니터링 결과, EC2 인스턴스의 CPU 사용률이 100% 근처에서 지속적으로 유지되고 있습니다. 회사는 시스템 성능을 개선하고, 사용자 로드에 따라 시스템을 확장하기를 원합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.2"], "Keywords": ["시스템 성능 개선", "사용자 로드 기반 확장", "분석 소프트웨어", "Amazon EC2", "Amazon S3", "Amazon SQS", "EC2 Auto Scaling"], "Terms": ["Amazon EC2", "Amazon S3", "Amazon CloudWatch", "Application Load Balancer", "S3 VPC Endpoint", "EC2 Auto Scaling", "Amazon Simple Queue Service (Amazon SQS)"], "Commentary": "이 문제는 EC2 인스턴스의 높은 CPU 부하로 인해 일부 작업 요청이 처리되지 않는 상황에서, 사용자 로드에 따라 확장 가능한 아키텍처를 제시해야 합니다. 정답인 Amazon SQS를 사용하면 요청을 대기열에 넣고, EC2 Auto Scaling 그룹을 대기열 크기에 따라 자동으로 확장함으로써 과부하 없이 작업을 처리할 수 있습니다. 또한 작업과 인스턴스 간 결합도를 낮추어 더욱 유연하고 성능 좋은 구조를 만들 수 있습니다.", "Selections": {"SelectA": {"Select": "인스턴스를 복제하고, 모든 인스턴스를 Application Load Balancer 뒤에 두십시오.", "Commentary": "단순히 인스턴스를 복제해서 ALB 뒤에 두더라도 CPU 사용률이 계속 100%면 병목이 해소되지 않고, 로드 밸런싱만으로는 작업 큐잉 문제를 해결할 수 없습니다."}, "SelectB": {"Select": "Amazon S3에 대한 S3 VPC 엔드포인트를 생성하고, 소프트웨어를 해당 엔드포인트를 참조하도록 업데이트하십시오.", "Commentary": "S3 접근 경로를 최적화하는 방법이지만, 이 문제의 핵심인 처리량 부족과 확장 이슈는 해결되지 않습니다."}, "SelectC": {"Select": "EC2 인스턴스를 중지하고, CPU가 더 강력하고 메모리가 더 많은 인스턴스 유형으로 변경한 후 인스턴스를 재시작하십시오.", "Commentary": "인스턴스 타입을 올리는 것은 일시적인 해결책이나, 계속 증가하는 사용자 로드에 맞춰 자동 확장하기에는 한계가 있으며 비용 효율도 떨어집니다."}, "SelectD": {"Select": "수신되는 요청을 Amazon SQS로 라우팅하십시오. 대기열 크기를 기준으로 EC2 Auto Scaling 그룹을 구성하십시오. 소프트웨어를 대기열에서 읽도록 업데이트하십시오.", "Commentary": "대기열을 사용해 작업을 비동기로 처리하고, 대기열 크기에 비례해 인스턴스를 자동 확장함으로써 성능과 확장성을 모두 확보할 수 있는 최적의 솔루션입니다."}}}
{"Question_Number": "Q249", "Question_Description": "한 회사가 AWS Cloud에 호스팅되는 미디어 애플리케이션을 위해 공유 스토리지 솔루션을 구현하려고 합니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스해야 하며, 솔루션은 완전관리형이어야 합니다. 이러한 요구사항을 충족하는 AWS 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["공유 스토리지", "SMB 클라이언트", "완전관리형", "Amazon FSx for Windows File Server"], "Terms": ["AWS Storage Gateway volume gateway", "AWS Storage Gateway tape gateway", "Amazon EC2 Windows", "Amazon FSx for Windows File Server", "SMB"], "Commentary": "이 문제는 SMB 프로토콜을 사용하는 애플리케이션 환경에 대해 완전관리형 공유 스토리지 솔루션을 선정하는 것이 핵심입니다. Amazon FSx for Windows File Server는 Windows 환경과 SMB 접근을 모두 지원하며 완전관리형 서비스로 운영 부담을 낮춥니다.", "Selections": {"SelectA": {"Select": "AWS Storage Gateway volume gateway를 생성하고, 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 생성한 뒤 애플리케이션 서버를 연결합니다.", "Commentary": "Storage Gateway volume gateway는 온프레미스 및 클라우드 하이브리드 시나리오에 유용하지만, 완전관리형 SMB 파일 스토어로서는 적합하지 않습니다."}, "SelectB": {"Select": "AWS Storage Gateway tape gateway를 생성하고, 테이프를 Amazon S3로 설정합니다. 애플리케이션 서버를 tape gateway에 연결합니다.", "Commentary": "Tape gateway는 백업 및 아카이브 목적에 특화된 형태로, 직접 SMB 프로토콜을 제공하지 않습니다."}, "SelectC": {"Select": "Amazon EC2 Windows 인스턴스를 생성합니다. 해당 인스턴스에 Windows file share 역할을 설치 및 구성하고, 애플리케이션 서버를 공유에 연결합니다.", "Commentary": "EC2에 직접 Windows 파일 공유를 설치하면 관리 오버헤드와 유지보수 비용이 올라가 완전관리형 솔루션이 아닙니다."}, "SelectD": {"Select": "Amazon FSx for Windows File Server 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결한 뒤, 애플리케이션 서버를 해당 파일 시스템에 연결합니다.", "Commentary": "FSx for Windows File Server는 SMB 프로토콜과 Windows 파일 서비스 기능을 완전관리형으로 제공하여 요구사항을 충족하는 가장 적합한 솔루션입니다."}}}
{"Question_Number": "Q250", "Question_Description": "한 회사의 보안 팀이 VPC Flow Logs에 네트워크 트래픽을 기록할 것을 요청했습니다. 이 로그는 90일 동안 자주 액세스되고, 이후에는 간헐적으로 액세스됩니다. 이 요구사항을 충족하기 위해 로그를 구성할 때 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["VPC Flow Logs", "90일", "간헐적 액세스", "비용 최적화", "S3 Lifecycle"], "Terms": ["VPC Flow Logs", "Amazon CloudWatch", "Amazon Kinesis", "AWS CloudTrail", "Amazon S3", "S3 Intelligent-Tiering", "S3 Lifecycle policy", "S3 Standard-Infrequent Access (S3 Standard-IA)"], "Commentary": "이 문제는 90일간 자주 조회되는 로그를 이후에 간헐적으로 조회하면서도 비용을 절감할 수 있도록 저장하는 방법을 묻습니다. Amazon S3에 저장하고 S3 Lifecycle 정책을 통해 S3 Standard-IA로 전환하면 보존 기간 후에도 필요한 때에만 저비용으로 접근 가능해집니다.", "Selections": {"SelectA": {"Select": "Amazon CloudWatch를 대상으로 사용합니다. CloudWatch 로그 그룹을 설정하여 90일 만료를 적용합니다.", "Commentary": "CloudWatch 로그 그룹에 만료 기간을 설정할 수 있지만, 장기 보관 및 간헐적 액세스 측면에서 비용 최적화가 충분치 않습니다."}, "SelectB": {"Select": "Amazon Kinesis를 대상으로 사용합니다. Kinesis 스트림을 구성하여 항상 로그를 90일 동안 보관하도록 설정합니다.", "Commentary": "Kinesis는 실시간 데이터 스트리밍에 적합하지만, 장기적으로 로그를 보관하고 간헐적으로 조회하기에는 효율적이지 않습니다."}, "SelectC": {"Select": "AWS CloudTrail을 대상으로 사용합니다. CloudTrail에서 Amazon S3 버킷에 저장하도록 설정하고, S3 Intelligent-Tiering을 활성화합니다.", "Commentary": "CloudTrail은 API 호출 이력을 추적하는 서비스이므로 VPC Flow Logs와는 용도가 다릅니다. 요구사항에 직접 부합하지 않습니다."}, "SelectD": {"Select": "Amazon S3를 대상으로 사용합니다. S3 Lifecycle 정책을 활성화하여 90일 후에 로그를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.", "Commentary": "S3에 로그를 저장하고 90일 후 Lifecycle 정책으로 S3 Standard-IA로 전환하면 자주 조회되지 않는 기간에도 비용을 절감하며 간헐적으로 필요한 접근을 지원합니다."}}}
{"Question_Number": "Q251", "Question_Description": "Amazon EC2 인스턴스가 새로운 VPC의 private subnet에 위치해 있습니다. 이 subnet은 아웃바운드 인터넷 액세스가 없지만, 해당 EC2 인스턴스는 외부 벤더로부터 매월 보안 업데이트를 다운로드해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon EC2 인스턴스", "private subnet", "NAT gateway", "public subnet", "internet gateway", "월간 보안 업데이트"], "Terms": ["VPC", "private subnet", "public subnet", "NAT gateway", "NAT instance", "internet gateway", "route table"], "Commentary": "private subnet에서 외부로 데이터를 전송하기 위해서는 NAT 구성과 internet gateway가 필요합니다. 일반적으로 public subnet에 NAT gateway를 두고, private subnet이 해당 NAT gateway를 통해 인터넷에 접근하도록 구성하는 것이 표준적이고 안전합니다.", "Selections": {"SelectA": {"Select": "internet gateway를 VPC에 연결하고, private subnet의 route table을 internet gateway로 기본 라우팅하도록 구성합니다.", "Commentary": "단순히 internet gateway만 붙여서는 private subnet이 직접 인터넷에 나갈 수 없습니다. NAT 역할이 없으므로 요구사항을 충족하기 어렵습니다."}, "SelectB": {"Select": "public subnet에 NAT gateway를 생성하고, private subnet의 route table을 NAT gateway로 기본 라우팅하도록 구성합니다.", "Commentary": "표준 솔루션으로, NAT gateway가 외부로의 트래픽을 중계하고 internet gateway와 연동되어 private subnet에서 안전하게 아웃바운드 연결을 제공합니다."}, "SelectC": {"Select": "동일한 subnet(EC2가 위치한)에 NAT instance를 생성하고, private subnet의 route table을 NAT instance로 기본 라우팅하도록 구성합니다.", "Commentary": "NAT instance가 private subnet 안에 있으면 자체 인터넷 연결을 확보하기 어렵고, 관리 복잡성이 증가해 적절하지 않습니다."}, "SelectD": {"Select": "internet gateway를 VPC에 연결하고, 동일한 subnet(EC2가 위치한)에 NAT instance를 생성합니다. private subnet의 route table을 internet gateway로 기본 라우팅하도록 구성합니다.", "Commentary": "NAT instance와 internet gateway를 같은 private subnet에 배치해도 올바른 NAT 구조가 형성되지 않으며, 라우팅이 맞지 않아 목적을 달성하기 어렵습니다."}}}
{"Question_Number": "Q252", "Question_Description": "한 솔루션스 아키텍트가 클라이언트 케이스 파일을 저장하기 위한 시스템을 설계해야 합니다. 이 파일들은 회사의 핵심 자산으로서 매우 중요하며, 시간이 지남에 따라 파일의 수가 증가할 것입니다. 이 파일들은 Amazon EC2 인스턴스에서 동작하는 여러 애플리케이션 서버에서 동시에 액세스할 수 있어야 합니다. 또한 솔루션은 자체 내장된 내결함성을 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["클라이언트 케이스 파일", "동시 액세스", "자동 확장", "내결함성"], "Terms": ["Amazon EFS", "Amazon EC2", "Amazon EBS", "Amazon S3 Glacier Deep Archive", "AWS Backup"], "Commentary": "이 문제는 중요한 파일을 여러 Amazon EC2 인스턴스에서 동시에 접근해야 하며, 파일 수가 지속적으로 증가하는 상황에 대한 스토리지 선택을 묻습니다. Amazon EFS는 완전관리형 파일 시스템으로 자동 확장과 다중 AZ 내결함성을 제공해 운영 복잡성을 줄이고 고가용성을 보장하므로 요구사항을 충족하는 최적의 해법입니다.", "Selections": {"SelectA": {"Select": "Amazon Elastic File System (Amazon EFS)", "Commentary": "NFS 기반 공유 스토리지로 동시 액세스와 자동 확장, 내결함성을 모두 제공하므로 요구사항에 부합하는 정답입니다."}, "SelectB": {"Select": "Amazon Elastic Block Store (Amazon EBS)", "Commentary": "단일 인스턴스 전용 볼륨이 기본이며, 자동 확장이 어렵고 다중 인스턴스 동시 액세스가 제한적입니다."}, "SelectC": {"Select": "Amazon S3 Glacier Deep Archive", "Commentary": "장기 보관 및 아카이브용이며 즉시 액세스가 필요한 운영 환경에 적합하지 않습니다."}, "SelectD": {"Select": "AWS Backup", "Commentary": "백업 및 복구 전용 서비스로, 실시간 파일 공유나 내결함성 파일시스템으로 활용하기 어렵습니다."}}}
{"Question_Number": "Q253", "Question_Description": "한 Solutions Architect가 두 개의 IAM Policy(Policy1과 Policy2)를 생성했습니다. 두 Policy는 모두 하나의 IAM Group에 연결되어 있습니다. 한 Cloud Engineer가 새로 IAM User로 추가되어 해당 IAM Group에 속해 있습니다. 이 Cloud Engineer가 수행할 수 있는 작업은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["IAM Policy", "IAM Group", "Amazon EC2 인스턴스 삭제", "CloudWatch Logs", "디렉터리 삭제"], "Terms": ["IAM Policy", "IAM Group", "IAM User", "Amazon EC2", "CloudWatch Logs", "ds:Delete"], "Commentary": "이 문제는 IAM Policy를 통해 어떤 작업이 허용되는지 확인하는 문제입니다. Policy1이 ec2:* 권한을 포함하여 Amazon EC2 리소스에 대한 완전한 액세스를 허용하므로, Cloud Engineer는 Amazon EC2 인스턴스를 삭제할 수 있습니다. 다른 작업들은 IAM, Directory Service, CloudWatch Logs 관련 권한이 제한되어 있어 수행이 불가능합니다.", "Selections": {"SelectA": {"Select": "Deleting IAM users", "Commentary": "IAM User 관련 권한은 get과 list 권한만 있으므로 삭제 권한은 허용되지 않습니다."}, "SelectB": {"Select": "Deleting directories", "Commentary": "ds:DeleteDirectory에 대한 권한이 명시적으로 거부(deny)되어 있으므로 디렉터리 삭제는 불가능합니다."}, "SelectC": {"Select": "Deleting Amazon EC2 instances", "Commentary": "ec2:* 권한이 허용되어 Amazon EC2 인스턴스 삭제가 가능합니다."}, "SelectD": {"Select": "Deleting logs from Amazon CloudWatch Logs", "Commentary": "로그에 대해서는 get과 describe 권한만 주어졌으므로 삭제 권한이 없습니다."}}}
{"Question_Number": "Q254", "Question_Description": "한 회사가 세 계층으로 구성된 애플리케이션을 VPC로 이전한 후 이를 검토하고 있습니다. 보안 팀은 애플리케이션 계층 간 Amazon EC2 보안 그룹 인바운드와 아웃바운드 규칙이 최소 권한 원칙(least privilege)을 적용하지 않고 있다고 지적했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["VPC", "3티어 애플리케이션", "보안 그룹", "최소 권한 원칙"], "Terms": ["Amazon EC2", "Security Group", "Ingress Rule", "Egress Rule", "Security Group ID", "VPC CIDR", "Subnet CIDR", "Instance ID"], "Commentary": "이 문제는 애플리케이션 계층 간 트래픽을 최소 권한 원칙으로 제한하는 방법을 묻습니다. 보안 그룹 간 통신 시 Security Group ID를 사용하면 필요한 계층 간 트래픽만 허용할 수 있어 보안을 강화합니다.", "Selections": {"SelectA": {"Select": "인스턴스 ID를 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.", "Commentary": "인스턴스별로 규칙을 지정하면 운영이 번거롭고, 확장성도 떨어지므로 최소 권한 구현에 적합하지 않습니다."}, "SelectB": {"Select": "Security Group ID를 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.", "Commentary": "보안 그룹 간의 통신만 허용하므로 필요 최소한의 액세스만 부여할 수 있어 가장 안전하고 유연한 방식입니다."}, "SelectC": {"Select": "VPC CIDR 블록을 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.", "Commentary": "VPC 전체 대역을 허용하면 범위가 너무 넓어 최소 권한 원칙에 어긋납니다."}, "SelectD": {"Select": "서브넷 CIDR 블록을 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.", "Commentary": "서브넷 단위로 허용해도 필요 이상으로 많은 트래픽을 허용하게 되어 최소 권한 규칙을 만족하기 어렵습니다."}}}
{"Question_Number": "Q255", "Question_Description": "한 회사가 전자상거래 체크아웃 워크플로우를 운영하고 있습니다. 이 워크플로우는 주문 정보를 데이터베이스에 저장하고, 결제를 처리하기 위해 별도의 서비스를 호출합니다. 현재 사용자가 결제 화면에서 시간 초과를 겪고 있으며, 사용자가 체크아웃 양식을 다시 제출하면 동일한 거래에 대해 여러 개의 고유 주문이 생성되는 문제가 발생하고 있습니다. 이러한 중복 주문 생성을 어떻게 방지할 수 있도록 워크플로우를 재구성해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["전자상거래", "체크아웃", "중복 주문 방지", "결제 서비스", "데이터베이스", "Amazon SQS FIFO"], "Terms": ["Amazon Kinesis Data Firehose", "AWS CloudTrail", "AWS Lambda", "Amazon Simple Notification Service (Amazon SNS)", "Amazon Simple Queue Service (Amazon SQS) FIFO queue"], "Commentary": "주문 처리와 결제를 분리하여 중복 주문을 방지하려면 메시지 큐를 사용해 느슨하게 결합된 워크플로우로 설계해야 합니다. Amazon SQS FIFO 큐를 이용하면 중복을 방지하고 순서대로 메시지를 처리하여 여러 주문 생성을 막을 수 있습니다.", "Selections": {"SelectA": {"Select": "웹 애플리케이션이 주문 메시지를 Amazon Kinesis Data Firehose로 전송하도록 구성합니다. 결제 서비스가 Kinesis Data Firehose에서 메시지를 가져와 주문을 처리합니다.", "Commentary": "Kinesis Data Firehose는 대량 데이터를 실시간으로 처리하기 위한 서비스이지만, 중복 방지와 메시지 순서 보장에는 적합하지 않습니다."}, "SelectB": {"Select": "AWS CloudTrail에 기록된 애플리케이션 경로 요청을 기반으로 Lambda 함수를 호출하는 규칙을 만듭니다. Lambda가 데이터베이스를 조회하고 결제 서비스를 호출하여 주문 정보를 전달합니다.", "Commentary": "CloudTrail은 API 호출 로깅 서비스로, 주문 중복 방지와 순서 제어를 지원하지 않아 문제 해결에 적합하지 않습니다."}, "SelectC": {"Select": "주문을 데이터베이스에 저장한 후, 주문 번호를 포함한 메시지를 Amazon SNS에 전송합니다. 결제 서비스가 Amazon SNS를 폴링하여 메시지를 가져와 주문을 처리합니다.", "Commentary": "SNS는 주로 게시-구독 모델로 즉시 알림 전달에는 유용하지만 중복 방지나 순서 보장 기능이 부족합니다."}, "SelectD": {"Select": "주문을 데이터베이스에 저장한 후, 주문 번호를 포함하는 메시지를 Amazon SQS FIFO 큐에 전송합니다. 결제 서비스가 메시지를 조회하여 주문을 처리하고, 메시지를 큐에서 삭제합니다.", "Commentary": "FIFO 큐는 메시지를 순서대로 처리하고 중복 전달을 방지합니다. 결제 서비스와 주문 처리를 분리해 중복 주문 문제를 해결하는 최적의 방법입니다."}}}
{"Question_Number": "Q256", "Question_Description": "한 솔루션스 아키텍트가 Amazon S3 bucket을 스토리지로 사용하는 문서 검토 애플리케이션을 구현하려고 합니다. 솔루션은 문서가 실수로 삭제되는 것을 방지하고, 모든 문서 버전을 보존해야 합니다. 또한 사용자가 문서를 다운로드, 수정, 업로드할 수 있어야 합니다. 이러한 요구 사항을 충족하기 위해 어떤 조합의 작업을 수행해야 합니까? (2개를 선택하세요.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["문서 검토", "실수로 삭제 방지", "Versioning", "MFA Delete", "S3 버킷"], "Terms": ["Amazon S3 bucket", "Bucket ACL", "Versioning", "IAM policy", "MFA Delete", "AWS KMS"], "Commentary": "이 문제는 문서가 실수로 삭제되지 않도록 보호하면서 모든 버전을 남겨야 하는 S3 구성 방안을 묻습니다. Versioning은 각각의 변경 이력을 남겨 복원이 가능하게 하며, MFA Delete는 삭제 시 다단계 인증을 요구해 우발적이거나 악의적인 삭제를 방지합니다.", "Selections": {"SelectA": {"Select": "read-only bucket ACL을 활성화합니다.", "Commentary": "문서를 수정하거나 업로드해야 하므로 read-only 구성은 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "버킷에 Versioning을 활성화합니다.", "Commentary": "모든 문서 버전을 보존해 실수로 삭제되더라도 이전 버전을 복원할 수 있어 필수적인 설정입니다."}, "SelectC": {"Select": "버킷에 IAM policy를 연결합니다.", "Commentary": "접근 권한을 세밀하게 제어할 수 있지만, 삭제 방지와 버전 보존을 직접적으로 보장하지 않으므로 핵심 요구사항을 단독으로 해결하진 못합니다."}, "SelectD": {"Select": "버킷에 MFA Delete를 활성화합니다.", "Commentary": "버킷 및 객체 삭제 시 추가 인증 과정을 요구하여 실수 또는 무단 삭제를 예방하므로 Versioning과 함께 매우 효과적인 보호를 제공합니다."}, "SelectE": {"Select": "버킷을 AWS KMS로 암호화합니다.", "Commentary": "암호화는 데이터 보호 측면에 유용하지만, 실수로 인한 삭제 방지나 버전 보존 기능을 제공하지 않으므로 요구사항과 직접적인 연관이 없습니다."}}}
{"Question_Number": "Q257", "Question_Description": "한 회사가 전체 AWS 계정의 모든 애플리케이션에서 발생하는 Amazon EC2 Auto Scaling 이벤트를 보고하는 솔루션을 구축하려 합니다. 회사는 서버리스 솔루션을 통해 EC2 Auto Scaling 상태 데이터를 Amazon S3에 저장해야 합니다. 이후 이 데이터는 Amazon S3에서 거의 실시간으로 대시보드에 반영되어야 합니다. 또한 이 솔루션은 EC2 인스턴스가 시작되는 속도에 영향을 주어서는 안 됩니다. 이러한 요구사항을 충족하기 위해, 데이터를 Amazon S3로 옮기는 가장 적합한 방법은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["EC2 Auto Scaling", "Amazon S3", "서버리스", "실시간 대시보드", "이벤트 스트리밍"], "Terms": ["Amazon CloudWatch metric stream", "Amazon Kinesis Data Firehose", "Amazon EMR", "Amazon EventBridge", "AWS Lambda", "Amazon Kinesis Agent", "EC2 Auto Scaling", "Bootstrap script"], "Commentary": "이 문제는 EC2 Auto Scaling 이벤트 데이터가 EC2 인스턴스 시작 시간을 지연시키지 않으면서도 거의 실시간으로 수집·저장되어야 한다는 점이 핵심입니다. 가장 빠르고 단순한 서버리스 아키텍처로 데이터를 전송하기 위해서는 CloudWatch metric stream과 Kinesis Data Firehose를 사용하는 방법이 적합합니다. 이는 데이터를 직접 스트리밍하여 거의 실시간으로 Amazon S3에 저장하도록 하며, 추가적인 오버헤드가 없어 인스턴스의 시작 시간을 방해하지 않습니다.", "Selections": {"SelectA": {"Select": "Amazon CloudWatch metric stream을 사용해 EC2 Auto Scaling 상태 데이터를 Amazon Kinesis Data Firehose로 전송합니다. 데이터를 Amazon S3에 저장합니다.", "Commentary": "CloudWatch metric stream과 Kinesis Data Firehose를 연계하여 서버리스 방식으로 실시간 이벤트를 S3로 전달하므로, 인스턴스 시작과정에 부하를 주지 않으며 실시간 대시보드 요구를 만족합니다."}, "SelectB": {"Select": "Amazon EMR 클러스터를 시작하여 EC2 Auto Scaling 상태 데이터를 수집하고, Amazon Kinesis Data Firehose로 데이터를 전송해 Amazon S3에 저장합니다.", "Commentary": "EMR은 대규모 데이터 처리를 위한 빅데이터 플랫폼이므로, 실시간 이벤트 중심의 가벼운 데이터 전송에 과도하며 운영 복잡도도 증가합니다."}, "SelectC": {"Select": "Amazon EventBridge 규칙을 생성하여 스케줄에 따라 AWS Lambda 함수를 호출합니다. Lambda 함수에서 EC2 Auto Scaling 상태 데이터를 직접 Amazon S3로 전송하도록 구성합니다.", "Commentary": "스케줄 기반 호출은 이벤트 발생 시점에 맞추어 실시간 처리를 보장하기 어렵고, 거의 실시간 대시보드 요구사항을 충족하기에 부족합니다."}, "SelectD": {"Select": "EC2 인스턴스 시작 시 부트스트랩 스크립트를 사용하여 Amazon Kinesis Agent를 설치합니다. Kinesis Agent가 EC2 Auto Scaling 상태 데이터를 수집해 Amazon Kinesis Data Firehose로 전송하고, S3에 저장합니다.", "Commentary": "각 EC2 인스턴스마다 별도 설정과 설치 과정이 필요하므로 인스턴스 시작 시간을 지연시킬 수 있어 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q258", "Question_Description": "한 회사가 매시간 수백 개의 .csv 파일을 Amazon S3 버킷에 저장하는 애플리케이션을 운영하고 있습니다. 각 파일의 크기는 1GB입니다. 회사는 매번 파일이 업로드될 때마다 해당 파일을 Apache Parquet 형식으로 변환하고, 변환된 파일을 S3 버킷에 저장해야 합니다. 이러한 요구사항을 만족하면서 운영 오버헤드를 최소화할 수 있는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["파일 변환", "Apache Parquet", "Amazon S3", "운영 오버헤드 최소화"], "Terms": ["AWS Lambda", "Apache Spark", "AWS Glue", "ETL job", "Amazon Athena", "AWS Glue Crawler", ".csv 파일", "Parquet 형식"], "Commentary": "이 문제의 핵심은 매시간 대량으로 업로드되는 1GB 크기의 CSV 파일을 자동으로 Parquet 형식으로 변환하면서 운영 부담을 최소화하는 것입니다. AWS Glue ETL job을 활용하면 서버리스 방식으로 확장성과 자동화가 가능하며, Lambda를 통해 업로드 이벤트마다 Glue job을 손쉽게 호출할 수 있어 최소한의 운영 작업으로 요구사항을 충족시킬 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Lambda 함수를 생성하여 .csv 파일을 다운로드하고, 해당 파일을 Parquet 형식으로 변환한 뒤 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 Lambda 함수를 호출합니다.", "Commentary": "Lambda만으로 대용량 파일을 처리하면 메모리, 시간 제한 등 관리가 복잡해져 운영 오버헤드가 증가하므로 가장 적합하지 않습니다."}, "SelectB": {"Select": "Apache Spark 잡을 생성하여 .csv 파일을 읽고 Parquet 형식으로 변환한 뒤 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 Spark 잡을 호출하는 Lambda 함수를 생성합니다.", "Commentary": "Spark 클러스터 운영이 필요해 관리가 번거롭고, 구성도 복잡해져 운영 오버헤드가 높아집니다."}, "SelectC": {"Select": "AWS Glue 테이블과 AWS Glue 크롤러를 만들어 .csv 파일이 있는 S3 버킷을 인식하게 합니다. 주기적으로 Lambda 함수를 호출하여 Amazon Athena로 Glue 테이블을 쿼리한 후, 결과를 Parquet 형식으로 변환해 S3 버킷에 저장합니다.", "Commentary": "주기적 Athena 쿼리 방식을 사용하면 실시간 변환이 어려우며, 관리 대상(크롤러, 쿼리 예약)이 많아져 운영 오버헤드가 증가합니다."}, "SelectD": {"Select": "AWS Glue ETL job을 생성하여 .csv 파일을 Parquet 형식으로 변환하고 결과 파일을 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 ETL job을 호출하는 Lambda 함수를 생성합니다.", "Commentary": "서버리스인 AWS Glue가 확장성과 자동화를 제공하므로 파일 변환 작업과 파이프라인 관리가 간소화되어 운영 오버헤드를 최소화합니다."}}}
{"Question_Number": "Q259", "Question_Description": "한 회사가 Amazon RDS DB 인스턴스에서 실행 중인 모든 데이터베이스에 대하여 새로운 데이터 보존 정책을 도입하려고 합니다. 회사는 매일 백업을 최소 2년간 보존해야 하며, 백업이 일관되고 복원 가능해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 솔루션을 권장해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["RDS DB 인스턴스", "일일 백업", "2년 보존", "일관성", "복원 가능", "AWS Backup"], "Terms": ["AWS Backup", "Backup vault", "Backup plan", "Amazon RDS", "Amazon Data Lifecycle Manager(Amazon DLM)", "AWS Database Migration Service(AWS DMS)", "Change Data Capture(CDC)", "S3 Lifecycle"], "Commentary": "이 문제는 RDS DB 인스턴스에 대한 장기 백업 보존 정책을 구현해 매일 백업을 최소 2년간 유지하고, 복원 가능하도록 하는 방법을 묻습니다. AWS Backup을 사용하면 중앙 집중식 백업 관리와 자동화된 일정 설정이 가능해, 백업 일관성과 쉽게 복원 가능한 환경을 보장합니다.", "Selections": {"SelectA": {"Select": "AWS Backup에서 RDS 백업을 보존할 백업 볼트를 생성합니다. 일일 스케줄과 생성 후 2년 만료 기간을 갖는 새로운 백업 플랜을 만든 뒤, 해당 RDS DB 인스턴스를 백업 플랜에 할당합니다.", "Commentary": "AWS Backup은 일관된 백업과 자동화를 제공하므로 매일 백업을 수행하고 2년간 보관하며 쉽게 복원할 수 있습니다. 요구사항을 충족하는 최적의 솔루션입니다."}, "SelectB": {"Select": "RDS DB 인스턴스에 대해 백업 윈도우를 구성해 일일 스냅샷을 생성합니다. 각 RDS DB 인스턴스에 2년 스냅샷 보존 정책을 할당하고, Amazon Data Lifecycle Manager(Amazon DLM)로 스냅샷 삭제를 예약합니다.", "Commentary": "스냅샷은 특정 시점의 백업이며, 완전한 일관성과 자동 복원 시나리오를 보장하기 어렵습니다. 게다가 DLM을 통한 삭제 일정만 관리하며, 중앙화된 자동화가 부족합니다."}, "SelectC": {"Select": "데이터베이스 트랜잭션 로그를 자동으로 Amazon CloudWatch Logs에 백업하도록 구성하고, 2년 만료 기간을 설정합니다.", "Commentary": "트랜잭션 로그 백업만으로 전체 데이터베이스 복원이 보장되지 않으며, 자동화된 일관성 백업과 쉽게 복구할 방법도 제공되지 않습니다."}, "SelectD": {"Select": "AWS Database Migration Service(AWS DMS) 복제 태스크를 구성합니다. 복제 인스턴스를 배포하고, Change Data Capture(CDC) 태스크를 설정해 Amazon S3를 대상으로 데이터베이스 변경 사항을 스트리밍합니다. 그리고 S3 Lifecycle 정책으로 2년 후 스냅샷을 삭제합니다.", "Commentary": "이 방식은 복제와 변경 데이터 캡처(CDC)에 집중된 솔루션으로, 매일 백업을 일관성 있게 유지하고 복원하는 용도로는 적합하지 않습니다."}}}
{"Question_Number": "Q260", "Question_Description": "한 회사의 컴플라이언스 팀이 Windows Server SMB 파일 공유로 운영 중인 파일 공유를 AWS로 이전해야 합니다. 사내에서 자체 관리하는 온프레미스 Active Directory가 파일과 폴더에 대한 액세스를 제어하고 있습니다. 이 회사는 솔루션의 일부로 Amazon FSx for Windows File Server를 사용하려고 합니다. 마이그레이션 후에도 온프레미스 Active Directory 그룹이 FSx for Windows File Server SMB 컴플라이언스 공유, 폴더 및 파일에 대한 액세스를 계속 제한해야 합니다. 이미 FSx for Windows File Server 파일 시스템을 생성해두었습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["Windows Server SMB 파일 공유", "온프레미스 Active Directory", "Amazon FSx for Windows File Server", "컴플라이언스", "액세스 제어", "파일 시스템 조인"], "Terms": ["FSx for Windows File Server", "SMB", "Active Directory", "Active Directory Connector", "IAM", "Service-linked Role"], "Commentary": "이 문제는 Amazon FSx for Windows File Server를 기존 온프레미스 Active Directory와 연동하여 이전과 동일한 접근 제어 정책을 유지하는 방법을 묻습니다. FSx 파일 시스템을 도메인에 조인하면, 이미 정의된 AD 그룹과 보안 정책을 그대로 적용해 마이그레이션의 편의성과 보안을 동시에 충족할 수 있습니다.", "Selections": {"SelectA": {"Select": "Active Directory Connector를 생성하여 Active Directory에 연결합니다. AD 그룹을 IAM 그룹과 매핑해 액세스를 제한합니다.", "Commentary": "AD Connector는 AWS Directory Service에 연결을 제공하지만, AD 그룹을 IAM 그룹과 각각 매핑해야 하므로 설정이 복잡해지고 온프레미스 권한을 그대로 살리기에 적합하지 않습니다."}, "SelectB": {"Select": "Restrict라는 태그 키와 Compliance라는 태그 값을 지정합니다. AD 그룹을 IAM 그룹과 매핑해 액세스를 제한합니다.", "Commentary": "태그를 활용한 접근 제한은 일반적으로 역할 기반 액세스 제어와 조합되어야 하며, 온프레미스 AD의 기존 구조를 그대로 반영하지 못합니다."}, "SelectC": {"Select": "IAM service-linked role을 생성해 FSx for Windows File Server와 직접 연결해 액세스를 제한합니다.", "Commentary": "Service-linked role은 FSx 자원에 대한 권한 위임을 돕지만, 기존 AD 보안 그룹과 ACL을 그대로 사용하기 위한 접점이 부족합니다."}, "SelectD": {"Select": "파일 시스템을 Active Directory에 조인해 액세스를 제한합니다.", "Commentary": "온프레미스 Active Directory에 FSx 파일 시스템을 조인하면 기존 AD 그룹과 ACL을 그대로 활용할 수 있어, 마이그레이션 후에도 동일한 정책과 관리 방식을 유지할 수 있는 가장 적합한 방법입니다."}}}
{"Question_Number": "Q261", "Question_Description": "한 회사가 최근 리테일 웹사이트를 전 세계 고객에게 공개했습니다. 이 웹사이트는 Elastic Load Balancer 뒤에서 다수의 Amazon EC2 인스턴스에서 구동되며, 여러 Availability Zone에 걸친 Auto Scaling group으로 운영됩니다. 회사는 고객들이 웹사이트에 접속하는 기기에 따라 다른 버전의 콘텐츠를 제공하고자 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect가 수행해야 할 조치는 무엇입니까? (두 가지를 고르세요.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["글로벌 웹사이트", "기기별 콘텐츠", "Elastic Load Balancer", "Auto Scaling group", "Amazon CloudFront", "Lambda@Edge", "User-Agent 헤더"], "Terms": ["Amazon EC2", "Elastic Load Balancer", "Auto Scaling group", "Amazon CloudFront", "Lambda@Edge", "AWS Global Accelerator", "Network Load Balancer(NLB)", "User-Agent 헤더", "호스트 기반 라우팅", "경로 기반 라우팅"], "Commentary": "이 문제는 사용자 기기에 따라 다른 버전의 웹 콘텐츠를 효율적으로 제공하는 방법을 묻습니다. Amazon CloudFront와 Lambda@Edge를 사용하면 캐시에 여러 버전을 저장하고, User-Agent 헤더를 기반으로 동적으로 다른 콘텐츠를 제공할 수 있습니다. NLB는 TCP/UDP 레벨의 라우팅만 지원하므로 호스트 기반이나 경로 기반 라우팅을 제공하기 어렵습니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront를 구성하여 여러 버전의 콘텐츠를 캐시합니다.", "Commentary": "CloudFront 캐싱은 전 세계적으로 분산된 Edge Location을 통해 다양한 버전의 콘텐츠를 빠르게 전달할 수 있어 요구사항에 부합합니다."}, "SelectB": {"Select": "Network Load Balancer에서 호스트 헤더를 구성하여 트래픽을 다른 인스턴스로 전달합니다.", "Commentary": "NLB는 Layer 4 로드 밸런싱만 지원하므로 호스트 헤더 기반 라우팅을 제공하지 못해 요구사항을 충족하기 어렵습니다."}, "SelectC": {"Select": "Lambda@Edge 함수를 구성하여 User-Agent 헤더에 따라 특정 객체를 사용자에게 전달합니다.", "Commentary": "Lambda@Edge는 CloudFront에서 요청을 가로채 사용자 기기에 따라 다른 콘텐츠를 반환할 수 있어 올바른 접근입니다."}, "SelectD": {"Select": "AWS Global Accelerator를 구성합니다. 요청을 NLB로 전달합니다. NLB를 구성하여 호스트 기반 라우팅으로 다른 EC2 인스턴스에 트래픽을 전달하도록 합니다.", "Commentary": "NLB는 호스트 기반 라우팅을 제공하지 않아, Layer 7 라우팅이 필요한 이 요구사항에 적합하지 않습니다."}, "SelectE": {"Select": "AWS Global Accelerator를 구성합니다. 요청을 NLB로 전달합니다. NLB를 구성하여 경로 기반 라우팅으로 다른 EC2 인스턴스에 트래픽을 전달하도록 합니다.", "Commentary": "NLB는 경로 기반 라우팅 또한 지원하지 않으므로, HTTP 헤더 기반의 맞춤 콘텐츠 제공에는 사용할 수 없습니다."}}}
{"Question_Number": "Q262", "Question_Description": "한 회사가 다중 계층 웹 애플리케이션에 Amazon ElastiCache를 사용하려고 합니다. 솔루션스 아키텍트는 ElastiCache cluster를 위한 Cache VPC와 애플리케이션의 Amazon EC2 인스턴스를 위한 App VPC를 생성했습니다. 두 VPC는 us-east-1 Region에 있습니다. 솔루션스 아키텍트는 애플리케이션의 EC2 인스턴스가 ElastiCache cluster에 액세스하도록 구현해야 합니다. 아래 어느 솔루션이 가장 비용 효율적으로 이러한 요구 사항을 충족합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["Amazon ElastiCache", "VPC Peering", "비용 효율"], "Terms": ["Amazon ElastiCache", "Cache VPC", "App VPC", "Amazon EC2", "VPC 피어링(VPC Peering)", "Transit VPC", "Security Group", "Inbound Rule", "Route Table"], "Commentary": "VPC 간 연결을 할 때 Transit VPC를 구성하면 추가 비용과 구성이 필요해 복잡도가 높아집니다. VPC Peering은 간단하고 비용이 들지 않아 가장 경제적인 연결 방식입니다.", "Selections": {"SelectA": {"Select": "두 VPC 간에 peering connection을 생성합니다. 양쪽 VPC에 route table 항목을 추가하고, ElastiCache cluster의 security group에 애플리케이션 security group에서 오는 인바운드 트래픽을 허용합니다.", "Commentary": "별도 인프라 없이 간단히 연결할 수 있고 추가 요금이 없어 비용 측면에서 유리합니다. 보안 그룹 설정만으로 접근을 제어할 수 있어 안전하며 요구사항을 충족합니다."}, "SelectB": {"Select": "Transit VPC를 생성합니다. Cache VPC와 App VPC의 route table을 Transit VPC를 거치도록 설정하고, ElastiCache cluster의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.", "Commentary": "Transit VPC를 유지하는 데 추가 비용과 구성이 필요해 비효율적입니다. 비용 효율성보다 복잡성과 비용이 증가하므로 적절하지 않습니다."}, "SelectC": {"Select": "두 VPC 간에 peering connection을 생성합니다. 양쪽 VPC에 route table 항목을 추가하고, peering connection의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.", "Commentary": "VPC Peering 자체에는 별도의 security group이 없으므로 설정이 맞지 않습니다. ElastiCache cluster가 속한 security group에 규칙을 두어야 하므로 오답입니다."}, "SelectD": {"Select": "Transit VPC를 생성합니다. Cache VPC와 App VPC의 route table을 Transit VPC를 거치도록 설정하고, Transit VPC의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.", "Commentary": "Transit VPC 구성이 필요해 추가 비용과 관리가 복잡해집니다. 단순 VPC Peering보다 운영 및 비용 면에서 비효율적입니다."}}}
{"Question_Number": "Q263", "Question_Description": "한 기업이 여러 microservice로 구성된 애플리케이션을 만들고 있습니다. 이 기업은 container 기술을 사용하여 AWS에서 소프트웨어를 배포하기로 결정했습니다. 이 기업은 유지 관리와 확장을 위한 지속적인 노력을 최소화하는 솔루션이 필요합니다. 추가 인프라를 관리할 수 없습니다. 이러한 요구 사항을 충족하기 위해 solutions architect가 취해야 할 조치 조합은 무엇입니까? (두 가지를 선택하세요.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["컨테이너", "유지 보수 최소화", "확장", "인프라 관리 불가", "Fargate"], "Terms": ["Amazon Elastic Container Service (Amazon ECS)", "Kubernetes", "Amazon EC2", "Fargate", "Microservices"], "Commentary": "이 문제는 컨테이너 기반 마이크로서비스 환경에서 인프라 관리 없이도 자동으로 확장 가능하고 유지 보수를 최소화할 수 있는 방법을 묻습니다. Amazon ECS와 Fargate launch type을 결합하면 서버 관리 걱정 없이 애플리케이션을 손쉽게 확장하고 운영 복잡성을 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Elastic Container Service (Amazon ECS) cluster를 배포합니다.", "Commentary": "ECS cluster를 통해 컨테이너를 통합 관리할 수 있으며, Fargate와 결합하면 서버 관리 없이도 확장이 가능합니다."}, "SelectB": {"Select": "여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 Kubernetes control plane을 배포합니다.", "Commentary": "Kubernetes control plane을 직접 운영하면 EC2 인스턴스 관리 부담이 커지므로 유지 보수 노력이 증가합니다."}, "SelectC": {"Select": "Amazon EC2 launch type을 사용하여 Amazon Elastic Container Service (Amazon ECS) service를 배포하고 작업 수를 2 이상으로 지정합니다.", "Commentary": "EC2 launch type을 사용하면 기본 인스턴스 관리를 직접 해야 하므로, 추가 인프라 관리가 필요한 점이 문제 요구사항에 부합하지 않습니다."}, "SelectD": {"Select": "Fargate launch type을 사용하여 Amazon Elastic Container Service (Amazon ECS) service를 배포하고 작업 수를 2 이상으로 지정합니다.", "Commentary": "Fargate launch type은 서버리스로 동작하여 인프라 관리를 제거하고 자동 확장이 가능해 요구사항에 가장 부합하는 솔루션입니다."}, "SelectE": {"Select": "여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 Kubernetes worker node를 배포합니다. 각 microservice에 대해 두 개 이상의 replica를 지정하는 deployment를 생성합니다.", "Commentary": "Kubernetes node 역시 EC2 인스턴스를 직접 관리해야 하므로 유지 보수와 스케일링 부담이 큽니다."}}}
{"Question_Number": "Q264", "Question_Description": "한 회사가 10개의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있고, Amazon Route 53으로 트래픽을 라우팅하고 있습니다. 회사는 애플리케이션에 접속하려고 시도할 때 가끔 타임아웃 오류가 발생합니다. 네트워크 팀은 일부 DNS 쿼리가 비정상 인스턴스의 IP 주소를 반환하여 타임아웃 오류가 생긴다는 점을 발견했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 구현해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["타임아웃 오류", "DNS 쿼리", "비정상 인스턴스", "Route 53", "ALB"], "Terms": ["Amazon EC2", "Amazon Route 53", "Simple routing policy", "Failover routing policy", "Amazon CloudFront", "Application Load Balancer (ALB)", "health check"], "Commentary": "이 문제는 비정상 EC2 인스턴스에도 트래픽이 라우팅되어 발생하는 타임아웃 오류를 해결하기 위한 고가용성 디자인을 요구합니다. Route 53의 단순 또는 페일오버 라우팅만으로는 모든 경우에 즉각적인 비정상 인스턴스 감지가 어려울 수 있습니다. ALB를 사용하면 자체적인 health check로 비정상 인스턴스를 제외하고 동적으로 트래픽을 분산할 수 있으므로 타임아웃 오류를 최소화하고 운영을 단순화할 수 있습니다.", "Selections": {"SelectA": {"Select": "각 EC2 인스턴스마다 Route 53 Simple Routing Policy 레코드를 생성하고, 각 레코드에 health check를 연결합니다.", "Commentary": "단순 라우팅은 레코드별 헬스 체크로 제한적이어서, 인스턴스 증설이나 관리 면에서 복잡성이 높아집니다."}, "SelectB": {"Select": "각 EC2 인스턴스마다 Route 53 Failover Routing Policy 레코드를 생성하고, 각 레코드에 health check를 연결합니다.", "Commentary": "Failover 라우팅은 주·보조 설정을 위해 적합하지만, 다수의 인스턴스 관리에는 복잡하고 탄력성이 떨어집니다."}, "SelectC": {"Select": "Amazon CloudFront 배포를 생성하고, EC2 인스턴스를 오리진으로 사용합니다. EC2 인스턴스에 health check를 연결합니다.", "Commentary": "CloudFront는 글로벌 엣지 캐싱과 배포에 유리하지만, 인스턴스 헬스 체크로 인한 타임아웃 문제 해결에는 적합하지 않습니다."}, "SelectD": {"Select": "EC2 인스턴스 앞에 health check를 설정한 Application Load Balancer(ALB)를 생성하고, Route 53에서 ALB로 라우팅합니다.", "Commentary": "ALB가 비정상 인스턴스를 health check로 분리해주어, 타임아웃 문제를 효과적으로 방지하고 고가용성을 구현합니다."}}}
{"Question_Number": "Q265", "Question_Description": "한 솔루션스 아키텍트가 웹, 애플리케이션, 데이터베이스 계층으로 구성된 고가용성 애플리케이션을 설계해야 합니다. HTTPS 콘텐츠는 가능한 한 에지(Edge)에 가깝게 배포되어 가장 짧은 전송 시간을 가져야 하며, 동시에 가장 안전해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2", "2.2"], "Keywords": ["고가용성 애플리케이션", "웹·애플리케이션·데이터베이스 계층", "HTTPS 콘텐츠", "에지(Edge) 전송", "가장 안전한 솔루션"], "Terms": ["Application Load Balancer (ALB)", "Amazon CloudFront", "Amazon EC2", "private subnets", "public subnets", "HTTPS", "고가용성", "에지(Edge)"], "Commentary": "이 문제는 웹, 애플리케이션, 데이터베이스 계층을 안전하면서도 고가용성으로 구성하고, 에지(Edge)에 가까운 HTTPS 전송을 통해 지연 시간을 최소화해야 합니다. ALB와 EC2를 어디에 배치하느냐에 따라 보안 수준과 응답 속도가 달라집니다. 정답인 C는 Public ALB 뒤에 Private subnet의 EC2를 배치하여 직접 노출을 피하면서 CloudFront를 통해 글로벌 에지 전송을 지원해 고가용성과 보안을 모두 만족합니다.", "Selections": {"SelectA": {"Select": "public Application Load Balancer (ALB)를 구성하고 여러 Amazon EC2 인스턴스를 public subnets에 배포합니다. Amazon CloudFront를 사용하여 public ALB를 오리진으로 HTTPS 콘텐츠를 전송합니다.", "Commentary": "EC2 인스턴스가 public subnets에 위치하므로 인터넷에 직접 노출되어 보안 측면이 약화됩니다."}, "SelectB": {"Select": "public Application Load Balancer를 구성하고 여러 Amazon EC2 인스턴스를 private subnets에 배포합니다. Amazon CloudFront를 사용하여 EC2 인스턴스를 오리진으로 HTTPS 콘텐츠를 전송합니다.", "Commentary": "CloudFront가 직접 EC2 인스턴스에 연결해야 하므로 추가적으로 EC2를 외부에 노출하는 설정이 필요하며, 관리 복잡도가 증가합니다."}, "SelectC": {"Select": "public Application Load Balancer (ALB)를 구성하고 여러 Amazon EC2 인스턴스를 private subnets에 배포합니다. Amazon CloudFront를 사용하여 public ALB를 오리진으로 HTTPS 콘텐츠를 전송합니다.", "Commentary": "ALB만 Public subnet에 배치하고 EC2는 Private subnet에 격리하여 보안과 고가용성을 모두 달성하는 가장 안전하고 효율적인 방식입니다."}, "SelectD": {"Select": "public Application Load Balancer를 구성하고 여러 Amazon EC2 인스턴스를 public subnets에 배포합니다. Amazon CloudFront를 사용하여 EC2 인스턴스를 오리진으로 HTTPS 콘텐츠를 전송합니다.", "Commentary": "EC2 인스턴스가 Public subnet에 존재하여 인터넷 노출 범위가 너무 커지고, 공격 표면이 확대됩니다."}}}
{"Question_Number": "Q266", "Question_Description": "한 회사가 AWS에서 인기 있는 게이밍 플랫폼을 운영 중입니다. 이 애플리케이션은 지연(latency)에 매우 민감하여, 지연이 사용자 경험에 영향을 미치거나 일부 플레이어에게 불공정한 이점을 줄 수 있습니다. 이 애플리케이션은 모든 AWS Region에 배포되어 있으며, Amazon EC2 인스턴스를 사용하고, Auto Scaling group에 속해 있으며 Application Load Balancer(ALB) 뒤에서 동작합니다. 솔루션스 아키텍트는 애플리케이션의 상태(health)를 모니터링하고 트래픽을 정상 동작 중인 엔드포인트(healthy endpoints)로 리다이렉트하는 메커니즘을 구현해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["게이밍 플랫폼", "지연(latency) 민감", "AWS Region", "Application Load Balancer(ALB)", "정상 엔드포인트", "트래픽 리다이렉트", "AWS Global Accelerator"], "Terms": ["AWS Global Accelerator", "Amazon CloudFront", "AWS Lambda", "Amazon S3", "Amazon DynamoDB", "DynamoDB Accelerator (DAX)", "Amazon EC2", "Auto Scaling", "Application Load Balancer(ALB)"], "Commentary": "이 문제는 전 세계로 배포된 게이밍 플랫폼의 지연을 최소화하고, 건강 상태를 모니터링해 정상적인 엔드포인트로 트래픽을 유도하는 고성능 네트워크 아키텍처 설계를 묻고 있습니다. AWS Global Accelerator를 사용하면 전역적으로 트래픽을 빠르고 안정적으로 라우팅할 수 있으며, 각 리전에 있는 ALB 상태를 확인해 자동으로 정상 엔드포인트로 연결함으로써 사용자 경험을 향상시킵니다.", "Selections": {"SelectA": {"Select": "AWS Global Accelerator에서 accelerator를 구성합니다. 애플리케이션이 사용하는 포트용 listener를 추가하고, 각 Region에 Regional endpoint를 등록합니다. ALB를 해당 endpoint로 추가합니다.", "Commentary": "AWS Global Accelerator는 글로벌 Anycast IP로 트래픽을 받고, 상태 확인을 통해 가장 가까운 정상 엔드포인트로 라우팅해 지연을 줄이고 유연한 장애 조치가 가능합니다."}, "SelectB": {"Select": "Amazon CloudFront 배포를 생성하고 ALB를 오리진 서버로 지정합니다. 캐시 동작을 origin cache header로 설정합니다. AWS Lambda 함수를 사용해 트래픽을 최적화합니다.", "Commentary": "CloudFront는 주로 정적 콘텐츠 캐싱과 전송 최적화용으로 적합하지만, 동적 애플리케이션 상태 모니터링과 리전별 즉각적인 라우팅을 구현하기에는 제약이 큽니다."}, "SelectC": {"Select": "Amazon CloudFront 배포를 생성하고 Amazon S3를 오리진 서버로 지정합니다. 캐시 동작을 origin cache header로 설정합니다. AWS Lambda 함수를 사용해 트래픽을 최적화합니다.", "Commentary": "S3를 오리진으로 사용하면 정적 파일 배포에는 유리하나, 게임 서버의 실시간 동작 및 지연 모니터링에는 부적합하며 정상 엔드포인트 라우팅도 어렵습니다."}, "SelectD": {"Select": "Amazon DynamoDB를 애플리케이션의 데이터 스토어로 사용하도록 구성합니다. DynamoDB Accelerator(DAX) 클러스터를 만들어 인메모리 캐시로 사용합니다.", "Commentary": "DynamoDB+DAX는 데이터 접근 속도를 높일 수 있지만 네트워크 트래픽을 건강 상태에 따라 전 세계적으로 라우팅하고 지연을 줄이는 데는 직접적인 도움을 주지 못합니다."}}}
{"Question_Number": "Q267", "Question_Description": "한 회사에 백만 명의 모바일 앱 사용자가 있습니다. 회사는 거의 실시간으로 데이터 사용량을 분석해야 합니다. 또한 데이터를 거의 실시간으로 암호화하고, 이후 분석을 위해 Apache Parquet 형식으로 데이터를 중앙 위치에 저장해야 합니다. 이 요구 사항을 최소의 운영 오버헤드로 충족할 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["모바일 앱", "실시간 분석", "암호화", "Apache Parquet", "중앙화 저장"], "Terms": ["Amazon Kinesis Data Firehose", "Amazon EMR", "Amazon Kinesis Data Analytics", "AWS Lambda", "Amazon S3", "Apache Parquet"], "Commentary": "이 문제는 모바일 앱에서 발생하는 대량 데이터를 거의 실시간으로 암호화하고 분석하며, Parquet 형식으로 S3에 저장하는 저오버헤드 솔루션을 묻습니다. Kinesis Data Firehose와 Kinesis Data Analytics를 결합하면 서버 관리 부담을 최소화하고 실시간 처리 요구사항을 만족할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Kinesis data stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 해당 데이터를 Kinesis Data Analytics 애플리케이션으로 전송합니다.", "Commentary": "Kinesis Data Stream에 직접 데이터가 들어가기 때문에 실시간 처리는 가능하나, Kinesis Data Stream과 Kinesis Data Analytics를 연결하기 위해 Lambda 함수를 추가로 관리해야 하므로 오버헤드가 증가합니다."}, "SelectB": {"Select": "Amazon Kinesis data stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 EMR 클러스터로 데이터를 전송합니다.", "Commentary": "EMR 클러스터를 직접 운영하고 Lambda 함수를 별도 호출해야 하므로 운영 복잡도가 높고 실시간 처리에도 비효율적입니다."}, "SelectC": {"Select": "Amazon Kinesis Data Firehose delivery stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다.", "Commentary": "Kinesis Data Firehose는 자동 암호화와 Parquet 변환을 지원하지만, EMR 클러스터 구성 및 관리가 추가되어 운영 오버헤드가 큽니다."}, "SelectD": {"Select": "Amazon Kinesis Data Firehose delivery stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다.", "Commentary": "완전관리형 서비스인 Kinesis Data Firehose로 실시간 암호화 및 Parquet 변환이 가능하고, Kinesis Data Analytics로 별도 인프라 관리 없이 빠르게 분석할 수 있어 운영 오버헤드가 가장 적습니다."}}}
{"Question_Number": "Q268", "Question_Description": "한 게임 회사는 점수를 표시하는 웹 애플리케이션을 운영하고 있습니다. 해당 웹 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon RDS for MySQL 데이터베이스에 데이터를 저장합니다. 사용자는 데이터베이스 읽기 성능 저하로 인해 지연이 길어지거나 중단이 발생하고 있습니다. 회사는 사용자 경험을 개선하면서 애플리케이션 아키텍처 변경을 최소화하고자 합니다. 이러한 요구 사항을 충족하기 위해 Solutions Architect는 어떤 조치를 취해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["데이터베이스 읽기 성능", "사용자 경험 개선", "아키텍처 변경 최소화", "점수 표시 웹 애플리케이션"], "Terms": ["Amazon EC2", "Application Load Balancer", "Amazon RDS for MySQL", "Amazon ElastiCache", "RDS Proxy", "AWS Lambda", "Amazon DynamoDB"], "Commentary": "이 문제는 MySQL 데이터베이스의 읽기 성능 문제로 인해 사용자 지연이 발생하는 상황에서, 기존 아키텍처 변경을 최소화하여 빠르게 읽기 성능을 개선하는 방안을 묻습니다. 캐싱 계층을 도입하면 DB 부하를 줄이고 빠른 응답을 제공할 수 있습니다.", "Selections": {"SelectA": {"Select": "데이터베이스 앞단에 Amazon ElastiCache를 사용합니다.", "Commentary": "ElastiCache를 활용해 자주 조회되는 데이터를 캐싱하면 DB의 읽기 부하가 줄어 응답 속도가 크게 향상되며, 전체 아키텍처 변경도 최소화됩니다."}, "SelectB": {"Select": "애플리케이션과 데이터베이스 사이에 RDS Proxy를 사용합니다.", "Commentary": "RDS Proxy는 연결 관리와 보안을 개선하지만, 주로 연결 수 급증을 완화하는 역할이며 본질적인 읽기 성능 문제 해결에는 제한적입니다."}, "SelectC": {"Select": "애플리케이션을 EC2 인스턴스에서 AWS Lambda로 마이그레이션합니다.", "Commentary": "Lambda로 이전해도 데이터베이스 읽기 성능 문제 자체는 해결되지 않으므로, 요구 사항을 충족하기 어렵습니다."}, "SelectD": {"Select": "Amazon RDS for MySQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.", "Commentary": "관계형 DB에서 NoSQL로 전환은 아키텍처상의 큰 변경이며, 요구사항인 최소 변경과 어긋납니다."}}}
{"Question_Number": "Q269", "Question_Description": "한 전자상거래 회사의 Amazon RDS 기반 웹 애플리케이션에서 성능 저하가 감지되었습니다. 성능 저하의 원인은 비즈니스 분석가들이 실행하는 읽기 전용 SQL 쿼리 증가에 있습니다. 솔루션스 아키텍트는 기존 웹 애플리케이션에 최소한의 변경으로 이 문제를 해결해야 합니다. 어떤 솔루션을 권장해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon RDS", "읽기 전용 SQL 쿼리", "성능 저하", "기존 웹 애플리케이션", "최소 변경"], "Terms": ["Amazon RDS", "Read Replica", "Amazon DynamoDB", "Amazon ElastiCache", "Amazon Redshift"], "Commentary": "읽기 부하가 급증하여 RDS의 성능 저하가 발생합니다. 해결 방법으로는 읽기 전용 트래픽을 다른 대상에게 오프로드하는 것이 적합합니다. Read Replica를 사용하면 기본 DB에 미치는 영향 없이 분석 쿼리를 실행할 수 있어, 웹 애플리케이션 코드 변경 없이 쉽게 적용 가능합니다.", "Selections": {"SelectA": {"Select": "데이터를 Amazon DynamoDB로 내보내고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.", "Commentary": "데이터 구조 변경 및 애플리케이션 로직 수정이 필요해 최소 변경 목표에 어긋납니다."}, "SelectB": {"Select": "데이터를 Amazon ElastiCache에 적재하고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.", "Commentary": "ElastiCache는 캐시 서비스로 주로 빠른 조회용이며, SQL 쿼리 수행을 직접 지원하지 않는 등 사용 사례가 맞지 않습니다."}, "SelectC": {"Select": "기본 데이터베이스의 Read Replica를 생성하고 비즈니스 분석가들이 그 Replica에서 쿼리를 실행하도록 합니다.", "Commentary": "읽기 전용 부하를 Replica로 오프로드하여 기본 DB의 성능 저하를 방지하며 최소한의 변경으로 구현 가능합니다."}, "SelectD": {"Select": "데이터를 Amazon Redshift 클러스터로 복사하고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.", "Commentary": "Redshift로의 마이그레이션에는 스키마 및 분석 워크플로우 변경이 필요해 최소 변경 요구사항에 맞지 않습니다."}}}
{"Question_Number": "Q270", "Question_Description": "한 회사가 중앙화된 AWS 계정을 사용하여 여러 Amazon S3 버킷에 로그 데이터를 저장하고 있습니다. 솔루션스 아키텍트는 데이터가 S3 버킷에 업로드되기 전에 암호화되도록 보장해야 하며, 또한 전송 중에도 암호화되어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["데이터 암호화", "전송 중 암호화", "업로드 전 암호화", "Client-side encryption", "Server-side encryption"], "Terms": ["Amazon S3", "Client-side encryption", "Server-side encryption (SSE)", "SSE-S3", "AWS KMS"], "Commentary": "이 문제는 S3에 데이터를 업로드하기 전에 이미 암호화가 되어 있어야 하며(‘before the data is uploaded’), 업로드 중에도 암호화(SSL/TLS)로 보호되어야 함을 요구합니다. Server-side encryption은 객체가 S3에 도달한 후에 암호화됩니다. 따라서 요구사항을 만족하려면 Client-side encryption을 사용해 로컬에서 데이터를 암호화한 뒤 HTTPS로 전송해야 합니다.", "Selections": {"SelectA": {"Select": "S3 버킷에 업로드되는 데이터를 Client-side encryption으로 암호화합니다.", "Commentary": "클라이언트 측에서 먼저 데이터를 암호화한 후 업로드하면 ‘업로드 전 암호화’와 전송 암호화를 모두 충족하므로 요구사항에 부합합니다."}, "SelectB": {"Select": "S3 버킷에 업로드되는 데이터를 Server-side encryption으로 암호화합니다.", "Commentary": "Server-side encryption은 S3에 도착한 이후 암호화를 적용하므로, ‘업로드 전 암호화’ 요구사항과는 맞지 않습니다."}, "SelectC": {"Select": "SSE-S3를 반드시 사용하도록 버킷 정책을 생성하여 업로드하도록 합니다.", "Commentary": "이 방법 역시 업로드 후 서버에서 암호화가 수행되므로, 사전에 암호화 상태로 업로드하는 요구사항을 만족하지 못합니다."}, "SelectD": {"Select": "기본 AWS KMS 키를 사용하여 S3 버킷 암호화를 활성화합니다.", "Commentary": "AWS KMS를 통한 서버 측 암호화 또한 업로드 후 암호화되므로, ‘업로드 전’ 암호화 요구사항과 일치하지 않습니다."}}}
{"Question_Number": "Q271", "Question_Description": "한 솔루션스 아키텍트가 야간에 실행되는 배치 처리 작업이 원하는 Amazon EC2 용량에 도달하기까지 자동으로 스케일업되는 데 1시간이 걸리는 것을 관찰했습니다. 최대 용량은 매일 밤 동일하며, 배치 작업은 항상 오전 1시에 시작됩니다. 솔루션스 아키텍트는 원하는 EC2 용량에 빠르게 도달하면서, 배치 작업이 완료된 후 Auto Scaling group이 스케일다운될 수 있도록 하는 비용 효율적인 솔루션을 찾아야 합니다. 이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["야간 배치 작업", "EC2 용량", "Auto Scaling group", "스케줄 기반 스케일링", "비용 효율"], "Terms": ["Amazon EC2", "Auto Scaling group", "scheduled scaling", "minimum capacity", "maximum capacity", "scaling policy"], "Commentary": "이 문제는 매일 일정한 시간(오전 1시)에 시작되는 배치 작업을 빠르게 처리하기 위해, 미리 원하는 EC2 용량에 도달하도록 스케줄 기반으로 Auto Scaling 설정을 최적화하는 방법을 묻습니다. 배치 작업이 끝나면 자동으로 스케일다운해 비용을 절감해야 합니다. 따라서 사전에 스케줄을 설정해 필요한 EC2 인스턴스를 즉시 확보하는 것이 가장 효율적입니다.", "Selections": {"SelectA": {"Select": "Auto Scaling group의 minimum capacity를 늘립니다.", "Commentary": "minimum capacity만 늘리면 항상 비용이 들며 작업이 없을 때도 필요 이상의 인스턴스를 유지하게 되어 비효율적입니다."}, "SelectB": {"Select": "Auto Scaling group의 maximum capacity를 늘립니다.", "Commentary": "maximum capacity는 상한 설정일 뿐, 빠르게 스케일업하는 것과 직결되지 않아 작업 시작 시점에 즉각적인 용량 확보가 어렵습니다."}, "SelectC": {"Select": "원하는 컴퓨팅 수준까지 스케일업하도록 scheduled scaling을 구성합니다.", "Commentary": "배치 작업이 시작되기 전인 일정 시간에 맞춰 EC2 용량을 미리 늘려둘 수 있어, 빠른 작업 처리와 비용 효율을 모두 충족하는 정답입니다."}, "SelectD": {"Select": "각 스케일링 동작마다 더 많은 EC2 인스턴스를 추가하도록 스케일링 정책을 변경합니다.", "Commentary": "정책 수정을 통해 더 빠른 스케일업이 가능할 수 있지만, 예상되는 부하 시간대가 명확하므로 scheduled scaling이 더 안정적이고 비용 효과적입니다."}}}
{"Question_Number": "Q272", "Question_Description": "한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스 풀에서 동적 웹사이트를 제공하고 있습니다. 이 웹사이트는 전 세계 고객에게 다중 언어를 지원해야 하며, 현재 us-west-1 리전에서만 운영되어 다른 지역 사용자에게 높은 지연 시간이 발생하고 있습니다. 사용자의 위치와 관계없이 빠르고 효율적인 응답 속도를 제공해야 하지만, 여러 리전에 기존 아키텍처를 재구성하고 싶지는 않습니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["동적 웹사이트", "글로벌 사용자", "다중 언어 지원", "지연 시간 단축", "기존 아키텍처 유지", "Amazon CloudFront", "Accept-Language"], "Terms": ["Application Load Balancer(ALB)", "Amazon EC2", "Amazon CloudFront", "Accept-Language", "Amazon S3", "Amazon API Gateway", "NGINX", "Amazon Route 53", "Geolocation routing", "HTTP integration", "API Gateway cache", "CloudFront distribution", "cache behavior", "S3 bucket"], "Commentary": "멀리 떨어진 사용자는 웹 요청 시 레이턴시가 증가합니다. ALB 뒤의 EC2 환경을 유지하면서 CloudFront를 사용해 전 세계 엣지 네트워크에서 콘텐츠를 캐싱하면, 다중 리전 재구성 없이 지연 시간을 크게 단축하고 Accept-Language 헤더 기준으로 다국어 캐싱도 가능합니다.", "Selections": {"SelectA": {"Select": "기존 아키텍처를 Amazon S3에서 호스팅되는 웹사이트로 교체하고, Amazon S3 버킷을 오리진으로 하는 Amazon CloudFront distribution을 설정한 뒤, Accept-Language 요청 헤더를 기준으로 캐시를 구성합니다.", "Commentary": "S3 정적 호스팅으로 전환하면 동적 웹사이트의 기존 구조가 사라질 수 있어 요구사항을 만족하지 못합니다."}, "SelectB": {"Select": "ALB를 오리진으로 하는 Amazon CloudFront distribution을 구성하고, Accept-Language 요청 헤더를 기준으로 캐시 동작(cache behavior)을 설정합니다.", "Commentary": "기존 ALB 뒤 EC2 아키텍처를 유지하면서 CloudFront로 글로벌 캐싱 및 다국어 지원을 구현하는 최적의 방법입니다."}, "SelectC": {"Select": "ALB와 연동된 Amazon API Gateway API를 생성하고, HTTP 통합 방식을 사용하도록 구성합니다. 그리고 Accept-Language 요청 헤더를 기반으로 API 캐시를 활성화합니다.", "Commentary": "API Gateway를 거치는 구성은 불필요한 복잡성을 일으키며 CloudFront만큼 효율적이지 않습니다."}, "SelectD": {"Select": "각 추가 리전에 EC2 인스턴스를 실행하고, 해당 리전에서 NGINX를 캐시 서버로 구성합니다. 모든 EC2 인스턴스와 ALB를 Amazon Route 53 지리 위치 라우팅(geolocation) 정책으로 연결합니다.", "Commentary": "각 리전에 인프라를 배포하기 때문에 회사가 원치 않는 다중 리전 아키텍처가 되어 운영 부담이 늘어납니다."}}}
{"Question_Number": "Q273", "Question_Description": "한 빠르게 성장하는 전자상거래 회사가 현재 단일 AWS 리전에서 워크로드를 운영하고 있습니다. 이제 다른 AWS 리전을 포함하는 재해 복구(Disaster Recovery, DR) 전략을 마련해야 합니다. 솔루션스 아키텍트는 DR 리전에서도 최소 지연으로 최신 상태의 데이터베이스를 유지해야 하며, DR 리전의 나머지 인프라는 축소된 용량으로 가동되지만 필요할 경우 확장 가능해야 합니다. 이러한 요구사항을 만족하면서 가장 낮은 RTO(복구 시간 목표)를 보장하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["재해 복구", "최소 지연", "낮은 RTO", "Aurora global database", "파일럿 라이트", "웜 스탠바이"], "Terms": ["Amazon Aurora global database", "Pilot light deployment", "Warm standby deployment", "Amazon RDS Multi-AZ DB instance", "RTO", "DR(Disaster Recovery)", "Region", "Scale up", "RPO"], "Commentary": "이 문제는 DR(재해 복구) 환경에서 데이터베이스를 최신 상태로 유지하고, 필요 시 빠르게 서비스를 재개하는 방법을 묻습니다. Aurora Global Database는 리전 간 복제를 통해 지연을 최소화하며, Warm Standby 방식은 이미 핵심 서비스를 DR 리전에 미리 배치해 두어 RTO를 낮출 수 있습니다. Pilot Light보다 Warm Standby가 더 빠른 전환이 가능하며, Multi-AZ 옵션은 동일 리전 내 고가용성만 보장할 뿐 다른 리전에서의 즉각적인 복구 기능은 제한적입니다. 따라서 최소 지연 및 신속한 확장을 위해 Amazon Aurora global database와 Warm Standby를 조합하는 것이 최적의 솔루션입니다.", "Selections": {"SelectA": {"Select": "Amazon Aurora global database를 파일럿 라이트(pilot light) 방식으로 구성합니다.", "Commentary": "Aurora Global Database는 지연을 줄일 수 있지만, 파일럿 라이트는 추가 설정이 필요해 RTO가 더 길어집니다."}, "SelectB": {"Select": "Amazon Aurora global database를 웜 스탠바이(warm standby) 방식으로 구성합니다.", "Commentary": "DR 리전에 이미 핵심 리소스가 가동 중이며, Aurora Global Database 덕분에 지연이 최소화되어 가장 짧은 RTO를 달성합니다."}, "SelectC": {"Select": "Amazon RDS Multi-AZ DB 인스턴스를 파일럿 라이트(pilot light) 방식으로 구성합니다.", "Commentary": "Multi-AZ는 동일 리전 내 장애 대비용으로, 다른 리전에서는 직접 복구 과정이 필요해 DR 관점에서 RTO가 길어집니다."}, "SelectD": {"Select": "Amazon RDS Multi-AZ DB 인스턴스를 웜 스탠바이(warm standby) 방식으로 구성합니다.", "Commentary": "다른 리전에서도 일부 리소스를 가동해 두지만, Aurora Global Database에 비해 지연 및 RTO 개선 효과가 제한됩니다."}}}
{"Question_Number": "Q274", "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 회사는 애플리케이션에 대한 Disaster Recovery(DR) 솔루션을 구현해야 합니다. DR 솔루션은 4시간 미만의 Recovery Time Objective(RTO)를 충족해야 하며, 평상시에는 가능한 한 적은 수의 AWS 리소스를 사용해야 합니다. 이러한 요구사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["DR 솔루션", "Amazon EC2", "RTO 4시간 미만", "AWS 리소스 최소화"], "Terms": ["Amazon EC2", "Disaster Recovery(DR)", "Recovery Time Objective(RTO)", "Amazon Machine Images(AMIs)", "AWS Region", "AWS Lambda", "AWS CloudFormation", "Availability Zone"], "Commentary": "이 문제는 EC2 인스턴스 기반 애플리케이션의 DR 전략 중, 4시간 미만 RTO 달성과 평시 AWS 리소스 최소 사용이 핵심입니다. AMI를 사용해 백업을 유지하고, 필요 시 자동으로 해당 이미지를 사용해 재빨리 인프라를 복원할 수 있도록 설계하는 방안이 요구됩니다. 특히 AWS CloudFormation으로 자동화를 구성하면 인프라를 신속하게 프로비저닝하여 RTO를 효율적으로 만족시킬 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스를 백업하기 위해 Amazon Machine Images(AMIs)를 생성합니다. 이 AMI들을 보조 AWS Region으로 복사합니다. AWS Lambda와 사용자 지정 스크립트를 사용하여 보조 Region에서 인프라 배포를 자동화합니다.", "Commentary": "Lambda와 커스텀 스크립트를 사용하는 방법도 가능하나, CloudFormation에 비해 표준화와 유지보수 측면에서 복잡도가 높을 수 있습니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스를 백업하기 위해 Amazon Machine Images(AMIs)를 생성합니다. 이 AMI들을 보조 AWS Region으로 복사합니다. AWS CloudFormation을 사용하여 보조 Region에서 인프라 배포를 자동화합니다.", "Commentary": "AMI를 통해 백업을 간단히 유지하면서, 필요 시 CloudFormation 템플릿으로 빠른 인프라 재구성을 할 수 있어 4시간 미만의 RTO와 운영 효율, 그리고 리소스 최소화를 모두 달성할 수 있습니다. (정답)"}, "SelectC": {"Select": "보조 AWS Region에 Amazon EC2 인스턴스를 시작합니다. 이 보조 Region의 EC2 인스턴스를 항상 활성 상태로 유지합니다.", "Commentary": "DR이 아닌 멀티-Region 활성 상태로 운영하게 되므로 평시 리소스 비용이 크게 증가합니다. RTO는 만족해도 요구사항인 ‘AWS 리소스 최소화’를 충족하지 못합니다."}, "SelectD": {"Select": "보조 Availability Zone에 Amazon EC2 인스턴스를 시작합니다. 이 보조 AZ의 EC2 인스턴스를 항상 활성 상태로 유지합니다.", "Commentary": "Region 단위 재해에 대응하기 어렵고, 인스턴스를 항상 구동해야 하므로 평시 비용이 높습니다. DR 요구사항을 충족하기에 부적합합니다."}}}
{"Question_Number": "Q275", "Question_Description": "한 회사는 내부 브라우저 기반 애플리케이션을 운영하고 있으며, 이 애플리케이션은 Application Load Balancer 뒤에서 동작하는 Amazon EC2 인스턴스에서 구동됩니다. 인스턴스들은 여러 Availability Zone에 분산된 Amazon EC2 Auto Scaling group에서 실행되며, 근무 시간 중에는 최대 20개의 인스턴스로 스케일 업하고, 야간에는 2개의 인스턴스로 스케일 다운합니다. 직원들은 업무 시작 시 애플리케이션이 매우 느려서 불편을 겪지만, 오전 중반이 되면 정상 속도로 작동한다고 보고합니다. 직원들의 불만을 해결하면서도 비용을 최소화하기 위해 스케일링 설정을 어떻게 변경해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["Auto Scaling 그룹", "Application Load Balancer", "Amazon EC2 인스턴스", "근무 시간", "야간 스케일 다운", "Target Tracking", "CPU 임계값", "Cooldown 기간", "비용 절감"], "Terms": ["Amazon EC2", "Application Load Balancer", "Amazon EC2 Auto Scaling group", "Availability Zone", "Scheduled Action", "Step Scaling", "Target Tracking", "Cooldown period", "Desired Capacity", "Minimum Capacity", "Maximum Capacity"], "Commentary": "이 문제는 Amazon EC2 Auto Scaling 그룹을 활용해 아침 시간의 지연 문제를 해결하면서도 불필요한 인스턴스 비용을 줄이는 방법을 묻습니다. Target Tracking Scaling은 특정 지표(예: CPU 사용률)를 기반으로 즉각적인 확장을 제공해 성능 저하가 발생하기 전에 충분한 인스턴스를 확보하며, 부하가 줄면 자동으로 스케일 다운하여 비용을 절감합니다.", "Selections": {"SelectA": {"Select": "사무실이 열리기 직전에 Desired Capacity를 20으로 설정하는 Scheduled Action을 구현합니다.", "Commentary": "아침 지연 문제는 해결되지만, 하루 종일 20개 인스턴스를 유지해 오히려 비용이 증가할 수 있습니다."}, "SelectB": {"Select": "더 낮은 CPU 임계값에서 트리거되는 Step Scaling 액션을 구현하고, Cooldown 기간을 단축합니다.", "Commentary": "Step Scaling은 임계값 범위를 세밀히 설정해야 하며, 부하 패턴 변화에 즉각 대응하기가 어렵고 관리가 복잡합니다."}, "SelectC": {"Select": "더 낮은 CPU 임계값에서 트리거되는 Target Tracking 액션을 구현하고, Cooldown 기간을 줄입니다.", "Commentary": "Target Tracking은 설정한 지표 수준에 맞춰 자동으로 확장·축소하므로 아침 부하를 빠르게 처리하고, 부하가 감소하면 자동으로 줄여 비용을 절감할 수 있습니다."}, "SelectD": {"Select": "사무실이 열리기 직전에 Scheduled Action으로 Minimum Capacity와 Maximum Capacity를 모두 20으로 설정합니다.", "Commentary": "인스턴스를 20개로 고정해 두어 운영하며, 부하가 줄어도 스케일 다운이 불가능해 오히려 비용이 크게 상승합니다."}}}
{"Question_Number": "Q276", "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스를 Auto Scaling 그룹으로 구성하여 다중 계층 애플리케이션을 운영하고 있습니다. 데이터 계층으로 Amazon RDS for Oracle을 사용하며, Oracle 전용 PL/SQL 함수를 활용합니다. 애플리케이션으로 유입되는 트래픽이 꾸준히 증가하여 EC2 인스턴스는 과부하 상태가 되고, RDS 인스턴스는 스토리지가 부족해지고 있습니다. 현재 Auto Scaling 그룹에는 별도의 스케일링 지표가 없으며 최소 정상 인스턴스 수만 정의되어 있습니다. 회사 측은 트래픽이 계속 일정하면서도 예측 불가능한 비율로 증가하다가 결국 안정화될 것으로 예상합니다. 증가한 트래픽에 대비해 시스템이 자동으로 확장되도록 하려면 어떻게 해야 합니까? (두 가지를 선택하십시오.)", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["EC2 인스턴스", "Auto Scaling 그룹", "Amazon RDS for Oracle", "Oracle 전용 PL/SQL", "스토리지 부족", "꾸준히 증가하는 트래픽", "자동 확장"], "Terms": ["Auto Scaling group", "Amazon RDS for Oracle", "Amazon Aurora", "PL/SQL", "Storage Auto Scaling", "CloudWatch Alarm", "Average CPU", "Average Free Memory"], "Commentary": "이 문제는 갑작스럽게 늘어나는 트래픽 상황에서 EC2와 RDS 인스턴스 모두 확장 가능하도록 설정해야 하는 시나리오입니다. RDS for Oracle에 Storage Auto Scaling을 적용하면 스토리지 공간 부족 문제를 자동으로 해결할 수 있으며, Auto Scaling 그룹에 올바른 지표(예: CPU 사용률)를 설정하면 인스턴스가 과부하 전에 늘어나도록 유연하게 확장할 수 있습니다.", "Selections": {"SelectA": {"Select": "RDS for Oracle 인스턴스에 Storage Auto Scaling을 구성합니다.", "Commentary": "RDS 스토리지가 부족해질 경우 자동으로 확장하도록 설정해둠으로써 공간 문제를 근본적으로 해결할 수 있는 올바른 선택입니다."}, "SelectB": {"Select": "Auto Scaling 스토리지를 사용하기 위해 데이터베이스를 Amazon Aurora로 마이그레이션합니다.", "Commentary": "Oracle 전용 PL/SQL 함수를 사용하므로 Aurora로 이전하면 호환성 문제가 발생합니다. 요구사항에 부합하지 않는 선택입니다."}, "SelectC": {"Select": "RDS for Oracle 인스턴스의 유휴 스토리지가 부족할 때 경보가 울리도록 설정합니다.", "Commentary": "단순 알람 설정으로는 스토리지 부족 상태가 해결되지 않으며 자동 확장을 보장하지 못합니다."}, "SelectD": {"Select": "Auto Scaling 그룹이 평균 CPU 사용률을 스케일링 지표로 사용하도록 구성합니다.", "Commentary": "CPU 활용도는 인스턴스 부담 정도를 대표하는 핵심 지표입니다. 과부하 전 자동으로 확장하기 적절한 선택입니다."}, "SelectE": {"Select": "Auto Scaling 그룹이 평균 유휴 메모리를 스케일링 지표로 사용하도록 구성합니다.", "Commentary": "메모리가 아니라 CPU 사용률이 주요 과부하 지표이므로, 이 선택은 상대적으로 덜 적합합니다."}}}
{"Question_Number": "Q277", "Question_Description": "한 회사가 온라인 비디오 게시 및 이를 모든 모바일 플랫폼에서 사용할 수 있도록 트랜스코딩하는 서비스를 제공합니다. 애플리케이션 아키텍처는 Amazon EFS Standard를 사용하여 비디오를 수집하고 저장하며, 여러 Amazon EC2 Linux 인스턴스가 이 비디오 콘텐츠에 액세스하여 처리합니다. 시간이 지남에 따라 서비스가 인기를 얻으면서 스토리지 비용이 너무 비싸졌습니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["온라인 비디오 서비스", "트랜스코딩", "스토리지 비용", "Amazon EFS", "Amazon S3"], "Terms": ["Amazon EFS", "Amazon EC2", "Linux", "AWS Storage Gateway", "Amazon S3", "Amazon Elastic Block Store (Amazon EBS)"], "Commentary": "이 문제는 비디오 파일 저장에 발생하는 높은 비용을 줄이기 위한 방안을 묻습니다. 사용 빈도가 낮은 데이터는 Amazon S3에 저장하고, 처리 시에만 Amazon EBS를 활용하여 비용 부담을 크게 낮출 수 있습니다.", "Selections": {"SelectA": {"Select": "AWS Storage Gateway for files를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.", "Commentary": "파일 게이트웨이는 온프레미스 환경과 AWS를 연결하는 데 주로 쓰이며, 장기 스토리지로 사용하기에는 적합하지 않아 비용 효율성을 기대하기 어렵습니다."}, "SelectB": {"Select": "AWS Storage Gateway for volumes를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.", "Commentary": "볼륨 게이트웨이는 블록 스토리지 형식으로 온프레미스에서 AWS로 데이터를 이전할 때 주로 사용되며, 이 역시 장기 스토리지로 활용하기에는 적합하지 않습니다."}, "SelectC": {"Select": "비디오 콘텐츠를 Amazon EFS에 저장합니다. 처리 완료 후 파일을 Amazon EBS로 전송합니다.", "Commentary": "EFS를 계속 사용하면 비용이 높게 유지됩니다. 처리 후 EBS로 옮기더라도 S3보다 비용 효율이 떨어집니다."}, "SelectD": {"Select": "비디오 콘텐츠를 Amazon S3에 저장합니다. 처리 시에는 서버에 연결된 Amazon EBS 볼륨으로 임시로 옮겨서 처리합니다.", "Commentary": "장기 저장은 Amazon S3가 가장 저렴하고, 필요한 시점에만 EBS를 사용해 파일을 처리하므로 비용과 운영 편의성 모두 충족시킵니다."}}}
{"Question_Number": "Q278", "Question_Description": "한 회사가 계층적으로 구조화된 관계로 사원 데이터를 저장할 애플리케이션을 구축하려고 합니다. 이 회사는 대규모 트래픽이 발생하는 쿼리에 대해 최소 지연 시간으로 응답해야 하며, 민감한 데이터를 보호해야 합니다. 또한 사원 데이터 중 재무 정보가 포함되어 있는 경우 매달 이메일 메시지를 받아야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 취해야 할 단계 조합은 무엇입니까? (2개를 선택하십시오.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.3"], "Keywords": ["계층적 데이터", "최소 지연 시간", "민감한 데이터 보호", "재무 정보", "월별 알림"], "Terms": ["Amazon DynamoDB", "Amazon Redshift", "Amazon Macie", "Amazon EventBridge", "Amazon Athena", "Amazon QuickSight", "Amazon SNS", "Export to Amazon S3"], "Commentary": "이 문제는 구조적으로 계층화된 데이터를 빠르게 조회해야 하며, 동시에 민감한 정보(재무 데이터 등)의 보안을 유지하려는 요구 사항을 다룹니다. Amazon DynamoDB는 고성능의 NoSQL DB로 계층적 구조를 효율적으로 처리하고 트래픽이 많은 읽기·쓰기 워크로드를 최소 지연 시간으로 처리합니다. Amazon Macie는 저장된 데이터 중 민감한 정보를 찾아내고, 그 결과를 EventBridge에서 SNS 등으로 알림을 보낼 수 있어, 월별 보고 요구 사항을 충족합니다. 따라서 DynamoDB로 실시간 고성능 처리를 담당하면서, Macie를 통해 민감 데이터 식별과 알림을 자동화하는 접근이 최적의 조합입니다.", "Selections": {"SelectA": {"Select": "Amazon Redshift를 사용하여 계층 구조로 사원 데이터를 저장합니다. 매달 Amazon S3로 데이터를 Unload합니다.", "Commentary": "Amazon Redshift는 대규모 데이터웨어하우징에 적합하지만, 빠른 단일 레코드 조회와 계층적 구조를 위해서는 DynamoDB가 더 적합합니다."}, "SelectB": {"Select": "Amazon DynamoDB를 사용하여 계층 구조로 사원 데이터를 저장합니다. 매달 Amazon S3로 데이터를 Export합니다.", "Commentary": "DynamoDB는 고성능으로 계층적 데이터를 처리할 수 있고, Export to Amazon S3 기능을 통해 사원 데이터를 정기적으로 백업하거나 분석용으로 옮길 수 있습니다."}, "SelectC": {"Select": "AWS 계정에 Amazon Macie를 구성합니다. Macie를 Amazon EventBridge와 연동하여 매달 이벤트를 AWS Lambda로 전송합니다.", "Commentary": "Macie로 민감 정보 식별은 가능하지만, Lambda를 통한 알림보다는 SNS를 통한 직접 알림이 월별 이메일 요구사항에 더 적합합니다."}, "SelectD": {"Select": "Amazon S3에 있는 사원 데이터를 Amazon Athena로 분석합니다. Athena를 Amazon QuickSight와 연동하여 분석 대시보드를 게시하고 사용자와 공유합니다.", "Commentary": "데이터 분석과 대시보드 공유에는 유용하지만, 실시간 최소 지연 처리와 민감 정보 보호 요구사항을 동시에 만족하기에는 부족합니다."}, "SelectE": {"Select": "AWS 계정에 Amazon Macie를 구성합니다. Macie를 Amazon EventBridge와 연동하여 매달 Amazon Simple Notification Service(Amazon SNS) 구독을 통해 알림을 전송합니다.", "Commentary": "Macie가 재무 등 민감 정보 여부를 식별하고, EventBridge를 통해 월별 SNS 알림을 자동화할 수 있어 보안·알림 요구사항을 충족합니다."}}}
{"Question_Number": "Q279", "Question_Description": "한 회사는 Amazon DynamoDB 테이블로 뒷받침되는 애플리케이션을 운영하고 있습니다. 이 회사의 컴플라이언스 요구 사항에 따라 데이터베이스 백업은 매달 진행되어야 하며, 6개월간 사용 가능해야 하고, 7년간 보관되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["DynamoDB", "컴플라이언스 요구 사항", "매달 백업", "6개월 유지", "7년 보존", "AWS Backup", "cold storage", "라이프사이클 정책"], "Terms": ["AWS Backup", "DynamoDB on-demand backup", "Amazon S3 Glacier Flexible Retrieval", "cold storage", "retention period", "Amazon EventBridge", "AWS SDK", "AWS CLI", "라이프사이클 정책", "cron expression"], "Commentary": "이 문제는 DynamoDB 테이블의 정기 백업 및 장기 보존 정책을 어떻게 구현할지 묻습니다. 컴플라이언스 준수를 위해 매달 백업, 6개월간 접근 가능, 그리고 7년 보관이 필요합니다. AWS Backup을 사용하면 백업 일정을 손쉽게 관리하고, 라이프사이클을 지정해 cold storage로 전환하며, 장기 보존까지 자동화할 수 있습니다. 이는 추가 스크립트 작성이나 S3 Glacier 전환처럼 복잡한 절차 없이 간단히 대응 가능하므로 운영 부담을 크게 줄여줍니다.", "Selections": {"SelectA": {"Select": "매달 첫 번째 날에 DynamoDB 테이블 백업을 진행하도록 AWS Backup 계획을 생성합니다. 6개월 후 백업이 cold storage로 전환되도록 라이프사이클 정책을 지정하고, 각 백업의 보존 기간을 7년으로 설정합니다.", "Commentary": "AWS Backup만으로 백업 일정, cold storage 전환, 7년 보존을 모두 자동화하여 간단하며 안정적으로 컴플라이언스를 충족합니다."}, "SelectB": {"Select": "매달 첫 번째 날에 DynamoDB 테이블의 DynamoDB 온디맨드 백업을 생성합니다. 6개월 후에 백업을 Amazon S3 Glacier Flexible Retrieval로 전환합니다. 7년보다 오래된 백업을 삭제하기 위해 S3 라이프사이클 정책을 생성합니다.", "Commentary": "DynamoDB 백업을 직접 S3 Glacier로 전환하는 것은 네이티브 기능이 아니므로 적용이 어렵고, 별도의 관리가 필요하여 적합하지 않습니다."}, "SelectC": {"Select": "AWS SDK를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성하는 스크립트를 개발합니다. 매달 첫 번째 날에 이 스크립트가 실행되도록 Amazon EventBridge 규칙을 설정합니다. 6개월보다 오래된 DynamoDB 백업을 cold storage로 전환하고 7년보다 오래된 백업을 삭제하기 위해 매달 두 번째 날에 실행되는 두 번째 스크립트를 작성합니다.", "Commentary": "사용자 정의 스크립트, 일정 규칙, 2단계 관리가 모두 필요해 복잡도가 높고 오류 가능성이 커서 효율적이지 못합니다."}, "SelectD": {"Select": "AWS CLI를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성합니다. cron 표현식을 사용하여 매달 첫 번째 날에 해당 명령이 실행되도록 Amazon EventBridge 규칙을 설정합니다. 명령에서 6개월 후 백업을 cold storage로 전환하고 7년 후 백업을 삭제하도록 지정합니다.", "Commentary": "CLI와 EventBridge로 구현은 가능하지만 여전히 스크립트 기반이며, AWS Backup을 활용하는 것에 비해 운영 부담이 크고 관리가 까다롭습니다."}}}
{"Question_Number": "Q280", "Question_Description": "한 회사가 웹사이트에 Amazon CloudFront를 사용하고 있으며 CloudFront distribution에서 로깅을 활성화하고 있습니다. 이 로깅 데이터는 회사의 Amazon S3 버킷 중 하나에 저장됩니다. 이 회사는 이 로그에 대해 고급 분석을 수행하고 시각화도 구축해야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.5"], "Keywords": ["Amazon CloudFront", "로그", "Amazon S3", "고급 분석", "시각화", "Amazon Athena", "Amazon QuickSight"], "Terms": ["Amazon CloudFront", "CloudFront distribution", "Amazon S3", "Amazon Athena", "AWS Glue", "Amazon QuickSight", "Amazon DynamoDB"], "Commentary": "이 문제는 CloudFront 로깅 데이터를 S3에 저장한 뒤, 그 데이터를 분석하고 시각화하는 방법을 묻습니다. Athena는 S3에 저장된 데이터를 표준 SQL로 분석할 수 있는 서비스이고, QuickSight는 시각화 도구로 적합합니다. 따라서 Athena로 로그를 분석하고 QuickSight로 시각화하는 것이 운영 부담을 줄이며 효율적인 솔루션입니다.", "Selections": {"SelectA": {"Select": "S3 버킷에 저장된 CloudFront 로그를 Amazon Athena에서 표준 SQL 쿼리로 분석하고, 결과를 AWS Glue로 시각화합니다.", "Commentary": "AWS Glue는 ETL 작업과 Data Catalog에 특화되어 있으며, 시각화 도구로 사용하기에는 적합하지 않습니다."}, "SelectB": {"Select": "S3 버킷에 저장된 CloudFront 로그를 Amazon Athena에서 표준 SQL 쿼리로 분석하고, 결과를 Amazon QuickSight로 시각화합니다.", "Commentary": "정답입니다. Athena를 통해 로그를 쉽게 분석하고, QuickSight를 활용하면 간편하게 보고서나 대시보드를 만들 수 있습니다."}, "SelectC": {"Select": "S3 버킷에 저장된 CloudFront 로그를 Amazon DynamoDB의 표준 SQL 쿼리로 분석하고, 결과를 AWS Glue로 시각화합니다.", "Commentary": "DynamoDB는 NoSQL 데이터베이스로, S3에 저장된 로그를 직접 SQL로 분석하기 어렵고 Glue는 시각화 도구가 아닙니다."}, "SelectD": {"Select": "S3 버킷에 저장된 CloudFront 로그를 Amazon DynamoDB의 표준 SQL 쿼리로 분석하고, 결과를 Amazon QuickSight로 시각화합니다.", "Commentary": "DynamoDB는 S3에 저장된 로그 분석용으로 적합하지 않으며, Athena가 제공하는 편의성과 확장성을 얻기 어렵습니다."}}}
{"Question_Number": "Q281", "Question_Description": "한 회사가 Amazon RDS for PostgreSQL DB 인스턴스를 사용해 웹 서버 팩을 운영하고 있습니다. 일상적인 컴플라이언스 점검 후, 모든 프로덕션 데이터베이스에 대해 RPO를 1초 미만으로 유지해야 한다는 표준을 설정했습니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["RPO 1초 미만", "Amazon RDS for PostgreSQL", "Multi-AZ 배포", "프로덕션 데이터베이스"], "Terms": ["Multi-AZ deployment", "Auto Scaling", "Read Replica", "AWS Database Migration Service (AWS DMS)", "Change Data Capture (CDC)"], "Commentary": "이 문제는 DB 장애 발생 시 데이터 손실 최소화(RPO)를 요구합니다. Amazon RDS Multi-AZ 배포는 동기식 복제로 거의 실시간에 가까운 RPO(1초 미만)를 보장하여 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "DB 인스턴스에 Multi-AZ 배포를 활성화합니다.", "Commentary": "동기식 복제를 통해 거의 동시에 데이터가 복제되어 RPO가 1초 미만으로 유지되므로 요구사항을 만족합니다."}, "SelectB": {"Select": "단일 가용 영역에 대해 DB 인스턴스 자동 확장을 활성화합니다.", "Commentary": "Auto Scaling은 성능 또는 트래픽 대비 용량 확장에 대한 기능이며, RPO(데이터 손실 허용 범위) 보장과는 직접적인 관련이 없습니다."}, "SelectC": {"Select": "한 가용 영역에 DB 인스턴스를 구성하고, 별도 가용 영역에 여러 Read Replica를 구성합니다.", "Commentary": "Read Replica는 비동기식 복제로 RPO가 1초 미만 보장을 하지 못하며, 장애 시 데이터 손실 가능성이 있습니다."}, "SelectD": {"Select": "한 가용 영역에 DB 인스턴스를 구성하고, AWS DMS Change Data Capture(CDC)를 구성합니다.", "Commentary": "AWS DMS CDC 역시 비동기 방식으로 동작하므로 RPO가 1초 미만 수준으로 엄격히 보장되지 않습니다."}}, "reference": "A: By using Multi-AZ deployment, the company can achieve an RPO of less than 1 second because the standby instance is always in sync with the primary instance, ensuring that data changes are continuously replicated."}
{"Question_Number": "Q282", "Question_Description": "한 회사가 VPC의 private subnet에 Amazon EC2 인스턴스를 배포해 웹 애플리케이션을 운영 중입니다. public subnet에 걸쳐 구성된 Application Load Balancer(ALB)가 웹 트래픽을 EC2 인스턴스로 전달합니다. 회사는 ALB로부터 EC2 인스턴스로 들어오는 인바운드 트래픽만 허용하고, EC2 인스턴스의 private subnet 내부나 외부의 다른 소스에서는 접근하지 못하도록 새로운 보안 방안을 구현하고자 합니다. 이러한 요구사항을 충족하려면 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["private subnet", "Application Load Balancer", "Amazon EC2", "Security Group", "인바운드 트래픽"], "Terms": ["VPC", "public subnet", "private subnet", "Amazon EC2", "Application Load Balancer(ALB)", "Security Group", "Elastic IP"], "Commentary": "이 문제는 내부 네트워크의 EC2 인스턴스에 ALB만이 접근하도록 보안을 강화하는 방법을 묻습니다. 즉, EC2 인스턴스의 Security Group에서 ALB의 Security Group만 신뢰하도록 설정하여, 그 외 소스는 모두 차단하는 구성을 해야 합니다. 따라서 EC2 인스턴스 보안 그룹에서 ALB 보안 그룹만 허용하는 B가 정답입니다.", "Selections": {"SelectA": {"Select": "라우트 테이블에서 인터넷 트래픽을 EC2 인스턴스의 private IP 주소로 전달하도록 라우트를 설정합니다.", "Commentary": "이 방법은 보안 그룹이 아닌 라우팅 레벨에서 인터넷 트래픽을 직접 private IP로 보내는 것으로, 외부 접근을 제한할 수 없으므로 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "EC2 인스턴스의 Security Group을 설정하여 ALB의 Security Group에서 오는 트래픽만 허용하도록 구성합니다.", "Commentary": "필요한 트래픽만 ALB를 통해 들여보내고 나머지를 차단해 보안을 강화하는 가장 적절한 솔루션입니다."}, "SelectC": {"Select": "EC2 인스턴스를 public subnet으로 옮기고 Elastic IP 주소를 할당합니다.", "Commentary": "EC2 인스턴스를 public subnet으로 옮기면 외부 접근이 가능해져 보안을 강화하려는 요건과 반대되는 결과를 초래합니다."}, "SelectD": {"Select": "ALB의 Security Group을 설정하여 어떤 포트든지 TCP 트래픽을 모두 허용하도록 구성합니다.", "Commentary": "ALB에 전 포트 허용은 보안 범위를 과도하게 넓혀 EC2 인스턴스에 대한 무분별한 접근 가능성을 열어두므로 적절하지 않습니다."}}}
{"Question_Number": "Q283", "Question_Description": "한 연구 회사는 시뮬레이션 애플리케이션과 시각화 애플리케이션을 사용해 실험을 수행하고 있습니다. 시뮬레이션 애플리케이션은 Linux에서 실행되며, 5분마다 중간 데이터를 NFS 공유에 출력합니다. 시각화 애플리케이션은 Windows 데스크톱 애플리케이션으로, 시뮬레이션 출력을 표시하며 SMB 파일 시스템을 필요로 합니다. 현재는 NFS와 SMB를 각각 사용해 데이터 동기화를 수행하고 있어 데이터 중복과 리소스가 비효율적으로 사용되고 있습니다. 회사는 두 애플리케이션 모두 코드 수정 없이 AWS로 마이그레이션해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["시뮬레이션 애플리케이션", "시각화 애플리케이션", "NFS 공유", "SMB 파일 시스템", "데이터 동기화", "코드 수정 없이 마이그레이션"], "Terms": ["Amazon EC2", "Amazon FSx for NetApp ONTAP", "NFS", "SMB", "Linux", "Windows"], "Commentary": "이 문제는 서로 다른 파일 시스템(NFS와 SMB)을 사용하는 두 애플리케이션을 어떻게 통합된 방식으로 AWS에 마이그레이션할지를 묻습니다. Amazon FSx for NetApp ONTAP은 Linux와 Windows 환경 모두에서 접근할 수 있는 공유 스토리지를 제공하므로, 두 애플리케이션 모두를 코드 수정 없이 통합된 파일 시스템에 연결할 수 있습니다. 이를 통해 데이터 중복과 불필요한 동기화 작업을 제거하고 운영 효율성을 높일 수 있습니다.", "Selections": {"SelectA": {"Select": "두 애플리케이션을 AWS Lambda로 마이그레이션하고, 애플리케이션 간 데이터를 교환하기 위해 Amazon S3 버킷을 생성합니다.", "Commentary": "Lambda 기반으로 시뮬레이션 애플리케이션을 그대로 옮기기 어렵고, S3만으로 NFS와 SMB 요구사항을 동시에 해결하기 어렵습니다."}, "SelectB": {"Select": "두 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션하고, 스토리지를 위해 Amazon FSx File Gateway를 구성합니다.", "Commentary": "Amazon FSx File Gateway는 온프레미스 NAS 환경과의 연결에 용이하나, NFS와 SMB를 동시 지원하는 NetApp ONTAP만큼 직접적이고 효율적인 해결책은 아닙니다."}, "SelectC": {"Select": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로, 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션하고, 애플리케이션 간 데이터 교환을 위해 Amazon SQS를 구성합니다.", "Commentary": "SQS는 메시지 기반 서비스로, 파일 I/O 동기화가 필요한 NFS와 SMB 요구사항을 충족시키기 부족합니다."}, "SelectD": {"Select": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로, 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션하고, 스토리지를 위해 Amazon FSx for NetApp ONTAP을 구성합니다.", "Commentary": "Amazon FSx for NetApp ONTAP은 NFS와 SMB 프로토콜을 모두 지원하므로, 두 애플리케이션이 단일 파일 시스템을 공유해 코드 수정 없이 효율적으로 운영 가능합니다."}}}
{"Question_Number": "Q284", "Question_Description": "예산 수립의 일환으로 경영진은 사용자를 기준으로 나열된 AWS 청구 항목 보고서를 원합니다. 이 데이터는 각 부서별 예산을 생성하는 데 사용될 예정입니다. 솔루션스 아키텍트는 이 보고서 정보를 가장 효율적으로 얻을 수 있는 방법을 결정해야 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": [], "Keywords": ["AWS 청구 항목", "사용자별 보고서", "부서별 예산", "Cost Explorer"], "Terms": ["Amazon Athena", "Cost Explorer", "Billing Dashboard", "AWS Budgets", "Amazon Simple Email Service (Amazon SES)"], "Commentary": "이 문제는 사용자를 기준으로 한 AWS 청구 항목을 효과적으로 조회하고 예산 수립에 활용하기 위한 보고서 생성 방법을 묻습니다. Cost Explorer를 이용하면 원하는 기준(사용자별 등)으로 쉽게 보고서를 생성하고 다운로드할 수 있어 가장 간편하고 효율적입니다.", "Selections": {"SelectA": {"Select": "Amazon Athena로 쿼리를 실행하여 보고서를 생성합니다.", "Commentary": "AWS Cost and Usage Report를 먼저 S3에 내보낸 뒤 Athena로 분석해야 하므로 설정이 복잡합니다."}, "SelectB": {"Select": "Cost Explorer에서 보고서를 생성하고 다운로드합니다.", "Commentary": "필요한 청구 정보를 사용자별로 손쉽게 필터링하고 바로 다운로드할 수 있으므로 가장 효율적인 방법입니다."}, "SelectC": {"Select": "Billing 대시보드에서 청구 세부 정보를 확인하고 청구서를 다운로드합니다.", "Commentary": "대시보드 청구서는 항목별 세분화가 제한적이어서 사용자별 구분 보고서로 활용하기 불편합니다."}, "SelectD": {"Select": "AWS Budgets에서 Cost Budget을 수정하여 Amazon Simple Email Service(Amazon SES)로 알림을 보냅니다.", "Commentary": "알림 발송 용도로 사용되는 Budgets 기능이며, 사용자별 청구 항목 보고서를 생성하는 데는 적합하지 않습니다."}}}
{"Question_Number": "Q285", "Question_Description": "한 회사가 Amazon S3를 사용하여 정적 웹사이트를 호스팅하고 있습니다. 회사는 웹페이지에 이름, 이메일 주소, 전화번호, 사용자 메시지를 입력할 수 있는 서버 측 로직이 있는 동적 연락처 양식을 추가하려고 합니다. 해당 웹사이트는 한 달에 100회 미만의 방문이 예상됩니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 방법은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["정적 웹사이트", "동적 서버 측 로직", "문의 양식", "비용 효율", "100회 미만 방문", "Amazon API Gateway", "AWS Lambda", "Amazon SES"], "Terms": ["Amazon S3", "Amazon ECS", "Amazon SES", "Amazon API Gateway", "AWS Lambda", "Amazon Lightsail", "Amazon WorkMail", "Amazon EC2", "LAMP"], "Commentary": "트래픽이 극히 적으므로 서버리스 구조가 가장 경제적입니다. API Gateway와 Lambda를 통해 동적 기능을 구현하고 Amazon SES로 이메일 송신까지 처리하는 방식이 비용을 최소화합니다.", "Selections": {"SelectA": {"Select": "Amazon Elastic Container Service(Amazon ECS)에서 동적 연락처 양식을 호스팅하고 Amazon Simple Email Service(Amazon SES)를 써드파티 이메일에 연결합니다.", "Commentary": "ECS 클러스터 유지 비용이 들 수 있으며, 요청 수가 적어 서버리스보다 비효율적입니다."}, "SelectB": {"Select": "Amazon API Gateway 엔드포인트를 생성하고, AWS Lambda 백엔드가 Amazon Simple Email Service(Amazon SES)에 호출을 수행하도록 구성합니다.", "Commentary": "서버리스 방식으로 트래픽이 적을 때 비용이 매우 낮아 요구사항을 가장 효율적으로 충족합니다."}, "SelectC": {"Select": "Amazon Lightsail로 정적 웹페이지를 동적 형태로 전환하고, 클라이언트 사이드 스크립팅으로 연락처 폼을 만든 다음 Amazon WorkMail과 통합합니다.", "Commentary": "Lightsail 인스턴스 비용이 지속적으로 청구되어, 방문자가 적은 사이트에는 과도한 구성입니다."}, "SelectD": {"Select": "t2.micro Amazon EC2 인스턴스를 만들고, LAMP 스택으로 웹페이지를 호스팅합니다. 클라이언트 사이드 스크립팅으로 폼을 만들고 Amazon WorkMail로 연동합니다.", "Commentary": "EC2 인스턴스를 상시 운영해야 하므로, 저트래픽 환경에는 비용 효율적이지 않습니다."}}}
{"Question_Number": "Q286", "Question_Description": "한 회사가 Amazon S3 앞단에 Amazon CloudFront를 사용하여 정적 웹사이트를 호스팅하고 있습니다. 이 정적 웹사이트에는 데이터베이스 백엔드가 있습니다. 회사는 웹사이트가 Git 리포지토리에서 변경한 내용을 반영하지 않는다고 확인했습니다. 회사는 Git 리포지토리와 Amazon S3 간 CI/CD 파이프라인의 webhook 설정이 정상 동작하고, 성공적인 배포 메시지를 전송하는 것도 확인했습니다. 솔루션스 아키텍트는 웹사이트가 업데이트 내용을 표시하도록 해결책을 구현해야 합니다. 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["정적 웹사이트", "Amazon CloudFront", "Amazon S3", "CI/CD 파이프라인", "캐시 무효화"], "Terms": ["Amazon CloudFront", "Amazon S3", "CI/CD", "webhook", "Application Load Balancer", "Amazon ElastiCache", "Redis", "Memcached", "Invalidate the CloudFront cache", "AWS Certificate Manager(ACM)"], "Commentary": "이 문제는 CI/CD 파이프라인이 정상적으로 작동해도 CloudFront 캐시가 이전 콘텐츠를 계속 제공할 수 있다는 점이 핵심입니다. 새로운 콘텐츠를 사용자에게 즉시 반영하기 위해서는 CloudFront 캐시 무효화(Invalidate)를 수행하여 최신 버전을 제공하도록 해야 합니다.", "Selections": {"SelectA": {"Select": "Application Load Balancer를 추가합니다.", "Commentary": "Application Load Balancer는 트래픽 분산 용도로 적합하지만, 이미 CloudFront와 S3 조합이 사용 중이므로 캐시 문제 해결과 직접적인 관련이 없습니다."}, "SelectB": {"Select": "Amazon ElastiCache for Redis나 Memcached를 웹 애플리케이션의 데이터베이스 계층에 추가합니다.", "Commentary": "데이터베이스 성능을 개선하는 옵션이며, 웹사이트 데이터가 즉시 반영되지 않는 문제와는 직접적인 연관이 없습니다."}, "SelectC": {"Select": "CloudFront 캐시를 무효화(Invalidate)합니다.", "Commentary": "CloudFront 캐시가 이전 콘텐츠를 제공 중이므로, 캐시를 무효화하면 배포된 최신 버전이 사용자에게 즉시 반영됩니다."}, "SelectD": {"Select": "AWS Certificate Manager(ACM)을 사용하여 웹사이트의 SSL 인증서를 검증합니다.", "Commentary": "SSL 인증서 검증은 보안과 신뢰성에 관련되어 있으나, 사이트 업데이트가 반영되지 않는 문제의 원인을 해결하지 못합니다."}}}
{"Question_Number": "Q287", "Question_Description": "한 회사가 온프레미스에서 Windows 기반 애플리케이션을 AWS Cloud로 마이그레이션하려고 합니다. 이 애플리케이션은 애플리케이션 티어, 비즈니스 티어, Microsoft SQL Server를 사용하는 데이터베이스 티어의 세 가지 티어로 구성되어 있습니다. 회사는 SQL Server의 native backups, Data Quality Services 등의 특정 기능을 활용하기 원하며, 각 티어 간에 파일을 공유하며 처리해야 합니다. 이러한 요구사항을 만족하는 아키텍처 설계는 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.3"], "Keywords": ["Windows 기반 애플리케이션", "SQL Server", "native backups", "Data Quality Services", "파일 공유", "3티어 구조", "Amazon FSx for Windows File Server"], "Terms": ["Amazon EC2", "Microsoft SQL Server", "Amazon FSx for Windows File Server", "Amazon FSx File Gateway", "Amazon RDS", "Amazon EFS", "Amazon EBS", "io2"], "Commentary": "문제 의도는 SQL Server 고유 기능을 사용하고 Windows 환경에서 SMB 기반 파일 공유를 제공하는 방안을 찾는 것입니다. 본격적인 배포 전 Windows 파일 공유가 필요하며, RDS 대신 EC2 기반 SQL Server로 구성 시 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "모든 티어를 Amazon EC2 인스턴스에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon FSx File Gateway를 사용합니다.", "Commentary": "Amazon FSx File Gateway는 온프레미스에서 클라우드의 FSx 공유 폴더에 접근할 때 적합하며, 모두 클라우드에 위치한 경우에는 적절하지 않아 비효율적입니다."}, "SelectB": {"Select": "모든 티어를 Amazon EC2 인스턴스에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon FSx for Windows File Server를 사용합니다.", "Commentary": "Windows용 SMB 파일 공유를 바로 제공하고, SQL Server 특화 기능도 EC2 환경에서 자유롭게 활용 가능하여 요구사항에 부합합니다."}, "SelectC": {"Select": "애플리케이션 티어와 비즈니스 티어는 Amazon EC2에서 호스팅하고, 데이터베이스 티어는 Amazon RDS에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon EFS를 사용합니다.", "Commentary": "Amazon EFS는 NFS 프로토콜을 사용하며 Windows 환경에서 SMB 공유를 직접 지원하지 않아 파일 공유 요구사항에 적합하지 않습니다."}, "SelectD": {"Select": "애플리케이션 티어와 비즈니스 티어는 Amazon EC2에서 호스팅하고, 데이터베이스 티어는 Amazon RDS에서 호스팅합니다. 티어 간 파일 공유를 위해 Provisioned IOPS SSD(io2) Amazon EBS 볼륨을 사용합니다.", "Commentary": "Amazon EBS는 서버 간 파일 공유용보다는 개별 인스턴스에 붙여 쓰는 블록 스토리지로, 멀티 인스턴스와의 공유가 어렵습니다."}}}
{"Question_Number": "Q288", "Question_Description": "한 회사가 Linux 기반 웹 서버 그룹을 AWS로 마이그레이션하고 있습니다. 웹 서버들은 일부 콘텐츠를 위해 공유 파일 스토어에 접근해야 합니다. 회사는 애플리케이션에 어떤 변경도 가하지 않으려 합니다. 이 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["Linux 기반 웹 서버", "공유 파일 스토어", "Amazon EFS", "애플리케이션 무변경"], "Terms": ["Amazon S3", "Amazon CloudFront", "Amazon Elastic File System(Amazon EFS)", "Amazon EBS", "General Purpose SSD(gp3)"], "Commentary": "이 문제의 핵심은 여러 웹 서버가 동시에 접근할 수 있는 파일 스토어를 제공하고, 애플리케이션 변경 없이 기존처럼 NFS 마운트 형태로 사용해야 한다는 점입니다. Amazon EFS는 Linux 서버 환경에서 공유 파일 시스템을 간편하게 제공하며, 스케일 및 가용성 측면에서도 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "Amazon S3 Standard 버킷을 생성하고 웹 서버에서 접근하도록 설정합니다.", "Commentary": "Object 스토리지인 Amazon S3는 파일 시스템 마운트 방식이 아니므로 애플리케이션 코드 변경 없이 사용하기 어렵습니다."}, "SelectB": {"Select": "Amazon CloudFront 배포를 Amazon S3 버킷을 오리진으로 구성합니다.", "Commentary": "CloudFront는 정적 콘텐츠 배포에 유리하지만, 웹 서버 간 공유 파일 시스템 기능을 제공하지 않습니다."}, "SelectC": {"Select": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 이 EFS 파일 시스템을 마운트합니다.", "Commentary": "Linux 기반 서버들이 NFS 방식으로 공유 스토어를 사용할 수 있어 애플리케이션을 수정할 필요가 없으며 확장성과 고가용성도 충족합니다."}, "SelectD": {"Select": "General Purpose SSD (gp3) Amazon EBS 볼륨을 구성합니다. 모든 웹 서버에 이 EBS 볼륨을 마운트합니다.", "Commentary": "Amazon EBS는 단일 EC2 인스턴스에 연결되는 블록 스토리지로, 여러 웹 서버가 동시에 마운트하기에 적합하지 않습니다."}}}
{"Question_Number": "Q289", "Question_Description": "어느 회사에서 동일한 AWS 계정 내에 위치한 Amazon S3 버킷에 대한 읽기 권한이 필요한 AWS Lambda 함수가 있습니다. 가장 안전한 방식으로 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.3"], "Keywords": ["Lambda 함수", "S3 버킷", "IAM role", "정책", "보안"], "Terms": ["AWS Lambda", "Amazon S3", "S3 bucket policy", "IAM role", "IAM policy", "Access Key", "Secret Key", "Least Privilege"], "Commentary": "이 문제는 Lambda 함수가 특정 S3 버킷에만 안전하게 접근하도록 구성하는 방법을 묻습니다. IAM role을 사용하면 Lambda 함수에 임시 자격 증명을 부여하여, 필요한 버킷에만 최소 권한으로 접근할 수 있습니다. 이러한 방식은 보안 및 위험 완화 측면에서 가장 우수하며, 액세스 키를 코드에 직접 포함시키는 것보다 안전합니다.", "Selections": {"SelectA": {"Select": "S3 버킷에 읽기 권한을 부여하는 S3 bucket policy를 적용합니다.", "Commentary": "버킷 정책만으로는 Lambda 함수에 대한 세분화된 제어가 어렵고 IAM role을 통한 임시 자격 증명 방식을 활용하지 않아 보안상 취약합니다."}, "SelectB": {"Select": "Lambda 함수에 IAM role을 적용하고, 해당 role에 S3 버킷에 대한 읽기 권한을 부여하는 IAM policy를 적용합니다.", "Commentary": "IAM role을 통해 필요한 S3 버킷만 읽을 권한을 부여하는 최소 권한 원칙을 만족하며, 함수가 안전한 임시 자격 증명을 사용하므로 보안 측면에서 가장 적합합니다."}, "SelectC": {"Select": "Lambda 함수 코드에 접근 키와 비밀 키를 하드코딩하여 필요한 IAM 권한을 부여합니다.", "Commentary": "코드에 키를 직접 포함하면 노출 위험이 크고, 키 관리를 어렵게 만듭니다. 보안 모범 사례에 어긋납니다."}, "SelectD": {"Select": "Lambda 함수에 IAM role을 적용하고, 계정 내 모든 S3 버킷에 대한 읽기 권한을 부여하는 IAM policy를 적용합니다.", "Commentary": "필요 이상의 광범위한 권한을 부여하므로 최소 권한 원칙을 지키지 못해 보안 취약점이 발생할 수 있습니다."}}}
{"Question_Number": "Q290", "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 이 EC2 인스턴스들은 Auto Scaling group에 속해 있으며, 사용자 트래픽에 따라 확장됩니다. 회사는 장기 약정 없이 비용 절감을 최적화하고자 합니다. 이러한 요구 사항을 충족하기 위한 EC2 인스턴스 구매 옵션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["Amazon EC2", "Auto Scaling group", "On-Demand Instances", "Spot Instances", "비용 절감", "장기 약정 없이"], "Terms": ["Amazon EC2", "Auto Scaling group", "On-Demand Instances", "Spot Instances", "Reserved Instances", "Dedicated Instances"], "Commentary": "이 문제는 장기 약정(Reserved Instances) 없이费用을 절감해야 하는 요구사항을 어떻게 충족할지 묻습니다. On-Demand Instances만 사용하면 유연성은 높지만 비용 절감 폭이 크지 않습니다. Spot Instances는 중단 가능성을 감수해야 하지만, 사용하지 않는 EC2 용량을 저렴하게 활용할 수 있으므로 비용 절감 효과가 큽니다. 따라서 일정 부분 On-Demand로 안정성을 확보하고, 나머지를 Spot으로 확보하는 혼합 구성이 장기 약정 없이 비용 최적화를 달성하는 적절한 해법입니다.", "Selections": {"SelectA": {"Select": "Dedicated Instances만 사용", "Commentary": "전용 물리 호스트를 이용하므로 비용이 높고 장기 약정이 없어도 목적에 부합하지 않습니다."}, "SelectB": {"Select": "On-Demand Instances만 사용", "Commentary": "유연성은 좋으나 Spot Instances를 활용하지 않으므로 비용 절감 효과가 제한적입니다."}, "SelectC": {"Select": "On-Demand Instances와 Spot Instances 혼합 사용", "Commentary": "장기 약정 없이 일부 안정성을 확보하면서도 Spot Instances로 높은 비용 절감 효과를 누릴 수 있어 최적입니다."}, "SelectD": {"Select": "On-Demand Instances와 Reserved Instances 혼합 사용", "Commentary": "Reserved Instances 구매 시 장기 약정이 필요하므로 문제의 요구사항인 '장기 약정 없음'에 부합하지 않습니다."}}}
{"Question_Number": "Q291", "Question_Description": "한 미디어 회사는 공개적으로 스트리밍되는 비디오 콘텐츠를 Amazon CloudFront를 통해 제공합니다. 이 회사는 Amazon S3에 호스팅된 비디오 콘텐츠에 대해 접근 권한을 제어해 보안을 강화하고자 합니다. 일부 사용자는 쿠키를 지원하지 않는 커스텀 HTTP 클라이언트를 사용하고, 일부 사용자는 이미 사용 중인 고정된 URL을 변경할 수 없습니다. 사용자에게 미치는 영향을 최소화하며 이 요구사항을 만족하는 서비스나 방법은 무엇입니까? (2개를 고르시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["CloudFront", "쿠키 미지원", "고정된 URL", "접근 보안", "사용자 영향 최소화"], "Terms": ["Signed cookies", "Signed URLs", "AWS AppSync", "JSON Web Token (JWT)", "AWS Secrets Manager"], "Commentary": "이 문제는 CloudFront와 S3 간 콘텐츠 접근 제어를 어떻게 구현할지 묻습니다. 일부 사용자는 쿠키를 지원하지 않고, 일부는 URL 변경이 불가능하므로, Signed cookies와 Signed URLs을 병행 사용해 다양한 상황을 지원하도록 설계해야 합니다. 그 외 솔루션인 AWS AppSync, JWT, AWS Secrets Manager는 요청 로직 변경이나 추가 로직 구현이 필요해 사용자에게 더 많은 영향을 줄 수 있습니다.", "Selections": {"SelectA": {"Select": "Signed cookies", "Commentary": "쿠키를 지원하는 환경에서 URL 변경 없이 접근을 제어할 수 있어, URL 고정 이슈가 있는 사용자 대응에 유리합니다."}, "SelectB": {"Select": "Signed URLs", "Commentary": "쿠키를 지원하지 않는 사용자나 외부 클라이언트에게 개별 URL에 짧은 만료 시간 등을 부여해 안전하게 접근을 제어할 수 있습니다."}, "SelectC": {"Select": "AWS AppSync", "Commentary": "GraphQL 기반 API 서비스를 제공하지만, 기존 URL 구조나 인증 방식 변경이 필요하여 사용자 영향이 큽니다."}, "SelectD": {"Select": "JSON Web Token (JWT)", "Commentary": "JWT는 토큰 기반 인증을 위한 추가 구현이 필요하므로, 크고 작은 코드 수정과 로직 변경이 따라가 사용자에게 부담이 됩니다."}, "SelectE": {"Select": "AWS Secrets Manager", "Commentary": "민감한 정보를 안전하게 저장·관리하는 서비스로, 직접 URL 접근 제어 기능과는 거리가 멀어 해결책으로 적합하지 않습니다."}}}
{"Question_Number": "Q292", "Question_Description": "한 회사가 여러 소스로부터 실시간 스트리밍 데이터로 새 데이터 플랫폼을 준비하고 있습니다. 회사는 Amazon S3에 데이터를 기록하기 전에 데이터를 변환해야 하며, 변환된 데이터에 대해 SQL로 질의할 수 있어야 합니다. 어떤 솔루션들이 이 요구사항을 충족할 수 있습니까? (정답은 두 개를 고르십시오.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["실시간 스트리밍 데이터", "데이터 변환", "Amazon S3", "SQL 질의", "새로운 데이터 플랫폼"], "Terms": ["Amazon Kinesis Data Streams", "Amazon Kinesis Data Analytics", "Amazon Kinesis Data Firehose", "Amazon MSK", "AWS Glue", "Amazon EMR", "AWS DMS", "Amazon S3", "Amazon Athena", "Amazon RDS query editor"], "Commentary": "이 문제는 다수의 소스에서 발생하는 실시간 스트리밍 데이터를 받아 변환한 후, Amazon S3에 저장하고 Athena를 통해 SQL 질의를 수행하는 아키텍처를 설계하는 것입니다. 고성능 스트리밍 처리와 간단한 ETL 과정을 동시에 충족해야 하므로 Kinesis 또는 MSK와 같은 스트리밍 서비스, Kinesis Data Analytics나 Glue와 같은 데이터 변환 서비스, 그리고 최종적으로 S3와 Athena가 결합되어야 합니다. 정답인 A와 B는 모두 실시간 스트리밍, 변환, S3에 저장, 그리고 Athena로 질의가 가능하도록 구성됩니다. 반면 C는 AWS DMS가 주로 데이터베이스 마이그레이션·복제에 초점이 맞춰져 있고, D와 E는 RDS query editor를 사용하는데 이는 S3 저장 데이터를 직접 SQL 질의하는 방식과 어긋납니다.", "Selections": {"SelectA": {"Select": "Amazon Kinesis Data Streams로 데이터를 스트리밍합니다. Amazon Kinesis Data Analytics로 데이터를 변환합니다. Amazon Kinesis Data Firehose로 데이터를 Amazon S3에 기록합니다. Amazon Athena를 사용해 변환된 데이터를 질의합니다.", "Commentary": "Kinesis 서비스 라인업을 활용한 전형적인 실시간 ETL 흐름이며, Athena로 손쉽게 SQL 질의를 수행할 수 있어 요구사항을 완벽히 충족합니다."}, "SelectB": {"Select": "Amazon Managed Streaming for Apache Kafka(Amazon MSK)로 데이터를 스트리밍합니다. AWS Glue를 사용해 데이터를 변환하고, Amazon S3에 기록합니다. Amazon Athena로 변환된 데이터를 질의합니다.", "Commentary": "MSK를 통한 스트리밍과 Glue의 스트리밍 ETL 조합으로 실시간 처리와 변환이 가능하고, Athena로 손쉽게 SQL 질의가 가능합니다."}, "SelectC": {"Select": "AWS Database Migration Service(AWS DMS)로 데이터를 수집합니다. Amazon EMR로 데이터를 변환 후 Amazon S3에 기록합니다. Amazon Athena로 변환된 데이터를 질의합니다.", "Commentary": "AWS DMS는 주로 DB 간 복제·마이그레이션에 특화되어 있으므로, 다수 스트리밍 소스 대상의 실시간 변환 요건에는 부적합합니다."}, "SelectD": {"Select": "Amazon MSK로 데이터를 스트리밍합니다. Amazon Kinesis Data Analytics로 데이터를 변환해 Amazon S3에 기록합니다. Amazon RDS query editor로 S3의 변환된 데이터를 질의합니다.", "Commentary": "RDS query editor는 RDS나 Aurora 같은 DB에 SQL 질의를 수행하는 서비스이므로, S3에 직접 저장된 데이터를 바로 질의하는 요건과 맞지 않습니다."}, "SelectE": {"Select": "Amazon Kinesis Data Streams로 데이터를 스트리밍합니다. AWS Glue로 데이터를 변환합니다. Amazon Kinesis Data Firehose로 Amazon S3에 기록합니다. Amazon RDS query editor로 S3의 변환된 데이터를 질의합니다.", "Commentary": "S3 데이터를 RDS query editor로 직접 질의할 수 없으므로, Athena 대신 RDS query editor를 사용하는 이 방법은 요구사항을 충족하지 못합니다."}}}
{"Question_Number": "Q293", "Question_Description": "한 회사의 온프레미스 볼륨 백업 솔루션이 수명이 다했습니다. 회사는 새로운 백업 솔루션의 일부로 AWS를 사용하고자 하며, AWS로 백업되는 동안에도 모든 데이터에 대한 로컬 액세스를 유지하기를 원합니다. 또한 백업이 AWS로 자동적이고 안전하게 전송되도록 보장해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["로컬 액세스", "자동 백업", "안전한 전송", "온프레미스", "AWS Storage Gateway", "Stored Volume Gateway"], "Terms": ["AWS Snowball", "AWS Snowball Edge", "AWS Storage Gateway", "Cached Volume Gateway", "Stored Volume Gateway", "S3", "백업 솔루션"], "Commentary": "이 문제는 온프레미스 환경에서 AWS로 백업을 진행하면서도 전체 데이터를 로컬에서 그대로 사용할 수 있는 방안을 찾는 것입니다. Stored Volume Gateway는 모든 데이터를 온프레미스에 보관하면서 비동기적으로 AWS에 백업하므로, 요구 사항을 모두 충족하는 최적의 선택입니다.", "Selections": {"SelectA": {"Select": "AWS Snowball을 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. 온프레미스 시스템이 Snowball S3 엔드포인트를 마운트하여 데이터에 로컬로 액세스하도록 구성합니다.", "Commentary": "Snowball은 주로 대용량 데이터 마이그레이션에 사용되며, 지속적인 로컬 액세스를 보장하는 솔루션으로는 적합하지 않습니다."}, "SelectB": {"Select": "AWS Snowball Edge를 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 로컬 액세스를 제공합니다.", "Commentary": "Snowball Edge는 일시적인 오프라인 전송에 유용하나, 상시 백업 및 전송 자동화 그리고 모든 데이터의 상시 로컬 액세스를 장기간 유지하기에는 제한적입니다."}, "SelectC": {"Select": "AWS Storage Gateway를 사용하고 Cached Volume Gateway를 구성합니다. 온프레미스에 Storage Gateway 소프트웨어 어플라이언스를 실행하고 일정 비율의 데이터를 로컬에 캐시하도록 구성합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 로컬로 액세스합니다.", "Commentary": "Cached Volume Gateway는 자주 액세스되는 데이터만 로컬에 두므로 전체 데이터를 로컬에서 모두 이용해야 하는 요구사항과 맞지 않습니다."}, "SelectD": {"Select": "AWS Storage Gateway를 사용하고 Stored Volume Gateway를 구성합니다. 온프레미스에 Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 해당 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 로컬로 액세스합니다.", "Commentary": "Stored Volume Gateway는 모든 데이터를 온프레미스에 보관하면서 AWS로 비동기 백업을 수행하므로, 로컬 액세스와 안전한 백업을 동시에 충족합니다."}}}
{"Question_Number": "Q294", "Question_Description": "Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 Amazon S3 버킷에 액세스해야 합니다. 트래픽은 인터넷을 통과하면 안 됩니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 어떻게 액세스를 구성해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["Amazon EC2 인스턴스", "Amazon S3 버킷", "트래픽 인터넷 미통과", "Gateway VPC endpoint"], "Terms": ["Amazon EC2", "Amazon S3", "Gateway VPC endpoint", "NAT gateway", "AWS Site-to-Site VPN", "Amazon Route 53", "Private hosted zone"], "Commentary": "이 문제는 EC2 인스턴스와 S3 버킷 간의 트래픽이 인터넷을 우회하지 않고 안전하게 내부 경로로만 전달되도록 설정하는 방안을 묻고 있습니다. Gateway VPC endpoint를 사용하면 트래픽이 곧바로 VPC 내부에서 S3와 통신하여 보안과 성능을 모두 만족시킵니다.", "Selections": {"SelectA": {"Select": "Amazon Route 53을 사용하여 private hosted zone을 생성합니다.", "Commentary": "이는 내부 DNS 이름 해석에 사용될 수 있지만, S3로의 트래픽이 인터넷을 우회하게 설정해 주지는 못합니다."}, "SelectB": {"Select": "VPC 내에서 Amazon S3용 Gateway VPC endpoint를 설정합니다.", "Commentary": "Gateway VPC endpoint를 사용하면 EC2 인스턴스가 인터넷에 노출되지 않고 내부적으로 S3와 직접 통신할 수 있습니다. 이 요구사항에 부합하며 정답입니다."}, "SelectC": {"Select": "EC2 인스턴스가 S3 버킷에 액세스하기 위해 NAT gateway를 사용하도록 구성합니다.", "Commentary": "NAT gateway를 사용하면 사설 서브넷에서 인터넷에 나갈 수 있지만, 트래픽은 결국 인터넷을 통해 S3에 도달할 수 있으므로 요구사항에 어긋납니다."}, "SelectD": {"Select": "VPC와 S3 버킷 간에 AWS Site-to-Site VPN 연결을 설정합니다.", "Commentary": "Site-to-Site VPN은 온프레미스와 VPC 간 연결 시 주로 사용됩니다. S3 버킷에 VPN을 직접 연결하는 방식은 일반적이지 않으며 복잡도와 비용이 높습니다."}}}
{"Question_Number": "Q295", "Question_Description": "한 전자 상거래 회사가 AWS Cloud에 테라바이트 규모의 고객 데이터를 저장하고 있습니다. 데이터에는 개인 식별 정보(PII)가 포함되어 있습니다. 이 데이터는 3개의 애플리케이션에서 사용되어야 하며, 이 중 오직 하나의 애플리케이션만이 PII를 처리해야 합니다. 나머지 두 애플리케이션에서 데이터를 처리하기 전에 PII를 제거해야 합니다. 운영 오버헤드를 최소화하면서 이를 구현하려면 어떤 솔루션이 적합합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["개인 식별 정보 제거", "테라바이트 규모 데이터", "운영 오버헤드 최소화", "3개의 애플리케이션"], "Terms": ["PII", "Amazon S3", "S3 Object Lambda", "Amazon DynamoDB", "Proxy application layer", "데이터 변환", "Macie"], "Commentary": "이 문제는 하나의 데이터셋에서 애플리케이션별로 PII 노출을 제어해야 하는 시나리오입니다. Amazon S3 Object Lambda를 사용하면 데이터를 요청하는 시점에 필요한 형태로 변환하여 반환할 수 있어, 애플리케이션별 요구사항(PII 필요 여부)에 따른 처리를 간소화할 수 있습니다. 여러 버킷이나 별도 Proxy 애플리케이션, 혹은 테이블을 운영하는 방법은 관리 부담이 크게 늘어납니다.", "Selections": {"SelectA": {"Select": "데이터를 Amazon DynamoDB 테이블에 저장합니다. 각 애플리케이션이 요청하는 데이터를 가로채어 처리하는 proxy application layer를 생성합니다.", "Commentary": "별도의 프록시 계층을 두는 것은 운영 과정이 복잡해지고 DynamoDB에서 적절히 필터링하기 위한 추가 로직이 필요해 오버헤드가 큽니다."}, "SelectB": {"Select": "데이터를 Amazon S3 버킷에 저장합니다. S3 Object Lambda를 사용해 요청하는 데이터에 대해 처리 및 변환을 수행한 뒤, 변환된 데이터를 요청 애플리케이션에 반환합니다.", "Commentary": "S3 Object Lambda를 이용해 필요할 때만 PII를 제거하여 반환하므로, 별도 데이터 사본을 유지할 필요가 없으며 운영 오버헤드가 최소화됩니다."}, "SelectC": {"Select": "데이터를 처리한 뒤 3개의 별도 Amazon S3 버킷에 변환된 데이터를 각각 저장하고, 각 애플리케이션이 해당 버킷을 사용하도록 설정합니다.", "Commentary": "애플리케이션 수만큼 별도 버킷을 운영하면 데이터 동기화 및 관리가 복잡해지고, 스토리지 및 운영 비용이 증가합니다."}, "SelectD": {"Select": "데이터를 처리한 뒤 3개의 별도 Amazon DynamoDB 테이블에 변환된 데이터를 각각 저장하고, 각 애플리케이션이 해당 테이블을 사용하도록 설정합니다.", "Commentary": "별도의 테이블 세 개를 관리하는 것은 DynamoDB 용량 조절, 동기화 등 운영 부담이 증가하여 오버헤드가 큽니다."}}}
{"Question_Number": "Q296", "Question_Description": "개발 팀이 개발용 VPC 내의 Amazon EC2 인스턴스에서 호스팅되는 새로운 애플리케이션을 출시했습니다. 솔루션스 아키텍트는 같은 계정에 새 VPC를 생성해야 하며, 이 새 VPC는 기존 개발 VPC와 피어링될 예정입니다. 개발 VPC의 CIDR 블록은 192.168.0.0/24입니다. 새 VPC에 대한 CIDR 블록을 생성해야 하며, 개발 VPC와 VPC 피어링 연결이 가능하려면 CIDR 블록이 겹치지 않아야 합니다. 이러한 요구사항을 충족하는 가장 작은 CIDR 블록은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["VPC 피어링", "CIDR 블록", "10.0.1.0/24", "개발 VPC"], "Terms": ["Amazon EC2", "VPC Peering", "CIDR Block", "192.168.0.0/24", "10.0.1.0/24", "/32 Network"], "Commentary": "이 문제는 서로 다른 VPC 간 피어링을 위해 CIDR 블록이 겹치지 않으면서, VPC로서 유효한 최소 크기를 찾아야 한다는 점에 주목해야 합니다. /32는 VPC에 불가능하고, 기존 VPC 대역(192.168.0.0/24)과 겹치지 않으면서 충분한 IP 주소 범위를 제공하는 10.0.1.0/24가 정답입니다.", "Selections": {"SelectA": {"Select": "10.0.1.0/32", "Commentary": "/32는 호스트가 1개만 가능한 너무 작은 네트워크입니다. 유효한 VPC CIDR 블록이 될 수 없습니다."}, "SelectB": {"Select": "192.168.0.0/24", "Commentary": "이미 개발 VPC가 사용하는 CIDR 블록과 동일하여 피어링이 불가능합니다."}, "SelectC": {"Select": "192.168.1.0/32", "Commentary": "/32 역시 네트워크가 1개 호스트만 가능한 사이즈로, 유효한 VPC CIDR 블록이 될 수 없습니다."}, "SelectD": {"Select": "10.0.1.0/24", "Commentary": "기존 VPC 대역과 겹치지 않고, /24로 충분한 IP 주소 수를 제공하므로 새 VPC로 사용하기에 적합합니다."}}}
{"Question_Number": "Q297", "Question_Description": "한 회사는 5개의 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. Application Load Balancer(ALB)는 target group을 사용하여 인스턴스로 트래픽을 분산하고 있습니다. 각 인스턴스의 평균 CPU 사용률은 대부분 10% 미만이지만, 가끔 65%까지 급등합니다. 솔루션스 아키텍트는 애플리케이션의 확장성을 자동화하면서 아키텍처 비용을 최적화하고, 급등 시 애플리케이션에 충분한 CPU 리소스를 보장할 수 있는 솔루션을 구현해야 합니다. 다음 중 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["자동화된 확장", "비용 최적화", "CPU 급등", "EC2 Auto Scaling"], "Terms": ["Amazon EC2", "Application Load Balancer(ALB)", "Target Group", "CPUUtilization", "Amazon CloudWatch", "AWS Lambda", "EC2 Auto Scaling", "ASGAverageCPUUtilization", "Amazon Simple Notification Service(Amazon SNS)"], "Commentary": "이 문제는 애플리케이션이 사용하는 EC2 리소스를 효율적으로 조절하는 방법을 묻습니다. EC2 Auto Scaling과 타겟 추적 스케일링 정책을 사용하면 급등 시 신속히 인스턴스를 늘리고, 평시에는 비용을 절감할 수 있습니다.", "Selections": {"SelectA": {"Select": "CPUUtilization 지표가 20% 미만일 때 ALARM 상태가 되도록 Amazon CloudWatch alarm을 생성하고, 해당 alarm이 AWS Lambda 함수를 호출해 ALB 대상 그룹 내 EC2 인스턴스 하나를 종료하도록 구성합니다.", "Commentary": "CPU 사용률이 낮을 때만 인스턴스를 종료하며, 높은 사용률 시 자동 확장이 없습니다. 스케일 인/아웃 균형을 맞추지 못해 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "EC2 Auto Scaling group을 생성합니다. 기존 ALB와 target group을 선택하고, ASGAverageCPUUtilization 지표 기반 타겟 추적 스케일링 정책을 설정합니다. 최소 인스턴스를 2, 원하는 용량을 3, 최대 인스턴스를 6, 타겟 값을 50%로 지정한 뒤, 기존 EC2 인스턴스들을 Auto Scaling 그룹에 추가합니다.", "Commentary": "타겟 추적 스케일링 정책으로 CPU가 한계에 근접하면 자동으로 인스턴스가 증가하고, 여유 시 축소하여 비용을 절감하므로 요구사항에 부합합니다."}, "SelectC": {"Select": "EC2 Auto Scaling group을 생성합니다. 기존 ALB와 target group을 선택하고, 최소 인스턴스를 2, 원하는 용량을 3, 최대 인스턴스를 6으로 설정합니다. 기존 EC2 인스턴스들을 Auto Scaling 그룹에 추가합니다.", "Commentary": "스케일링 정책이 없어서 CPU 급등 시 자동 확장이 이뤄지지 않습니다. 동적 스케일링이 필요하므로 요구사항을 만족하지 못합니다."}, "SelectD": {"Select": "두 개의 Amazon CloudWatch alarm을 생성합니다. 첫 번째는 평균 CPUUtilization이 20% 미만일 때, 두 번째는 50% 초과일 때 ALARM 상태가 되도록 설정합니다. alarm이 Amazon SNS 토픽으로 이메일을 발송하도록 구성하고, 이메일을 받으면 수동으로 EC2 인스턴스를 줄이거나 늘립니다.", "Commentary": "수동 작업이 필요하여 자동화된 확장이 불가능합니다. 즉각적이고 효율적인 비용 최적화를 이룰 수 없습니다."}}}
{"Question_Number": "Q298", "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스로 구동되는 중요한 비즈니스 애플리케이션을 운영하고 있습니다. 이 EC2 인스턴스들은 Auto Scaling group으로 동작하며, Amazon RDS DB instance에 액세스합니다. 그러나 현재 설계에서는 EC2 인스턴스와 DB instance 모두가 하나의 Availability Zone에만 위치해 있어 운영 검토에서 통과하지 못했습니다. 솔루션스 아키텍트는 두 번째 Availability Zone을 사용하도록 설계를 업데이트해야 합니다. 어떤 솔루션이 애플리케이션을 고가용성으로 만들 수 있습니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["Application Load Balancer", "Amazon EC2", "Auto Scaling group", "Amazon RDS DB instance", "Availability Zone", "Multi-AZ"], "Terms": ["Application Load Balancer", "Amazon EC2", "Auto Scaling group", "Amazon RDS DB instance", "Multi-AZ deployment", "Availability Zone", "subnet"], "Commentary": "이 문제는 단일 Availability Zone에서 호스팅하던 EC2 인스턴스들과 RDS DB instance를 다중 AZ로 구성하여 고가용성을 달성하는 방법에 관한 것입니다. VPC 구성에서 subnet은 반드시 단일 Availability Zone에 속해야 합니다. 또한 RDS DB instance를 Multi-AZ로 설정하면 장애가 발생해도 자동으로 다른 AZ에서 서비스가 지속되므로 다운타임을 크게 줄일 수 있습니다. 이를 통해 EC2 측면과 DB 측면에서 모두 이중화·고가용성을 갖춘 아키텍처로 개선할 수 있습니다.", "Selections": {"SelectA": {"Select": "각 Availability Zone에 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 각 네트워크에 연결되도록 구성합니다.", "Commentary": "DB instance를 단순히 각 네트워크에 연결하는 것만으로는 장애 발생 시 고가용성을 보장하지 못합니다. Multi-AZ 설정이 필요합니다."}, "SelectB": {"Select": "두 AZ에 걸쳐 확장되는 두 개의 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 각 네트워크에 연결되도록 구성합니다.", "Commentary": "subnet은 단일 AZ 안에만 속해야 하므로, 'AZ에 걸쳐 확장되는 subnet'은 유효하지 않습니다."}, "SelectC": {"Select": "각 Availability Zone에 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 Multi-AZ로 구성합니다.", "Commentary": "두 AZ에 각각 subnet을 두어 EC2를 이중화하고, DB instance를 Multi-AZ 설정으로 구성하여 장애 시에도 데이터를 안전하게 보호하고 고가용성을 달성할 수 있는 옳은 솔루션입니다."}, "SelectD": {"Select": "두 AZ에 걸쳐 확장되는 subnet을 하나 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 Multi-AZ로 구성합니다.", "Commentary": "subnet은 단일 AZ 안에만 존재해야 하므로 이 구성이 불가능합니다. Multi-AZ 설정은 적절하지만 subnet 구성 자체가 잘못되었습니다."}}}
{"Question_Number": "Q299", "Question_Description": "한 연구소가 약 8TB의 데이터를 처리해야 합니다. 이 연구소는 스토리지 서브시스템에서 서브밀리초 지연 시간과 최소 6GBps 이상의 처리량을 요구합니다. 수백 대의 Amazon EC2(Amazon Linux) 인스턴스가 이 데이터를 분산 처리할 예정입니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["서브밀리초 지연 시간", "6GBps 처리량", "Amazon FSx for Lustre", "SSD", "Amazon S3", "Amazon EC2", "고성능 저장소"], "Terms": ["Amazon FSx for NetApp ONTAP", "Tiering Policy", "Amazon FSx for Lustre", "Persistent SSD Storage", "Persistent HDD Storage", "Amazon S3", "Amazon EC2", "Amazon Linux"], "Commentary": "이 문제는 고성능 저장소를 요구하는 대용량 데이터 처리 시나리오입니다. 서브밀리초 지연 시간과 6GBps 이상의 처리량을 만족하기 위해서는 SSD 기반 FSx for Lustre가 적합합니다.", "Selections": {"SelectA": {"Select": "Amazon FSx for NetApp ONTAP 파일 시스템을 생성하고, 각 볼륨의 tiering policy를 ALL로 설정한 후 원시 데이터를 가져옵니다. 이후 EC2 인스턴스에서 해당 파일 시스템을 마운트합니다.", "Commentary": "NetApp ONTAP은 뛰어난 기능이 있지만 Lustre SSD만큼의 고성능(6GBps 이상) 달성이 어려워 요구 사항을 만족하기 어렵습니다."}, "SelectB": {"Select": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. SSD 스토리지 유형의 Amazon FSx for Lustre 파일 시스템을 생성하고, S3로부터의 데이터 가져오기 옵션을 활성화한 뒤, EC2 인스턴스에 마운트합니다.", "Commentary": "SSD 기반 FSx for Lustre는 서브밀리초 지연 시간과 6GBps 이상의 처리량을 구현할 수 있으므로 요구 사항을 충족하는 최적의 솔루션입니다."}, "SelectC": {"Select": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. HDD 스토리지 유형의 Amazon FSx for Lustre 파일 시스템을 생성하고, S3로부터의 데이터 가져오기 옵션을 활성화한 뒤, EC2 인스턴스에 마운트합니다.", "Commentary": "HDD는 SSD 대비 지연 시간과 처리량이 낮아 6GBps 요구 사항을 만족하기 어렵습니다."}, "SelectD": {"Select": "Amazon FSx for NetApp ONTAP 파일 시스템을 생성하고, 각 볼륨의 tiering policy를 NONE으로 설정한 후 원시 데이터를 가져옵니다. 이후 EC2 인스턴스에서 해당 파일 시스템을 마운트합니다.", "Commentary": "tiering을 끄면 일부 성능 향상이 가능하지만 FSx for Lustre SSD만큼의 고성능 요구 사항(6GBps)을 달성하기에는 제한이 있습니다."}}}
{"Question_Number": "Q300", "Question_Description": "한 회사는 온프레미스 데이터 센터에서 하드웨어 용량 부족 문제로 인해 레거시 애플리케이션을 AWS Cloud로 마이그레이션해야 합니다. 이 애플리케이션은 연중무휴(24시간, 주7일)로 동작합니다. 데이터베이스 스토리지는 시간이 지날수록 계속 확장됩니다. 가장 비용 효율적인 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2", "4.3"], "Keywords": ["장기 실행 워크로드", "비용 절감", "리저브드 인스턴스", "자동 스토리지 확장", "Aurora"], "Terms": ["Amazon EC2 Spot Instances", "Amazon S3", "Amazon EC2 Reserved Instances", "Amazon RDS On-Demand Instances", "Amazon Aurora Reserved Instances", "Amazon RDS Reserved Instances"], "Commentary": "장기적으로 24시간 상시 구동되는 애플리케이션은 Reserved Instances를 활용하면 큰 비용 절감 효과를 얻을 수 있으며, 스토리지 요구사항이 계속 증가하므로 Amazon Aurora의 자동 확장 기능이 적합합니다.", "Selections": {"SelectA": {"Select": "애플리케이션 계층을 Amazon EC2 Spot Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon S3로 마이그레이션합니다.", "Commentary": "Spot Instances는 저렴하지만 언제든지 인스턴스가 중단될 수 있어 24시간 상시 구동 애플리케이션에는 부적합합니다. 데이터베이스로 S3를 사용하는 것도 일반적이지 않습니다."}, "SelectB": {"Select": "애플리케이션 계층을 Amazon EC2 Reserved Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon RDS On-Demand Instances로 마이그레이션합니다.", "Commentary": "애플리케이션에 Reserved Instances는 적절하나, RDS를 On-Demand로 사용하면 장기적으로 비용이 더 많이 들 수 있습니다."}, "SelectC": {"Select": "애플리케이션 계층을 Amazon EC2 Reserved Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon Aurora Reserved Instances로 마이그레이션합니다.", "Commentary": "24시간 상시 구동 환경에는 Reserved Instances가 비용을 절감해 주고, Aurora의 자동 확장 기능으로 스토리지 요구 증가에도 효율적이며 장기적으로 가장 경제적입니다."}, "SelectD": {"Select": "애플리케이션 계층을 Amazon EC2 On-Demand Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon RDS Reserved Instances로 마이그레이션합니다.", "Commentary": "애플리케이션이 항상 동작하므로 On-Demand보다는 Reserved Instances가 더 적합합니다. 한쪽만 리저브드로 사용하는 것은 최적의 비용 절감에 미치지 못합니다."}}}
{"Question_Number": "Q301", "Question_Description": "한 대학교 연구실이 온프레미스 Windows 파일 서버에 있는 30 TB 데이터를 Amazon FSx for Windows File Server로 마이그레이션해야 합니다. 연구실은 다른 부서와 공유하는 1 Gbps 네트워크 링크를 사용 중이며, 데이터 전송 성능을 최대화하면서도 다른 부서에 미치는 영향(대역폭 사용량)을 제어해야 합니다. 또한 데이터 이전은 5일 안에 완료되어야 합니다. 어떤 AWS 솔루션이 이 요구사항을 충족합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4"], "Keywords": ["Amazon FSx for Windows File Server", "30 TB", "데이터 마이그레이션", "1 Gbps 네트워크", "데이터 전송 대역폭 조절"], "Terms": ["AWS Snowcone", "Amazon FSx File Gateway", "AWS DataSync", "AWS Transfer Family", "Amazon FSx for Windows File Server"], "Commentary": "이 문제는 제한된 네트워크 대역폭을 공유하면서 대용량 데이터를 높은 성능으로 옮겨야 하는 시나리오입니다. AWS DataSync는 네트워크 전송 속도를 조정하고 안정적으로 30 TB를 5일 이내에 전송 가능하므로 가장 적합합니다.", "Selections": {"SelectA": {"Select": "AWS Snowcone을 사용하여 데이터를 이전합니다.", "Commentary": "AWS Snowcone은 물리적 장비이므로 대용량인 30 TB를 신속히 전송하기에는 적합하지 않습니다."}, "SelectB": {"Select": "Amazon FSx File Gateway를 구성해 데이터를 전송합니다.", "Commentary": "FSx File Gateway는 온프레미스 애플리케이션과 FSx를 연결하는 게이트웨이일 뿐, 대역폭 조절과 대규모 데이터 이전에 최적화되지 않았습니다."}, "SelectC": {"Select": "AWS DataSync를 사용하여 데이터를 전송합니다.", "Commentary": "AWS DataSync는 전송 속도를 조절하고 대량 데이터도 네트워크를 통해 빠르게 복사할 수 있어 요구 사항에 부합합니다."}, "SelectD": {"Select": "AWS Transfer Family를 활용해 데이터를 이전합니다.", "Commentary": "AWS Transfer Family는 SFTP, FTP 등의 프로토콜 전송용이므로 대역폭 제어와 대규모 파일 전송 자동화에 적합하지 않습니다."}}}
{"Question_Number": "Q302", "Question_Description": "한 회사는 모바일 기기에서 슬로우 모션 동영상을 스트리밍할 수 있는 모바일 앱을 만들고자 합니다. 현재 앱은 비디오 클립을 촬영한 후 원본(Raw) 형식으로 Amazon S3 버킷에 업로드하고, 사용자는 해당 S3 버킷에서 직접 비디오 클립을 가져와 재생합니다. 그러나 원본 동영상 파일 크기가 커서 모바일 기기에서 버퍼링과 재생 문제가 발생하고 있습니다. 회사는 앱의 성능과 확장성을 극대화하며, 동시에 운영 오버헤드를 최소화할 수 있는 솔루션을 도입하려고 합니다. 다음 중 어떠한 솔루션 조합이 이러한 요구사항을 충족합니까? (두 가지를 고르시오.)", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.4", "3.5"], "Keywords": ["슬로우 모션 동영상", "모바일 스트리밍", "성능 및 확장성", "CloudFront", "Elastic Transcoder"], "Terms": ["Amazon S3", "Amazon CloudFront", "AWS DataSync", "AWS Regions", "Amazon Elastic Transcoder", "Auto Scaling group", "Amazon EC2", "Local Zones"], "Commentary": "이 문제는 큰 원본 동영상을 모바일 환경에 맞게 효율적으로 제공하고 처리하는 방법을 결정하는 문제입니다. CloudFront를 통한 글로벌 캐싱과 Elastic Transcoder를 사용한 포맷 변환이 운영 오버헤드를 낮추면서 성능과 확장성을 극대화하는 최적의 조합입니다.", "Selections": {"SelectA": {"Select": "Amazon CloudFront를 사용해 콘텐츠를 전송하고 캐싱합니다.", "Commentary": "글로벌 엣지 로케이션을 통해 대기 시간을 낮추고 캐싱으로 성능이 개선됩니다. 운영 오버헤드도 낮아서 대용량 동영상 스트리밍에 유리합니다."}, "SelectB": {"Select": "AWS DataSync를 사용해 다른 AWS Regions의 여러 S3 버킷에 동영상 파일을 복제합니다.", "Commentary": "DataSync는 주로 파일 동기화나 복제에 쓰이며 스트리밍 성능 개선에 직접적인 도움이 되지 않습니다."}, "SelectC": {"Select": "Amazon Elastic Transcoder를 사용해 동영상 파일을 더 적합한 형식으로 변환합니다.", "Commentary": "원본 동영상을 모바일 친화적 포맷으로 인코딩해 파일 크기를 줄이고, 재생 품질과 스트리밍 성능을 높일 수 있어 효과적입니다."}, "SelectD": {"Select": "Local Zones에 Auto Scaling group을 구성한 Amazon EC2 인스턴스로 콘텐츠를 전송·캐싱합니다.", "Commentary": "EC2 인스턴스를 직접 설정해 캐싱하는 것은 운영이 복잡해지고, CloudFront를 활용한 글로벌 캐싱만큼 효율적이지 못합니다."}, "SelectE": {"Select": "Auto Scaling group의 Amazon EC2 인스턴스를 사용해 더 적합한 형식으로 동영상을 변환합니다.", "Commentary": "직접 EC2로 트랜스코딩하면 관리 부담과 운영 비용이 커지며, 서비스 확장성도 Elastic Transcoder만큼 간편하지 않습니다."}}}
{"Question_Number": "Q303", "Question_Description": "한 회사가 새로운 애플리케이션을 Amazon ECS 클러스터에 배포하고 있으며, ECS 태스크에는 Fargate launch type을 사용하고 있습니다. 회사는 런칭 시 높은 트래픽이 예상되어 CPU와 메모리 사용량을 모니터링하고 있지만, 사용량이 감소할 때 비용을 절감하고 싶어 합니다. 솔루션스 아키텍트가 권장해야 할 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["Amazon ECS", "Fargate", "자동 확장", "CPU와 메모리", "비용 절감"], "Terms": ["Amazon ECS", "Fargate launch type", "CPU and memory usage", "Amazon EC2 Auto Scaling", "AWS Lambda", "Amazon CloudWatch alarm", "AWS Application Auto Scaling", "Target tracking policy"], "Commentary": "이 문제는 Amazon ECS Fargate를 사용하는 애플리케이션에서 트래픽이 많을 때 확장하고, 트래픽이 적을 때 자동으로 리소스를 축소하여 비용을 절감하고자 하는 시나리오입니다. AWS Application Auto Scaling의 타깃 추적 정책을 사용하면 CPU, 메모리 등의 지표를 기준으로 ECS 태스크 수를 자동으로 조정하여 유연하고 비용 효율적인 아키텍처를 구축할 수 있습니다.", "Selections": {"SelectA": {"Select": "이전 트래픽 패턴을 기준으로 특정 시점에 확장하기 위해 Amazon EC2 Auto Scaling을 사용합니다.", "Commentary": "정해진 스케줄에 따라 확장하므로 실시간 리소스 사용량 반영이 어려워, 트래픽 급증/감소에 즉각적으로 대응하기 어렵습니다."}, "SelectB": {"Select": "AWS Lambda 함수를 사용하여 Amazon CloudWatch 알람을 트리거하는 지표 초과 시 Amazon ECS를 확장합니다.", "Commentary": "Lambda 함수를 직접 작성하고 관리해야 하므로 오버헤드가 늘어납니다. ECS에 대한 자동 확장 관리에 가장 적합한 방식은 아닙니다."}, "SelectC": {"Select": "Amazon EC2 Auto Scaling과 간단한 스케일링 정책을 사용하여 ECS 지표 초과 시 Amazon CloudWatch 알람으로 확장합니다.", "Commentary": "EC2 Auto Scaling은 EC2 인스턴스에 초점을 맞추고 있으며, Fargate 태스크 자동 확장에는 적합하지 않아 운영이 복잡합니다."}, "SelectD": {"Select": "AWS Application Auto Scaling에 타깃 추적 정책을 사용하여 ECS 지표 초과 시 Amazon CloudWatch 알람으로 확장합니다.", "Commentary": "Fargate 태스크에 최적화된 자동 확장을 제공하며 CPU, 메모리 사용률에 따라 빠르게 스케일 업/다운하여 비용을 효율적으로 관리할 수 있는 권장 솔루션입니다."}}}
{"Question_Number": "Q304", "Question_Description": "한 회사가 다른 AWS Region에 재해 복구(Disaster Recovery) 사이트를 최근에 구축했습니다. 이 회사는 주기적으로 두 Region 간 NFS 파일 시스템에 저장된 대용량 데이터를 양방향으로 전송해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족할 수 있는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["NFS 파일 시스템", "재해 복구", "AWS DataSync", "운영 오버헤드 최소화"], "Terms": ["AWS DataSync", "AWS Snowball", "SFTP server on Amazon EC2", "AWS Database Migration Service (AWS DMS)", "NFS file system"], "Commentary": "주기적으로 대규모 데이터를 양방향으로 복제해야 하는 재해 복구 시나리오에서는 자동화와 최소 운영 오버헤드가 핵심입니다. AWS DataSync는 완전관리형 서비스로서, 별도 인프라 구성 없이 대량 데이터를 신속하고 안정적으로 전송하도록 지원합니다.", "Selections": {"SelectA": {"Select": "AWS DataSync를 사용합니다.", "Commentary": "AWS DataSync는 두 Region 간 대규모 파일 전송을 자동화하고 운영 overhead를 최소화합니다. 완전관리형이므로 설정이 간단하고, 주기적인 동기화에도 적합합니다."}, "SelectB": {"Select": "AWS Snowball 디바이스를 사용합니다.", "Commentary": "물리적 디바이스 배송이 필요하며 양방향 전송에도 반복 사용이 번거로워서 운영 오버헤드가 증가합니다."}, "SelectC": {"Select": "Amazon EC2에서 SFTP 서버를 구성합니다.", "Commentary": "직접 서버를 구성·운영해야 하므로 유지보수 부담이 크고 자동화 측면에서 효율적이지 않습니다."}, "SelectD": {"Select": "AWS Database Migration Service(AWS DMS)를 사용합니다.", "Commentary": "AWS DMS는 주로 데이터베이스 마이그레이션에 최적화되어 있으며, 파일 기반의 NFS 전송에는 적합하지 않습니다."}}}
{"Question_Number": "Q305", "Question_Description": "한 회사가 AWS Cloud에 호스팅된 게임 애플리케이션용 공유 스토리지 솔루션을 설계하고 있습니다. 이 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있어야 합니다. 솔루션은 완전관리형(Fully Managed)이어야 합니다. 이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1"], "Keywords": ["게임 애플리케이션", "공유 스토리지", "SMB 클라이언트", "완전관리형"], "Terms": ["AWS DataSync", "Amazon EC2 Windows instance", "Windows file share role", "Amazon FSx for Windows File Server", "Amazon S3", "IAM role"], "Commentary": "이 문제는 SMB 프로토콜을 지원하는 완전관리형 공유 스토리지 솔루션을 구축하는 상황을 묻습니다. Amazon FSx for Windows File Server는 Windows 네이티브 SMB 공유를 완전관리형으로 제공하기 때문에 가장 적합합니다. 다른 옵션들은 직접 서버를 구성하거나 SMB와 호환되지 않거나 관리 부담이 크므로 적합하지 않습니다.", "Selections": {"SelectA": {"Select": "AWS DataSync 작업을 생성하여 데이터를 마운트 가능한 파일시스템으로 공유합니다. 이 파일시스템을 애플리케이션 서버에 마운트합니다.", "Commentary": "AWS DataSync는 데이터 전송 및 동기화 서비스로 SMB 공유를 완전관리형 파일시스템 형태로 제공하지 않으므로 요구사항에 부합하지 않습니다."}, "SelectB": {"Select": "Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 애플리케이션 서버를 파일 공유에 연결합니다.", "Commentary": "EC2 인스턴스에 Windows 파일 공유를 구성하면 사용자가 직접 OS와 파일 서버를 관리해야 하므로 완전관리형 솔루션이 아닙니다."}, "SelectC": {"Select": "Amazon FSx for Windows File Server 파일시스템을 생성합니다. 해당 파일시스템을 원본 서버에 연결합니다. 애플리케이션 서버를 파일시스템에 연결합니다.", "Commentary": "Amazon FSx for Windows File Server는 SMB 프로토콜을 완전히 지원하고 완전관리형이므로 요구사항에 가장 부합하며 올바른 선택지입니다."}, "SelectD": {"Select": "Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM role을 할당하여 S3 버킷에 대한 액세스를 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다.", "Commentary": "Amazon S3는 객체 스토리지로서 SMB 파일 공유 프로토콜을 직접 제공하지 않으며, 완전관리형 SMB 접근 방식과는 거리가 있습니다."}}}
{"Question_Number": "Q306", "Question_Description": "한 회사에서 Amazon EC2 인스턴스에서 실행되는 지연 시간에 민감한 애플리케이션을 위해 in-memory database를 사용하려고 합니다. 이 애플리케이션은 분당 100,000건 이상의 트랜잭션을 처리하며 높은 network throughput이 필요합니다. Solutions Architect는 data transfer charges를 최소화하면서 비용 효율적인 네트워크 설계를 제시해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["인메모리 데이터베이스", "지연 시간 민감", "100,000건 트랜잭션", "높은 네트워크 처리량", "비용 효율적인 네트워크 설계", "데이터 전송 비용 최소화"], "Terms": ["Amazon EC2", "in-memory database", "Availability Zone", "AWS Region", "placement group", "cluster strategy", "partition strategy", "Auto Scaling group", "step scaling policy", "network throughput", "data transfer charges"], "Commentary": "지연 시간에 민감하고 대규모 트랜잭션을 처리하는 환경에서, 동일 AZ에 모아 두고 cluster placement group을 사용하는 것이 비용을 낮추면서도 높은 처리량을 보장하는 핵심 포인트입니다.", "Selections": {"SelectA": {"Select": "동일한 AWS Region의 동일한 Availability Zone에 모든 EC2 인스턴스를 배포합니다. EC2 인스턴스를 시작할 때 cluster strategy가 적용된 placement group을 지정합니다.", "Commentary": "모든 인스턴스를 하나의 AZ와 cluster placement group에 배치하면 네트워크 지연을 최소화하고, AZ 간 트래픽 비용을 피하면서 높은 처리량을 달성할 수 있는 최적의 해법입니다."}, "SelectB": {"Select": "동일한 AWS Region의 서로 다른 Availability Zone에 모든 EC2 인스턴스를 배포합니다. EC2 인스턴스를 시작할 때 partition strategy가 적용된 placement group을 지정합니다.", "Commentary": "서로 다른 AZ에 분산하면 AZ 간 데이터 전송 비용이 증가하고, partition strategy는 동일 AZ 내에서의 높은 처리량을 극대화하기 어렵습니다."}, "SelectC": {"Select": "Auto Scaling group을 설정하여 네트워크 사용량 기준치에 따라 서로 다른 Availability Zone에 EC2 인스턴스를 배포합니다.", "Commentary": "다수의 AZ로 확장되면 AZ 간 트래픽 비용이 증가하고, 지연 시간 및 네트워크 처리량 측면에서도 일관성 유지가 어려워집니다."}, "SelectD": {"Select": "step scaling policy를 적용한 Auto Scaling group을 사용하여 서로 다른 Availability Zone에 EC2 인스턴스를 배포합니다.", "Commentary": "step scaling을 적용해도 Availability Zone이 달라지면 데이터 전송 비용이 늘어나고, 인스턴스 간 네트워크 성능을 극대화하기 어렵습니다."}}}
{"Question_Number": "Q307", "Question_Description": "한 회사는 주로 온프레미스에서 애플리케이션 서버를 운영해 왔습니다. 이 회사는 AWS로 마이그레이션하면서 로컬 iSCSI 스토리지를 확장해야 하는 상황을 최소화하고자 합니다. 이때 최근에 액세스한 데이터만 로컬에 남기길 원합니다. 이러한 요구사항을 만족할 수 있는 AWS 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["온프레미스 iSCSI", "최근에 액세스된 데이터", "AWS Storage Gateway Volume Gateway", "cached volumes"], "Terms": ["AWS Storage Gateway", "Volume Gateway", "Tape Gateway", "cached volumes", "stored volumes", "S3 File Gateway", "Amazon S3", "iSCSI", "마이그레이션"], "Commentary": "회사는 온프레미스 iSCSI 스토리지 확장을 최소화하면서 자주 사용하는 데이터는 로컬에 캐싱하고 싶어 합니다. AWS Storage Gateway Volume Gateway cached volumes는 최근에 액세스한 데이터만 로컬에 저장하고 나머지를 Amazon S3에 보관하여 비용과 운영 부담을 줄이는 최적의 방식입니다.", "Selections": {"SelectA": {"Select": "Amazon S3 File Gateway", "Commentary": "S3 File Gateway는 NFS나 SMB 프로토콜을 사용해 파일 스토리지를 제공하므로 iSCSI 기반으로 최근 데이터만 로컬에 보관하려는 요건과 맞지 않습니다."}, "SelectB": {"Select": "AWS Storage Gateway Tape Gateway", "Commentary": "Tape Gateway는 백업 테이프 환경을 클라우드로 확장하는 솔루션으로, 최근에 자주 사용하는 데이터를 로컬에만 두는 요구사항을 만족하기 어렵습니다."}, "SelectC": {"Select": "AWS Storage Gateway Volume Gateway stored volumes", "Commentary": "Stored volumes 모드는 전체 데이터를 온프레미스에 보관하고 AWS에 백업하므로 로컬 iSCSI 확장을 줄이려는 요구조건과 반대됩니다."}, "SelectD": {"Select": "AWS Storage Gateway Volume Gateway cached volumes", "Commentary": "최근에 액세스된 데이터만 로컬에 캐싱하고 나머지는 Amazon S3에 저장하여 로컬 스토리지 확장을 최소화하는 요구사항을 충족합니다."}}}
{"Question_Number": "Q308", "Question_Description": "한 회사가 통합 청구(Consolidated Billing)를 사용하는 여러 개의 AWS 계정을 보유하고 있습니다. 이 회사는 90일 동안 여러 개의 활성 고성능 Amazon RDS for Oracle 온디맨드(On-Demand) DB 인스턴스를 실행해 왔습니다. 회사의 재무 팀은 통합 청구 계정 및 모든 다른 AWS 계정에서 AWS Trusted Advisor에 접근할 수 있습니다. 재무 팀은 RDS 비용을 절감하기 위해 합리적인 AWS 계정에서 Trusted Advisor 체크 권장 사항을 확인하고, 적절한 Trusted Advisor 체크를 검토해야 합니다. 이 요구사항을 만족하기 위해 재무 팀이 수행해야 할 조합으로 적절한 것은 무엇입니까? (두 가지를 선택하세요.)", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.3"], "Keywords": ["RDS 비용 절감", "온디맨드 인스턴스", "통합 청구", "AWS Trusted Advisor", "활성 DB 인스턴스", "Idle DB Instances 체크"], "Terms": ["Consolidated Billing", "Amazon RDS", "AWS Trusted Advisor", "Oracle On-Demand DB Instances", "Amazon RDS Reserved Instance Optimization", "Amazon RDS Idle DB Instances", "Amazon Redshift Reserved Node Optimization"], "Commentary": "이 문제는 여러 AWS 계정에서 실행되고 있는 On-Demand RDS 인스턴스의 비용을 절감하기 위해 어떤 Trusted Advisor 체크와 어느 계정에서 확인해야 하는지를 묻습니다. 통합 청구 계정을 통해 전체 RDS 사용 현황을 모니터링하고, 유휴(Idle) DB 인스턴스 체크를 통해 불필요한 비용을 절감할 수 있습니다.", "Selections": {"SelectA": {"Select": "RDS 인스턴스가 실제로 실행 중인 계정에서만 Trusted Advisor 권장 사항을 확인합니다.", "Commentary": "각 계정으로 따로 들어가서 확인하는 방식은 비효율적이며, 전체 사용 현황을 한눈에 보기가 어렵습니다. 또한 통합 청구 계정에서 일괄적으로 RDS 체크를 보는 것이 더 적합합니다."}, "SelectB": {"Select": "통합 청구 계정을 사용하여 모든 RDS 인스턴스 체크를 동시에 확인합니다.", "Commentary": "통합 청구 계정에서는 여러 계정에 걸친 자원 사용량과 비용을 한 번에 모니터링할 수 있으므로 전체 RDS 비용 최적화 작업에 유리하며, 정답 중 하나입니다."}, "SelectC": {"Select": "Amazon RDS Reserved Instance Optimization 체크를 검토합니다.", "Commentary": "Reserved Instance 최적화 체크는 유효한 방법이지만, 이 문제의 정답 두 가지 중 하나로 지목되지는 않았습니다. Reference에 따르면 더 긴 기간 사용하거나 다른 체크와 함께 검토할 수 있습니다."}, "SelectD": {"Select": "Amazon RDS Idle DB Instances 체크를 검토합니다.", "Commentary": "오랫동안 유휴 상태로 유지되는 RDS 인스턴스가 있는지 확인하고, 필요 없다면 중지하거나 크기를 줄임으로써 비용 절감이 가능합니다. 정답 중 하나입니다."}, "SelectE": {"Select": "Amazon Redshift Reserved Node Optimization 체크를 검토합니다.", "Commentary": "이 체크는 Amazon Redshift 전용이며, 현재 문제에서 다루는 Amazon RDS 비용 최적화와 직접 관련이 없으므로 오답입니다."}}}
{"Question_Number": "Q309", "Question_Description": "한 Solutions Architect가 스토리지 비용을 최적화해야 합니다. 이 Solutions Architect는 더 이상 사용되지 않거나 거의 사용되지 않는 Amazon S3 버킷을 식별해야 합니다. 가장 적은 운영 오버헤드로 이 목표를 달성할 수 있는 솔루션은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["스토리지 비용 최적화", "Amazon S3 버킷 접근 패턴", "S3 Storage Lens", "운영 오버헤드 최소화"], "Terms": ["S3 Storage Lens", "S3 dashboard", "AWS Management Console", "Amazon CloudWatch BucketSizeBytes metric", "Amazon Athena", "AWS CloudTrail", "Amazon CloudWatch Logs"], "Commentary": "이 문제는 S3 버킷 사용 패턴을 파악하여 비용을 절감하려는 상황에서, 가장 적은 운영 오버헤드로 작동하는 기능을 찾는 것입니다. S3 Storage Lens는 S3 버킷 사용량과 액세스 패턴을 종합적으로 분석하고 보고서를 자동으로 제공하므로, 추가 설정 및 유지 관리 부담이 적습니다.", "Selections": {"SelectA": {"Select": "S3 Storage Lens 대시보드를 사용하여 고급 액티비티 지표로 버킷 액세스 패턴을 분석합니다.", "Commentary": "S3 Storage Lens는 완전관리형 분석 도구로 버킷 액세스 데이터를 간단히 시각화 및 분석 가능하여, 운영 오버헤드를 최소화하며 비용 최적화에 적합합니다."}, "SelectB": {"Select": "AWS Management Console의 S3 대시보드를 사용하여 버킷 액세스 패턴을 분석합니다.", "Commentary": "기본 S3 대시보드는 버킷의 단순 지표만 제공하므로, 고급 액세스 분석이나 장기 사용 통계를 쉽게 확인하기 어렵습니다."}, "SelectC": {"Select": "각 버킷에 대해 Amazon CloudWatch BucketSizeBytes 지표를 활성화하고, Amazon Athena를 사용해 지표 데이터를 분석합니다.", "Commentary": "CloudWatch 및 Athena를 함께 사용하는 것은 설정과 쿼리 작성 등 추가 작업이 필요하여 운영 오버헤드가 높아집니다."}, "SelectD": {"Select": "S3 객체 모니터링을 위해 AWS CloudTrail을 활성화하고, Amazon CloudWatch Logs와 통합된 CloudTrail 로그로 버킷 액세스 패턴을 분석합니다.", "Commentary": "CloudTrail 로그 분석 방식은 설정, 로그 보관 및 분석 절차가 복잡하여 운영 부담이 증가합니다."}}}
{"Question_Number": "Q310", "Question_Description": "한 회사에서 AI/ML 연구를 수행하는 고객들에게 대규모로 포맷된 데이터셋을 판매하고 있습니다. 이러한 데이터셋은 us-east-1 리전의 Amazon S3 버킷에 저장되어 있으며, 회사는 Application Load Balancer 뒤의 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 고객들은 웹 애플리케이션에서 데이터셋 열람권을 구매한 뒤, 해당 파일에 접근할 수 있도록 Amazon S3 signed URL을 받습니다. 고객들은 북미 및 유럽 전역에 분포해 있으며, 회사는 데이터 전송에 드는 비용을 줄이고 성능을 유지하거나 개선하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.4"], "Keywords": ["데이터 전송 비용 절감", "성능 유지 및 개선", "Amazon CloudFront", "S3 signed URL", "Application Load Balancer"], "Terms": ["Amazon S3", "Amazon EC2", "Application Load Balancer", "S3 signed URL", "Amazon CloudFront", "S3 Transfer Acceleration", "Cross-Region Replication"], "Commentary": "이 문제는 전 세계에 분산된 고객에게 대규모 데이터셋을 제공하면서, 데이터 전송 비용을 낮추고 성능을 유지 또는 향상하려는 상황에서 최적의 방법을 찾아야 합니다. Amazon CloudFront는 엣지 로케이션을 통해 데이터를 캐싱하고, 가까운 위치에서 콘텐츠를 전달해 전송 비용을 절감하고 응답 속도를 높입니다. 따라서 CloudFront를 사용해 S3 버킷의 정적 파일을 배포하고 CloudFront signed URL로 보안 액세스를 제어하는 것이 가장 효과적인 접근 방식입니다.", "Selections": {"SelectA": {"Select": "기존 S3 버킷에 S3 Transfer Acceleration을 구성하고, 고객 요청을 해당 가속화 엔드포인트로 유도합니다. 접근 제어에는 계속 S3 signed URL을 사용합니다.", "Commentary": "S3 Transfer Acceleration은 특정 상황에서 전송 속도를 높일 수 있지만, CloudFront보다 전송 비용 절감과 글로벌 성능 향상 측면에서 이점이 작습니다."}, "SelectB": {"Select": "기존 S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 구성합니다. 고객 요청을 CloudFront URL로 유도하고, CloudFront signed URL을 이용해 액세스를 제어합니다.", "Commentary": "전 세계 엣지 로케이션을 통한 캐싱으로 데이터 전송 비용 절감과 성능 개선을 모두 달성할 수 있는 최적의 솔루션입니다."}, "SelectC": {"Select": "eu-central-1 리전에 두 번째 S3 버킷을 생성하고, 두 버킷 간 S3 Cross-Region Replication을 설정합니다. 가장 가까운 리전에 고객 요청을 유도하고, S3 signed URL을 계속 사용합니다.", "Commentary": "리전을 이중화해 지연 시간을 낮추는 효과는 있으나, 전 세계 고객 대상 앞단 캐싱이 없어 비용 절감 효과와 전송 성능 측면에서 부족합니다."}, "SelectD": {"Select": "웹 애플리케이션에서 사용자가 데이터를 스트리밍으로 받을 수 있도록 수정합니다. 웹 애플리케이션이 기존 S3 버킷에서 데이터를 읽도록 설정하고, 애플리케이션 내에서 직접 액세스 제어를 구현합니다.", "Commentary": "데이터 스트리밍 로직을 애플리케이션에 구현하면 복잡성이 증가하고, CloudFront 활용에 비해 전송 비용 및 성능 최적화 효과가 제한적입니다."}}}
{"Question_Number": "Q311", "Question_Description": "한 회사에서 AWS를 사용하여 보험 견적(quote)을 처리하는 웹 애플리케이션을 설계하려고 합니다. 사용자들은 애플리케이션을 통해 견적을 요청합니다. 견적은 견적 유형별로 분리되어야 하고, 24시간 내에 응답해야 하며, 유실되지 않아야 합니다. 또한 운영 효율성을 극대화하고 유지 보수를 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["보험 견적", "견적 유형 분리", "24시간 내 응답", "유실 방지", "운영 효율성", "유지 보수 최소화", "SNS", "SQS", "Message Filtering"], "Terms": ["Amazon Kinesis Data Streams", "Kinesis Client Library (KCL)", "AWS Lambda", "Amazon Simple Notification Service (Amazon SNS)", "Amazon Simple Queue Service (Amazon SQS)", "SNS Message Filtering", "Amazon Kinesis Data Firehose", "Amazon OpenSearch Service"], "Commentary": "이 문제는 메시지를 견적 유형별로 분리하고, 24시간 내에 처리 가능하며, 메시지가 유실되지 않도록 하는 안정적인 메시지 전송 및 소비 구조를 설계하는 것입니다. Amazon SNS와 SQS를 결합하여 SNS Message Filtering을 활용하면, 유지 보수를 최소화하면서도 견적 유형별로 메시지를 효율적으로 분리하고 안정적으로 처리할 수 있습니다.", "Selections": {"SelectA": {"Select": "견적 유형별로 여러 Amazon Kinesis data stream을 생성합니다. 웹 애플리케이션이 적절한 data stream으로 메시지를 전송하도록 구성합니다. 각 백엔드 애플리케이션 서버 그룹은 Kinesis Client Library(KCL)을 사용해 해당 data stream에서 메시지를 풀링합니다.", "Commentary": "Kinesis Data Streams는 실시간 처리에 용이하지만, 견적 유형별 분리 후 메시지 보관이나 24시간 응답 보장에는 추가 고려가 필요해 유지 비용이 더 높아질 수 있습니다."}, "SelectB": {"Select": "각 견적 유형별로 AWS Lambda 함수와 Amazon SNS 주제를 생성합니다. Lambda 함수를 해당 SNS 주제에 구독시킵니다. 애플리케이션에서 적절한 SNS 주제로 견적 요청을 퍼블리시하도록 구성합니다.", "Commentary": "Lambda와 SNS만으로는 메시지 보관 및 긴 대기열 처리가 부족하여 24시간 내 처리 보장에 제약이 있을 수 있으며, 유형별 분리가 더 복잡해질 수 있습니다."}, "SelectC": {"Select": "단일 Amazon SNS 주제를 생성하고, Amazon SQS 대기열들을 SNS 주제에 구독시킵니다. SNS Message Filtering을 사용하여 견적 유형에 따라 적절한 SQS 대기열로 메시지를 전달합니다. 각 백엔드 애플리케이션 서버는 자체 SQS 대기열을 사용합니다.", "Commentary": "SNS와 SQS를 결합하고 Message Filtering을 활용해 견적 유형별로 메시지를 분리하고, 안정적인 메시지 보관과 24시간 내 처리 보장을 모두 충족하는 최적 솔루션입니다."}, "SelectD": {"Select": "견적 유형별로 여러 Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon OpenSearch Service로 데이터를 전송합니다. 애플리케이션에서 올바른 전송 스트림으로 메시지를 보냅니다. 각 백엔드 서버 그룹은 OpenSearch Service에서 메시지를 검색해 처리합니다.", "Commentary": "OpenSearch Service와 Kinesis Data Firehose를 사용해 검색 기능을 제공할 수 있지만, 견적별 보장 처리 및 재시도가 복잡해지고 유지 보수가 늘어납니다."}}}
{"Question_Number": "Q312", "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 각 EC2 인스턴스는 여러 Amazon EBS 데이터 볼륨을 연결해 사용 중입니다. 매일 밤 애플리케이션의 EC2 인스턴스 구성과 데이터를 백업해야 하며, 다른 AWS Region에서도 애플리케이션을 복구할 수 있어야 합니다. 가장 운영 효율성이 높은 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["백업", "Amazon EC2 인스턴스", "EBS 볼륨", "다른 리전 복구", "AWS Backup", "운영 효율"], "Terms": ["AWS Backup", "Amazon EC2", "Amazon EBS", "스냅샷", "Region", "Availability Zone", "AWS Lambda", "백업 플랜"], "Commentary": "이 문제는 EC2 인스턴스의 설정(구성)과 EBS 볼륨 데이터를 함께 백업하고, 다른 리전에서도 신속히 복원해 재해 복구 기능을 확보하는 방법을 묻습니다. AWS Backup을 사용해 EC2 인스턴스 자체를 백업 대상으로 지정하면 인스턴스 구성과 연결된 EBS 볼륨을 함께 백업∙복사할 수 있어 운영 부담을 크게 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "매일 밤 애플리케이션 EBS 볼륨의 스냅샷을 생성하고, 다른 리전으로 스냅샷을 복사하는 AWS Lambda 함수를 작성합니다.", "Commentary": "직접 Lambda 함수를 작성해 스냅샷을 관리해야 하므로 운영 복잡도가 높습니다. 또한 인스턴스 구성이 아닌 EBS 볼륨만 백업합니다."}, "SelectB": {"Select": "AWS Backup을 사용해 백업 플랜을 생성하고, 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다.", "Commentary": "EC2 인스턴스를 대상으로 지정하면 인스턴스 설정과 EBS 볼륨 데이터가 함께 자동 백업되며, 리전 간 복사도 간편하게 설정 가능하여 가장 효율적입니다."}, "SelectC": {"Select": "AWS Backup을 사용해 백업 플랜을 생성하고, 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다.", "Commentary": "EBS 볼륨만 백업 대상이 되어 EC2 인스턴스 구성은 포함되지 않아, 재해 복구 시 완벽한 복원이 어렵습니다."}, "SelectD": {"Select": "매일 밤 애플리케이션 EBS 볼륨의 스냅샷을 생성하고, 다른 가용 영역(Availability Zone)으로 스냅샷을 복사하는 AWS Lambda 함수를 작성합니다.", "Commentary": "AZ 단위 복사는 리전 자체 문제가 발생하면 복구가 어려워 재해 복구에 적합하지 않으며, Lambda 함수를 직접 구현해야 해 운영 부담이 큽니다."}}}
{"Question_Number": "Q313", "Question_Description": "한 회사가 AWS 상에서 모바일 앱을 구축하고 있으며, 수백만 명의 사용자에게 도달하기를 원합니다. 회사는 승인된 사용자만이 모바일 기기에서 회사의 콘텐츠를 시청할 수 있도록 플랫폼을 구축해야 합니다. 이를 위해 솔루션스 아키텍트는 어떤 방법을 권장해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["모바일 앱", "승인된 사용자", "콘텐츠 스트리밍", "CloudFront", "Signed URL"], "Terms": ["Amazon CloudFront", "Signed URLs", "AWS Key Management Service (AWS KMS)", "IPsec VPN", "AWS Client VPN"], "Commentary": "이 문제의 핵심은 대규모 사용자에게 콘텐츠를 제공하면서 오직 승인된 사용자만 접근할 수 있도록 안정적으로 보호하고 확장성 있게 스트리밍하는 것입니다. Amazon CloudFront와 Signed URLs 조합은 글로벌 엣지 로케이션을 통해 빠른 콘텐츠 전송과 안전한 액세스 제어 모두를 충족합니다.", "Selections": {"SelectA": {"Select": "퍼블릭 Amazon S3 버킷에 콘텐츠를 게시하고, AWS KMS 키를 이용해 콘텐츠를 스트리밍합니다.", "Commentary": "S3 버킷을 퍼블릭으로 설정하면 접근 제어가 충분치 않아, 승인되지 않은 사용자도 데이터에 접근할 수 있습니다."}, "SelectB": {"Select": "모바일 앱과 AWS 환경 간 IPsec VPN을 설정하여 콘텐츠를 스트리밍합니다.", "Commentary": "VPN은 대규모 사용자에게 적용하기 어렵고, 각 사용자마다 VPN 연결이 필요하므로 확장성이 떨어집니다."}, "SelectC": {"Select": "Amazon CloudFront를 사용하고, Signed URLs을 제공하여 콘텐츠를 스트리밍합니다.", "Commentary": "전 세계 사용자에게 빠르게 콘텐츠를 제공하면서, Signed URLs로 승인된 사용자만 접근하도록 제한하는 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "모바일 앱과 AWS 환경 간 AWS Client VPN을 설정하여 콘텐츠를 스트리밍합니다.", "Commentary": "Client VPN도 다수 사용자에게 적용하기 복잡하며, 스트리밍 요구에 맞는 확장성을 제공하기 어렵습니다."}}}
{"Question_Number": "Q314", "Question_Description": "한 회사에는 전 세계 세일즈 팀이 사용하며 접근 빈도가 낮은 on-premises MySQL database가 있습니다. 세일즈 팀은 이 데이터베이스가 최소한의 다운타임을 갖기를 요구합니다. 데이터베이스 관리자는 향후 더 많은 사용자가 늘어날 것을 예상하여 특정 인스턴스 타입을 선택하지 않고 이 데이터베이스를 AWS로 마이그레이션하고 싶어 합니다. 솔루션스 아키텍트는 어떤 서비스를 추천해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["온프레미스 MySQL database", "글로벌 세일즈 팀", "드문 접근 패턴", "최소 다운타임", "인스턴스 타입 미선택", "미래 사용자 증가", "Amazon Aurora Serverless for MySQL"], "Terms": ["on-premises MySQL database", "Amazon Aurora MySQL", "Amazon Aurora Serverless for MySQL", "Amazon Redshift Spectrum", "Amazon RDS for MySQL", "minimal downtime", "infrequent access patterns", "serverless"], "Commentary": "이 문제는 on-premises MySQL database를 AWS로 이전하면서도 향후 확장성과 최소 다운타임을 모두 만족하는 해결책을 찾는 것입니다. Amazon Aurora Serverless for MySQL은 인스턴스 타입을 미리 정할 필요 없이 자동으로 확장·축소가 가능하므로 요구사항에 가장 적합합니다.", "Selections": {"SelectA": {"Select": "Amazon Aurora MySQL", "Commentary": "Aurora MySQL은 고성능이지만 인스턴스 타입을 직접 선택해야 하므로 향후 사용자 증가에 대한 자동 확장 측면에서 Serverless 버전만큼 유연하지 않습니다."}, "SelectB": {"Select": "Amazon Aurora Serverless for MySQL", "Commentary": "사용량에 따라 자동으로 확장하고 축소되어 특정 인스턴스 타입을 선택할 필요가 없습니다. 드문 접근 패턴과 증가할 수 있는 사용자 수를 모두 만족할 수 있는 최적의 솔루션입니다."}, "SelectC": {"Select": "Amazon Redshift Spectrum", "Commentary": "Redshift Spectrum은 대규모 데이터 분석에 특화된 솔루션이며, MySQL 호환 DB로의 마이그레이션 및 최소 다운타임 요구사항을 충족하는 데 적절하지 않습니다."}, "SelectD": {"Select": "Amazon RDS for MySQL", "Commentary": "RDS for MySQL은 관리가 간편하지만 인스턴스 타입을 사전에 선택해야 하며, 자동 확장 기능은 Aurora Serverless만큼 유연하지 않습니다."}}}
{"Question_Number": "Q315", "Question_Description": "한 회사는 온프레미스 데이터 센터에서 여러 애플리케이션에 영향을 미치는 침해 사고를 겪었습니다. 공격자는 서버에서 실행 중인 커스텀 애플리케이션의 취약점을 악용했습니다. 이제 이 회사는 애플리케이션을 Amazon EC2 인스턴스에서 실행하도록 마이그레이션하는 중입니다. 이 회사는 EC2 인스턴스에서 활발하게 취약점을 스캔하고, 그 결과를 자세히 알려주는 리포트를 전송하는 솔루션을 구현하기를 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.2"], "Keywords": ["침해 사고", "취약점 스캔", "보고서 전송", "Amazon EC2", "Amazon Inspector"], "Terms": ["AWS Shield", "Amazon Macie", "Amazon GuardDuty", "Amazon Inspector", "AWS Lambda", "AWS CloudTrail", "EC2 인스턴스", "Agent"], "Commentary": "이 문제는 온프레미스 환경에서의 침해 사고를 EC2로 마이그레이션한 뒤에도 재발하지 않도록, 자동으로 취약점을 분석하고 리포트를 제공하는 솔루션을 요구합니다. Amazon Inspector는 EC2 인스턴스의 보안 취약점을 지속적으로 평가하고 결과 리포트를 자동화할 수 있어 적합한 해답이 됩니다.", "Selections": {"SelectA": {"Select": "AWS Shield를 배포하여 EC2 인스턴스를 스캔합니다. AWS Lambda 함수를 생성하여 모든 발견사항을 AWS CloudTrail에 로깅합니다.", "Commentary": "AWS Shield는 DDoS 공격 방어에 특화된 서비스로, 애플리케이션 취약점 스캔 기능은 제공하지 않습니다."}, "SelectB": {"Select": "Amazon Macie와 AWS Lambda 함수를 배포하여 EC2 인스턴스를 스캔합니다. 발견사항을 AWS CloudTrail에 로깅합니다.", "Commentary": "Amazon Macie는 민감 데이터 식별에 중점을 둔 서비스이며, 일반적인 시스템 취약점 스캔 기능은 지원하지 않습니다."}, "SelectC": {"Select": "Amazon GuardDuty를 활성화하고 GuardDuty Agent를 EC2 인스턴스에 배포합니다. AWS Lambda 함수를 구성해 발견사항에 대한 상세 리포트를 자동 생성 및 배포합니다.", "Commentary": "Amazon GuardDuty는 계정 및 네트워크 수준의 위협 탐지 서비스로, 애플리케이션 취약점 분석보다는 이상 트래픽 모니터링에 집중합니다."}, "SelectD": {"Select": "Amazon Inspector를 활성화하고 Amazon Inspector Agent를 EC2 인스턴스에 배포합니다. AWS Lambda 함수를 구성해 발견사항에 대한 상세 리포트를 자동 생성 및 배포합니다.", "Commentary": "Amazon Inspector는 EC2 인스턴스를 대상으로 자동화된 취약점 평가를 수행하고 결과를 리포트로 생성해 운영 측면에서 효율적인 보안 솔루션을 제공합니다."}}}
{"Question_Number": "Q316", "Question_Description": "한 회사는 Amazon EC2 인스턴스를 사용하여 Amazon Simple Queue Service (Amazon SQS) 큐의 메시지를 폴링하고 처리하는 스크립트를 실행하고 있습니다. 이 회사는 큐에 추가되는 증가하는 메시지를 처리할 수 있는 능력을 유지하면서 운영 비용을 절감하기를 원합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트가 권장해야 하는 방법은 무엇입니까?", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.2"], "Keywords": ["운영 비용 절감", "자동 확장", "메시지 처리", "AWS Lambda"], "Terms": ["Amazon EC2", "Amazon SQS", "AWS Lambda", "Amazon EventBridge", "AWS Systems Manager Run Command", "Auto-scaling"], "Commentary": "AWS Lambda로 마이그레이션하면 이벤트 기반으로만 비용을 지불하고, 대규모 메시지가 도착해도 자동으로 확장되어 운영 비용과 관리 부담을 효과적으로 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "EC2 인스턴스의 크기를 늘려 메시지를 더 빠르게 처리하도록 합니다.", "Commentary": "인스턴스 크기를 늘리면 순간 처리 속도는 높아지지만 비용이 급증하고 메시지 양 증가에 따른 자동 확장성이 충분히 보장되지 않습니다."}, "SelectB": {"Select": "Amazon EventBridge를 사용하여 EC2 인스턴스가 과소 활용될 때 인스턴스를 종료하도록 합니다.", "Commentary": "EventBridge 스케줄링으로 인스턴스를 중지하는 것은 일부 비용 절감이 가능하나, 메시지 급증 시 즉시 확장과 자동 처리 기능을 제공하지 못해 한계가 있습니다."}, "SelectC": {"Select": "EC2 인스턴스에서 동작하는 스크립트를 적절한 런타임을 사용하여 AWS Lambda 함수로 마이그레이션합니다.", "Commentary": "AWS Lambda는 이벤트 기반 실행과 자동 확장을 지원하여 증가하는 메시지를 효율적으로 처리하고, 실행한 만큼만 비용을 지불하므로 요구사항에 가장 적합한 솔루션입니다."}, "SelectD": {"Select": "AWS Systems Manager Run Command를 사용하여 스크립트를 온디맨드로 실행합니다.", "Commentary": "온디맨드 실행은 특정 시점에만 처리 가능하며, 메시지 량 증가 시 즉각적인 자동 확장과 비용 효율성을 충분히 담보하지 못하므로 적합하지 않습니다."}}}
{"Question_Number": "Q317", "Question_Description": "한 회사는 오래된(legacy) 애플리케이션으로부터 .csv 형식의 데이터를 생성하고, 이 데이터를 Amazon S3에 저장하고 있습니다. 회사는 Amazon Redshift와 Amazon S3에 저장된 데이터를 대상으로 복잡한 SQL 쿼리를 수행할 수 있는 신규 COTS(상용 오프더셸프) 애플리케이션을 배포하려고 합니다. 하지만 신규 COTS 애플리케이션은 기존 애플리케이션이 생성하는 .csv 파일을 처리할 수 없습니다. 또한 기존 애플리케이션에서 다른 형식을 생성하도록 업데이트하는 것은 불가능합니다. 회사는 신규 COTS 애플리케이션에서 기존 애플리케이션이 생성하는 데이터를 활용할 수 있도록 해야 하며, 이때 운영 오버헤드를 최소화해야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족할 수 있습니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3", "3.5"], "Keywords": ["CSV 형식", "Amazon S3", "Amazon Redshift", "COTS 애플리케이션", "운영 오버헤드 최소화", "ETL"], "Terms": ["AWS Glue", "ETL", "Amazon Redshift", "Amazon S3", "Amazon EMR", "Python 스크립트", "Amazon EC2", "Amazon DynamoDB", "Amazon EventBridge", "크론(cron) 스케줄"], "Commentary": "이 문제는 기존 레거시 애플리케이션이 생성하는 .csv 파일을 Amazon Redshift에서 분석 가능하도록 변환하는 최적의 방법을 찾는 것입니다. 신규 COTS 애플리케이션은 Redshift와 S3만 지원하므로, 자동화된 ETL 파이프라인이 필요합니다. AWS Glue는 완전관리형 ETL 서비스로 스케줄 기반으로 작업을 수행할 수 있어 운영 오버헤드를 최소화합니다.", "Selections": {"SelectA": {"Select": "스케줄에 따라 실행되는 AWS Glue ETL 잡을 생성합니다. .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift에 저장하도록 구성합니다.", "Commentary": "AWS Glue는 자동화된 ETL 파이프라인을 제공하므로 운영 관리를 최소화할 수 있습니다. 적은 노력으로 CSV 데이터를 Redshift 형식으로 변환 가능해 정답입니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스에서 Python 스크립트를 실행하여 .csv 파일을 .sql 형식으로 변환합니다. cron 스케줄을 설정하여 변환 결과 파일을 Amazon S3에 저장합니다.", "Commentary": "개발·배포 및 EC2 인스턴스 관리가 필요해 운영 오버헤드가 큽니다."}, "SelectC": {"Select": "AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트로 Lambda를 트리거해 CSV 파일을 ETL 작업으로 처리하고 DynamoDB에 저장합니다.", "Commentary": "COTS 애플리케이션은 DynamoDB를 지원하지 않아 목적지로 적절치 않으며, 데이터베이스도 Redshift가 필요하므로 부적합합니다."}, "SelectD": {"Select": "Amazon EventBridge로 주간 스케줄에 따라 Amazon EMR 클러스터를 실행합니다. CSV 파일을 ETL 작업으로 처리하여 Amazon Redshift 테이블에 저장하도록 구성합니다.", "Commentary": "EMR 클러스터 설정 및 관리가 필요하므로 Glue보다 운영 오버헤드가 더 큽니다."}}}
{"Question_Number": "Q318", "Question_Description": "한 회사가 최근 IT 환경 전체를 AWS Cloud로 마이그레이션했습니다. 이 회사는 사용자가 적절한 변경 제어 프로세스를 거치지 않고 용량이 과도하게 큰 Amazon EC2 인스턴스를 프로비저닝하고 security group 규칙을 수정하고 있음을 발견했습니다. 솔루션스 아키텍트는 이러한 인벤토리 및 configuration 변경 사항을 추적하고 감사(auditing)할 수 있는 전략을 마련해야 합니다. 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까? (2개를 선택하십시오.)", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1", "1.2"], "Keywords": ["AWS Cloud", "Amazon EC2", "security group", "configuration 변경 추적", "auditing", "compliance"], "Terms": ["AWS CloudTrail", "Amazon EC2", "security group", "AWS Config", "AWS Trusted Advisor", "AWS CloudFormation", "data lifecycle policies", "auditing", "compliance"], "Commentary": "이 문제는 AWS 환경에서 무분별하게 생성·수정되는 자원과 보안 설정을 추적·감사하는 방법을 묻습니다. AWS CloudTrail은 사용자 활동과 API 호출 이력을 기록하여 누가 어떻게 변경했는지 파악하게 해주며, AWS Config는 리소스 설정 변경 내용을 지속적으로 모니터링하고 규칙 기반 평가를 제공해 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "AWS CloudTrail을 활성화하고 이를 auditing에 활용합니다.", "Commentary": "AWS CloudTrail은 계정 내 활동 이력을 기록하여 누가 어떤 작업을 수행했는지 쉽게 추적할 수 있습니다. 보안 이벤트 감시 및 감사에 핵심적인 역할을 하므로 적합합니다."}, "SelectB": {"Select": "Amazon EC2 인스턴스에 data lifecycle policies를 사용합니다.", "Commentary": "data lifecycle policies는 주로 스토리지 관리와 보존 기간 등에 초점을 맞추므로, EC2 인스턴스나 보안 구성 변경 추적 및 감사와는 직접적인 관련이 없습니다."}, "SelectC": {"Select": "AWS Trusted Advisor를 활성화하고 security dashboard를 참고합니다.", "Commentary": "AWS Trusted Advisor는 비용 최적화, 보안 모범 사례 등을 제안하지만, 실시간 변경 추적 및 세부 감사 기능을 직접 제공하지 않으므로 요구사항에 부합하지 않습니다."}, "SelectD": {"Select": "AWS Config를 활성화하고 auditing 및 compliance 목적을 위한 규칙을 생성합니다.", "Commentary": "AWS Config는 리소스 구성 변경 이력을 추적하고 규칙 기반으로 이를 평가할 수 있습니다. 원하는 보안 규칙이나 구성 상태를 정의하면 자동으로 감사와 모니터링이 가능해집니다."}, "SelectE": {"Select": "AWS CloudFormation template을 사용하여 이전 resource configuration을 복원합니다.", "Commentary": "AWS CloudFormation은 리소스 구성 자동화에 유용하지만, 이미 발생한 임의 변경 사항을 추적하고 감사하는 주 기능과는 거리가 멉니다."}}}
{"Question_Number": "Q319", "Question_Description": "한 회사는 AWS Cloud에 수백 개의 Amazon EC2 Linux 기반 instance를 보유하고 있습니다. 시스템 관리자들은 이 instance들을 관리하기 위해 공유 SSH 키를 사용했습니다. 최근 감사 이후, 회사의 보안 팀은 모든 공유 키를 제거하도록 요구했습니다. 솔루션스 아키텍트는 EC2 instance에 대한 안전한 액세스를 제공하는 솔루션을 설계해야 합니다. 가장 적은 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["공유 SSH 키", "EC2 인스턴스", "보안 액세스", "Session Manager", "관리 오버헤드"], "Terms": ["Amazon EC2", "AWS Systems Manager Session Manager", "SSH 키", "AWS Security Token Service (AWS STS)", "Bastion Host", "Amazon Cognito", "AWS Lambda"], "Commentary": "이 문제는 EC2에 대한 안전한 연결 방식을 최소한의 관리 부담으로 구성하는 방법을 묻습니다. Session Manager를 사용하면 SSH 키나 포트를 따로 관리할 필요가 없어 보안과 편의성을 동시에 충족합니다.", "Selections": {"SelectA": {"Select": "AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결합니다.", "Commentary": "Session Manager를 통해 SSH 포트를 열지 않고도 EC2에 안전하게 접속할 수 있으며, 키 관리 필요도 없어 관리 오버헤드가 최소화됩니다."}, "SelectB": {"Select": "AWS Security Token Service(AWS STS)를 사용하여 필요할 때마다 일회용 SSH 키를 생성합니다.", "Commentary": "임시 키를 생성해도 각 사용자별 키를 발급·회수하는 절차가 필요해 관리 오버헤드가 증가합니다."}, "SelectC": {"Select": "Bastion 인스턴스 집합에 공유 SSH 접근을 허용하고, 다른 인스턴스는 bastion 인스턴스에서만 SSH를 허용하도록 구성합니다.", "Commentary": "Bastion 호스트를 따로 운영하고 재설정해야 하므로, 공유 SSH 키 폐지가 충분치 않고 운영 복잡성이 커집니다."}, "SelectD": {"Select": "Amazon Cognito custom authorizer로 사용자 인증 후, AWS Lambda 함수를 호출하여 임시 SSH 키를 생성합니다.", "Commentary": "Cognito와 Lambda 연동 구성이 복잡하며, 임시 키 생성·관리 절차로 인해 관리 부담이 큽니다."}}}
{"Question_Number": "Q320", "Question_Description": "한 회사는 온프레미스 데이터 소스로부터 데이터를 수집하기 위해 여러 Amazon EC2 인스턴스를 사용하고 있습니다. 데이터는 JSON 형식이며, 최대 초당 1MB까지 수집 속도가 가능합니다. EC2 인스턴스가 재부팅될 경우, 전송 중이던 데이터가 손실됩니다. 회사의 데이터 사이언스 팀은 수집된 데이터를 거의 실시간으로 조회하길 원합니다. 최소한의 데이터 손실로 확장 가능하며 거의 실시간으로 데이터를 조회할 수 있는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.5"], "Keywords": ["EC2 인스턴스", "JSON 데이터", "1MB/s", "근실시간 데이터 조회", "데이터 손실 최소화", "확장성"], "Terms": ["Amazon Kinesis Data Streams", "Kinesis Data Analytics", "Amazon Kinesis Data Firehose", "Amazon Redshift", "Amazon S3", "Amazon Athena", "Amazon ElastiCache for Redis", "Amazon EC2", "Amazon EBS", "JSON"], "Commentary": "이 문제는 온프레미스에서 지속적으로 유입되는 데이터를 EC2 인스턴스에서 안전하게 처리하고, 거의 실시간으로 조회하기 위한 방법을 묻습니다. Kinesis Data Streams를 사용하면 데이터를 안정적으로 스트리밍하면서, Kinesis Data Analytics로 실시간 분석이 가능해 데이터 손실을 최소화하고 확장성도 확보할 수 있습니다.", "Selections": {"SelectA": {"Select": "데이터를 Amazon Kinesis Data Streams로 전송하고, Kinesis Data Analytics를 사용하여 데이터를 조회합니다.", "Commentary": "Kinesis Data Streams는 데이터가 빠르게 유입되어도 확장 가능하며, Kinesis Data Analytics를 통해 거의 실시간 데이터 처리가 가능합니다. EC2 인스턴스 재부팅 시에도 데이터 손실이 최소화됩니다."}, "SelectB": {"Select": "데이터를 Amazon Kinesis Data Firehose로 전송하고, 대상은 Amazon Redshift로 설정합니다. Amazon Redshift에서 데이터를 조회합니다.", "Commentary": "Redshift로 대량 데이터 분석은 가능하지만, Firehose 배치는 일정 간격으로 수행되어 실시간성 측면에서 A보다 느리고, 구성 복잡도가 더 높아질 수 있습니다."}, "SelectC": {"Select": "수집된 데이터를 EC2 인스턴스 스토어에 저장한 뒤, Amazon Kinesis Data Firehose를 통해 Amazon S3로 전송합니다. Amazon Athena를 사용해 데이터를 조회합니다.", "Commentary": "인스턴스 스토어는 EC2 인스턴스 종료나 재부팅 시 데이터 유실 위험이 큽니다. S3와 Athena로 조회가 가능하나, 근실시간 처리에는 다소 비효율적입니다."}, "SelectD": {"Select": "수집된 데이터를 Amazon EBS 볼륨에 저장하고, Amazon ElastiCache for Redis에 전송합니다. Redis 채널을 구독하여 데이터를 조회합니다.", "Commentary": "Redis를 실시간 캐시로 활용할 수 있지만, EBS 저장 및 Redis 전송 과정이 복잡하고 재부팅 시 데이터 내구성이 보장되지 않아 손실 위험이 큽니다."}}}
{"Question_Number": "Q321", "Question_Description": "솔루션스 아키텍트가 Amazon S3 버킷에 업로드되는 모든 객체가 반드시 암호화되도록 하려면 어떻게 해야 합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.3"], "Keywords": ["Amazon S3", "암호화", "Bucket Policy", "x-amz-server-side-encryption"], "Terms": ["Bucket Policy", "PutObject", "s3:x-amz-acl", "aws:SecureTransport", "x-amz-server-side-encryption"], "Commentary": "이 문제는 S3 버킷 정책을 통해 객체 암호화를 보장하는 방법을 묻습니다. S3 버킷에 업로드될 때 x-amz-server-side-encryption 헤더가 없으면 요청을 거부하여 반드시 서버 측 암호화를 강제합니다.", "Selections": {"SelectA": {"Select": "PutObject 요청에 s3:x-amz-acl 헤더를 설정하지 않으면 거부하도록 버킷 정책을 업데이트합니다.", "Commentary": "ACL 설정은 객체의 접근 권한을 정의할 뿐, 암호화 적용 여부와 직접적으로 관련이 없어 요구사항을 충족하지 못합니다."}, "SelectB": {"Select": "PutObject 요청에 s3:x-amz-acl 헤더가 private으로 설정되지 않으면 거부하도록 버킷 정책을 업데이트합니다.", "Commentary": "ACL을 private으로 설정하는 것은 접근 제어에 대한 설정이지, 객체 암호화를 강제하지 못하므로 정답이 아닙니다."}, "SelectC": {"Select": "PutObject 요청에 aws:SecureTransport 헤더가 true가 아니면 거부하도록 버킷 정책을 업데이트합니다.", "Commentary": "SecureTransport는 HTTPS 전송을 강제하지만, 암호화 적용(서버 측 암호화)과 직접적인 연관이 없어 정확한 요구사항을 만족시키지 못합니다."}, "SelectD": {"Select": "PutObject 요청에 x-amz-server-side-encryption 헤더가 없으면 거부하도록 버킷 정책을 업데이트합니다.", "Commentary": "서버 측 암호화가 적용되지 않으면 요청을 거부하여 객체가 무조건 암호화되도록 보장하므로 이 옵션이 정답입니다."}}}
{"Question_Number": "Q322", "Question_Description": "한 회사의 Solutions Architect가 다중 계층 애플리케이션을 설계하고 있습니다. 사용자는 모바일 기기에서 이미지를 업로드하며, 애플리케이션은 각 이미지에 대한 썸네일을 생성한 뒤 업로드 성공 메시지를 사용자에게 반환합니다. 썸네일 생성에 최대 60초가 걸릴 수 있지만, 사용자에게 원본 이미지가 성공적으로 접수되었음을 더 빨리 알리고 싶어 합니다. 따라서 애플리케이션은 서로 다른 계층에 비동기 방식으로 요청을 전달할 수 있어야 합니다. 이러한 요구사항을 충족하기 위해 어떤 솔루션을 구성해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1"], "Keywords": ["비동기 처리", "이미지 업로드", "썸네일 생성", "모바일 사용자"], "Terms": ["AWS Lambda", "AWS Step Functions", "Amazon Simple Queue Service (Amazon SQS)", "Amazon Simple Notification Service (Amazon SNS)"], "Commentary": "이 문제는 사용자 요청에 대한 빠른 응답과 뒤에서 진행되는 긴 작업(썸네일 생성)을 분리하는 비동기 아키텍처 설계를 묻습니다. Amazon SQS는 느슨한 결합과 확장성을 제공하여 프런트엔드에서 빠른 응답 이후에 썸네일 생성 작업을 독립적으로 처리할 수 있도록 합니다. 이를 통해 사용자 경험을 개선하면서 애플리케이션 계층 간의 의존성을 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "사용자 이미지 업로드 과정을 이벤트 소스로 하여 커스텀 AWS Lambda 함수를 호출하고, Lambda에서 썸네일을 생성한 뒤 사용자에게 알림을 보냅니다.", "Commentary": "Lambda 하나로 모든 작업을 직접 처리하면 그 자체로는 간단해 보이지만, 썸네일 생성 시간 때문에 응답이 지연될 수 있으며 이벤트 소스 매핑만으로는 원하는 비동기 분리가 충분치 않습니다."}, "SelectB": {"Select": "AWS Step Functions 워크플로우를 생성하고, 애플리케이션 계층 간 오케스트레이션 및 썸네일 생성 완료 후 사용자 알림을 처리하도록 구성합니다.", "Commentary": "Step Functions는 상태 기계 기반 오케스트레이션에 유용하나, 단순 썸네일 생성 트리거에는 오버엔지니어링일 수 있으며 빠른 사용자 응답과 완전한 비동기 처리에 초점을 맞추기에는 복잡합니다."}, "SelectC": {"Select": "Amazon SQS 메시지 큐를 생성하고, 이미지 업로드 시 SQS 큐에 메시지를 넣어 썸네일 생성을 처리합니다. 이후 애플리케이션 메시지로 사용자에게 업로드 완료를 알립니다.", "Commentary": "SQS로 비동기 처리를 구현하면 신속한 사용자 응답 후 백그라운드에서 썸네일을 생성할 수 있어 구조가 단순하고 확장성도 우수합니다."}, "SelectD": {"Select": "Amazon SNS 토픽과 구독을 생성합니다. 하나의 구독으로 이미지 업로드 완료 후 애플리케이션에서 썸네일을 생성하고, 두 번째 구독으로 썸네일 생성 후 모바일 앱에 푸시 알림을 보냅니다.", "Commentary": "SNS는 주로 팬아웃(Fan-out)이나 다중 구독 시나리오에 적합하지만, 여기서는 썸네일 작업 큐로 사용하는 데 오버헤드가 크고 정확한 작업 분리와 큐 관리는 어려울 수 있습니다."}}}
{"Question_Number": "Q323", "Question_Description": "한 회사 시설은 건물 전체의 각 출입구마다 배지 리더기를 설치해 두었습니다. 배지를 스캔하면, 해당 리더기는 누가 그 출입구에 접근했는지 HTTPS를 통해 메시지를 전송합니다. Solutions Architect는 이 센서로부터 오는 메시지를 처리할 시스템을 설계해야 합니다. 이 솔루션은 높은 가용성을 가지며, 결과를 회사의 보안팀이 분석할 수 있도록 제공되어야 합니다. 이러한 요구사항을 충족하는 시스템 아키텍처로 어떤 것을 권장해야 합니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.1", "2.2"], "Keywords": ["배지 리더기", "HTTPS 메시지", "높은 가용성", "보안팀 분석", "API Gateway", "DynamoDB"], "Terms": ["Amazon EC2", "HTTPS endpoint", "Amazon S3", "Amazon API Gateway", "AWS Lambda", "Amazon DynamoDB", "Amazon Route 53", "VPC endpoint", "Site-to-Site VPN"], "Commentary": "이 문제는 각 출입구에서 전송되는 센서 메시지를 안정적으로 처리해야 하는 시나리오입니다. 고가용성과 확장성을 보장하기 위해서는 서버리스 패턴을 사용하는 것이 최적입니다. Amazon API Gateway를 HTTPS endpoint로 구성하고, AWS Lambda에서 메시지를 처리함으로써 자동으로 확장되고 단일 장애 지점을 피할 수 있습니다. 처리 후 결과는 Amazon DynamoDB에 영구 보관되어 보안팀이 쉽게 분석할 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon EC2 인스턴스를 시작하여 HTTPS endpoint 역할과 메시지 처리 역할을 수행하도록 합니다. 그리고 해당 EC2 인스턴스가 처리 결과를 Amazon S3 bucket에 저장하도록 구성합니다.", "Commentary": "단일 Amazon EC2 인스턴스를 사용하면 단일 장애 지점이 생겨 고가용성을 보장하기 어렵습니다."}, "SelectB": {"Select": "Amazon API Gateway에서 HTTPS endpoint를 생성합니다. 그리고 API Gateway endpoint에서 AWS Lambda function을 호출하여 메시지를 처리하고 그 결과를 Amazon DynamoDB table에 저장하도록 구성합니다.", "Commentary": "서버리스 아키텍처로 자동 확장 및 무중단 환경을 제공하므로 고가용성과 확장성을 충족하며 결과도 빠르게 저장하고 분석할 수 있어 가장 적합합니다."}, "SelectC": {"Select": "Amazon Route 53를 사용하여 들어오는 센서 메시지를 AWS Lambda function으로 라우팅합니다. 그리고 Lambda function을 구성하여 메시지를 처리한 후 그 결과를 Amazon DynamoDB table에 저장하도록 합니다.", "Commentary": "Lambda 함수를 직접 Public Internet에 노출하는 것은 권장되지 않는 접근 방식이며, API Gateway가 제공하는 추가 보안 및 제어 기능을 활용하기 어렵습니다."}, "SelectD": {"Select": "Amazon S3를 위한 gateway VPC endpoint를 생성합니다. 시설 네트워크에서 VPC로의 Site-to-Site VPN connection을 설정하여, 센서 데이터가 VPC endpoint를 통해 S3 bucket에 직접 기록될 수 있도록 구성합니다.", "Commentary": "VPN 설정과 VPC endpoint 구성으로 복잡도가 높아지고, 실시간 처리보다는 단순 원시 데이터 저장 방식이므로 요구사항에 적합하지 않습니다."}}}
{"Question_Number": "Q324", "Question_Description": "한 회사는 온프레미스 주요 파일 스토리지 볼륨에 대한 재해 복구(Disaster Recovery) 계획을 구현하려고 합니다. 해당 파일 스토리지 볼륨은 로컬 스토리지 서버의 iSCSI 디바이스에 마운트되어 있으며, 수백TB에 달하는 데이터를 보유하고 있습니다. 회사는 온프레미스 시스템에서 모든 파일 유형에 대해 지연 없이 즉시 액세스가 가능하도록 유지하고 싶어 합니다. 기존 인프라에 대한 변경을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?", "Domain": "복원력을 갖춘 아키텍처 설계", "Tasks": ["2.2"], "Keywords": ["재해 복구", "온프레미스 파일 스토리지", "iSCSI", "수백TB", "지연 없이 즉시 액세스", "AWS Storage Gateway Volume Gateway stored volume"], "Terms": ["Disaster Recovery", "iSCSI", "AWS Storage Gateway", "Amazon S3 File Gateway", "Volume Gateway (cached volume, stored volume)", "Tape Gateway", "Amazon EC2", "Amazon EBS", "NFS", "Snapshot"], "Commentary": "이 문제는 온프레미스 전체 데이터를 완전히 유지하면서 즉시 액세스를 보장할 수 있는 재해 복구 솔루션을 찾는 것입니다. Volume Gateway stored 볼륨은 모든 데이터를 온프레미스에 저장하고, 주기적 스냅샷을 사용해 클라우드로 백업함으로써 로컬 환경에서의 성능 저하 없이 DR을 구현합니다. 재해 발생 시 스냅샷을 Amazon EBS 볼륨으로 복원해 빠르게 서비스를 재개할 수 있어, 기존 인프라 변경이 최소화되면서 즉시 액세스 요건을 충족합니다.", "Selections": {"SelectA": {"Select": "온프레미스에 Amazon S3 File Gateway를 VM으로 프로비저닝하고 로컬 캐시 용량을 10TB로 설정합니다. 기존 애플리케이션이 NFS 프로토콜을 사용하도록 수정하고, 재해 시에는 Amazon EC2 인스턴스를 프로비저닝하여 S3 버킷을 마운트합니다.", "Commentary": "기존 iSCSI 프로토콜 사용 환경을 NFS로 변경해야 하므로 인프라 변경 범위가 큽니다. 전체 데이터를 로컬에 모두 저장하지 않아 즉시 액세스에 제한이 있습니다."}, "SelectB": {"Select": "AWS Storage Gateway tape gateway를 프로비저닝합니다. 데이터 백업 솔루션을 이용해 기존 데이터를 가상 테이프 라이브러리에 백업하고, 수동으로 EBS 볼륨에 복원합니다.", "Commentary": "테이프 백업은 주로 장기 보관용이며, 필요 시 즉시 액세스가 어렵고 복원 과정이 길어지는 단점이 있습니다."}, "SelectC": {"Select": "AWS Storage Gateway Volume Gateway cached volume을 프로비저닝하고 로컬 캐시를 10TB로 설정합니다. iSCSI로 파일 서버에 마운트 후 파일을 복사하고, 스냅샷을 예약합니다. 재해 시 스냅샷을 복원해 Amazon EBS 볼륨으로 사용합니다.", "Commentary": "Cached 볼륨은 자주 액세스하는 데이터를 로컬에 두지만, 전체 데이터를 온프레미스에 보관하지 않아 네트워크 의존도가 커질 수 있고 즉시 액세스에 지연이 발생할 수 있습니다."}, "SelectD": {"Select": "AWS Storage Gateway Volume Gateway stored volume을 기존 파일 스토리지 볼륨만큼 디스크 공간으로 프로비저닝하고, iSCSI로 기존 파일 서버에 마운트합니다. 모든 파일을 저장한 후 스냅샷을 예약합니다. 재해 시 이 스냅샷을 Amazon EBS 볼륨으로 복원해 Amazon EC2 인스턴스에 연결합니다.", "Commentary": "Stored 볼륨은 전체 데이터를 온프레미스에 보관하므로 애플리케이션 수정 없이 즉시 액세스가 가능합니다. DR 시 스냅샷을 통해 신속히 복원할 수 있어 요구 사항을 최적 충족합니다."}}}
{"Question_Number": "Q325", "Question_Description": "한 회사가 Amazon S3 버킷에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon Cognito를 ID 공급자로 사용하여 사용자를 인증하고, 보호된 리소스(다른 S3 버킷에 저장됨)에 액세스할 수 있는 JSON Web Token(JWT)을 반환합니다. 애플리케이션 배포 후, 사용자들은 오류가 발생하여 보호된 콘텐츠에 액세스할 수 없다고 보고했습니다. 솔루션스 아키텍트는 사용자가 보호된 콘텐츠에 액세스할 수 있도록 적절한 권한을 부여해 이 문제를 해결해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["웹 애플리케이션", "Amazon S3", "Amazon Cognito", "JSON Web Token(JWT)", "보호된 콘텐츠", "IAM 역할", "권한"], "Terms": ["Amazon S3", "Amazon Cognito", "JSON Web Token(JWT)", "Identity Pool", "IAM Role", "ACL"], "Commentary": "이 문제는 Amazon Cognito로 인증 후, JWT를 통해 다른 S3 버킷에 있는 보호된 리소스에 액세스할 수 있는 권한 설정이 제대로 되어 있지 않아 발생했습니다. Amazon Cognito Identity Pool이 올바른 IAM 역할을 사용하도록 구성해야만, 인증된 사용자들이 S3 버킷의 보호된 콘텐츠에 접근할 수 있습니다. 이는 Amazon Cognito를 통한 보안 액세스의 핵심 개념이며, 정답은 Identity Pool에 권한을 위임하는 방식으로 해결됩니다.", "Selections": {"SelectA": {"Select": "Amazon Cognito Identity Pool을 업데이트하여 보호된 콘텐츠에 액세스할 수 있는 적절한 IAM 역할을 할당합니다.", "Commentary": "Cognito Identity Pool이 적절한 IAM 역할을 사용하여 인증된 사용자에게 필요한 권한을 부여함으로써 버킷의 보호된 리소스에 접근이 가능합니다."}, "SelectB": {"Select": "S3 ACL을 업데이트하여 애플리케이션이 보호된 콘텐츠에 액세스하도록 허용합니다.", "Commentary": "ACL 단순 수정으로는 사용자 권한이 아닌 객체 수준 정책만 변경될 뿐이므로, Cognito 기반 인증 사용자에게 적절한 권한을 부여하는 근본 해결책이 되지 못합니다."}, "SelectC": {"Select": "Amazon S3에 애플리케이션을 다시 배포하여 Eventually Consistent Reads가 사용자 액세스에 영향을 주지 않도록 합니다.", "Commentary": "재배포나 S3의 일시적 일관성 문제는 권한 부여와 직접적인 관련이 없으므로, 보호된 컨텐츠 접근 문제 해결과는 무관합니다."}, "SelectD": {"Select": "Amazon Cognito Pool에서 커스텀 속성 매핑을 사용하도록 업데이트하고 사용자들에게 보호된 콘텐츠 접속 권한을 부여합니다.", "Commentary": "커스텀 속성 매핑은 사용자 속성만 정의할 뿐, 올바른 IAM 역할 부여와 직접 연결되지 않아 필요한 권한을 제대로 설정하기 어렵습니다."}}}
{"Question_Number": "Q326", "Question_Description": "한 이미지 호스팅 회사가 대용량 에셋을 Amazon S3 Standard 버킷에 업로드하고 있습니다. 해당 회사는 S3 API를 사용하여 multipart upload를 병렬로 수행하며, 같은 객체가 다시 업로드되면 덮어씁니다. 업로드 후 처음 30일 동안은 객체에 대한 액세스가 빈번하게 발생합니다. 30일 이후에는 객체를 덜 사용하지만, 각 객체마다 액세스 패턴이 일관적이지 않습니다. 이 회사는 저장된 에셋의 높은 가용성과 복원력을 유지하면서도 S3 스토리지 비용을 최적화해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트가 추천해야 할 조합은 무엇입니까? (두 가지를 선택하세요.)", "Domain": "비용에 최적화된 아키텍처 설계", "Tasks": ["4.1"], "Keywords": ["Amazon S3 Standard", "multipart upload", "30일 후 액세스 감소", "액세스 패턴 불규칙", "S3 Intelligent-Tiering", "incomplete multipart uploads", "비용 최적화", "높은 가용성", "복원력"], "Terms": ["Amazon S3 Standard", "S3 Intelligent-Tiering", "S3 Standard-Infrequent Access (S3 Standard-IA)", "S3 One Zone-Infrequent Access (S3 One Zone-IA)", "Multipart Upload", "Incomplete Multipart Upload", "Lifecycle Policy"], "Commentary": "이 문제는 S3에 업로드되는 대용량 객체의 액세스 빈도가 30일 이후에 불규칙적으로 감소하는 상황에서, 비용을 효율적으로 줄이면서도 높은 가용성과 복원력을 유지하는 스토리지 전략을 찾는 것입니다. S3 Intelligent-Tiering은 액세스 패턴이 일정치 않은 객체를 자동으로 적절한 티어로 이동시켜 비용과 성능을 모두 만족합니다. 또한 불완전 multipart upload를 자동으로 정리하면 쓸데없이 발생하는 스토리지 비용을 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "30일 후에 S3 Intelligent-Tiering으로 에셋을 이동합니다.", "Commentary": "액세스 패턴이 불규칙한 객체를 자동으로 가장 적절한 티어로 전환해 비용을 절감하면서도 가용성과 복원력을 유지하므로 적합합니다."}, "SelectB": {"Select": "S3 Lifecycle 정책을 구성하여 불완전 multipart upload를 정리합니다.", "Commentary": "병렬로 진행되는 multipart upload 중 불완전하게 남은 파트를 제거함으로써 스토리지 비용을 줄이고 운영 효율성을 높일 수 있습니다."}, "SelectC": {"Select": "S3 Lifecycle 정책으로 만료된 객체 삭제 마커를 정리합니다.", "Commentary": "삭제 마커 정리는 버킷 정리에 유용하지만, 현재 요구사항인 액세스 패턴 최적화와 직접적인 연관이 크지 않습니다."}, "SelectD": {"Select": "30일 후에 S3 Standard-Infrequent Access (S3 Standard-IA)로 에셋을 이동합니다.", "Commentary": "S3 Standard-IA로 전환 시 일관적으로 적은 액세스에 효과적이지만, 불규칙한 패턴에는 Intelligent-Tiering이 더 적합합니다."}, "SelectE": {"Select": "30일 후에 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 에셋을 이동합니다.", "Commentary": "One Zone-IA는 가용 영역 하나만 활용해 복원력이 떨어집니다. 높은 가용성을 유지해야 하므로 적합하지 않습니다."}}}
{"Question_Number": "Q327", "Question_Description": "한 솔루션스 아키텍트가 Amazon EC2 인스턴스를 호스팅하는 VPC 네트워크를 안전하게 구성해야 합니다. 이 EC2 인스턴스들은 매우 민감한 데이터를 포함하고, 프라이빗 서브넷에서 동작하고 있습니다. 회사 정책에 따르면, VPC에서 동작하는 EC2 인스턴스는 소프트웨어 제품 업데이트를 위해 해당 서드파티의 URL을 사용하는 승인된 서드파티 소프트웨어 레포지토리에만 인터넷 접속이 가능해야 합니다. 그 외 모든 인터넷 트래픽은 차단되어야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["VPC 네트워크 보안", "민감한 데이터", "프라이빗 서브넷", "승인된 서드파티 레포지토리", "인터넷 트래픽 차단"], "Terms": ["VPC", "Amazon EC2", "AWS Network Firewall", "domain list rule groups", "AWS WAF", "web ACL", "Application Load Balancer (ALB)", "Security Group", "Private Subnet"], "Commentary": "이 문제는 프라이빗 서브넷 내 민감 데이터를 보유한 EC2 인스턴스가 특정 서드파티 소프트웨어 레포지토리 URL만을 사용하도록 보안 정책을 구성하는 시나리오입니다. AWS Network Firewall을 통해 도메인 기반 아웃바운드 필터링을 수행하면, 승인된 도메인만 허용하고 나머지 인터넷 트래픽을 차단할 수 있어 요구사항을 충족합니다.", "Selections": {"SelectA": {"Select": "프라이빗 서브넷의 라우트 테이블을 업데이트하여 아웃바운드 트래픽을 AWS Network Firewall로 라우팅합니다. 그리고 domain list rule groups를 구성합니다.", "Commentary": "AWS Network Firewall에서 허용된 도메인만 아웃바운드로 접근하게 제어할 수 있으므로, 회사 정책을 가장 효과적으로 만족합니다."}, "SelectB": {"Select": "AWS WAF web ACL을 설정합니다. 소스 및 대상 IP 주소 범위 세트 기반으로 트래픽 요청을 필터링하는 커스텀 규칙 세트를 만듭니다.", "Commentary": "AWS WAF는 주로 웹 어플리케이션 레이어 보호에 적합하며, IP 기반 필터링만으로 특정 도메인만 허용하기는 어렵습니다."}, "SelectC": {"Select": "엄격한 인바운드 보안 그룹 규칙을 구현합니다. 아웃바운드 규칙을 구성하여 인터넷 허가된 소프트웨어 레포지토리로만 트래픽을 허용하도록 URL을 지정합니다.", "Commentary": "보안 그룹은 도메인 이름 기반의 제어가 불가능하므로, URL을 직접 지정해도 원하는 도메인만 필터링하기 어렵습니다."}, "SelectD": {"Select": "Amazon EC2 인스턴스 앞에 Application Load Balancer(ALB)를 구성합니다. 모든 아웃바운드 트래픽을 ALB로 전달하고 ALB의 타겟 그룹에서 URL 기반 룰 리스너를 사용하여 인터넷으로의 아웃바운드 액세스를 제어합니다.", "Commentary": "ALB는 주로 인바운드 트래픽 처리를 위한 로드 밸런싱 서비스이며, 아웃바운드 트래픽 제어에 적합하지 않습니다."}}}
