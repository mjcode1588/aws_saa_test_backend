{"Question_Number": "Q1", "Question_Description": "한 회사가 여러 대륙의 도시들에서 온도, 습도, 대기압 데이터를 수집하고 있습니다. 각 사이트에서 매일 수집하는 평균 데이터 볼륨은 500GB이며, 모든 사이트는 고속 인터넷 연결을 보유하고 있습니다. 회사는 이러한 전 세계 사이트의 데이터를 하나의 Amazon S3 버킷에 가능한 한 빠르게 집계하기를 원합니다. 또한 솔루션은 운영상의 복잡성을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.1", "3.4"], "Keywords": ["Amazon S3", "글로벌 사이트", "고속 업로드", "운영 복잡성 최소화"], "Terms": ["S3 Transfer Acceleration", "Multipart Upload", "S3 Cross-Region Replication (CRR)", "AWS Snowball Edge", "Storage Optimized", "Amazon EBS", "스냅샷"], "Commentary": "이 문제는 전 세계적으로 분산된 사이트에서 대규모 데이터(하루 500GB씩)를 가장 빠르고 단순하게 하나의 S3 버킷으로 모으기 위해 어떤 아키텍처를 사용할지 묻고 있습니다. S3 Transfer Acceleration을 사용하면 Amazon CloudFront의 전 세계 엣지 로케이션을 통해 업로드를 가속화할 수 있으며, Multipart Upload를 이용해 대용량 파일을 여러 부분으로 나누어 병렬로 전송함으로써 업로드 시간을 크게 단축할 수 있습니다. 또한 추가적인 중간 단계를 거치지 않으므로 운영 복잡성이 가장 낮습니다.", "Selections": {"SelectA": {"Select": "대상 S3 버킷에서 S3 Transfer Acceleration을 활성화합니다. Multipart Upload를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다.", "Tasks": ["3.1", "3.4"], "Commentary": "S3 Transfer Acceleration을 통해 전 세계 어디서든 빠른 업로드가 가능하며, Multipart Upload를 함께 사용하면 500GB 이상의 대규모 파일도 병렬 전송으로 전송 시간을 단축할 수 있습니다. 또한 별도의 중간 경로나 운영 단계가 없어 운영 복잡성을 최소화합니다. 따라서 요구사항(전 세계 빠른 업로드, 최소한의 운영 복잡성)에 가장 부합하는 솔루션입니다."}, "SelectB": {"Select": "각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. 그런 다음 S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷에 복제하고, 원본 버킷에서 데이터를 제거합니다.", "Tasks": ["3.1"], "Commentary": "중간 리전에 데이터 업로드 후 Cross-Region Replication으로 복제하는 2단계 프로세스가 필요하여 운영이 복잡해지며, 복제(Replication)에 소요되는 지연 시간 때문에 원하는 만큼 빠른 집계를 보장하기 어렵습니다. 또한 원본 버킷에서 데이터 제거 등의 추가 작업이 필요하므로 운영 복잡성이 증가합니다."}, "SelectC": {"Select": "각 사이트에서 가장 가까운 리전으로 데이터를 전송하기 위해 AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약합니다. 그 후 S3 Cross-Region Replication을 사용하여 객체를 대상 S3 버킷에 복제합니다.", "Tasks": ["3.1"], "Commentary": "AWS Snowball Edge 기기를 사용하면 물리적 장비를 배송하고 받아야 하므로 시간이 오래 걸리며, 이미 사이트에 고속 인터넷 연결이 되어 있는 환경에서는 비효율적입니다. 또한 매일 기기를 주고받는 것은 현실적으로 쉽지 않고 운영 복잡성도 상당히 증가합니다."}, "SelectD": {"Select": "각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스에 업로드하고, Amazon EBS 볼륨에 저장합니다. 정기적으로 EBS 스냅샷을 생성하고 대상 S3 버킷이 있는 리전에 스냅샷을 복사하여, 해당 리전에서 EBS 볼륨을 복원합니다.", "Tasks": ["3.1"], "Commentary": "EC2 인스턴스와 EBS를 사용하고, 스냅샷을 복사하고, 다시 볼륨을 복원한 후 S3에 업로드하는 다단계 과정으로 운영 복잡성이 크게 증가하며, 전송 속도도 S3 Transfer Acceleration을 직접 사용하는 것보다 효율이 떨어집니다. 빠른 집계와 운영 단순성 모두 만족하기 어렵습니다."}}}
{"Question_Number": "Q2", "Question_Description": "한 회사는 자체 애플리케이션에서 생성되는 로그 파일을 분석해야 합니다. 이 로그는 JSON 형식으로 Amazon S3 버킷에 저장되어 있습니다. 쿼리는 단순하며 필요할 때마다(on-demand) 실행될 예정입니다. 솔루션스 아키텍트는 기존 아키텍처에 대한 변경을 최소화하면서 로그를 분석해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하려면 어떻게 해야 합니까?", "Domain": "고성능 아키텍처 설계", "Tasks": ["3.3"], "Keywords": ["Amazon S3", "JSON", "온디맨드 쿼리", "운영 오버헤드 최소화", "기존 아키텍처 최소 변경"], "Terms": {"Question_Description": ["Amazon S3", "JSON", "쿼리(Queries)"], "SelectA": ["Amazon Redshift"], "SelectB": ["Amazon CloudWatch Logs"], "SelectC": ["Amazon Athena"], "SelectD": ["AWS Glue", "Apache Spark", "Amazon EMR"]}, "Commentary": "이 문제는 Amazon S3에 저장된 JSON 형태의 로그를 간단히 분석할 수 있는 방법을 묻습니다. 로그가 이미 S3에 저장되어 있고, 쿼리도 간단하며 온디맨드로 실행하므로, 별도의 복잡한 인프라 구축 없이 즉시 분석할 수 있는 솔루션이 최적의 선택입니다. Amazon Athena는 서버리스 쿼리 서비스로, 데이터를 미리 로드하거나 데이터베이스를 구성하지 않아도 S3에 있는 데이터를 즉시 SQL로 조회할 수 있어 운영 오버헤드를 크게 줄일 수 있습니다.", "Selections": {"SelectA": {"Select": "Amazon Redshift로 모든 로그를 로드한 뒤, 필요한 SQL 쿼리를 실행합니다.", "Commentary": "Amazon Redshift는 강력한 데이터 웨어하우스 솔루션이지만, 데이터를 로드하고 스키마를 정의하는 작업이 필요하며 클러스터 운영 관리 부담이 큽니다. 단순한 온디맨드 쿼리 측면에서 운영 오버헤드를 최소화하지 못합니다."}, "SelectB": {"Select": "Amazon CloudWatch Logs를 사용하여 로그를 저장한 후에, Amazon CloudWatch 콘솔에서 SQL 쿼리를 실행합니다.", "Commentary": "Amazon CloudWatch Logs는 주로 애플리케이션 로그 모니터링 및 지표화에 사용됩니다. SQL 쿼리를 직접 수행하는 목적으로 활용하기에는 기능적 제약이 있으므로 요구사항을 충족하기 어렵습니다."}, "SelectC": {"Select": "Amazon Athena를 Amazon S3에 직접 연결하여 필요한 쿼리를 실행합니다.", "Commentary": "가장 운영 오버헤드가 적은 방식입니다. 서버리스 서비스인 Athena를 사용하면 데이터를 별도로 옮기거나 로드할 필요가 없으며, 직접 S3에 저장된 JSON 로그를AWS Glue Data Catalog와 함께 바로 SQL로 쿼리할 수 있습니다. 쿼리 형태가 단순하고 온디맨드 방식이므로 Athena 사용이 최적의 솔루션입니다."}, "SelectD": {"Select": "AWS Glue로 로그를 카탈로그화하고, Amazon EMR의 일시적(Transient) Apache Spark 클러스터에서 SQL 쿼리를 실행합니다.", "Commentary": "EMR은 큰 규모의 분산 처리와 고급 분석에 유용하지만, 온디맨드로 간단한 쿼리를 실행하기에는 구축 및 운영 과정(클러스터 생성, 관리 등)이 복잡합니다. 운영 오버헤드가 커지므로 요구사항과 맞지 않습니다."}}}
{"Question_Number": "Q3", "Question_Description": "한 회사는 서로 다른 부서별로 여러 AWS 계정을 관리하기 위해 AWS Organizations를 사용하고 있습니다. 관리 계정(Management Account)에는 프로젝트 보고서가 저장된 Amazon S3 버킷이 존재하며, 회사는 이 S3 버킷 조회 권한을 오직 동일한 AWS Organizations 내 계정의 사용자들에게만 허용하고자 합니다. 동시에, 가능한 한 운영 오버헤드를 최소화하는 방법을 찾고 있습니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["AWS Organizations", "Amazon S3", "운영 오버헤드 최소화", "조직 내 계정 제한"], "Terms": ["aws:PrincipalOrgID", "aws:PrincipalOrgPaths", "AWS CloudTrail", "CreateAccount", "InviteAccountToOrganization", "LeaveOrganization", "RemoveAccountFromOrganization", "aws:PrincipalTag"], "Commentary": "이 문제는 AWS Organizations를 사용하여 여러 계정을 중앙에서 관리하는 환경에서, 특정 Amazon S3 버킷에 대한 액세스를 조직 내 계정으로만 제한하는 방법을 묻고 있습니다. 운영 오버헤드를 최소화하면서, 간단하게 조직 내 계정 이외의 액세스를 막으려면 정책에서 글로벌 Condition Key 중 하나인 aws:PrincipalOrgID를 사용하는 것이 핵심입니다. 버킷 정책에 이 조건을 명시하면, 자동으로 AWS Organizations 내 동일 조직에 속한 계정에서 오는 요청만 허용할 수 있으므로, 별도의 태그 관리 또는 복잡한 OU 구조 설정이나 CloudTrail 모니터링 과정이 필요 없습니다. 따라서 가장 간단하고 직관적인 방법은 aws:PrincipalOrgID를 사용하는 것입니다.", "Selections": {"SelectA": {"Select": "S3 버킷 정책에 aws:PrincipalOrgID 글로벌 Condition Key를 추가하고, 조직 ID를 참조하도록 설정합니다.", "Commentary": "aws:PrincipalOrgID를 사용하면, 해당 S3 버킷에 접근하는 주체(principal)가 지정된 조직 ID에 속한 계정인지 자동으로 검사합니다. 별도의 OU 분리나 태그 설정, CloudTrail 이벤트를 기반으로 한 정책 업데이트가 필요 없어 운영 오버헤드가 가장 적습니다. 정답입니다."}, "SelectB": {"Select": "각 부서별로 조직 단위(OU)를 생성합니다. 그리고 aws:PrincipalOrgPaths 글로벌 Condition Key를 S3 버킷 정책에 추가합니다.", "Commentary": "OU 구조를 세분화하고 이를 기반으로 aws:PrincipalOrgPaths를 설정하는 것은 가능하지만 구성 작업이 상대적으로 복잡합니다. 운영적인 부담이 A보다 훨씬 크므로 정답으로 적합하지 않습니다."}, "SelectC": {"Select": "AWS CloudTrail을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization, RemoveAccountFromOrganization 이벤트를 모니터링하고, S3 버킷 정책을 이에 따라 업데이트합니다.", "Commentary": "CloudTrail 이벤트를 실시간으로 모니터링하여 정책을 업데이트하는 것은 유지보수나 모니터링 부담이 매우 큽니다. 단순히 버킷 정책 조건에 조직 ID를 명시하는 방식보다 훨씬 많은 운영 오버헤드가 발생하므로 비효율적입니다."}, "SelectD": {"Select": "S3 버킷 접근이 필요한 각 사용자에게 태그를 부여합니다. 그리고 aws:PrincipalTag 글로벌 Condition Key를 S3 버킷 정책에 추가합니다.", "Commentary": "각 사용자 단위로 태그를 달아 접근을 제어하려면, 태그 관리가 필요해 부서나 계정이 늘어날 때마다 관리가 복잡해집니다. 또한 조직 외부의 사용자가 태그를 보유하게 될 수 있으므로 의도치 않은 액세스를 허용할 위험도 있습니다. 운영 오버헤드가 크므로 최적의 해법이 아닙니다."}}}
{"Question_Number": "Q4", "Question_Description": "어플리케이션이 Amazon EC2 인스턴스에서 VPC 내부에서 실행되고 있습니다. 이 어플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 Amazon S3 버킷에 접근해야 합니다. 이 요구사항을 충족하기 위해 Amazon S3로 사설 네트워크 연결을 제공하는 솔루션은 무엇입니까?", "Domain": "보안 아키텍처 설계", "Tasks": ["1.1"], "Keywords": ["EC2 인스턴스", "VPC", "Amazon S3", "Private Connectivity", "콘솔 접속 없이", "Internet 연결 제한"], "Terms": ["Gateway VPC Endpoint", "Amazon CloudWatch Logs", "Instance Profile", "Amazon API Gateway", "Private Link", "VPC Endpoint"], "Commentary": "이 문제는 VPC 내부에 있는 Amazon EC2 인스턴스가 공용 인터넷 연결 없이 Amazon S3 버킷에 접근해야 하는 상황을 다룹니다. 여러 가지 방법이 있지만, 가장 간단하고 안전하며 사설 연결을 보장하는 것은 Gateway VPC Endpoint를 사용하는 것입니다. 이는 EC2 트래픽이 인터넷으로 나가지 않고도 내부적으로 Amazon S3와 통신할 수 있도록 구성해 주며, 보안 액세스와 관련된 운영 복잡도를 낮춰줍니다.", "Selections": {"SelectA": {"Select": "Gateway VPC Endpoint를 생성하여 S3 버킷에 연결합니다.", "Commentary": "Gateway VPC Endpoint는 VPC 내부에서 Amazon S3로의 전용 통신 경로를 제공하여 트래픽이 인터넷으로 나가지 않고서도 S3에 직접 연결할 수 있게 만듭니다. 추가 비용 없이 안전하게 사설 네트워크 연결을 보장하므로 요구사항에 가장 부합합니다.", "Tasks": ["1.1"]}, "SelectB": {"Select": "로그를 Amazon CloudWatch Logs로 스트림합니다. 그런 다음 해당 로그를 S3 버킷으로 내보냅니다.", "Commentary": "CloudWatch Logs를 통해 로그를 전송하고 다시 S3로 내보내는 것은 간접적 방법이며, CloudWatch로 전달 후 내보내기까지 최대 12시간 지연이 발생할 수 있습니다. 또한 EC2 인스턴스와 S3 간 직통 사설 연결 요구사항을 해결하지 못하므로 적합하지 않습니다.", "Tasks": ["1.1"]}, "SelectC": {"Select": "Amazon EC2에 Instance Profile을 생성하여 S3 액세스를 허용합니다.", "Commentary": "Instance Profile은 EC2 인스턴스가 Amazon S3에 접근할 수 있는 권한을 부여하는 역할(permissions)만 구성합니다. 네트워크 경로 그 자체를 사설로 만드는 것은 아니기에, 인터넷 연결 없이 S3에 연결하는 문제는 해결되지 않습니다.", "Tasks": ["1.1"]}, "SelectD": {"Select": "Amazon API Gateway API를 생성하여 S3 엔드포인트에 접근하기 위한 프라이빗 링크를 설정합니다.", "Commentary": "API Gateway는 주로 HTTPS 기반 요청을 라우팅하거나, Lambda, ELB 등 다양한 AWS 서비스 엔드포인트와 연동하기 위해 사용됩니다. 단순히 EC2 인스턴스가 S3에 사설로 접근하기 위해서는 오버엔지니어링이며, S3와 네트워크를 직접 연결하기 위한 기본적인 기능(예: Gateway VPC Endpoint)을 제공하지 않습니다. 또한 S3용 API Gateway 설정은 이 요구사항에 적절하지 않습니다.", "Tasks": ["1.1"]}}}
