[
  {
    "Question_Number": "Q1",
    "Question_Description": "한 회사가 여러 대륙의 도시들에서 온도, 습도, 대기압 데이터를 수집하고 있습니다. 각 사이트에서 매일 수집하는 평균 데이터 볼륨은 500GB입니다. 각 사이트는 고속 인터넷 연결을 보유하고 있습니다. 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 가능한 한 빠르게 집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 전 세계 지점에서 발생하는 대규모 데이터를 단일 Amazon S3 버킷으로 빠르고 간편하게 업로드하는 방법을 묻고 있습니다. S3 Transfer Acceleration을 사용하면 네트워크 지연을 줄이고, Multipart Upload로 대용량 데이터를 병렬 전송하여 업로드 속도를 높이는 최적의 해법을 구현할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "글로벌 사이트",
      "500GB",
      "고속 인터넷",
      "운영 복잡성",
      "Amazon S3",
      "S3 Transfer Acceleration",
      "Multipart Upload"
    ],
    "Terms": [
      "S3 Transfer Acceleration",
      "Multipart Upload",
      "S3 Cross-Region Replication",
      "AWS Snowball Edge",
      "Amazon EBS",
      "EBS Snapshot"
    ],
    "SelectA": "대상 S3 버킷에서 S3 Transfer Acceleration을 활성화하고, Multipart Upload를 사용해 사이트 데이터를 직접 업로드합니다.",
    "SelectA_Commentary": "S3 Transfer Acceleration은 글로벌 Edge Location을 통해 빠른 업로드를 가능하게 하며, Multipart Upload와 결합하면 대용량 파일도 병렬로 효과적으로 업로드할 수 있어 요구사항을 가장 잘 충족합니다.",
    "SelectB": "가장 가까운 리전의 S3 버킷에 데이터를 업로드하고, S3 Cross-Region Replication으로 대상 S3 버킷에 복제한 후 원본 버킷에서 데이터를 제거합니다.",
    "SelectB_Commentary": "중간 S3 버킷을 활용한 복제 프로세스는 추가 단계가 많아 운영이 복잡해지며, 복제 지연이 발생해 데이터를 즉시 집계하기 어려워집니다.",
    "SelectC": "AWS Snowball Edge Storage Optimized 디바이스를 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송하고, S3 Cross-Region Replication으로 대상 버킷에 복제합니다.",
    "SelectC_Commentary": "Snowball Edge는 물리적 장비 운송이 필요해 시간이 오래 걸리며 이미 고속 인터넷이 있는 환경에서는 오버엔지니어링으로 운영 복잡성이 커집니다.",
    "SelectD": "가장 가까운 리전의 Amazon EC2 인스턴스에 데이터를 업로드하고, Amazon EBS 볼륨에 저장합니다. 정기적으로 EBS 스냅샷을 생성해 대상 S3 버킷이 있는 리전으로 복사하고 필요 시 EBS 볼륨을 복원합니다.",
    "SelectD_Commentary": "EC2, EBS, 스냅샷 복사 등 단계가 많아 복잡하며, 바로 S3에 업로드하는 것보다 지연이 늘어나고 관리 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q397",
      "Q43",
      "Q501",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q38",
      "Q680",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q672",
      "Q501",
      "Q155"
    ],
    "SelectC_recommedations": [
      "Q702",
      "Q38",
      "Q620"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q155",
      "Q41"
    ]
  },
  {
    "Question_Number": "Q2",
    "Question_Description": "한 회사는 자체 애플리케이션의 로그 파일을 분석해야 합니다. 로그는 JSON 형식으로 Amazon S3 버킷에 저장되어 있습니다. 쿼리는 간단하며 필요할 때마다 실행될 예정입니다. 솔루션스 아키텍트는 기존 아키텍처에 최소한의 변경으로 분석을 수행해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84848-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 Amazon S3에 저장된 JSON 로그 데이터를 최소한의 변경으로 즉시 분석해야 하는 시나리오입니다. Athena를 사용하면 추가 인프라 구성 없이 S3에 직접 쿼리를 실행할 수 있고, 서버리스 방식으로 운영 오버헤드가 매우 적습니다. 따라서 각 선택지 중 가장 간단하고 효율적인 해법을 제공하는 C가 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "Amazon S3",
      "JSON 로그",
      "분석",
      "운영 오버헤드 최소화",
      "온디맨드 쿼리"
    ],
    "Terms": [
      "Amazon Redshift",
      "Amazon CloudWatch Logs",
      "Amazon Athena",
      "AWS Glue",
      "Apache Spark",
      "Amazon EMR",
      "SQL 쿼리",
      "JSON"
    ],
    "SelectA": "Amazon Redshift를 사용해 모든 데이터를 한 곳으로 로드하고, 필요할 때 SQL 쿼리를 실행합니다.",
    "SelectA_Commentary": "Redshift 클러스터 구성, 관리, 로드 작업이 필요해 운영 오버헤드가 높고 초기 설정이 복잡합니다.",
    "SelectB": "Amazon CloudWatch Logs에 로그를 저장하고, 콘솔에서 SQL 쿼리를 필요할 때 실행합니다.",
    "SelectB_Commentary": "CloudWatch Logs는 로그 수집 및 모니터링에 적합하지만, S3에 이미 저장된 JSON을 직접 분석하기엔 적합하지 않습니다.",
    "SelectC": "Amazon Athena를 사용해 Amazon S3에 직접 쿼리를 실행합니다.",
    "SelectC_Commentary": "서버리스 기반으로, 기존 데이터가 저장된 S3에 대해 바로 SQL 쿼리를 수행할 수 있어 설정과 운영이 간단하며, 필요할 때만 비용이 발생하는 가장 효율적인 방법입니다.",
    "SelectD": "AWS Glue로 로그를 카탈로그하고, Amazon EMR의 일시적 Apache Spark 클러스터로 필요 시 SQL 쿼리를 실행합니다.",
    "SelectD_Commentary": "EMR 클러스터를 설정하고 Glue 카탈로그와 연동하는 과정이 필요하며, Athena보다 운영 부담과 비용이 높습니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q501",
      "Q43",
      "Q166",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q117",
      "Q292",
      "Q834"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q910",
      "Q33",
      "Q386"
    ]
  },
  {
    "Question_Number": "Q3",
    "Question_Description": "한 회사가 여러 부서별로 다른 AWS 계정을 관리하기 위해 AWS Organizations를 사용하고 있습니다. 관리 계정에는 프로젝트 보고서가 들어 있는 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 오직 조직 내 계정(=AWS Organizations에 속한 계정)의 사용자만 접근할 수 있도록 제한하고자 합니다. 가장 적은 운영 오버헤드를 들이면서 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84838-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 여러 AWS 계정으로 구성된 조직에서 특정 S3 버킷을 오직 조직 내 계정만 접근하도록 설정하는 방법을 묻습니다. 조직 ID를 활용해 S3 버킷 정책에서 aws:PrincipalOrgID 키를 사용하면, 심플하고 효율적으로 조직 내 모든 계정 사용자에게만 접근을 허용할 수 있습니다. 다른 옵션들은 조직 구조 변경, CloudTrail 이벤트 모니터링, 사용자 태깅 등 추가 관리 작업이 많아 운영 오버헤드가 증가합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "S3 버킷 접근 제한",
      "AWS Organizations",
      "aws:PrincipalOrgID",
      "조직 내 계정",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Organizations",
      "Amazon S3",
      "aws:PrincipalOrgID",
      "aws:PrincipalOrgPaths",
      "AWS CloudTrail",
      "aws:PrincipalTag"
    ],
    "SelectA": "S3 버킷 정책에 aws:PrincipalOrgID 글로벌 컨디션 키를 조직 ID로 참조하도록 추가합니다.",
    "SelectA_Commentary": "조직 내 계정임을 쉽게 검증하므로 유지보수가 최소화되고 접근 제어가 간편합니다. 정답입니다.",
    "SelectB": "각 부서별로 조직 단위(OU)를 만들고, aws:PrincipalOrgPaths 글로벌 컨디션 키를 S3 버킷 정책에 추가합니다.",
    "SelectB_Commentary": "OU를 세분화하고 정책을 관리해야 하므로 추가 설정과 관리 비용이 늘어납니다.",
    "SelectC": "AWS CloudTrail로 CreateAccount, InviteAccountToOrganization, LeaveOrganization, RemoveAccountFromOrganization 이벤트를 모니터링하고 버킷 정책을 그때그때 업데이트합니다.",
    "SelectC_Commentary": "계정 변동이 발생할 때마다 직접 정책을 수정해야 하므로 운영이 복잡해집니다.",
    "SelectD": "S3 버킷 접근이 필요한 각 사용자를 태깅하고, aws:PrincipalTag 글로벌 컨디션 키를 S3 버킷 정책에 추가합니다.",
    "SelectD_Commentary": "필요 사용자마다 태그를 꾸준히 관리해야 하므로 계정이 늘어날수록 오버헤드가 커집니다.",
    "Question_Description_recommedations": [
      "Q945",
      "Q168",
      "Q270",
      "Q412",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q3",
      "Q965",
      "Q270"
    ],
    "SelectB_recommedations": [
      "Q3",
      "Q965",
      "Q889"
    ],
    "SelectC_recommedations": [
      "Q619",
      "Q748",
      "Q524"
    ],
    "SelectD_recommedations": [
      "Q202",
      "Q270",
      "Q412"
    ]
  },
  {
    "Question_Number": "Q4",
    "Question_Description": "한 애플리케이션이 VPC 내의 Amazon EC2 인스턴스에서 실행 중입니다. 해당 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 인터넷 연결 없이 S3 버킷에 접근해야 합니다. Amazon S3에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84980-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 VPC 내 EC2 인스턴스가 인터넷 없이 Amazon S3 버킷에 접근해야 하는 상황입니다. Gateway VPC endpoint를 사용하면 사설 경로를 통해 S3와 안전하게 통신할 수 있으므로 비용 부담도 적고 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "인터넷 없이",
      "프라이빗 네트워크 연결",
      "Amazon S3",
      "VPC Endpoint"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC",
      "Amazon S3",
      "Gateway VPC endpoint",
      "CloudWatch Logs",
      "Instance profile",
      "Amazon API Gateway"
    ],
    "SelectA": "S3 버킷에 대한 Gateway VPC endpoint를 생성합니다.",
    "SelectA_Commentary": "Gateway VPC endpoint는 S3에 대한 사설 경로를 제공하여 인터넷 연결 없이도 버킷에 안전하게 액세스할 수 있습니다.",
    "SelectB": "Amazon CloudWatch Logs로 로그를 스트리밍한 뒤, 이를 S3 버킷에 내보냅니다.",
    "SelectB_Commentary": "CloudWatch Logs는 로그 집계에 유용하지만, S3와의 직접적인 사설 연결을 제공하지 않아 요구사항을 충족하기 어렵습니다.",
    "SelectC": "Amazon EC2 인스턴스에 Instance profile을 생성하여 S3 접근을 허용합니다.",
    "SelectC_Commentary": "Instance profile은 권한만 부여할 뿐, 인터넷 없이 S3 버킷에 연결할 프라이빗 경로를 제공하지 않습니다.",
    "SelectD": "Amazon API Gateway API를 사용해 S3 엔드포인트에 대한 프라이빗 링크를 만듭니다.",
    "SelectD_Commentary": "API Gateway는 S3에 대한 직접적이고 효율적인 사설 연결 방식이 아니므로 적절한 선택지가 아닙니다.",
    "Question_Description_recommedations": [
      "Q980",
      "Q866",
      "Q92",
      "Q91",
      "Q710"
    ],
    "SelectA_recommedations": [
      "Q92",
      "Q91",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q678",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q612",
      "Q92"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q185",
      "Q862"
    ]
  },
  {
    "Question_Number": "Q5",
    "Question_Description": "회사는 단일 Amazon EC2 인스턴스를 사용하여 웹 애플리케이션을 AWS에서 호스팅하고 있으며, 사용자 업로드 문서를 Amazon EBS 볼륨에 저장하고 있습니다. 더 나은 확장성과 가용성을 위해 회사는 동일한 아키텍처를 복제하여 두 번째 EC2 인스턴스와 EBS 볼륨을 다른 Availability Zone에 생성하고, 둘 다 Application Load Balancer 뒤에 배치했습니다. 이 변경을 마친 후, 사용자가 웹사이트를 새로고침할 때마다 어느 순간에는 특정 문서 집합만 보이고, 다른 순간에는 다른 문서 집합만 보이지만 동시에 모든 문서를 볼 수는 없다고 보고했습니다. 사용자가 모든 문서를 한꺼번에 볼 수 있도록 하기 위해 솔루션스 아키텍트는 어떤 제안을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84981-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 다중 AZ 환경에서 여러 EC2 인스턴스가 동일한 파일에 접근해야 할 때 공유 스토리지가 필요한 상황을 묻습니다. Amazon EFS를 사용하면 모든 인스턴스에서 실시간으로 동일한 데이터를 볼 수 있어 문제를 해결할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "다중 AZ",
      "공유 스토리지",
      "Amazon EBS",
      "Amazon EFS",
      "문서 접근",
      "가용성",
      "확장성"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Application Load Balancer",
      "Availability Zone",
      "Amazon EFS"
    ],
    "SelectA": "두 EBS 볼륨 모두 모든 문서를 포함하도록 데이터를 복사합니다.",
    "SelectA_Commentary": "각 볼륨의 데이터를 계속 동기화해야 하므로 운영이 복잡하며, 새 문서가 추가될 때마다 실시간 일관성을 보장하기 어렵습니다.",
    "SelectB": "Application Load Balancer가 문서를 갖고 있는 서버로 사용자를 보내도록 구성합니다.",
    "SelectB_Commentary": "사용자를 문서를 가진 서버로만 연결해도 두 서버의 문서가 각각 다르다면 모든 문서를 동시에 보는 문제는 해결되지 않습니다.",
    "SelectC": "두 EBS 볼륨의 데이터를 Amazon EFS로 복사하고, 애플리케이션이 새 문서를 Amazon EFS에 저장하도록 수정합니다.",
    "SelectC_Commentary": "Amazon EFS는 여러 AZ에서 동시에 접근할 수 있는 공유 파일 시스템이므로, 모든 인스턴스에서 동일한 데이터를 즉시 볼 수 있어 근본적인 문제를 해결하는 최적의 방법입니다.",
    "SelectD": "Application Load Balancer가 요청을 두 서버로 모두 보내도록 구성하고, 각 서버에서 적절한 문서를 반환합니다.",
    "SelectD_Commentary": "두 서버가 가진 문서를 합쳐 보여주려 해도 실시간 동기화 없이 서로 다른 볼륨에 분산된 데이터를 동시에 일관성 있게 제공하기는 어렵습니다.",
    "Question_Description_recommedations": [
      "Q639",
      "Q312",
      "Q602",
      "Q275",
      "Q246"
    ],
    "SelectA_recommedations": [
      "Q58",
      "Q917",
      "Q615"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q357",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q602",
      "Q194",
      "Q892"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q357",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q6",
    "Question_Description": "한 회사가 사내 NFS(Network File System)를 사용하여 대용량 동영상 파일을 저장하고 있습니다. 각 동영상 파일은 1MB부터 500GB까지 다양하며, 총 70TB의 스토리지가 있고 더 이상 증가하지 않습니다. 회사는 이 동영상 파일들을 가능한 한 빨리, 그리고 네트워크 대역폭 사용을 최소화하면서 Amazon S3로 마이그레이션하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84875-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 온프레미스 NFS 스토리지에 보관된 대용량 데이터를 짧은 시간 안에, 그리고 네트워크 사용량을 최소화해서 Amazon S3로 옮기는 방법을 묻습니다. 네트워크 활용도를 고려하면 물리적 장비를 통한 오프라인 전송이 유리하며, Snowball Edge를 통해 대규모 데이터를 효율적으로 마이그레이션할 수 있습니다. 직접 Network 연결 방식인 Direct Connect나 S3 File Gateway를 통한 온라인 전송은 대역폭을 많이 소모하거나 전송 시간이 길어질 수 있으므로, 오프라인 전송이 최적의 선택입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "NFS",
      "동영상 파일",
      "70TB",
      "Amazon S3",
      "마이그레이션",
      "네트워크 대역폭 최소화",
      "최대한 빠른 전송",
      "AWS Snowball Edge"
    ],
    "Terms": [
      "NFS",
      "Amazon S3",
      "AWS Snowball Edge",
      "IAM role",
      "AWS CLI",
      "S3 File Gateway",
      "AWS Direct Connect",
      "NFS file share",
      "on-premises"
    ],
    "SelectA": "S3 버킷을 생성합니다. S3 버킷에 쓸 수 있는 IAM role을 생성합니다. AWS CLI를 사용하여 모든 파일을 로컬에서 S3 버킷으로 복사합니다.",
    "SelectA_Commentary": "70TB 규모를 인터넷으로 직접 전송하면 대역폭 사용이 큽니다. 빠른 전송 방식으로 보기 어렵습니다.",
    "SelectB": "AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 디바이스를 수령한 후 Snowball Edge 클라이언트를 사용하여 데이터를 디바이스로 옮깁니다. 이후 디바이스를 반환해 AWS에서 Amazon S3로 데이터를 가져오도록 합니다.",
    "SelectB_Commentary": "물리적인 장비를 사용하여 대규모 데이터를 오프라인으로 전송하므로 네트워크 대역폭 사용을 최소화하면서도 빠른 전송이 가능합니다. 정답입니다.",
    "SelectC": "온프레미스에 S3 File Gateway를 배포합니다. 공용 서비스 엔드포인트로 S3 File Gateway에 접속합니다. S3 버킷을 생성한 후, S3 File Gateway에 새 NFS file share를 생성하고 해당 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 File Gateway로 데이터를 전송합니다.",
    "SelectC_Commentary": "인터넷을 통한 온라인 전송으로 70TB를 전송하는 데 오랜 시간이 걸리며, 네트워크 대역폭을 크게 소모합니다.",
    "SelectD": "온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 File Gateway를 배포하고, public VIF를 생성해 S3 File Gateway와 연결합니다. S3 버킷을 생성한 뒤, S3 File Gateway에 새 NFS file share를 만들고 해당 공유를 S3 버킷에 연결합니다. 기존 NFS 파일 공유에서 S3 File Gateway로 데이터를 전송합니다.",
    "SelectD_Commentary": "Direct Connect를 활용해 전송 속도를 높일 수 있지만, 여전히 온라인 전송으로 70TB 전송 시 대역폭 사용이 상당하며 오프라인보다 시간이 더 오래 걸릴 수 있습니다.",
    "Question_Description_recommedations": [
      "Q283",
      "Q990",
      "Q76",
      "Q496",
      "Q680"
    ],
    "SelectA_recommedations": [
      "Q672",
      "Q155",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q155",
      "Q173",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q6",
      "Q680",
      "Q990"
    ],
    "SelectD_recommedations": [
      "Q844",
      "Q680",
      "Q6"
    ]
  },
  {
    "Question_Number": "Q7",
    "Question_Description": "한 회사는 들어오는 메시지를 수집하는 애플리케이션을 운영하고 있습니다. 수십 개의 다른 애플리케이션과 마이크로서비스가 이 메시지들을 빠르게 소비합니다. 메시지의 양은 크게 변동하며 때때로 초당 100,000개로 갑자기 증가하기도 합니다. 회사는 솔루션을 느슨하게 결합하고 확장성을 높이기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84721-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 메시지의 폭발적인 증가에도 빠르게 확장하면서 마이크로서비스들이 동시에 소비할 수 있는 구조, 즉 느슨하게 결합된 아키텍처를 설계하는 방법을 묻습니다. Amazon SNS와 Amazon SQS 조합을 사용하면 게시된 메시지를 여러 큐로 분산하여 처리 가능하며, 높은 확장성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "메시지",
      "느슨한 결합",
      "확장성",
      "100,000건",
      "SNS",
      "SQS"
    ],
    "Terms": [
      "Amazon Kinesis Data Analytics",
      "Amazon Kinesis Data Streams",
      "Auto Scaling group",
      "Amazon DynamoDB",
      "Amazon SNS",
      "Amazon SQS",
      "AWS Lambda"
    ],
    "SelectA": "Amazon Kinesis Data Analytics에 메시지를 저장한 뒤, 컨슈머 애플리케이션들이 메시지를 읽고 처리하도록 구성합니다.",
    "SelectA_Commentary": "Kinesis Data Analytics는 실시간 분석 용도로 적합하지만, 메시지를 빠르게 분산/수신하는 데는 SNS+SQS 같은 단순 큐 방식이 더 적절합니다.",
    "SelectB": "Amazon EC2 Auto Scaling 그룹에서 애플리케이션을 배포하고 CPU 지표에 따라 EC2 인스턴스 수를 확대/축소합니다.",
    "SelectB_Commentary": "EC2 Auto Scaling만으로는 메시지 처리 로직을 분산하지 못해 느슨한 결합 구조를 확보하기 어렵고, 갑작스러운 트래픽 변화에도 유연성이 제한적입니다.",
    "SelectC": "단일 shard로 설정된 Amazon Kinesis Data Streams에 메시지를 기록하고, AWS Lambda로 전처리하여 Amazon DynamoDB에 저장합니다. 이후 컨슈머 애플리케이션들이 DynamoDB에서 메시지를 읽어 처리하도록 구성합니다.",
    "SelectC_Commentary": "단일 shard는 초당 처리량에 한계가 있어 100,000건 이상의 급증 상황에 대응하기 어렵습니다.",
    "SelectD": "Amazon SNS 토픽에 메시지를 게시하고, 여러 Amazon SQS 구독을 설정합니다. 컨슈머 애플리케이션들은 각 큐로부터 메시지를 받아 처리하도록 구성합니다.",
    "SelectD_Commentary": "SNS+SQS 구조는 높은 확장성과 느슨한 결합을 동시에 달성할 수 있어 급격한 메시지 증가에도 유연하게 대응할 수 있는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q917",
      "Q967",
      "Q58",
      "Q255",
      "Q491"
    ],
    "SelectA_recommedations": [
      "Q198",
      "Q897",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q210",
      "Q595",
      "Q581"
    ],
    "SelectC_recommedations": [
      "Q1002",
      "Q768",
      "Q198"
    ],
    "SelectD_recommedations": [
      "Q784",
      "Q8",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q8",
    "Question_Description": "한 회사가 분산된 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 가변적인 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨트 노드에 걸쳐 작업을 조정하는 기본 서버로 구성됩니다. 회사는 복원력과 확장성을 최대화하는 솔루션으로 애플리케이션을 현대화하고자 합니다. 어떻게 설계해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84679-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 레거시 환경에서 기본 서버가 여러 노드를 관리하던 구조를 AWS 서비스로 현대화해, 변동이 큰 워크로드를 효율적으로 처리하고 복원력을 극대화하는 방법을 묻습니다. Amazon SQS를 통해 작업을 큐에 넣고, 큐 크기에 따라 Auto Scaling 그룹의 EC2 인스턴스를 동적으로 확대·축소하는 방식이 가장 적절한 해결책입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "분산된 애플리케이션",
      "가변적인 워크로드",
      "기본 서버",
      "여러 컴퓨트 노드",
      "복원력",
      "확장성",
      "Amazon SQS",
      "Amazon EC2",
      "Auto Scaling 그룹",
      "큐 크기 기반 스케일링"
    ],
    "Terms": [
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon EC2",
      "Auto Scaling group",
      "EC2 Auto Scaling",
      "AWS CloudTrail",
      "Amazon EventBridge (Amazon CloudWatch Events)"
    ],
    "SelectA": "Amazon SQS 큐를 작업 전송 대상으로 구성합니다. Amazon EC2 인스턴스로 구성된 컴퓨트 노드를 Auto Scaling group으로 관리하고, EC2 Auto Scaling에서 예약 기반 스케일링을 구성합니다.",
    "SelectA_Commentary": "예약 스케일링은 실제 부하와 무관하게 정해진 시점에만 스케일링되어, 가변적인 워크로드를 대응하기엔 유연성이 부족합니다.",
    "SelectB": "Amazon SQS 큐를 작업 전송 대상으로 구성합니다. Amazon EC2 인스턴스로 구성된 컴퓨트 노드를 Auto Scaling group으로 관리하고, EC2 Auto Scaling에서 큐 크기에 따라 스케일링하도록 설정합니다.",
    "SelectB_Commentary": "큐의 길이에 따라 자동으로 인스턴스 수를 조절하는 유연한 아키텍처로, 가변적인 워크로드와 높은 복원성을 모두 만족하는 최적의 솔루션입니다.",
    "SelectC": "기본 서버와 컴퓨트 노드를 모두 Amazon EC2 인스턴스로 구성하여 Auto Scaling group으로 관리합니다. AWS CloudTrail을 작업 전송 대상으로 구성하고, EC2 Auto Scaling에서 기본 서버의 부하를 기준으로 스케일링합니다.",
    "SelectC_Commentary": "CloudTrail은 API 호출 기록 용도로, 작업 대기열로 쓰기에 적합하지 않습니다. 또한 기본 서버와 컴퓨트 노드를 같은 그룹으로 묶으면 계층 분리가 깨져 확장성이 떨어집니다.",
    "SelectD": "기본 서버와 컴퓨트 노드를 모두 Amazon EC2 인스턴스로 구성하여 Auto Scaling group으로 관리합니다. Amazon EventBridge(Amazon CloudWatch Events)를 작업 전송 대상으로 구성하고, EC2 Auto Scaling에서 컴퓨트 노드의 부하를 기준으로 스케일링합니다.",
    "SelectD_Commentary": "EventBridge는 이벤트 라우팅 서비스로, 작업 부하를 처리하기에는 적합하지 않습니다. 기본 서버와 컴퓨트 노드를 분리하지 않아 확장성과 복원성을 모두 극대화하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q163",
      "Q149",
      "Q802",
      "Q519",
      "Q786"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q581",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q581",
      "Q1001"
    ],
    "SelectC_recommedations": [
      "Q581",
      "Q595",
      "Q271"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q9",
    "Question_Description": "한 회사가 데이터 센터에서 SMB file server를 운영하고 있습니다. 이 file server는 대용량 파일을 저장하며, 생성 후 처음 며칠 동안 자주 액세스됩니다. 7일이 지나면 파일은 거의 액세스되지 않습니다. 전체 데이터 용량이 꾸준히 증가하여 회사의 스토리지 한계에 도달하고 있습니다. 솔루션스 아키텍트는 최근에 액세스된 파일에 대한 저지연 액세스를 유지하면서도 사용 가능한 스토리지를 확장해야 합니다. 또한, future storage issues를 피하기 위해 파일 lifecycle management도 제공해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84680-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 기존 온프레미스 SMB file server와 연동하면서 자주 액세스되는 파일에 대한 낮은 지연 시간을 유지하고, 오래된 파일을 자동으로 아카이빙해 비용을 절감하는 솔루션을 찾는 것입니다. Amazon S3 File Gateway를 통해 확장 가능하고 저비용의 클라우드 스토리지를 연동한 뒤, Lifecycle policy로 오래된 파일을 S3 Glacier Deep Archive로 옮겨 효율적인 파일 수명 관리를 달성할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "SMB file server",
      "저지연 액세스",
      "lifecycle management",
      "스토리지 용량 확장",
      "S3 Glacier Deep Archive"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3 File Gateway",
      "S3 Lifecycle policy",
      "S3 Glacier Deep Archive",
      "Amazon FSx for Windows File Server",
      "Amazon S3"
    ],
    "SelectA": "AWS DataSync를 사용하여 7일 이상 지난 데이터를 SMB file server에서 AWS로 복사합니다.",
    "SelectA_Commentary": "단순 복사만 제공하므로 파일을 자주 액세스해야 하는 시나리오에 대한 저지연 액세스 보장이 부족하고, Lifecycle policy 연동도 명시되지 않아 요구사항에 부합하지 않습니다.",
    "SelectB": "Amazon S3 File Gateway를 생성하여 회사의 스토리지를 확장합니다. 7일 후 데이터를 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle policy를 만듭니다.",
    "SelectB_Commentary": "SMB file server와 투명하게 연동해 자주 액세스되는 파일에는 로컬 캐싱으로 저지연을 제공하고, 오래된 파일은 자동으로 저비용 스토리지로 옮겨 요구사항을 충족합니다.",
    "SelectC": "Amazon FSx for Windows File Server 파일 시스템을 생성하여 회사의 스토리지를 확장합니다.",
    "SelectC_Commentary": "Windows 기반 파일 서버를 간단히 확장하지만, 오래된 파일의 자동 아카이빙이나 비용 최적화 관리가 부족하므로 적합하지 않습니다.",
    "SelectD": "모든 사용자 컴퓨터에 유틸리티를 설치해 Amazon S3에 접근하게 합니다. 7일 후 데이터를 S3 Glacier Flexible Retrieval로 전환하는 S3 Lifecycle policy를 만듭니다.",
    "SelectD_Commentary": "각 사용자 측에서 별도 프로그램을 사용해야 하고, File Gateway처럼 SMB 프로토콜과 연동되지 않아 저지연 액세스 제공이 번거로우며 운영 복잡성이 큽니다.",
    "Question_Description_recommedations": [
      "Q673",
      "Q719",
      "Q806",
      "Q205",
      "Q411"
    ],
    "SelectA_recommedations": [
      "Q918",
      "Q719",
      "Q285"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q606",
      "Q415"
    ],
    "SelectC_recommedations": [
      "Q719",
      "Q703",
      "Q277"
    ],
    "SelectD_recommedations": [
      "Q285",
      "Q606",
      "Q769"
    ]
  },
  {
    "Question_Number": "Q10",
    "Question_Description": "한 회사가 AWS에서 전자상거래 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 새 주문 정보를 처리하기 위해 Amazon API Gateway REST API로 보냅니다. 회사는 주문이 도착한 순서대로 처리되도록 보장하고자 합니다. 이 요구사항을 충족할 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84681-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 주문이 들어오는 순서대로 처리해야 하는 시나리오에서 적합한 메커니즘을 찾는 것입니다. Amazon SQS FIFO queue는 메시지의 순서를 보장하므로 요구사항을 충족합니다. API Gateway를 통해 메시지를 FIFO 큐로 보내고, AWS Lambda가 순차적으로 메시지를 처리하도록 설정하면 안정적이고 확장 가능한 구조를 구현할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon API Gateway",
      "REST API",
      "Amazon SQS FIFO queue",
      "AWS Lambda",
      "주문 처리 순서 보장"
    ],
    "Terms": [
      "Amazon API Gateway",
      "REST API",
      "Amazon SNS",
      "AWS Lambda",
      "Amazon SQS FIFO queue",
      "Amazon SQS standard queue",
      "API Gateway authorizer"
    ],
    "SelectA": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Notification Service(Amazon SNS) 토픽에 메시지를 게시합니다. AWS Lambda 함수를 토픽 구독자로 설정해 주문을 처리합니다.",
    "SelectA_Commentary": "Amazon SNS는 메시지 브로드캐스트에 적합하며, 순서 보장은 제공하지 않으므로 요구사항과 맞지 않습니다.",
    "SelectB": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Queue Service(SQS) FIFO queue에 메시지를 보냅니다. 해당 SQS FIFO queue가 AWS Lambda 함수를 호출하도록 구성해 주문을 처리합니다.",
    "SelectB_Commentary": "FIFO 큐는 메시지 순서를 엄격하게 보장하므로 주문을 처리하는 순서를 유지해야 하는 상황에 최적의 선택입니다.",
    "SelectC": "API Gateway authorizer를 사용하여 애플리케이션이 한 주문을 처리하는 동안 모든 요청을 차단합니다.",
    "SelectC_Commentary": "전체 요청을 차단하는 방식은 순서 보장보다는 진입 자체를 제한하는 방법이며, 운영상 비효율적이고 요구사항을 충족하지 못합니다.",
    "SelectD": "애플리케이션에서 주문을 받을 때 Amazon API Gateway 통합을 사용하여 Amazon Simple Queue Service(SQS) standard queue로 메시지를 보냅니다. 해당 SQS standard queue가 AWS Lambda 함수를 호출하도록 구성해 주문을 처리합니다.",
    "SelectD_Commentary": "SQS standard queue는 높은 처리량을 제공하지만 메시지 순서를 보장하지 않습니다. FIFO 큐와 달리 순서 제어가 불가능합니다.",
    "Question_Description_recommedations": [
      "Q207",
      "Q293",
      "Q513",
      "Q869",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q636",
      "Q45",
      "Q148"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q739",
      "Q207"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q798",
      "Q171"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q739",
      "Q207"
    ]
  },
  {
    "Question_Number": "Q11",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있으며, Amazon Aurora 데이터베이스를 사용하고 있습니다. EC2 인스턴스는 로컬 파일에 저장된 사용자 이름과 비밀번호를 이용하여 데이터베이스에 접속합니다. 회사는 자격 증명 관리에 대한 운영 오버헤드를 최소화하고 싶어 합니다. 이 목표를 달성하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84682-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 로컬 파일에 저장된 데이터베이스 자격 증명을 안전하게 관리하고 자동으로 갱신할 방법을 찾는 보안 설계 문제입니다. AWS Secrets Manager는 자동 자격 증명 로테이션 기능을 제공하여 운영 오버헤드를 크게 줄여주므로 효과적인 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon Aurora",
      "자격 증명 관리",
      "운영 오버헤드 최소화",
      "AWS Secrets Manager",
      "automatic rotation"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Aurora",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "Amazon S3",
      "AWS Key Management Service (AWS KMS)",
      "Amazon Elastic Block Store (Amazon EBS)"
    ],
    "SelectA": "AWS Secrets Manager를 사용하고, automatic rotation을 활성화합니다.",
    "SelectA_Commentary": "AWS Secrets Manager는 관리형 비밀번호 로테이션을 지원하므로 자격 증명을 안전하게 보관하고 자동으로 갱신할 수 있어 운영 오버헤드를 최소화합니다.",
    "SelectB": "AWS Systems Manager Parameter Store를 사용하고, automatic rotation을 활성화합니다.",
    "SelectB_Commentary": "Parameter Store는 기본적으로 자동 로테이션을 제공하지 않으므로, 자체 로직이 필요해 관리 비용이 더 큽니다.",
    "SelectC": "AWS KMS 암호화 키로 암호화된 객체를 저장하는 Amazon S3 버킷을 생성하고, 자격 증명 파일을 마이그레이션하여 애플리케이션이 S3 버킷을 사용하도록 합니다.",
    "SelectC_Commentary": "S3 버킷에 자격 증명을 저장해도 자동 로테이션 기능이 없고, 애플리케이션 호출 방식이 복잡해져 운영 오버헤드를 줄이기 어렵습니다.",
    "SelectD": "각 Amazon EC2 인스턴스에 암호화된 Amazon EBS 볼륨을 생성하고 연결한 뒤, 자격 증명 파일을 옮기고 애플리케이션이 이를 사용하도록 합니다.",
    "SelectD_Commentary": "이 방식은 단순히 저장 매체를 암호화하는 것이므로 자동 자격 증명 갱신 기능이 없어 원하는 운영 간소화를 달성하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q294",
      "Q26",
      "Q549",
      "Q85",
      "Q393"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q678",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q678",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q550",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q453",
      "Q675"
    ]
  },
  {
    "Question_Number": "Q12",
    "Question_Description": "한 글로벌 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 웹 애플리케이션은 정적 데이터와 동적 데이터를 모두 사용하며, 정적 데이터는 Amazon S3 버킷에 저장됩니다. 회사는 정적 데이터와 동적 데이터의 성능을 개선하고 지연 시간을 줄이고 싶어 합니다. 또한 회사는 Amazon Route 53에 등록된 자체 도메인 이름을 사용하고 있습니다. 이러한 요구 사항을 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85010-exam-aws-certified-solut",
    "AnswerDescription": "이 문제에서는 정적 콘텐츠(S3)와 동적 콘텐츠(ALB) 양쪽 모두의 지연 시간을 줄이고 성능을 높이기 위한 최적의 분산 전략을 묻습니다. Amazon CloudFront는 글로벌 엣지를 활용하여 정적·동적 콘텐츠 모두의 전송 속도를 향상시킬 수 있고, Route 53으로 트래픽을 라우팅해 간단히 구성할 수 있습니다. AWS Global Accelerator는 주로 비HTTP 프로토콜, 혹은 정적 IP가 필요한 특정 사례에 더욱 적합합니다. 따라서 S3와 ALB를 동시에 Origin으로 사용하는 CloudFront 배포가 운영 복잡도와 성능 개선 면에서 최적의 해답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "정적 데이터",
      "동적 데이터",
      "지연 시간 감소",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Application Load Balancer",
      "Amazon S3"
    ],
    "Terms": [
      "Amazon Route 53",
      "Amazon EC2",
      "Amazon S3",
      "Application Load Balancer",
      "Amazon CloudFront",
      "AWS Global Accelerator"
    ],
    "SelectA": "Amazon CloudFront distribution을 생성하고 S3 버킷과 ALB를 각각 Origin으로 설정합니다. Route 53에서 이 CloudFront distribution으로 트래픽을 라우팅하도록 구성합니다.",
    "SelectA_Commentary": "정적·동적 콘텐츠를 동일한 CloudFront distribution에서 제공함으로써 네트워크 엣지에서 캐싱과 가속을 동시에 수행해 지연 시간을 효과적으로 줄입니다.",
    "SelectB": "ALB를 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. AWS Global Accelerator standard accelerator를 생성하고, S3 버킷을 endpoint로 합니다. 그리고 Route 53에서 CloudFront distribution으로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "정적 콘텐츠를 Global Accelerator로, 동적 콘텐츠를 CloudFront로 분리하므로 구성 복잡도가 높아집니다. HTTP 환경에서 Global Accelerator를 꼭 써야 할 이유가 부족합니다.",
    "SelectC": "S3 버킷을 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. ALB와 CloudFront distribution을 endpoint로 하는 AWS Global Accelerator standard accelerator를 생성합니다. Accelerator DNS에 연결된 커스텀 도메인을 만들어 웹 애플리케이션 엔드포인트로 사용합니다.",
    "SelectC_Commentary": "Global Accelerator와 CloudFront를 동시에 사용해 이중 구성을 구성하므로 운영 복잡도가 높아집니다. 필요한 요구사항을 초과해 복잡성을 증가시킵니다.",
    "SelectD": "ALB를 Origin으로 하는 Amazon CloudFront distribution을 생성합니다. AWS Global Accelerator standard accelerator를 생성하고 S3 버킷을 endpoint로 합니다. 두 개의 도메인 이름을 만들어 하나는 동적 콘텐츠용 CloudFront, 다른 하나는 정적 콘텐츠용 accelerator DNS에 매핑합니다.",
    "SelectD_Commentary": "정적·동적 콘텐츠를 각기 다른 경로로 분리하여 도메인까지 이원화합니다. 관리가 복잡해지고 CloudFront 단일 사용 시 얻을 수 있는 이점을 놓칩니다.",
    "Question_Description_recommedations": [
      "Q358",
      "Q141",
      "Q272",
      "Q530",
      "Q815"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q38",
      "Q358"
    ],
    "SelectB_recommedations": [
      "Q38",
      "Q358",
      "Q280"
    ],
    "SelectC_recommedations": [
      "Q38",
      "Q358",
      "Q280"
    ],
    "SelectD_recommedations": [
      "Q358",
      "Q280",
      "Q38"
    ]
  },
  {
    "Question_Number": "Q13",
    "Question_Description": "한 회사가 AWS 인프라에 대해 매달 정기 유지 보수를 수행합니다. 이 유지 보수 기간 중, 회사는 여러 AWS Region에 걸쳐 있는 Amazon RDS for MySQL 데이터베이스의 자격 증명을 회전해야 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84728-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 여러 AWS Region에 분산된 Amazon RDS for MySQL 자격 증명을 매달 회전하는 방법을 묻습니다. 가장 간단하고 자동화된 방식으로 자격 증명을 안전하게 관리해야 하므로, AWS Secrets Manager의 자동 회전 기능을 활용하는 것이 최소의 운영 오버헤드를 제공합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "정기 유지 보수",
      "Amazon RDS for MySQL",
      "자격 증명 회전",
      "여러 AWS Region",
      "운영 오버헤드 최소화",
      "AWS Secrets Manager"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "AWS Secrets Manager",
      "AWS Systems Manager",
      "multi-Region replication",
      "Amazon S3",
      "server-side encryption (SSE)",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "AWS Lambda",
      "AWS Key Management Service (AWS KMS)",
      "Amazon DynamoDB global table"
    ],
    "SelectA": "AWS Secrets Manager에 자격 증명을 secrets로 저장합니다. 필요한 Region에 대해 multi-Region secret replication을 구성합니다. Secrets Manager를 통해 스케줄에 따라 secrets를 회전하도록 설정합니다.",
    "SelectA_Commentary": "AWS Secrets Manager는 RDS 자격 증명 회전에 특화된 자동화 기능과 multi-Region replication 기능을 제공하므로, 관리 부담이 최소화되는 최적의 솔루션입니다.",
    "SelectB": "AWS Systems Manager의 secure string 매개변수로 자격 증명을 저장합니다. 필요한 Region에 대해 multi-Region secret replication을 구성합니다. Systems Manager를 통해 스케줄에 따라 secrets를 회전하도록 설정합니다.",
    "SelectB_Commentary": "Parameter Store도 보안 저장을 지원하지만, RDS 자격 증명 회전에 대한 자동화 기능은 Secrets Manager만큼 완비되어 있지 않아 운영 편의성이 떨어집니다.",
    "SelectC": "서버 사이드 암호화(SSE)가 활성화된 Amazon S3 버킷에 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events)를 사용해 AWS Lambda 함수를 호출하여 자격 증명을 회전합니다.",
    "SelectC_Commentary": "S3 버킷과 Lambda를 이용한 자체 회전 로직 구현은 운영 복잡도가 높고, 별도의 스크립팅과 관리가 필요합니다.",
    "SelectD": "AWS Key Management Service(AWS KMS) multi-Region 고객 관리형 키로 자격 증명을 암호화해서 Amazon DynamoDB 글로벌 테이블에 저장합니다. AWS Lambda 함수를 사용하여 DynamoDB에서 secrets를 가져오고 RDS API를 호출해 자격 증명을 회전합니다.",
    "SelectD_Commentary": "직접 암호화, DynamoDB 글로벌 테이블, Lambda를 결합한 방안은 구성 요소가 많아 운영 부담이 증가하며, 별도 로직 구현이 필요합니다.",
    "Question_Description_recommedations": [
      "Q742",
      "Q951",
      "Q330",
      "Q438",
      "Q61"
    ],
    "SelectA_recommedations": [
      "Q889",
      "Q868",
      "Q535"
    ],
    "SelectB_recommedations": [
      "Q517",
      "Q889",
      "Q134"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q211",
      "Q364"
    ],
    "SelectD_recommedations": [
      "Q640",
      "Q743",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q14",
    "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스 기반의 전자상거래 애플리케이션을 운영하고 있습니다. 이 인스턴스들은 여러 가용 영역에 분산된 Amazon EC2 Auto Scaling 그룹에서 실행되며, CPU 사용률 지표를 기준으로 확장됩니다. 전자상거래 애플리케이션은 거래 데이터를 MySQL 8.0 데이터베이스(대형 EC2 인스턴스에 호스팅)로 저장하는데, 애플리케이션 부하가 증가함에 따라 데이터베이스 성능이 급격히 저하되고 있습니다. 애플리케이션은 쓰기 트랜잭션보다 읽기 요청이 더 많은 상황입니다. 회사는 예측하기 어려운 읽기 워크로드 수요를 자동으로 충족하고, 동시에 고가용성을 유지하기 위한 솔루션을 원합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족할까요?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85019-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 읽기 트래픽이 많은 MySQL 기반 전자상거래 애플리케이션에서 데이터베이스를 자동으로 확장하고 고가용성을 유지해야 하는 상황입니다. Amazon Aurora의 Multi-AZ 배포와 Aurora Auto Scaling 기능을 사용하면 요구 사항을 충족하면서 뛰어난 성능과 내결함성을 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon EC2 Auto Scaling",
      "MySQL 8.0",
      "읽기 워크로드",
      "고가용성",
      "Amazon Aurora"
    ],
    "Terms": [
      "Amazon Redshift",
      "Amazon RDS",
      "Amazon Aurora",
      "Aurora Auto Scaling",
      "Aurora Replica",
      "Multi-AZ Deployment",
      "Amazon ElastiCache",
      "Memcached",
      "EC2 Spot Instances"
    ],
    "SelectA": "Amazon Redshift를 단일 노드로 구성하여 리더와 컴퓨팅 기능을 동시에 수행합니다.",
    "SelectA_Commentary": "Redshift는 주로 데이터 웨어하우징 및 분석(OLAP)용이며, 트랜잭션 데이터베이스 활용 및 자동 확장 요구 사항에 적합하지 않아 성능 저하가 발생할 수 있습니다.",
    "SelectB": "Amazon RDS를 Single-AZ 배포로 사용하고, Amazon RDS에서 다른 가용 영역에 읽기 전용 인스턴스를 추가하도록 구성합니다.",
    "SelectB_Commentary": "Single-AZ 배포는 가용 영역 장애 시 접속 불가 가능성이 있으며, 읽기 트래픽 폭주에 유연하게 대응하기에도 제한이 큽니다.",
    "SelectC": "Amazon Aurora를 Multi-AZ 배포로 구성하고, Aurora Replicas에 대해 Aurora Auto Scaling을 설정합니다.",
    "SelectC_Commentary": "Aurora는 MySQL 호환이 가능하며 Multi-AZ 환경으로 고가용성을 제공하고, 자동 확장을 통해 증가하는 읽기 요청에도 빠르게 대처할 수 있어 정답입니다.",
    "SelectD": "Amazon ElastiCache for Memcached를 EC2 Spot Instances와 함께 사용합니다.",
    "SelectD_Commentary": "Memcached는 읽기 캐싱에 도움이 될 수 있지만, 트랜잭션이 필요한 DB 자체를 대체하기 어렵고 EC2 Spot Instances는 예측 불가능성이 높아 핵심 DB로 적절치 않습니다.",
    "Question_Description_recommedations": [
      "Q141",
      "Q229",
      "Q358",
      "Q369",
      "Q272"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q269",
      "Q90",
      "Q661"
    ],
    "SelectC_recommedations": [
      "Q620",
      "Q361",
      "Q481"
    ],
    "SelectD_recommedations": [
      "Q690",
      "Q594",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q15",
    "Question_Description": "한 회사가 최근 AWS로 마이그레이션을 완료했고, 프로덕션 VPC 내부 및 외부로 흐르는 트래픽을 보호하기 위한 솔루션을 구현하려고 합니다. 이 회사는 온프레미스 데이터 센터에서 점검 서버를 운용하며 트래픽 흐름 분석과 트래픽 필터링을 수행해 왔습니다. 회사는 AWS Cloud에서도 동일한 기능을 갖추길 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84731-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 기존 온프레미스 점검 서버가 담당하던 트래픽 점검 및 필터링 기능을 AWS 환경에서 어떻게 구현할지를 묻습니다. VPC 내부와 외부 트래픽을 보안 정책에 따라 제어하고, 운영 방식이 간단하며 확장성이 있어야 합니다. AWS Network Firewall은 상태 기반 점검과 규칙 기반 필터링을 제공하여 이러한 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "트래픽 보호",
      "프로덕션 VPC",
      "트래픽 점검",
      "트래픽 필터링",
      "AWS Network Firewall"
    ],
    "Terms": [
      "VPC",
      "트래픽 인바운드/아웃바운드",
      "Amazon GuardDuty",
      "Traffic Mirroring",
      "AWS Network Firewall",
      "AWS Firewall Manager",
      "AWS Cloud",
      "트래픽 흐름 분석"
    ],
    "SelectA": "프로덕션 VPC에서 Amazon GuardDuty를 사용하여 트래픽 점검 및 트래픽 필터링을 수행합니다.",
    "SelectA_Commentary": "Amazon GuardDuty는 위협 탐지 서비스로서 자체 필터링 기능을 제공하지 않으므로 요구사항을 충족하지 못합니다.",
    "SelectB": "Traffic Mirroring을 사용하여 프로덕션 VPC의 트래픽을 미러링해 점검 및 필터링을 수행합니다.",
    "SelectB_Commentary": "Traffic Mirroring은 트래픽을 복사하여 분석 도구로 보내는 기능만 제공하며, 직접적인 필터링을 수행하지 않습니다.",
    "SelectC": "AWS Network Firewall을 사용하여 프로덕션 VPC를 위한 트래픽 점검 및 트래픽 필터링 규칙을 생성합니다.",
    "SelectC_Commentary": "AWS Network Firewall은 상태 기반 방화벽과 규칙 기반 필터링을 지원해 요구사항을 모두 충족하는 올바른 솔루션입니다.",
    "SelectD": "AWS Firewall Manager를 사용하여 프로덕션 VPC에 필요한 트래픽 점검 및 필터링 규칙을 생성합니다.",
    "SelectD_Commentary": "AWS Firewall Manager는 보안 규칙을 중앙에서 관리하는 서비스로, 트래픽 필터링 엔진을 자체 제공하지 않아 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q970",
      "Q529",
      "Q898",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q135",
      "Q950"
    ],
    "SelectB_recommedations": [
      "Q928",
      "Q950",
      "Q15"
    ],
    "SelectC_recommedations": [
      "Q950",
      "Q15",
      "Q782"
    ],
    "SelectD_recommedations": [
      "Q950",
      "Q15",
      "Q151"
    ]
  },
  {
    "Question_Number": "Q16",
    "Question_Description": "한 회사가 AWS에서 Data Lake를 운영하고 있습니다. 이 Data Lake는 Amazon S3와 Amazon RDS for PostgreSQL에 저장된 데이터를 포함합니다. 회사에서는 모든 Data Lake의 데이터 소스를 활용해 데이터 시각화가 가능한 보고 솔루션을 원합니다. 경영진만 모든 시각화 자료에 대해 완전한 접근 권한을 가져야 하며, 그 외 직원들은 제한된 접근 권한만 가져야 합니다. 이러한 요구사항을 충족시키는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84732-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 데이터 레이크 내 여러 데이터 소스로부터 시각화 대시보드를 생성하고, 사용자별(특히 경영진과 일반 직원) 접근 권한을 구분하는 요구사항을 해결하는 방안을 찾는 것입니다. Amazon QuickSight는 다양한 데이터 소스를 연결하고, 사용자와 그룹별 권한관리를 통해 접근 통제 기능을 간편하게 설정할 수 있어 조건을 만족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "데이터 시각화",
      "제한된 접근 권한",
      "Amazon QuickSight",
      "경영진 전용"
    ],
    "Terms": [
      "Amazon QuickSight",
      "Amazon S3",
      "Amazon RDS for PostgreSQL",
      "AWS Glue",
      "Amazon Athena Federated Query",
      "Amazon Athena",
      "S3 bucket policies",
      "ETL job"
    ],
    "SelectA": "Amazon QuickSight에서 Analysis를 생성하고 모든 데이터 소스를 연결해 신규 데이터셋을 만듭니다. 대시보드를 게시하고 적절한 IAM 역할과 공유합니다.",
    "SelectA_Commentary": "IAM 역할 기준으로 공유는 가능하나, 세부 사용자/그룹별 접근 제한 설정이 까다롭습니다.",
    "SelectB": "Amazon QuickSight에서 Analysis를 생성하고 모든 데이터 소스를 연결해 신규 데이터셋을 만듭니다. 대시보드를 게시하고 적절한 사용자와 그룹과 공유합니다.",
    "SelectB_Commentary": "사용자와 그룹 기반으로 보다 세밀하고 직관적인 접근 제어가 가능해 요구사항을 충족하는 최적의 솔루션입니다.",
    "SelectC": "AWS Glue 테이블과 크롤러로 Amazon S3 데이터를 수집하고, AWS Glue ETL 작업을 통해 리포트를 생성하여 Amazon S3에 게시합니다. S3 버킷 정책으로 접근을 제한합니다.",
    "SelectC_Commentary": "ETL 기반 리포트 생성은 시각화 기능이 부족하며, 즉각적인 대시보드 공유에 대한 세밀한 권한 제어가 어렵습니다.",
    "SelectD": "AWS Glue 테이블과 크롤러로 Amazon S3 데이터를 수집하고, Amazon Athena Federated Query를 사용해 Amazon RDS for PostgreSQL 데이터를 조회합니다. Athena로 리포트를 생성하고 Amazon S3에 게시합니다. S3 버킷 정책으로 접근을 제한합니다.",
    "SelectD_Commentary": "표준 쿼리와 파일 형태로 결과를 제공하므로 실시간 대시보드 기능과 사용 권한 세분화 측면에서 QuickSight 대비 제한적입니다.",
    "Question_Description_recommedations": [
      "Q901",
      "Q1007",
      "Q862",
      "Q970",
      "Q495"
    ],
    "SelectA_recommedations": [
      "Q222",
      "Q476",
      "Q780"
    ],
    "SelectB_recommedations": [
      "Q592",
      "Q313",
      "Q548"
    ],
    "SelectC_recommedations": [
      "Q862",
      "Q270",
      "Q412"
    ],
    "SelectD_recommedations": [
      "Q663",
      "Q862",
      "Q981"
    ]
  },
  {
    "Question_Number": "Q17",
    "Question_Description": "한 회사에서 새로운 비즈니스 애플리케이션을 구현하고 있습니다. 애플리케이션은 두 개의 Amazon EC2 인스턴스에서 실행되며, 문서 저장소로 Amazon S3 버킷을 사용합니다. 솔루션스 아키텍트는 EC2 인스턴스가 S3 버킷에 접근할 수 있도록 보장해야 합니다. 이를 위해 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85032-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스가 Amazon S3 버킷에 접근할 수 있도록 권한을 설정하는 방법에 관한 것입니다. 가장 안전하고 권장되는 방법은 IAM role을 생성해 인스턴스에 연결하는 것이며, 이를 통해 보안 자격 증명 없이도 S3에 안전하게 액세스 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "비즈니스 애플리케이션",
      "EC2 인스턴스",
      "S3 버킷",
      "IAM Role",
      "문서 저장소"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "IAM role",
      "IAM policy",
      "IAM group",
      "IAM user"
    ],
    "SelectA": "S3 버킷에 대한 액세스를 부여하는 IAM role을 생성하고, 해당 role을 EC2 인스턴스에 연결합니다.",
    "SelectA_Commentary": "IAM role을 통해 EC2 인스턴스가 자격 증명 없이 안전하게 S3에 접근할 수 있으며, AWS 모범 사례에 부합하는 가장 적절한 솔루션입니다.",
    "SelectB": "S3 버킷에 대한 액세스를 부여하는 IAM policy를 생성하고, 이를 EC2 인스턴스에 직접 연결합니다.",
    "SelectB_Commentary": "IAM policy는 role이나 user 등에 적용해야 하며, 인스턴스에 직접 부착하는 방식은 존재하지 않으므로 올바르지 않습니다.",
    "SelectC": "S3 버킷에 대한 액세스를 부여하는 IAM group을 생성하고, 해당 group을 EC2 인스턴스에 연결합니다.",
    "SelectC_Commentary": "IAM group은 사용자 계정을 모아 권한을 부여하는 용도로, 인스턴스에 직접 적용할 수 없어 적절한 방법이 아닙니다.",
    "SelectD": "S3 버킷에 대한 액세스를 부여하는 IAM user를 생성하고, 이 user 계정을 EC2 인스턴스에 연결합니다.",
    "SelectD_Commentary": "EC2 인스턴스가 user 자격 증명을 직접 사용하도록 구성하는 것은 관리와 보안 면에서 권장되지 않는 방식입니다.",
    "Question_Description_recommedations": [
      "Q612",
      "Q453",
      "Q480",
      "Q710",
      "Q315"
    ],
    "SelectA_recommedations": [
      "Q982",
      "Q612",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q982",
      "Q403",
      "Q494"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q982",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q202",
      "Q982",
      "Q612"
    ]
  },
  {
    "Question_Number": "Q18",
    "Question_Description": "애플리케이션 개발 팀이 대용량 이미지를 작은 압축 이미지로 변환하는 마이크로서비스를 설계하고 있습니다. 사용자가 웹 인터페이스를 통해 이미지를 업로드하면, 해당 이미지는 Amazon S3 버킷에 저장되고, AWS Lambda 함수를 통해 처리 및 압축된 후 별도의 S3 버킷에 압축된 형태로 저장되어야 합니다. 솔루션 아키텍트는 내구성 있고 무상태(stateless)인 구성 요소를 사용하여 이미지를 자동으로 처리할 수 있는 솔루션을 설계해야 합니다. 다음 중 어떤 조합을 구성하면 이 요구사항을 충족할 수 있습니까? (2개를 선택하세요)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85033-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 무상태이면서 내구성이 뛰어난 구조로 이미지를 자동 처리하는 방안을 묻습니다. S3로부터 업로드 이벤트를 Amazon SQS 큐로 전달하고, AWS Lambda가 큐 메시지를 트리거로 이미지를 압축 처리하는 방식이 가장 단순하고 안정적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "마이크로서비스",
      "이미지 압축",
      "S3 버킷",
      "AWS Lambda",
      "무상태 컴포넌트",
      "자동 처리"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon SNS",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon EC2"
    ],
    "SelectA": "Amazon Simple Queue Service(Amazon SQS) 큐를 생성합니다. Amazon S3 버킷이 이미지를 업로드할 때, 해당 S3 버킷에서 SQS 큐로 알림을 보내도록 구성합니다.",
    "SelectA_Commentary": "S3 업로드 이벤트를 SQS 큐에 전달하여 이벤트를 내구성 있게 보관하고, 무상태 구조를 유지하는 핵심 단계입니다. 정답에 필요한 요소입니다.",
    "SelectB": "AWS Lambda 함수를 Amazon SQS 큐를 호출 소스로 사용하도록 구성합니다. SQS 메시지가 정상 처리되면, 큐에서 메시지를 삭제합니다.",
    "SelectB_Commentary": "Lambda 함수를 SQS로부터 직접 트리거해 메시지가 처리될 때마다 자동으로 이미지를 압축 처리하고, 처리 후 메시지를 제거함으로써 중복 수행을 방지합니다. 정답에 필요한 요소입니다.",
    "SelectC": "AWS Lambda 함수를 S3 버킷의 신규 업로드를 모니터하도록 구성합니다. 업로드된 이미지가 감지되면, 파일 이름을 텍스트 파일(메모리)에 기록하고, 이 파일을 사용해 처리된 이미지를 추적합니다.",
    "SelectC_Commentary": "직접 S3 이벤트로 Lambda를 호출할 수 있지만, 문제에서 요구하는 내구성과 무상태 구조를 확보하기 위해서는 SQS를 통해 이벤트를 비동기로 분리하는 것이 적합합니다.",
    "SelectD": "Amazon EC2 인스턴스를 실행하여 Amazon SQS 큐를 모니터링합니다. 큐에 아이템이 추가될 때마다, EC2 인스턴스에서 파일 이름을 텍스트 파일로 기록하고 Lambda 함수를 호출합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 별도로 운영해야 하므로 무상태 아키텍처 요구사항에 부합하지 않으며, 불필요한 운영 복잡성이 증가합니다.",
    "SelectE": "Amazon EventBridge(Amazon CloudWatch Events)를 구성하여 S3 버킷을 모니터합니다. 이미지가 업로드되면, Amazon SNS 주제로 알림을 전송하여 해당 이메일 구독자에게 알립니다.",
    "SelectE_Commentary": "SNS 알림을 이메일로 보내는 방식은 사람이 후속 작업을 진행해야 하므로 자동 처리 요건에 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q404",
      "Q94",
      "Q784",
      "Q110",
      "Q351"
    ],
    "SelectA_recommedations": [
      "Q98",
      "Q636",
      "Q203"
    ],
    "SelectB_recommedations": [
      "Q98",
      "Q785",
      "Q404"
    ],
    "SelectC_recommedations": [
      "Q18",
      "Q404",
      "Q636"
    ],
    "SelectD_recommedations": [
      "Q67",
      "Q203",
      "Q194"
    ],
    "SelectE_recommedations": [
      "Q569",
      "Q636",
      "Q98"
    ]
  },
  {
    "Question_Number": "Q19",
    "Question_Description": "회사에 AWS에 배포된 3계층 웹 애플리케이션이 있습니다. 웹 서버는 VPC의 퍼블릭 서브넷에, 애플리케이션 서버와 데이터베이스 서버는 동일한 VPC의 프라이빗 서브넷에 배포되어 있습니다. 회사는 AWS Marketplace의 타사 가상 방화벽 어플라이언스를 검사 VPC에 배포했습니다. 어플라이언스는 IP 패킷을 수락할 수 있는 IP 인터페이스로 구성됩니다. 솔루션 설계자는 트래픽이 웹 서버에 도달하기 전에 애플리케이션에 대한 모든 트래픽을 검사하고자 합니다. 최소한의 운영 오버헤드로 이 요구 사항을 충족하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "D",
    "Link": "",
    "AnswerDescription": "이 문제의 핵심은 VPC 환경에서 웹 트래픽이 방화벽 어플라이언스를 반드시 거치도록 하여 모든 패킷을 검사하는 것입니다. Gateway Load Balancer는 방화벽 같은 가상 어플라이언스를 쉽게 배포하고 트래픽을 전달할 수 있어 운영 오버헤드를 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "3계층 웹 애플리케이션",
      "검사 VPC",
      "타사 가상 방화벽 어플라이언스",
      "Gateway Load Balancer"
    ],
    "Terms": [
      "VPC",
      "Public Subnet",
      "Private Subnet",
      "AWS Marketplace",
      "타사 가상 방화벽",
      "Gateway Load Balancer",
      "Gateway Load Balancer Endpoint",
      "Network Load Balancer",
      "Application Load Balancer",
      "Transit Gateway"
    ],
    "SelectA": "애플리케이션 VPC의 퍼블릭 서브넷에 Network Load Balancer를 생성하여 패킷 검사를 위해 어플라이언스로 트래픽을 라우팅합니다.",
    "SelectA_Commentary": "Network Load Balancer 자체로는 모든 패킷을 가상 방화벽으로 강제 전달하기에 추가 구성 요소가 많이 필요해 운영이 복잡해질 수 있으므로 요구사항을 효율적으로 충족하기 어렵습니다.",
    "SelectB": "애플리케이션 VPC의 퍼블릭 서브넷에 Application Load Balancer를 생성하여 패킷 검사를 위해 어플라이언스로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "Application Load Balancer는 HTTP/HTTPS 계층에서 기능을 제공하지만, IP 패킷 수준의 검사 요구사항에는 적합하지 않아 타사 방화벽 어플라이언스와의 통합에 제약이 있습니다.",
    "SelectC": "전송 게이트웨이를 통해 들어오는 패킷을 라우팅하도록 라우팅 테이블을 구성하는 검사 VPC에 Transit Gateway를 배포합니다.",
    "SelectC_Commentary": "Transit Gateway로도 트래픽을 중앙화할 수 있지만, 추가 라우팅 설정과 관리가 필요하여 운영 오버헤드가 커질 수 있고, Gateway Load Balancer처럼 네이티브로 패킷을 검사하기엔 복잡합니다.",
    "SelectD": "검사 VPC에 Gateway Load Balancer를 배포합니다. Gateway Load Balancer 엔드포인트를 생성하여 수신 패킷을 수신하고 패킷을 어플라이언스로 전달합니다.",
    "SelectD_Commentary": "Gateway Load Balancer와 엔드포인트를 사용하면 IP 패킷을 투명하게 전달해 방화벽 등 가상 어플라이언스에서 검사할 수 있습니다. 구성과 확장이 용이해 운영 부담이 최소화됩니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q15",
      "Q151",
      "Q135",
      "Q92"
    ],
    "SelectA_recommedations": [
      "Q928",
      "Q170",
      "Q676"
    ],
    "SelectB_recommedations": [
      "Q170",
      "Q928",
      "Q625"
    ],
    "SelectC_recommedations": [
      "Q950",
      "Q151",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q928",
      "Q676",
      "Q1016"
    ]
  },
  {
    "Question_Number": "Q20",
    "Question_Description": "회사는 동일한 AWS Region 내에서 대규모 프로덕션 데이터를 테스트 환경으로 복제하는 시간을 단축하고 싶어 합니다. 데이터는 Amazon EC2 인스턴스의 Amazon EBS 볼륨에 저장되어 있으며, 복제된 데이터가 변경되더라도 프로덕션 환경에 영향을 주어서는 안 됩니다. 또한 이 데이터를 사용하는 소프트웨어는 항상 높은 I/O 성능을 필요로 합니다. 솔루션 아키텍트는 프로덕션 데이터를 테스트 환경으로 최소한의 시간으로 복제해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85226-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 프로덕션 환경의 EBS 데이터를 신속하게 테스트 환경에 복사하면서도 높은 I/O 성능과 운영 분리를 달성해야 합니다. Fast Snapshot Restore를 사용하면 스냅샷에서 생성되는 볼륨이 즉시 최대 성능을 제공하므로 복제 시간을 크게 단축할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "프로덕션 데이터 복제",
      "테스트 환경",
      "Amazon EBS",
      "EBS Snapshot",
      "Fast Snapshot Restore",
      "고성능 I/O"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EBS Multi-Attach",
      "EBS Snapshot",
      "EC2 Instance Store",
      "Fast Snapshot Restore",
      "I/O 성능"
    ],
    "SelectA": "프로덕션 EBS 볼륨의 스냅샷을 생성한 후, 해당 스냅샷을 테스트 환경의 EC2 Instance Store 볼륨에 복원합니다.",
    "SelectA_Commentary": "Instance Store는 일시적 스토리지이며 스냅샷 복원 시간이 오래 걸릴 수 있어 운영 분리와 빠른 복제, 고성능 I/O 요구 사항에 모두 부합하기 어렵습니다.",
    "SelectB": "프로덕션 EBS 볼륨에 EBS Multi-Attach 기능을 구성하고 스냅샷을 생성합니다. 그 후 프로덕션 EBS 볼륨을 테스트 환경의 EC2 인스턴스에 연결합니다.",
    "SelectB_Commentary": "Multi-Attach로 같은 볼륨을 동시에 사용하면 프로덕션 데이터가 영향을 받을 가능성이 있으므로, 완전한 환경 분리를 보장하기 어렵습니다.",
    "SelectC": "프로덕션 EBS 볼륨의 스냅샷을 생성합니다. 새 EBS 볼륨을 만들고 초기화한 후, 프로덕션 EBS 스냅샷을 복원하기 전에 이를 테스트 환경의 EC2 인스턴스에 연결합니다.",
    "SelectC_Commentary": "일반적인 스냅샷 복원은 볼륨을 처음 사용할 때 데이터 블록을 로드하는 지연이 발생해 전체 복원 시간이 길어질 수 있습니다.",
    "SelectD": "프로덕션 EBS 볼륨의 스냅샷을 생성합니다. 해당 스냅샷에 EBS Fast Snapshot Restore 기능을 활성화한 뒤, 새 EBS 볼륨으로 복원하여 테스트 환경의 EC2 인스턴스에 연결합니다.",
    "SelectD_Commentary": "Fast Snapshot Restore를 활성화하면 새 볼륨이 생성 즉시 최대 성능을 제공하므로 복제 시간을 단축하고 고성능 I/O를 보장합니다.",
    "Question_Description_recommedations": [
      "Q976",
      "Q754",
      "Q818",
      "Q686",
      "Q461"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q594",
      "Q193"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q695",
      "Q895"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q361",
      "Q895"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q746",
      "Q895"
    ]
  },
  {
    "Question_Number": "Q21",
    "Question_Description": "한 전자상거래(ecommerce) 회사가 AWS에서 하루에 하나의 특별 할인 상품(one-deal-a-day)을 제공하는 웹사이트를 론칭하려고 합니다. 매일 정확히 하나의 상품이 24시간 동안 판매됩니다. 이 회사는 피크 시간대에 밀리초(ms) 단위의 지연 시간으로 시간당 수백만 건의 요청을 처리할 수 있기를 바랍니다. 가장 적은 운영 오버헤드(operational overhead)로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85195-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 하루에 하나의 상품을 매우 짧은 지연 시간으로 대규모 트래픽에 대응해야 하는 시나리오입니다. 정적 콘텐츠는 Amazon S3와 CloudFront로 빠르고 확장 가능하게 제공할 수 있으며, 백엔드는 API Gateway와 Lambda 같은 서버리스로 구성해 자동 확장과 운영 단순화를 제공합니다. 데이터베이스 계층도 DynamoDB를 사용하여 높은 처리량과 낮은 지연 시간을 확보할 수 있어, 요구사항을 가장 효율적으로 만족할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2",
      "3.3",
      "3.4"
    ],
    "Keywords": [
      "하루에 하나의 특별 할인 상품",
      "24시간 판매",
      "수백만 건의 요청",
      "밀리초 단위 지연 시간",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon EC2",
      "Auto Scaling",
      "Application Load Balancer (ALB)",
      "Amazon EKS",
      "Kubernetes Cluster Autoscaler",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon RDS for MySQL"
    ],
    "SelectA": "Use Amazon S3 to host the full website in different S3 buckets. Add Amazon CloudFront distributions. Set the S3 buckets as origins for the distributions. Store the order data in Amazon S3.",
    "SelectA_Commentary": "전체 웹사이트를 S3에서 호스팅하지만 동적 요청 처리와 데이터 관리가 부족합니다. 단순 파일 호스팅 용도로는 좋지만, 초당 대량 트랜잭션 처리를 위한 서버리스 백엔드 구성이 마련되어 있지 않습니다.",
    "SelectB": "Deploy the full website on Amazon EC2 instances that run in Auto Scaling groups across multiple Availability Zones. Add an Application Load Balancer (ALB) to distribute the website traffic. Add another ALB for the backend APIs. Store the data in Amazon RDS for MySQL.",
    "SelectB_Commentary": "EC2 인스턴스와 확장형 RDS 구성은 충분한 성능을 낼 수 있지만, 서버 운영과 Auto Scaling 관리 등 운영 오버헤드가 큽니다. 밀리초 단위 지연에 대응하기 위해서는 인프라 관리가 복잡해집니다.",
    "SelectC": "Migrate the full application to run in containers. Host the containers on Amazon Elastic Kubernetes Service (Amazon EKS). Use the Kubernetes Cluster Autoscaler to increase and decrease the number of pods to process bursts in traffic. Store the data in Amazon RDS for MySQL.",
    "SelectC_Commentary": "EKS로 컨테이너를 자동 확장할 수 있지만, Kubernetes 관리와 클러스터 운영은 여전히 복잡합니다. 서버리스보다 운영 부담이 크며, 데이터베이스도 RDS로 유지 시 오버헤드가 적지 않습니다.",
    "SelectD": "Use an Amazon S3 bucket to host the website's static content. Deploy an Amazon CloudFront distribution. Set the S3 bucket as the origin. Use Amazon API Gateway and AWS Lambda functions for the backend APIs. Store the data in Amazon DynamoDB.",
    "SelectD_Commentary": "정적 콘텐츠는 S3와 CloudFront, 동적 처리는 API Gateway와 Lambda, 데이터는 DynamoDB에 저장하여 무한 확장성과 낮은 지연 시간을 확보할 수 있습니다. 운영 오버헤드를 최소화하며 고성능을 달성하는 최적의 서버리스 아키텍처입니다.",
    "Question_Description_recommedations": [
      "Q143",
      "Q865",
      "Q33",
      "Q361",
      "Q620"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q38",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q999",
      "Q386",
      "Q261"
    ],
    "SelectC_recommedations": [
      "Q695",
      "Q394",
      "Q261"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q280",
      "Q166"
    ]
  },
  {
    "Question_Number": "Q22",
    "Question_Description": "한 Solutions Architect가 새로운 디지털 미디어 애플리케이션의 스토리지 아키텍처를 Amazon S3로 설계하고 있습니다. 매체 파일은 하나의 가용 영역 상실에도 견딜 수 있어야 하며, 파일들은 어떤 것은 자주 액세스되고 어떤 것은 거의 액세스되지 않을 수 있지만 그 패턴이 예측 불가능합니다. 이 때 파일을 저장하고 검색하는 데 드는 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84943-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 예측하기 어려운 액세스 패턴을 가진 파일을 안정적으로 보관하고, 비용을 절감해야 하는 상황에서 올바른 S3 스토리지 클래스를 선택하는 것입니다. 가용 영역 상실에도 견딜 수 있어야 하므로 최소 3개의 Availability Zone에 데이터를 저장하는 클래스여야 하며, 접근 빈도의 예측이 어렵다면 S3 Intelligent-Tiering을 고려해야 합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "디지털 미디어 애플리케이션",
      "가용 영역 상실",
      "예측 불가능한 액세스 패턴",
      "비용 최소화",
      "S3 Intelligent-Tiering"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Standard",
      "S3 Intelligent-Tiering",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
    ],
    "SelectA": "S3 Standard",
    "SelectA_Commentary": "S3 Standard는 다중 AZ 내구성을 제공하지만, 자주 액세스되지 않는 객체에도 동일 요율이 부과되어 비용 최적화 효과가 떨어집니다.",
    "SelectB": "S3 Intelligent-Tiering",
    "SelectB_Commentary": "자주 액세스되는 객체와 드물게 액세스되는 객체를 자동으로 계층화하고 비용을 절감하면서도 다중 AZ 내구성을 제공하는 최적의 솔루션입니다.",
    "SelectC": "S3 Standard-Infrequent Access (S3 Standard-IA)",
    "SelectC_Commentary": "다중 AZ 내구성을 제공하지만, 불규칙한 액세스에 적합하지 않고 검색 패턴이 불투명할 경우 비용이 더 들 수 있습니다.",
    "SelectD": "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
    "SelectD_Commentary": "한 개의 AZ에만 데이터를 보관하여 가용 영역 상실에 대응할 수 없어 내구성 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q309",
      "Q124",
      "Q872",
      "Q643",
      "Q63"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q415",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q552",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q23",
    "Question_Description": "한 회사가 Amazon S3 Standard 스토리지를 사용하여 백업 파일을 저장하고 있습니다. 해당 파일들은 1개월 동안은 자주 액세스되지만 이후로는 거의 액세스되지 않습니다. 또한 회사는 이 파일들을 무기한 보관해야 합니다. 비용 효율성을 최대화하기 위해 사용할 수 있는 가장 적절한 스토리지 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85092-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 1개월 후에 더 이상 조회되지 않는 백업 파일을 무기한 보관해야 하므로 장기 보관 및 비용 효율성에 중점을 두는 것이 핵심입니다. Amazon S3 Glacier Deep Archive는 매우 저렴한 비용으로 데이터를 보관할 수 있는 스토리지 클래스이므로, 1개월 후에는 이 클래스로 자동 전환되도록 S3 Lifecycle Policy를 설정하는 것이 가장 비용 효과적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "백업 파일",
      "무기한 보관",
      "비용 효율성",
      "1개월 후 비액세스",
      "S3 Glacier Deep Archive"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Intelligent-Tiering",
      "S3 Glacier Deep Archive",
      "S3 Standard-IA",
      "S3 One Zone-IA",
      "S3 Lifecycle Configuration"
    ],
    "SelectA": "S3 Intelligent-Tiering을 구성하여 객체를 자동으로 마이그레이션합니다.",
    "SelectA_Commentary": "S3 Intelligent-Tiering은 엑세스 패턴이 불규칙할 때 유용하지만, 장기적으로 거의 액세스가 없는 백업 파일에는 Deep Archive만큼 저렴하지 않습니다.",
    "SelectB": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 Glacier Deep Archive로 전환하도록 설정합니다.",
    "SelectB_Commentary": "백업 파일을 1개월 동안 S3 Standard에서 유지한 뒤, 거의 액세스가 없을 때 극도로 저렴한 Deep Archive로 자동 전환해 비용을 크게 절감하는 최적의 선택입니다.",
    "SelectC": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 Standard-IA로 전환하도록 설정합니다.",
    "SelectC_Commentary": "S3 Standard-IA도 저렴하지만, 최장 유지 비용면에서 Deep Archive보다 비싸므로 장기 보관에는 부적합합니다.",
    "SelectD": "S3 Lifecycle 구성을 만들어, 객체를 1개월 후 S3 One Zone-Infrequent Access로 전환하도록 설정합니다.",
    "SelectD_Commentary": "One Zone-IA는 내구성 측면에서 여러 AZ를 활용하지 않으므로 백업 파일용으로 안전성이 떨어지며, 장기 보관에서는 Deep Archive만큼 비용 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q415",
      "Q126",
      "Q469",
      "Q829",
      "Q769"
    ],
    "SelectA_recommedations": [
      "Q486",
      "Q943",
      "Q953"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q606",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q23",
      "Q415",
      "Q356"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q23",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q24",
    "Question_Description": "한 회사가 최근 청구서를 확인하던 중 Amazon EC2 비용이 증가한 것을 발견했습니다. 청구 담당 부서에서는 몇 개의 EC2 인스턴스가 원치 않게 인스턴스 유형을 상향(Vertical Scaling)했다는 점을 파악했습니다. 솔루션스 아키텍트는 지난 2개월 간 EC2 비용을 비교하는 그래프를 생성하고, 이러한 상향 조정의 근본 원인을 찾기 위해 심층 분석을 수행해야 합니다. 가장 적은 운영 오버헤드로 정보를 생성하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85038-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 EC2 인스턴스 유형 변경으로 인한 비용 증가의 원인을 파악하는 방법을 묻습니다. 가장 간단하면서 분석 기능이 뛰어난 Cost Explorer의 필터링 기능을 활용하면, 인스턴스 타입별로 지난 2개월간의 비용 변화를 직관적으로 분석할 수 있습니다. 이 방식이 추가적인 인프라 구성 없이 운영 부담을 최소화하는 데 최적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "인스턴스 유형",
      "EC2 비용",
      "비용 비교",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Budgets",
      "Cost Explorer",
      "AWS Billing and Cost Management",
      "AWS Cost and Usage Reports",
      "Amazon QuickSight",
      "Amazon S3"
    ],
    "SelectA": "AWS Budgets를 사용하여 예산 보고서를 생성하고 인스턴스 유형을 기준으로 EC2 비용을 비교합니다.",
    "SelectA_Commentary": "AWS Budgets는 예산 모니터링 및 알림에 강점이 있으나, 세부적인 비용 분석 기능은 제한적입니다.",
    "SelectB": "Cost Explorer의 세분화된 필터링 기능을 사용하여 인스턴스 유형별 EC2 비용에 대해 심층 분석을 수행합니다.",
    "SelectB_Commentary": "Cost Explorer는 인스턴스 유형 별 비용을 직관적으로 비교할 수 있고, 추가 설정이 없어 운영 오버헤드를 크게 줄이는 최적의 선택입니다.",
    "SelectC": "AWS Billing and Cost Management 대시보드의 그래프를 사용하여 지난 2개월 간 인스턴스 유형별 EC2 비용을 비교합니다.",
    "SelectC_Commentary": "대시보드의 그래프 비교는 기본적인 정보를 제공하지만, 원하는 수준의 세밀한 필터링 및 분석 기능이 제한됩니다.",
    "SelectD": "AWS Cost and Usage Reports를 생성하여 Amazon S3 버킷에 전송하고, Amazon QuickSight로 S3를 소스로 사용하여 인스턴스 유형 기반 인터랙티브 그래프를 생성합니다.",
    "SelectD_Commentary": "이 방법은 강력한 시각화가 가능하지만, QuickSight와 S3 설정 등 추가 구성이 필요해 운영 오버헤드가 커집니다.",
    "Question_Description_recommedations": [
      "Q505",
      "Q552",
      "Q347",
      "Q671",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q238",
      "Q552",
      "Q671"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ],
    "SelectD_recommedations": [
      "Q641",
      "Q31",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q25",
    "Question_Description": "한 회사가 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 Amazon API Gateway를 통해 정보를 받아 Amazon Aurora PostgreSQL 데이터베이스에 저장하기 위해 AWS Lambda 함수를 사용합니다. 개념 증명 단계에서, 회사는 대규모 데이터를 데이터베이스에 로드하기 위해 Lambda 할당량을 크게 늘려야 했습니다. 솔루션스 아키텍트는 확장성을 높이고 구성 노력을 최소화할 수 있는 새로운 설계를 제안해야 합니다. 어떤 솔루션이 이 요구사항을 만족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85197-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 API Gateway로 받은 대규모 데이터를 Aurora PostgreSQL에 저장하는 과정에서 Lambda 한도 증가가 필요한 상황을 해결해야 합니다. 기본 Lambda 구조를 무리하게 확장하기보다, 두 개의 Lambda 함수를 두고 Amazon SQS로 분리하면 수신과 적재를 느슨하게 결합해 확장성 및 가용성을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Lambda 확장성",
      "Aurora PostgreSQL",
      "대규모 데이터 로드",
      "구성 노력 최소화",
      "애플리케이션 설계"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon Aurora PostgreSQL",
      "Amazon EC2",
      "Apache Tomcat",
      "JDBC",
      "Amazon DynamoDB",
      "DynamoDB Accelerator(DAX)",
      "Amazon SNS",
      "Amazon SQS"
    ],
    "SelectA": "AWS Lambda 함수 코드를 Amazon EC2 인스턴스에서 실행되는 Apache Tomcat 코드로 리팩터링합니다. 데이터베이스는 JDBC 드라이버를 사용해 연결합니다.",
    "SelectA_Commentary": "코드 리팩터링과 EC2 환경 구성에 많은 작업이 필요해 구성 노력이 크고, 서버 관리 부담이 높아집니다.",
    "SelectB": "Amazon Aurora에서 Amazon DynamoDB로 플랫폼을 변경하고, DynamoDB Accelerator(DAX) 클러스터를 프로비저닝합니다. DAX 클라이언트 SDK를 사용해 기존 DynamoDB API 호출을 DAX 클러스터로 지정합니다.",
    "SelectB_Commentary": "Aurora(관계형)에서 DynamoDB(비관계형)로 마이그레이션이 필요해 설계 변경 폭이 크고, SQL을 NoSQL로 바꾸는 데도 큰 노력이 들어갑니다.",
    "SelectC": "두 개의 Lambda 함수를 구성합니다. 하나는 정보를 수신하고, 다른 하나는 데이터를 데이터베이스에 로드합니다. Amazon Simple Notification Service(Amazon SNS)를 사용해 두 Lambda 함수를 통합합니다.",
    "SelectC_Commentary": "SNS 알림으로 데이터를 전달하지만, 대량 전송 시 동시에 많은 이벤트가 발생해 여전히 부하 제어가 어렵습니다.",
    "SelectD": "두 개의 Lambda 함수를 구성합니다. 하나는 정보를 수신하고, 다른 하나는 데이터를 데이터베이스에 로드합니다. Amazon Simple Queue Service(Amazon SQS) 큐를 사용해 두 Lambda 함수를 통합합니다.",
    "SelectD_Commentary": "SQS를 통해 비동기 큐 기반 구조로 확장성과 안정성을 확보하며, 대규모 데이터도 효율적으로 처리할 수 있는 가장 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q87",
      "Q207",
      "Q354",
      "Q136",
      "Q739"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q768",
      "Q404"
    ],
    "SelectB_recommedations": [
      "Q338",
      "Q490",
      "Q1002"
    ],
    "SelectC_recommedations": [
      "Q45",
      "Q636",
      "Q148"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q98",
      "Q404"
    ]
  },
  {
    "Question_Number": "Q26",
    "Question_Description": "한 회사가 Amazon S3 버킷의 구성 변경 사항을 검토하여 무단으로 변경된 부분이 없는지 확인해야 합니다. 이를 달성하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84940-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 S3 버킷 설정이 무단으로 변경되지 않도록 모니터링 및 감사가 가능한 솔루션을 찾는 상황입니다. AWS Config를 통해 S3 버킷 구성 변경 이력을 추적하고 평가 규칙을 적용하면 무단 변경 사항을 빠르게 식별하고 대응할 수 있어, 가장 적절한 해법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "구성 변경",
      "무단 변경 방지",
      "AWS Config"
    ],
    "Terms": [
      "AWS Config",
      "AWS Trusted Advisor",
      "Amazon Inspector",
      "Amazon S3 server access logging",
      "Amazon EventBridge (Amazon CloudWatch Events)"
    ],
    "SelectA": "AWS Config를 활성화하고 적절한 규칙을 설정합니다.",
    "SelectA_Commentary": "AWS Config는 리소스의 구성 상태를 지속적으로 모니터링하고 기록할 수 있어 무단 변경 사항을 자동으로 감지하고 보고할 수 있습니다.",
    "SelectB": "AWS Trusted Advisor를 활성화하고 적절한 체크를 설정합니다.",
    "SelectB_Commentary": "Trusted Advisor는 모범 사례 관점에서 권장 사항을 제시하지만, 실시간 구성 변경 추적이나 감시 기능은 제한적입니다.",
    "SelectC": "Amazon Inspector를 활성화하고 적절한 평가 템플릿을 설정합니다.",
    "SelectC_Commentary": "Amazon Inspector는 주로 EC2 인스턴스 및 애플리케이션 보안을 평가하는 도구로, S3 버킷 구성 변경 모니터링 용도와는 맞지 않습니다.",
    "SelectD": "Amazon S3 server access logging을 활성화하고, Amazon EventBridge를 구성합니다.",
    "SelectD_Commentary": "서버 액세스 로그와 EventBridge를 사용하면 액세스 및 이벤트 정보를 모니터링할 수 있으나, 직접적이고 체계적인 구성 변경 추적에는 AWS Config가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q294",
      "Q393",
      "Q89",
      "Q85",
      "Q11"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectC_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q862",
      "Q451"
    ]
  },
  {
    "Question_Number": "Q27",
    "Question_Description": "회사는 새 애플리케이션을 시작하며 Amazon CloudWatch 대시보드에서 애플리케이션 지표를 모니터링합니다. 회사의 제품 관리자는 AWS 계정이 없지만, 이 대시보드를 주기적으로 확인해야 합니다. 솔루션 설계자는 최소 권한 원칙에 따라 이 대시보드에 대한 접근 권한을 제공해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-dashbo",
    "AnswerDescription": "이 문제는 AWS 계정이 없는 사용자에게 필요 최소한의 권한만 부여하여 CloudWatch 대시보드를 접근하도록 설계하는 시나리오입니다. CloudWatch 대시보드의 공유 기능을 사용하면, IAM 자격 증명 없이도 이메일을 통해 안전하고 간단하게 접근 권한을 제공할 수 있습니다. 다른 옵션들은 IAM 사용자 생성 혹은 배스천 서버 활용 등으로 과도하게 복잡하거나 권한 범위가 넓습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "CloudWatch 대시보드",
      "새 애플리케이션 지표",
      "최소 권한 원칙",
      "공유",
      "이메일 주소"
    ],
    "Terms": [
      "Amazon CloudWatch",
      "CloudWatch 대시보드",
      "IAM 사용자",
      "CloudWatchReadOnlyAccess",
      "ViewOnlyAccess",
      "배스천 서버",
      "RDP",
      "SSO",
      "Amazon Cognito"
    ],
    "SelectA": "CloudWatch 콘솔에서 대시보드를 공유합니다. 제품 관리자의 이메일 주소를 입력하고 공유 단계를 완료합니다. 대시보드에 대한 공유 가능한 링크를 제품 관리자에게 제공하십시오.",
    "SelectA_Commentary": "정답입니다. AWS 계정 없이도 대시보드를 볼 수 있도록 이메일로 초대하는 CloudWatch 공유 기능을 사용해 최소 권한과 운영 편의성을 모두 충족합니다.",
    "SelectB": "특히 제품 관리자를 위한 IAM 사용자를 생성합니다. CloudWatchReadOnlyAccess AWS 관리형 정책을 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 올바른 대시보드의 브라우저 URL 을 제품 관리자와 공유하십시오.",
    "SelectB_Commentary": "IAM 사용자를 생성하면 AWS 콘솔 전반에 접근 가능한 자격 증명이 생깁니다. 필요 이상으로 권한 범위가 넓어 최소 권한 원칙에 비해 과도합니다.",
    "SelectC": "회사 직원을 위한 IAM 사용자를 생성합니다. ViewOnlyAccess AWS 관리형 정책을 IAM 사용자에게 연결합니다. 새 로그인 자격 증명을 제품 관리자와 공유하십시오. 제품 관리자에게 CloudWatch 콘솔로 이동하여 대시보드 섹션에서 이름으로 대시보드를 찾으라고 요청합니다.",
    "SelectC_Commentary": "ViewOnlyAccess 정책은 읽기 전용이지만, 여전히 계정의 다른 리소스를 표시할 수 있으므로 정확히 제한된 권한만 부여하는 데 적합하지 않습니다.",
    "SelectD": "퍼블릭 서브넷에 배스천 서버를 배포합니다. 제품 관리자가 대시보드에 액세스해야 하는 경우 서버를 시작하고 RDP 자격 증명을 공유합니다. 배스천 서버에서 대시보드를 볼 수 있는 적절한 권한이 있는 캐시된 AWS 자격 증명으로 대시보드 URL 을 열도록 브라우저가 구성되어 있는지 확인합니다.",
    "SelectD_Commentary": "배스천 서버와 RDP 자격 증명을 공유하는 것은 매우 복잡하며 보안 부담이 큽니다. 단순히 대시보드 보는 용도로 과도하고 최소 권한 원칙에도 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q484",
      "Q970",
      "Q548",
      "Q922",
      "Q529"
    ],
    "SelectA_recommedations": [
      "Q27",
      "Q893",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q27",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q27"
    ],
    "SelectD_recommedations": [
      "Q831",
      "Q313",
      "Q922"
    ]
  },
  {
    "Question_Number": "Q28",
    "Question_Description": "회사는 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 여러 AWS 계정에 배포될 예정이며, 회사는 AWS Organizations를 사용해 계정을 중앙에서 관리합니다. 회사 보안 팀은 모든 계정에서 Single Sign-On(SSO) 솔루션을 사용해야 한다고 요구합니다. 또한 사용자와 그룹은 사내에서 자체 관리하는 Microsoft Active Directory에서 계속 관리해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_providers.html",
    "AnswerDescription": "이 문제는 사내 Microsoft AD 사용을 유지하면서 여러 AWS 계정을 통합 관리하기 위한 AWS SSO 설정을 묻습니다. AWS SSO와 Microsoft AD 연동에는 양방향 트러스트 설정이 핵심이며, 온프레미스 사용자와 그룹 정보를 변경 없이 사용하는 방법을 이해해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "Single Sign-On(SSO)",
      "Microsoft Active Directory",
      "계정 중앙 관리",
      "보안 팀",
      "사용자 및 그룹 관리"
    ],
    "Terms": [
      "AWS Single Sign-On(AWS SSO)",
      "AWS Organizations",
      "Microsoft Active Directory 용 AWS Directory Service",
      "단방향 트러스트",
      "양방향 트러스트",
      "IdP(Identity Provider)"
    ],
    "SelectA": "AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. 단방향 포리스트 트러스트 또는 단방향 도메인 트러스트를 생성하여 Microsoft Active Directory 용 AWS Directory Service를 사용해 자체 관리형 Microsoft AD를 AWS SSO와 연결합니다.",
    "SelectA_Commentary": "AWS 엔터프라이즈 앱 사용 시 양방향 트러스트가 필요하므로 단방향 트러스트만으로는 요구 사항을 완전히 충족하기 어렵습니다.",
    "SelectB": "AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다. Microsoft Active Directory 용 AWS Directory Service를 사용해 자체 관리형 Microsoft AD를 AWS SSO와 연결하는 양방향 포리스트 트러스트를 생성합니다.",
    "SelectB_Commentary": "AWS 콘솔 및 여러 애플리케이션에서 온프레미스 AD 사용자 인증을 위해서는 양방향 트러스트가 필수이므로, 이 옵션이 요구 사항을 충족합니다.",
    "SelectC": "AWS 디렉터리 서비스를 사용합니다. 회사의 자체 관리 Microsoft Active Directory와 양방향 신뢰 관계를 만드십시오.",
    "SelectC_Commentary": "단순 디렉터리 서비스 구축만으로는 AWS 월등한 기능인 SSO 및 권한 관리를 간편하게 통합 제공하기 어렵습니다.",
    "SelectD": "온프레미스에 ID 공급자(IdP)를 배포합니다. AWS SSO 콘솔에서 AWS Single Sign-On(AWS SSO)을 활성화합니다.",
    "SelectD_Commentary": "외부 IdP만 배포하는 것은 온프레미스 AD를 그대로 활용하려는 요구 사항을 직접적으로 지원하지 못하며, 트러스트 구성도 복잡합니다.",
    "Question_Description_recommedations": [
      "Q826",
      "Q1018",
      "Q945",
      "Q168",
      "Q668"
    ],
    "SelectA_recommedations": [
      "Q28",
      "Q826",
      "Q688"
    ],
    "SelectB_recommedations": [
      "Q28",
      "Q826",
      "Q688"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q898",
      "Q529"
    ],
    "SelectD_recommedations": [
      "Q28",
      "Q750",
      "Q826"
    ]
  },
  {
    "Question_Number": "Q29",
    "Question_Description": "회사는 UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스를 제공합니다. 이 서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 회사는 여러 AWS 리전에 배포하고 있습니다. 회사는 지연 시간이 가장 짧은 리전으로 사용자를 라우팅해야 합니다. 또한 지역 간 자동 장애 조치가 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://aws.amazon.com/global-accelerator/faqs/",
    "AnswerDescription": "이 문제는 UDP 기반 VoIP 서비스에 대해 가장 낮은 지연 시간을 제공하고 지역 간 장애 조치를 자동화할 방법을 묻습니다. NLB와 AWS Global Accelerator를 결합해 Anycast IP와 전역 로드 밸런싱을 활용하는 것이 핵심이며, 이를 통해 사용자에게 가장 가까운 리전으로 트래픽을 분산하고 자동 장애 조치까지 수행할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "UDP 연결",
      "VoIP",
      "지연 시간이 가장 짧은 리전",
      "자동 장애 조치",
      "AWS Global Accelerator",
      "NLB"
    ],
    "Terms": [
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "AWS Global Accelerator",
      "Amazon Route 53",
      "Amazon CloudFront",
      "Auto Scaling group",
      "UDP",
      "EC2"
    ],
    "SelectA": "NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포하고 Auto Scaling 그룹을 대상 그룹에 연결합니다. 각 리전에서 NLB를 AWS Global Accelerator 엔드포인트로 사용합니다.",
    "SelectA_Commentary": "UDP 트래픽에 적합한 NLB와 AWS Global Accelerator의 결합은 낮은 지연 시간과 자동 장애 조치를 모두 달성할 수 있는 최적의 솔루션입니다.",
    "SelectB": "ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포하고 Auto Scaling 그룹을 대상 그룹에 연결합니다. 각 리전에서 ALB를 AWS Global Accelerator 엔드포인트로 사용합니다.",
    "SelectB_Commentary": "ALB는 기본적으로 UDP 트래픽을 지원하지 않으므로 VoIP와 같은 UDP 애플리케이션에는 적합하지 않습니다.",
    "SelectC": "NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포하고 Auto Scaling 그룹을 대상 그룹에 연결합니다. 각 NLB의 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 그리고 해당 지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 생성합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS 기반 콘텐츠 전송용이며, UDP 트래픽을 효율적으로 전달하기 어렵고 설정 복잡도도 큽니다.",
    "SelectD": "ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포하고 Auto Scaling 그룹을 대상 그룹에 연결합니다. 각 ALB의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 해당 가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다.",
    "SelectD_Commentary": "가중치 라우팅은 자동 장애 조치 및 지연 시간 라우팅을 세밀하게 제공하기 어렵고, ALB 역시 UDP를 지원하지 않아 요구 사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q642",
      "Q1001",
      "Q194",
      "Q720",
      "Q935"
    ],
    "SelectA_recommedations": [
      "Q70",
      "Q405",
      "Q174"
    ],
    "SelectB_recommedations": [
      "Q174",
      "Q405",
      "Q589"
    ],
    "SelectC_recommedations": [
      "Q70",
      "Q545",
      "Q405"
    ],
    "SelectD_recommedations": [
      "Q405",
      "Q545",
      "Q174"
    ]
  },
  {
    "Question_Number": "Q30",
    "Question_Description": "한 개발 팀이 Performance Insights가 활성화된 general purpose Amazon RDS for MySQL DB instance에서 매월 리소스를 많이 사용하는 테스트를 실행합니다. 이 테스트는 한 달에 한 번, 48시간 동안만 진행되며, 이 데이터베이스를 사용하는 유일한 프로세스입니다. 해당 팀은 DB 인스턴스의 컴퓨팅 및 메모리 사양은 유지하면서, 테스트를 실행하는 비용을 절감하고 싶어 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85030-exam-aws-certified-solut",
    "AnswerDescription": "테스트에만 사용되는 DB를 상시로 유지하면 비용이 많이 듭니다. 스냅샷을 생성 후 DB 인스턴스를 종료하면 월 대부분의 시간에 비용을 절약하면서 필요 시 동일 사양으로 복원할 수 있어 가장 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "RDS",
      "MySQL",
      "Performance Insights",
      "스냅샷",
      "비용 절감"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Performance Insights",
      "Snapshot",
      "귀중(High) Compute",
      "메모리 사양",
      "DB instance"
    ],
    "SelectA": "테스트가 완료되면 DB 인스턴스를 중지합니다. 필요할 때 DB 인스턴스를 다시 시작합니다.",
    "SelectA_Commentary": "인스턴스를 중지해도 저장소 비용은 계속 들고, 7일 제한 등의 제약이 있어 월 1회 장기 중지 시 운용상 불편이 큽니다.",
    "SelectB": "DB 인스턴스를 사용하는 Auto Scaling policy를 적용하여, 테스트가 완료되면 자동으로 스케일 다운합니다.",
    "SelectB_Commentary": "Amazon RDS for MySQL에 직접적인 Auto Scaling 정책이 적용되지 않으며, 테스트 외 시간에도 RDS 인스턴스가 계속 동작해 비용을 절감하기 어렵습니다.",
    "SelectC": "테스트가 끝나면 스냅샷을 생성합니다. DB 인스턴스를 종료한 뒤, 필요할 때 해당 스냅샷을 복원합니다.",
    "SelectC_Commentary": "인스턴스를 완전히 종료해 사용 시간이 없을 때 인스턴스 비용이 들지 않아 가장 비용 효율적입니다. 스냅샷 복원으로 동일 사양을 빠르고 손쉽게 재생성 가능합니다.",
    "SelectD": "테스트가 완료되면 DB 인스턴스를 소용량 인스턴스로 변경합니다. 필요할 때 다시 원래 사양으로 변경합니다.",
    "SelectD_Commentary": "DB 인스턴스 스펙 변경은 원하는 컴퓨팅·메모리를 유지해야 한다는 요구사항과 어긋나며, 변경 과정에서도 추가 비용과 시간이 소요됩니다.",
    "Question_Description_recommedations": [
      "Q574",
      "Q152",
      "Q959",
      "Q579",
      "Q436"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectB_recommedations": [
      "Q79",
      "Q670",
      "Q348"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectD_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ]
  },
  {
    "Question_Number": "Q31",
    "Question_Description": "한 회사가 AWS에서 웹 애플리케이션을 호스팅 중이며, 모든 Amazon EC2 인스턴스, Amazon RDS DB 인스턴스, Amazon Redshift 클러스터가 태그(Tag)로 구성되어 있는지 확인하고자 합니다. 이 확인 작업의 구성과 운영 부담을 최소화하려면 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85198-exam-aws-certified-solut",
    "AnswerDescription": "AWS 리소스의 태그 상태를 자동으로 검사하고 싶다면 AWS Config가 가장 간단하고 효율적인 방법입니다. 수동이나 자체 코드 대신 관리형 규칙을 사용하면 운영 부담이 크게 줄어듭니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon Redshift",
      "태그",
      "운영 부담 최소화"
    ],
    "Terms": [
      "AWS Config",
      "Cost Explorer",
      "AWS Lambda",
      "CloudWatch"
    ],
    "SelectA": "AWS Config 규칙을 사용하여 태그가 올바르게 설정되지 않은 리소스를 정의하고 감지합니다.",
    "SelectA_Commentary": "AWS Config는 자동 규칙으로 미태그 자원을 식별하고 모니터링하므로 운영 부담을 줄이는 최적의 솔루션입니다.",
    "SelectB": "Cost Explorer를 사용해 태그가 잘못된 리소스를 표시하고 수동으로 태그를 구성합니다.",
    "SelectB_Commentary": "Cost Explorer로 확인은 가능하지만 태그 반영 과정이 전부 수동이므로 운영 부담이 높습니다.",
    "SelectC": "적절한 태그 할당을 확인하는 API 호출을 작성하고, 이를 EC2 인스턴스에서 주기적으로 실행합니다.",
    "SelectC_Commentary": "별도 코드 유지와 스케줄 관리가 필요해 운영 복잡성이 큽니다.",
    "SelectD": "API 호출을 작성해 태그 할당을 확인하고, AWS Lambda 함수를 CloudWatch로 스케줄링해 주기적으로 실행합니다.",
    "SelectD_Commentary": "Lambda를 통해 자동화 가능하지만 자체 코드 작성과 유지가 필요해 AWS Config보다 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q380",
      "Q238",
      "Q449",
      "Q455",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q284",
      "Q728",
      "Q541"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q49"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q128",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q32",
    "Question_Description": "한 개발 팀이 다른 팀이 접속할 웹사이트를 호스팅해야 합니다. 웹사이트의 콘텐츠는 HTML, CSS, client-side JavaScript, 그리고 images로 구성됩니다. 가장 비용 효율적인 웹사이트 호스팅 방법은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85199-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 정적 콘텐츠로만 구성된 웹사이트를 가장 저렴하고 간단하게 호스팅하는 방안을 묻습니다. Amazon S3의 정적 웹 호스팅 기능은 서버나 컨테이너에 비용이 들지 않으므로, 소규모 팀 환경에서 특히 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "비용 효율적인 웹사이트 호스팅",
      "정적 웹사이트",
      "Amazon S3",
      "HTML",
      "client-side JavaScript"
    ],
    "Terms": [
      "AWS Fargate",
      "Amazon S3",
      "Amazon EC2",
      "Application Load Balancer",
      "AWS Lambda",
      "Express.js",
      "HTML",
      "CSS",
      "client-side JavaScript",
      "images"
    ],
    "SelectA": "웹사이트를 컨테이너로 만든 뒤 AWS Fargate에서 호스팅합니다.",
    "SelectA_Commentary": "정적 웹사이트를 컨테이너로 운영하면 불필요한 운영 및 컴퓨팅 비용이 추가되어 최적의 비용 효율이 아닙니다.",
    "SelectB": "Amazon S3 버킷을 생성하고 그곳에서 웹사이트를 호스팅합니다.",
    "SelectB_Commentary": "HTML, CSS, client-side JavaScript 등의 정적 파일은 Amazon S3에서 매우低 운영 비용으로 손쉽게 제공할 수 있으므로 가장 비용 효율적입니다.",
    "SelectC": "웹 서버를 Amazon EC2 인스턴스에 배포하여 웹사이트를 호스팅합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 임대하는 비용이 발생하며, 서버 유지 관리도 필요하므로 정적 사이트 호스팅으로는 효율이 떨어집니다.",
    "SelectD": "Application Load Balancer를 설정하고 AWS Lambda에서 Express.js 프레임워크를 사용하는 대상으로 연결합니다.",
    "SelectD_Commentary": "Lambda와 ALB 구성이 가능하긴 하나, 정적 콘텐츠 제공만을 위해서는 과도하며 복잡도와 비용이 증가합니다.",
    "Question_Description_recommedations": [
      "Q411",
      "Q300",
      "Q767",
      "Q997",
      "Q728"
    ],
    "SelectA_recommedations": [
      "Q926",
      "Q728",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q1003",
      "Q911",
      "Q769"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q473",
      "Q146",
      "Q894"
    ]
  },
  {
    "Question_Number": "Q33",
    "Question_Description": "한 회사가 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 운영하고 있습니다. 피크 시간대에는 수십만 명의 사용자를 지원합니다. 이 회사는 여러 내부 애플리케이션에 수백만 건의 금융 거래 정보를 거의 실시간(near-real-time)으로 공유할 수 있는 확장 가능한 솔루션이 필요합니다. 또한 트랜잭션을 document database에 낮은 지연 시간으로 저장하기 전에 민감한 데이터를 제거해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 구성을 추천해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85201-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 수백만 건의 금융 거래를 거의 실시간으로 여러 내부 애플리케이션에 전달하고, 동시에 민감한 데이터를 제거하여 문서형 데이터베이스에 저장해야 하는 고속·확장성 아키텍처를 설계하는 상황입니다. Amazon Kinesis Data Streams와 AWS Lambda를 조합하면 실시간 처리가 가능하며, Lambda 함수로 민감한 데이터를 제거 후 Amazon DynamoDB에 저장할 수 있습니다. 다른 애플리케이션들은 Kinesis Data Streams로부터 직접 데이터를 구독함으로써 확장성을 유지하면서도 지연 시간을 최소화할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "온라인 마켓플레이스",
      "near-real-time",
      "수백만 건의 금융 거래",
      "민감한 데이터 제거",
      "document database",
      "낮은 지연 시간"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "DynamoDB Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon Kinesis Data Streams",
      "AWS Lambda",
      "Amazon S3"
    ],
    "SelectA": "Amazon DynamoDB에 트랜잭션 데이터를 저장하고, DynamoDB에 쓰여질 때 민감한 데이터를 제거하도록 설정합니다. DynamoDB Streams를 사용하여 다른 애플리케이션과 데이터를 공유합니다.",
    "SelectA_Commentary": "DynamoDB에 쓰기 시점에서 자동 필터링 규칙을 적용하는 기능은 기본적으로 제공되지 않아 원하는 대로 민감 정보를 완전히 제거하기 어렵습니다.",
    "SelectB": "트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB와 Amazon S3에 저장합니다. AWS Lambda 통합으로 민감한 데이터를 제거합니다. 다른 애플리케이션들은 Amazon S3에 저장된 데이터를 사용합니다.",
    "SelectB_Commentary": "Kinesis Data Firehose는 DynamoDB를 직접 대상으로 지원하지 않으므로, 요구사항인 near-real-time DynamoDB 삽입이 어렵습니다.",
    "SelectC": "트랜잭션 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 통해 각 트랜잭션에서 민감한 데이터를 제거한 후 Amazon DynamoDB에 저장합니다. 다른 애플리케이션들은 Kinesis 스트림에서 데이터를 소비합니다.",
    "SelectC_Commentary": "Kinesis Data Streams와 Lambda의 조합은 최소 지연으로 대량 데이터를 처리하고 민감 정보를 필터링하기 적합하며 DynamoDB 저장으로 저지연 읽기도 가능합니다.",
    "SelectD": "배치된 트랜잭션 데이터를 Amazon S3에 파일 형태로 저장합니다. AWS Lambda로 각 파일을 처리하여 민감한 데이터를 제거한 다음, 파일을 업데이트하고 Amazon DynamoDB에 저장합니다. 다른 애플리케이션들은 S3에 저장된 파일을 사용합니다.",
    "SelectD_Commentary": "배치 파일 처리 방식이므로 실시간성이 떨어지고, 민감 정보 제거-재업로드 과정도 복잡해 요구사항과 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q192",
      "Q631",
      "Q361",
      "Q472",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q173",
      "Q515",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q472",
      "Q523"
    ],
    "SelectD_recommedations": [
      "Q173",
      "Q292",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q34",
    "Question_Description": "한 회사가 AWS에서 다중 계층 애플리케이션을 호스팅하고 있습니다. 컴플라이언스, 거버넌스, 감사, 보안 목적상 AWS 리소스에 대한 구성 변경 사항을 추적하고 이 리소스들에 대한 API 호출 이력을 기록해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85202-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 AWS 리소스에 대한 구성 변경 사항과 API 호출 이력을 동시에 추적해야 하는 상황입니다. AWS Config는 리소스 변경 내역을 지속적으로 모니터링하고, AWS CloudTrail은 사용자 및 서비스 API 호출 정보를 기록하여 보안, 감사, 거버넌스 요구 사항을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "다중 계층 애플리케이션",
      "컴플라이언스",
      "구성 변경 사항",
      "API 호출 이력",
      "AWS Config",
      "AWS CloudTrail"
    ],
    "Terms": [
      "AWS Config",
      "AWS CloudTrail",
      "Amazon CloudWatch",
      "Configuration changes",
      "API calls",
      "Compliance",
      "Governance",
      "Auditing",
      "Security"
    ],
    "SelectA": "AWS CloudTrail을 사용하여 구성 변경 사항을 추적하고 AWS Config를 사용하여 API 호출을 기록합니다.",
    "SelectA_Commentary": "각 서비스의 역할이 반대로 설정되어 있어 요구 사항을 충족하지 못합니다.",
    "SelectB": "AWS Config를 사용하여 구성 변경 사항을 추적하고 AWS CloudTrail을 사용하여 API 호출을 기록합니다.",
    "SelectB_Commentary": "정답입니다. 각 서비스가 맡은 역할과 기능이 정확히 부합해 보안과 감사 요구 사항을 모두 충족합니다.",
    "SelectC": "AWS Config를 사용하여 구성 변경 사항을 추적하고 Amazon CloudWatch를 사용하여 API 호출을 기록합니다.",
    "SelectC_Commentary": "Amazon CloudWatch는 로그 모니터링을 주로 담당하며, API 호출 기록 기능은 CloudTrail이 제공하므로 적절하지 않습니다.",
    "SelectD": "AWS CloudTrail을 사용하여 구성 변경 사항을 추적하고 Amazon CloudWatch를 사용하여 API 호출을 기록합니다.",
    "SelectD_Commentary": "CloudTrail이 API 호출 로깅을 담당해야 하므로, 이 조합은 요구 사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q548",
      "Q529",
      "Q970",
      "Q898",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q34",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q942",
      "Q34",
      "Q970"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q34",
      "Q748"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q942",
      "Q34"
    ]
  },
  {
    "Question_Number": "Q35",
    "Question_Description": "한 회사가 AWS 클라우드에서 공개 웹 애플리케이션 출시를 준비하고 있습니다. 아키텍처는 Elastic Load Balancer(ELB) 뒤의 VPC 내 Amazon EC2 인스턴스로 구성됩니다. DNS에는 타사 서비스가 사용됩니다. 회사의 솔루션 설계자는 대규모 DDoS 공격을 감지하고 보호하기 위한 솔루션을 권장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://aws.amazon.com/ko/shield/?whats-new-cards.sort-by=item.additionalFields.post",
    "AnswerDescription": "이 문제는 웹 애플리케이션을 대규모 DDoS 공격으로부터 보호하기 위한 솔루션을 찾는 상황입니다. AWS Shield Advanced는 다양한 리소스에 대해 실시간에 가까운 가시성과 추가 보호를 제공하므로 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "대규모 DDoS 공격",
      "공개 웹 애플리케이션",
      "Elastic Load Balancer",
      "Amazon EC2",
      "DNS",
      "AWS Shield Advanced"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic Load Balancer (ELB)",
      "Amazon Route 53",
      "Amazon GuardDuty",
      "Amazon Inspector",
      "AWS Shield",
      "AWS Shield Advanced"
    ],
    "SelectA": "계정에서 Amazon GuardDuty를 활성화합니다.",
    "SelectA_Commentary": "Amazon GuardDuty는 계정 전반의 위협 탐지 서비스일 뿐, 대규모 DDoS 공격 완화 기능은 제공하지 않습니다.",
    "SelectB": "EC2 인스턴스에서 Amazon Inspector를 활성화합니다.",
    "SelectB_Commentary": "Amazon Inspector는 주로 애플리케이션 취약점을 찾는 서비스이며, DDoS 방어와 직접 관련이 없습니다.",
    "SelectC": "AWS Shield를 활성화하고 여기에 Amazon Route 53을 할당합니다.",
    "SelectC_Commentary": "기본 AWS Shield(Standard)는 DDoS 방어 기능을 제공하지만, 규모가 큰 DDoS 공격에는 Shield Advanced가 더 효과적입니다.",
    "SelectD": "AWS Shield Advanced를 활성화하고 ELB를 할당합니다.",
    "SelectD_Commentary": "AWS Shield Advanced는 대규모 DDoS 공격에 대한 종합 보호, 모니터링, 비용 보호까지 제공하므로 가장 적합한 선택입니다.",
    "Question_Description_recommedations": [
      "Q927",
      "Q396",
      "Q169",
      "Q382",
      "Q701"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q682",
      "Q893",
      "Q480"
    ],
    "SelectC_recommedations": [
      "Q532",
      "Q893",
      "Q1019"
    ],
    "SelectD_recommedations": [
      "Q35",
      "Q689",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q36",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 구축하고 있습니다. 애플리케이션은 두 개의 AWS Region에 있는 Amazon S3 버킷에 데이터를 저장할 예정입니다. 회사는 모든 데이터를 AWS Key Management Service(AWS KMS)의 Customer managed key로 암호화해야 합니다. 또한 두 버킷에 있는 모든 데이터가 동일한 KMS key로 암호화 및 복호화되어야 하며, 두 Region 각각에 데이터와 해당 KMS key가 존재해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84747-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 동일한 Customer managed key를 두 개의 Region에서 모두 활용해야 하는 조건을 만족하면서 운영 오버헤드를 최소화하는 KMS 암호화 방안을 묻습니다. Multi-Region KMS key를 사용해야 Region별 동일 키 운용이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "AWS KMS",
      "Customer managed key",
      "S3 버킷",
      "다른 Region",
      "암호화"
    ],
    "Terms": [
      "Multi-Region KMS key",
      "SSE-KMS",
      "SSE-S3",
      "Client-side Encryption",
      "Server-side Encryption",
      "Replication"
    ],
    "SelectA": "각 Region에 S3 버킷을 생성하고, Amazon S3 managed encryption keys(SSE-S3)로 서버측 암호화를 활성화합니다. 그런 다음 두 버킷 간에 복제를 구성합니다.",
    "SelectA_Commentary": "SSE-S3는 고객이 관리하는 KMS key가 아니라서 요구사항을 충족하지 못합니다.",
    "SelectB": "Multi-Region KMS key로 Customer managed key를 생성합니다. 각 Region에 S3 버킷을 생성하고, 버킷 간 복제를 구성합니다. 애플리케이션은 이 KMS key를 사용해 클라이언트 측 암호화를 수행합니다.",
    "SelectB_Commentary": "Multi-Region KMS key를 사용해 두 Region에서 동일한 키를 운용할 수 있으므로 요구사항을 충족하며 운영이 간단합니다.",
    "SelectC": "각 Region에 Customer managed KMS key와 S3 버킷을 생성합니다. 버킷을 SSE-S3로 서버측 암호화하도록 설정합니다. 두 버킷 간 복제를 구성합니다.",
    "SelectC_Commentary": "KMS key는 생성했지만 실제 버킷 암호화는 SSE-S3를 사용하므로 Customer managed key 요구사항에 부합하지 않습니다.",
    "SelectD": "각 Region에 Customer managed KMS key와 S3 버킷을 생성합니다. 버킷을 AWS KMS keys(SSE-KMS)로 서버측 암호화하도록 설정합니다. 두 버킷 간 복제를 구성합니다.",
    "SelectD_Commentary": "일반적인 KMS key는 Region 간 공유가 불가능하므로 동일한 키로 암호화·복호화한다는 조건을 만족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q640",
      "Q793",
      "Q1009",
      "Q681"
    ],
    "SelectA_recommedations": [
      "Q889",
      "Q868",
      "Q740"
    ],
    "SelectB_recommedations": [
      "Q36",
      "Q916",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q36",
      "Q1009",
      "Q740"
    ],
    "SelectD_recommedations": [
      "Q36",
      "Q793",
      "Q1009"
    ]
  },
  {
    "Question_Number": "Q37",
    "Question_Description": "한 회사가 최근에 본인의 AWS account에서 Amazon EC2 인스턴스 위에 다양한 신규 워크로드를 시작했습니다. 회사는 이러한 인스턴스에 원격으로 안전하게 접속하고 관리하기 위한 전략이 필요합니다. 이 프로세스는 반복 가능해야 하고, 네이티브 AWS 서비스를 활용하며, AWS Well-Architected Framework를 준수해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85037-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스에 대한 원격 액세스를 안전하고 반복 가능하게 설계하는 방법을 묻습니다. AWS Systems Manager Session Manager를 사용하면 인바운드 포트를 열 필요가 없고, SSH 키나 bastion host 관리 부담을 줄여 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "원격 액세스",
      "보안 관리",
      "반복 가능한 프로세스",
      "AWS Well-Architected Framework",
      "운영 오버헤드 최소화",
      "IAM role",
      "Session Manager"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS account",
      "EC2 serial console",
      "IAM role",
      "AWS Systems Manager Session Manager",
      "SSH key pair",
      "bastion host",
      "AWS Site-to-Site VPN",
      "AWS Well-Architected Framework"
    ],
    "SelectA": "각 인스턴스의 EC2 serial console을 사용하여 직접 터미널 인터페이스에 접근해 관리합니다.",
    "SelectA_Commentary": "serial console은 긴급 상황에서 유용하지만 개별 인스턴스마다 직접 접근해야 해 대규모 운영에는 비효율적입니다.",
    "SelectB": "모든 기존 및 신규 인스턴스에 적절한 IAM role을 연결하고, AWS Systems Manager Session Manager로 원격 SSH 세션을 설정합니다.",
    "SelectB_Commentary": "Session Manager는 인바운드 포트나 SSH 키 관리가 필요 없어 운영 부담이 크지 않으며, 보안과 확장성을 동시에 만족합니다.",
    "SelectC": "관리용 SSH key pair를 생성하고 공용 키를 각각의 EC2 인스턴스에 로드합니다. 퍼블릭 서브넷에 bastion host를 두어 터널링 방식으로 인스턴스를 관리합니다.",
    "SelectC_Commentary": "bastion host 운영과 SSH 키 관리를 지속해야 하므로 운영 절차가 복잡하고 오버헤드가 높습니다.",
    "SelectD": "AWS Site-to-Site VPN 연결을 설정하고, 온프레미스 머신에서 SSH 키를 이용해 VPN 터널로 인스턴스에 직접 접속하도록 안내합니다.",
    "SelectD_Commentary": "VPN 구성과 SSH 키 관리, 별도의 네트워크 설정 등이 추가로 필요하여 운영 부담이 높아집니다.",
    "Question_Description_recommedations": [
      "Q492",
      "Q176",
      "Q329",
      "Q949",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q453",
      "Q329"
    ],
    "SelectB_recommedations": [
      "Q517",
      "Q233",
      "Q232"
    ],
    "SelectC_recommedations": [
      "Q232",
      "Q480",
      "Q17"
    ],
    "SelectD_recommedations": [
      "Q782",
      "Q810",
      "Q232"
    ]
  },
  {
    "Question_Number": "Q38",
    "Question_Description": "한 회사가 Amazon S3를 통해 정적 웹사이트를 호스팅하고, DNS로 Amazon Route 53을 사용하고 있습니다. 전 세계적으로 웹사이트 트래픽이 증가해 사용자 접속 시 지연 시간(latency)을 줄여야 합니다. 가장 비용 효율적인 해결책은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85238-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 전 세계 사용자에게 정적 웹사이트를 빠르게 제공하고 비용을 최소화하기 위한 방안을 묻습니다. Amazon CloudFront를 사용하면 글로벌 엣지 로케이션에 콘텐츠를 캐싱하여 지연 시간을 낮추고, 별도의 복잡한 복제나 추가 인프라가 없어 가장 비용 효율적으로 성능을 개선할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "정적 웹사이트",
      "지연 시간 감소",
      "비용 효율",
      "Amazon S3",
      "Amazon Route 53",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Route 53",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "Geolocation Routing",
      "DNS",
      "Static Website"
    ],
    "SelectA": "웹사이트를 담고 있는 S3 버킷을 모든 AWS 리전에 복제합니다. Route 53 지리 위치(geolocation) 라우팅 규칙을 추가합니다.",
    "SelectA_Commentary": "모든 리전에 버킷 복제와 geolocation 라우팅 설정은 비용도 높고 구성도 복잡해져 비효율적입니다.",
    "SelectB": "AWS Global Accelerator를 프로비저닝하고 제공된 IP 주소를 해당 S3 버킷과 연결합니다. Route 53 레코드를 Accelerator IP로 수정합니다.",
    "SelectB_Commentary": "Global Accelerator는 추가 인프라와 비용이 늘어나며 CloudFront와 유사한 가속 기능을 중복으로 제공합니다.",
    "SelectC": "S3 버킷 앞에 Amazon CloudFront distribution을 추가하고, Route 53 레코드를 CloudFront distribution으로 수정합니다.",
    "SelectC_Commentary": "CloudFront의 글로벌 캐싱과 엣지 로케이션을 통해 지연 시간을 줄이고 운영 복잡성과 비용도 절감하는 최적의 솔루션입니다.",
    "SelectD": "S3 Transfer Acceleration을 활성화하고, Route 53 레코드를 새로운 엔드포인트로 수정합니다.",
    "SelectD_Commentary": "Transfer Acceleration은 주로 업로드 가속에 유리하며, 정적 웹사이트 전달 지연 시간 개선에는 제한적입니다.",
    "Question_Description_recommedations": [
      "Q1015",
      "Q704",
      "Q155",
      "Q173",
      "Q266"
    ],
    "SelectA_recommedations": [
      "Q38",
      "Q582",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q38",
      "Q582",
      "Q530"
    ],
    "SelectC_recommedations": [
      "Q38",
      "Q280",
      "Q582"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q1015",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q39",
    "Question_Description": "한 회사는 웹사이트에서 검색 가능한 아이템 저장소를 운영하고 있습니다. 이 데이터는 1천만 건이 넘는 레코드를 담은 Amazon RDS for MySQL 데이터베이스 테이블에 저장되어 있으며, General Purpose SSD 스토리지를 2TB 사용 중입니다. 회사 웹사이트를 통해 매일 수백만 건의 업데이트가 이루어지는데, 일부 insert 연산이 10초 이상 걸리는 현상을 발견했습니다. 데이터베이스 스토리지 성능이 문제로 확인되었습니다. 다음 중 이 성능 문제를 해결할 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84748-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 스토리지 I/O 성능이 병목이 되어 insert 연산이 지연되는 상황입니다. 높은 IOPS를 보장하는 Provisioned IOPS SSD로 전환하면 일관적이고 예측 가능한 스토리지 성능을 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "General Purpose SSD",
      "Provisioned IOPS SSD",
      "insert 연산 지연",
      "스토리지 성능 문제"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "General Purpose SSD",
      "Provisioned IOPS SSD",
      "memory optimized instance class",
      "burstable performance instance class",
      "Multi-AZ RDS",
      "MySQL native asynchronous replication",
      "RDS read replicas"
    ],
    "SelectA": "스토리지 타입을 Provisioned IOPS SSD로 변경합니다.",
    "SelectA_Commentary": "Provisioned IOPS SSD는 높은 IOPS를 보장하여 저장 연산 지연을 줄이는 데 가장 효과적입니다.",
    "SelectB": "DB 인스턴스를 memory optimized instance class로 변경합니다.",
    "SelectB_Commentary": "메모리 증가로 캐싱 효과를 기대할 수 있지만, 스토리지 I/O 병목 자체를 해결하지 못하므로 근본적 대안이 아닙니다.",
    "SelectC": "DB 인스턴스를 burstable performance instance class로 변경합니다.",
    "SelectC_Commentary": "버스팅 기능은 주로 CPU 성능 확장에 유리하며, 스토리지 성능 문제 해결과는 직접적인 관련이 없습니다.",
    "SelectD": "Multi-AZ RDS read replicas를 MySQL native asynchronous replication으로 활성화합니다.",
    "SelectD_Commentary": "읽기 성능 확장에는 도움이 되지만, 기본 DB에 대한 쓰기(insert) 성능 개선에는 도움이 되지 않습니다.",
    "Question_Description_recommedations": [
      "Q95",
      "Q376",
      "Q590",
      "Q726",
      "Q386"
    ],
    "SelectA_recommedations": [
      "Q496",
      "Q305",
      "Q299"
    ],
    "SelectB_recommedations": [
      "Q472",
      "Q225",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q472",
      "Q578",
      "Q225"
    ],
    "SelectD_recommedations": [
      "Q247",
      "Q481",
      "Q337"
    ]
  },
  {
    "Question_Number": "Q40",
    "Question_Description": "한 회사는 수천 대의 엣지 디바이스에서 매일 총 1TB의 상태 알림(status alerts)을 생성합니다. 각 알림은 약 2KB 정도의 크기입니다. 이제 솔루션스 아키텍트는 추후 분석을 위해 이러한 알림을 수집하고 저장하는 솔루션을 구축해야 합니다. 회사는 고가용성(highly available)을 원하면서도 비용을 최소화하고 추가 인프라 관리를 원치 않습니다. 또한 14일 동안은 데이터를 즉시 분석하기 위해 사용 가능해야 하며, 14일이 지난 데이터는 보관(archive)해야 합니다. 이 요구사항을 만족하면서 가장 운영 효율적인(MOST operationally efficient) 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85204-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 대규모 엣지 디바이스에서 생성되는 상태 알림을 자동으로 수집하고, 14일 동안은 신속하게 분석하며, 이후에는 저비용 스토리지로 보관하는 방안을 찾는 것입니다. Kinesis Data Firehose를 사용하면 완전 관리형 스트리밍 서비스로 알림을 안전하게 S3에 저장하고, Lifecycle 정책을 통해 데이터를 자동으로 Glacier로 이전할 수 있어 운영 효율성과 비용 절감을 모두 달성할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "2.2"
    ],
    "Keywords": [
      "엣지 디바이스",
      "알림 데이터",
      "고가용성",
      "코스트 최소화",
      "데이터 수집",
      "14일 보관",
      "장기 보관"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "S3 Lifecycle",
      "Amazon S3 Glacier",
      "Amazon EC2",
      "Elastic Load Balancer",
      "Amazon OpenSearch Service",
      "Amazon Simple Queue Service (Amazon SQS)"
    ],
    "SelectA": "Amazon Kinesis Data Firehose delivery stream을 생성하여 알림을 수집합니다. Kinesis Data Firehose 스트림에서 Amazon S3 버킷으로 알림을 전송하도록 구성합니다. 그리고 S3 Lifecycle 설정을 통해 14일 이후 데이터를 Amazon S3 Glacier로 이전하도록 구성합니다.",
    "SelectA_Commentary": "완전 관리형 스트리밍 서비스인 Kinesis Data Firehose와 S3 Lifecycle 설정만으로 구축 가능해 운영이 간소화되고, 비용도 절감됩니다.",
    "SelectB": "두 개의 가용 영역(Availability Zone)에 Amazon EC2 인스턴스를 띄우고, Elastic Load Balancer 뒤에 두어 알림을 수집합니다. EC2 인스턴스에 스크립트를 만들어 알림을 Amazon S3 버킷에 저장하도록 합니다. 14일 이후에는 S3 Lifecycle 정책을 통해 S3 Glacier로 이전합니다.",
    "SelectB_Commentary": "EC2 인스턴스 관리와 확장, 로드 밸런서 구성 등 추가 인프라가 필요해 운영 복잡도가 높아집니다.",
    "SelectC": "Amazon Kinesis Data Firehose delivery stream을 생성하여 알림을 수집합니다. Kinesis Data Firehose 스트림이 Amazon OpenSearch Service(이전 Amazon Elasticsearch Service) 클러스터로 알림을 전송하도록 구성합니다. OpenSearch Service 클러스터는 매일 수동 스냅샷을 찍고, 14일 이상 된 데이터는 클러스터에서 삭제합니다.",
    "SelectC_Commentary": "OpenSearch Service를 활용하면 검색과 분석이 쉽지만, 14일 이전 데이터 보관을 위해 수동으로 스냅샷을 관리해야 하므로 운영 부담이 큽니다.",
    "SelectD": "Amazon Simple Queue Service(Amazon SQS) 표준 큐를 생성하여 알림을 수집하고, 메시지 보존 기간을 14일로 설정합니다. 컨슈머는 SQS 큐를 폴링하면서 메시지의 연령을 확인해 필요 시 분석하고, 14일이 지난 메시지는 Amazon S3에 복사 후 큐에서 삭제합니다.",
    "SelectD_Commentary": "개발자가 메시지 연령 및 보관 처리를 직접 구현해야 하므로 코드와 인프라 관리가 까다롭습니다.",
    "Question_Description_recommedations": [
      "Q778",
      "Q583",
      "Q147",
      "Q372",
      "Q300"
    ],
    "SelectA_recommedations": [
      "Q373",
      "Q498",
      "Q415"
    ],
    "SelectB_recommedations": [
      "Q984",
      "Q773",
      "Q353"
    ],
    "SelectC_recommedations": [
      "Q373",
      "Q591",
      "Q670"
    ],
    "SelectD_recommedations": [
      "Q316",
      "Q167",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q41",
    "Question_Description": "어떤 회사의 애플리케이션은 여러 SaaS(Software-as-a-Service) 소스와 연동되어 데이터를 수집합니다. 회사는 Amazon EC2 인스턴스를 사용하여 데이터를 수신하고 Amazon S3 버킷으로 업로드한 뒤 분석에 활용합니다. 또한 같은 EC2 인스턴스가 업로드 완료 시점에 사용자에게 알림을 발송합니다. 현재 애플리케이션 성능이 저하되어 이를 최대한 개선하고자 합니다. 운영 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85446-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 SaaS 소스로부터 데이터를 수집해 S3에 업로드하고, 업로드 후 사용자에게 알리는 과정을 성능 저하 없이 진행하려면 어떻게 할지 묻습니다. 이미 Amazon EC2에 구현된 워크로드를 Auto Scaling group으로 확장하고, 알림 로직을 S3 event notification+Amazon SNS로 분리해 병목을 최소화하는 것이 가장 단순하고 효과적인 방법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "S3 버킷",
      "알림",
      "성능 향상",
      "운영 오버헤드",
      "Auto Scaling group",
      "S3 event notification",
      "Amazon SNS"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "Amazon SNS",
      "Auto Scaling group",
      "Amazon AppFlow",
      "Amazon EventBridge",
      "Docker container",
      "Amazon ECS",
      "Amazon CloudWatch Container Insights"
    ],
    "SelectA": "Amazon EC2 인스턴스가 확장 가능하도록 Auto Scaling group을 구성합니다. Amazon S3 버킷으로 업로드가 완료되면 Amazon S3 event notification을 통해 Amazon SNS 토픽으로 이벤트를 전송하도록 설정합니다.",
    "SelectA_Commentary": "기존 EC2 인스턴스를 유지하면서 확장성을 제공하고, 알림 단계를 S3 event notification으로 분리해 부하를 줄여 성능을 높이는 가장 간단하고 효과적인 솔루션입니다.",
    "SelectB": "각 SaaS 소스와 S3 버킷 간 데이터 전송을 위해 Amazon AppFlow 플로우를 생성합니다. S3 버킷으로 업로드가 완료되면 Amazon S3 event notification으로 Amazon SNS 토픽에 알림을 전송하도록 구성합니다.",
    "SelectB_Commentary": "Amazon AppFlow를 새로 구성하고 장애 시 처리를 고려해야 하므로 운영 오버헤드가 늘어납니다. 이미 있는 EC2 기반 워크로드 확장보다 설정과 관리가 복잡합니다.",
    "SelectC": "각 SaaS 소스별로 Amazon EventBridge(Amazon CloudWatch Events) 규칙을 설정해 데이터를 S3 버킷으로 전송합니다. S3 업로드 완료 시점을 감지하도록 두 번째 EventBridge 규칙을 생성하고, Amazon SNS 토픽을 대상으로 설정합니다.",
    "SelectC_Commentary": "EventBridge 규칙을 소스별로 설정하고 업로드 후 알림을 위한 이중 규칙을 구성해야 하므로, 새로운 인프라 구성이 많아집니다. 운영 오버헤드가 증가합니다.",
    "SelectD": "Docker 컨테이너를 만들어 Amazon EC2 인스턴스 대신 사용하고, Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. 업로드 완료 알림은 Amazon CloudWatch Container Insights로 Amazon SNS 토픽에 전달되도록 설정합니다.",
    "SelectD_Commentary": "기존 인스턴스를 폐기하고 컨테이너 기반으로 전환하며 추가 모니터링을 구성해야 하므로, 아키텍처 전체를 크게 변경하는 방안입니다. 요구사항 대비 과도하게 복잡합니다.",
    "Question_Description_recommedations": [
      "Q746",
      "Q173",
      "Q547",
      "Q155",
      "Q226"
    ],
    "SelectA_recommedations": [
      "Q335",
      "Q257",
      "Q461"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q402",
      "Q286"
    ],
    "SelectC_recommedations": [
      "Q41",
      "Q402",
      "Q680"
    ],
    "SelectD_recommedations": [
      "Q695",
      "Q857",
      "Q41"
    ]
  },
  {
    "Question_Number": "Q42",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 고가용성 이미지 처리 애플리케이션을 단일 VPC 내부에서 운영하고 있습니다. EC2 인스턴스들은 여러 가용 영역에 걸쳐 다양한 서브넷에 배치되어 있으며, 서로 간에는 통신하지 않습니다. 그러나 모든 EC2 인스턴스는 단일 NAT Gateway를 통해 Amazon S3로부터 이미지를 다운로드하고, Amazon S3로 이미지를 업로드합니다. 회사는 발생하는 데이터 전송 요금에 대해 우려하고 있습니다. 가장 비용 효율적인 방식으로 리전 간 데이터 전송 요금을 회피하기 위해서는 어떤 방법을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85205-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 NAT Gateway를 통해 S3로 데이터를 전송할 때 발생하는 비용을 최소화하는 방법을 찾는 것입니다. Gateway VPC Endpoint를 사용하면 VPC와 S3 간 트래픽이 인터넷으로 나가지 않아 전송 요금이 발생하지 않습니다. 따라서 S3에 대한 접근에 있어 가장 비용 효율적인 방식입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 전송 요금",
      "NAT Gateway",
      "Amazon S3",
      "Gateway VPC Endpoint"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC",
      "NAT Gateway",
      "Gateway VPC Endpoint for Amazon S3",
      "EC2 Dedicated Host"
    ],
    "SelectA": "각 가용 영역마다 NAT Gateway를 생성합니다.",
    "SelectA_Commentary": "가용 영역마다 NAT Gateway를 배포하면 중복성과 가용성은 높아지지만, NAT Gateway 요금이 여러 개로 늘어나 오히려 비용이 더 증가합니다.",
    "SelectB": "NAT Gateway 대신 NAT Instance를 사용합니다.",
    "SelectB_Commentary": "NAT Instance가 NAT Gateway보다 저렴할 수 있지만, 여전히 인터넷 트래픽 경로가 필요해 데이터 전송 요금 자체를 없애지는 못합니다.",
    "SelectC": "Amazon S3용 Gateway VPC Endpoint를 배포합니다.",
    "SelectC_Commentary": "S3로의 데이터 전송이 인터넷 경로를 거치지 않고 내부 통신으로 처리되어 전송 요금이 발생하지 않으므로 가장 비용 효율적인 솔루션입니다.",
    "SelectD": "EC2 Dedicated Host를 프로비저닝합니다.",
    "SelectD_Commentary": "Dedicated Host는 물리 서버 전용 사용을 위한 옵션으로, 데이터 전송 요금과는 무관하여 비용 절감 효과가 거의 없습니다.",
    "Question_Description_recommedations": [
      "Q497",
      "Q860",
      "Q471",
      "Q993",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q485",
      "Q728",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q485",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q497",
      "Q943",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q300",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q43",
    "Question_Description": "한 회사에는 온프레미스 애플리케이션이 있으며 이 애플리케이션은 대규모 시간 민감형 데이터를 생성하여 Amazon S3로 백업합니다. 최근 애플리케이션이 확장되면서 내부 사용자들이 인터넷 대역폭 제약에 대해 불만을 제기하고 있습니다. 솔루션스 아키텍트는 인터넷 연결에 미치는 영향을 최소화하면서도 Amazon S3로 신속하게 백업할 수 있는 장기 솔루션을 설계해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85206-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 대규모 데이터를 S3로 꾸준히 백업하면서, 내부 네트워크 혼잡을 줄이고 백업 속도를 확보하는 방안을 찾는 것입니다. VPN은 여전히 공용 인터넷에 의존하고, Snowball 매일 주문은 효율이 떨어집니다. S3 서비스 제한 해제 역시 대역폭 문제를 해결하지 못합니다. 따라서 전용 네트워크 연결 방식인 AWS Direct Connect가 장기적이고 안정적인 솔루션이 됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "온프레미스 백업",
      "시간 민감 데이터",
      "인터넷 대역폭 제약",
      "Amazon S3",
      "AWS Direct Connect"
    ],
    "Terms": [
      "AWS VPN",
      "VPC Gateway Endpoint",
      "AWS Direct Connect",
      "AWS Snowball",
      "S3 Service Limits",
      "Internet Bandwidth"
    ],
    "SelectA": "AWS VPN 연결을 구축하고 모든 트래픽을 VPC Gateway Endpoint를 통해 프록시합니다.",
    "SelectA_Commentary": "VPN은 여전히 인터넷을 사용하여 내부 대역폭 문제를 해결하지 못합니다.",
    "SelectB": "새로운 AWS Direct Connect 연결을 구축하고 백업 트래픽을 이 연결로 전송합니다.",
    "SelectB_Commentary": "전용 회선을 통해 인터넷을 우회하여 빠르고 안정적으로 백업이 가능하므로 요구사항을 충족합니다.",
    "SelectC": "매일 AWS Snowball 디바이스를 주문하여 데이터를 Snowball에 적재 후 AWS로 반환합니다.",
    "SelectC_Commentary": "매일 디바이스를 교환하는 방식은 장기적인 운영 측면에서 비효율적입니다.",
    "SelectD": "AWS Management Console에서 지원 티켓을 제출하여 계정의 S3 서비스 제한을 제거해 달라고 요청합니다.",
    "SelectD_Commentary": "S3 제한 설정을 풀어도 인터넷 대역폭 문제는 해결되지 않습니다.",
    "Question_Description_recommedations": [
      "Q501",
      "Q626",
      "Q672",
      "Q173",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q686",
      "Q957",
      "Q474"
    ],
    "SelectB_recommedations": [
      "Q734",
      "Q361",
      "Q443"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q515",
      "Q143"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q672",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q44",
    "Question_Description": "한 회사가 중요한 데이터를 저장한 Amazon S3 버킷을 보유합니다. 회사는 해당 데이터를 실수로 삭제하는 상황을 막아야 합니다. 이를 달성하기 위해 솔루션스 아키텍트는 어떤 두 단계를 수행해야 합니까? (2개 선택)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/84750-exam-aws-certified-solut",
    "AnswerDescription": "Versioning 활성화와 MFA Delete를 통한 2중 안전장치가 실수로 인한 객체 삭제를 방지하는 핵심 전략입니다. 다른 설정들은 보안이나 관리에는 도움이 되지만 삭제 방지를 완벽히 대체하지 못합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "Amazon S3 버킷",
      "실수로 인한 삭제 방지",
      "Versioning",
      "MFA Delete",
      "중요 데이터 보호"
    ],
    "Terms": [
      "S3 Versioning",
      "MFA Delete",
      "S3 Bucket Policy",
      "Default Encryption",
      "Lifecycle Policy"
    ],
    "SelectA": "S3 버킷에서 Versioning을 활성화합니다.",
    "SelectA_Commentary": "Versioning을 통해 객체의 이전 버전을 보관해 간단히 복원할 수 있습니다.",
    "SelectB": "S3 버킷에서 MFA Delete를 활성화합니다.",
    "SelectB_Commentary": "삭제 시 추가 인증을 요구해 실수 혹은 무단 삭제를 예방합니다.",
    "SelectC": "S3 버킷에 Bucket Policy를 생성합니다.",
    "SelectC_Commentary": "접근을 세분화할 수 있으나 삭제 방지 기능 자체는 제공하지 않습니다.",
    "SelectD": "S3 버킷에서 기본 암호화를 활성화합니다.",
    "SelectD_Commentary": "데이터 암호화는 보안을 향상하지만 삭제 방지와 직접적 연관이 없습니다.",
    "SelectE": "S3 버킷의 객체에 대해 Lifecycle Policy를 생성합니다.",
    "SelectE_Commentary": "객체 이동 및 만료 관리를 위한 것이며, 실수 삭제 방지 목적과는 다릅니다.",
    "Question_Description_recommedations": [
      "Q825",
      "Q925",
      "Q154",
      "Q202",
      "Q856"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q825",
      "Q678",
      "Q106"
    ],
    "SelectC_recommedations": [
      "Q256",
      "Q825",
      "Q678"
    ],
    "SelectD_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectE_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q45",
    "Question_Description": "한 회사는 다음과 같은 데이터 인제스트 워크플로우를 운영하고 있습니다:\n• 새로운 데이터 전달에 대한 알림을 위한 Amazon Simple Notification Service(Amazon SNS) 토픽\n• 데이터를 처리하고 메타데이터를 기록하기 위한 AWS Lambda 함수\n\n회사는 네트워크 연결 문제로 인해 인제스트 워크플로우가 간헐적으로 실패하는 것을 관찰했습니다. 이러한 실패가 발생하면, 회사가 수동으로 작업을 다시 실행하지 않는 이상 해당 Lambda 함수는 해당 데이터를 처리하지 않습니다.\n앞으로 Lambda 함수가 모든 데이터를 누락 없이 인제스트하도록 보장하기 위해 솔루션스 아키텍트가 취해야 할 조치 조합은 무엇입니까? (2개를 고르시오.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85408-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 네트워크 장애로 인한 알림 누락을 방지하기 위해 SNS와 Lambda 사이에 SQS를 도입하고, Lambda가 SQS에서 메시지를 읽도록 설계해 데이터 유실 없이 안정적으로 처리하도록 하는 것입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "데이터 인제스트",
      "네트워크 연결 문제",
      "Amazon SNS",
      "AWS Lambda",
      "Amazon SQS",
      "재시도",
      "큐 기반 아키텍처"
    ],
    "Terms": [
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Availability Zones",
      "CPU",
      "Memory",
      "Provisioned Throughput"
    ],
    "SelectA": "Lambda 함수를 여러 Availability Zone에 배포합니다.",
    "SelectA_Commentary": "Lambda는 이미 다중 AZ로 고가용성을 제공하므로 추가적인 다중 AZ 배포로 네트워크 연결 문제를 근본적으로 해결하기 어렵습니다.",
    "SelectB": "Amazon Simple Queue Service(Amazon SQS) 큐를 생성하고, 해당 큐를 SNS 토픽에 구독시킵니다.",
    "SelectB_Commentary": "SNS에서 온 메시지를 SQS에 저장함으로써 네트워크 장애 시에도 데이터가 큐에 적재되어 유실 없이 처리할 수 있습니다.",
    "SelectC": "Lambda 함수에 할당된 CPU와 메모리를 늘립니다.",
    "SelectC_Commentary": "CPU와 메모리를 늘려도 네트워크 연결 문제 자체를 해결할 수 없으므로 근본적인 대안이 아닙니다.",
    "SelectD": "Lambda 함수의 프로비저닝된 처리량을 늘립니다.",
    "SelectD_Commentary": "프로비저닝된 처리량은 Lambda를 더 자주 혹은 빠르게 실행하기 위한 방식이며, 네트워크 장애로 인한 실패에는 직접적인 해결 효과가 없습니다.",
    "SelectE": "Lambda 함수를 수정하여 Amazon SQS 큐에서 메시지를 읽도록 합니다.",
    "SelectE_Commentary": "Lambda를 SQS 트리거로 동작하도록 구성하면, 장애 발생 시에도 큐에 쌓인 데이터를 재시도할 수 있어 안정적인 데이터 처리 환경을 확보할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q148",
      "Q98",
      "Q785",
      "Q636",
      "Q404"
    ],
    "SelectA_recommedations": [
      "Q758",
      "Q987",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q636",
      "Q203",
      "Q98"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q8",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q187",
      "Q917",
      "Q58"
    ],
    "SelectE_recommedations": [
      "Q785",
      "Q404",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q46",
    "Question_Description": "한 회사가 매장에서 발생하는 이전 구매 기록을 기반으로 마케팅 서비스를 제공하는 애플리케이션을 운영하고 있습니다. 매장들은 SFTP를 통해 거래 데이터를 회사로 업로드하며, 업로드된 데이터는 분석 및 처리되어 새로운 마케팅 제안을 생성합니다. 일부 파일은 200GB를 초과할 수 있습니다. 최근, 몇몇 매장에서 포함되어서는 안 될 개인정보(PII)가 업로드된 사실이 확인되었습니다. 회사는 PII가 다시 업로드될 경우 관리자에게 알림을 보내고, 자동으로 조치가 수행되기를 원합니다. 가장 적은 개발 작업으로 이를 만족시키려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85264-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 외부 매장에서 업로드되는 대형 파일에 포함된 PII를 자동으로 탐지하고, 최소한의 개발 노력으로 보안 위협을 방지하는 방법을 묻습니다. Amazon Macie는 S3 객체를 자동으로 스캔하여 PII를 식별할 수 있고, SNS 알림을 통해 관리자가 빠르게 대응할 수 있습니다. 별도의 맞춤 알고리즘 설계 없이 간단히 설정 가능하므로 개발 부담이 적습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "SFTP",
      "Amazon Macie",
      "PII",
      "자동화된 조치",
      "S3 Lifecycle"
    ],
    "Terms": [
      "SFTP",
      "Amazon S3",
      "Amazon Inspector",
      "Amazon Macie",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Email Service (Amazon SES)",
      "S3 Lifecycle policy"
    ],
    "SelectA": "Amazon S3 버킷을 안전한 전송 지점으로 사용하고, Amazon Inspector로 버킷의 객체를 스캔합니다. PII가 포함된 객체가 발견되면 S3 Lifecycle policy로 해당 객체를 제거하도록 합니다.",
    "SelectA_Commentary": "Amazon Inspector는 취약점 스캐닝 서비스로 PII 탐지를 지원하지 않습니다. 요구사항에 부합하지 않습니다.",
    "SelectB": "Amazon S3 버킷을 안전한 전송 지점으로 사용하고, Amazon Macie로 버킷의 객체를 스캔합니다. PII가 포함되어 있으면 Amazon SNS로 관리자에게 알림을 보내고, 관리자가 해당 객체를 제거합니다.",
    "SelectB_Commentary": "Amazon Macie로 PII를 손쉽게 탐지하고 SNS 알림을 자동화하며, 추가 개발이 최소화됩니다. 자동화된 탐지와 알림으로 신속 대응이 가능합니다.",
    "SelectC": "AWS Lambda 함수에 맞춤형 스캐닝 알고리즘을 구현하고, 객체가 버킷에 업로드될 때 이를 트리거합니다. PII가 포함된 경우 Amazon SNS를 통해 관리자에게 알림을 보내 해당 객체를 제거합니다.",
    "SelectC_Commentary": "직접 스캐너를 개발해야 하므로 개발 노력이 많이 들며, 자동으로 제거가 이뤄지지 않습니다.",
    "SelectD": "AWS Lambda 함수에 맞춤형 스캐닝 알고리즘을 구현하고, 객체가 버킷에 업로드될 때 이를 트리거합니다. PII가 포함된 경우 Amazon SES로 관리자에게 알림을 보내고, S3 Lifecycle policy를 통해 해당 객체를 제거합니다.",
    "SelectD_Commentary": "맞춤 알고리즘 구현과 SES 연동이 필요해 개발 부담이 크며, Macie 활용 대비 간단하지 않습니다.",
    "Question_Description_recommedations": [
      "Q756",
      "Q204",
      "Q154",
      "Q533",
      "Q816"
    ],
    "SelectA_recommedations": [
      "Q533",
      "Q295",
      "Q553"
    ],
    "SelectB_recommedations": [
      "Q533",
      "Q756",
      "Q359"
    ],
    "SelectC_recommedations": [
      "Q295",
      "Q936",
      "Q533"
    ],
    "SelectD_recommedations": [
      "Q289",
      "Q403",
      "Q913"
    ]
  },
  {
    "Question_Number": "Q47",
    "Question_Description": "한 회사가 다가오는 1주일간의 이벤트를 위해 특정 AWS Region 내의 세 Availability Zones에서 Amazon EC2 용량을 보장받아야 합니다. 어떤 방법을 사용해야 Amazon EC2 용량을 보장할 수 있습니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85529-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 짧은 기간(1주일) 동안 특정 AWS Region과 세 Availability Zones에서 확실하게 Amazon EC2 용량을 확보하는 방법을 묻습니다. Reserved Instances는 장기적으로 비용을 절감하는 옵션이지만, 즉각적인 용량 보장을 위해서는 On-Demand Capacity Reservation이 적합합니다. 원하는 Region과 Availability Zones를 지정해두면 해당 기간 동안 필요한 EC2 용량이 고정적으로 예약되어 이벤트 트래픽을 안정적으로 처리할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "AWS Region",
      "Availability Zones",
      "On-Demand Capacity Reservation",
      "Reserved Instances"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "AWS Region",
      "On-Demand Capacity Reservation",
      "Reserved Instances"
    ],
    "SelectA": "해당 Region만 지정한 Reserved Instances를 구매합니다.",
    "SelectA_Commentary": "Reserved Instances는 장기 사용 시 비용 절감에 초점이 있어, 기간 한정 이벤트에서 특정 AZ 용량 보장을 확실히 제공하지 못합니다.",
    "SelectB": "해당 Region만 지정한 On-Demand Capacity Reservation을 생성합니다.",
    "SelectB_Commentary": "Region만 지정하면 특정 AZ별로 할당이 보장되지 않아 원하는 세 Availability Zones 모두에 대한 용량을 확실히 보장하기 어렵습니다.",
    "SelectC": "해당 Region과 세 Availability Zones를 지정한 Reserved Instances를 구매합니다.",
    "SelectC_Commentary": "Reserved Instances로 AZ까지 지정은 가능하나, 일반적으로 1주일과 같은 단기 이벤트에는 장기 계약인 Reserved Instances가 비효율적입니다.",
    "SelectD": "해당 Region과 세 Availability Zones를 지정한 On-Demand Capacity Reservation을 생성합니다.",
    "SelectD_Commentary": "정확히 필요한 기간과 AZ를 지정해 필요한 EC2 용량을 즉시 예약하고, 원하는 기간 동안 안정적으로 용량을 확보할 수 있는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q456",
      "Q312",
      "Q224",
      "Q570",
      "Q691"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q363",
      "Q362"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q311",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q758",
      "Q570",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q758",
      "Q691",
      "Q47"
    ]
  },
  {
    "Question_Number": "Q48",
    "Question_Description": "한 회사의 웹사이트는 카탈로그를 Amazon EC2 instance store에 저장하고 있습니다. 회사는 해당 카탈로그를 고가용성으로 유지하고 내구성 높은 위치에 저장하고자 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85119-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 EC2 instance store가 휘발성 스토리지이므로 카탈로그 데이터를 안정적이고 내구성 있는, 그리고 고가용성을 지원하는 스토리지로 이전해야 하는 시나리오입니다. 정답이 Amazon EFS인 이유는 EFS가 멀티 AZ 환경에서의 내구성과 고가용성을 보장하기 때문입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "카탈로그",
      "고가용성",
      "내구성",
      "Amazon EFS"
    ],
    "Terms": [
      "Amazon EC2 instance store",
      "Amazon EFS",
      "Amazon ElastiCache for Redis",
      "Amazon S3 Glacier Deep Archive"
    ],
    "SelectA": "카탈로그를 Amazon ElastiCache for Redis로 이전합니다.",
    "SelectA_Commentary": "ElastiCache는 인메모리 캐시 서비스로, 영구 저장용도가 아니어서 카탈로그를 내구적으로 보존하기 어렵습니다.",
    "SelectB": "인스턴스 스토리지가 더 큰 EC2 인스턴스로 배포합니다.",
    "SelectB_Commentary": "인스턴스 스토리지는 EC2 인스턴스가 중단될 경우 데이터가 사라질 수 있는 휘발성 스토리지입니다.",
    "SelectC": "인스턴스 스토어의 카탈로그를 Amazon S3 Glacier Deep Archive로 이전합니다.",
    "SelectC_Commentary": "S3 Glacier Deep Archive는 장기 보관에 적합하지만, 즉시 접근이 어려워 고가용성 요구사항에 부합하지 않습니다.",
    "SelectD": "카탈로그를 Amazon Elastic File System(Amazon EFS) 파일 시스템으로 이전합니다.",
    "SelectD_Commentary": "EFS는 멀티 AZ를 통해 뛰어난 내구성과 고가용성을 제공하므로 카탈로그 저장에 가장 적합한 선택입니다.",
    "Question_Description_recommedations": [
      "Q584",
      "Q244",
      "Q757",
      "Q252",
      "Q110"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q48",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q584",
      "Q194",
      "Q252"
    ],
    "SelectC_recommedations": [
      "Q784",
      "Q8",
      "Q149"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q102",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q49",
    "Question_Description": "한 회사에서 매달 콜 녹취 파일을 저장하고 있습니다. 사용자들은 콜 후 1년 이내에는 이 파일들을 무작위로 자주 액세스하지만, 1년 이후에는 거의 액세스하지 않습니다. 회사는 1년 미만 된 파일들을 가능한 한 빠르게 조회하고 가져올 수 있도록 최적화하면서, 오래된 파일을 가져오는 데 지연이 있어도 괜찮은 솔루션을 원합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85211-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 1년 이내에는 자주 접근하고, 이후에는 드물게 접근하는 콜 녹취 파일의 저장 비용을 최적화하는 방법을 묻습니다. S3 Intelligent-Tiering을 활용하면 자동 티어 조정이 가능하고, 1년 뒤에는 S3 Glacier Flexible Retrieval로 전환하여 비용을 절감할 수 있습니다. 특히 필요 시 Amazon Athena나 S3 Glacier Select로 데이터 조회가 가능해 빠른 액세스와 저렴한 보관비용을 모두 만족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "콜 녹취 파일",
      "1년 이내 빈번한 조회",
      "1년 후 드문 조회",
      "비용 효율",
      "S3 Intelligent-Tiering",
      "S3 Glacier Flexible Retrieval",
      "Amazon Athena",
      "S3 Glacier Select"
    ],
    "Terms": [
      "S3 Glacier Instant Retrieval",
      "S3 Glacier Flexible Retrieval",
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 Lifecycle",
      "Amazon Athena",
      "S3 Glacier Select",
      "Amazon RDS"
    ],
    "SelectA": "Amazon S3 Glacier Instant Retrieval에 각 파일을 태그와 함께 저장하고, 태그를 조회하여 파일을 S3 Glacier Instant Retrieval에서 가져옵니다.",
    "SelectA_Commentary": "Instant Retrieval은 검색 속도는 빠르지만 1년 이내 자주 조회되는 데이터에 대해서는 S3 Intelligent-Tiering보다 비용 효율이 떨어집니다.",
    "SelectB": "Amazon S3 Intelligent-Tiering에 각 파일을 저장합니다. 1년 후에는 S3 Lifecycle 정책을 사용하여 S3 Glacier Flexible Retrieval로 객체를 이동시킵니다. Amazon Athena로 S3에 있는 파일을 조회하고, S3 Glacier Select로 Glacier에 있는 파일을 조회합니다.",
    "SelectB_Commentary": "예측이 어려운 액세스 패턴에서 Intelligent-Tiering은 자동으로 비용 최적화 효과를 제공하며, 1년 후 Glacier Flexible Retrieval로 이동하여 가장 효율적입니다.",
    "SelectC": "Amazon S3 Standard 스토리지에 각 파일을 태그와 함께 저장하고, 각 파일의 검색 메타데이터를 Amazon S3 Standard에 별도로 보관합니다. 1년 후에는 S3 Lifecycle 정책을 통해 파일을 S3 Glacier Instant Retrieval로 이동합니다. Amazon S3에서 메타데이터를 검색해 파일을 조회 및 가져옵니다.",
    "SelectC_Commentary": "메타데이터를 이중 관리해야 해서 복잡도가 높고, Glacier Instant Retrieval은 Intelligent-Tiering에 비해 가격이 더 부담됩니다.",
    "SelectD": "Amazon S3 Standard에 각 파일을 저장합니다. 1년 후에는 S3 Glacier Deep Archive로 파일을 이동하도록 S3 Lifecycle 정책을 설정합니다. 검색 메타데이터를 Amazon RDS에 저장합니다. RDS에서 파일을 조회하고 S3 Glacier Deep Archive에서 파일을 가져옵니다.",
    "SelectD_Commentary": "Deep Archive는 보관 비용은 저렴하지만 검색 시 복원 시간이 길고, 별도의 DB를 이용해 메타데이터를 관리해야 해 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q794",
      "Q630",
      "Q997",
      "Q656",
      "Q930"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q469",
      "Q769"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q415",
      "Q356"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q912",
      "Q415",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q50",
    "Question_Description": "회사는 1,000개의 Amazon EC2 Linux 인스턴스에서 프로덕션 워크로드를 운영하고 있습니다. 해당 워크로드는 타사 소프트웨어에 의존하며, 보안 취약점을 가능한 한 신속하게 패치해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/about-windows-",
    "AnswerDescription": "이 문제는 대규모 EC2 인스턴스 환경에서 보안 패치를 빠르고 일관되게 적용하는 방법을 묻습니다. 선택지는 각기 다른 AWS 기능을 활용하는 시나리오를 제시하며, 긴급 패치가 요구되는 상황에서 가장 효율적인 방안을 고르는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "EC2 Linux 인스턴스",
      "프로덕션 워크로드",
      "타사 소프트웨어",
      "보안 취약성",
      "패치",
      "AWS Systems Manager Run Command"
    ],
    "Terms": [
      "AWS Lambda",
      "AWS Systems Manager Patch Manager",
      "AWS Systems Manager Maintenance Window",
      "AWS Systems Manager Run Command",
      "Amazon EC2",
      "Patch",
      "Resource Groups"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 모든 EC2 인스턴스에 패치를 적용합니다.",
    "SelectA_Commentary": "Lambda를 통한 대규모 패치는 자동화 면에서 제약이 많고, 각 인스턴스별 작업 흐름 제어가 복잡하여 즉시 쓸 수 있는 최적의 방식이 아닙니다.",
    "SelectB": "모든 EC2 인스턴스에 패치를 적용하도록 AWS Systems Manager Patch Manager를 구성합니다.",
    "SelectB_Commentary": "Patch Manager는 자동 승인을 통한 단계적 관리를 제공하지만, 구성 후 자동화 및 승인 절차로 인해 ‘가능한 한 빨리’라는 요구사항을 만족하기에는 시간이 더 소요될 수 있습니다.",
    "SelectC": "AWS Systems Manager 유지 관리 기간을 예약하여 모든 EC2 인스턴스에 패치를 적용합니다.",
    "SelectC_Commentary": "유지 관리 기간(Maintenance Window)은 특정 시간에 맞춰 작업을 예약하는 방식이므로 긴급 패치에는 적합하지 않습니다.",
    "SelectD": "AWS Systems Manager Run Command를 사용하여 모든 EC2 인스턴스에 패치를 적용하는 사용자 지정 명령을 실행합니다.",
    "SelectD_Commentary": "Run Command는 여러 인스턴스에서 동시에 명령을 실행할 수 있어 대규모 환경에서도 빠르고 일관된 보안 패치 적용이 가능합니다.",
    "Question_Description_recommedations": [
      "Q682",
      "Q315",
      "Q100",
      "Q329",
      "Q480"
    ],
    "SelectA_recommedations": [
      "Q936",
      "Q791",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q682",
      "Q453",
      "Q612"
    ],
    "SelectC_recommedations": [
      "Q723",
      "Q492",
      "Q517"
    ],
    "SelectD_recommedations": [
      "Q723",
      "Q682",
      "Q492"
    ]
  },
  {
    "Question_Number": "Q51",
    "Question_Description": "한 회사가 REST API로 조회할 수 있는 주문 배송 통계 애플리케이션을 개발하고 있습니다. 회사는 매일 아침 정해진 시간에 주문 배송 통계를 추출하여, 데이터를 읽기 쉬운 HTML 형식으로 정리하고 여러 이메일 주소로 보고서를 전송하려고 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계를 조합해서 수행해야 합니까? (2개를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85557-exam-aws-certified-solut",
    "AnswerDescription": "매일 일정 시간에 REST API로부터 데이터를 조회하고, HTML로 변환 후 여러 이메일로 전송해야 합니다. 이를 위해 Amazon EventBridge를 사용해 스케줄링하고, AWS Lambda로 데이터를 불러온 뒤 Amazon SES로 HTML 형식 보고서를 전송하는 구성이 간단하고 효과적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "주문 배송 통계",
      "HTML 보고서",
      "이메일 전송",
      "EventBridge",
      "Lambda",
      "SES"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "Amazon Simple Email Service (Amazon SES)",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "AWS Glue",
      "AWS Lambda",
      "Amazon S3",
      "Amazon Simple Notification Service (Amazon SNS)"
    ],
    "SelectA": "애플리케이션에서 Amazon Kinesis Data Firehose로 데이터를 전송하도록 구성합니다.",
    "SelectA_Commentary": "Kinesis Data Firehose는 실시간 스트리밍 데이터를 저장·변환할 때 유용하지만, 매일 아침 정기 보고서 전송에는 적합하지 않습니다.",
    "SelectB": "Amazon Simple Email Service(Amazon SES)를 사용하여 데이터를 HTML로 형식화하고 이메일로 보고서를 전송합니다.",
    "SelectB_Commentary": "HTML 형식 보고서 전송을 간편하게 구현할 수 있는 핵심 구성요소이며, 여러 이메일 주소로 동시 전송도 간단합니다. (정답)",
    "SelectC": "Amazon EventBridge(Amazon CloudWatch Events) 스케줄 이벤트를 생성하여 AWS Glue 작업이 애플리케이션의 API에서 데이터를 조회하도록 합니다.",
    "SelectC_Commentary": "AWS Glue는 주로 데이터베이스나 S3 크롤링 및 ETL에 활용됩니다. 단순 API 조회에는 Lambda가 더 간편합니다.",
    "SelectD": "Amazon EventBridge(Amazon CloudWatch Events) 스케줄 이벤트를 생성하여 AWS Lambda 함수를 호출해 애플리케이션의 API에서 데이터를 조회합니다.",
    "SelectD_Commentary": "Lambda를 사용하면 매일 특정 시간에 API에서 데이터를 가져와 HTML 보고서 생성을 위한 준비를 쉽게 할 수 있습니다. (정답)",
    "SelectE": "애플리케이션 데이터를 Amazon S3에 저장합니다. S3 이벤트 대상로 Amazon SNS 토픽을 생성하여 이메일로 보고서를 전송합니다.",
    "SelectE_Commentary": "S3 이벤트 트리거나 SNS만으로는 HTML 형식 변환과 스케줄링 시간이 맞춰진 전송을 구현하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q567",
      "Q798",
      "Q228",
      "Q611",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q845",
      "Q8",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q363",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q569",
      "Q10",
      "Q351"
    ],
    "SelectD_recommedations": [
      "Q569",
      "Q10",
      "Q739"
    ],
    "SelectE_recommedations": [
      "Q784",
      "Q110",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q52",
    "Question_Description": "한 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 수십 GB부터 수백 TB까지 다양한 크기의 출력 파일을 생성합니다. 애플리케이션 데이터는 표준 파일 시스템 구조로 저장되어야 합니다. 회사는 자동 확장, 고가용성, 최소한의 운영 오버헤드를 요구하는 솔루션을 찾고 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85265-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 온프레미스 애플리케이션을 AWS로 이전하면서 수십 GB~수백 TB 규모의 데이터를 표준 파일 시스템 형태로 보관해야 하는 상황입니다. Amazon EFS는 파일 시스템 구조를 제공하면서 자동 확장 및 Multi-AZ 고가용성을 지원하므로, 운영 부담을 줄이기에 가장 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "마이그레이션",
      "표준 파일 시스템",
      "자동 확장",
      "고가용성",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon ECS",
      "Amazon EKS",
      "Amazon EC2",
      "Amazon EBS",
      "Amazon EFS",
      "Auto Scaling group",
      "Multi-AZ"
    ],
    "SelectA": "애플리케이션을 Amazon ECS 컨테이너로 마이그레이션하고, Amazon S3를 스토리지로 사용합니다.",
    "SelectA_Commentary": "S3는 객체 스토리지로, 표준 파일 시스템 요구사항을 충족하지 못합니다.",
    "SelectB": "애플리케이션을 Amazon EKS 컨테이너로 마이그레이션하고, Amazon EBS를 스토리지로 사용합니다.",
    "SelectB_Commentary": "EBS는 EC2 인스턴스에 종속적이며, 대규모 자동 확장이나 Multi-AZ 가용성 보장 측면에서 제한적입니다.",
    "SelectC": "애플리케이션을 Multi-AZ Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행하고, Amazon EFS를 스토리지로 사용합니다.",
    "SelectC_Commentary": "표준 파일 시스템 구조, Multi-AZ 고가용성, 자동 확장을 모두 지원하므로 요구사항에 부합하는 최적의 솔루션입니다.",
    "SelectD": "애플리케이션을 Multi-AZ Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행하고, Amazon EBS를 스토리지로 사용합니다.",
    "SelectD_Commentary": "EBS는 인스턴스 단위로 볼륨을 관리하므로 확장성과 고가용성 면에서 EFS보다 제한적입니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q163",
      "Q363",
      "Q149",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q110",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q8",
      "Q615"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q53",
    "Question_Description": "한 회사가 회계 데이터를 Amazon S3에 저장해야 합니다. 이 데이터는 1년 동안 즉시 접근 가능해야 하며, 이후 9년 동안은 장기 보관해야 합니다. 또한 회사 내 관리자 계정과 root 계정을 포함하여 10년의 전체 보존 기간 동안 아무도 데이터를 삭제할 수 없어야 합니다. 그리고 이 데이터는 최대한 높은 내구성을 가지는 스토리지에 저장되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85532-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 회계 데이터에 대한 장기 보존 정책과 삭제 방지 요구사항을 충족해야 하므로, S3 Object Lock의 compliance mode와 Lifecycle 정책을 활용하는 방법이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "회계 데이터 저장",
      "10년 보존",
      "즉시 접근 1년",
      "장기 보관 9년",
      "S3 Object Lock",
      "compliance mode",
      "S3 Glacier Deep Archive"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Glacier",
      "S3 Intelligent-Tiering",
      "S3 Glacier Deep Archive",
      "S3 Object Lock",
      "compliance mode",
      "governance mode",
      "S3 Lifecycle policy",
      "IAM policy"
    ],
    "SelectA": "S3 Glacier에 10년 전체 기간 동안 레코드를 저장합니다. 10년 동안 레코드 삭제를 거부하도록 하는 access control policy를 사용합니다.",
    "SelectA_Commentary": "S3 Glacier만 사용하고 policy로만 삭제를 막는 방식은 root나 관리자 권한을 완전히 제한할 수 없고, 1년간 즉시 접근 요건에도 부적합합니다.",
    "SelectB": "S3 Intelligent-Tiering을 사용하여 레코드를 저장합니다. IAM policy로 10년 동안 삭제를 거부한 뒤, 10년 후 정책을 변경합니다.",
    "SelectB_Commentary": "IAM policy만으로는 최상위 권한 계정의 삭제 방지를 완벽히 보장하기 어렵고, 별도의 장기 보관 방식도 고려되지 않아 요구사항에 부합하지 않습니다.",
    "SelectC": "1년 후 S3 Standard에서 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle policy를 설정하고, S3 Object Lock의 compliance mode를 10년간 적용합니다.",
    "SelectC_Commentary": "compliance mode는 root나 관리자도 삭제 못 하게 하며, 1년 즉시 접근 후 9년 장기 보관 요구사항을 모두 만족시키는 올바른 솔루션입니다.",
    "SelectD": "1년 후 S3 Standard에서 S3 One Zone-Infrequent Access로 전환하는 S3 Lifecycle policy를 사용하고, S3 Object Lock의 governance mode를 10년간 적용합니다.",
    "SelectD_Commentary": "governance mode는 적절한 권한을 가진 사용자가 삭제를 해제할 수 있어, root 계정 등도 삭제를 막지 못하는 위험이 있어 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q154",
      "Q44",
      "Q856",
      "Q825",
      "Q106"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q53"
    ],
    "SelectB_recommedations": [
      "Q477",
      "Q423",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q740",
      "Q801",
      "Q256"
    ],
    "SelectD_recommedations": [
      "Q740",
      "Q801",
      "Q868"
    ]
  },
  {
    "Question_Number": "Q54",
    "Question_Description": "한 회사가 AWS에서 여러 Windows 워크로드를 운영하고 있습니다. 회사의 직원들은 두 개의 Amazon EC2 인스턴스에 호스팅된 Windows file shares를 사용합니다. 해당 file share들은 서로 간 데이터를 동기화하며 중복 사본을 유지하고 있습니다. 회사는 현재 사용자가 파일에 접근하는 방식을 유지하면서, 고가용성(High Availability)과 내구성(Durability)을 갖춘 스토리지 솔루션을 원합니다. 이를 만족하기 위한 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85574-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 Windows 환경 특유의 SMB 기반 파일 공유 방식을 유지하면서, 고가용성과 내구성을 높이는 스토리지를 선택하는 것입니다. Amazon FSx for Windows File Server는 Windows 네이티브 프로토콜을 완벽히 지원하므로 요구사항을 모두 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Windows file shares",
      "고가용성",
      "내구성",
      "FSx for Windows File Server",
      "Multi-AZ"
    ],
    "Terms": [
      "Amazon EC2",
      "Windows file shares",
      "Amazon S3",
      "IAM",
      "S3 File Gateway",
      "Amazon FSx for Windows File Server",
      "Multi-AZ",
      "Amazon EFS"
    ],
    "SelectA": "모든 데이터를 Amazon S3로 마이그레이션하고 사용자가 파일에 접근할 수 있도록 IAM 인증을 설정합니다.",
    "SelectA_Commentary": "S3는 Windows의 SMB 프로토콜을 그대로 지원하지 않으므로 사용자 측 접근 방식을 유지하기 어렵습니다.",
    "SelectB": "Amazon S3 File Gateway를 설정하고, 기존 EC2 인스턴스에 S3 File Gateway를 마운트합니다.",
    "SelectB_Commentary": "S3 File Gateway는 파일 공유를 위한 일부 기능을 제공하지만, Windows ACL 등 완전한 Windows 파일 공유 호환성을 보장하지 못합니다.",
    "SelectC": "Amazon FSx for Windows File Server 환경을 Multi-AZ로 확장하고, 모든 데이터를 FSx for Windows File Server로 마이그레이션합니다.",
    "SelectC_Commentary": "Amazon FSx for Windows File Server는 Windows 네이티브 파일 시스템과 호환되어 고가용성과 내구성을 제공하므로 요구사항에 가장 적합한 솔루션입니다.",
    "SelectD": "Amazon Elastic File System(Amazon EFS)에 Multi-AZ 구성을 추가하고, 모든 데이터를 EFS로 마이그레이션합니다.",
    "SelectD_Commentary": "Amazon EFS는 Linux 기반 파일 시스템으로, Windows 파일 공유 방식(SMB)에 대한 지원이 불가능하므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q186",
      "Q892",
      "Q972",
      "Q934",
      "Q790"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q94",
      "Q188"
    ],
    "SelectB_recommedations": [
      "Q188",
      "Q194",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q618",
      "Q54",
      "Q934"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q102",
      "Q934"
    ]
  },
  {
    "Question_Number": "Q55",
    "Question_Description": "한 솔루션스 아키텍트가 여러 서브넷을 포함하는 VPC 아키텍처를 설계하고 있습니다. 이 아키텍처는 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스를 사용하며, 두 개의 가용 영역(Availability Zone)에 걸쳐 총 6개의 서브넷으로 구성됩니다. 각 가용 영역에는 Public Subnet, Private Subnet, Database용 전용 Subnet이 각각 존재합니다. Private Subnet에서 실행 중인 EC2 인스턴스만이 RDS Database에 액세스할 수 있어야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85409-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 서로 다른 서브넷 간 트래픽을 제어하여 Private Subnet에서만 RDS DB에 접근하도록 하는 방법을 묻습니다. 보안 그룹(Security Group)은 기본적으로 허용 규칙만 설정 가능하며, 원하는 소스(Private Subnet의 인스턴스)에 대해서만 Inbound 허용 규칙을 생성하여 트래픽을 제한하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC 아키텍처",
      "Amazon EC2",
      "Amazon RDS",
      "서브넷 구성",
      "Private Subnet",
      "데이터베이스 접근 제어"
    ],
    "Terms": [
      "VPC",
      "EC2",
      "RDS",
      "Security Group",
      "Route Table",
      "CIDR block",
      "VPC Peering"
    ],
    "SelectA": "Public Subnet의 CIDR 블록으로 가는 라우트를 제외한 새로운 Route Table을 생성하고, Database Subnet에 연결합니다.",
    "SelectA_Commentary": "Route Table만으로는 Database Subnet의 Inbound 흐름 제어를 완전히 해결하지 못하므로 적절한 접근 제한에 부족합니다.",
    "SelectB": "Public Subnet에 할당된 인스턴스의 Security Group으로부터 들어오는 트래픽을 거부하는 Security Group을 생성하고, DB 인스턴스에 할당합니다.",
    "SelectB_Commentary": "Security Group에서는 거부(Deny) 규칙이 불가능하므로 이 방법은 구현할 수 없습니다.",
    "SelectC": "Private Subnet에 할당된 인스턴스의 Security Group으로부터 들어오는 트래픽을 허용하는 Security Group을 생성하고, DB 인스턴스에 할당합니다.",
    "SelectC_Commentary": "Security Group은 기본적으로 허용 규칙만 설정 가능하므로, Private Subnet 인스턴스만 접근 허용 규칙을 두면 요구 사항을 충족합니다.",
    "SelectD": "Public Subnet과 Private Subnet 간 새로운 Peering Connection을 생성하고, Private Subnet과 Database Subnet 간 별도의 Peering Connection을 생성합니다.",
    "SelectD_Commentary": "VPC Peering은 주로 서로 다른 VPC 간 트래픽을 연결하기 위한 것이며, 같은 VPC 내 Subnet 간 트래픽 제어에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q370",
      "Q388",
      "Q251",
      "Q555",
      "Q950"
    ],
    "SelectA_recommedations": [
      "Q468",
      "Q657",
      "Q875"
    ],
    "SelectB_recommedations": [
      "Q74",
      "Q774",
      "Q385"
    ],
    "SelectC_recommedations": [
      "Q74",
      "Q468",
      "Q774"
    ],
    "SelectD_recommedations": [
      "Q468",
      "Q875",
      "Q509"
    ]
  },
  {
    "Question_Number": "Q56",
    "Question_Description": "한 회사가 Amazon Route 53을 통해 도메인 이름을 등록했습니다. 회사는 ca-central-1 리전에서 Amazon API Gateway를 퍼블릭 인터페이스로 사용하여 백엔드 마이크로서비스 API를 제공하고 있으며, 서드파티 서비스들이 보안 연결을 통해 API를 소비하고 있습니다. 회사는 서드파티 서비스가 HTTPS를 사용할 수 있도록, 회사의 도메인 이름과 해당 인증서를 사용해 API Gateway URL을 구성하고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85266-exam-aws-certified-solut",
    "AnswerDescription": "API Gateway에 커스텀 도메인 이름과 HTTPS를 적용하려면, 동일한 리전 내 ACM 인증서와 Regional 엔드포인트를 사용해야 합니다. 그 후 Route 53 레코드를 통해 트래픽을 해당 도메인으로 라우팅하면 HTTPS 연결이 완성됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "API Gateway",
      "도메인 이름",
      "ACM 인증서",
      "HTTPS",
      "Regional 엔드포인트"
    ],
    "Terms": [
      "Amazon Route 53",
      "Amazon API Gateway",
      "ca-central-1 Region",
      "AWS Certificate Manager (ACM)",
      "Route 53 DNS records",
      "Regional API Gateway endpoint",
      "Stage variables",
      "Public certificate",
      "HTTPS",
      "A record",
      "Alias record"
    ],
    "SelectA": "API Gateway에서 Name=\"Endpoint-URL\"와 Value=\"Company Domain Name\"을 갖는 Stage Variable을 생성하여 기본 URL을 덮어씁니다. 회사 도메인 이름에 대한 Public Certificate를 AWS Certificate Manager (ACM)에 Import합니다.",
    "SelectA_Commentary": "Stage Variable만으로 API Gateway에 커스텀 도메인을 설정할 수 없으므로 올바른 설정 방식이 아닙니다.",
    "SelectB": "회사 도메인 이름을 사용해 Route 53 DNS 레코드를 생성합니다. Alias 레코드를 Regional API Gateway 스테이지 엔드포인트로 지정합니다. 회사 도메인 이름 관련 Public Certificate를 us-east-1 리전의 AWS Certificate Manager (ACM)에 Import합니다.",
    "SelectB_Commentary": "Regional 엔드포인트이지만 인증서를 us-east-1 리전에 배포하면 ca-central-1 리전의 API Gateway와 정상 연동이 어려워 잘못된 접근입니다.",
    "SelectC": "Regional API Gateway 엔드포인트를 생성합니다. API Gateway 엔드포인트를 회사 도메인 이름과 연결합니다. 동일 리전에서 회사 도메인 이름에 대한 Public Certificate를 AWS Certificate Manager (ACM)에 Import하고, 이를 API Gateway 엔드포인트에 연결합니다. Route 53을 구성하여 트래픽을 API Gateway 엔드포인트로 라우팅합니다.",
    "SelectC_Commentary": "동일 리전의 ACM 인증서와 Regional 엔드포인트가 필요하며, Route 53을 통해 트래픽을 연결하는 설정으로 요구사항을 충족합니다.",
    "SelectD": "Regional API Gateway 엔드포인트를 생성합니다. 회사 도메인 이름과 엔드포인트를 연결합니다. 회사 도메인 이름에 대한 Public Certificate를 us-east-1 리전의 AWS Certificate Manager (ACM)에 Import하고, 이를 API Gateway에 연결합니다. 회사 도메인 이름으로 A 레코드를 생성하여 해당 도메인으로 지정합니다.",
    "SelectD_Commentary": "인증서를 API Gateway 엔드포인트와 동일한 리전에 배포해야 하는데, us-east-1에 Import하면 ca-central-1 엔드포인트와 호환되지 않습니다.",
    "Question_Description_recommedations": [
      "Q532",
      "Q1019",
      "Q399",
      "Q172",
      "Q291"
    ],
    "SelectA_recommedations": [
      "Q532",
      "Q1019",
      "Q159"
    ],
    "SelectB_recommedations": [
      "Q532",
      "Q56",
      "Q712"
    ],
    "SelectC_recommedations": [
      "Q532",
      "Q56",
      "Q1019"
    ],
    "SelectD_recommedations": [
      "Q56",
      "Q1019",
      "Q532"
    ]
  },
  {
    "Question_Number": "Q57",
    "Question_Description": "한 회사에서 인기가 높은 소셜 미디어 웹사이트를 운영 중이며, 사용자가 다른 사용자와 공유할 이미지를 업로드할 수 있는 기능을 제공합니다. 회사는 이러한 이미지에 부적절한 콘텐츠가 포함되지 않도록 사전에 확인하고자 합니다. 또한, 개발 노력을 최소화할 수 있는 솔루션을 원합니다. 이를 충족하는 방법으로 어떤 것을 선택해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85452-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 사용자가 업로드하는 사진을 자동으로 점검해 부적절한 콘텐츠를 걸러내는 요구 사항에 관한 것입니다. Amazon Rekognition은 이미지를 기반으로 한 콘텐츠 모더레이션 기능을 이미 갖추고 있어 개발 부담을 최소화하며 정확도를 높일 수 있는 최적의 서비스입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "소셜 미디어",
      "이미지 업로드",
      "부적절한 콘텐츠",
      "개발 노력 최소화",
      "Amazon Rekognition"
    ],
    "Terms": [
      "Amazon Comprehend",
      "Amazon Rekognition",
      "Amazon SageMaker",
      "AWS Fargate",
      "Ground Truth",
      "Human Review"
    ],
    "SelectA": "Amazon Comprehend를 사용해 부적절한 내용을 감지하고, 신뢰도가 낮은 예측에 대해서는 인적 리뷰를 진행",
    "SelectA_Commentary": "Comprehend는 주로 텍스트 분석에 특화되어 있으므로 이미지 부적절성 검출에는 적합하지 않습니다.",
    "SelectB": "Amazon Rekognition을 사용해 부적절한 내용을 감지하고, 신뢰도가 낮은 예측에 대해서는 인적 리뷰를 진행",
    "SelectB_Commentary": "이미지 분석에 최적화된 Amazon Rekognition을 사용하면 최소한의 개발 노력으로 정확하고 빠른 콘텐츠 모더레이션을 구현할 수 있는 최적의 선택입니다.",
    "SelectC": "Amazon SageMaker로 부적절한 내용을 감지하고, Ground Truth를 사용해 신뢰도가 낮은 예측에 라벨을 지정",
    "SelectC_Commentary": "직접 모델을 개발하고 학습해야 하므로 개발 과정이 복잡하고 시간과 비용이 많이 듭니다.",
    "SelectD": "AWS Fargate에 맞춤형 머신 러닝 모델을 배포해 부적절한 내용을 감지하고, Ground Truth를 사용해 신뢰도가 낮은 예측에 라벨을 지정",
    "SelectD_Commentary": "커스텀 모델을 배포해 운영하려면 상당한 개발 및 유지보수 노력이 필요하며, 요구 사항인 개발 노력 최소화에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q665",
      "Q122",
      "Q189",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q796",
      "Q548",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q898",
      "Q548",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q313",
      "Q898",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q58",
    "Question_Description": "한 회사가 컨테이너로 크리티컬 애플리케이션을 구동하여 확장성과 가용성 요구사항을 충족하고자 합니다. 회사는 크리티컬 애플리케이션 유지보수에만 집중하기를 원하며, 컨테이너화된 워크로드가 동작하는 기본 인프라를 프로비저닝하고 관리하는 책임을 지고 싶어 하지 않습니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85453-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 확장성과 고가용성을 위해 컨테이너화된 애플리케이션을 운영하면서, 인프라 관리까지 맡지 않으려는 상황에 대한 해결책을 찾는 것입니다. AWS Fargate는 서버리스 방식으로 기본 인프라 관리를 자동화하고, 애플리케이션 유지보수에 집중할 수 있도록 지원하기 때문에 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "크리티컬 애플리케이션",
      "컨테이너",
      "확장성",
      "가용성",
      "서버리스",
      "AWS Fargate"
    ],
    "Terms": [
      "AWS Fargate",
      "Amazon ECS",
      "Amazon EC2",
      "Docker",
      "Amazon Machine Image (AMI)"
    ],
    "SelectA": "Amazon EC2 인스턴스를 사용하고, 인스턴스에 Docker를 설치합니다.",
    "SelectA_Commentary": "서버 설정 및 Docker 설치·관리가 필요하여 인프라 관리를 전담해야 하므로 요구사항에 부적합합니다.",
    "SelectB": "Amazon ECS를 Amazon EC2 worker 노드에서 사용합니다.",
    "SelectB_Commentary": "EC2 노드를 직접 관리해야 하므로 인프라 관리 부담이 그대로 남아있어 요구사항에 맞지 않습니다.",
    "SelectC": "Amazon ECS를 AWS Fargate에서 사용합니다.",
    "SelectC_Commentary": "서버리스 환경으로 인프라 관리가 자동화되어 크리티컬 애플리케이션 유지보수에만 집중할 수 있는 최적의 해법입니다.",
    "SelectD": "Amazon ECS 최적화 Amazon Machine Image (AMI)를 사용하여 Amazon EC2 인스턴스에서 구동합니다.",
    "SelectD_Commentary": "AMI를 사용해도 EC2 인스턴스 프로비저닝·관리가 필요해 요구사항을 충분히 만족시키지 못합니다.",
    "Question_Description_recommedations": [
      "Q917",
      "Q491",
      "Q255",
      "Q735",
      "Q187"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q698",
      "Q303"
    ],
    "SelectD_recommedations": [
      "Q762",
      "Q194",
      "Q900"
    ]
  },
  {
    "Question_Number": "Q59",
    "Question_Description": "한 회사가 300개 이상의 글로벌 웹사이트와 애플리케이션을 운영하고 있습니다. 이 회사는 매일 30TB 이상의 clickstream 데이터를 분석할 플랫폼이 필요합니다. 솔루션스 아키텍트는 이러한 clickstream 데이터를 전송하고 처리하기 위해 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85793-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 대규모(30TB 이상) clickstream 데이터를 매일 빠르고 안정적으로 수집, 전송, 처리, 분석해야 하는 시나리오입니다. Amazon Kinesis Data Streams와 Kinesis Data Firehose를 사용하면 실시간 스트리밍 데이터 수집 및 저장소 전송이 용이하고, Amazon Redshift를 통해 대규모 데이터 웨어하우징과 분석을 수행할 수 있습니다. 이는 고성능 아키텍처 설계를 위한 핵심 전략입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "글로벌 웹사이트",
      "애플리케이션",
      "clickstream 데이터",
      "데이터 분석",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "Amazon Redshift"
    ],
    "Terms": [
      "AWS Data Pipeline",
      "Amazon EMR",
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon CloudFront",
      "AWS Lambda",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon S3 data lake",
      "Amazon Redshift"
    ],
    "SelectA": "AWS Data Pipeline을 설계하여 Amazon S3 버킷에 데이터를 보관하고 Amazon EMR 클러스터에서 분석을 진행합니다.",
    "SelectA_Commentary": "AWS Data Pipeline과 Amazon EMR은 배치 기반 분석에는 적합하지만, 대규모 실시간 clickstream 처리를 위한 전송 및 스트리밍 측면에서 적절하지 않습니다.",
    "SelectB": "Amazon EC2 인스턴스로 구성된 Auto Scaling group에서 데이터를 처리하고 Amazon S3 data lake로 전송한 뒤 Amazon Redshift로 분석합니다.",
    "SelectB_Commentary": "EC2를 통한 직접 처리는 확장성 및 실시간 처리 측면에서 추가 설정이 복잡하고 대규모 스트리밍 처리 효율이 떨어질 수 있습니다.",
    "SelectC": "데이터를 Amazon CloudFront에 캐싱하고 Amazon S3 버킷에 저장합니다. 객체가 S3 버킷에 올라오면 AWS Lambda 함수를 실행해 분석용으로 처리합니다.",
    "SelectC_Commentary": "CloudFront 캐싱은 주로 콘텐츠 전달을 위한 기능이며, 매일 30TB 이상의 실시간 clickstream 데이터를 효과적으로 스트리밍 처리하기에는 적합하지 않습니다.",
    "SelectD": "Amazon Kinesis Data Streams에서 데이터를 수집하고 Amazon Kinesis Data Firehose를 사용해 데이터를 Amazon S3 data lake로 전송합니다. 데이터를 Amazon Redshift에 로드하여 분석을 수행합니다.",
    "SelectD_Commentary": "대규모 실시간 스트리밍 처리에 특화된 Amazon Kinesis와 확장성이 뛰어난 Kinesis Data Firehose 전송, 그리고 분석을 위한 Amazon Redshift 결합은 가장 효율적인 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q830",
      "Q331",
      "Q1000",
      "Q747",
      "Q1"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q804",
      "Q680"
    ],
    "SelectB_recommedations": [
      "Q674",
      "Q335",
      "Q461"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q501",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q557",
      "Q402"
    ]
  },
  {
    "Question_Number": "Q60",
    "Question_Description": "회사에 AWS 에서 호스팅되는 웹 사이트가 있습니다. 웹 사이트는 HTTP 와 HTTPS 를 별도로 처리하도록 구성된 ALB(Application Load Balancer) 뒤에 있습니다. 회사는 요청이 HTTPS 를 사용하도록 모든 요청을 웹사이트로 전달하려고 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://repost.aws/ko/knowledge-center/elb-redirect-http-to-https-using-alb",
    "AnswerDescription": "이 문제는 ALB 뒤에서 모든 요청을 HTTPS로 강제하기 위한 보안 구성 방법을 묻습니다. 올바른 설정은 HTTP 요청이 들어오면 ALB Listener Rule을 통해 자동으로 HTTPS로 리디렉션하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "HTTPS 리디렉션",
      "ALB 리스너",
      "HTTP 트래픽",
      "HTTPS 트래픽",
      "보안 접속"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "HTTP",
      "HTTPS",
      "Listener Rule",
      "Network ACL",
      "SNI(Server Name Indication)"
    ],
    "SelectA": "HTTPS 트래픽만 허용하도록 ALB 의 네트워크 ACL 을 업데이트합니다.",
    "SelectA_Commentary": "네트워크 ACL 변경만으로는 HTTP 트래픽이 차단되는 것일 뿐, HTTPS로 자동 리디렉션되지 않습니다.",
    "SelectB": "URL 의 HTTP 를 HTTPS 로 바꾸는 규칙을 만듭니다.",
    "SelectB_Commentary": "개별 URL 변경 규칙을 수동으로 구현해야 하므로 비효율적이며 ALB의 공식 리디렉션 기능을 최적으로 활용하지 못합니다.",
    "SelectC": "ALB 에서 리스너 규칙을 생성하여 HTTP 트래픽을 HTTPS 로 리디렉션합니다.",
    "SelectC_Commentary": "올바른 접근입니다. ALB에서 HTTP Listener 생성 후 리디렉션 동작을 설정하면 모든 요청을 HTTPS로 자동 전환할 수 있습니다.",
    "SelectD": "ALB 를 SNI(서버 이름 표시)를 사용하도록 구성된 Network Load Balancer 로 교체합니다.",
    "SelectD_Commentary": "NLB는 기본적으로 4계층 로드 밸런싱이며, HTTP→HTTPS 리디렉션은 ALB 기능에 해당하므로 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q608",
      "Q927",
      "Q884",
      "Q707",
      "Q169"
    ],
    "SelectA_recommedations": [
      "Q60",
      "Q265",
      "Q855"
    ],
    "SelectB_recommedations": [
      "Q265",
      "Q803",
      "Q564"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q265",
      "Q169"
    ],
    "SelectD_recommedations": [
      "Q707",
      "Q169",
      "Q884"
    ]
  },
  {
    "Question_Number": "Q61",
    "Question_Description": "한 회사가 AWS에서 2티어 웹 애플리케이션을 개발 중입니다. 이 회사의 개발자들은 백엔드 Amazon RDS 데이터베이스와 직접 연결되는 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. 회사는 애플리케이션에 데이터베이스 자격 증명을 하드코딩하면 안 되며, 정기적으로 데이터베이스 자격 증명을 자동으로 로테이션하는 솔루션을 구현해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85580-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 애플리케이션 코드에 하드코딩 없이 데이터베이스 자격 증명을 안전하게 관리하고, 정기적으로 인증 정보를 갱신하기 위한 접근 방안을 묻습니다. AWS Secrets Manager는 자격 증명 보안을 자동화하여 처리하며, 자동 로테이션까지 제공해 운영 오버헤드를 크게 줄일 수 있으므로 가장 적합한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "데이터베이스 자격 증명",
      "자동 로테이션",
      "Amazon EC2",
      "Amazon RDS",
      "운영 오버헤드 최소화",
      "AWS Secrets Manager"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "AWS Lambda",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon S3",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "자동 로테이션 (Automatic Rotation)",
      "인스턴스 메타데이터"
    ],
    "SelectA": "데이터베이스 자격 증명을 인스턴스 메타데이터에 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용해 예약된 AWS Lambda 함수를 실행하여 RDS 자격 증명과 인스턴스 메타데이터를 동시에 업데이트합니다.",
    "SelectA_Commentary": "인스턴스 메타데이터에 자격 증명을 저장하는 것은 보안상 위험이 높습니다. 또한 EventBridge와 Lambda를 사용해 수동으로 로테이션 로직을 구현해야 하므로 운영 부담이 큽니다.",
    "SelectB": "암호화된 Amazon S3 버킷의 설정 파일에 데이터베이스 자격 증명을 저장합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙을 사용해 예약된 AWS Lambda 함수를 실행하여 RDS 자격 증명과 설정 파일 내 자격 증명을 동시에 업데이트합니다. S3 Versioning으로 이전 버전 복구 기능을 보장합니다.",
    "SelectB_Commentary": "S3에 직접 자격 증명을 저장하면 자동 로테이션을 위한 로직을 추가로 개발해야 하므로 운영 오버헤드가 큽니다. Versioning으로 이전 상태 복구가 가능하지만, 별도의 구성과 유지 비용이 발생합니다.",
    "SelectC": "데이터베이스 자격 증명을 AWS Secrets Manager의 시크릿으로 저장합니다. 시크릿 자동 로테이션을 활성화합니다. EC2 역할에 해당 시크릿에 대한 액세스 권한을 부여합니다.",
    "SelectC_Commentary": "AWS Secrets Manager는 자동으로 RDS 자격 증명을 로테이션하며, EC2 역할에 권한만 부여하면 되므로 운영 오버헤드가 매우 적습니다. 보안 및 편의성 모두를 만족하는 솔루션입니다.",
    "SelectD": "데이터베이스 자격 증명을 AWS Systems Manager Parameter Store의 암호화된 파라미터로 저장합니다. 암호화된 파라미터에 대한 자동 로테이션을 활성화합니다. EC2 역할에 해당 파라미터들에 대한 액세스 권한을 부여합니다.",
    "SelectD_Commentary": "Parameter Store는 기본적으로 자격 증명 자동 로테이션 기능을 제공하지 않거나 제한적이므로, Secrets Manager처럼 간편하고 완전한 자동 로테이션을 지원하지 않아 운영 부담이 늘어납니다.",
    "Question_Description_recommedations": [
      "Q732",
      "Q742",
      "Q492",
      "Q838",
      "Q977"
    ],
    "SelectA_recommedations": [
      "Q981",
      "Q330",
      "Q428"
    ],
    "SelectB_recommedations": [
      "Q981",
      "Q868",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q612",
      "Q682"
    ],
    "SelectD_recommedations": [
      "Q179",
      "Q453",
      "Q682"
    ]
  },
  {
    "Question_Number": "Q62",
    "Question_Description": "한 회사가 새로운 Public Web Application을 AWS에 배포하려고 합니다. 이 Application은 Application Load Balancer(ALB) 뒤에서 동작합니다. 외부 Certificate Authority(CA)가 발급한 SSL/TLS Certificate를 사용하여 엣지에서 암호화해야 하며, 해당 Certificate는 만료 전에 매년 교체(Rotate)되어야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85524-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 외부 CA가 발급한 SSL/TLS 인증서를 ALB에 적용해야 하며, 자동 갱신이 불가능하다는 점이 핵심입니다. AWS가 직접 관리하지 않는 제3자 인증서는 만료 알림을 받은 뒤 수동으로 교체해야 하므로, EventBridge를 통한 알림 후 수동 갱신이 유일한 실현 방법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Application Load Balancer(ALB)",
      "SSL/TLS Certificate",
      "외부 Certificate Authority(CA)",
      "만료 전 교체",
      "ACM Import",
      "Amazon EventBridge"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "SSL/TLS Certificate",
      "External Certificate Authority(CA)",
      "AWS Certificate Manager(ACM)",
      "ACM Private Certificate Authority",
      "Amazon EventBridge(Amazon CloudWatch Events)",
      "Managed Renewal"
    ],
    "SelectA": "AWS Certificate Manager(ACM)을 사용하여 SSL/TLS Certificate를 발급받습니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 자동으로 인증서를 교체합니다.",
    "SelectA_Commentary": "AWS 자체 인증서를 활용하므로 외부 CA 요구사항을 충족하지 못하며, 3rd party 인증서는 자동 갱신 대상이 아닙니다.",
    "SelectB": "AWS Certificate Manager(ACM)을 사용하여 SSL/TLS Certificate를 발급받고, 키 재질을 가져옵니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 자동으로 인증서를 교체합니다.",
    "SelectB_Commentary": "역시 ACM이 발급한 인증서이므로, 외부 CA에서 발급된 인증서를 자동 갱신하는 방식이 아닙니다.",
    "SelectC": "AWS Certificate Manager(ACM) Private Certificate Authority를 사용하여 루트 CA로부터 SSL/TLS Certificate를 발급받습니다. 그리고 이 인증서를 ALB에 적용합니다. 이후 Managed Renewal 기능을 통해 인증서를 자동 교체합니다.",
    "SelectC_Commentary": "ACM Private CA를 사용하면 내부 CA가 되므로, 외부 CA를 요구하는 시나리오와 맞지 않습니다.",
    "SelectD": "AWS Certificate Manager(ACM)에 외부 SSL/TLS Certificate를 Import합니다. ALB에 해당 인증서를 적용합니다. 그리고 Amazon EventBridge(Amazon CloudWatch Events)를 통해 인증서 만료가 가까워지면 알림을 받고 수동으로 인증서를 교체합니다.",
    "SelectD_Commentary": "외부 CA에서 발급된 인증서는 AWS가 자동 갱신할 수 없습니다. EventBridge 알림으로 만료 시점을 파악하여 직접 교체하는 방식이 유일한 방법이므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q60",
      "Q927",
      "Q884",
      "Q644",
      "Q608"
    ],
    "SelectA_recommedations": [
      "Q62",
      "Q60",
      "Q82"
    ],
    "SelectB_recommedations": [
      "Q62",
      "Q60",
      "Q82"
    ],
    "SelectC_recommedations": [
      "Q62",
      "Q60",
      "Q82"
    ],
    "SelectD_recommedations": [
      "Q62",
      "Q60",
      "Q82"
    ]
  },
  {
    "Question_Number": "Q63",
    "Question_Description": "회사는 AWS에서 인프라를 운영하고 있으며, 문서 관리 애플리케이션을 사용 중인 700,000명의 사용자 기반을 보유하고 있습니다. 회사는 큰 용량의 .pdf 파일을 .jpg 이미지 파일로 변환하는 제품을 만들 계획입니다. .pdf 파일은 평균적으로 5MB 정도의 크기를 갖습니다. 회사는 원본 파일과 변환된 파일을 모두 저장해야 합니다. 한 Solutions Architect는 빠르게 증가하는 수요를 수용할 수 있는 확장 가능한 솔루션을 설계해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85795-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 많은 사용자의 대규모 PDF 파일을 JPG로 변환하고, 원본과 변환본을 모두 저장해야 하는 상황에서 가장 비용 효율적이면서도 확장성이 높은 방법을 묻습니다. Amazon S3에 업로드 시 S3 PUT event로 트리거되는 AWS Lambda 함수를 통해 파일을 변환하고 S3에 재저장하는 방식이 서버 관리 부담 없이 비용 또한 절감할 수 있어 정답이 됩니다. DynamoDB나 Elastic Beanstalk 등을 사용하는 방식은 파일 크기와 비용 효율성 측면에서 적합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "PDF 파일 변환",
      "비용 효율성",
      "대규모 사용자",
      "Amazon S3",
      "AWS Lambda",
      "S3 PUT event",
      "원본 파일 저장",
      "확장 가능한 솔루션"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lambda",
      "S3 PUT event",
      "DynamoDB",
      "DynamoDB Streams",
      "AWS Elastic Beanstalk",
      "Amazon EC2",
      "Amazon EBS",
      "Amazon EFS",
      "Auto Scaling"
    ],
    "SelectA": "Amazon S3에 .pdf 파일을 저장합니다. S3 PUT event를 통해 파일이 업로드될 때마다 AWS Lambda 함수를 호출하여 .jpg로 변환하고, 변환된 파일을 다시 Amazon S3에 저장합니다.",
    "SelectA_Commentary": "Lambda와 S3를 사용하면 파일 변환을 이벤트 기반으로 처리하고, 서버less 구조로 관리 부담 없이 비용 효율적인 스토리지와 컴퓨팅 환경을 확보할 수 있습니다.",
    "SelectB": "DynamoDB에 .pdf 파일을 저장합니다. DynamoDB Streams 기능을 사용해 AWS Lambda 함수를 호출하여 파일을 .jpg로 변환하고, 변환된 파일을 다시 DynamoDB에 저장합니다.",
    "SelectB_Commentary": "DynamoDB는 대규모 파일 저장에 적합하지 않으며, 파일을 직접 저장하면 비용이 크게 증가할 수 있습니다.",
    "SelectC": "AWS Elastic Beanstalk 애플리케이션(EC2 인스턴스, Amazon EBS 스토리지, Auto Scaling 포함)에 .pdf 파일을 업로드합니다. EC2 인스턴스에서 프로그램을 사용해 .jpg로 변환한 뒤, .pdf와 .jpg 파일을 EBS에 저장합니다.",
    "SelectC_Commentary": "EC2와 EBS를 이용하면 서버와 스토리지를 직접 관리해야 하며, 확장성과 비용 효율성 측면에서 Lambda+S3 조합보다 부담이 큽니다.",
    "SelectD": "AWS Elastic Beanstalk 애플리케이션(EC2 인스턴스, Amazon EFS 스토리지, Auto Scaling 포함)에 .pdf 파일을 업로드합니다. EC2 인스턴스에서 프로그램을 사용해 .jpg로 변환한 뒤, .pdf와 .jpg 파일을 EBS에 저장합니다.",
    "SelectD_Commentary": "Elastic Beanstalk와 EFS, EBS를 혼합 사용하면 관리와 운영 비용이 늘어나며, 서버리스 아키텍처 대비 확장성과 비용 최적화 측면에서 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q643",
      "Q872",
      "Q124",
      "Q22",
      "Q309"
    ],
    "SelectA_recommedations": [
      "Q829",
      "Q498",
      "Q469"
    ],
    "SelectB_recommedations": [
      "Q670",
      "Q348",
      "Q79"
    ],
    "SelectC_recommedations": [
      "Q937",
      "Q867",
      "Q841"
    ],
    "SelectD_recommedations": [
      "Q937",
      "Q841",
      "Q505"
    ]
  },
  {
    "Question_Number": "Q64",
    "Question_Description": "한 회사는 온프레미스에서 Windows 파일 서버를 통해 5TB 이상의 파일 데이터를 보유하고 있습니다. 사용자와 애플리케이션은 매일 해당 데이터에 액세스합니다. 회사는 Windows 워크로드를 AWS로 이전하고 있으며, 이전 과정 중에도 AWS와 온프레미스 환경 모두에서 최소 지연으로 파일 스토리지에 접근해야 합니다. 운영 오버헤드를 최소화하고 기존 파일 액세스 방식을 크게 변경하지 않는 솔루션이 필요합니다. 이 회사는 AWS와의 연결을 위해 AWS Site-to-Site VPN을 사용 중입니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85173-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 온프레미스 Windows 파일 서버를 AWS로 마이그레이션하면서도 기존 SMB 기반 파일 액세스 방식을 그대로 유지하고, 지연을 최소화하려는 상황입니다. Amazon FSx for Windows File Server와 FSx File Gateway를 결합하면 클라우드와 온프레미스에서 동일한 파일 서버 인터페이스를 사용하도록 구성할 수 있어, 운영 오버헤드와 애플리케이션 변경을 최소화합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "Windows 파일 서버",
      "온프레미스",
      "Amazon FSx for Windows File Server",
      "FSx File Gateway",
      "파일 액세스 패턴",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon FSx for Windows File Server",
      "Amazon S3 File Gateway",
      "FSx File Gateway",
      "VPN",
      "SMB 프로토콜"
    ],
    "SelectA": "Amazon FSx for Windows File Server를 AWS에 배포 및 구성합니다. 온프레미스 파일 데이터를 FSx로 이전하고, 워크로드를 FSx 서비스로 재구성하여 사용합니다.",
    "SelectA_Commentary": "온프레미스에서 직접 FSx로 접속하므로 VPN 대역폭과 지연이 문제가 될 수 있고, 온프레미스에 대한 캐시나 게이트웨이가 없어 기존 패턴을 유지하기 어렵습니다.",
    "SelectB": "온프레미스에 Amazon S3 File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 S3 File Gateway로 이전하고, 온프레미스와 클라우드 워크로드 모두에서 S3 File Gateway를 사용하도록 재구성합니다.",
    "SelectB_Commentary": "S3를 사용하는 파일 게이트웨이는 SMB가 아닌 객체 스토리지 인터페이스를 사용하므로, Windows 파일 서버 패턴과 맞지 않아 큰 변경이 필요합니다.",
    "SelectC": "온프레미스에 Amazon S3 File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 Amazon S3로 이전합니다. 각 워크로드의 위치에 따라 Amazon S3 또는 S3 File Gateway를 직접 사용하도록 재구성합니다.",
    "SelectC_Commentary": "이 역시 S3 기반 접근이므로 파일 서버 방식(SMB)과 달라 애플리케이션과 사용자 측면에서 많은 변경이 필요합니다.",
    "SelectD": "AWS에 Amazon FSx for Windows File Server를 배포 및 구성합니다. 온프레미스에 Amazon FSx File Gateway를 배포 및 구성합니다. 온프레미스 파일 데이터를 FSx File Gateway로 마이그레이션하고, 클라우드 워크로드는 FSx를, 온프레미스 워크로드는 FSx File Gateway를 사용하도록 설정합니다.",
    "SelectD_Commentary": "FSx File Gateway를 통해 온프레미스 환경에서도 로컬 SMB 형태로 접근이 가능하며, 클라우드에서는 FSx를 직접 활용하므로 최소 변화를 유지하면서 지연을 줄일 수 있는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q659",
      "Q844",
      "Q283",
      "Q113",
      "Q771"
    ],
    "SelectA_recommedations": [
      "Q301",
      "Q283",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q672",
      "Q155",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q672",
      "Q155",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q301",
      "Q283",
      "Q844"
    ]
  },
  {
    "Question_Number": "Q65",
    "Question_Description": "한 병원이 Amazon API Gateway와 AWS Lambda를 사용하여 RESTful API를 최근에 배포했습니다. 이 병원은 PDF 형식과 JPEG 형식의 보고서를 업로드하기 위해 API Gateway와 Lambda를 사용하고 있습니다. 병원은 보고서 내의 Protected Health Information(PHI)을 식별하기 위해 Lambda 코드를 수정해야 합니다. 가장 낮은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85367-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 의료 보고서에서 PHI를 식별하기 위한 가장 간단하고 직관적인 접근 방식을 찾는 것입니다. 문서에서 텍스트를 정확히 추출하고, 의료 특화 엔티티 식별에 최적화된 서비스를 활용해야 운영 오버헤드를 줄일 수 있습니다. Amazon Textract는 PDF·JPEG 등 다양한 문서 포맷에서 텍스트를 추출하고, Amazon Comprehend Medical은 의료 텍스트에 대한 PHI 식별 기능을 완전관리형으로 제공합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "PHI 식별",
      "Amazon Textract",
      "Amazon Comprehend Medical",
      "PDF/JPEG 보고서",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "RESTful API",
      "PDF",
      "JPEG",
      "Protected Health Information(PHI)",
      "Python libraries",
      "Amazon Textract",
      "Amazon SageMaker",
      "Amazon Comprehend Medical",
      "Amazon Rekognition"
    ],
    "SelectA": "기존 Python 라이브러리를 사용하여 보고서에서 텍스트를 추출하고, 추출된 텍스트에서 PHI를 식별합니다.",
    "SelectA_Commentary": "직접 라이브러리를 선택·구현·유지보수해야 하므로 추가 코드 작업과 관리 부담이 커져, 운영 오버헤드가 높을 수 있습니다.",
    "SelectB": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon SageMaker를 사용하여 추출된 텍스트에서 PHI를 식별합니다.",
    "SelectB_Commentary": "Textract로 텍스트 추출은 편리하지만, SageMaker로 PHI 식별 모델을 직접 구축·운영해야 하므로 관리 부담이 큽니다.",
    "SelectC": "Amazon Textract를 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다.",
    "SelectC_Commentary": "문서 텍스트 추출과 의료 특화 PHI 식별에 최적화된 완전관리형 서비스들을 연계하여, 유지보수가 간단하고 운영 오버헤드가 최소화됩니다.",
    "SelectD": "Amazon Rekognition을 사용하여 보고서에서 텍스트를 추출합니다. Amazon Comprehend Medical을 사용하여 추출된 텍스트에서 PHI를 식별합니다.",
    "SelectD_Commentary": "Rekognition의 OCR 기능은 주로 이미지 분석에 초점이 맞춰져 있어, 문서 텍스트 추출에는 Textract 대비 적합성이 낮습니다.",
    "Question_Description_recommedations": [
      "Q159",
      "Q428",
      "Q1019",
      "Q936",
      "Q913"
    ],
    "SelectA_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q678",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q359",
      "Q548",
      "Q592"
    ],
    "SelectD_recommedations": [
      "Q359",
      "Q592",
      "Q548"
    ]
  },
  {
    "Question_Number": "Q66",
    "Question_Description": "어떤 회사는 대략 5MB 크기의 파일을 대량으로 생성하는 애플리케이션을 운영하고 있습니다. 이 파일들은 Amazon S3에 저장되며, 회사 정책상 4년 동안 삭제할 수 없습니다. 이 파일들은 재생산이 어려운 중요한 비즈니스 데이터가 포함되어 있어 항상 즉시 액세스할 수 있어야 합니다. 객체 생성 후 첫 30일 동안은 자주 액세스되지만, 그 이후에는 드물게 액세스됩니다. 이러한 요구사항을 만족하면서 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85310-exam-aws-certified-solut",
    "AnswerDescription": "이 문제의 핵심은 일정 기간 자주 액세스된 후 드물게 참조되는 데이터를 비용 효율적으로 장기 보관하면서도, ‘언제든 즉시 액세스해야 한다’는 요구사항을 충족하는 방식입니다. S3 Glacier는 저렴하지만 즉시 액세스가 불가능하므로 부적합합니다. S3 One Zone-IA는 멀티 AZ 저장을 제공하지 않아 중요 데이터에 대한 내구성과 가용성을 모두 보장하기 어렵습니다. 반면 S3 Standard-IA는 멀티 AZ를 유지하며 즉시 액세스가 가능하고 드문 액세스 시 더 낮은 요금을 제공합니다. 따라서 30일 후 S3 Standard-IA로 전환하고, 4년 후 제거하는 것이 최적의 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "파일 즉시 액세스",
      "4년 보관",
      "30일 이후 드문 액세스",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "S3 Glacier",
      "Lifecycle policy"
    ],
    "SelectA": "객체 생성 30일 후 S3 Standard에서 S3 Glacier로 이동하고, 4년 후 삭제",
    "SelectA_Commentary": "S3 Glacier로 이동 시 저렴하지만 즉시 액세스가 불가능하여 요구사항에 부합하지 않습니다.",
    "SelectB": "객체 생성 30일 후 S3 Standard에서 S3 One Zone-IA로 이동하고, 4년 후 삭제",
    "SelectB_Commentary": "One Zone-IA는 멀티 AZ가 아니므로 중요한 데이터에 대한 내구성 및 가용성 면에서 위험도가 높습니다.",
    "SelectC": "객체 생성 30일 후 S3 Standard에서 S3 Standard-IA로 이동하고, 4년 후 삭제",
    "SelectC_Commentary": "중요 데이터를 멀티 AZ에 안전하게 보관하면서도 접근이 적은 시점부터 더 낮은 요금으로 즉시 액세스를 지원해 가장 적합합니다.",
    "SelectD": "객체 생성 30일 후 S3 Standard에서 S3 Standard-IA로 이동하고, 4년 후 S3 Glacier로 이동",
    "SelectD_Commentary": "어차피 4년 후에 삭제할 파일을 Glacier로 옮기는 것은 불필요한 단계를 거치게 되어 비용과 운영 복잡성을 증가시킵니다.",
    "Question_Description_recommedations": [
      "Q551",
      "Q153",
      "Q759",
      "Q890",
      "Q1003"
    ],
    "SelectA_recommedations": [
      "Q126",
      "Q486",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q486",
      "Q126"
    ],
    "SelectC_recommedations": [
      "Q126",
      "Q356",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q126",
      "Q890"
    ]
  },
  {
    "Question_Number": "Q67",
    "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon SQS 큐에서 메시지를 받아 처리한 뒤, Amazon RDS 테이블에 기록하고, 큐에서 메시지를 삭제합니다. 가끔 Amazon RDS 테이블에 중복된 레코드가 발견되지만, Amazon SQS 큐에는 중복 메시지가 존재하지 않습니다. 메시지가 한 번만 처리되도록 보장하려면 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85583-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 Amazon SQS 큐를 사용하는 다중 소비자 환경에서 중복 처리를 방지하는 방법을 묻습니다. 메시지를 처리하는 동안 다른 인스턴스가 해당 메시지를 다시 가져가지 못하도록 적절한 Visibility Timeout을 설정해주는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "메시지 중복 방지",
      "Visibility Timeout",
      "Amazon SQS",
      "Amazon EC2",
      "Amazon RDS"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon SQS",
      "CreateQueue API",
      "AddPermission API",
      "ReceiveMessage API",
      "ChangeMessageVisibility API",
      "Visibility Timeout"
    ],
    "SelectA": "CreateQueue API 호출을 사용하여 새 큐를 생성합니다.",
    "SelectA_Commentary": "새 큐를 만든다고 기존 중복 문제가 해결되지는 않아 오답입니다.",
    "SelectB": "AddPermission API 호출을 사용하여 적절한 권한을 추가합니다.",
    "SelectB_Commentary": "권한 설정은 보안 및 접근 제어 목적이며, 메시지 중복 처리 문제를 해결하지 못합니다.",
    "SelectC": "ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다.",
    "SelectC_Commentary": "대기 시간(WaitTimeSeconds)은 메시지 수신 방식에 영향을 주지만, 중복 처리를 방지하려면 Visibility Timeout 조정이 필요하므로 오답입니다.",
    "SelectD": "ChangeMessageVisibility API 호출을 사용하여 visibility timeout을 늘립니다.",
    "SelectD_Commentary": "메시지가 처리 중일 때 충분히 숨겨 다른 인스턴스에서 재처리되지 않도록 visibility timeout을 늘려야 하므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q195",
      "Q944",
      "Q125",
      "Q203",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q8",
      "Q51"
    ],
    "SelectB_recommedations": [
      "Q567",
      "Q51",
      "Q798"
    ],
    "SelectC_recommedations": [
      "Q51",
      "Q567",
      "Q798"
    ],
    "SelectD_recommedations": [
      "Q845",
      "Q8",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q68",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 온프레미스 인프라를 AWS로 확장하기 위한 새로운 하이브리드 아키텍처를 설계하고 있습니다. 회사는 AWS Region으로 가는 고가용성 및 일관된 저지연 연결을 요구합니다. 또한 총 비용을 최소화하고자 하며, 기본 연결(Direct Connect)이 실패했을 때는 더 느린 트래픽 전송을 수용할 수 있습니다. 이러한 요구사항을 충족하려면 어떤 구성을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85593-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 온프레미스 인프라와 AWS를 연결하는 하이브리드 아키텍처에서 고가용성과 낮은 지연을 유지하면서도 장애 시 비용을 아끼고 느린 트래픽을 수용할 수 있는 대안을 묻습니다. 주 연결로 Direct Connect를 사용하고, 백업으로 VPN connection을 두어 장애 시에도 서비스 연속성과 비용 효율성을 모두 달성하는 구성이 최적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "하이브리드 아키텍처",
      "고가용성",
      "저지연",
      "비용 최소화",
      "AWS Direct Connect",
      "VPN connection"
    ],
    "Terms": [
      "AWS Direct Connect",
      "VPN connection",
      "AWS Region",
      "Direct Connect failover attribute"
    ],
    "SelectA": "AWS Direct Connect를 Region에 프로비저닝합니다. 기본 Direct Connect 장애에 대비해 VPN connection을 백업으로 구성합니다.",
    "SelectA_Commentary": "Direct Connect로 일관된 저지연을 보장하고, 장애 시 VPN으로 전환하여 비용 부담 없이 고가용성을 유지할 수 있는 최적 구성입니다.",
    "SelectB": "Region에 대한 private connectivity를 위해 VPN tunnel connection을 프로비저닝합니다. 기본 VPN 연결이 실패할 경우를 대비해 추가 VPN tunnel을 구성합니다.",
    "SelectB_Commentary": "VPN만 두 개 구성하면 일관된 저지연을 보장하기 어려워 회사의 요구사항을 충족하기 힘듭니다.",
    "SelectC": "Region에 대한 AWS Direct Connect 연결을 프로비저닝합니다. 기본 Direct Connect 장애에 대비해 동일 Region에 두 번째 Direct Connect 연결을 구성합니다.",
    "SelectC_Commentary": "Direct Connect를 이중화하면 고가용성이지만, 비용이 높고 장애 시에도 VPN 같은 저비용 대안이 없어 요구사항과 맞지 않습니다.",
    "SelectD": "Region에 AWS Direct Connect를 프로비저닝합니다. 기본 Direct Connect 장애 시 AWS CLI의 Direct Connect failover attribute를 사용해 자동으로 백업 연결을 생성하도록 구성합니다.",
    "SelectD_Commentary": "AWS CLI만으로 자동 백업 연결을 즉시 생성하는 기능은 없으며, 별도의 물리적 이중화가 필요하므로 적절한 솔루션이 아닙니다.",
    "Question_Description_recommedations": [
      "Q408",
      "Q700",
      "Q293",
      "Q983",
      "Q487"
    ],
    "SelectA_recommedations": [
      "Q68",
      "Q722",
      "Q983"
    ],
    "SelectB_recommedations": [
      "Q487",
      "Q68",
      "Q700"
    ],
    "SelectC_recommedations": [
      "Q68",
      "Q983",
      "Q722"
    ],
    "SelectD_recommedations": [
      "Q68",
      "Q585",
      "Q983"
    ]
  },
  {
    "Question_Number": "Q69",
    "Question_Description": "한 회사가 비즈니스 크리티컬 웹 애플리케이션을 Amazon EC2 인스턴스에서 Application Load Balancer 뒤에서 운영 중입니다. 이 EC2 인스턴스들은 Auto Scaling group으로 구성되어 있습니다. 애플리케이션은 단일 Availability Zone에 배포된 Amazon Aurora PostgreSQL 데이터베이스를 사용하고 있습니다. 회사는 최소한의 다운타임과 데이터 손실로 애플리케이션을 고가용성으로 운영하기를 원합니다. 이 요구사항을 최소한의 운영 노력으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85594-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 웹 애플리케이션과 데이터베이스 모두에서 단일 AZ 문제 발생 시에도 운영이 중단되지 않는 구성을 요구합니다. 다중 AZ를 사용하는 Auto Scaling group과 Multi-AZ로 구성된 Amazon Aurora PostgreSQL, 그리고 Amazon RDS Proxy를 사용하면 다운타임과 데이터 손실을 최소화하면서 자동으로 장애조치 되어 고가용성을 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "최소 다운타임",
      "최소 데이터 손실",
      "Auto Scaling group",
      "Multi-AZ",
      "Amazon RDS Proxy"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon Aurora PostgreSQL",
      "Multi-AZ",
      "Amazon RDS Proxy",
      "Amazon Route 53",
      "AWS Lambda",
      "Amazon S3",
      "S3 Event Notifications"
    ],
    "SelectA": "EC2 인스턴스들을 서로 다른 AWS Region에 배치합니다. Amazon Route 53 헬스 체크를 사용해 트래픽을 리다이렉션합니다. Aurora PostgreSQL Cross-Region Replication을 사용합니다.",
    "SelectA_Commentary": "멀티 리전 구성과 Cross-Region Replication은 설정과 운영이 복잡하며, 단일 AZ 장애 대비보다는 과도한 솔루션입니다.",
    "SelectB": "Auto Scaling group을 다중 Availability Zone에서 동작하도록 구성합니다. 데이터베이스를 Multi-AZ로 구성합니다. 데이터베이스용 Amazon RDS Proxy 인스턴스를 설정합니다.",
    "SelectB_Commentary": "다중 AZ와 Multi-AZ 구성, 그리고 RDS Proxy를 통해 다운타임 시에도 즉시 대체 인스턴스로 전환 가능하여 고가용성과 최소 데이터 손실을 구현합니다.",
    "SelectC": "Auto Scaling group을 단일 Availability Zone에서 사용하도록 설정합니다. 데이터베이스 스냅샷을 시간 단위로 생성합니다. 장애 시 스냅샷에서 복구합니다.",
    "SelectC_Commentary": "스냅샷 복구는 시간이 오래 걸리며, 데이터 손실 가능성도 있어 비즈니스 크리티컬 환경에는 적합하지 않습니다.",
    "SelectD": "Auto Scaling group을 여러 AWS Region에서 동작하도록 구성합니다. 애플리케이션에서 생성되는 데이터를 Amazon S3로 쓰고, S3 Event Notifications로 AWS Lambda 함수를 트리거하여 데이터베이스에 기록합니다.",
    "SelectD_Commentary": "멀티 리전 구성과 Lambda 트리거로 데이터베이스 동기화를 구성하는 것은 운영 복잡도가 높으며, 다운타임은 줄여도 즉각적인 DB 장애 조치는 어렵습니다.",
    "Question_Description_recommedations": [
      "Q275",
      "Q405",
      "Q691",
      "Q298",
      "Q879"
    ],
    "SelectA_recommedations": [
      "Q879",
      "Q178",
      "Q241"
    ],
    "SelectB_recommedations": [
      "Q390",
      "Q298",
      "Q466"
    ],
    "SelectC_recommedations": [
      "Q691",
      "Q729",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q595",
      "Q874"
    ]
  },
  {
    "Question_Number": "Q70",
    "Question_Description": "회사의 HTTP 애플리케이션이 Network Load Balancer(NLB) 뒤에 위치해 있으며, 이 NLB의 대상 그룹은 여러 Amazon EC2 인스턴스가 포함된 Amazon EC2 Auto Scaling 그룹으로 구성되어 웹 서비스를 실행하고 있습니다. 회사는 애플리케이션에서 발생하는 HTTP 오류를 NLB가 감지하지 못하고 있으며, 이 오류가 발생할 때마다 웹 서비스를 실행하는 EC2 인스턴스를 수동으로 재시작해야 하는 상황입니다. 회사는 커스텀 스크립트나 코드를 작성하지 않고도 애플리케이션의 가용성을 높이고자 합니다. 이러한 요구 사항을 만족하기 위해서는 어떤 조치를 취해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85734-exam-aws-certified-solut",
    "AnswerDescription": "NLB는 주로 TCP 또는 제한적인 계층 4 수준의 헬스 체크를 지원하여 특정 HTTP URL 상태 확인에는 적합하지 않습니다. ALB는 계층 7에서 HTTP 상태 코드를 확인할 수 있어, 애플리케이션 레벨의 오류를 감지하고 문제가 있는 인스턴스를 자동으로 교체하도록 설정할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "HTTP 애플리케이션",
      "NLB",
      "EC2 Auto Scaling",
      "가용성 개선",
      "HTTP 오류 감지"
    ],
    "Terms": [
      "Network Load Balancer(NLB)",
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Amazon EC2 Auto Scaling",
      "HTTP Health Check",
      "Amazon CloudWatch"
    ],
    "SelectA": "NLB에서 HTTP 헬스 체크를 활성화하고 회사 애플리케이션의 URL을 입력합니다.",
    "SelectA_Commentary": "NLB는 기본적으로 HTTP/HTTPS 헬스 체크를 지원하지만, 특정 URL 기반의 정교한 헬스 체크 기능이 제한적이어서 문제 해결에 적합하지 않습니다.",
    "SelectB": "EC2 인스턴스에 cron 작업을 추가하여 로컬 애플리케이션 로그를 분마다 확인하고, HTTP 오류가 관찰되면 애플리케이션을 재시작합니다.",
    "SelectB_Commentary": "이는 커스텀 스크립트 작성과 설정이 필요하여 운영 복잡도가 높습니다. 자동 확장 및 교체가 이루어지지 않아 가용성 향상에 한계가 있습니다.",
    "SelectC": "NLB를 Application Load Balancer(ALB)로 교체하고, 회사 애플리케이션의 URL을 제공하여 HTTP 헬스 체크를 활성화합니다. Auto Scaling 액션을 구성하여 비정상 인스턴스를 자동으로 교체합니다.",
    "SelectC_Commentary": "ALB는 계층 7 기반 헬스 체크를 지원하여 HTTP 오류를 세밀하게 감지할 수 있으며, Auto Scaling과 연동해 불량 인스턴스를 자동으로 교체하여 가용성을 크게 향상시키는 최적의 해법입니다.",
    "SelectD": "NLB에 대한 UnhealthyHostCount 지표를 모니터링하는 Amazon CloudWatch Alarm을 생성합니다. 경보가 ALARM 상태가 되면 비정상 인스턴스를 교체하도록 Auto Scaling 액션을 구성합니다.",
    "SelectD_Commentary": "UnhealthyHostCount는 TCP 수준 헬스 체크만 감지하기 때문에 HTTP 레이어에서의 세부적인 오류 식별이 어렵습니다. 근본 해결책이 되지 못합니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q846",
      "Q174",
      "Q275",
      "Q120"
    ],
    "SelectA_recommedations": [
      "Q567",
      "Q51",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q584",
      "Q194",
      "Q757"
    ],
    "SelectC_recommedations": [
      "Q70",
      "Q405",
      "Q174"
    ],
    "SelectD_recommedations": [
      "Q70",
      "Q405",
      "Q174"
    ]
  },
  {
    "Question_Number": "Q71",
    "Question_Description": "한 회사는 Amazon DynamoDB를 사용하여 고객 정보를 저장하는 쇼핑 애플리케이션을 운영하고 있습니다. 데이터가 손상될 경우를 대비해, 솔루션스 아키텍트는 복구 시점 목표(RPO)를 15분, 복구 시간 목표(RTO)를 1시간으로 충족하는 솔루션을 설계해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85603-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 짧은 RPO와 RTO를 만족하기 위해 DynamoDB 데이터를 빠르고 정확하게 백업하고 복원하는 방안을 찾는 것입니다. Point-in-time recovery(PITR)는 DynamoDB에서 연속 백업을 제공해 원하는 시점으로 바로 복원이 가능하므로 15분 이내의 RPO와 1시간 내 RTO를 충족하기에 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DynamoDB",
      "RPO 15분",
      "RTO 1시간",
      "Point-in-time recovery",
      "백업 및 복원"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "RPO",
      "RTO",
      "DynamoDB Global Tables",
      "DynamoDB Point-in-time recovery",
      "Amazon S3 Glacier",
      "Amazon EBS Snapshot"
    ],
    "SelectA": "DynamoDB Global Tables를 구성합니다. RPO 복구 시, 애플리케이션을 다른 AWS 리전으로 지정합니다.",
    "SelectA_Commentary": "Global Tables는 리전 간 데이터 동기화에 유용하지만, 데이터 손상이 여러 리전에 그대로 복제될 수 있어 백업/복원 시점 제어가 어렵습니다.",
    "SelectB": "DynamoDB Point-in-time recovery를 구성합니다. RPO 복구 시, 원하는 시점으로 복원합니다.",
    "SelectB_Commentary": "PITR을 통해 최대 35일 이내 어떤 시점으로든 손쉽게 복원할 수 있어, 15분 RPO와 1시간 RTO 목표를 만족합니다.",
    "SelectC": "DynamoDB 데이터를 매일 Amazon S3 Glacier로 내보냅니다. RPO 복구 시, S3 Glacier로부터 DynamoDB로 데이터를 가져옵니다.",
    "SelectC_Commentary": "하루에 한 번 백업은 15분 RPO 요구사항을 충족하지 못하고 S3 Glacier 복원 속도도 느려 RTO 충족이 어렵습니다.",
    "SelectD": "Amazon EBS 스냅샷을 15분 간격으로 예약 실행합니다. RPO 복구 시, 이 EBS 스냅샷을 사용해 DynamoDB 테이블을 복원합니다.",
    "SelectD_Commentary": "DynamoDB는 서버리스 서비스이므로 EBS 스냅샷 기반 복원이 불가능하며, 해당 접근 방식은 적용할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q896",
      "Q281",
      "Q490",
      "Q78",
      "Q1002"
    ],
    "SelectA_recommedations": [
      "Q71",
      "Q490",
      "Q896"
    ],
    "SelectB_recommedations": [
      "Q71",
      "Q588",
      "Q896"
    ],
    "SelectC_recommedations": [
      "Q71",
      "Q490",
      "Q896"
    ],
    "SelectD_recommedations": [
      "Q71",
      "Q281",
      "Q845"
    ]
  },
  {
    "Question_Number": "Q72",
    "Question_Description": "한 회사가 사진 처리 애플리케이션을 운영하는데, 동일한 AWS Region에 위치한 Amazon S3 버킷들로부터 자주 이미지를 업로드하고 다운로드해야 합니다. 솔루션스 아키텍트는 데이터 전송 비용이 증가하고 있음을 확인했고, 이를 절감할 수 있는 솔루션을 구현해야 합니다. 어떤 접근 방식이 이 요구 사항을 충족할 수 있습니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85604-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 같은 Region 내에서 빈번하게 발생하는 S3 트래픽을 어떻게 내부 경로로 라우팅해 데이터 전송 비용을 줄일지 묻습니다. S3 VPC gateway endpoint를 사용하면 인터넷을 거치지 않아 비용이 크게 절감됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "동일한 AWS Region",
      "데이터 전송 비용",
      "Amazon S3 버킷",
      "S3 VPC gateway endpoint"
    ],
    "Terms": [
      "Amazon S3",
      "S3 VPC gateway endpoint",
      "NAT gateway",
      "Internet gateway",
      "Amazon API Gateway",
      "endpoint policy",
      "퍼블릭 서브넷",
      "VPC"
    ],
    "SelectA": "퍼블릭 서브넷에 Amazon API Gateway를 배포하고, 라우트 테이블을 조정하여 S3 호출을 이를 통해 라우팅합니다.",
    "SelectA_Commentary": "API Gateway로 트래픽을 우회하면 내부 통신을 활용하지 못하고 외부 흐름을 유발하므로, 비용 절감에 효과적이지 않습니다.",
    "SelectB": "퍼블릭 서브넷에 NAT gateway를 배포하고, S3 버킷 액세스를 허용하는 endpoint policy를 연결합니다.",
    "SelectB_Commentary": "NAT gateway를 경유하면 인터넷 트래픽으로 처리되어 추가 전송 비용이 발생하므로, VPC endpoint보다 비용 효율성이 떨어집니다.",
    "SelectC": "애플리케이션을 퍼블릭 서브넷에 배포하고, Internet gateway를 통해 S3 버킷에 접근하도록 라우팅을 허용합니다.",
    "SelectC_Commentary": "Internet gateway를 통한 액세스는 인터넷을 거치는 방식이므로, 전송 비용 절감 효과가 충분히 크지 않습니다.",
    "SelectD": "VPC에 S3 VPC gateway endpoint를 배포하고, S3 버킷 액세스를 허용하는 endpoint policy를 연결합니다.",
    "SelectD_Commentary": "S3 VPC gateway endpoint를 이용하면 VPC 내부 트래픽으로 연결되어 데이터 전송 비용을 절감하고, endpoint policy로 세부 권한 제어도 가능합니다.",
    "Question_Description_recommedations": [
      "Q960",
      "Q829",
      "Q498",
      "Q469",
      "Q993"
    ],
    "SelectA_recommedations": [
      "Q993",
      "Q469",
      "Q829"
    ],
    "SelectB_recommedations": [
      "Q497",
      "Q42",
      "Q993"
    ],
    "SelectC_recommedations": [
      "Q911",
      "Q769",
      "Q469"
    ],
    "SelectD_recommedations": [
      "Q471",
      "Q497",
      "Q860"
    ]
  },
  {
    "Question_Number": "Q73",
    "Question_Description": "한 회사가 최근 Amazon EC2의 private subnet에 Linux 기반 애플리케이션 인스턴스를, VPC의 public subnet에 Linux 기반 bastion host를 런칭했습니다. 이 솔루션스 아키텍트는 온프레미스 네트워크에서 회사의 인터넷 연결을 통해 bastion host로, 그리고 애플리케이션 서버들로 연결해야 합니다. 이 솔루션스 아키텍트는 모든 EC2 인스턴스의 보안 그룹이 해당 액세스를 허용하도록 해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트가 취해야 하는 단계의 조합은 무엇입니까? (2개를 선택하십시오.)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85613-exam-aws-certified-solut",
    "AnswerDescription": "온프레미스 외부 IP에서 bastion host로 접속하고, 그 bastion host의 private IP만 애플리케이션 서버에 SSH를 허용하도록 보안 그룹을 구성해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "bastion host",
      "private subnet",
      "public subnet",
      "on-premises network",
      "security group",
      "접근 허용",
      "external IP range",
      "private IP",
      "SSH"
    ],
    "Terms": [
      "Amazon EC2",
      "bastion host",
      "security group",
      "private subnet",
      "public subnet",
      "SSH",
      "inbound access",
      "IP range"
    ],
    "SelectA": "현재 bastion host의 보안 그룹을 애플리케이션 인스턴스에서만 들어오는 액세스를 허용하도록 교체하십시오.",
    "SelectA_Commentary": "bastion host가 온프레미스에서 접근 가능해야 하므로 잘못된 구성입니다.",
    "SelectB": "현재 bastion host의 보안 그룹을 회사 내부 IP 범위에서만 들어오는 액세스를 허용하도록 교체하십시오.",
    "SelectB_Commentary": "온프레미스 연결이지만 외부 인터넷 IP를 통한 연결도 필요한 경우가 많으므로 제한적입니다.",
    "SelectC": "현재 bastion host의 보안 그룹을 회사의 외부 IP 범위에서만 들어오는 액세스를 허용하도록 교체하십시오.",
    "SelectC_Commentary": "bastion host에 외부 IP(온프레미스)에서 SSH 접근을 허용해야 하므로 옳은 선택입니다.",
    "SelectD": "현재 애플리케이션 인스턴스의 보안 그룹을 bastion host의 private IP 주소에서만 SSH로 들어오는 액세스를 허용하도록 교체하십시오.",
    "SelectD_Commentary": "같은 VPC 내에서 bastion host는 private IP로 애플리케이션 서버에 연결하므로 옳은 선택입니다.",
    "SelectE": "현재 애플리케이션 인스턴스의 보안 그룹을 bastion host의 public IP 주소에서만 SSH로 들어오는 액세스를 허용하도록 교체하십시오.",
    "SelectE_Commentary": "동일 VPC에서는 private IP를 활용하므로 public IP 접근은 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q251",
      "Q254",
      "Q610",
      "Q370",
      "Q115"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q803"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q803",
      "Q73"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q803",
      "Q73"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q468",
      "Q232"
    ],
    "SelectE_recommedations": [
      "Q774",
      "Q232",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q74",
    "Question_Description": "한 솔루션스 아키텍트가 2티어 웹 애플리케이션을 설계하고 있습니다. 웹 계층은 public subnet에 위치한 Amazon EC2에 호스팅되어 있으며, 데이터베이스 계층은 Microsoft SQL Server가 구동되는 Amazon EC2가 private subnet에 위치합니다. 회사에서는 보안을 매우 중요하게 생각합니다. 이러한 상황에서 security group을 어떻게 구성해야 할까요? (정답은 2개를 고르십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85346-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 웹 계층(프론트엔드)과 데이터베이스 계층(백엔드)을 각각 다른 subnet에 두고, 서로 다른 security group을 올바르게 구성하여 보안을 강화하는 방법을 묻습니다. 웹 계층에서는 HTTPS(443)로 외부에서 접근 가능해야 하고, 데이터베이스 계층에서는 오직 웹 계층 security group에서 오는 1433 포트 트래픽만 허용해야 합니다. 이를 통해 공용 인터넷에서 직접 접근이 불가능하도록 하면서도 애플리케이션이 정상적으로 동작하게끔 보안 구성을 설정합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "2티어 웹 애플리케이션",
      "Amazon EC2",
      "public subnet",
      "private subnet",
      "Microsoft SQL Server",
      "security group",
      "포트 443",
      "포트 1433"
    ],
    "Terms": [
      "Amazon EC2",
      "Microsoft SQL Server",
      "public subnet",
      "private subnet",
      "security group",
      "inbound traffic",
      "outbound traffic",
      "port 443",
      "port 1433",
      "0.0.0.0/0"
    ],
    "SelectA": "웹 계층 security group을 0.0.0.0/0에서 포트 443으로의 인바운드 트래픽을 허용하도록 설정합니다.",
    "SelectA_Commentary": "HTTPS 접속을 위해 외부로부터 443 포트를 열어둬야 하므로 필수적인 설정입니다. 따라서 정답에 해당합니다.",
    "SelectB": "웹 계층 security group을 0.0.0.0/0에서 포트 443으로의 아웃바운드 트래픽을 허용하도록 설정합니다.",
    "SelectB_Commentary": "일반적으로 웹 서버에서의 아웃바운드 443은 서버가 외부로 접속할 때 필요한 규칙이지만, 질문에서 요구하는 필수적인 보안 구성 사항은 아닙니다.",
    "SelectC": "데이터베이스 계층 security group에서 웹 계층 security group으로부터 포트 1433 인바운드 트래픽을 허용하도록 설정합니다.",
    "SelectC_Commentary": "웹 계층(프론트엔드)에서 백엔드 DB(Microsoft SQL Server)에 연결하기 위한 포트를 열어주어야 하므로 정답입니다.",
    "SelectD": "데이터베이스 계층 security group에서 웹 계층 security group으로 포트 443과 1433에 대한 아웃바운드 트래픽을 허용하도록 설정합니다.",
    "SelectD_Commentary": "DB 계층에서 웹 계층으로 443이나 1433을 보낼 필요는 없습니다. 주로 웹 계층 → DB 계층으로 연결이 필요하므로 불필요한 설정입니다.",
    "SelectE": "데이터베이스 계층 security group에서 웹 계층 security group으로부터 포트 443과 1433 인바운드 트래픽을 허용하도록 설정합니다.",
    "SelectE_Commentary": "DB 계층에는 1433만 열면 되고 443은 필요하지 않으므로 과도한 허용 규칙입니다.",
    "Question_Description_recommedations": [
      "Q115",
      "Q875",
      "Q318",
      "Q251",
      "Q388"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q265",
      "Q803"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q265",
      "Q803"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q122",
      "Q665"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q803",
      "Q265"
    ],
    "SelectE_recommedations": [
      "Q774",
      "Q803",
      "Q395"
    ]
  },
  {
    "Question_Number": "Q75",
    "Question_Description": "한 회사가 애플리케이션의 성능을 개선하기 위해 온프레미스 환경에서 AWS Cloud로 다중 계층(multi-tiered) 애플리케이션을 이전하려고 합니다. 이 애플리케이션은 RESTful 서비스를 통해 서로 통신하는 여러 계층으로 구성되며, 한 계층이 과부하되면 트랜잭션이 누락되는 문제가 발생합니다. 솔루션 아키텍트는 이 문제를 해결하고 애플리케이션을 모던화할 방안을 설계해야 합니다. 이러한 요구사항을 만족하면서 가장 운영 효율적인 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86120-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 과부하로 인해 트랜잭션이 누락되는 전통적 계층 구조를 클라우드 환경에서 현대화하는 시나리오입니다. 병목 해소와 성능 개선을 위해 서버리스 구조(AWS Lambda)와 메시징(Amazon SQS)을 활용해 느슨하게 결합된 확장형 아키텍처를 구성하는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "다중 계층 애플리케이션",
      "성능 개선",
      "RESTful 서비스",
      "모던화",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon SQS"
    ],
    "Terms": [
      "AWS Cloud",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon CloudWatch",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon EC2",
      "Auto Scaling group"
    ],
    "SelectA": "Amazon API Gateway를 사용하여 트랜잭션을 AWS Lambda 함수(애플리케이션 계층)로 직접 연결하고, 애플리케이션 서비스 간 통신 계층으로 Amazon SQS를 사용합니다.",
    "SelectA_Commentary": "서버리스(Lambda)와 SQS를 활용한 메시지 처리로 계층 간 과부하를 방지하고 완전관리형 환경을 통해 운영 부담을 크게 줄이는 최적의 솔루션입니다.",
    "SelectB": "Amazon CloudWatch 지표를 사용해 애플리케이션 성능 기록을 분석한 뒤, 문제 발생 시점의 서버 피크 사용량에 맞추어 Amazon EC2 인스턴스 크기를 늘립니다.",
    "SelectB_Commentary": "서버 사양 증설은 트래픽 급증에 대비하지만, 과부하 발생 시점을 근본적으로 해결하지 못하고 운영 복잡도가 상대적으로 높아집니다.",
    "SelectC": "Amazon EC2 Auto Scaling 그룹으로 동작하는 애플리케이션 서버 간 메시징에 Amazon SNS를 사용하고, Amazon CloudWatch로 SNS 대기열 길이를 모니터링해 필요 시 확장합니다.",
    "SelectC_Commentary": "SNS는 주로 브로드캐스트 성격의 알림에 적합하며, SQS만큼 강력한 큐잉 기능을 제공하지 않아 트랜잭션 누락 문제를 완전히 해결하기 어렵습니다.",
    "SelectD": "Amazon EC2 Auto Scaling 그룹으로 동작하는 애플리케이션 서버 간 메시징에 Amazon SQS를 사용하고, Amazon CloudWatch로 SQS 대기열 길이를 모니터링한 뒤 통신 장애가 감지되면 확장합니다.",
    "SelectD_Commentary": "대기열 모니터링을 통한 확장은 가능하지만, 애플리케이션 계층을 서버리스로 전환하지 않아 민첩성과 운영 효율성이 A에 비해 떨어집니다.",
    "Question_Description_recommedations": [
      "Q1014",
      "Q513",
      "Q351",
      "Q683",
      "Q293"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q739",
      "Q207"
    ],
    "SelectB_recommedations": [
      "Q714",
      "Q584",
      "Q790"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q210",
      "Q581"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q210"
    ]
  },
  {
    "Question_Number": "Q76",
    "Question_Description": "한 회사는 단일 공장 안에 있는 여러 기계로부터 매일 10TB의 계측 데이터를 받습니다. 이 데이터는 공장 내부 온프레미스 데이터 센터의 SAN(Storage Area Network)에 JSON 파일 형태로 저장되어 있습니다. 회사는 이 데이터를 Amazon S3로 전송하여 여러 추가 시스템이 거의 실시간 분석을 수행하도록 하길 원합니다. 데이터는 민감 정보이므로 안전한 전송이 필수적입니다. 이러한 요구사항을 만족하는 가장 신뢰도 높은 데이터 전송 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85801-exam-aws-certified-solut",
    "AnswerDescription": "이 문제는 공장 내 SAN에 저장된 대규모 JSON 파일을 Amazon S3로 빠르고 안전하게 전송하는 방법을 묻습니다. AWS DataSync에 AWS Direct Connect를 사용하면 전용 네트워크로 안정성과 보안을 모두 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "AWS DataSync",
      "AWS Direct Connect",
      "JSON 파일",
      "10TB",
      "SAN",
      "민감 데이터",
      "Amazon S3"
    ],
    "Terms": [
      "AWS DataSync",
      "AWS Direct Connect",
      "AWS Database Migration Service (AWS DMS)",
      "SAN(Storage Area Network)",
      "JSON",
      "on-premises data center",
      "public internet"
    ],
    "SelectA": "AWS DataSync over public internet",
    "SelectA_Commentary": "인터넷 기반 전송은 지연 및 보안 이슈가 발생할 수 있어 신뢰도가 떨어집니다.",
    "SelectB": "AWS DataSync over AWS Direct Connect",
    "SelectB_Commentary": "전용 네트워크 연결을 사용해 안정적이고 안전한 전송이 가능하므로 대규모 민감 데이터 전송에 최적입니다.",
    "SelectC": "AWS Database Migration Service (AWS DMS) over public internet",
    "SelectC_Commentary": "DMS는 주로 데이터베이스 마이그레이션용으로 JSON 파일 전송에 적합하지 않으며, 공용 인터넷은 신뢰성이 낮습니다.",
    "SelectD": "AWS Database Migration Service (AWS DMS) over AWS Direct Connect",
    "SelectD_Commentary": "DMS 자체는 데이터베이스 마이그레이션에 집중된 서비스이므로 JSON 파일 전송 요구사항에는 부적절합니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q672",
      "Q397",
      "Q292",
      "Q1"
    ],
    "SelectA_recommedations": [
      "Q704",
      "Q501",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q704",
      "Q472",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q305",
      "Q249",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q305",
      "Q249",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q77",
    "Question_Description": "한 회사가 애플리케이션에 대해 실시간 데이터 수집 아키텍처를 구성해야 합니다. 회사는 API가 필요하고, 스트리밍되는 동안 데이터를 변환하는 프로세스가 필요하며, 데이터를 저장할 스토리지 솔루션이 필요합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85740-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션에서 실시간으로 유입되는 데이터를 가져와 변환하고 저장하기 위한 아키텍처 구성에 대한 것입니다. Amazon API Gateway와 Amazon Kinesis Data Streams, Kinesis Data Firehose, AWS Lambda를 결합하여 데이터를 실시간으로 처리하고 Amazon S3에 저장하면 운영 부담을 크게 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "실시간 데이터 스트리밍",
      "API",
      "데이터 변환",
      "저장",
      "Kinesis Data Firehose",
      "Lambda",
      "Amazon S3",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon API Gateway",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "AWS Lambda",
      "Amazon S3",
      "AWS Glue"
    ],
    "SelectA": "Amazon EC2 인스턴스를 배포하여 API를 호스팅하고, 데이터를 Amazon Kinesis data stream으로 전송합니다. Amazon Kinesis Data Firehose를 생성하여 해당 data stream을 데이터 소스로 사용합니다. AWS Lambda 함수를 사용해 데이터를 변환하고, 변환된 데이터를 Kinesis Data Firehose를 통해 Amazon S3로 전송합니다.",
    "SelectA_Commentary": "별도의 EC2 배포가 필요하므로 운영 오버헤드가 증가합니다. 전체 흐름은 유사하나 API를 EC2에서 호스팅해야 하므로 관리가 복잡해집니다.",
    "SelectB": "Amazon EC2 인스턴스를 배포하여 API를 호스팅하고 AWS Glue로 데이터를 전송합니다. EC2 인스턴스에서 소스/대상 확인을 해제합니다. AWS Glue를 사용하여 데이터를 변환하고 Amazon S3로 전송합니다.",
    "SelectB_Commentary": "EC2와 AWS Glue를 결합한 방식으로 실시간 스트리밍에는 적합하지 않으며, 운영 오버헤드가 큽니다.",
    "SelectC": "Amazon API Gateway API를 구성하여 데이터를 Amazon Kinesis data stream으로 전송합니다. Amazon Kinesis Data Firehose를 생성하여 해당 data stream을 데이터 소스로 사용합니다. AWS Lambda 함수를 사용해 데이터를 변환하고, Kinesis Data Firehose를 통해 Amazon S3로 데이터를 전송합니다.",
    "SelectC_Commentary": "API Gateway와 Kinesis, Lambda, Firehose를 연계하여 실시간 데이터를 처리하고 S3에 저장하며, EC2가 필요 없어 운영 오버헤드를 최소화하는 최적의 솔루션입니다.",
    "SelectD": "Amazon API Gateway API를 구성하여 데이터를 AWS Glue로 전송합니다. AWS Lambda 함수를 사용하여 데이터를 변환합니다. AWS Glue를 사용하여 데이터를 Amazon S3로 전송합니다.",
    "SelectD_Commentary": "AWS Glue는 주로 배치 데이터 처리에 사용되며, API Gateway를 통한 실시간 스트리밍 처리와는 맞지 않아 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q516",
      "Q107",
      "Q506",
      "Q915",
      "Q132"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q910",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q103",
      "Q910",
      "Q226"
    ],
    "SelectC_recommedations": [
      "Q402",
      "Q597",
      "Q576"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q78",
    "Question_Description": "한 회사가 Amazon DynamoDB 테이블에 사용자 트랜잭션 데이터를 보관해야 합니다. 이 회사는 데이터를 7년 동안 유지해야 합니다. 이 요구사항을 충족하는 가장 운영 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85742-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB에 저장된 데이터를 7년간 유지하면서 운영 복잡도를 최소화하는 백업 전략을 찾는 것입니다. 단순한 PITR(Point-in-time recovery)로는 최대 35일까지 복원이 가능해 장기 보관 요건을 충족하지 못합니다. On-demand 백업과 S3 라이프사이클 등 수동 관리 방식은 오퍼레이션 부담이 큽니다. 반면 AWS Backup을 사용하면 백업 일정 관리와 보존 정책을 한 번에 지정할 수 있어 가장 운영 효율적인 솔루션이 됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon DynamoDB",
      "7년 보관",
      "운영 효율성",
      "백업 일정",
      "AWS Backup"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Point-in-time recovery (PITR)",
      "On-demand backup",
      "AWS Backup",
      "Amazon S3",
      "S3 Lifecycle",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "SelectA": "DynamoDB 테이블에 대해 point-in-time recovery를 사용하여 연속 백업을 수행합니다.",
    "SelectA_Commentary": "PITR은 최대 35일까지 복원이 가능하므로 7년 보관을 충족하지 않습니다.",
    "SelectB": "AWS Backup을 사용하여 백업 일정과 테이블의 보존 정책을 생성합니다.",
    "SelectB_Commentary": "AWS Backup으로 장기 백업 일정 및 보존 정책을 중앙에서 자동 관리할 수 있어 운영 효율성이 매우 높습니다.",
    "SelectC": "DynamoDB 콘솔에서 테이블의 온디맨드 백업을 생성하고, 이를 Amazon S3 버킷에 저장합니다. S3 Lifecycle 구성으로 관리합니다.",
    "SelectC_Commentary": "수동으로 백업 스케줄을 설정해야 하므로 장기적으로 운영 부담이 큽니다.",
    "SelectD": "Amazon EventBridge 규칙로 AWS Lambda 함수를 호출하여 테이블을 백업하고, Amazon S3 버킷에 저장합니다. 이후 S3 Lifecycle을 설정합니다.",
    "SelectD_Commentary": "별도의 Lambda 및 EventBridge 설정이 필요해 운영 절차가 복잡하기 때문에 가장 효율적인 방법이 아닙니다.",
    "Question_Description_recommedations": [
      "Q1002",
      "Q845",
      "Q400",
      "Q768",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q1002",
      "Q78",
      "Q845"
    ],
    "SelectB_recommedations": [
      "Q293",
      "Q8",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q490",
      "Q1002",
      "Q78"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q569",
      "Q98"
    ]
  },
  {
    "Question_Number": "Q79",
    "Question_Description": "한 회사가 Amazon DynamoDB 테이블을 사용하여 데이터 저장을 계획하고 있습니다. 회사는 비용 최적화에 대해 우려하고 있습니다. 이 테이블은 대부분의 아침 시간대에는 사용되지 않을 것입니다. 저녁 시간대에는 읽기 및 쓰기 트래픽이 종종 예측하기 힘들 것입니다. 트래픽 급증이 발생하면 매우 빠르게 일어납니다. 솔루션스 아키텍트는 어떤 방안을 권장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85743-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 일정하지 않고 예측하기 어려운 트래픽 패턴과 비용 최적화를 동시에 해결해야 합니다. on-demand capacity mode를 사용하면 사용량 급증 시 자동으로 확장되고, 사용한 만큼만 비용을 지불해 무활성 시간대 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "비용 최적화",
      "아침 시간대 미사용",
      "저녁 예측 불가능 트래픽",
      "트래픽 급증",
      "on-demand capacity mode"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "on-demand capacity mode",
      "provisioned capacity",
      "auto scaling",
      "global table",
      "global secondary index"
    ],
    "SelectA": "Amazon DynamoDB 테이블을 on-demand capacity mode로 생성하십시오.",
    "SelectA_Commentary": "필요할 때 자동으로 확장되며, 사용량이 적을 때는 비용도 줄어듭니다. 트래픽 급변 상황에서도 프로비저닝 설정 없이 즉시 대응 가능해 비용 최적화에 가장 적합합니다.",
    "SelectB": "글로벌 보조 인덱스(global secondary index)가 포함된 DynamoDB 테이블을 생성하십시오.",
    "SelectB_Commentary": "글로벌 보조 인덱스는 조회 패턴 확장에 유용하지만 예측 불가능한 트래픽과 비용 최적화 문제 자체를 해결해 주지는 못합니다.",
    "SelectC": "프로비저닝된 용량(provisioned capacity)과 auto scaling이 설정된 DynamoDB 테이블을 생성하십시오.",
    "SelectC_Commentary": "auto scaling은 트래픽 변화에 대응할 수 있지만 예측치 설정이 필요하며, 급격한 급증에 대한 즉각 대응과 비사용 시간대 비용 절감에서 on-demand만큼 유연하지 않습니다.",
    "SelectD": "프로비저닝된 용량 모드로 DynamoDB 테이블을 생성하고, 이를 글로벌 테이블(global table)로 구성하십시오.",
    "SelectD_Commentary": "글로벌 테이블을 통한 다중 리전 동기화는 가용성과 지연 시간 개선에 도움을 주지만, 비용 최적화와预测 불가 트래픽에 대한 신속 대응 면에서는 on-demand 모드가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q348",
      "Q670",
      "Q799",
      "Q196",
      "Q411"
    ],
    "SelectA_recommedations": [
      "Q670",
      "Q79",
      "Q348"
    ],
    "SelectB_recommedations": [
      "Q348",
      "Q670",
      "Q79"
    ],
    "SelectC_recommedations": [
      "Q670",
      "Q505",
      "Q196"
    ],
    "SelectD_recommedations": [
      "Q348",
      "Q79",
      "Q670"
    ]
  },
  {
    "Question_Number": "Q80",
    "Question_Description": "한 회사는 최근 애플리케이션 마이그레이션 이니셔티브를 지원하기 위해 AWS Managed Service Provider(MSP) Partner와 계약을 체결했습니다. 한 Solutions Architect는 기존 AWS 계정의 Amazon Machine Image(AMI)를 MSP Partner의 AWS 계정과 공유해야 합니다. 해당 AMI는 Amazon Elastic Block Store(Amazon EBS) 기반이며, EBS 볼륨 스냅샷 암호화를 위해 AWS Key Management Service(AWS KMS)의 customer managed key를 사용합니다. 가장 보안성이 높은 방식으로 AMI를 MSP Partner의 AWS 계정과 공유하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85606-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 KMS customer managed key로 암호화된 Amazon EBS 기반 AMI를 외부 AWS 계정(MSP Partner)과 공유할 때의 보안적인 방법을 묻습니다. 공유 대상 계정이 스냅샷을 복호화하고 AMI를 정상적으로 사용할 수 있도록, launchPermission과 KMS 키 정책을 적절히 설정해야 합니다. 퍼블릭 공유나 Export 절차 등은 불필요하거나 보안 위험, 운영 복잡성을 유발하므로 피해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Managed Service Provider(MSP) Partner",
      "Amazon Machine Image(AMI)",
      "암호화된 AMI 공유",
      "AWS KMS customer managed key",
      "EBS 볼륨 스냅샷"
    ],
    "Terms": [
      "Amazon Machine Image (AMI)",
      "AWS Managed Service Provider (MSP)",
      "Amazon EBS",
      "AWS KMS",
      "customer managed key",
      "EBS volume snapshots",
      "Key Policy",
      "launchPermission"
    ],
    "SelectA": "암호화된 AMI와 스냅샷을 퍼블릭하게 만듭니다. 키 정책을 수정하여 MSP Partner의 AWS 계정이 해당 키를 사용할 수 있도록 허용합니다.",
    "SelectA_Commentary": "AMI와 스냅샷을 퍼블릭하게 하면 보안을 크게 약화시키므로, 필요 계정 이외에는 공개하지 않는 것이 안전합니다.",
    "SelectB": "AMI의 launchPermission 속성을 수정합니다. AMI를 MSP Partner의 AWS 계정과만 공유합니다. 키 정책을 수정하여 MSP Partner의 AWS 계정이 키를 사용할 수 있도록 허용합니다.",
    "SelectB_Commentary": "AMI를 특정 계정만 접근 가능하도록 설정하고, KMS 키 정책을 통해 해당 계정이 암호화된 스냅샷을 복호화할 수 있게 해주는 가장 보안적이고 간결한 접근입니다.",
    "SelectC": "AMI의 launchPermission 속성을 수정합니다. AMI를 MSP Partner의 AWS 계정과만 공유합니다. 새로 MSP Partner가 소유한 KMS 키가 암호화에 신뢰되도록 키 정책을 수정합니다.",
    "SelectC_Commentary": "기존 KMS 키가 아닌 다른 키를 쓰려면 재암호화가 필요할 수 있어 운영 복잡성이 상당히 높아집니다.",
    "SelectD": "소스 계정에서 AMI를 MSP Partner의 AWS 계정 내 Amazon S3 버킷으로 Export합니다. 해당 S3 버킷을 MSP Partner가 소유한 새로운 KMS 키로 암호화합니다. 그런 다음 AMI를 MSP Partner의 AWS 계정에서 복사 및 실행합니다.",
    "SelectD_Commentary": "Export 후 다시 Import하는 과정이 늘어나고 재암호화도 필수여서 절차가 복잡해집니다. 기존 KMS 키를 활용해 직접 공유하는 것보다 효율성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q777",
      "Q681",
      "Q82",
      "Q916",
      "Q924"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q893",
      "Q550"
    ],
    "SelectD_recommedations": [
      "Q1009",
      "Q965",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q81",
    "Question_Description": "한 솔루션스 아키텍트가 새로운 애플리케이션을 AWS에 배포하기 위해 클라우드 아키텍처를 설계하고 있습니다. 이 프로세스는 병렬로 실행되며, 처리해야 할 작업(job)의 수에 따라 애플리케이션 노드를 추가하거나 제거할 수 있어야 합니다. 프로세서 애플리케이션(processor application)은 무상태(stateless)입니다. 솔루션스 아키텍트는 애플리케이션이 느슨하게 결합되어 있고, 작업 항목(job items)이 영구적으로(durably) 저장되도록 해야 합니다. 이러한 요구사항을 충족하는 설계는 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86621-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 병렬 처리가 필요한 무상태 애플리케이션을 효율적으로 확장하고 작업을 안정적으로 저장하는 방법을 묻습니다. 느슨한 결합을 위해 Amazon SQS 같은 Queue 서비스 활용이 핵심이며, 처리량에 따라 Auto Scaling group을 동적으로 조정해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "병렬 처리",
      "무상태 애플리케이션",
      "느슨한 결합",
      "durably stored",
      "Amazon SQS",
      "Auto Scaling"
    ],
    "Terms": [
      "Amazon SNS",
      "Amazon SQS",
      "Amazon Machine Image (AMI)",
      "Launch Configuration",
      "Launch Template",
      "Auto Scaling group",
      "Scaling policy",
      "Stateless"
    ],
    "SelectA": "처리할 작업을 Amazon SNS 토픽을 통해 전송합니다. 프로세서 애플리케이션이 포함된 Amazon Machine Image(AMI)를 생성합니다. 해당 AMI를 사용하는 Launch Configuration을 만들고, Auto Scaling group을 생성합니다. Auto Scaling group은 CPU 사용률에 따라 노드를 조정합니다.",
    "SelectA_Commentary": "SNS는 주로 알림·푸시 기반 서비스로 내재적 메시지 보관 기능이 제한적입니다. 상태 저장과 내구성(durability)을 보장하기 어렵고 CPU 사용량만으로 처리가 필요한 작업 수를 제대로 반영하기 어렵습니다.",
    "SelectB": "처리할 작업을 저장할 Amazon SQS 큐를 만듭니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Configuration을 구성하고, Auto Scaling group을 만듭니다. 네트워크 사용량을 기준으로 노드를 조정하도록 설정합니다.",
    "SelectB_Commentary": "SQS를 이용해 내구성 있는 큐를 사용하지만, 네트워크 사용량을 기준으로 확장하면 작업 수와 직접 연관되지 않아 과소 혹은 과다 확장이 일어날 수 있습니다.",
    "SelectC": "처리할 작업을 저장할 Amazon SQS 큐를 만듭니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Template을 생성하고, Auto Scaling group을 구성합니다. SQS 큐의 항목 수에 따라 노드를 추가하거나 제거하도록 설정합니다.",
    "SelectC_Commentary": "SQS 큐는 메시지를 내구성 있게 저장해 느슨한 결합을 실현하며, 큐 항목 수에 따라 수평 확장을 자동으로 조정할 수 있어 요구사항을 완벽히 충족합니다.",
    "SelectD": "처리할 작업을 Amazon SNS 토픽에 전송합니다. 프로세서 애플리케이션이 포함된 AMI를 생성합니다. 해당 AMI를 사용하는 Launch Template을 생성하고, Auto Scaling group을 만듭니다. SNS 토픽에 게시되는 메시지 수를 기준으로 노드를 조정합니다.",
    "SelectD_Commentary": "SNS 토픽은 알림 기반이며 큐 자체가 없으므로 작업의 내구성 보장이 어렵습니다. 게시 메시지 수만으로는 실제 큐잉 기반 처리와 달리 안정적인 확장을 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q351",
      "Q963",
      "Q18",
      "Q720",
      "Q311"
    ],
    "SelectA_recommedations": [
      "Q1001",
      "Q405",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q1001",
      "Q405",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q1001",
      "Q405",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q489",
      "Q1001",
      "Q636"
    ]
  },
  {
    "Question_Number": "Q82",
    "Question_Description": "한 회사가 AWS Cloud에서 웹 애플리케이션을 호스팅하고 있습니다. 이 회사는 Elastic Load Balancer가 AWS Certificate Manager (ACM)에 가져온 인증서를 사용하도록 구성했습니다. 회사의 보안 팀은 각 인증서가 만료되기 30일 전에 반드시 알림을 받아야 합니다. 이 요구 사항을 충족하기 위해 Solutions Architect는 무엇을 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85615-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ACM에 등록된 인증서가 만료되기 전에 어떻게 미리 알림을 보낼 수 있는가에 대한 보안 운용 시나리오입니다. AWS Certificate Manager 자체에는 만료 알림을 직접 Scheduler 형태로 구성하는 기능이 없으므로, 만료 30일 전에 자동으로 리소스를 검사하고 알림을 보낼 수 있는 기능이 필요합니다. AWS Config는 acm-certificate-expiration-check라는 관리형 규칙을 제공하며, 이 규칙을 기반으로 인증서 만료 시점을 모니터링할 수 있습니다. EventBridge 규칙과 Amazon SNS 알림을 연계하여 보안 팀에 자동으로 알림을 전송하도록 설정할 수 있으므로 운영 복잡성 없이 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "AWS Cloud",
      "Elastic Load Balancer",
      "AWS Certificate Manager (ACM)",
      "인증서 만료",
      "30일 전 알림"
    ],
    "Terms": [
      "AWS Certificate Manager (ACM)",
      "Elastic Load Balancer",
      "AWS Config",
      "acm-certificate-expiration-check",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda",
      "AWS Trusted Advisor"
    ],
    "SelectA": "ACM에서 30일 전부터 매일 Amazon Simple Notification Service (Amazon SNS) 토픽으로 커스텀 메시지를 게시하는 규칙을 추가합니다.",
    "SelectA_Commentary": "ACM 자체에 이러한 규칙을 직접 추가할 수 없기에 부적절합니다.",
    "SelectB": "AWS Config에서 만료 30일 이내의 인증서를 검사하는 규칙을 생성하고, Amazon EventBridge (Amazon CloudWatch Events)와 SNS를 연동하여 비준수 리소스가 보고되면 경고를 발송합니다.",
    "SelectB_Commentary": "AWS Config의 acm-certificate-expiration-check 관리형 규칙을 사용하여 간단히 해결 가능합니다.",
    "SelectC": "AWS Trusted Advisor로 30일 이내에 만료될 인증서를 확인하고, Trusted Advisor의 상태 변경 지표를 기반으로 Amazon CloudWatch 알람을 생성해 SNS로 커스텀 알림을 전송합니다.",
    "SelectC_Commentary": "Trusted Advisor는 일부 인증서 점검을 제공하지만 즉시적이고 세밀한 만료 알림에는 AWS Config가 더 적합합니다.",
    "SelectD": "Amazon EventBridge (Amazon CloudWatch Events) 규칙을 생성해 30일 이내에 만료될 인증서를 감지하고, AWS Lambda 함수를 호출하여 SNS를 통해 커스텀 알림을 전송합니다.",
    "SelectD_Commentary": "직접 증분 로직을 구현해야 하므로, 이미 관리형 규칙이 있는 AWS Config 방식보다 복잡합니다.",
    "Question_Description_recommedations": [
      "Q549",
      "Q924",
      "Q26",
      "Q294",
      "Q393"
    ],
    "SelectA_recommedations": [
      "Q793",
      "Q364",
      "Q765"
    ],
    "SelectB_recommedations": [
      "Q27",
      "Q793",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q893",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q105",
      "Q981",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q83",
    "Question_Description": "한 회사의 동적 웹사이트가 미국에 있는 on-premises 서버를 사용해 호스팅되고 있습니다. 이 회사는 유럽에서 제품 출시를 앞두고, 새롭게 유럽 지역 사용자들의 사이트 로딩 시간을 최적화하고자 합니다. 하지만 웹사이트 백엔드는 계속 미국에 유지되어야 하며, 제품은 며칠 뒤 출시 예정이므로 즉시 구현 가능한 솔루션이 필요합니다. 솔루션스 아키텍트는 어떤 해결책을 제안해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85902-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 유럽 사용자들의 웹사이트 로딩 시간을 개선하면서 백엔드는 미국에 그대로 두고, 빠르게 구현 가능한 방안을 찾는 것이 핵심입니다. CloudFront를 사용해 on-premises 서버를 custom origin으로 설정하면, 전 세계 Edge Location에서 콘텐츠를 캐싱해 유럽 사용자에게 신속하게 전달할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "동적 웹사이트",
      "on-premises 서버",
      "유럽 사용자",
      "사이트 로딩 시간 최적화",
      "즉시 솔루션",
      "Amazon CloudFront",
      "custom origin"
    ],
    "Terms": [
      "Amazon CloudFront",
      "on-premises",
      "Amazon EC2",
      "Amazon S3",
      "Cross-Region Replication",
      "Amazon Route 53 geoproximity routing"
    ],
    "SelectA": "us-east-1에 Amazon EC2 인스턴스를 실행하고 사이트를 해당 인스턴스로 마이그레이션합니다.",
    "SelectA_Commentary": "사이트를 EC2로 이전해도 물리적 거리가 멀어 유럽 사용자의 지연 시간이 크게 개선되지 않고, 즉시 사용하기에도 시간이 더 소요됩니다.",
    "SelectB": "웹사이트를 Amazon S3로 이전합니다. 리전 간 Cross-Region Replication을 사용합니다.",
    "SelectB_Commentary": "정적 콘텐츠에는 적절하지만, 동적 웹사이트와 미국에 있는 on-premises 백엔드를 그대로 활용하는 요구사항에는 부적합합니다.",
    "SelectC": "Amazon CloudFront를 사용하고, on-premises 서버를 custom origin으로 지정합니다.",
    "SelectC_Commentary": "CloudFront의 CDN 기능으로 전 세계 Edge Location에서 콘텐츠를 제공해 유럽 사용자에게 빠른 응답 속도를 보장하므로 즉각적 해결책입니다.",
    "SelectD": "Amazon Route 53 geoproximity 라우팅 정책을 사용하여 on-premises 서버로 트래픽을 라우팅합니다.",
    "SelectD_Commentary": "지리적 위치에 따라 트래픽을 분산하지만, 미국에 있는 백엔드 자체를 그대로 두면서 유럽에서의 지연을 낮추기 위해서는 CloudFront와 같은 CDN 방식이 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q568",
      "Q631",
      "Q192",
      "Q443",
      "Q990"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q684",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q501",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q582",
      "Q38",
      "Q692"
    ]
  },
  {
    "Question_Number": "Q84",
    "Question_Description": "한 회사가 기존의 3티어 웹 아키텍처 비용을 절감하려고 합니다. 웹, 애플리케이션, 데이터베이스 서버는 개발, 테스트, 프로덕션 환경에서 Amazon EC2 인스턴스로 실행되고 있습니다. EC2 인스턴스는 피크 시간대에 평균 30% CPU 활용률, 비피크 시간대에 평균 10% CPU 활용률을 보입니다. 프로덕션 EC2 인스턴스는 하루 24시간 실행되며, 개발 및 테스트 EC2 인스턴스는 매일 최소 8시간씩 실행됩니다. 회사는 사용 중이 아닐 때 개발 및 테스트 EC2 인스턴스를 중지하도록 자동화를 구현하려고 합니다. 회사 요구사항을 가장 비용 효율적으로 충족하는 EC2 인스턴스 구매 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85665-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프로덕션에서는 24시간 상시 실행이 필요하므로 미리 예약해 두어 할인 혜택이 적용되는 Reserved Instances가 적합합니다. 개발과 테스트는 사용하지 않을 때 자동으로 중지할 수 있어 가변적인 시간만큼 비용을 지불하는 On-Demand Instances가 합리적입니다. Spot blocks는 현재 제공되지 않고, 상시 가용성이 필요한 프로덕션에 Spot Instances를 사용하는 것은 적합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 절감",
      "Amazon EC2",
      "Reserved Instances",
      "On-Demand Instances",
      "Spot Instances",
      "Spot blocks",
      "개발 환경",
      "테스트 환경",
      "프로덕션 환경"
    ],
    "Terms": [
      "CPU Utilization",
      "Three-tier web architecture",
      "Reserved Instances",
      "On-Demand Instances",
      "Spot Instances",
      "Spot blocks"
    ],
    "SelectA": "Spot Instances를 프로덕션 EC2 인스턴스에 사용하고, Reserved Instances를 개발 및 테스트 인스턴스에 사용합니다.",
    "SelectA_Commentary": "프로덕션은 24시간 안정적으로 실행되어야 하므로 중단될 수 있는 Spot Instances는 적절하지 않습니다.",
    "SelectB": "Reserved Instances를 프로덕션 EC2 인스턴스에 사용하고, On-Demand Instances를 개발 및 테스트 인스턴스에 사용합니다.",
    "SelectB_Commentary": "프로덕션은 상시 실행이 필요하므로 Reserved Instances로 장기 비용 절감이 가능하며, 개발 및 테스트는 On-Demand Instances로 필요 시간만큼만 비용을 지불할 수 있어 가장 효율적입니다.",
    "SelectC": "Spot blocks를 프로덕션 EC2 인스턴스에 사용하고, Reserved Instances를 개발 및 테스트 인스턴스에 사용합니다.",
    "SelectC_Commentary": "Spot blocks는 현재 이용할 수 없으며, 프로덕션의 안정적인 가동에도 적합하지 않습니다.",
    "SelectD": "On-Demand Instances를 프로덕션 EC2 인스턴스에 사용하고, Spot blocks를 개발 및 테스트 인스턴스에 사용합니다.",
    "SelectD_Commentary": "Spot blocks는 더 이상 제공되지 않으며, 자동 중지와 재시작이 가능한 On-Demand가 아닌 다른 방식으로는 개발/테스트의 탄력성을 제대로 살리기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q347",
      "Q552",
      "Q505",
      "Q671",
      "Q452"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q552",
      "Q773"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q1008",
      "Q552"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q904",
      "Q773"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ]
  },
  {
    "Question_Number": "Q85",
    "Question_Description": "한 회사는 프로덕션 웹 애플리케이션을 운영 중이며, 웹 인터페이스나 모바일 앱을 통해 사용자가 문서를 업로드합니다. 새로운 규제 요구사항에 따르면, 업로드된 문서는 저장 후 수정하거나 삭제할 수 없습니다. 이 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85751-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 규제 요구사항을 만족하기 위해 문서를 저장한 후 변경 또는 삭제가 불가능하도록 해야 하는 시나리오입니다. 정답은 Amazon S3에서 S3 Object Lock과 S3 Versioning을 함께 활성화하여 WORM(Write-Once-Read-Many) 보관 모델을 구현하는 것입니다. 이를 통해 업로드된 문서를 일정 기간 또는 무기한 동안 삭제나 덮어쓰기를 방지하고, 규제 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "프로덕션 웹 애플리케이션",
      "문서 업로드",
      "규제 요구사항",
      "변경 불가능",
      "Amazon S3",
      "S3 Object Lock",
      "S3 Versioning"
    ],
    "Terms": [
      "S3 Object Lock",
      "WORM",
      "S3 Versioning",
      "S3 Lifecycle Policy",
      "ACL",
      "Amazon EFS"
    ],
    "SelectA": "업로드된 문서를 S3 Versioning과 S3 Object Lock이 활성화된 Amazon S3 버킷에 저장합니다.",
    "SelectA_Commentary": "S3 Object Lock을 통해 저장된 객체를 변경 또는 삭제할 수 없는 WORM 모드를 구현할 수 있으므로 규제 요구사항을 충족합니다.",
    "SelectB": "업로드된 문서를 Amazon S3 버킷에 저장하고, 주기적으로 S3 Lifecycle 정책을 구성해 아카이빙합니다.",
    "SelectB_Commentary": "Lifecycle 정책은 객체를 다른 스토리지 클래스로 이동 또는 만료시키는 기능으로, 수정·삭제 방지를 보장하지 못합니다.",
    "SelectC": "S3 Versioning이 활성화된 Amazon S3 버킷에 업로드하고, ACL를 통해 읽기 전용 권한으로 제한합니다.",
    "SelectC_Commentary": "ACL만으로는 사용자가 객체를 수정하거나 삭제하지 못하게 완전히 막을 수 없으며, 규제 수준의 변경 불가 상태를 구현하기 어렵습니다.",
    "SelectD": "Amazon EFS 볼륨에 문서를 저장하고, read-only 모드로 볼륨을 마운트하여 데이터를 액세스합니다.",
    "SelectD_Commentary": "read-only 모드만으로는 EFS 데이터 변경을 영구적으로 금지하는 보장을 하지 못하고, WORM 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q26",
      "Q549",
      "Q393",
      "Q11",
      "Q294"
    ],
    "SelectA_recommedations": [
      "Q868",
      "Q965",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q270",
      "Q202",
      "Q412"
    ],
    "SelectC_recommedations": [
      "Q868",
      "Q862",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q825",
      "Q689"
    ]
  },
  {
    "Question_Number": "Q86",
    "Question_Description": "한 회사는 여러 웹 서버에서 공용 Amazon RDS MySQL Multi-AZ DB 인스턴스에 자주 액세스해야 합니다. 회사는 안전한 방법으로 웹 서버가 데이터베이스에 연결할 수 있기를 원하며, 사용자 자격 증명을 자주 교체(회전)해야 한다는 보안 요구사항을 충족해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85753-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 서버가 Amazon RDS MySQL Multi-AZ DB 인스턴스에 안전하게 연결하면서 자격 증명을 자주 교체해야 하는 상황을 다룹니다. AWS Secrets Manager를 사용하면 자격 증명을 안전하게 저장하고, 자동으로 회전시킬 수 있어 보안과 운영 편의성을 모두 충족합니다. 이를 통해 하드코딩된 비밀번호 위험을 최소화하고, 규칙적인 자격 증명 교체가 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon RDS MySQL Multi-AZ",
      "사용자 자격 증명 교체",
      "AWS Secrets Manager",
      "IAM 권한",
      "웹 서버 안전 연결"
    ],
    "Terms": [
      "Amazon RDS MySQL Multi-AZ",
      "AWS Secrets Manager",
      "IAM",
      "AWS Systems Manager OpsCenter",
      "Amazon S3",
      "AWS Key Management Service (AWS KMS)"
    ],
    "SelectA": "데이터베이스 사용자 자격 증명을 AWS Secrets Manager에 저장합니다. 웹 서버가 AWS Secrets Manager에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.",
    "SelectA_Commentary": "AWS Secrets Manager는 자격 증명 저장 및 자동 회전을 제공하여 보안을 크게 강화합니다. 웹 서버에서는 IAM 권한을 통해 동적으로 자격 증명을 받아 안전하게 DB에 연결할 수 있습니다.",
    "SelectB": "데이터베이스 사용자 자격 증명을 AWS Systems Manager OpsCenter에 저장합니다. 웹 서버가 OpsCenter에 액세스할 수 있도록 필요한 IAM 권한을 부여합니다.",
    "SelectB_Commentary": "OpsCenter는 운영 이벤트 관리를 주 목적으로 하며, Secrets Manager처럼 전문적으로 자격 증명을 자동 회전해 주는 기능이 별도로 제공되지 않습니다.",
    "SelectC": "데이터베이스 사용자 자격 증명을 보안 설정된 Amazon S3 버킷에 저장합니다. 필요한 IAM 권한을 부여하여 웹 서버가 자격 증명을 조회하고 DB에 액세스하도록 합니다.",
    "SelectC_Commentary": "S3 버킷을 사용할 경우 자격 증명 자동 회전을 지원하지 않아 수동 관리가 필요하며, 보안 및 운영 측면에서 추가 부담이 생깁니다.",
    "SelectD": "데이터베이스 사용자 자격 증명을 AWS KMS로 암호화된 파일 형태로 웹 서버 파일 시스템에 저장합니다. 웹 서버가 이 파일을 복호화하여 DB에 액세스하도록 합니다.",
    "SelectD_Commentary": "웹 서버 내에 직접 자격 증명을 저장하면 보안 리스크가 높고, 자격 증명 교체 시 운영 절차가 복잡해집니다. 자동 교체도 지원되지 않습니다.",
    "Question_Description_recommedations": [
      "Q121",
      "Q992",
      "Q951",
      "Q330",
      "Q742"
    ],
    "SelectA_recommedations": [
      "Q222",
      "Q780",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q222",
      "Q780",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q44",
      "Q965",
      "Q202"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q916",
      "Q831"
    ]
  },
  {
    "Question_Number": "Q87",
    "Question_Description": "한 회사는 Amazon API Gateway API에 의해 호출되는 AWS Lambda 함수를 사용하여 애플리케이션을 호스팅하고 있습니다. Lambda 함수는 고객 데이터를 Amazon Aurora MySQL 데이터베이스에 저장합니다. 회사가 데이터베이스를 업그레이드할 때마다 업그레이드가 완료될 때까지 Lambda 함수가 데이터베이스 연결을 수립하지 못하게 되어, 이벤트 중 일부 고객 데이터가 기록되지 않는 문제가 발생합니다. 솔루션 아키텍트는 데이터베이스가 업그레이드되는 동안 생성되는 고객 데이터를 저장할 방안을 설계해야 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85319-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터베이스 업그레이드 시점에 데이터베이스 연결이 일시적으로 끊겨 고객 데이터가 손실되는 상황을 방지하고자 하는 요구사항을 다룹니다. 업그레이드 중에도 데이터를 안전하게 저장한 뒤, 데이터베이스가 정상화되면 다시 처리할 수 있는 구조가 핵심입니다. 정답은 Amazon SQS FIFO 큐를 통해 데이터가 유실되지 않고 큐에 보관되도록 하여, 이후 새로운 Lambda 함수가 해당 데이터를 데이터베이스에 정상 반영하도록 하는 방식입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon Aurora MySQL",
      "Database Upgrade",
      "SQS FIFO Queue",
      "고객 데이터 보존"
    ],
    "Terms": [
      "Amazon RDS Proxy",
      "Lambda local storage",
      "Amazon SQS FIFO",
      "Retry mechanism",
      "Aurora MySQL 업그레이드",
      "Amazon RDS",
      "Lambda 함수"
    ],
    "SelectA": "Amazon RDS Proxy를 설정하여 Lambda 함수와 데이터베이스 사이에 두고, Lambda 함수가 RDS Proxy로 연결하도록 구성합니다.",
    "SelectA_Commentary": "RDS Proxy는 데이터베이스 장애나 재시작 시 연결 풀을 관리해 failover 시간을 단축하지만, 업그레이드 중 데이터베이스가 완전히 오프라인이면 여전히 요청이 실패할 수 있어 업그레이드 동안 생성되는 데이터를 보관하는 데에는 한계가 있습니다.",
    "SelectB": "Lambda 함수 실행 시간을 최대로 늘리고, 고객 데이터를 데이터베이스에 저장하는 코드에 재시도 메커니즘을 구현합니다.",
    "SelectB_Commentary": "재시도 로직만으로는 데이터베이스가 업그레이드로 인해 길게 다운되는 상황에서 요청이 계속 실패할 가능성이 높아, 데이터 손실을 완전히 방지하기 어렵습니다.",
    "SelectC": "Lambda local storage에 고객 데이터를 저장합니다. 그리고 새 Lambda 함수를 구성하여 local storage에 저장된 데이터를 데이터베이스에 저장하도록 합니다.",
    "SelectC_Commentary": "Lambda 함수의 local storage는 영구적이지 않고 함수별 격리 영역이 달라서 업그레이드 기간 동안의 데이터를 안정적으로 보관하기 적합하지 않습니다.",
    "SelectD": "Amazon Simple Queue Service(Amazon SQS) FIFO 큐에 고객 데이터를 저장합니다. 새로운 Lambda 함수를 생성하여 큐에서 메시지를 폴링하여 데이터베이스에 저장하도록 합니다.",
    "SelectD_Commentary": "데이터베이스가 업그레이드 중이더라도 SQS가 데이터를 안전하게 보관하고, 데이터베이스가 정상화되면 큐에서 메시지를 읽어 처리할 수 있어 데이터 손실을 방지하고 서비스의 복원력을 높입니다.",
    "Question_Description_recommedations": [
      "Q25",
      "Q207",
      "Q739",
      "Q785",
      "Q10"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q785",
      "Q259"
    ],
    "SelectB_recommedations": [
      "Q187",
      "Q917",
      "Q58"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q48",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q98",
      "Q785",
      "Q636"
    ]
  },
  {
    "Question_Number": "Q88",
    "Question_Description": "한 설문 회사가 미국 지역에서 여러 해 동안 수집한 데이터를 Amazon S3 버킷에 저장하고 있으며, 현재 크기는 3TB이고 계속 증가하고 있습니다. 이 회사는 유럽에 있는 마케팅 회사와 데이터를 공유하기 시작했으며, 마케팅 회사 또한 S3 버킷을 가지고 있습니다. 회사는 자신의 데이터 전송 비용을 최대한 낮게 유지하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85738-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기업이 보유한 S3 데이터를 해외 파트너에게 공유할 때 발생하는 데이터 전송 비용을 최소화하기 위한 방법을 묻습니다. Requester Pays를 사용하면 다운로드 비용을 요청 측(마케팅 회사)으로 전가하여, 데이터 제공 회사(미국 회사) 측의 트래픽 비용을 최소화할 수 있습니다. 다른 옵션들은 회사 측에 각종 전송 및 복제 비용이 발생하거나 단순 스토리지 비용 절감에 머물기 때문에, 문제의 요구사항인 '자사의 전송 비용 최소화' 핵심에 부합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 전송 비용",
      "Amazon S3",
      "Requester Pays",
      "Cross-Region Replication",
      "S3 Intelligent-Tiering"
    ],
    "Terms": [
      "Requester Pays",
      "S3 Cross-Region Replication",
      "Cross-account access",
      "S3 Intelligent-Tiering",
      "Amazon S3 버킷"
    ],
    "SelectA": "회사의 S3 버킷에서 Requester Pays 기능을 구성합니다.",
    "SelectA_Commentary": "Requester Pays 사용 시, 데이터 요청자(마케팅 회사)가 전송 요금을 부담하여 회사의 전송 비용을 최소화할 수 있습니다.",
    "SelectB": "회사의 S3 버킷에서 마케팅 회사의 S3 버킷으로 S3 Cross-Region Replication을 구성합니다.",
    "SelectB_Commentary": "회사 측이 복제 비용과 전송 비용을 부담하므로, 전송 비용 절감 목표에 부합하지 않습니다.",
    "SelectC": "Cross-account access를 구성하여 마케팅 회사가 회사의 S3 버킷에 접근하도록 설정합니다.",
    "SelectC_Commentary": "접근 권한만 부여할 뿐 전송 비용은 여전히 회사가 부담할 가능성이 크므로 요구사항에 맞지 않습니다.",
    "SelectD": "회사의 S3 버킷을 S3 Intelligent-Tiering으로 설정하고, 해당 버킷을 마케팅 회사의 S3 버킷과 동기화합니다.",
    "SelectD_Commentary": "S3 Intelligent-Tiering은 스토리지 비용을 자동 관리하지만, 전송 비용 절감에는 직접적인 도움이 되지 않습니다.",
    "Question_Description_recommedations": [
      "Q469",
      "Q212",
      "Q911",
      "Q829",
      "Q498"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q285",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q285",
      "Q943",
      "Q606"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q829"
    ],
    "SelectD_recommedations": [
      "Q486",
      "Q943",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q89",
    "Question_Description": "한 회사가 Amazon S3를 사용하여 기밀 감사 문서를 저장하고 있습니다. 해당 S3 버킷은 감사 팀 IAM 사용자 자격 증명에 대해 최소 권한 원칙에 따라 접근을 제한하기 위해 버킷 정책을 사용합니다. 회사의 관리자들은 S3 버킷에 있는 문서가 실수로 삭제되는 상황을 우려하며, 더 안전한 솔루션을 원하고 있습니다. 문서를 안전하게 보호하기 위해 Solutions Architect가 해야 할 작업은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85808-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장된 감사 문서를 실수로 삭제하지 않도록 안전하게 보호하는 방법을 묻습니다. 단순히 IAM 사용자에게 MFA를 적용하는 것만으로는 실수로 인한 삭제를 막을 수 없습니다. 대신 Versioning을 활성화하고 MFA Delete를 적용하면 버킷에서 객체를 완전히 삭제하기 전 추가적인 MFA 검증이 필요해, 실수 혹은 권한 남용으로 인한 영구 삭제를 예방할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "기밀 감사 문서",
      "실수로 삭제",
      "S3 버킷 보안",
      "Versioning",
      "MFA Delete"
    ],
    "Terms": [
      "Amazon S3",
      "IAM",
      "Versioning",
      "MFA Delete",
      "Multi-factor authentication(MFA)",
      "S3 Lifecycle policy",
      "s3:DeleteObject",
      "AWS Key Management Service(AWS KMS)"
    ],
    "SelectA": "S3 버킷에서 Versioning과 MFA Delete 기능을 활성화합니다.",
    "SelectA_Commentary": "Versioning과 MFA Delete를 함께 사용하면 객체가 잘못 삭제되더라도 복원이 가능하며, 영구 삭제 전에 추가 MFA 확인이 필요해 보안을 크게 강화합니다.",
    "SelectB": "각 감사 팀 IAM 사용자 계정의 IAM 사용자 자격 증명에 대해 Multi-factor authentication(MFA)을 활성화합니다.",
    "SelectB_Commentary": "사용자 인증 자체에 MFA를 적용하는 것은 유용하나, 객체 삭제시 별도의 MFA 확인을 거치지 않으므로 실수로 인한 영구 삭제를 근본적으로 방지하지 못합니다.",
    "SelectC": "감사 팀 IAM 사용자 계정에 대해 S3 Lifecycle 정책을 추가하여 감사 기간 동안 s3:DeleteObject 작업을 거부하도록 설정합니다.",
    "SelectC_Commentary": "감사 기간에만 삭제를 막는 정책으로, 기간 외에는 실수 삭제가 여전히 가능하고 다른 운영 상 제약이 발생하므로 최적의 솔루션이 아닙니다.",
    "SelectD": "AWS Key Management Service(AWS KMS)를 사용해 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 접근하지 못하도록 제한합니다.",
    "SelectD_Commentary": "데이터 암호화는 기밀성을 높일 수 있으나, 실수로 삭제되는 자체 문제를 해결하지 못하므로 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q26",
      "Q393",
      "Q924",
      "Q294",
      "Q982"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q825",
      "Q106"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q982",
      "Q403",
      "Q477"
    ],
    "SelectD_recommedations": [
      "Q640",
      "Q1009",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q90",
    "Question_Description": "한 회사는 공개적으로 접근 가능한 영화 데이터를 저장하기 위해 SQL database를 사용하고 있습니다. 이 database는 Amazon RDS Single-AZ DB instance에서 실행 중입니다. 매일 불규칙한 간격으로 스크립트가 실행되어 database에 새로 추가된 영화의 개수를 기록합니다. 이 스크립트는 업무 시간 동안 최종 집계 결과를 보고해야 합니다. 회사의 개발팀은 스크립트가 실행되고 있을 때 database 성능이 개발 업무에 충분하지 않다고 판단했습니다. 솔루션스 아키텍트는 이 문제를 해결하는 솔루션을 권장해야 합니다. 가장 낮은 운영 오버헤드로 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85339-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주기적으로 실행되는 스크립트가 읽기 부하를 유발해 개발팀 업무에 영향을 주는 상황입니다. read replica를 사용하면 최소한의 추가 설정으로 성능 저하 문제를 효과적으로 해결할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "SQL database",
      "Amazon RDS Single-AZ DB instance",
      "새로 추가된 영화",
      "개발팀 성능 문제",
      "read replica"
    ],
    "Terms": [
      "Amazon RDS Single-AZ",
      "Multi-AZ deployment",
      "Read Replica",
      "Amazon ElastiCache"
    ],
    "SelectA": "DB instance를 Multi-AZ로 변경합니다.",
    "SelectA_Commentary": "Multi-AZ는 장애 복구나 고가용성에는 좋지만 읽기 부담을 분산시키지 못해 스크립트로 인한 성능 문제는 크게 해소되지 않습니다.",
    "SelectB": "데이터베이스의 read replica를 생성하고 스크립트가 오직 해당 read replica만 조회하도록 구성합니다.",
    "SelectB_Commentary": "스크립트로 인한 읽기 부하를 본 DB에서 분리해 성능 문제를 해결할 수 있으며, 추가 작업이 적어 운영 오버헤드가 낮은 최적의 방법입니다.",
    "SelectC": "개발팀에 매일 말에 데이터베이스 항목들을 수동으로 export하도록 지시합니다.",
    "SelectC_Commentary": "사람이 직접 수행해야 하므로 운영 오버헤드가 높고, 실수 가능성도 있어서 자동화되지 않은 비효율적인 방법입니다.",
    "SelectD": "Amazon ElastiCache를 사용해 스크립트가 자주 실행하는 쿼리 결과를 캐싱합니다.",
    "SelectD_Commentary": "ElastiCache는 반복 조회에 유용하지만, 새로 추가된 영화 수를 매번 조회하는 경우 캐시 이점이 적어 근본적인 해결책이 되기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q95",
      "Q269",
      "Q590",
      "Q776",
      "Q193"
    ],
    "SelectA_recommedations": [
      "Q633",
      "Q481",
      "Q834"
    ],
    "SelectB_recommedations": [
      "Q888",
      "Q158",
      "Q506"
    ],
    "SelectC_recommedations": [
      "Q77",
      "Q888",
      "Q158"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q361",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q91",
    "Question_Description": "한 회사에서 Amazon EC2 인스턴스가 있는 VPC에서 애플리케이션을 운영하고 있습니다. 그중 하나의 애플리케이션에서는 Amazon S3 API를 호출해 객체를 저장하고 읽어야 합니다. 회사의 보안 규정에 따르면 애플리케이션에서 발생하는 어떠한 트래픽도 인터넷을 통과해서는 안 됩니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85667-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내의 EC2 인스턴스에서 S3로의 통신이 인터넷을 거치지 않도록 하는 보안 액세스 설계가 핵심입니다. NAT Gateway나 Internet Gateway 등 외부 연결을 사용하지 않으려면 S3 Gateway Endpoint를 설정하여 프라이빗 네트워크 환경에서 S3에 직접 연결하도록 구성하는 것이 최선의 방법입니다. 이를 통해 EC2 인스턴스 트래픽이 인터넷으로 노출되지 않고 S3 접근이 가능해집니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC",
      "Amazon EC2",
      "Amazon S3",
      "보안 규정",
      "인터넷 통신 제한",
      "S3 Gateway Endpoint"
    ],
    "Terms": [
      "S3 Gateway Endpoint",
      "NAT Gateway",
      "VPC",
      "Amazon EC2",
      "Amazon S3",
      "Private Subnet"
    ],
    "SelectA": "S3 Gateway Endpoint를 구성합니다.",
    "SelectA_Commentary": "S3 Gateway Endpoint를 사용하면 VPC 내에서 인터넷을 통하지 않고 Amazon S3에 안전하게 연결할 수 있습니다. 회사의 보안 규정에도 부합합니다.",
    "SelectB": "Private Subnet에 S3 버킷을 생성합니다.",
    "SelectB_Commentary": "S3는 기본적으로 리전 기반의 글로벌 서비스라 Private Subnet에 직접 버킷을 생성하는 개념이 없습니다. 보안 요구사항도 충족할 수 없습니다.",
    "SelectC": "EC2 인스턴스와 동일한 AWS Region에 S3 버킷을 생성합니다.",
    "SelectC_Commentary": "동일 리전에 버킷을 생성해도 기본적으로 인터넷 경로를 통한 통신이 발생할 수 있어 보안 규정을 만족하지 못합니다.",
    "SelectD": "EC2 인스턴스와 동일 서브넷에 NAT Gateway를 구성합니다.",
    "SelectD_Commentary": "NAT Gateway를 구성하면 인터넷을 통해서 S3와 통신하므로 회사의 ‘인터넷을 거치면 안 된다’는 규정에 어긋납니다.",
    "Question_Description_recommedations": [
      "Q92",
      "Q866",
      "Q980",
      "Q4",
      "Q208"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q875",
      "Q678",
      "Q106"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q480",
      "Q612"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q480",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q92",
    "Question_Description": "한 회사가 민감한 사용자 정보를 Amazon S3 버킷에 저장하고 있습니다. 회사는 VPC 내부에서 동작하는 Amazon EC2 인스턴스 애플리케이션 계층에서 이 버킷에 안전하게 액세스하기를 원합니다. 이를 달성하기 위해 솔루션스 아키텍트가 취해야 하는 단계 조합은 어떤 것인가요? (2개를 고르십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85903-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부 EC2 인스턴스가 Amazon S3 버킷에 직접적이고 안전하게 접근하도록 설계하는 방법입니다. VPC Gateway Endpoint를 사용하면 내부 망을 통해서만 S3와 통신할 수 있어 외부 노출이 줄어듭니다. 또한 Bucket Policy로 특정 VPC 리소스만 접근 가능하도록 제한해 보안을 강화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "민감한 사용자 정보",
      "Amazon S3 버킷",
      "VPC 내부 EC2",
      "안전한 액세스",
      "VPC Gateway Endpoint",
      "Bucket Policy"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2",
      "VPC",
      "VPC Gateway Endpoint",
      "Bucket Policy",
      "NAT instance",
      "IAM user",
      "S3 Access Policy"
    ],
    "SelectA": "VPC 내부에 Amazon S3용 VPC Gateway Endpoint를 구성합니다.",
    "SelectA_Commentary": "VPC Gateway Endpoint를 사용하면 S3 트래픽이 인터넷으로 나가지 않고 내부 경로로만 전송되어 안전성과 성능이 향상됩니다.",
    "SelectB": "S3 버킷의 객체를 공개로 설정하는 Bucket Policy를 생성합니다.",
    "SelectB_Commentary": "버킷을 ‘public’으로 설정하면 민감 데이터가 노출될 위험이 커지므로 안전한 구성에 부적합합니다.",
    "SelectC": "VPC에서 동작하는 애플리케이션 계층에만 액세스를 제한하는 Bucket Policy를 생성합니다.",
    "SelectC_Commentary": "Bucket Policy를 통해 특정 VPC 리소스에서만 접근이 가능하도록 설정하면 민감한 데이터 보호에 효과적입니다.",
    "SelectD": "IAM 사용자와 S3 액세스 정책을 만들고 이 자격 증명을 EC2 인스턴스에 복사합니다.",
    "SelectD_Commentary": "IAM 사용자 자격 증명을 직접 인스턴스에 복사하는 방식은 관리가 어렵고 보안에 취약하므로 모범 사례가 아닙니다.",
    "SelectE": "NAT 인스턴스를 생성하고 EC2 인스턴스가 NAT 인스턴스를 통해 S3 버킷에 액세스하도록 합니다.",
    "SelectE_Commentary": "NAT 인스턴스 사용은 인터넷 게이트웨이를 통한 통신을 전제로 하므로 민감 데이터에 대한 내부 전송 요구사항에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q866",
      "Q91",
      "Q980",
      "Q4",
      "Q612"
    ],
    "SelectA_recommedations": [
      "Q91",
      "Q866",
      "Q92"
    ],
    "SelectB_recommedations": [
      "Q256",
      "Q965",
      "Q216"
    ],
    "SelectC_recommedations": [
      "Q950",
      "Q135",
      "Q15"
    ],
    "SelectD_recommedations": [
      "Q982",
      "Q222",
      "Q403"
    ],
    "SelectE_recommedations": [
      "Q453",
      "Q612",
      "Q17"
    ]
  },
  {
    "Question_Number": "Q93",
    "Question_Description": "회사는 MySQL 데이터베이스로 구동되는 온프레미스 애플리케이션을 운영하고 있습니다. 애플리케이션의 탄력성(elasticity)과 가용성을 높이기 위해 AWS로 마이그레이션하려고 합니다. 현재 아키텍처는 정상 운영 시 데이터베이스에 대한 무거운 읽기 부하가 있습니다. 또한 4시간마다 운영 환경 데이터베이스를 전체 export하여 스테이징 환경에 구성하고 있는데, 이 과정에서 사용자들은 애플리케이션 지연을 겪으며, 개발팀도 export가 끝날 때까지 스테이징 환경을 사용할 수 없습니다. 솔루션스 아키텍트는 이 애플리케이션 지연 문제를 완화하고, 개발팀이 지연 없이 스테이징 환경을 꾸준히 사용할 수 있도록 하는 대체 아키텍처를 제안해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85729-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 MySQL 기반 온프레미스 환경에서 AWS로 이전하여, 데이터베이스 부하와 스테이징 환경 동시 사용 이슈를 해결하려는 상황입니다. Amazon Aurora MySQL의 database cloning을 활용해 큰 부하 없이 스테이징 환경을 구성하고, Multi-AZ Aurora Replicas로 가용성과 성능을 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "온프레미스 MySQL",
      "높은 읽기 부하",
      "4시간마다 전체 export",
      "스테이징 환경",
      "애플리케이션 지연",
      "Amazon Aurora MySQL",
      "Multi-AZ Aurora Replicas",
      "database cloning"
    ],
    "Terms": [
      "Amazon Aurora MySQL",
      "Multi-AZ Aurora Replicas",
      "Amazon RDS for MySQL",
      "read replicas",
      "mysqldump",
      "database cloning",
      "standby instance"
    ],
    "SelectA": "Amazon Aurora MySQL with Multi-AZ Aurora Replicas를 운영 환경으로 사용합니다. mysqldump 유틸리티를 사용하는 백업/복원 프로세스로 스테이징 데이터베이스를 채웁니다.",
    "SelectA_Commentary": "mysqldump 활용 시 운영 DB에 큰 부하가 발생하고, 스테이징 환경 준비에도 시간이 오래 걸려 기존 문제를 해결하기에 충분치 않습니다.",
    "SelectB": "Amazon Aurora MySQL with Multi-AZ Aurora Replicas를 운영 환경으로 사용합니다. database cloning을 적용하여 필요 시 스테이징 데이터베이스를 온디맨드로 생성합니다.",
    "SelectB_Commentary": "Aurora database cloning은 운영 DB를 빠르고 효율적으로 복제해 초기화 시간을 단축하고 부하를 최소화하므로 요구사항을 충족하는 최적의 솔루션입니다.",
    "SelectC": "Amazon RDS for MySQL Multi-AZ 배포와 read replicas를 운영 환경으로 사용합니다. 스탠바이 인스턴스를 스테이징 데이터베이스로 활용합니다.",
    "SelectC_Commentary": "Multi-AZ 스탠바이는 장애 복구용으로 동기화되어 있어 자유로운 스테이징 환경 구성에 제약이 크고, read replica만으로는 완전한 스테이징 구축이 어렵습니다.",
    "SelectD": "Amazon RDS for MySQL Multi-AZ 배포와 read replicas를 운영 환경으로 사용합니다. mysqldump 유틸리티를 사용하는 백업/복원 프로세스로 스테이징 데이터베이스를 구성합니다.",
    "SelectD_Commentary": "mysqldump로 생성·복원 시 운영에 부하가 커 문제 해결에 적합하지 않으며, 스테이징 환경 준비 과정이 지연되므로 요구사항을 만족시키기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q834",
      "Q565",
      "Q229",
      "Q192",
      "Q314"
    ],
    "SelectA_recommedations": [
      "Q946",
      "Q481",
      "Q834"
    ],
    "SelectB_recommedations": [
      "Q481",
      "Q946",
      "Q235"
    ],
    "SelectC_recommedations": [
      "Q247",
      "Q337",
      "Q633"
    ],
    "SelectD_recommedations": [
      "Q247",
      "Q337",
      "Q376"
    ]
  },
  {
    "Question_Number": "Q94",
    "Question_Description": "한 회사에서 사용자가 작은 파일을 Amazon S3에 업로드하는 애플리케이션을 설계하고 있습니다. 사용자가 파일을 업로드하면, 그 파일은 한 번의 간단한 처리를 통해 데이터를 변환하고 이후 분석을 위해 JSON 형식으로 저장되어야 합니다. 파일은 업로드되자마자 가능한 한 빨리 처리되어야 하며, 수요는 날짜에 따라 매우 많이 업로드될 수도 있고 거의 업로드되지 않을 수도 있습니다. 이때 운영 오버헤드를 최소화하면서 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86676-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자의 가변적인 업로드 빈도에 실시간으로 대응하면서 파일을 신속하게 처리하고, 운영상의 복잡함을 최소화하는 아키텍처를 구현하는 방법을 묻습니다. 서버나 클러스터 관리가 필요 없는 서버리스 기반 이벤트 구독 방식(Amazon S3 이벤트 → Amazon SQS → AWS Lambda)이 운영 오버헤드를 크게 줄이고 자동 확장에 유리합니다. 또한 결과를 NoSQL 기반인 Amazon DynamoDB에 JSON 형식으로 저장하면 구조화 과정이 간편하고 확장성도 뛰어납니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "S3 업로드",
      "JSON 변환",
      "단일 처리",
      "가변적인 수요",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EMR",
      "Amazon Aurora",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon EC2",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon Kinesis Data Streams",
      "Amazon DynamoDB"
    ],
    "SelectA": "Amazon EMR을 구성하여 Amazon S3에서 텍스트 파일을 읽고, 스크립트를 실행해 데이터를 변환한 뒤 Amazon Aurora DB cluster에 JSON 파일을 저장합니다.",
    "SelectA_Commentary": "EMR 클러스터 관리와 오케스트레이션이 필요해 운영 오버헤드가 높으며, 간단한 처리를 위해 과도한 솔루션입니다.",
    "SelectB": "Amazon S3 이벤트 알림을 Amazon SQS 큐로 전송합니다. Amazon EC2 인스턴스가 큐를 읽고 데이터를 처리하여 JSON 파일을 Amazon DynamoDB에 저장합니다.",
    "SelectB_Commentary": "EC2 인스턴스 운영 및 스케일링 관리가 필요해 서버리스보다 오버헤드가 큽니다.",
    "SelectC": "Amazon S3 이벤트 알림을 Amazon SQS 큐로 전송합니다. AWS Lambda 함수가 큐에서 메시지를 읽어 데이터를 처리하고, JSON 파일을 Amazon DynamoDB에 저장합니다.",
    "SelectC_Commentary": "서버리스 아키텍처로 자동 확장과 이벤트 기반 처리가 가능하여 운영 오버헤드가 가장 적은 최적 솔루션입니다.",
    "SelectD": "Amazon EventBridge(Amazon CloudWatch Events)를 구성하여 새 파일이 업로드될 때 Amazon Kinesis Data Streams로 이벤트를 전송합니다. AWS Lambda 함수가 스트림 이벤트를 처리하고, Amazon Aurora DB cluster에 JSON 파일을 저장합니다.",
    "SelectD_Commentary": "Kinesis 스트림 설정과 Aurora 관리가 필요해 처리 흐름이 복잡하며, 단순 처리 요구 사항에 비해 과도한 구성입니다.",
    "Question_Description_recommedations": [
      "Q784",
      "Q110",
      "Q1014",
      "Q188",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q490",
      "Q462",
      "Q338"
    ],
    "SelectB_recommedations": [
      "Q768",
      "Q944",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q944",
      "Q354",
      "Q636"
    ],
    "SelectD_recommedations": [
      "Q569",
      "Q354",
      "Q351"
    ]
  },
  {
    "Question_Number": "Q95",
    "Question_Description": "한 회사의 본사 사용자들이 제품 데이터에 액세스할 수 있는 애플리케이션이 있습니다. 이 제품 데이터는 Amazon RDS MySQL DB instance에 저장되어 있습니다. 운영 팀은 애플리케이션 성능 저하 문제를 찾아내었고, 읽기 트래픽과 쓰기 트래픽을 분리하고자 합니다. 솔루션스 아키텍트는 애플리케이션 성능을 빠르게 최적화해야 합니다. 어떤 조치를 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85906-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS 환경에서읽기 트래픽을 효율적으로 분산해 애플리케이션 성능을 빠르게 높이는 방법을 묻습니다. Multi-AZ는 고가용성 목적이므로, Read Replica를 동일 리소스로 구성해 읽기 요청을 분산해야 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS MySQL",
      "애플리케이션 성능",
      "읽기 트래픽",
      "쓰기 트래픽",
      "Read Replica",
      "Multi-AZ"
    ],
    "Terms": [
      "Amazon RDS MySQL",
      "DB instance",
      "Multi-AZ",
      "Read Replica",
      "Primary Availability Zone",
      "Secondary Availability Zone"
    ],
    "SelectA": "기존 데이터베이스를 Multi-AZ 배포로 변경합니다. 읽기 요청은 기본 가용 영역에서 처리합니다.",
    "SelectA_Commentary": "Multi-AZ는 주로 장애 대비용이며, 기본 가용 영역에서 읽기를 처리하면 여전히 트래픽 부담이 높아집니다.",
    "SelectB": "기존 데이터베이스를 Multi-AZ 배포로 변경합니다. 읽기 요청은 보조 가용 영역에서 처리합니다.",
    "SelectB_Commentary": "Multi-AZ 보조 노드는 장애 발생 시에만 활성화되므로, 일반 상황에서 읽기 요청 처리에 적합하지 않습니다.",
    "SelectC": "데이터베이스에 대해 Read Replica를 생성합니다. Read Replica에는 원본 DB의 절반 크기의 컴퓨트와 스토리지 리소스를 구성합니다.",
    "SelectC_Commentary": "읽기 부하 분산은 가능하지만, 리소스가 부족하면 대규모 동시 읽기 요청 처리에 한계가 있습니다.",
    "SelectD": "데이터베이스에 대해 Read Replica를 생성합니다. Read Replica에 원본 DB와 동일한 컴퓨트와 스토리지 리소스를 구성합니다.",
    "SelectD_Commentary": "Read Replica를 충분한 리소스로 구성해 읽기 트래픽을 안정적으로 분산함으로써, 빠르게 성능을 개선할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q590",
      "Q376",
      "Q90",
      "Q386",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q622",
      "Q888",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q622",
      "Q888",
      "Q158"
    ],
    "SelectC_recommedations": [
      "Q243",
      "Q225",
      "Q77"
    ],
    "SelectD_recommedations": [
      "Q243",
      "Q225",
      "Q77"
    ]
  },
  {
    "Question_Number": "Q96",
    "Question_Description": "한 Amazon EC2 관리자가 여러 사용자가 포함된 IAM 그룹에 다음 정책을 연결했습니다. 이 정책에는 특정 리전과 소스 IP 조건이 설정되어 있습니다. 이 정책의 효과는 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86460-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM Policy의 조건(Context Keys) 설정을 통해 EC2 인스턴스 종료 권한을 제한하는 방법을 묻습니다. 정책에서는 us-east-1 리전 내에서, 소스 IP가 10.100.100.254인 경우에만 EC2 인스턴스 종료를 허용하고 다른 리전에서는 종료를 허용하지 않습니다. 따라서 이 정책의 실제 효과를 바르게 파악해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "us-east-1 리전",
      "EC2 인스턴스 종료",
      "소스 IP 주소",
      "IAM 정책"
    ],
    "Terms": [
      "Amazon EC2",
      "IAM 그룹",
      "Policy",
      "소스 IP",
      "us-east-1 Region",
      "TerminateInstance"
    ],
    "SelectA": "사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다.",
    "SelectA_Commentary": "정책 해석과 반대되는 설명입니다. 정책은 오직 us-east-1 리전에서만 종료를 허용합니다.",
    "SelectB": "사용자는 us-east-1 리전에서 IP 주소가 10.100.100.1인 EC2 인스턴스를 종료할 수 있습니다.",
    "SelectB_Commentary": "정책에서 요구하는 소스 IP는 10.100.100.254이며, 10.100.100.1은 조건에 부합하지 않습니다.",
    "SelectC": "사용자의 소스 IP가 10.100.100.254일 때, us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다.",
    "SelectC_Commentary": "정책에서 us-east-1 리전과 소스 IP가 10.100.100.254인 경우에만 종료를 허용하므로, 이 설명이 정확한 정책의 효과입니다.",
    "SelectD": "사용자의 소스 IP가 10.100.100.254일 때, us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다.",
    "SelectD_Commentary": "정책은 소스 IP가 10.100.100.254이고 리전이 us-east-1일 경우에 종료를 허용하므로, 이 설명은 틀립니다.",
    "Question_Description_recommedations": [
      "Q222",
      "Q476",
      "Q780",
      "Q494",
      "Q470"
    ],
    "SelectA_recommedations": [
      "Q480",
      "Q682",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q682",
      "Q893",
      "Q480"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q106",
      "Q678"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q106",
      "Q678"
    ]
  },
  {
    "Question_Number": "Q97",
    "Question_Description": "한 회사는 온프레미스에서 대규모 Microsoft SharePoint를 운영 중이며, Microsoft Windows 공유 파일 스토리지가 필요합니다. 이 워크로드를 AWS Cloud로 마이그레이션하려고 하며, 여러 스토리지 옵션을 검토 중입니다. 스토리지 솔루션은 고가용성을 갖추고, 액세스 제어를 위해 Active Directory와 통합되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86626-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows 기반 워크로드(SharePoint)를 AWS로 마이그레이션하면서, 고가용성이 보장되고 Active Directory를 통한 인증이 필요한 공유 파일 스토리지를 설계하는 방법을 묻습니다. 네이티브 Windows 파일 시스템 통합과 SMB 프로토콜, AD 연동이 필수적이므로, Amazon FSx for Windows File Server가 가장 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Microsoft SharePoint",
      "Microsoft Windows 공유 파일 스토리지",
      "Active Directory",
      "고가용성",
      "Amazon FSx for Windows File Server"
    ],
    "Terms": [
      "Amazon EFS",
      "AWS Storage Gateway",
      "SMB",
      "Amazon S3",
      "Amazon FSx for Windows File Server",
      "Active Directory",
      "고가용성"
    ],
    "SelectA": "Amazon EFS 스토리지를 구성하고 Active Directory 도메인을 인증용으로 설정합니다.",
    "SelectA_Commentary": "Amazon EFS는 Linux 기반 NFS 프로토콜을 주로 사용하므로 Windows 환경 및 SMB 기반 공유에는 최적화되어 있지 않습니다.",
    "SelectB": "두 개의 가용 영역(AZ)에 AWS Storage Gateway 파일 게이트웨이로 SMB 파일 공유를 생성합니다.",
    "SelectB_Commentary": "파일 게이트웨이는 온프레미스와의 하이브리드 환경에 유용하지만, 완전한 AD 통합 및 고가용성 측면에서 FSx보다 부족합니다.",
    "SelectC": "Amazon S3 버킷을 생성하고 Microsoft Windows Server에서 이를 볼륨으로 마운트하도록 구성합니다.",
    "SelectC_Commentary": "Windows 서버에서 S3 버킷을 직접 파일 공유로 쓰기는 제한적이며, 대비해 SMB 및 AD 통합 지원이 부족합니다.",
    "SelectD": "AWS에서 Amazon FSx for Windows File Server 파일 시스템을 생성하고, 인증용으로 Active Directory 도메인을 설정합니다.",
    "SelectD_Commentary": "SMB 프로토콜과 AD 통합을 기본 제공하며, 고가용성을 확보하기 위해 여러 AZ에 데이터를 복제하므로 요구사항을 모두 충족합니다.",
    "Question_Description_recommedations": [
      "Q197",
      "Q843",
      "Q190",
      "Q914",
      "Q1014"
    ],
    "SelectA_recommedations": [
      "Q842",
      "Q194",
      "Q102"
    ],
    "SelectB_recommedations": [
      "Q934",
      "Q10",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q972",
      "Q784"
    ],
    "SelectD_recommedations": [
      "Q54",
      "Q618",
      "Q972"
    ]
  },
  {
    "Question_Number": "Q98",
    "Question_Description": "한 이미지 처리 회사에서는 사용자가 이미지를 업로드할 수 있는 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon S3 버킷에 이미지를 업로드합니다. 회사는 Amazon Simple Queue Service(Amazon SQS) 스탠다드 큐로 객체 생성 이벤트를 게시하기 위해 S3 event notifications을 설정했습니다. 이 SQS 큐는 이미지를 처리하고 처리 결과를 이메일로 사용자에게 전송하는 AWS Lambda 함수의 이벤트 소스로 동작합니다.\n\n사용자들은 업로드된 각 이미지마다 여러 개의 이메일이 도착하고 있다고 보고했습니다. 솔루션스 아키텍트는 SQS 메시지가 Lambda 함수를 여러 번 호출하여 중복 이메일이 발생한다는 사실을 확인했습니다.\n\n가장 적은 운영 오버헤드로 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85185-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SQS 메시지가 Lambda 함수의 처리 시간보다 일찍 다시 큐로 돌아와 중복 처리가 발생하는 상황을 해결하는 방법을 묻습니다. Lambda가 메시지를 정상적으로 처리할 수 있도록 visibility timeout을 충분히 늘리면, 메시지가 재전송되지 않아 중복 메일이 방지됩니다. 이는 운영적인 부담이 적고 가장 직접적인 해결책입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "중복 메시지",
      "Lambda 함수",
      "visibility timeout",
      "이메일 중복",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "S3 event notifications",
      "Amazon Simple Queue Service (Amazon SQS)",
      "SQS standard queue",
      "AWS Lambda",
      "visibility timeout",
      "SQS FIFO queue",
      "long polling",
      "function timeout",
      "batch window timeout",
      "message deduplication ID"
    ],
    "SelectA": "SQS 큐에 long polling을 설정하기 위해 ReceiveMessage 대기 시간을 30초로 늘립니다.",
    "SelectA_Commentary": "long polling은 메시지 수신 빈도를 줄일 뿐, Lambda 처리 시간 초과로 인한 중복 메시지 문제는 근본적으로 해결하지 못합니다.",
    "SelectB": "SQS 스탠다드 큐를 SQS FIFO 큐로 변경합니다. 메시지 deduplication ID를 사용해 중복 메시지를 제거합니다.",
    "SelectB_Commentary": "FIFO 큐로 바꾸면 메시지 순서 및 Deduplication 기능이 있지만, 애플리케이션 구조를 변경해야 하고 스루풋 제한도 있어 운영 오버헤드가 증가할 수 있습니다.",
    "SelectC": "Lambda 함수 타임아웃 및 배치 윈도우 타임아웃의 합보다 큰 값을 SQS 큐의 visibility timeout으로 설정합니다.",
    "SelectC_Commentary": "Lambda가 메시지를 완전히 처리하기 전에 메시지가 다시 큐로 돌아오지 않도록 visibility timeout을 충분히 늘려 한 번만 처리되게 하는 최적의 솔루션입니다.",
    "SelectD": "Lambda 함수가 메시지를 읽자마자 메시지를 처리하기 전에 SQS 큐에서 메시지를 삭제하도록 수정합니다.",
    "SelectD_Commentary": "처리 전에 메시지를 삭제하면 Lambda 함수 오류 발생 시 메시지를 잃을 위험이 큽니다. 신뢰성을 저해하는 좋지 않은 방식입니다.",
    "Question_Description_recommedations": [
      "Q636",
      "Q45",
      "Q148",
      "Q404",
      "Q139"
    ],
    "SelectA_recommedations": [
      "Q845",
      "Q344",
      "Q311"
    ],
    "SelectB_recommedations": [
      "Q843",
      "Q490",
      "Q293"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q404",
      "Q531"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q404",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q99",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에서 호스팅되는 게임 애플리케이션을 위한 공유 스토리지 솔루션을 구현하려고 합니다. 이 회사는 Lustre 클라이언트를 사용하여 데이터를 액세스할 수 있는 기능이 필요하며, 이 솔루션은 완전관리형(Fully Managed)이어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85811-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lustre 클라이언트를 활용해야 하며 완전관리형 서비스가 필수적입니다. FSx for Lustre는 HPC 환경에서 자주 사용되는 Lustre 파일 시스템을 완전관리형으로 제공하므로 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "공유 스토리지",
      "완전관리형",
      "Lustre 클라이언트",
      "온프레미스 데이터 센터",
      "게임 애플리케이션"
    ],
    "Terms": [
      "Amazon FSx for Lustre",
      "Amazon EFS",
      "AWS Storage Gateway",
      "Windows file share role",
      "Lustre",
      "Shared Storage"
    ],
    "SelectA": "AWS Storage Gateway file gateway를 생성하고 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 생성한 후, 해당 애플리케이션 서버를 연결합니다.",
    "SelectA_Commentary": "AWS Storage Gateway는 Lustre 클라이언트를 직접 지원하지 않으므로 요구사항을 충족하지 못합니다.",
    "SelectB": "Amazon EC2 Windows 인스턴스를 생성하고 Windows file share role을 설치·구성합니다. 애플리케이션 서버를 해당 파일 공유에 연결합니다.",
    "SelectB_Commentary": "Windows 기반 파일 공유는 Lustre 프로토콜을 지원하지 않아 요구사항에 부합하지 않습니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하여 Lustre 지원으로 구성한 뒤 원본 서버와 연결하고, 애플리케이션 서버를 파일 시스템에 연결합니다.",
    "SelectC_Commentary": "Amazon EFS는 Lustre 프로토콜을 기본적으로 지원하지 않아 요구사항을 충족하기 어렵습니다.",
    "SelectD": "Amazon FSx for Lustre 파일 시스템을 생성하고 이를 원본 서버에 연결합니다. 애플리케이션 서버를 해당 파일 시스템에 연결합니다.",
    "SelectD_Commentary": "Amazon FSx for Lustre는 Lustre를 완전관리형으로 제공하며 고성능 공유 스토리지를 구현하기에 적합한 정답입니다.",
    "Question_Description_recommedations": [
      "Q622",
      "Q506",
      "Q888",
      "Q915",
      "Q132"
    ],
    "SelectA_recommedations": [
      "Q155",
      "Q361",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q369",
      "Q283"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q407",
      "Q695"
    ],
    "SelectD_recommedations": [
      "Q407",
      "Q99",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q100",
    "Question_Description": "한 회사의 컨테이너화된 애플리케이션이 Amazon EC2 인스턴스에서 실행됩니다. 이 애플리케이션은 다른 비즈니스 애플리케이션과 통신하기 전에 보안 인증서를 다운로드해야 합니다. 회사는 보안 인증서를 실시간에 가깝게 암호화 및 복호화할 수 있는 고도로 안전한 솔루션을 원합니다. 또한 암호화된 후의 데이터를 고가용성 스토리지에 저장해야 하며, 운용상 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 가장 적은 운영 복잡도로 충족할 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85186-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 상에서 실행되는 컨테이너화된 애플리케이션이 보안 인증서를 안전하고 빠르게 다루는 방법을 묻습니다. 실시간에 가까운 암호화·복호화가 필요하며, 암호화된 데이터를 고가용성 스토리지에 저장해야 합니다. 가장 효율적이고 운영 부담이 적은 방식은 AWS KMS를 사용하여 데이터를 암호화하고, Amazon S3와 결합해 보관하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "컨테이너화된 애플리케이션",
      "보안 인증서",
      "암호화",
      "복호화",
      "고가용성 스토리지",
      "운영 오버헤드"
    ],
    "Terms": [
      "AWS Secrets Manager",
      "IAM",
      "AWS Lambda",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key",
      "Amazon EC2",
      "Amazon S3",
      "Amazon EBS"
    ],
    "SelectA": "AWS Secrets Manager에 보안 인증서를 암호화된 형태로 저장하고, 필요할 때 수동으로 인증서를 업데이트합니다. 세분화된 IAM 액세스를 사용하여 데이터에 대한 접근을 제어합니다.",
    "SelectA_Commentary": "Secrets Manager를 통해 인증서 관리를 할 수 있으나, 실시간에 가까운 암호화·복호화가 큰 규모로 요구될 때는 수동 업데이트가 오버헤드를 증가시키고 실시간 처리에 제약이 있을 수 있습니다.",
    "SelectB": "Python cryptography 라이브러리를 사용하는 AWS Lambda 함수를 생성하여 암호화 작업을 수행합니다. 해당 함수를 Amazon S3 버킷에 저장합니다.",
    "SelectB_Commentary": "직접 암호화 라이브러리를 관리하고 Lambda의 배포·버전을 관리해야 하므로 운영 복잡도가 상대적으로 높아집니다. 완전관리형 KMS보다 실시간 처리나 보안 관리 면에서 비효율적일 수 있습니다.",
    "SelectC": "AWS KMS Customer Managed Key를 생성하고, EC2 역할이 이 KMS 키를 암호화 작업에 사용할 수 있도록 허용합니다. 암호화된 데이터를 Amazon S3에 저장합니다.",
    "SelectC_Commentary": "KMS를 통해 안전하고 실시간에 가까운 암호화·복호화를 수행하고, Amazon S3에 저장함으로써 고가용성과 낮은 운영 부담을 동시에 달성할 수 있으므로 가장 적합한 솔루션입니다.",
    "SelectD": "AWS KMS Customer Managed Key를 생성하고, EC2 역할이 이 KMS 키를 암호화 작업에 사용할 수 있도록 허용합니다. 암호화된 데이터를 Amazon EBS 볼륨에 저장합니다.",
    "SelectD_Commentary": "Amazon EBS는 인스턴스 기반 스토리지로, Amazon S3 대비 고가용성이 낮으며 추가적인 백업 및 확장 구성이 필요해 운영 오버헤드가 더 큽니다.",
    "Question_Description_recommedations": [
      "Q315",
      "Q682",
      "Q480",
      "Q329",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q222",
      "Q476",
      "Q780"
    ],
    "SelectB_recommedations": [
      "Q289",
      "Q791",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q681",
      "Q371",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q371",
      "Q681",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q101",
    "Question_Description": "한 솔루션스 아키텍트가 IPv4 CIDR 블록을 사용하는 VPC를 설계하고 있으며, 공용 서브넷과 사설 서브넷을 구성하려고 합니다. 고가용성을 위해 3개의 AZ 각각에 공용 서브넷 1개, 사설 서브넷 1개씩 배치합니다. 공용 서브넷에는 인터넷 게이트웨이를 사용하여 인터넷 접속을 제공합니다. 사설 서브넷은 Amazon EC2 인스턴스에서 소프트웨어 업데이트를 다운로드하기 위해 인터넷에 접근해야 합니다. 사설 서브넷에서 인터넷에 접속하기 위해서는 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86019-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사설 서브넷에서 패치나 업데이트를 위해 외부 인터넷에 접근해야 하는 구조를 어떻게 고가용성으로 구성할지 묻습니다. 가장 모범 사례는 각 AZ의 공용 서브넷에 NAT Gateway를 생성하고, 각 사설 서브넷의 라우팅을 해당 NAT Gateway로 보내는 것입니다. NAT Instance 대신 NAT Gateway를 권장하며, NAT Gateway는 반드시 공용 서브넷에 생성해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "사설 서브넷 인터넷 액세스",
      "공용 서브넷",
      "NAT Gateway",
      "고가용성"
    ],
    "Terms": [
      "NAT Gateway",
      "NAT Instance",
      "Egress-Only Internet Gateway",
      "인터넷 게이트웨이(IGW)",
      "공용 서브넷",
      "사설 서브넷",
      "VPC",
      "Route Table"
    ],
    "SelectA": "각 AZ 내 공용 서브넷에 NAT Gateway를 하나씩 생성하고, 각 AZ에 대한 사설 라우트 테이블을 생성하여 VPC 외부 트래픽을 해당 AZ의 NAT Gateway로 포워딩합니다.",
    "SelectA_Commentary": "NAT Gateway는 공용 서브넷에 위치해야 하며, 사설 라우트 테이블에서 0.0.0.0/0을 NAT Gateway로 라우팅함으로써 사설 서브넷 인스턴스가 인터넷 통신을 안전하고 간단하게 수행할 수 있습니다.",
    "SelectB": "각 AZ 내 사설 서브넷에 NAT Instance를 하나씩 생성하고, 각 AZ에 대한 사설 라우트 테이블을 생성하여 VPC 외부 트래픽을 해당 AZ의 NAT Instance로 포워딩합니다.",
    "SelectB_Commentary": "NAT Instance는 공용 서브넷에 있어야 인터넷 게이트웨이를 통해 외부와 통신할 수 있습니다. 사설 서브넷에 직접 배치하면 인터넷 접근이 불가능하므로 올바르지 않습니다.",
    "SelectC": "사설 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성하고, 사설 서브넷의 라우트 테이블을 변경하여 VPC 외부 트래픽을 새 인터넷 게이트웨이로 포워딩합니다.",
    "SelectC_Commentary": "인터넷 게이트웨이는 VPC 단위로만 연결되며 서브넷마다 별도로 설치할 수 없습니다. 게다가 한 VPC에는 한 개의 인터넷 게이트웨이만 연결 가능합니다.",
    "SelectD": "공용 서브넷 중 하나에 Egress-Only Internet Gateway를 생성하고, 사설 서브넷의 라우트 테이블을 변경하여 VPC 외부 트래픽을 Egress-Only Internet Gateway로 포워딩합니다.",
    "SelectD_Commentary": "Egress-Only Internet Gateway는 IPv6 전용 트래픽에 사용되므로, IPv4 기반 사설 서브넷의 인터넷 다운로드 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q439",
      "Q296",
      "Q504",
      "Q729",
      "Q570"
    ],
    "SelectA_recommedations": [
      "Q708",
      "Q230",
      "Q487"
    ],
    "SelectB_recommedations": [
      "Q230",
      "Q758",
      "Q101"
    ],
    "SelectC_recommedations": [
      "Q58",
      "Q917",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q439",
      "Q708",
      "Q487"
    ]
  },
  {
    "Question_Number": "Q102",
    "Question_Description": "한 회사가 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 해당 데이터 센터에는 SFTP 서버가 있으며, 이 서버는 NFS 기반 파일 시스템에 데이터를 저장하고 있습니다. 현재 서버에는 전송해야 할 데이터가 200GB 있습니다. 이 서버는 Amazon EFS 파일 시스템을 사용하는 Amazon EC2 인스턴스에서 호스팅되어야 합니다. 이 작업을 자동화하기 위해 솔루션스 아키텍트는 어떤 단계 조합을 수행해야 합니까? (2개를 선택하십시오.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85814-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 SFTP 서버의 데이터를 Amazon EFS로 자동 전송하는 방안을 묻습니다. AWS DataSync agent를 온프레미스에 설치한 뒤, SFTP 서버 위치를 DataSync로 설정해 자동화 전송을 구현하는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "온프레미스 데이터 센터 마이그레이션",
      "SFTP 서버",
      "NFS 기반 파일 시스템",
      "Amazon EC2 인스턴스",
      "Amazon EFS",
      "AWS DataSync"
    ],
    "Terms": [
      "SFTP server",
      "NFS-based file system",
      "Amazon EC2",
      "Amazon EFS",
      "AWS DataSync",
      "DataSync agent",
      "Amazon EBS"
    ],
    "SelectA": "EC2 인스턴스를 EFS 파일 시스템과 동일한 Availability Zone에 Launch합니다.",
    "SelectA_Commentary": "EFS는 여러 AZ에 걸쳐 사용할 수 있어 같은 AZ에 EC2를 배치할 필요가 없으며, 자동화 전송과 직접적인 연관성이 적습니다.",
    "SelectB": "온프레미스 데이터 센터에 AWS DataSync agent를 설치합니다.",
    "SelectB_Commentary": "자동화된 데이터 전송을 위해서는 온프레미스측에 DataSync agent가 필요하며, 이를 통해 대량 데이터를 안전하게 AWS로 이동할 수 있습니다.",
    "SelectC": "EC2 인스턴스에 데이터를 저장할 보조 Amazon EBS 볼륨을 생성합니다.",
    "SelectC_Commentary": "Amazon EFS를 이미 사용할 예정이므로, 추가적인 EBS 볼륨은 필요 없으며 자동화 전송과도 직접 연관이 없습니다.",
    "SelectD": "수동으로 운영체제 copy 명령어를 사용해 데이터를 EC2 인스턴스로 전송합니다.",
    "SelectD_Commentary": "수동 복사는 자동화되지 않고, 대규모 데이터 이전에 비효율적이므로 문제 요구사항에 부합하지 않습니다.",
    "SelectE": "AWS DataSync를 사용해 온프레미스 SFTP 서버에 대한 적절한 location 구성을 생성합니다.",
    "SelectE_Commentary": "SFTP 서버에서 EFS로 자동으로 데이터를 이동하려면 DataSync location 구성이 필수이므로, 이는 자동화 전송을 위한 핵심 단계입니다.",
    "Question_Description_recommedations": [
      "Q753",
      "Q892",
      "Q842",
      "Q934",
      "Q188"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q570"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q194",
      "Q843"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q584",
      "Q757"
    ],
    "SelectD_recommedations": [
      "Q584",
      "Q194",
      "Q757"
    ],
    "SelectE_recommedations": [
      "Q188",
      "Q753",
      "Q621"
    ]
  },
  {
    "Question_Number": "Q103",
    "Question_Description": "한 회사가 매일 같은 시간에 실행되는 AWS Glue ETL 작업을 보유하고 있습니다. 이 작업은 Amazon S3 버킷에 저장된 XML 데이터를 처리합니다. 매일 새 데이터가 S3 버킷에 추가되지만, 솔루션스 아키텍트는 AWS Glue가 매번 모든 데이터를 다시 처리하고 있음을 발견했습니다. 이전에 처리된 데이터를 재처리하지 않도록 하려면 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85781-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AWS Glue Job Bookmark 기능을 사용하면 이전 실행에서 처리한 데이터를 기록해 반복 처리를 방지할 수 있습니다. 이를 적용하면 매일 추가되는 새로운 데이터만 효율적으로 처리할 수 있어 불필요한 리소스 사용과 시간을 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "AWS Glue",
      "ETL 작업",
      "XML 데이터",
      "S3 버킷",
      "재처리 방지",
      "job bookmark"
    ],
    "Terms": [
      "AWS Glue",
      "Amazon S3",
      "ETL",
      "Job Bookmark",
      "FindMatches",
      "NumberOfWorkers",
      "XML Data"
    ],
    "SelectA": "Edit the job to use job bookmarks.",
    "SelectA_Commentary": "Job Bookmark을 사용하면 이전에 처리된 데이터를 건너뛰고 새로 추가된 데이터만 처리할 수 있어 효율적입니다.",
    "SelectB": "Edit the job to delete data after the data is processed.",
    "SelectB_Commentary": "데이터 삭제는 재처리를 방지할 수 있지만, 보관 및 분석 목적으로 기존 데이터가 필요할 수 있어 권장되지 않습니다.",
    "SelectC": "Edit the job by setting the NumberOfWorkers field to 1.",
    "SelectC_Commentary": "작업자 수를 변경해도 이전 데이터 재처리를 막지는 못합니다. 성능 조정과 관련됩니다.",
    "SelectD": "Use a FindMatches machine learning (ML) transform.",
    "SelectD_Commentary": "FindMatches는 유사 레코드를 식별하는 용도로, 이전 데이터 재처리 방지와는 직접적으로 관련이 없습니다.",
    "Question_Description_recommedations": [
      "Q155",
      "Q292",
      "Q173",
      "Q680",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q158",
      "Q77",
      "Q888"
    ],
    "SelectB_recommedations": [
      "Q414",
      "Q2",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q352",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q77",
      "Q158",
      "Q493"
    ]
  },
  {
    "Question_Number": "Q104",
    "Question_Description": "한 솔루션스 아키텍트가 웹사이트의 고가용성 인프라를 설계해야 합니다. 이 웹사이트는 Amazon EC2 인스턴스에서 동작하는 Windows 웹 서버에 의해 제공됩니다. 솔루션스 아키텍트는 수천 개의 IP 주소에서 발생하는 대규모 DDoS 공격을 완화할 수 있는 솔루션을 구현해야 합니다. 웹사이트에 다운타임이 발생하면 안 됩니다. 이러한 공격으로부터 웹사이트를 보호하기 위해 어떤 조치를 취해야 합니까? (2개를 선택하십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85342-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 DDoS 공격으로부터 웹사이트를 보호해야 하며, 다운타임이 허용되지 않는 상황을 다룹니다. AWS Shield Advanced는 L3/L4를 포함한 다양한 계층에서의 보호를 제공하며, Amazon CloudFront는 트래픽을 분산시켜 공격 규모를 줄입니다. 보안 관점에서 효율적인 방어와 동시에 고가용성을 유지하려면 이 두 가지를 함께 활용하는 전략이 최적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "고가용성 웹사이트",
      "대규모 DDoS 공격",
      "AWS Shield Advanced",
      "Amazon CloudFront",
      "Downtime 방지"
    ],
    "Terms": [
      "AWS Shield Advanced",
      "Amazon GuardDuty",
      "Amazon CloudFront",
      "AWS Lambda",
      "VPC Network ACL",
      "EC2 Spot Instances",
      "Auto Scaling",
      "Target Tracking Scaling Policy"
    ],
    "SelectA": "AWS Shield Advanced를 사용하여 DDoS 공격을 중단합니다.",
    "SelectA_Commentary": "AWS Shield Advanced는 대규모 DDoS 공격 방어에 최적화된 서비스이며, 고급 모니터링과 자동 완화 기능을 제공합니다. 다운타임 방지에 매우 효과적입니다.",
    "SelectB": "Amazon GuardDuty를 구성하여 공격자를 자동으로 차단합니다.",
    "SelectB_Commentary": "Amazon GuardDuty는 위협 탐지 서비스로, 공격 발생 사실을 알려주지만 직접적으로 DDoS 트래픽을 차단하지는 않습니다. 완전한 방어책에 적합하지 않습니다.",
    "SelectC": "웹사이트를 정적 및 동적 콘텐츠 모두 Amazon CloudFront를 통해 제공하도록 구성합니다.",
    "SelectC_Commentary": "Amazon CloudFront는 엣지 로케이션을 통해 전 세계 트래픽을 분산시켜 공격을 완화하고, 지연 시간을 줄여 고가용성을 유지하는 데 도움이 됩니다.",
    "SelectD": "AWS Lambda 함수를 사용하여 공격자 IP 주소를 자동으로 VPC Network ACL에 추가합니다.",
    "SelectD_Commentary": "일시적으로는 도움이 되지만 공격 IP가 수천 개에 달할 수 있어 관리 복잡성이 증가합니다. 대규모 공격에 즉각적으로 대응하기엔 한계가 있습니다.",
    "SelectE": "EC2 Spot Instances를 Auto Scaling group에서 CPU 사용률 80%로 목표 추적 확장 정책과 함께 사용합니다.",
    "SelectE_Commentary": "확장 정책은 트래픽 급증 시 임시적으로 대응할 수는 있지만, 근본적인 DDoS 방어책이 아니며 Spot 특성상 인스턴스가 회수될 위험도 있습니다.",
    "Question_Description_recommedations": [
      "Q315",
      "Q100",
      "Q682",
      "Q480",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q396",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q538",
      "Q172",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q839",
      "Q231",
      "Q950"
    ],
    "SelectE_recommedations": [
      "Q655",
      "Q614",
      "Q682"
    ]
  },
  {
    "Question_Number": "Q105",
    "Question_Description": "한 회사가 새로운 서버리스 워크로드를 배포할 준비를 하고 있습니다. Solutions Architect는 AWS Lambda function을 실행할 최소 권한 원칙(Principle of Least Privilege)을 준수하도록 권한을 설정해야 합니다. Amazon EventBridge(Amazon CloudWatch Events) 규칙이 이 함수를 호출합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85816-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EventBridge가 AWS Lambda 함수를 호출할 때 필요한 권한 설정을 최소 권한 원칙에 맞춰 구성하는 방법을 묻습니다. EventBridge가 함수를 직접 호출하려면 함수에 Resource-based policy를 부여하여 events.amazonaws.com에 lambda:InvokeFunction 액션만 허용하면 됩니다. 이는 Role보다 직접적인 방식으로 외부 서비스가 함수를 호출할 수 있도록 허용하며, 필요 이상으로 광범위한 권한을 부여하지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Lambda",
      "EventBridge",
      "최소 권한 원칙",
      "Resource-based policy"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "lambda:InvokeFunction",
      "Service: events.amazonaws.com",
      "Resource-based policy",
      "Execution role",
      "Least Privilege"
    ],
    "SelectA": "함수에 실행 역할을 추가하고, 작업을 lambda:InvokeFunction, Principal을 * 로 설정합니다.",
    "SelectA_Commentary": "Principal 값이 * 로 설정되면 누구나 함수 호출이 가능해져 최소 권한 원칙을 위배하므로 적절하지 않습니다.",
    "SelectB": "함수에 실행 역할을 추가하고, 작업을 lambda:InvokeFunction, Principal을 Service: lambda.amazonaws.com 로 설정합니다.",
    "SelectB_Commentary": "lambda.amazonaws.com은 Lambda 자체 서비스에 대한 Principal입니다. EventBridge가 함수를 호출하려면 events.amazonaws.com에 대한 권한이 필요합니다.",
    "SelectC": "함수에 Resource-based policy를 추가하고, 작업을 lambda:* 로, Principal을 Service: events.amazonaws.com 로 설정합니다.",
    "SelectC_Commentary": "lambda:* 는 InvokeFunction 이상의 권한을 포함할 수 있어 최소 권한 원칙에 맞지 않습니다.",
    "SelectD": "함수에 Resource-based policy를 추가하고, 작업을 lambda:InvokeFunction, Principal을 Service: events.amazonaws.com 로 설정합니다.",
    "SelectD_Commentary": "EventBridge 이벤트가 함수를 호출하기 위해 필요한 정확한 액션(lambda:InvokeFunction)과 Principal(events.amazonaws.com)만 허용하므로 최소 권한 원칙을 준수합니다.",
    "Question_Description_recommedations": [
      "Q913",
      "Q387",
      "Q82",
      "Q393",
      "Q924"
    ],
    "SelectA_recommedations": [
      "Q791",
      "Q936",
      "Q34"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q936",
      "Q34"
    ],
    "SelectC_recommedations": [
      "Q791",
      "Q913",
      "Q105"
    ],
    "SelectD_recommedations": [
      "Q791",
      "Q913",
      "Q105"
    ]
  },
  {
    "Question_Number": "Q106",
    "Question_Description": "한 회사가 기밀 데이터를 Amazon S3에 저장하려고 합니다. 컴플라이언스 요건상 데이터는 저장 시점에서 암호화되어야 하며, 암호화 키 사용 내역이 감사 목적으로 로깅되어야 합니다. 또한 키는 매년 교체(회전)되어야 합니다. 이 요구 사항을 충족하며 운영 효율성이 가장 높은 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85817-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장되는 기밀 정보를 암호화하고, 키 사용 이력을 로깅하며, 매년 키를 교체해야 하는 요구 사항을 만족해야 합니다. SSE-KMS 자동 키 회전은 로깅과 연간 회전을 자동화해 운영 부담을 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "기밀 데이터",
      "암호화",
      "키 사용 로깅",
      "연간 키 회전",
      "SSE-KMS",
      "자동 키 교체"
    ],
    "Terms": [
      "Server-side encryption",
      "SSE-C",
      "SSE-S3",
      "SSE-KMS",
      "AWS KMS",
      "Key Rotation",
      "자동 키 회전",
      "Manual Rotation"
    ],
    "SelectA": "고객 제공 키를 사용한 서버 측 암호화 (SSE-C)",
    "SelectA_Commentary": "고객이 직접 키를 관리해야 하며, 연간 회전과 로깅도 직접 처리해야 합니다. 운영 효율성이 떨어집니다.",
    "SelectB": "Amazon S3 관리 키를 사용한 서버측 암호화 (SSE-S3)",
    "SelectB_Commentary": "S3가 자체 관리하는 키지만, 키 사용 로깅과 연간 키 교체 제어가 제한적이라 감사 요건 충족이 어렵습니다.",
    "SelectC": "수동 로테이션을 포함한 AWS KMS keys를 사용한 서버측 암호화 (SSE-KMS)",
    "SelectC_Commentary": "AWS KMS로 키 사용을 로깅할 수 있지만, 키 회전을 사람이 직접 수행해야 하므로 운영 비용이 증가합니다.",
    "SelectD": "자동 로테이션을 포함한 AWS KMS keys를 사용한 서버측 암호화 (SSE-KMS)",
    "SelectD_Commentary": "키 사용 로깅이 자동으로 제공되고, 연간 키 회전도 자동화되어 운영 복잡도를 최소화하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q678",
      "Q44",
      "Q825",
      "Q154",
      "Q925"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q57"
    ],
    "SelectB_recommedations": [
      "Q321",
      "Q453",
      "Q202"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q107",
    "Question_Description": "한 자전거 공유 회사가 피크 시간대에 자전거 위치를 추적하기 위한 멀티 계층 아키텍처를 개발하고 있습니다. 회사는 이 위치 데이터 포인트를 기존 애널리틱스 플랫폼에서 활용하려고 합니다. 솔루션스 아키텍트는 이 아키텍처를 지원하기 위한 가장 적합한 멀티 계층 방안을 결정해야 합니다. 위치 데이터 포인트는 REST API를 통해 액세스 가능해야 합니다. 이러한 요구사항을 충족하기 위해 위치 데이터를 저장하고 조회하기 위한 방법은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 REST API를 통해 빠르게 위치 데이터를 수집하고, 기존 분석 플랫폼에서 활용하기 위한 멀티 계층 아키텍처를 구성하는 방법을 묻습니다. 빠른 호출과 간단한 연동이 가능한 Amazon API Gateway와 AWS Lambda를 사용하는 것이 핵심 포인트입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "자전거 위치 추적",
      "멀티 계층 아키텍처",
      "피크 시간대",
      "기존 애널리틱스 플랫폼",
      "REST API",
      "위치 데이터"
    ],
    "Terms": [
      "Amazon Athena",
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon QuickSight",
      "Amazon Redshift",
      "Amazon Kinesis Data Analytics",
      "REST API"
    ],
    "SelectA": "Amazon Athena와 Amazon S3를 사용합니다.",
    "SelectA_Commentary": "단순 스토리지와 쿼리 서비스로 REST API 접근을 제공하기 어렵습니다. 저장은 가능하나 실시간 처리나 API 호출과의 연계가 부족합니다.",
    "SelectB": "Amazon API Gateway와 AWS Lambda를 사용합니다.",
    "SelectB_Commentary": "REST API 엔드포인트와 Lambda 함수를 통해 실시간으로 위치 데이터를 수집하고 빠르게 분석 플랫폼으로 전달할 수 있는 가장 적합한 솔루션입니다.",
    "SelectC": "Amazon QuickSight와 Amazon Redshift를 사용합니다.",
    "SelectC_Commentary": "분석 및 시각화 용도로 적합하지만, 실시간 REST API 접근성을 위한 멀티 계층 아키텍처로 사용하기에는 제한적입니다.",
    "SelectD": "Amazon API Gateway와 Amazon Kinesis Data Analytics를 사용합니다.",
    "SelectD_Commentary": "Kinesis Data Analytics는 스트리밍 데이터 분석을 위한 서비스이지만, 기존 플랫폼에 데이터를 즉시 연결하는 데는 과도하며 필요 이상으로 복잡합니다.",
    "Question_Description_recommedations": [
      "Q516",
      "Q77",
      "Q2",
      "Q568",
      "Q915"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q361",
      "Q557"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q515",
      "Q576"
    ]
  },
  {
    "Question_Number": "Q108",
    "Question_Description": "한 회사가 자동차 판매 웹사이트를 운영하며, Amazon RDS에 데이터베이스를 두고 자동차 매물 정보를 저장하고 있습니다. 어떤 자동차가 판매되면 이 매물은 웹사이트에서 제거되어야 하며, 해당 데이터는 여러 대상 시스템으로 전송되어야 합니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 어떤 설계를 추천해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85427-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS 데이터를 다른 여러 시스템으로 동시에 전달해야 하며, RDS 자체 이벤트로는 데이터 업데이트를 감지할 수 없다는 점이 핵심입니다. 따라서 Lambda 함수를 통해 DB 변경 시점을 애플리케이션 계층에서 감지하고 SQS를 이용해 비동기적으로 여러 목표 시스템에 데이터를 전송하는 방식이 적절합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "자동차 판매 웹사이트",
      "매물 삭제",
      "다중 대상 시스템 전송",
      "데이터베이스 업데이트",
      "Amazon RDS"
    ],
    "Terms": [
      "Amazon RDS",
      "AWS Lambda",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "RDS event notification",
      "FIFO queue",
      "fanout"
    ],
    "SelectA": "데이터베이스(Amazon RDS)가 업데이트될 때 트리거되는 AWS Lambda 함수를 만들어, 해당 정보를 Amazon Simple Queue Service(Amazon SQS) 큐에 전송하여 대상들이 소비하도록 구성합니다.",
    "SelectA_Commentary": "DB 업데이트 시 직접 Lambda를 호출하여 SQS에 메시지를 전달하면, 여러 시스템에 비동기적으로 분산할 수 있어 확장성과 작업 분리를 모두 달성할 수 있으므로 올바른 솔루션입니다.",
    "SelectB": "데이터베이스(Amazon RDS)가 업데이트될 때 트리거되는 AWS Lambda 함수를 만들어, Amazon Simple Queue Service(Amazon SQS) FIFO 큐에 정보를 전송하여 대상들이 소비하도록 구성합니다.",
    "SelectB_Commentary": "FIFO 큐가 필요한 순서 보장이 요구되지 않으며, 단순한 이벤트 전파에 불필요한 과도한 기능으로 오히려 처리량과 확장성에 제약이 생길 수 있으므로 적합하지 않습니다.",
    "SelectC": "RDS 이벤트 알림에 가입하고 Amazon Simple Queue Service(Amazon SQS) 큐를 여러 Amazon Simple Notification Service(Amazon SNS) 토픽으로 퍼나르게 구성합니다. 그 후 AWS Lambda 함수를 사용하여 대상들을 업데이트합니다.",
    "SelectC_Commentary": "RDS 이벤트 알림은 데이터 자체 변경(INSERT, UPDATE, DELETE)을 지원하지 않아 이를 활용한 팬아웃 구조는 의미가 없어 요구사항을 충족하지 못합니다.",
    "SelectD": "RDS 이벤트 알림에 가입하고 Amazon Simple Notification Service(Amazon SNS) 토픽을 여러 Amazon Simple Queue Service(Amazon SQS) 큐로 퍼나르게 구성합니다. 그 후 AWS Lambda 함수를 사용하여 대상들을 업데이트합니다.",
    "SelectD_Commentary": "마찬가지로 RDS 이벤트 알림에서 DB 내부 데이터 변경 이벤트를 제공하지 않으므로, SNS와 SQS를 통한 팬아웃이 구현되지 않아 목적을 달성할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q863",
      "Q259",
      "Q629",
      "Q195",
      "Q228"
    ],
    "SelectA_recommedations": [
      "Q67",
      "Q518",
      "Q259"
    ],
    "SelectB_recommedations": [
      "Q67",
      "Q944",
      "Q354"
    ],
    "SelectC_recommedations": [
      "Q67",
      "Q518",
      "Q125"
    ],
    "SelectD_recommedations": [
      "Q67",
      "Q518",
      "Q108"
    ]
  },
  {
    "Question_Number": "Q109",
    "Question_Description": "한 회사가 Amazon S3에 데이터를 저장해야 하며, 데이터가 변경되지 않도록 해야 합니다. 회사는 Amazon S3에 업로드되는 새 객체가 회사가 객체를 수정하기로 결정할 때까지 불특정 기간 변경 불가능하게 유지되길 원합니다. 또한 회사의 AWS 계정에서 오직 특정 사용자만 해당 객체를 삭제할 수 있도록 해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85634-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 업로드된 객체가 회사가 의도하기 전까지 수정·삭제되지 않도록 설정하는 방법을 묻습니다. S3 Object Lock의 Legal hold는 만료 기간 없이 객체를 잠그고, 특정 권한을 가진 사용자만 해제할 수 있어 요구 사항에 부합합니다. 버저닝과 함께 사용하면 기존 객체가 변경되더라도 이전 버전을 보존할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "S3 Object Lock",
      "불특정 기간 변경 불가",
      "Legal hold",
      "특정 사용자 삭제 권한",
      "Versioning"
    ],
    "Terms": [
      "S3 Glacier vault",
      "WORM (Write-Once, Read-Many) vault lock policy",
      "S3 Object Lock",
      "Versioning",
      "Retention period",
      "Governance mode",
      "Legal hold",
      "AWS CloudTrail",
      "s3:PutObjectLegalHold",
      "IAM policy"
    ],
    "SelectA": "S3 Glacier vault를 생성하고 WORM vault lock policy를 적용합니다.",
    "SelectA_Commentary": "Vault lock 정책은 확대 적용되며, 특정 사용자만 삭제 권한을 갖도록 세분화하기가 용이하지 않습니다.",
    "SelectB": "S3 Object Lock을 활성화한 S3 버킷과 100년 보존기간을 설정하고 governance mode로 기본 모드를 설정합니다.",
    "SelectB_Commentary": "명확히 정해진 보존 기간(100년)이 필요하므로, 불특정 기간 보존 요구사항에는 맞지 않습니다.",
    "SelectC": "S3 버킷을 생성하고, AWS CloudTrail로 모든 S3 API 이벤트를 추적한 뒤 변경 사실이 있으면 백업에서 복원합니다.",
    "SelectC_Commentary": "변경 발생 후 복원 방식이므로 객체가 아예 변경되지 않도록 막는 요구사항과 맞지 않습니다.",
    "SelectD": "S3 Object Lock을 활성화한 S3 버킷을 생성하고, 버저닝을 활성화한 뒤 객체에 legal hold를 추가합니다. s3:PutObjectLegalHold IAM 권한을 부여받은 사용자만 해당 객체를 삭제할 수 있게 합니다.",
    "SelectD_Commentary": "Legal hold는 별도 기간 없이 객체를 잠글 수 있으며 특정 IAM 권한을 통해서만 해제가 가능하므로 요구사항을 충족하는 가장 적합한 옵션입니다.",
    "Question_Description_recommedations": [
      "Q412",
      "Q270",
      "Q638",
      "Q202",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q202",
      "Q270",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q942",
      "Q862",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q270",
      "Q982",
      "Q412"
    ]
  },
  {
    "Question_Number": "Q110",
    "Question_Description": "한 소셜 미디어 회사는 사용자가 웹사이트에 이미지를 업로드하도록 허용합니다. 웹사이트는 Amazon EC2 인스턴스에서 동작합니다. 업로드 요청 중 웹사이트는 이미지를 표준 크기로 리사이즈한 뒤 Amazon S3에 저장합니다. 현재 사용자들은 업로드 요청이 느리다고 호소하고 있습니다. 회사는 애플리케이션 내 결합도를 낮추고 웹사이트 성능을 향상해야 합니다. 솔루션스 아키텍트는 이미지 업로드 과정을 가장 운영 효율적으로 설계해야 합니다. 이 요구사항을 충족하기 위해 필요한 조치의 조합은 무엇입니까? (두 개를 선택하세요.)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86471-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이미지 업로드 시 동기적 리사이즈로 인해 웹 서버에 부하가 집중되고, 이 과정이 애플리케이션과 강하게 결합되어 있어 성능이 저하되는 상황입니다. Pre-Signed URL을 통해 브라우저가 직접 Amazon S3로 이미지를 업로드하도록 분산하면 웹 서버의 부담이 크게 감소합니다. 이후 S3 Event Notifications를 사용해 AWS Lambda 함수로 비동기 이미지 리사이즈를 수행하면 애플리케이션의 결합도가 낮아지고, 업로드 성능과 확장성을 효과적으로 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이미지 업로드",
      "웹사이트 성능",
      "느슨한 결합",
      "Amazon S3",
      "AWS Lambda"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "S3 Glacier",
      "AWS Lambda",
      "S3 Event Notifications",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Pre-Signed URL"
    ],
    "SelectA": "애플리케이션이 이미지를 S3 Glacier로 업로드하도록 설정합니다.",
    "SelectA_Commentary": "S3 Glacier는 장기 보관용 스토리지 클래스로, 업로드 시점에 쓰기에는 부적합하며 실시간 접근성과 성능 개선에도 도움이 되지 않습니다.",
    "SelectB": "웹 서버가 원본 이미지를 Amazon S3로 업로드하도록 설정합니다.",
    "SelectB_Commentary": "웹 서버에서 직접 업로드하면 일부 개선은 가능하지만, 여전히 웹 서버가 관여하여 결합을 완전히 해소하지 못하고 부하가 남아있습니다.",
    "SelectC": "Pre-Signed URL을 사용하여 각 사용자의 브라우저에서 Amazon S3로 직접 이미지를 업로드하도록 애플리케이션을 설정합니다.",
    "SelectC_Commentary": "정답. 이렇게 하면 웹 서버의 중간 처리 없이 브라우저가 직접 업로드하여 결합을 줄이고 웹 서버 부하를 크게 낮출 수 있습니다.",
    "SelectD": "이미지가 업로드될 때 AWS Lambda 함수를 호출하도록 S3 Event Notifications를 구성하고, 해당 함수에서 이미지를 리사이즈합니다.",
    "SelectD_Commentary": "정답. 업로드 후 비동기적으로 이미지를 리사이즈하므로, 웹 서버 성능을 개선하고 애플리케이션 결합도를 줄이는 효과가 있습니다.",
    "SelectE": "Amazon EventBridge (Amazon CloudWatch Events) 룰을 만들어 일정에 따라 AWS Lambda 함수를 호출하여 업로드된 이미지를 리사이즈합니다.",
    "SelectE_Commentary": "스케줄 기반 처리는 실시간으로 이미지를 리사이즈하기 어려워 사용자의 즉각적 경험을 만족시키기 어렵고, 진정한 애플리케이션 결합 해소에도 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q252",
      "Q584",
      "Q757",
      "Q413",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q7",
      "Q967"
    ],
    "SelectB_recommedations": [
      "Q784",
      "Q8",
      "Q110"
    ],
    "SelectC_recommedations": [
      "Q784",
      "Q94",
      "Q188"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q98",
      "Q404"
    ],
    "SelectE_recommedations": [
      "Q569",
      "Q531",
      "Q785"
    ]
  },
  {
    "Question_Number": "Q111",
    "Question_Description": "한 회사가 최근 메시지 처리 시스템을 AWS로 마이그레이션했습니다. 이 시스템은 Amazon EC2에서 실행되는 ActiveMQ 큐를 통해 메시지를 수신하고, Amazon EC2에서 실행되는 consumer 애플리케이션이 메시지를 처리하여 Amazon EC2에서 구동되는 MySQL 데이터베이스에 결과를 기록합니다. 회사는 낮은 운영 복잡도로 높은 가용성을 달성하기를 원합니다. 다음 중 가장 높은 가용성을 제공하는 아키텍처는 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 메시지 큐, 애플리케이션, 데이터베이스를 모두 이중화하거나 관리형 서비스를 사용하여 운영 복잡도를 줄이면서 고가용성을 달성하는 방법을 묻습니다. 관리형 Amazon MQ, Auto Scaling group, 그리고 Amazon RDS for MySQL Multi-AZ로 구성된 D안이 가장 높은 가용성을 보장합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "메시지 처리",
      "가용성",
      "운영 복잡도",
      "Multi-AZ",
      "Auto Scaling group"
    ],
    "Terms": [
      "Amazon EC2",
      "ActiveMQ",
      "consumer 애플리케이션",
      "Amazon MQ",
      "active/standby brokers",
      "MySQL",
      "Amazon RDS for MySQL",
      "Multi-AZ",
      "Auto Scaling group"
    ],
    "SelectA": "ActiveMQ 서버를 추가로 다른 Availability Zone에 배포하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 두며, MySQL 데이터베이스를 다른 Availability Zone으로 복제합니다.",
    "SelectA_Commentary": "직접 ActiveMQ와 MySQL 복제를 구성해야 하므로 관리 오버헤드가 크고, RDS Multi-AZ 활용이 없어 고가용성 수준이 떨어집니다.",
    "SelectB": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 배포합니다. MySQL 데이터베이스는 다른 Availability Zone으로만 복제합니다.",
    "SelectB_Commentary": "Amazon MQ는 관리형이지만 MySQL은 RDS Multi-AZ가 아니므로, 수동 복제가 필요해 운영 복잡성이 있고 완전한 고가용성을 보장하기 어렵습니다.",
    "SelectC": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, 추가 consumer EC2 인스턴스를 다른 Availability Zone에 배포합니다. MySQL 데이터베이스는 Multi-AZ를 활성화한 Amazon RDS for MySQL을 사용합니다.",
    "SelectC_Commentary": "DB와 MQ는 고가용성 옵션이지만 consumer EC2 인스턴스가 단순 이중화만 되어 Auto Scaling group이 없어 장애 시 자동 복구가 제한적입니다.",
    "SelectD": "두 개의 Availability Zone에 걸쳐 active/standby brokers를 구성한 Amazon MQ를 사용하고, Auto Scaling group을 통해 두 개의 Availability Zone 전반에 consumer EC2 인스턴스를 배포합니다. MySQL 데이터베이스는 Multi-AZ를 활성화한 Amazon RDS for MySQL을 사용합니다.",
    "SelectD_Commentary": "MQ, DB, 그리고 consumer 인스턴스 모두 관리형 고가용성 구성을 적용해, 장애에 즉시 대응하면서 운영 복잡도를 최소화하는 가장 완벽한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q824",
      "Q944",
      "Q203",
      "Q892",
      "Q654"
    ],
    "SelectA_recommedations": [
      "Q111",
      "Q758",
      "Q987"
    ],
    "SelectB_recommedations": [
      "Q639",
      "Q298",
      "Q111"
    ],
    "SelectC_recommedations": [
      "Q466",
      "Q390",
      "Q958"
    ],
    "SelectD_recommedations": [
      "Q390",
      "Q466",
      "Q298"
    ]
  },
  {
    "Question_Number": "Q112",
    "Question_Description": "한 회사가 내부 데이터 센터의 서버 여러 대에서 컨테이너화된 웹 애플리케이션을 운영하여 들어오는 요청을 처리하고 있습니다. 요청 수가 빠르게 증가하여 내부 서버들이 더 이상 늘어난 요청을 감당하지 못하고 있습니다. 회사는 애플리케이션 코드를 최소한으로 수정하고 개발 노력을 최소화하면서 AWS로 이전하고자 합니다. 이러한 요구사항을 충족하며 오퍼레이셔널 오버헤드를 가장 적게 소모하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85913-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 내부 서버에서 운영 중인 컨테이너화된 웹 애플리케이션을 최소한의 코드 변경으로 AWS로 이전하는 상황입니다. AWS Fargate를 사용하면 EC2 인스턴스 관리를 생략해 오퍼레이셔널 오버헤드가 줄어들고, Service Auto Scaling과 ALB로 높은 확장성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "컨테이너화된 웹 애플리케이션",
      "오퍼레이셔널 오버헤드",
      "AWS로 이전",
      "AWS Fargate",
      "Service Auto Scaling",
      "Application Load Balancer"
    ],
    "Terms": [
      "AWS Fargate",
      "Amazon ECS",
      "Service Auto Scaling",
      "Application Load Balancer",
      "Amazon EC2",
      "AWS Lambda",
      "Amazon API Gateway",
      "AWS ParallelCluster"
    ],
    "SelectA": "AWS Fargate를 사용하는 Amazon ECS에서 컨테이너화된 웹 애플리케이션을 실행하고 Service Auto Scaling을 설정합니다. Application Load Balancer를 통해 요청을 분산합니다.",
    "SelectA_Commentary": "AWS Fargate는 서버 관리를 대신 처리하므로 운영 부담이 낮고, Service Auto Scaling과 ALB를 통해 손쉽게 확장성을 확보할 수 있어 요구사항에 가장 적합합니다.",
    "SelectB": "Amazon EC2 인스턴스 두 대를 사용해 컨테이너화된 웹 애플리케이션을 배포하고 Application Load Balancer로 트래픽을 분산합니다.",
    "SelectB_Commentary": "EC2 인스턴스 관리가 필요하여 운영 부담이 늘어나고, 트래픽 증가 시 인스턴스 증설 등의 추가 작업이 필요해 오퍼레이셔널 오버헤드가 커집니다.",
    "SelectC": "AWS Lambda에서 지원되는 언어 중 하나로 새 코드를 작성하고 여러 Lambda function을 생성하여 부하를 처리합니다. Amazon API Gateway를 엔드포인트로 사용합니다.",
    "SelectC_Commentary": "기존 컨테이너 애플리케이션을 완전히 재개발해야 하므로 개발 노력이 상당하며, 최소한의 코드 변경이라는 목표에 맞지 않습니다.",
    "SelectD": "AWS ParallelCluster를 사용해 HPC 클러스터를 구성하고 증가하는 요청을 처리할 수 있도록 고성능 환경을 설정합니다.",
    "SelectD_Commentary": "HPC 클러스터는 대규모 과학 계산 등에 적합하며, 웹 트래픽 처리에는 과도한 설정과 복잡도가 추가되어 오퍼레이셔널 오버헤드가 커집니다.",
    "Question_Description_recommedations": [
      "Q786",
      "Q519",
      "Q802",
      "Q149",
      "Q869"
    ],
    "SelectA_recommedations": [
      "Q698",
      "Q303",
      "Q900"
    ],
    "SelectB_recommedations": [
      "Q357",
      "Q405",
      "Q714"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q10",
      "Q739"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q879",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q113",
    "Question_Description": "한 회사는 보고 용도로 50TB의 데이터를 사용하고 있습니다. 이 회사는 온프레미스에서 이 데이터를 AWS로 이전하려고 합니다. 회사 데이터 센터에는 매주 데이터 변환 작업을 수행하는 맞춤형 애플리케이션이 있으며, 회사는 데이터 전송 완료 후 최대한 빠르게 이 전송 작업을 시작하고자 합니다. 하지만 데이터 센터에는 추가 작업 부하를 처리할 만한 네트워크 대역폭이 없습니다. 솔루션스 아키텍트는 데이터를 전송하고 이 변환 작업을 AWS Cloud에서 계속 실행할 수 있도록 구성해야 합니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85912-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스에서 50TB 대규모 데이터를 빠른 시일 내에 전송해야 하며, 추가 네트워크 사용이 어려운 상황입니다. Snowball Edge Storage Optimized 디바이스를 이용해 물리적으로 데이터를 전송함과 동시에 AWS Glue로 자동화된 변환 작업을 구성하면, 운영 부담을 최소화하고 빠르게 문제를 해결할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "50TB",
      "데이터 전송",
      "온프레미스",
      "Snowball Edge",
      "AWS Glue"
    ],
    "Terms": [
      "AWS DataSync",
      "AWS Glue",
      "AWS Snowcone",
      "Amazon EC2",
      "Snowball Edge",
      "Storage Optimized",
      "ETL"
    ],
    "SelectA": "AWS DataSync를 사용하여 데이터를 전송하고 AWS Glue를 사용하여 맞춤형 변환 작업을 생성합니다.",
    "SelectA_Commentary": "DataSync는 추가 네트워크 대역폭이 필요한데 데이터 센터에 여유가 없으므로 적절하지 않습니다.",
    "SelectB": "AWS Snowcone 디바이스를 주문하여 데이터를 전송하고, 변환 애플리케이션을 해당 디바이스에 배포합니다.",
    "SelectB_Commentary": "Snowcone은 최대 약 14TB 용량으로 50TB 데이터를 모두 담기에 부족합니다.",
    "SelectC": "AWS Snowball Edge Storage Optimized 디바이스를 주문하고 데이터를 디바이스에 복사합니다. AWS Glue를 사용해 맞춤형 변환 작업을 생성합니다.",
    "SelectC_Commentary": "대용량 Snowball Edge 디바이스를 통해 빠른 물리 전송이 가능하며, 서버리스 AWS Glue로 변환 작업을 수행하므로 운영 오버헤드가 가장 적은 해결책입니다.",
    "SelectD": "Amazon EC2 컴퓨팅이 포함된 AWS Snowball Edge Storage Optimized 디바이스를 주문하고 데이터를 디바이스에 복사합니다. AWS에서 새 EC2 인스턴스를 생성해 변환 애플리케이션을 실행합니다.",
    "SelectD_Commentary": "EC2 인스턴스 배포와 유지 관리가 필요해 운영 부담이 증가하며, C 옵션보다 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q747",
      "Q1",
      "Q1000",
      "Q631",
      "Q127"
    ],
    "SelectA_recommedations": [
      "Q155",
      "Q515",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q865",
      "Q443"
    ],
    "SelectC_recommedations": [
      "Q702",
      "Q620",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q702",
      "Q976",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q114",
    "Question_Description": "한 회사가 사용자들이 사진을 업로드하고 자신의 이미지에 사진 테두리를 추가할 수 있는 이미지 분석 애플리케이션을 만들었습니다. 사용자는 이미지를 업로드하고, 어떤 사진 테두리를 추가할지 표시하기 위한 메타데이터도 함께 업로드합니다. 현재 애플리케이션은 단일 Amazon EC2 인스턴스와 Amazon DynamoDB를 사용하여 메타데이터를 저장하고 있습니다. 그러나 애플리케이션의 인기가 높아지면서 사용자 수가 증가하고, 하루 중 특정 시간대나 요일에 따라 동시 사용자 수가 크게 달라질 수 있습니다. 이 회사는 증가하는 사용자 수요를 충족하기 위해 애플리케이션이 확장 가능해야 함을 요구합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85189-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션이 동시 사용자 수 증가에 맞춰 유연하고 자동으로 확장할 수 있는 구조를 구성해야 하는 상황을 다룹니다. 이미지를 데이터베이스에 직접 저장하는 것은 비효율적이며, Lambda 등 서버리스 기반의 확장성과 저비용 스토리지인 Amazon S3를 조합해 아키텍처를 구성하는 것이 일반적인 모범 사례입니다. 따라서 이미지 처리를 Lambda로 수행하고 사진은 S3에 두며 메타데이터만 DynamoDB에 저장하면 쉽고 효과적으로 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이미지 분석 애플리케이션",
      "사진 업로드",
      "메타데이터",
      "동시 사용자 확장",
      "AWS Lambda",
      "Amazon S3",
      "Amazon DynamoDB"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon S3",
      "Amazon Kinesis Data Firehose",
      "Amazon EBS (io2)"
    ],
    "SelectA": "Use AWS Lambda to process the photos. Store the photos and metadata in DynamoDB.",
    "SelectA_Commentary": "이미지를 직접 DynamoDB에 저장하면 비용이 많이 들고 확장성 측면에서 비효율적이므로 적절하지 않습니다.",
    "SelectB": "Use Amazon Kinesis Data Firehose to process the photos and to store the photos and metadata.",
    "SelectB_Commentary": "Kinesis Data Firehose는 스트리밍 데이터 수집에 적합하지만, 이미지 파일 자체를 저장하고 처리하기엔 구조가 복잡하고 적절치 않습니다.",
    "SelectC": "Use AWS Lambda to process the photos. Store the photos in Amazon S3. Retain DynamoDB to store the metadata.",
    "SelectC_Commentary": "Lambda가 자동으로 확장되며, S3에 이미지를 저장해 비용과 확장성 문제를 해결하고, DynamoDB에는 메타데이터만 저장하여 가볍고 탄력적인 아키텍처를 구성하므로 정답입니다.",
    "SelectD": "Increase the number of EC2 instances to three. Use Provisioned IOPS SSD (io2) Amazon Elastic Block Store (Amazon EBS) volumes to store the photos and metadata.",
    "SelectD_Commentary": "EC2 인스턴스 수를 늘리고 EBS를 사용하는 방식은 서버 관리를 직접 해야 하고, 빠르게 달라지는 수요에 따라 자동 확장이 제한적이므로 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q252",
      "Q400",
      "Q1014",
      "Q110",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q768",
      "Q351",
      "Q785"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q194",
      "Q784"
    ],
    "SelectC_recommedations": [
      "Q768",
      "Q18",
      "Q404"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q48",
      "Q150"
    ]
  },
  {
    "Question_Number": "Q115",
    "Question_Description": "한 의료 기록 회사가 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon S3에 저장된 고객 데이터 파일을 처리합니다. 현재 EC2 인스턴스는 public subnets에 위치해 있으며, 인터넷을 통해 Amazon S3에 액세스하고 있습니다. 그러나 EC2 인스턴스에는 그 외 다른 네트워크 액세스가 필요하지는 않습니다. 새로운 요구사항으로 인해 파일 전송에 대한 네트워크 트래픽은 인터넷이 아닌 사설 경로를 통해서만 전송되어야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 네트워크 아키텍처에 어떤 변경 사항을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86031-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스에서 Amazon S3로의 파일 전송을 퍼블릭 인터넷을 거치지 않고 사설 경로로 전송하게끔 네트워크를 재설계하는 방법을 묻습니다. 정답은 private subnets로 옮긴 뒤 VPC endpoint를 사용하여 트래픽이 인터넷에 노출되지 않는 경로로 전송하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "파일 전송",
      "사설 경로",
      "public subnets",
      "private subnets",
      "Amazon EC2",
      "Amazon S3",
      "VPC endpoint",
      "internet gateway"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "public subnets",
      "private subnets",
      "VPC endpoint",
      "NAT gateway",
      "internet gateway",
      "security group",
      "S3 prefix list",
      "AWS Direct Connect",
      "route table"
    ],
    "SelectA": "NAT gateway를 생성합니다. public subnets의 route table을 구성하여 Amazon S3로의 트래픽을 NAT gateway를 통해 전송하도록 설정합니다.",
    "SelectA_Commentary": "NAT gateway는 사설 서브넷에서 아웃바운드 인터넷 접속을 제공할 때 사용되며, 여전히 인터넷을 통한 연결이 필요하므로 사설 경로 요구사항을 충족하지 못합니다.",
    "SelectB": "EC2 인스턴스에 대한 security group을 설정하여 아웃바운드 트래픽을 S3 prefix list로의 트래픽만 허용하도록 제한합니다.",
    "SelectB_Commentary": "Security group 규칙만으로는 인터넷을 우회하는 사설 경로를 확보할 수 없습니다. 트래픽 경로 자체가 여전히 인터넷을 포함하게 됩니다.",
    "SelectC": "EC2 인스턴스를 private subnets로 이동합니다. Amazon S3에 대한 VPC endpoint를 생성하고, 이 endpoint를 private subnets의 route table에 연결합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 사설 서브넷에 배치하고 S3 VPC endpoint를 사용하면, 인터넷을 거치지 않고도 내부 경로를 통해 안전하게 S3에 접근할 수 있으므로 요구사항을 모두 만족시킵니다.",
    "SelectD": "VPC에서 internet gateway를 제거합니다. AWS Direct Connect 연결을 설정하고, Amazon S3로 가는 트래픽을 Direct Connect 연결을 통해 전송합니다.",
    "SelectD_Commentary": "Direct Connect는 온프레미스 환경과 AWS 간 사설 연결에 주로 사용되며, 이 문제에서는 사설 경로 확보에 과도한 솔루션으로 운영 복잡도와 비용이 증가합니다.",
    "Question_Description_recommedations": [
      "Q875",
      "Q710",
      "Q610",
      "Q612",
      "Q453"
    ],
    "SelectA_recommedations": [
      "Q1016",
      "Q875",
      "Q532"
    ],
    "SelectB_recommedations": [
      "Q903",
      "Q612",
      "Q453"
    ],
    "SelectC_recommedations": [
      "Q251",
      "Q875",
      "Q4"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q810",
      "Q610"
    ]
  },
  {
    "Question_Number": "Q116",
    "Question_Description": "한 회사가 인기 있는 CMS(콘텐츠 관리 시스템)를 사용해 기업 웹사이트를 운영하고 있었으나, 패치 및 유지보수에 대한 부담이 큽니다. 회사는 웹사이트를 새로 설계하려고 하며, 연 4회 업데이트만 필요하고 동적으로 생성되는 콘텐츠도 필요 없습니다. 이 솔루션은 높은 확장성과 보안을 제공해야 하며, 운영 오버헤드를 최소화해야 합니다. 다음 중 이러한 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션 조합은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 정적 콘텐츠를 활용해 운영 부담을 줄이고, 동시에 높은 확장성과 보안을 구현하는 것이 핵심입니다. CloudFront와 S3 정적 웹 호스팅을 결합하면 손쉽게 HTTPS 접근과 전 세계적 콘텐츠 캐싱이 가능하여, 관리해야 할 인프라가 줄어들고 패치 부담도 없어집니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "기업 웹사이트",
      "CMS 부담",
      "정적 사이트",
      "높은 확장성",
      "보안 강화",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon CloudFront",
      "AWS WAF web ACL",
      "AWS Lambda",
      "Amazon S3",
      "Auto Scaling group",
      "Amazon EC2",
      "Application Load Balancer",
      "HTTPS"
    ],
    "SelectA": "Amazon CloudFront를 웹사이트 앞단에 구성하여 HTTPS 기능을 사용하도록 합니다.",
    "SelectA_Commentary": "CloudFront를 통해 전 세계 엣지 로케이션에서 캐싱하며 HTTPS 설정도 간단해, 보안과 확장성 모두를 향상시키는 효과적인 방식입니다.",
    "SelectB": "AWS WAF web ACL을 웹사이트 앞단에 배포해 HTTPS 기능을 제공합니다.",
    "SelectB_Commentary": "AWS WAF는 HTTPS를 직접 제공하지 않고, 주로 웹 공격 방어를 위한 보안 계층이므로 HTTPS 자체 제공 목적에는 적합하지 않습니다.",
    "SelectC": "웹사이트 콘텐츠를 관리하고 제공하기 위해 AWS Lambda 함수를 생성 후 배포합니다.",
    "SelectC_Commentary": "Lambda를 사용해 정적 콘텐츠를 서빙하려면 별도의 설정과 코드가 필요해 운영 복잡도가 오히려 증가합니다.",
    "SelectD": "새로운 웹사이트를 Amazon S3 버킷에 생성하고, 정적 웹사이트 호스팅을 활성화하여 웹사이트를 배포합니다.",
    "SelectD_Commentary": "정적 웹사이트 호스팅으로 S3를 이용하면 관리 서버 없이 확장성과 저비용을 달성할 수 있어 운영 부담이 크게 줄어듭니다.",
    "SelectE": "새로운 웹사이트를 생성 후, Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹을 통해 웹사이트를 배포합니다.",
    "SelectE_Commentary": "EC2 인스턴스와 Auto Scaling, 로드 밸런서 등을 설정해야 하므로 관리가 복잡해지고 오버헤드가 크게 증가합니다.",
    "Question_Description_recommedations": [
      "Q622",
      "Q493",
      "Q77",
      "Q915",
      "Q506"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q280",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q249",
      "Q443"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q631",
      "Q568"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q626",
      "Q43"
    ],
    "SelectE_recommedations": [
      "Q261",
      "Q141",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q117",
    "Question_Description": "한 회사가 Amazon CloudWatch Logs log group에 애플리케이션 로그를 저장하고 있습니다. 새로운 정책에 따라, 회사는 모든 애플리케이션 로그를 거의 실시간으로 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 저장해야 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudWatch Logs log group에 저장된 애플리케이션 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 실시간에 가깝게 전달하는 방안을 묻습니다. 가장 운영 오버헤드가 적은 방법은 CloudWatch Logs 자체 기능을 사용하여 로그를 직접 스트리밍하는 것입니다. 별도의 추가 구성(예: Kinesis Data Firehose나 Lambda 함수, Kinesis Agent 설치 등)을 최소화함으로써 운영 비용과 복잡도를 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "애플리케이션 로그",
      "CloudWatch Logs",
      "Amazon OpenSearch Service(Amazon Elasticsearch Service)",
      "운영 오버헤드",
      "거의 실시간"
    ],
    "Terms": [
      "CloudWatch Logs subscription",
      "Amazon OpenSearch Service(Amazon Elasticsearch Service)",
      "Kinesis Data Firehose",
      "Amazon Kinesis Data Streams",
      "AWS Lambda",
      "Amazon Kinesis Agent"
    ],
    "SelectA": "CloudWatch Logs 구독(subscription)을 구성하여 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)로 스트리밍합니다.",
    "SelectA_Commentary": "CloudWatch Logs에서 제공하는 기본 구독 기능을 통해 추가 인프라 없이 거의 실시간으로 로그를 전송할 수 있어 가장 적은 운영 오버헤드를 제공합니다.",
    "SelectB": "AWS Lambda 함수를 생성합니다. log group으로 함수를 호출하여 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 기록합니다.",
    "SelectB_Commentary": "Lambda 함수를 사용하면 실시간 처리가 가능하지만, 함수 코드 유지보수와 트리거 구성 등 추가적 운영 부담이 생깁니다.",
    "SelectC": "Amazon Kinesis Data Firehose delivery stream을 생성합니다. log group을 소스로 구성하고, Amazon OpenSearch Service(Amazon Elasticsearch Service)를 대상로 구성합니다.",
    "SelectC_Commentary": "Kinesis Data Firehose는 실시간에 가까운 데이터 전송이 가능하지만, 별도 스트리밍 리소스 설정과 관리가 필요해 오버헤드가 더 높습니다.",
    "SelectD": "각 애플리케이션 서버에 Amazon Kinesis Agent를 설치하고 Kinesis Data Streams로 로그를 전송합니다. 그리고 Kinesis Data Streams를 통해 로그를 Amazon OpenSearch Service(Amazon Elasticsearch Service)에 전송합니다.",
    "SelectD_Commentary": "Kinesis Agent 설치와 Data Streams 관리가 모두 필요하므로 구성과 운영이 복잡하며, 실시간에 가깝게 전송 가능하지만 운영 오버헤드가 매우 커집니다.",
    "Question_Description_recommedations": [
      "Q292",
      "Q515",
      "Q177",
      "Q695",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q117",
      "Q695",
      "Q515"
    ],
    "SelectB_recommedations": [
      "Q117",
      "Q597",
      "Q576"
    ],
    "SelectC_recommedations": [
      "Q117",
      "Q402",
      "Q515"
    ],
    "SelectD_recommedations": [
      "Q117",
      "Q402",
      "Q695"
    ]
  },
  {
    "Question_Number": "Q118",
    "Question_Description": "한 회사에서 여러 Availability Zone에 분산된 Amazon EC2 인스턴스 위에서 실행되는 웹 기반 애플리케이션을 구축하고 있습니다. 이 웹 애플리케이션은 총 900TB에 달하는 텍스트 문서 저장소에 대한 접근 기능을 제공합니다. 회사는 웹 애플리케이션이 높은 트래픽을 경험할 시기가 있을 것으로 예상하며, 솔루션스 아키텍트는 텍스트 문서를 저장하는 스토리지가 언제나 애플리케이션의 수요를 충족할 수 있도록 확장 가능해야 한다고 요구합니다. 또한 회사는 전체 솔루션에 대한 비용 문제를 우려하고 있습니다. 이 요구사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86512-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량(900TB) 텍스트 문서를 저장하면서, 높은 트래픽 부담에도 확장 가능하고 비용을 최소화해야 하는 시나리오입니다. Amazon S3는 저렴한 가격 구조와 탄력적 확장이 가능해 요구사항을 모두 충족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "2.1"
    ],
    "Keywords": [
      "웹 기반 애플리케이션",
      "텍스트 문서",
      "900TB",
      "확장 가능",
      "비용 효율"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Amazon Elastic Block Store (Amazon EBS)",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "Amazon S3"
    ],
    "SelectA": "Amazon EBS",
    "SelectA_Commentary": "블록 스토리지로서 고성능이지만 단일 AZ 기반이고 비용이 높아 대규모 데이터 저장에는 비효율적입니다.",
    "SelectB": "Amazon EFS",
    "SelectB_Commentary": "파일 스토리지 서비스로 확장성은 좋지만, S3에 비해 GB당 비용이 높아 900TB 규모의 데이터에는 부담이 큽니다.",
    "SelectC": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
    "SelectC_Commentary": "실시간 검색 및 분석용 서비스로, 대규모 단순 데이터 저장에는 부적합하며 비용 또한 높습니다.",
    "SelectD": "Amazon S3",
    "SelectD_Commentary": "비용이 저렴하고 무제한에 가까운 확장성을 제공하므로, 대규모 텍스트 문서 저장 요구사항에 가장 적합합니다.",
    "Question_Description_recommedations": [
      "Q773",
      "Q384",
      "Q671",
      "Q347",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q943",
      "Q238"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q703",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q285",
      "Q943",
      "Q1003"
    ]
  },
  {
    "Question_Number": "Q119",
    "Question_Description": "글로벌 회사가 us-east-1 리전과 ap-southeast-2 리전에서 운영되는 Amazon API Gateway로 REST API를 설계하고 있습니다. 여러 AWS 계정에서 이 API를 사용하고 있으며, SQL injection과 cross-site scripting 공격으로부터 안전하게 보호해야 합니다. Solutions Architect는 관리 오버헤드를 최소화하면서 API Gateway에서 이러한 공격을 방어할 수 있는 방법을 설계해야 합니다. 다음 중 어떤 솔루션이 최소한의 관리 노력으로 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86450-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 리전과 계정에 걸쳐 운영되는 API를 공격으로부터 보호하면서, 관리 노력도 최소화해야 합니다. AWS Firewall Manager를 사용하면 여러 계정과 리전에서 중앙 집중식으로 AWS WAF 구성을 관리할 수 있어 SQL injection, XSS 같은 공격을 효율적으로 방어하고 자동화된 보호까지 가능하도록 해줍니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "API Gateway",
      "SQL injection",
      "cross-site scripting",
      "관리 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS WAF",
      "AWS Firewall Manager",
      "AWS Shield",
      "Regional web ACL",
      "API stage",
      "REST API"
    ],
    "SelectA": "두 리전에서 AWS WAF를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.",
    "SelectA_Commentary": "모든 리전에 개별적으로 WAF를 설정해야 하므로 계정 단위의 관리가 여전히 복잡합니다.",
    "SelectB": "두 리전에서 AWS Firewall Manager를 설정하고, 중앙에서 AWS WAF 규칙을 구성합니다.",
    "SelectB_Commentary": "AWS Firewall Manager로 여러 계정과 리전을 일괄 관리할 수 있어 노력과 복잡도가 크게 줄어듭니다.",
    "SelectC": "두 리전에서 AWS Shield를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.",
    "SelectC_Commentary": "AWS Shield는 주로 DDoS 방어에 특화되어 있고, SQL injection 및 XSS 방어를 위해선 WAF 구성이 별도로 필요합니다.",
    "SelectD": "한 리전에서만 AWS Shield를 설정하고, Regional web ACL을 API 스테이지에 연결합니다.",
    "SelectD_Commentary": "DDoS 방어 위주 솔루션이며 전 세계적으로 SQL injection과 XSS를 다루기엔 효과적이지 못합니다.",
    "Question_Description_recommedations": [
      "Q623",
      "Q399",
      "Q180",
      "Q1019",
      "Q393"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q34",
      "Q165"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q893",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q34",
      "Q893",
      "Q1019"
    ],
    "SelectD_recommedations": [
      "Q34",
      "Q893",
      "Q1019"
    ]
  },
  {
    "Question_Number": "Q120",
    "Question_Description": "한 회사가 us-west-2 리전에 위치한 Network Load Balancer(NLB) 뒤의 Amazon EC2 인스턴스 3대를 활용하여 자체 관리 DNS 솔루션을 구성했습니다. 이 회사의 대부분 사용자들은 미국과 유럽에 분포해 있으며, 성능과 가용성을 더욱 개선하고자 합니다. 회사는 eu-west-1 리전에도 EC2 인스턴스 3대를 추가로 구축하고 새로운 NLB의 대상으로 등록했습니다. 모든 EC2 인스턴스로 트래픽을 라우팅하기 위해 어떤 솔루션을 사용할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 리전에 분산된 EC2 인스턴스를 사용해 자체 관리 DNS를 제공할 때, 성능과 가용성을 높이는 방안을 묻습니다. 답은 AWS Global Accelerator를 사용해 us-west-2와 eu-west-1 두 리전에 걸쳐 엔드포인트 그룹을 생성한 뒤, 각각의 NLB를 엔드포인트로 추가하는 방법입니다. 이렇게 하면 글로벌 사용자가 물리적 위치와 관계없이 가장 빠른 네트워크 경로를 통해 DNS 서비스에 접근할 수 있어 성능과 가용성이 모두 개선됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "성능",
      "가용성",
      "Network Load Balancer",
      "AWS Global Accelerator",
      "라우팅"
    ],
    "Terms": [
      "Amazon EC2",
      "Network Load Balancer(NLB)",
      "AWS Global Accelerator",
      "Endpoint groups",
      "Amazon Route 53",
      "Geolocation routing policy",
      "Latency routing policy",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront",
      "Elastic IP addresses"
    ],
    "SelectA": "Amazon Route 53 지리 위치(geolocation) 라우팅 정책을 만들어 두 NLB 중 하나로 요청을 전달합니다. 그런 다음 Amazon CloudFront 배포를 생성하고, Route 53 레코드를 배포의 오리진으로 사용합니다.",
    "SelectA_Commentary": "지리 위치 라우팅은 지역을 기준으로 트래픽을 나누지만, 글로벌 사용자의 가장 빠른 경로 제공을 보장하지 못합니다. CloudFront 배포를 추가하더라도 NLB 선택에 있어 지역 구분만 사용하므로 성능 향상이 제한적입니다.",
    "SelectB": "AWS Global Accelerator 표준 가속기를 생성합니다. us-west-2와 eu-west-1 리전에 엔드포인트 그룹을 만들고, 두 NLB를 엔드포인트로 추가합니다.",
    "SelectB_Commentary": "AWS Global Accelerator를 사용하면 전 세계 사용자에게 단일 고정 진입점을 제공하고, 글로벌 AWS 네트워크를 통해 가장 빠른 경로로 트래픽을 라우팅하므로 성능과 가용성이 크게 향상됩니다. 정답입니다.",
    "SelectC": "6대의 EC2 인스턴스 각각에 Elastic IP 주소를 할당합니다. Amazon Route 53 지리 위치 라우팅 정책으로 6대 중 하나로 트래픽을 전달하게 구성합니다. 그리고 Amazon CloudFront 배포를 생성하고, 해당 Route 53 레코드를 CloudFront의 오리진으로 사용합니다.",
    "SelectC_Commentary": "개별 EC2 인스턴스에 직접 트래픽을 전달하면 로드 밸런서를 통한 확장성, 고가용성 이점을 활용하기 어렵고, 관리 복잡성도 높아집니다.",
    "SelectD": "두 NLB를 두 Application Load Balancer(ALB)로 교체합니다. Amazon Route 53 지연 시간(latency) 라우팅 정책을 생성하여 두 ALB 중 하나로 요청을 전송합니다. 그런 다음 Amazon CloudFront 배포를 만들고, Route 53 레코드를 배포의 오리진으로 사용합니다.",
    "SelectD_Commentary": "지연 시간 라우팅을 사용해도, AWS Global Accelerator가 제공하는 전용 글로벌 백본을 통한 성능 이점을 활용하기는 어렵습니다. ALB 교체 및 CloudFront 연동 또한 필요한 단계를 늘려 운영 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q70",
      "Q5",
      "Q714",
      "Q246",
      "Q570"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q264",
      "Q544"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q8",
      "Q311"
    ],
    "SelectC_recommedations": [
      "Q264",
      "Q545",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q70",
      "Q813"
    ]
  },
  {
    "Question_Number": "Q121",
    "Question_Description": "한 회사가 온라인 트랜잭션 처리(OLTP) 워크로드를 AWS에서 운영하고 있습니다. 이 워크로드는 Multi-AZ 배포 구성의 암호화되지 않은 Amazon RDS DB 인스턴스를 사용하며, 매일 이 인스턴스에서 데이터베이스 스냅샷을 생성하고 있습니다. 앞으로 데이터베이스와 스냅샷을 항상 암호화하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85941-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "기존에 암호화되지 않은 DB 인스턴스는 직접 암호화를 활성화할 수 없습니다. 대신 먼저 최신 DB 스냅샷의 암호화 복사본을 만들고, 해당 스냅샷을 복원하여 암호화된 새 DB 인스턴스를 생성하면 이후 모든 스냅샷도 자동으로 암호화됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon RDS",
      "Multi-AZ",
      "암호화",
      "DB 스냅샷",
      "AWS KMS",
      "OLTP"
    ],
    "Terms": [
      "Amazon RDS DB instance",
      "Multi-AZ deployment",
      "Daily database snapshots",
      "AWS Key Management Service (AWS KMS)",
      "Unencrypted DB instance",
      "SSE-KMS",
      "Amazon EBS volume",
      "Restore"
    ],
    "SelectA": "최신 DB 스냅샷의 암호화 복사본을 생성한 뒤, 해당 암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다.",
    "SelectA_Commentary": "암호화된 DB 스냅샷을 생성 후 이를 복원해 새 인스턴스를 만들면 암호화가 적용된 인스턴스를 확보해 이후 스냅샷도 모두 암호화됩니다. 이 접근이 올바른 해결책입니다.",
    "SelectB": "새로운 암호화된 Amazon EBS 볼륨을 생성하고, 기존 스냅샷을 그 볼륨에 복사합니다. 이후 DB 인스턴스에 암호화를 활성화합니다.",
    "SelectB_Commentary": "RDS 인스턴스는 생성 시점에만 암호화 설정이 가능하므로, 단순히 EBS 볼륨을 암호화해도 현재 DB 인스턴스를 바로 암호화할 수 없어서 적합하지 않습니다.",
    "SelectC": "스냅샷을 복사하면서 AWS KMS를 사용해 암호화를 활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스에 복원합니다.",
    "SelectC_Commentary": "암호화된 스냅샷은 기존 DB 인스턴스에 직접 복원될 수 없고, 새 인스턴스로 복원해야 실제로 암호화 인스턴스를 얻을 수 있으므로 이 방식은 부적절합니다.",
    "SelectD": "스냅샷을 AWS KMS 관리 암호화(SSE-KMS)가 적용된 Amazon S3 버킷으로 복사합니다.",
    "SelectD_Commentary": "스냅샷을 S3로 암호화해 보관해도 원래의 RDS 인스턴스를 암호화 상태로 전환하지 못하므로, 이후 DB 스냅샷 자동 암호화에도 영향을 주지 못합니다.",
    "Question_Description_recommedations": [
      "Q86",
      "Q992",
      "Q742",
      "Q61",
      "Q330"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q689",
      "Q176",
      "Q675"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q916",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q1009",
      "Q681",
      "Q793"
    ]
  },
  {
    "Question_Number": "Q122",
    "Question_Description": "회사는 애플리케이션에서 데이터를 암호화해야 하는 개발자들을 지원하기 위해 스케일러블한 키 관리 인프라스트럭처를 구축하려고 합니다. 솔루션스 아키텍트의 운영 부담을 줄이기 위한 최적의 방안은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85942-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 암호화 키를 안전하고 확장 가능하게 관리해야 하는 상황입니다. AWS KMS는 중앙 집중식 키 생성, 로테이션, 접근 제어 등을 자동화하여 운영 부담을 크게 줄여 줍니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "스케일러블 키 관리",
      "암호화",
      "애플리케이션",
      "운영 부담 최소화",
      "AWS KMS"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "IAM policy",
      "AWS Certificate Manager (ACM)",
      "Multi-factor authentication (MFA)",
      "Encryption keys"
    ],
    "SelectA": "Multi-factor authentication (MFA)를 사용하여 Encryption keys를 보호합니다.",
    "SelectA_Commentary": "MFA는 계정 보호에는 유용하나, 자체적으로 스케일러블한 키 관리 인프라스트럭처를 제공하지 못합니다.",
    "SelectB": "AWS Key Management Service (AWS KMS)를 사용하여 Encryption keys를 보호합니다.",
    "SelectB_Commentary": "AWS KMS는 암호화 키를 안전하게 저장, 관리, 자동 로테이션할 수 있어 운영 부담과 라이선스 비용을 모두 줄일 수 있는 최적의 솔루션입니다.",
    "SelectC": "AWS Certificate Manager (ACM)을 사용하여 Encryption keys를 생성, 저장 및 할당합니다.",
    "SelectC_Commentary": "ACM은 주로 SSL/TLS 인증서 관리에 특화되어 있으며, 일반적인 데이터 암호화를 위한 키 관리에는 적합하지 않습니다.",
    "SelectD": "IAM policy로 Encryption keys에 대한 액세스 권한 범위를 제한합니다.",
    "SelectD_Commentary": "IAM policy로 접근을 제어하는 것은 중요하지만, 키를 직접 관리하고 자동화할 수 있는 기능은 제공하지 못해 운영 부담을 충분히 줄이지 못합니다.",
    "Question_Description_recommedations": [
      "Q665",
      "Q478",
      "Q57",
      "Q189",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q645",
      "Q797"
    ],
    "SelectB_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q645",
      "Q916",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q423",
      "Q429",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q123",
    "Question_Description": "한 회사가 두 대의 Amazon EC2 인스턴스에 동적 웹 애플리케이션을 호스팅하고 있습니다. 회사는 자체 SSL certificate를 보유하고 있으며, 각 인스턴스에서 SSL termination을 수행하고 있습니다. 최근 트래픽이 증가하여 운영팀은 SSL 암호화·복호화 작업이 웹 서버의 컴퓨팅 용량을 최대치로 사용한다고 판단했습니다. 애플리케이션 성능을 높이기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85943-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 SSL 암복호화로 인한 서버 부하를 줄여 애플리케이션 성능을 높이는 것입니다. 인스턴스에서 SSL termination을 수행하면 CPU 사용량이 크게 증가하므로, AWS Certificate Manager에 SSL certificate를 등록하고 ALB(HTTPS listener)에서 암복호화를 처리하도록 오프로딩하는 방식이 최적의 해결책입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "SSL certificate",
      "SSL termination",
      "AWS Certificate Manager",
      "Application Load Balancer",
      "EC2",
      "HTTPS",
      "웹 서버 성능"
    ],
    "Terms": [
      "SSL certificate",
      "SSL termination",
      "AWS Certificate Manager (ACM)",
      "Application Load Balancer",
      "Amazon EC2",
      "Amazon S3",
      "Proxy server",
      "HTTPS listener"
    ],
    "SelectA": "AWS Certificate Manager (ACM)에서 새로운 SSL certificate를 생성하고, 각 인스턴스에 설치합니다.",
    "SelectA_Commentary": "각 EC2 인스턴스에서 SSL termination을 계속 수행하므로 암복호화 부담이 여전히 남아 있습니다.",
    "SelectB": "Amazon S3 버킷을 생성하고 SSL certificate를 마이그레이션한 후, EC2 인스턴스가 해당 버킷을 참조하도록 설정합니다.",
    "SelectB_Commentary": "S3 버킷은 SSL termination 기능을 제공하지 않으므로 서버 부하 문제를 해결할 수 없습니다.",
    "SelectC": "프록시 서버용 새 EC2 인스턴스를 생성하고, SSL certificate를 마이그레이션하여 기존 EC2 인스턴스에 연결되도록 구성합니다.",
    "SelectC_Commentary": "프록시 서버에서 SSL termination을 수행하지만, EC2 인스턴스를 하나 더 두어 직접 관리해야 하므로 운영 복잡도가 증가합니다.",
    "SelectD": "SSL certificate를 AWS Certificate Manager (ACM)에 가져옵니다. ACM의 SSL certificate를 사용하는 HTTPS listener가 있는 Application Load Balancer를 생성합니다.",
    "SelectD_Commentary": "ALB에서 SSL 암복호화를 담당하게 하여 웹 서버의 부하를 줄이고, 관리 편의성과 보안성을 모두 높이는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q294",
      "Q26",
      "Q82",
      "Q11",
      "Q393"
    ],
    "SelectA_recommedations": [
      "Q577",
      "Q855",
      "Q62"
    ],
    "SelectB_recommedations": [
      "Q612",
      "Q453",
      "Q17"
    ],
    "SelectC_recommedations": [
      "Q480",
      "Q17",
      "Q682"
    ],
    "SelectD_recommedations": [
      "Q62",
      "Q60",
      "Q577"
    ]
  },
  {
    "Question_Number": "Q124",
    "Question_Description": "한 회사는 매우 동적인 배치 처리 작업을 수행하기 위해 여러 Amazon EC2 인스턴스를 사용하고 있습니다. 이 작업은 상태 정보가 없으므로 언제든지 중지 및 재시작해도 문제가 없으며, 보통 전체 수행 시간은 60분 이상 걸립니다. 회사는 이 작업의 요구 사항을 충족하면서 확장 가능하고 비용 효율적인 솔루션을 설계해 달라고 Solutions Architect에게 요청했습니다. 어떤 솔루션을 권장해야 할까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86038-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 배치 작업을 간헐적으로 중단·재시작해도 무방한 특성을 활용해, 중단 허용 워크로드에 최적화된 저비용 실행 방안을 찾는 것입니다. EC2 Spot Instances는 일반 온디맨드 대비 매우 저렴하며, 작업이 중단되어도 문제가 없는 배치 처리를 수행하기에 안성맞춤입니다. On-Demand Instances는 유연성이 있으나 비용이 더 높고, Reserved Instances는 장기 약정이 필요해 유연성이 떨어집니다. AWS Lambda는 실행 시간 제한(최대 15분)이 있어 60분 이상의 작업에는 적합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "동적인 배치 처리",
      "stateless",
      "확장 가능",
      "비용 효율적인 솔루션",
      "60분 이상",
      "EC2 Spot Instances"
    ],
    "Terms": [
      "Amazon EC2",
      "EC2 Spot Instances",
      "EC2 Reserved Instances",
      "EC2 On-Demand Instances",
      "AWS Lambda"
    ],
    "SelectA": "EC2 Spot Instances를 구현합니다.",
    "SelectA_Commentary": "Spot은 중단될 가능성이 있지만, 유연한 배치 작업에는 저비용으로 적합한 선택입니다.",
    "SelectB": "EC2 Reserved Instances를 구매합니다.",
    "SelectB_Commentary": "장기 약정으로 비용은 줄일 수 있으나, 동적 배치 작업을 수시로 중지/재시작하기에는 적합하지 않습니다.",
    "SelectC": "EC2 On-Demand Instances를 구현합니다.",
    "SelectC_Commentary": "온디맨드는 유연하지만 Spot 대비 비용이 높아 대규모 배치 작업의 비용 절감에는 한계가 있습니다.",
    "SelectD": "AWS Lambda에서 작업을 처리합니다.",
    "SelectD_Commentary": "Lambda의 최대 실행 시간이 15분이라 60분 이상 소요되는 배치 작업에는 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q872",
      "Q643",
      "Q63",
      "Q309",
      "Q22"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q1008",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q728",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q125",
    "Question_Description": "한 회사가 AWS에서 2티어 전자상거래 웹사이트를 운영하고 있습니다. 웹 티어는 로드 밸런서를 통해 Amazon EC2 인스턴스로 트래픽을 전송합니다. 데이터베이스 티어는 Amazon RDS DB 인스턴스를 사용합니다. EC2 인스턴스와 RDS DB 인스턴스는 퍼블릭 인터넷에 노출되어서는 안 됩니다. 하지만 EC2 인스턴스는 서드파티 웹 서비스를 통한 결제 처리를 위해 인터넷 액세스가 필요합니다. 또한 애플리케이션은 고가용성을 유지해야 합니다. 이러한 요구사항을 충족하는 구성 옵션의 조합은 무엇입니까? (정답으로 2개를 고르세요.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85221-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 인터넷에 직접 노출되지 않는 EC2 인스턴스와 RDS DB 인스턴스를 구성하면서도, EC2 인스턴스가 외부 결제 서비스를 위해 아웃바운드 인터넷 액세스를 갖도록 해야 하며, 동시에 고가용성을 보장해야 합니다. EC2와 RDS를 모두 Private Subnet에 배치하고, Public Subnet에는 NAT Gateway와 Application Load Balancer를 다중 AZ로 구성함으로써 이러한 요구사항을 충족할 수 있습니다. 따라서 Auto Scaling group으로 Private Subnet에 EC2를 생성하고 Multi-AZ로 RDS를 구성하며, Public Subnet에 배포된 NAT Gateway와 ALB를 통해 인터넷 액세스와 외부 트래픽 수용을 동시에 만족시킬 수 있는 (A)와 (E)가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "1.1",
      "2.2"
    ],
    "Keywords": [
      "2티어 전자상거래",
      "EC2 인스턴스",
      "RDS DB 인스턴스",
      "NAT Gateway",
      "퍼블릭 인터넷 노출 방지",
      "고가용성"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Multi-AZ",
      "Auto Scaling group",
      "VPC",
      "Public Subnet",
      "Private Subnet",
      "NAT Gateway",
      "Application Load Balancer"
    ],
    "SelectA": "Auto Scaling group을 사용하여 EC2 인스턴스를 Private Subnet에 생성합니다. RDS Multi-AZ DB 인스턴스를 Private Subnet에 배포합니다.",
    "SelectA_Commentary": "EC2와 RDS 모두 Private Subnet에서 운영하며, Multi-AZ 구성으로 고가용성을 지원합니다. EC2는 NAT Gateway를 통해 인터넷에 접근할 수 있게 됩니다.",
    "SelectB": "두 개의 Private Subnet과 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Private Subnet에 배포합니다.",
    "SelectB_Commentary": "ALB가 Private Subnet에 위치하면 외부에서 직접 접근이 불가하여 웹 트래픽 수용이 불가능하므로 요구사항을 충족하지 못합니다.",
    "SelectC": "Auto Scaling group을 사용하여 EC2 인스턴스를 두 개의 Availability Zone에 걸쳐 Public Subnet에 생성합니다. RDS Multi-AZ DB 인스턴스를 Private Subnet에 배포합니다.",
    "SelectC_Commentary": "EC2 인스턴스가 Public Subnet에 위치하여 퍼블릭 인터넷에 노출되므로, 보안 요구사항에 어긋납니다.",
    "SelectD": "하나의 Public Subnet과 하나의 Private Subnet, 그리고 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Public Subnet에 배포합니다.",
    "SelectD_Commentary": "Public Subnet이 단 하나뿐이라 가용 영역을 둘 이상 활용하기 어렵고, 고가용성 구성에 부합하지 않습니다.",
    "SelectE": "두 개의 Public Subnet, 두 개의 Private Subnet, 그리고 두 NAT Gateway를 두 개의 Availability Zone에 구성합니다. Application Load Balancer를 Public Subnet들에 배포합니다.",
    "SelectE_Commentary": "각 AZ에 Public Subnet과 Private Subnet을 모두 두고, ALB를 Public Subnet에 배치해 외부 트래픽을 처리합니다. EC2와 RDS는 Private Subnet에 배치해 인터넷 노출을 방지하면서 NAT Gateway를 통해 필요한 아웃바운드 액세스를 보장합니다. 다중 AZ 구성을 통해 높은 가용성을 달성할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q195",
      "Q67",
      "Q944",
      "Q444",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q390",
      "Q595",
      "Q466"
    ],
    "SelectB_recommedations": [
      "Q708",
      "Q545",
      "Q639"
    ],
    "SelectC_recommedations": [
      "Q466",
      "Q390",
      "Q298"
    ],
    "SelectD_recommedations": [
      "Q708",
      "Q545",
      "Q639"
    ],
    "SelectE_recommedations": [
      "Q545",
      "Q639",
      "Q708"
    ]
  },
  {
    "Question_Number": "Q126",
    "Question_Description": "한 솔루션즈 아키텍트가 회사의 스토리지 비용 절감을 위해 솔루션을 구현해야 합니다. 회사의 모든 데이터는 Amazon S3 Standard 스토리지 클래스로 저장되어 있습니다. 회사는 최소 25년 동안 모든 데이터를 보관해야 합니다. 가장 최근 2년간의 데이터는 높은 가용성과 즉시 검색이 가능해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86731-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "데이터를 2년간은 Amazon S3 Standard로 유지해 즉시 액세스를 보장하고, 이후에는 S3 Glacier Deep Archive로 전환하여 비용을 크게 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "25년 보관",
      "2년 즉시 검색",
      "Amazon S3 Standard",
      "S3 Glacier Deep Archive",
      "스토리지 비용 절감"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Lifecycle policy",
      "S3 Glacier Deep Archive",
      "S3 Intelligent-Tiering",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
    ],
    "SelectA": "객체를 S3 Glacier Deep Archive로 즉시 전환하도록 S3 Lifecycle policy를 설정합니다.",
    "SelectA_Commentary": "즉시 전환 시 2년 동안 필요한 즉시 검색 요구를 충족할 수 없어 부적합합니다.",
    "SelectB": "객체를 2년 후에 S3 Glacier Deep Archive로 전환하도록 S3 Lifecycle policy를 설정합니다.",
    "SelectB_Commentary": "정답. 먼저 2년간 Amazon S3 Standard로 즉시 접근성을 보장하고 이후 장기 보관을 위해 S3 Glacier Deep Archive로 전환해 비용을 절감합니다.",
    "SelectC": "S3 Intelligent-Tiering을 사용합니다. archiving option을 활성화하여 S3 Glacier Deep Archive에 데이터가 보관되도록 합니다.",
    "SelectC_Commentary": "archiving option 활성 시 2년 이내 데이터도 아카이빙될 수 있으므로, 필요한 즉시 검색 요구사항을 충족하기 어렵습니다.",
    "SelectD": "객체를 즉시 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 전환하고, 2년 후에는 S3 Glacier Deep Archive로 전환하도록 S3 Lifecycle policy를 설정합니다.",
    "SelectD_Commentary": "One Zone-IA는 가용성이 낮고, 2년간의 높은 가용성 및 즉시 검색 요구에도 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q769",
      "Q1003",
      "Q606",
      "Q23",
      "Q890"
    ],
    "SelectA_recommedations": [
      "Q912",
      "Q606",
      "Q285"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q606",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q912",
      "Q415",
      "Q356"
    ]
  },
  {
    "Question_Number": "Q127",
    "Question_Description": "한 미디어 회사가 시스템을 AWS 클라우드로 이전하는 방안을 검토하고 있습니다. 회사는 비디오 처리용으로 최대한의 I/O 성능을 제공해야 하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 매우 내구성 있는 스토리지, 그리고 이미 사용되지 않는 아카이브 미디어 보관을 위한 900TB의 스토리지가 필요합니다. 이 요구 사항을 충족하기 위해 솔루션스 아키텍트가 권장해야 할 서비스 조합은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85432-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 각각의 스토리지 요구 사항에 맞춰 가장 적합한 AWS 스토리지 서비스를 선택하는 상황입니다. 높은 I/O 성능을 위해 Instance Store를 활용하고, 내구성이 필요한 300TB는 Amazon S3에 저장하며, 사용하지 않는 900TB 데이터는 S3 Glacier로 아카이빙하는 구성이 최적 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "비디오 처리",
      "최대 I/O 성능",
      "내구성 높은 스토리지",
      "아카이브 스토리지"
    ],
    "Terms": [
      "Amazon EC2 Instance Store",
      "Amazon S3",
      "Amazon S3 Glacier",
      "Amazon EBS",
      "Amazon EFS"
    ],
    "SelectA": "Amazon EBS로 최대 성능을 확보하고, Amazon S3로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현",
    "SelectA_Commentary": "EBS는 상당히 높은 성능을 제공하지만 Instance Store에 비해 최대 I/O 성능이 제한적이라 요구 사항을 최적화하기에 부족합니다.",
    "SelectB": "Amazon EBS로 최대 성능을 확보하고, Amazon EFS로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현",
    "SelectB_Commentary": "EFS는 파일 스토리지로 유연하나 대규모 300TB를 비용 효율적으로 저장하기에는 S3만큼 적합하지 않습니다.",
    "SelectC": "Amazon EC2 Instance Store로 최대 성능을 확보하고, Amazon EFS로 내구성 있는 스토리지를 제공하며, Amazon S3로 아카이브 스토리지 구현",
    "SelectC_Commentary": "Instance Store로 I/O 성능은 충족하나, 900TB의 아카이브 데이터를 S3에만 보관하면 장기 아카이빙 용도에 적합한 Glacier를 활용하지 못합니다.",
    "SelectD": "Amazon EC2 Instance Store로 최대 성능을 확보하고, Amazon S3로 내구성 있는 스토리지를 제공하며, Amazon S3 Glacier로 아카이브 스토리지 구현",
    "SelectD_Commentary": "Instance Store가 EBS 대비 더 높은 최대 I/O 성능을 제공하고, 300TB의 내구성 높은 스토리지로 Amazon S3를 활용하며, 900TB의 장기 보관 데이터는 비용 효율적인 S3 Glacier로 아카이빙하는 가장 적절한 방안입니다.",
    "Question_Description_recommedations": [
      "Q113",
      "Q747",
      "Q331",
      "Q443",
      "Q361"
    ],
    "SelectA_recommedations": [
      "Q173",
      "Q155",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q155",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q910",
      "Q857"
    ],
    "SelectD_recommedations": [
      "Q690",
      "Q155",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q128",
    "Question_Description": "한 회사가 AWS Cloud에서 컨테이너로 애플리케이션을 실행하려고 합니다. 이 애플리케이션들은 stateless하며 기본 인프라의 중단을 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 어떤 방법이 이 요구사항을 충족할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85404-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컨테이너 기반의 애플리케이션을 중단에 견딜 수 있을 만큼 유연하게 설계하고, 동시에 비용과 운영 부담을 줄이는 방법을 묻습니다. Stateless 특성으로 인해 Spot Instances의 중단 위험을 감내할 수 있어 온디맨드 대비 매우 저렴한 비용으로 운영 가능합니다. 따라서 Spot Instances를 사용하는 것이 최적의 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "컨테이너",
      "stateless",
      "중단 견딤",
      "비용 최적화",
      "운영 오버헤드",
      "Spot Instances",
      "On-Demand Instances"
    ],
    "Terms": [
      "Amazon EC2 Auto Scaling group",
      "Amazon EKS",
      "Spot Instances",
      "On-Demand Instances",
      "Managed node group"
    ],
    "SelectA": "Amazon EC2 Auto Scaling group에서 Spot Instances를 사용하여 애플리케이션 컨테이너를 실행합니다.",
    "SelectA_Commentary": "Stateless 애플리케이션 환경에서는 Spot 중단도 쉽게 복구할 수 있어 비용을 크게 줄이고 운영 오버헤드도 최소화할 수 있는 최적의 방법입니다.",
    "SelectB": "Spot Instances를 Amazon Elastic Kubernetes Service(Amazon EKS) managed node group에서 사용합니다.",
    "SelectB_Commentary": "EKS를 사용하면 컨트롤 플레인 및 관리 비용이 추가되어 운영 오버헤드가 증가하므로 요구사항에 비해 비효율적입니다.",
    "SelectC": "Amazon EC2 Auto Scaling group에서 On-Demand Instances를 사용하여 애플리케이션 컨테이너를 실행합니다.",
    "SelectC_Commentary": "On-Demand Instances는 유연하나, Spot 대비 비용이 더 높기 때문에 비용 최소화 목표에 부합하지 않습니다.",
    "SelectD": "On-Demand Instances를 Amazon Elastic Kubernetes Service(Amazon EKS) managed node group에서 사용합니다.",
    "SelectD_Commentary": "On-Demand와 EKS 조합은 비용 절감 효과가 적고, EKS 운영 오버헤드도 추가되어 요구사항을 만족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q728",
      "Q300",
      "Q284",
      "Q985",
      "Q485"
    ],
    "SelectA_recommedations": [
      "Q290",
      "Q937",
      "Q441"
    ],
    "SelectB_recommedations": [
      "Q591",
      "Q937",
      "Q677"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q290",
      "Q505"
    ],
    "SelectD_recommedations": [
      "Q591",
      "Q677",
      "Q1013"
    ]
  },
  {
    "Question_Number": "Q129",
    "Question_Description": "한 회사가 온프레미스 환경에서 멀티 티어 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 컨테이너화되어 있으며, 사용자 레코드를 포함하는 PostgreSQL 데이터베이스와 연결된 여러 Linux 호스트에서 동작합니다. 인프라 유지관리와 용량 계획에 대한 운영 오버헤드가 회사의 성장을 제한하고 있어, 솔루션스 아키텍트는 애플리케이션 인프라를 개선해야 합니다. 이러한 요구사항을 달성하기 위해 솔루션스 아키텍트가 취해야 할 조합은 무엇입니까? (2개를 고르세요.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86658-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "운영 오버헤드와 용량 계획 문제를 해소하려면 완전관리형 서비스로 마이그레이션하는 것이 효과적입니다. Amazon Aurora로 데이터베이스를 이전하면 고가용성 및 확장성을 쉽게 확보할 수 있고, AWS Fargate를 통해 컨테이너 오케스트레이션 환경을 자동으로 관리할 수 있어 인프라 관리 부담이 크게 줄어듭니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "온프레미스",
      "멀티 티어 웹 애플리케이션",
      "컨테이너화",
      "PostgreSQL",
      "사용자 레코드",
      "운영 오버헤드",
      "용량 계획",
      "인프라 개선"
    ],
    "Terms": [
      "Amazon Aurora",
      "AWS Fargate",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon CloudFront",
      "Amazon EC2",
      "Amazon ElastiCache",
      "PostgreSQL"
    ],
    "SelectA": "PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션합니다.",
    "SelectA_Commentary": "Amazon Aurora는 높은 확장성, 관리 편의성을 제공하므로 운영 오버헤드를 줄이고 고가용성을 보장하는 데 적합합니다.",
    "SelectB": "웹 애플리케이션을 Amazon EC2 인스턴스에서 호스팅하도록 마이그레이션합니다.",
    "SelectB_Commentary": "Amazon EC2는 직접 인스턴스를 관리해야 하므로, 인프라 관리 부담이 여전히 남아 문제 개선 효과가 제한적입니다.",
    "SelectC": "웹 애플리케이션 콘텐츠를 위해 Amazon CloudFront 배포를 설정합니다.",
    "SelectC_Commentary": "CloudFront는 전 세계 엣지 로케이션에서 콘텐츠를 캐싱하여 성능을 개선하지만, 근본적인 인프라 운영 오버헤드 문제 해결과 직접적인 연관이 적습니다.",
    "SelectD": "웹 애플리케이션과 PostgreSQL 데이터베이스 사이에 Amazon ElastiCache를 설정합니다.",
    "SelectD_Commentary": "ElastiCache는 데이터 접근 속도를 개선하나, DB 인프라 유지관리 및 용량 계획 오버헤드를 근본적으로 줄이는 데에는 제한적입니다.",
    "SelectE": "AWS Fargate와 Amazon Elastic Container Service(Amazon ECS)를 사용하여 웹 애플리케이션을 호스팅하도록 마이그레이션합니다.",
    "SelectE_Commentary": "AWS Fargate는 서버 관리가 필요 없어 애플리케이션 컨테이너 운영 부담을 최소화하고 자동 확장을 지원하기 때문에 운영 오버헤드를 크게 완화합니다.",
    "Question_Description_recommedations": [
      "Q114",
      "Q914",
      "Q252",
      "Q400",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q601",
      "Q136",
      "Q526"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q149"
    ],
    "SelectD_recommedations": [
      "Q241",
      "Q768",
      "Q824"
    ],
    "SelectE_recommedations": [
      "Q698",
      "Q900",
      "Q303"
    ]
  },
  {
    "Question_Number": "Q130",
    "Question_Description": "어떤 애플리케이션이 여러 Availability Zone에 걸쳐 Amazon EC2 인스턴스에서 실행되고 있으며, 이들 인스턴스는 한 Application Load Balancer 뒤에 위치한 Amazon EC2 Auto Scaling group 내에 있습니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 약 40%일 때 최고의 성능을 발휘합니다. 솔루션스 아키텍트가 Auto Scaling group 내 모든 인스턴스에서 원하는 성능을 유지하기 위해서는 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86659-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션이 특정 CPU 사용률(약 40%)을 유지할 때 가장 효율적이라는 점에 주목하여, Auto Scaling group을 동적으로 조정하는 최적의 방법을 찾는 문제입니다. Target Tracking Scaling은 설정된 지표(여기서는 CPU 사용률)를 기준으로 자동으로 인스턴스 규모를 조정하므로, 정확한 목표 값을 유지하며 성능을 극대화할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "Auto Scaling",
      "CPU 사용률 40%",
      "Application Load Balancer",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Availability Zone",
      "Application Load Balancer",
      "CPU utilization",
      "AWS Lambda",
      "scheduled scaling"
    ],
    "SelectA": "simple scaling policy를 사용하여 Auto Scaling group을 동적으로 확장하도록 설정합니다.",
    "SelectA_Commentary": "simple scaling policy는 한 번의 지표 평가 후 단순 규칙로 확장하거나 축소하지만, CPU 사용률을 일정하게 유지하기에는 유연성이 부족합니다.",
    "SelectB": "target tracking policy를 사용하여 Auto Scaling group을 동적으로 확장하도록 설정합니다.",
    "SelectB_Commentary": "Target Tracking Scaling은 CPU 사용률 목표치를 40%로 설정하면 이를 자동으로 유지하도록 확장/축소를 수행하므로 문제 요구사항에 가장 적합합니다.",
    "SelectC": "AWS Lambda 함수를 사용하여 원하는 Auto Scaling group 용량을 업데이트합니다.",
    "SelectC_Commentary": "Lambda 함수를 통해 직접 용량을 조정하면 추가적인 로직과 관리가 필요하여 실시간 유연 조정에 비효율적입니다.",
    "SelectD": "scheduled scaling을 사용하여 정해진 시간에 Auto Scaling group을 확장 및 축소합니다.",
    "SelectD_Commentary": "스케줄 기반 확장은 CPU 사용률 변동에 실시간 대응이 어려워 필요 시점에 적절한 규모를 유지하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q818",
      "Q461",
      "Q261",
      "Q566",
      "Q335"
    ],
    "SelectA_recommedations": [
      "Q335",
      "Q461",
      "Q674"
    ],
    "SelectB_recommedations": [
      "Q335",
      "Q461",
      "Q674"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q461",
      "Q674"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q461",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q131",
    "Question_Description": "한 회사가 파일 공유 애플리케이션을 개발 중이며, 이 애플리케이션은 Amazon S3 버킷을 스토리지로 사용할 예정입니다. 회사는 모든 파일을 Amazon CloudFront distribution을 통해 제공하고자 합니다. 또한 S3 URL로 직접 접근하는 것을 허용하고 싶지 않습니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85992-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 객체를 직접 URL로 접근할 수 없도록 보호하면서도 CloudFront를 통해 파일을 제공하는 아키텍처를 설계하는 방법을 묻습니다. 가장 효율적이자 권장되는 방식은 CloudFront의 origin access identity(OAI)를 생성하고, 이를 통해서만 S3 버킷에 대한 읽기 권한을 부여하여 S3 URL에 직접 접근이 불가능하게 만드는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "파일 공유 애플리케이션",
      "Amazon S3 버킷",
      "Amazon CloudFront distribution",
      "S3 URL 직접 접근 차단",
      "origin access identity (OAI)"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "origin access identity (OAI)",
      "IAM",
      "S3 Bucket Policy",
      "Principal",
      "Amazon Resource Name (ARN)"
    ],
    "SelectA": "각 S3 버킷에 대해 개별 정책을 작성하고, CloudFront에만 읽기 권한을 부여한다.",
    "SelectA_Commentary": "CloudFront에서 버킷별로 정책을 따로 설정할 수 있지만, 버킷 정책이 복잡해지고 실수 가능성이 커 비효율적입니다.",
    "SelectB": "IAM 사용자를 생성하고, 해당 사용자에게 S3 버킷 객체에 대한 읽기 권한을 부여합니다. 그리고 CloudFront에 이 사용자를 할당합니다.",
    "SelectB_Commentary": "CloudFront가 IAM 사용자 자격 증명을 직접 사용하는 방식은 일반적이지 않으며 보안 및 관리 측면에서도 권장되지 않습니다.",
    "SelectC": "S3 버킷 정책에서 CloudFront distribution ID를 Principal로 지정하고 대상 S3 버킷을 ARN으로 지정합니다.",
    "SelectC_Commentary": "distribution ID만으로는 접근을 완전히 제어하기 어렵고, 추천되는 표준 접근 방식(Origin Access Identity)을 사용하지 않았습니다.",
    "SelectD": "origin access identity (OAI)를 생성하고, 이를 CloudFront distribution에 할당합니다. S3 버킷 권한을 OAI가 읽기 권한을 갖도록만 구성합니다.",
    "SelectD_Commentary": "OAI를 통해 CloudFront만이 S3 버킷에 접근하도록 제한할 수 있어, 직접 S3 URL 접근을 차단하고 안전하게 콘텐츠를 제공하는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q291",
      "Q542",
      "Q202",
      "Q412",
      "Q270"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q825",
      "Q106"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q222",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q131",
      "Q542",
      "Q216"
    ],
    "SelectD_recommedations": [
      "Q542",
      "Q131",
      "Q533"
    ]
  },
  {
    "Question_Number": "Q132",
    "Question_Description": "회사의 웹사이트는 사용자에게 다운로드 가능한 과거 성능 보고서를 제공합니다. 이 웹사이트는 전 세계적으로 확장 가능해야 하며, 비용 효율적이고 인프라 리소스 프로비저닝을 최소화하면서 가능한 한 가장 빠른 응답 시간을 제공해야 합니다. 어떤 솔루션 조합을 사용하면 이 요구사항을 충족할 수 있습니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86654-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 사용자에게 정적 파일을 빠르고 효율적으로 제공하기 위한 최적의 방법을 묻습니다. Amazon CloudFront와 Amazon S3를 조합하면 글로벌 Edge Location을 통한 빠른 전송과 무제한 확장이 가능하여 최소 인프라로도 요구사항을 충족할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "글로벌 확장",
      "정적 콘텐츠",
      "비용 효율",
      "빠른 응답 시간",
      "Amazon CloudFront",
      "Amazon S3"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Amazon S3",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Application Load Balancer",
      "Amazon EC2 Auto Scaling",
      "Amazon Route 53",
      "Internal Application Load Balancer"
    ],
    "SelectA": "Amazon CloudFront와 Amazon S3를 사용합니다.",
    "SelectA_Commentary": "정적 콘텐츠를 S3에 저장하고, CloudFront Edge Location을 통해 글로벌 사용자에게 빠르게 제공할 수 있어 비용과 운영 복잡도를 모두 줄이면서 매우 빠른 응답 시간을 얻을 수 있습니다.",
    "SelectB": "AWS Lambda와 Amazon DynamoDB를 사용합니다.",
    "SelectB_Commentary": "Lambda+DynamoDB는 서버리스 환경이지만 정적 파일 전달에 적합하지 않으며, 대규모 다운로드 트래픽 처리에 불리합니다.",
    "SelectC": "Application Load Balancer와 Amazon EC2 Auto Scaling을 사용합니다.",
    "SelectC_Commentary": "EC2 인스턴스 기반 확장은 정적 콘텐츠 제공에는 불필요하게 복잡하며, S3+CloudFront 대비 비용 효율과 글로벌 가속 측면이 떨어집니다.",
    "SelectD": "Amazon Route 53과 내부 Application Load Balancers를 사용합니다.",
    "SelectD_Commentary": "내부 ALB는 내부 트래픽 처리용으로 적합하며, 전 세계 정적 파일 배포와는 직접적으로 연관이 없습니다.",
    "Question_Description_recommedations": [
      "Q915",
      "Q506",
      "Q888",
      "Q158",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q280",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q472",
      "Q177",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q14",
      "Q141",
      "Q335"
    ],
    "SelectD_recommedations": [
      "Q692",
      "Q530",
      "Q12"
    ]
  },
  {
    "Question_Number": "Q133",
    "Question_Description": "한 회사가 온프레미스에서 Oracle 데이터베이스를 운영하고 있습니다. 회사의 AWS 마이그레이션의 일환으로, 해당 데이터베이스를 최신 버전으로 업그레이드하려고 합니다. 또한 데이터베이스에 대한 재해 복구(DR)도 설정해야 합니다. 회사는 운영 오버헤드를 최소화하면서 데이터베이스 기반 운영 체제에 대한 액세스를 유지하고 싶어 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85423-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스의 Oracle DB를 최신 버전으로 업그레이드함과 동시에 재해 복구 환경을 구축해야 합니다. 운영 오버헤드를 낮추고 OS 접근성을 유지하려면 Amazon RDS Custom for Oracle이 최적이며, 다른 리전에 Read Replica를 생성하면 DR을 쉽고 안정적으로 구성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Oracle 데이터베이스",
      "AWS 마이그레이션",
      "최신 버전 업그레이드",
      "DR",
      "운영 오버헤드",
      "OS 접근",
      "Amazon RDS Custom for Oracle"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS for Oracle",
      "Amazon RDS Custom for Oracle",
      "OS 접근",
      "Read Replica",
      "Cross-Region Automated Backups",
      "Standby Database",
      "DR",
      "온프레미스"
    ],
    "SelectA": "Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하고, 다른 AWS 리전에 데이터베이스 복제를 설정합니다.",
    "SelectA_Commentary": "OS 접근이 가능하나, DR 구성과 패치·백업 등 전반적인 관리 부담이 커서 운영 오버헤드가 증가합니다.",
    "SelectB": "Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션하고, 자동화된 Cross-Region 백업을 활성화하여 다른 AWS 리전으로 스냅샷을 복제합니다.",
    "SelectB_Commentary": "RDS 제공 기능으로 관리 오버헤드는 낮지만, OS 접근 권한을 제공하지 않으므로 요구 사항을 충족하지 못합니다.",
    "SelectC": "Oracle 데이터베이스를 Amazon RDS Custom for Oracle로 마이그레이션하고, 다른 AWS 리전에 데이터베이스의 Read Replica를 생성합니다.",
    "SelectC_Commentary": "RDS Custom은 OS 접근 권한을 허용하며, DR을 위한 Read Replica 구성을 통해 운영 오버헤드를 낮추면서 재해 복구 요건도 충족합니다.",
    "SelectD": "Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션하고, 다른 가용 영역(AZ)에 대기(Standby) 데이터베이스를 생성합니다.",
    "SelectD_Commentary": "Multi-AZ 대기는 같은 리전에 속해 있으므로 광역 재해에 대한 대비가 부족하고, OS 접근 또한 불가능합니다.",
    "Question_Description_recommedations": [
      "Q540",
      "Q163",
      "Q293",
      "Q8",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q133"
    ],
    "SelectB_recommedations": [
      "Q978",
      "Q178",
      "Q518"
    ],
    "SelectC_recommedations": [
      "Q978",
      "Q518",
      "Q629"
    ],
    "SelectD_recommedations": [
      "Q978",
      "Q133",
      "Q629"
    ]
  },
  {
    "Question_Number": "Q134",
    "Question_Description": "한 회사가 애플리케이션을 서버리스 솔루션으로 이전하려고 합니다. 서버리스 솔루션은 기존 및 신규 데이터를 SL을 사용하여 분석해야 합니다. 회사는 Amazon S3 버킷에 데이터를 저장하고 있으며, 이 데이터는 암호화를 필요로 하고, 다른 AWS Region으로 복제되어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85993-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 데이터를 Amazon S3에 두고, 암호화와 Cross-Region 복제를 동시에 충족해야 합니다. 또한 서버리스 방식으로 기존·신규 데이터를 분석하려면 관리 부담이 낮은 Amazon Athena 사용이 적합합니다. SSE-KMS는 추가적인 AWS KMS 설정이 필요해 오버헤드가 크지만, SSE-S3는 자동 관리가 가능해 운영 상 더 간편합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "서버리스 솔루션",
      "기존 및 신규 데이터 분석",
      "암호화",
      "Amazon S3",
      "S3 Cross-Region Replication",
      "SSE-KMS",
      "SSE-S3",
      "Amazon Athena",
      "Amazon RDS"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Cross-Region Replication (CRR)",
      "AWS KMS multi-Region keys (SSE-KMS)",
      "Amazon S3 managed encryption keys (SSE-S3)",
      "Amazon Athena",
      "Amazon RDS"
    ],
    "SelectA": "새로운 S3 버킷을 생성 후 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 AWS KMS multi-Region keys (SSE-KMS)를 사용합니다. Amazon Athena로 데이터를 쿼리합니다.",
    "SelectA_Commentary": "SSE-KMS 구성은 유연하지만 추가 설정이 필요해 운영 오버헤드가 늘어날 수 있습니다. 버킷도 새로 생성해야 하므로 최소 오버헤드 요건에 부합하지 않습니다.",
    "SelectB": "새로운 S3 버킷을 생성 후 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 AWS KMS multi-Region keys (SSE-KMS)를 사용합니다. Amazon RDS로 데이터를 쿼리합니다.",
    "SelectB_Commentary": "이 옵션 역시 SSE-KMS 구성이 필요하고, 분석용으로 RDS를 사용하여 서버 관리를 직접 해야 하므로 서버리스 목표와 어긋납니다.",
    "SelectC": "기존 S3 버킷에 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 Amazon S3 managed encryption keys (SSE-S3)를 사용합니다. Amazon Athena로 데이터를 쿼리합니다.",
    "SelectC_Commentary": "SSE-S3 사용 시 자동 키 관리를 통해 오버헤드가 적으며, Athena는 서버리스로 운영 부담이 낮습니다. Cross-Region Replication도 바로 구성 가능해 요구 사항을 가장 간단히 충족합니다.",
    "SelectD": "기존 S3 버킷에 데이터를 로드합니다. S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. 서버 사이드 암호화로 Amazon S3 managed encryption keys (SSE-S3)를 사용합니다. Amazon RDS로 데이터를 쿼리합니다.",
    "SelectD_Commentary": "SSE-S3는 간편하지만 RDS는 서버리스가 아니기 때문에 관리 오버헤드가 증가하고, Athena만큼 손쉽게 데이터를 분석하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q889",
      "Q965",
      "Q109",
      "Q202",
      "Q696"
    ],
    "SelectA_recommedations": [
      "Q1009",
      "Q36",
      "Q868"
    ],
    "SelectB_recommedations": [
      "Q868",
      "Q889",
      "Q36"
    ],
    "SelectC_recommedations": [
      "Q868",
      "Q889",
      "Q862"
    ],
    "SelectD_recommedations": [
      "Q868",
      "Q889",
      "Q862"
    ]
  },
  {
    "Question_Number": "Q135",
    "Question_Description": "한 회사가 AWS에서 워크로드를 운영하고 있습니다. 외부 공급자의 service에 연결해야 합니다. 해당 service는 공급자의 VPC에 호스팅되어 있습니다. 회사 보안 팀은 연결이 사설로만 이루어져야 하고, 오직 target service에만 한정되어야 한다고 요구합니다. 또한 연결은 오직 회사의 VPC에서만 시작되어야 합니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85994-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 외부 공급자의 VPC에 있는 target service에 대해 사설 연결을 구성해야 하는 상황입니다. VPC Peering은 광범위한 통신을 허용해 보안 요건을 만족하기 어렵고, NAT Gateway는 트래픽이 인터넷을 거쳐 이동하게 됩니다. 따라서 PrivateLink 기반의 VPC Endpoint를 사용하면 특정 service만 사설로 접근할 수 있고, 연결은 오직 회사 VPC에서 시작되므로 요구사항에 부합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "사설 연결",
      "target service 제한",
      "AWS PrivateLink",
      "VPC endpoint",
      "VPC Peering",
      "NAT Gateway"
    ],
    "Terms": [
      "AWS PrivateLink",
      "VPC Peering",
      "NAT Gateway",
      "VPC Endpoint",
      "Virtual Private Gateway"
    ],
    "SelectA": "회사의 VPC와 공급자의 VPC 간에 VPC peering connection을 생성하고, 라우팅 테이블을 수정하여 target service로 연결합니다.",
    "SelectA_Commentary": "VPC Peering은 VPC 간의 양방향 연결을 제공합니다. target service만으로 트래픽을 한정하기 어려우며, 공급자 측에서의 접근 제한도 복잡해집니다.",
    "SelectB": "공급자에게 VPC 내에 virtual private gateway를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 target service에 연결합니다.",
    "SelectB_Commentary": "Virtual private gateway는 일반적으로 site-to-site VPN 용도입니다. PrivateLink를 이용하려면 VPC Endpoint가 필요하며, 이 방식은 잘못된 구성입니다.",
    "SelectC": "회사의 VPC 퍼블릭 서브넷에 NAT Gateway를 생성하고, 라우팅 테이블을 수정하여 target service로 연결합니다.",
    "SelectC_Commentary": "NAT Gateway를 통한 트래픽은 인터넷을 경유하게 됩니다. 이는 사설 연결 및 특정 service만으로 제한한다는 요건을 충족하지 않습니다.",
    "SelectD": "공급자에게 target service에 대한 VPC endpoint를 생성하도록 요청합니다. AWS PrivateLink를 사용하여 target service에 연결합니다.",
    "SelectD_Commentary": "AWS PrivateLink 기반의 VPC Endpoint를 사용하면 오직 지정된 service로만 사설 연결이 이루어지고, 연결이 회사 VPC에서만 시작되도록 보장할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q15",
      "Q151",
      "Q893",
      "Q19"
    ],
    "SelectA_recommedations": [
      "Q135",
      "Q950",
      "Q468"
    ],
    "SelectB_recommedations": [
      "Q135",
      "Q950",
      "Q712"
    ],
    "SelectC_recommedations": [
      "Q135",
      "Q468",
      "Q1016"
    ],
    "SelectD_recommedations": [
      "Q135",
      "Q468",
      "Q151"
    ]
  },
  {
    "Question_Number": "Q136",
    "Question_Description": "한 회사가 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하려고 합니다. 마이그레이션 중에도 온프레미스 데이터베이스는 온라인 상태로 접근 가능해야 합니다. 또한 Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 작업 조합은 무엇입니까? (정답은 두 개를 고르십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85438-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AWS DMS를 사용하면 온프레미스 데이터베이스를 온라인 상태로 유지하면서 Aurora PostgreSQL과 실시간 동기화가 가능합니다. Replication Server를 생성하고 Ongoing Replication Task를 설정해 최소 다운타임으로 마이그레이션할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "온프레미스 PostgreSQL",
      "Amazon Aurora PostgreSQL",
      "AWS DMS",
      "온라인 상태",
      "동기화",
      "마이그레이션"
    ],
    "Terms": [
      "AWS Database Migration Service (AWS DMS)",
      "Ongoing Replication Task",
      "AWS DMS Replication Server",
      "AWS Schema Conversion Tool (AWS SCT)",
      "Amazon EventBridge"
    ],
    "SelectA": "Create an ongoing replication task.",
    "SelectA_Commentary": "DMS에서 지속적인 동기화를 수행하는 핵심 설정입니다. 온라인 상태로 데이터가 계속 복제되어 온프레미스와 Aurora 간 최신 상태를 유지합니다.",
    "SelectB": "Create a database backup of the on-premises database.",
    "SelectB_Commentary": "백업은 단발성 작업이므로 실시간 동기화에는 적합하지 않습니다. 온라인 동작을 위한 지속적 업데이트 기능이 제공되지 않습니다.",
    "SelectC": "Create an AWS Database Migration Service (AWS DMS) replication server.",
    "SelectC_Commentary": "DMS 동작에 필요한 컴퓨팅 리소스로, 원본·타깃 간 실시간 복제를 진행하려면 반드시 구성해야 하는 핵심 요소입니다.",
    "SelectD": "Convert the database schema by using the AWS Schema Conversion Tool (AWS SCT).",
    "SelectD_Commentary": "엔진 유형이 동일(동종 마이그레이션)인 경우 필수적이지 않을 수 있습니다. 필요 시 사용하지만 실시간 동기화 자체에는 영향이 적습니다.",
    "SelectE": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor the database synchronization.",
    "SelectE_Commentary": "EventBridge 규칙은 이벤트 알림용으로, 실시간 데이터 복제를 해주지는 않습니다. 동기화 작업 자체와는 직접 관련이 없습니다.",
    "Question_Description_recommedations": [
      "Q601",
      "Q526",
      "Q25",
      "Q462",
      "Q879"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q584",
      "Q48"
    ],
    "SelectB_recommedations": [
      "Q843",
      "Q512",
      "Q228"
    ],
    "SelectC_recommedations": [
      "Q518",
      "Q843",
      "Q933"
    ],
    "SelectD_recommedations": [
      "Q843",
      "Q768",
      "Q194"
    ],
    "SelectE_recommedations": [
      "Q569",
      "Q768",
      "Q69"
    ]
  },
  {
    "Question_Number": "Q137",
    "Question_Description": "한 회사는 AWS Organizations를 사용하여 각 사업부별로 전용 AWS account를 생성하여, 사업부 계정 요청 시 독립적으로 관리하고 있습니다. 어느 한 계정의 root user email 주소로 전송된 알림을 해당 root 사용자가 놓친 일이 있었고, 회사는 앞으로 모든 알림을 놓치지 않도록 하면서도 이러한 알림이 계정 관리자에게만 제한적으로 전달되기를 원합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85997-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 root user email 주소로 갈 알림을 놓치지 않으면서도, 계정 관리자에게만 이메일이 전달되도록 모범적인 설정 방안을 묻습니다. 각 계정별로 distribution list를 두고 alternate contact를 설정하면, 중요한 알림이 제대로 전달되면서 오남용을 방지할 수 있어 요구사항을 만족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "AWS account",
      "root user email 주소",
      "account administrators",
      "distribution list",
      "alternate contact"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS account",
      "root user email address",
      "account administrators",
      "alternate contacts",
      "distribution list",
      "management account root user"
    ],
    "SelectA": "회사 이메일 서버를 구성하여 AWS account root user email address로 전송되는 알림 이메일을 조직의 모든 사용자에게 전달하도록 설정합니다.",
    "SelectA_Commentary": "알림이 전체 조직에 전달되므로 계정 관리자에게만 제한된 전달이라는 요구사항을 충족하지 못합니다.",
    "SelectB": "모든 AWS account root user email 주소를 몇몇 관리자에게만 전달되는 distribution list로 구성하고, AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS account alternate contacts를 설정합니다.",
    "SelectB_Commentary": "소수 관리자에게만 알림이 전달되고 alternate contact를 통해 추가적으로 관리할 수 있어, 알림 누락 없이 계정 관리자만 확인하도록 제한할 수 있는 가장 적합한 방법입니다.",
    "SelectC": "모든 AWS account root user email 메시지를 한 명의 관리자에게만 보내도록 구성하고, 이 관리자가 알림을 모니터링하여 적절한 그룹에 전달하도록 합니다.",
    "SelectC_Commentary": "단일 관리자에게만 의존하면 알림 누락 위험이 높아지고, 적절한 담당자 구분이 복잡해집니다.",
    "SelectD": "모든 기존 AWS account와 새로 생성되는 계정이 동일한 root user email 주소를 사용하도록 설정합니다. 그리고 AWS Organizations 콘솔 또는 프로그래밍 방식을 통해 AWS account alternate contact를 구성합니다.",
    "SelectD_Commentary": "모든 계정이 동일한 이메일을 사용하면 관리 범위가 과도하게 넓어지고, 계정별 관리자 제한 전달이라는 조건을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q878",
      "Q168",
      "Q945",
      "Q619",
      "Q745"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q745",
      "Q780"
    ],
    "SelectB_recommedations": [
      "Q137",
      "Q233",
      "Q878"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q745",
      "Q137"
    ],
    "SelectD_recommedations": [
      "Q137",
      "Q745",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q138",
    "Question_Description": "한 회사는 AWS 상에서 전자상거래 애플리케이션을 운영하고 있습니다. 새로운 주문이 발생할 때마다 해당 주문은 단일 Availability Zone에서 실행 중인 Amazon EC2 인스턴스의 RabbitMQ queue에 메시지로 게시됩니다. 이 메시지들은 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션이 처리하며, 이 애플리케이션은 정보를 또 다른 EC2 인스턴스에 있는 PostgreSQL database에 저장합니다. 현재 모든 EC2 인스턴스는 동일한 Availability Zone에 있습니다. 회사는 높은 가용성과 최소한의 운영 오버헤드를 제공하도록 아키텍처를 재설계해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85999-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RabbitMQ 메시지 처리와 PostgreSQL database를 사용하는 전자상거래 애플리케이션을 어떻게 고가용성과 낮은 운영 부담으로 재구성할지 묻습니다. Amazon MQ로 마이그레이션하면 Queue 운영 부담을 줄일 수 있고, Database를 Amazon RDS for PostgreSQL Multi-AZ로 이전하면 관리가 간소화되면서도 가용성을 높일 수 있습니다. 따라서 큐와 DB 모두 완전관리형 혹은 최소 관리로 전환해 운영 오버헤드를 최소화하는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "RabbitMQ queue",
      "Amazon MQ",
      "Amazon RDS for PostgreSQL",
      "Multi-AZ",
      "Availability Zone",
      "운영 오버헤드",
      "고가용성",
      "Auto Scaling group",
      "PostgreSQL",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon MQ",
      "RabbitMQ",
      "Auto Scaling group",
      "Multi-AZ",
      "Amazon RDS for PostgreSQL",
      "Amazon EC2",
      "Availability Zone",
      "PostgreSQL"
    ],
    "SelectA": "Amazon MQ에서 RabbitMQ를 active/standby로 구성된 이중화 인스턴스로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. PostgreSQL database를 호스팅하는 다른 EC2 인스턴스에도 Multi-AZ Auto Scaling group을 생성합니다.",
    "SelectA_Commentary": "Database를 직접 EC2에 Multi-AZ로 구성하면 운영 측면에서 여전히 부담이 높습니다.",
    "SelectB": "Amazon MQ에서 RabbitMQ를 active/standby로 구성된 이중화 인스턴스로 마이그레이션합니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. Database를 Multi-AZ Amazon RDS for PostgreSQL로 마이그레이션합니다.",
    "SelectB_Commentary": "큐와 DB 모두 완전관리형 또는 최소한의 관리로 구성해 고가용성과 낮은 운영 오버헤드를 확보하는 최적의 솔루션입니다.",
    "SelectC": "RabbitMQ queue를 호스팅하는 EC2 인스턴스에 Multi-AZ Auto Scaling group을 생성합니다. 애플리케이션을 호스팅하는 다른 EC2 인스턴스에도 Multi-AZ Auto Scaling group을 생성합니다. Database는 Multi-AZ Amazon RDS for PostgreSQL로 마이그레이션합니다.",
    "SelectC_Commentary": "RabbitMQ를 직접 EC2에서 Multi-AZ로 운영하면 관리가 복잡해지고, 오버헤드가 큽니다.",
    "SelectD": "RabbitMQ queue를 호스팅하는 EC2 인스턴스, 애플리케이션을 호스팅하는 EC2 인스턴스, PostgreSQL database를 호스팅하는 EC2 인스턴스 각각에 대해 모두 Multi-AZ Auto Scaling group을 생성합니다.",
    "SelectD_Commentary": "큐와 DB 모두 EC2 기반 Multi-AZ로 구성하면 운영 부담이 크고 관리가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q479",
      "Q434",
      "Q711",
      "Q454",
      "Q288"
    ],
    "SelectA_recommedations": [
      "Q390",
      "Q69",
      "Q935"
    ],
    "SelectB_recommedations": [
      "Q390",
      "Q69",
      "Q958"
    ],
    "SelectC_recommedations": [
      "Q390",
      "Q69",
      "Q874"
    ],
    "SelectD_recommedations": [
      "Q390",
      "Q69",
      "Q874"
    ]
  },
  {
    "Question_Number": "Q139",
    "Question_Description": "보고 팀은 매일 Amazon S3 버킷에 업로드되는 파일들을 수령합니다. 현재는 보고 팀이 매일 같은 시각에 이 초기 S3 버킷에서 파일을 검토하고, Amazon QuickSight에 활용하기 위해 분석용 S3 버킷으로 수동 복사하고 있습니다. 하지만 추가 팀들이 더 많은 용량의 파일들을 초기 S3 버킷으로 전송하기 시작했습니다. 보고 팀은 파일이 초기 S3 버킷에 업로드되는 즉시 자동으로 분석용 S3 버킷에 복사되도록 원합니다. 또한 AWS Lambda 함수를 이용해 복사된 데이터에 대해 패턴 매칭 코드를 실행하고 싶으며, 파일들을 Amazon SageMaker Pipelines에도 전달하기를 원합니다. 최소한의 운영 오버헤드로 이를 만족하려면 어떤 솔루션을 구현해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85872-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "S3 Replication을 사용하면 초기 S3 버킷에서 분석용 S3 버킷으로 파일 복사를 자동화할 수 있어 운영 부담이 크게 줄어듭니다. 또한 분석용 버킷에서의 객체 생성 이벤트를 Amazon EventBridge와 연계하면 Lambda로 패턴 매칭 함수를 호출하고 SageMaker Pipelines로 데이터를 전달할 수 있어 가장 간단하고 확장성이 뛰어납니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "분석용 S3 버킷 자동 복사",
      "AWS Lambda 패턴 매칭",
      "S3 Replication",
      "Amazon SageMaker Pipelines",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Replication",
      "AWS Lambda",
      "Amazon SageMaker Pipelines",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "S3 이벤트 알림",
      "s3:ObjectCreated:Put"
    ],
    "SelectA": "Lambda 함수를 생성하여 파일을 분석용 S3 버킷으로 복사합니다. 분석용 S3 버킷에 S3 이벤트 알림을 설정하고, Lambda와 SageMaker Pipelines를 이벤트 알림 대상으로 구성합니다. 이벤트 유형은 s3:ObjectCreated:Put으로 설정합니다.",
    "SelectA_Commentary": "Lambda로 수동 복사 과정을 대체하지만, 복제 로직을 직접 유지·관리해야 하므로 운영 오버헤드가 높아집니다.",
    "SelectB": "Lambda 함수를 만들어 파일을 분석용 S3 버킷으로 복사합니다. 분석용 S3 버킷에서 Amazon EventBridge(CloudWatch Events)로 이벤트 알림을 보내도록 설정합니다. EventBridge(CloudWatch Events)에 ObjectCreated 규칙을 생성하고, Lambda와 SageMaker Pipelines를 대상으로 구성합니다.",
    "SelectB_Commentary": "A와 마찬가지로 파일 복사를 Lambda가 직접 처리해야 하므로, 코드를 유지·관리하는 부담이 여전히 큽니다.",
    "SelectC": "두 S3 버킷 간에 S3 Replication을 구성합니다. 분석용 S3 버킷에 S3 이벤트 알림을 설정하여 Lambda와 SageMaker Pipelines를 이벤트 대상로 구성하고, 이벤트 유형은 s3:ObjectCreated:Put으로 설정합니다.",
    "SelectC_Commentary": "파일 복사는 자동화되지만 S3 이벤트 알림에서 SageMaker Pipelines를 직접 대상으로 삼기가 번거로울 수 있습니다. 다른 AWS 서비스 중개가 필요해 추가 설정이 늘어날 수 있습니다.",
    "SelectD": "두 S3 버킷 간에 S3 Replication을 구성합니다. 분석용 S3 버킷에서 Amazon EventBridge(CloudWatch Events)로 이벤트 알림을 보내도록 설정합니다. EventBridge(CloudWatch Events)에서 ObjectCreated 규칙을 생성하고, Lambda와 SageMaker Pipelines를 대상으로 구성합니다.",
    "SelectD_Commentary": "S3 Replication으로 파일 복사를 자동화하고, EventBridge로 이벤트를 중앙에서 처리하여 Lambda와 SageMaker Pipelines를 유연하게 호출할 수 있습니다. 운영 오버헤드가 가장 적고 확장성도 뛰어납니다.",
    "Question_Description_recommedations": [
      "Q98",
      "Q636",
      "Q18",
      "Q94",
      "Q404"
    ],
    "SelectA_recommedations": [
      "Q139",
      "Q404",
      "Q18"
    ],
    "SelectB_recommedations": [
      "Q139",
      "Q98",
      "Q636"
    ],
    "SelectC_recommedations": [
      "Q139",
      "Q636",
      "Q18"
    ],
    "SelectD_recommedations": [
      "Q139",
      "Q98",
      "Q636"
    ]
  },
  {
    "Question_Number": "Q140",
    "Question_Description": "한 솔루션스 아키텍트가 AWS 상에서 애플리케이션을 실행하는 비용을 최적화하도록 회사에 조언해야 합니다. 이 애플리케이션은 Amazon EC2, AWS Fargate, AWS Lambda를 사용합니다. EC2 인스턴스는 데이터 수집 계층을 실행하며 사용량이 산발적이고 예측할 수 없습니다. 해당 워크로드는 언제든 중단될 수 있습니다. 애플리케이션의 프런트엔드는 Fargate에서 실행되고, Lambda는 API 계층을 제공합니다. 프런트엔드와 API 계층의 사용량은 향후 1년 동안 예측 가능합니다. 이 애플리케이션을 가장 비용 효율적으로 호스팅하기 위해 어떤 구매 옵션 조합을 사용해야 합니까? (2개를 선택하세요)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 산발적이고 예측 불가능한 워크로드와 예측 가능한 워크로드를 분리해 비용 최적화 전략을 찾는 것입니다. 데이터 수집 계층에는 Spot을 활용하여 비용을 절감하고, 예측 가능한 Fargate와 Lambda에는 Compute Savings Plan을 적용해 최대한 유연성을 확보하면서 비용 효율을 높일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 최적화",
      "EC2",
      "Fargate",
      "Lambda",
      "Spot Instances",
      "Compute Savings Plan"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Fargate",
      "AWS Lambda",
      "Spot Instances",
      "On-Demand Instances",
      "Compute Savings Plan",
      "EC2 instance Savings Plan",
      "All Upfront Reserved Instances"
    ],
    "SelectA": "데이터 수집 계층에 Spot Instances를 사용합니다.",
    "SelectA_Commentary": "Spot Instances는 필요 시 언제든 중단될 수 있는 불규칙적 워크로드에 매우 저렴하게 적합합니다.",
    "SelectB": "데이터 수집 계층에 On-Demand Instances를 사용합니다.",
    "SelectB_Commentary": "On-Demand Instances는 유연하지만 비용이 더 높아, 산발적인 워크로드에는 비효율적입니다.",
    "SelectC": "프런트엔드와 API 계층에 1년 Compute Savings Plan을 구매합니다.",
    "SelectC_Commentary": "Compute Savings Plan은 Fargate, Lambda, 그리고 EC2 모든 서비스에 적용되므로 예측 가능한 워크로드에 효과적입니다.",
    "SelectD": "데이터 수집 계층에 1년 All Upfront Reserved Instances를 구매합니다.",
    "SelectD_Commentary": "Reserved Instances는 예측 불가능한 워크로드에 적합하지 않고, 중단 위험이 큰 환경에서 유연성이 떨어집니다.",
    "SelectE": "프런트엔드와 API 계층에 1년 EC2 instance Savings Plan을 구매합니다.",
    "SelectE_Commentary": "EC2 instance Savings Plan은 EC2 인스턴스에만 적용되어 Fargate와 Lambda에서는 혜택을 받지 못합니다.",
    "Question_Description_recommedations": [
      "Q770",
      "Q417",
      "Q238",
      "Q671",
      "Q715"
    ],
    "SelectA_recommedations": [
      "Q49",
      "Q630",
      "Q767"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ],
    "SelectC_recommedations": [
      "Q885",
      "Q543",
      "Q467"
    ],
    "SelectD_recommedations": [
      "Q49",
      "Q486",
      "Q943"
    ],
    "SelectE_recommedations": [
      "Q885",
      "Q543",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q141",
    "Question_Description": "한 회사가 전 세계 사용자들에게 글로벌 속보, 지역 알림, 날씨 업데이트를 제공하는 웹 기반 포털을 운영합니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합해 각 사용자에게 맞춤화된 화면을 제공합니다. 콘텐츠는 Application Load Balancer(ALB) 뒤에서 동작하는 Amazon EC2 인스턴스 상의 API 서버를 통해 HTTPS로 제공됩니다. 회사는 전 세계 모든 사용자에게 가능한 한 지연 없이 빠른 콘텐츠 제공을 원합니다. 가장 낮은 지연 시간을 보장하기 위해 솔루션스 아키텍트는 애플리케이션을 어떻게 설계해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85439-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 대상으로 개인화된 정적·동적 콘텐츠를 빠르게 제공해야 하는 상황에서, 지연 시간을 최소화하는 네트워크 아키텍처를 설계하는 방법을 묻습니다. Amazon CloudFront는 정적 및 동적 콘텐츠 전송 시 Edge Location을 통해 전 세계 곳곳에서 발생하는 요청에 대해 빠른 응답을 제공합니다. ALB를 직접 오리진으로 두면 동적 콘텐츠도 CloudFront 배포를 통해 캐시 이점과 네트워크 가속을 누릴 수 있어 최소 지연 응답이 가능합니다. 따라서 단일 Region에 배포하고 CloudFront를 활용하는 구성이 가장 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "전 세계 사용자",
      "정적 콘텐츠",
      "동적 콘텐츠",
      "낮은 지연 시간",
      "Application Load Balancer",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "Amazon Route 53",
      "latency routing policy",
      "geolocation routing policy",
      "AWS Region",
      "HTTPS"
    ],
    "SelectA": "AWS 리전 하나에 애플리케이션 스택을 배포하고, ALB를 origin으로 설정한 Amazon CloudFront를 통해 모든 정적 및 동적 콘텐츠를 서빙합니다.",
    "SelectA_Commentary": "전 세계 Edge Location을 활용해 모든 콘텐츠를 빠르고 일관되게 제공하는 최적의 솔루션입니다.",
    "SelectB": "애플리케이션 스택을 두 개의 AWS 리전에 배포하고, Amazon Route 53 latency routing policy를 사용해 가장 가까운 리전의 ALB에서 콘텐츠를 제공하도록 합니다.",
    "SelectB_Commentary": "복수 리전 배포로 글로벌 성능을 높일 수 있지만, 관리 복잡성이 증가하고 CloudFront의 광범위한 캐싱 및 가속 이점을 활용하지 못해 A보다 효율이 낮습니다.",
    "SelectC": "애플리케이션 스택을 단일 AWS 리전에 배포하고, 정적 콘텐츠는 Amazon CloudFront로, 동적 콘텐츠는 ALB에서 직접 서빙합니다.",
    "SelectC_Commentary": "동적 콘텐츠의 지연이 증가할 수 있어 최소 지연을 보장하기 어렵습니다.",
    "SelectD": "애플리케이션 스택을 두 개의 AWS 리전에 배포하고, Amazon Route 53 geolocation routing policy를 사용해 가장 가까운 리전의 ALB에서 모든 콘텐츠를 제공합니다.",
    "SelectD_Commentary": "지리적 정책은 특정 국가 또는 지역별 라우팅에 유용하지만, 네트워크 지연을 최적으로 줄이지 못해 A보다 성능이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q12",
      "Q358",
      "Q272",
      "Q14",
      "Q746"
    ],
    "SelectA_recommedations": [
      "Q358",
      "Q361",
      "Q280"
    ],
    "SelectB_recommedations": [
      "Q12",
      "Q530",
      "Q38"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q631",
      "Q865"
    ],
    "SelectD_recommedations": [
      "Q692",
      "Q530",
      "Q12"
    ]
  },
  {
    "Question_Number": "Q142",
    "Question_Description": "한 게임 회사가 고가용성 아키텍처를 설계하고 있습니다. 애플리케이션은 수정된 Linux 커널에서 동작하며 UDP 기반 트래픽만 지원합니다. 회사는 프론트엔드 계층이 가능한 최고의 사용자 경험을 제공하기를 원합니다. 이 계층은 지연 시간이 낮아야 하며, 가장 가까운 엣지 로케이션으로 트래픽을 라우팅해야 하고, 애플리케이션 엔드포인트에 진입하기 위한 고정 IP 주소를 제공해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86667-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 UDP 트래픽을 지원하는 게임 애플리케이션을 전 세계적으로 빠르고 안정적으로 서비스하기 위해 어떤 프론트엔드 구성을 사용해야 하는지를 묻습니다. AWS Global Accelerator는 UDP 같은 비 HTTP 트래픽에도 최적화되어 있고, 전용 엣지 네트워크를 통해 트래픽을 가장 가까운 리전으로 라우팅하며, 고정 IP 주소를 제공할 수 있어 요구사항을 가장 잘 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.4"
    ],
    "Keywords": [
      "고가용성 아키텍처",
      "UDP 기반 트래픽",
      "지연 시간 최소화",
      "엣지 로케이션",
      "고정 IP 주소",
      "AWS Global Accelerator",
      "Network Load Balancer",
      "Amazon EC2",
      "EC2 Auto Scaling"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon EC2",
      "EC2 Auto Scaling",
      "Network Load Balancer",
      "Application Load Balancer",
      "Amazon Route 53",
      "AWS Lambda",
      "AWS Application Auto Scaling",
      "Amazon API Gateway"
    ],
    "SelectA": "Amazon Route 53을 구성하여 요청을 Application Load Balancer로 포워딩합니다. AWS Lambda를 AWS Application Auto Scaling에서 애플리케이션으로 사용합니다.",
    "SelectA_Commentary": "Application Load Balancer는 HTTP/HTTPS를 주로 처리하고 UDP 트래픽을 직접 지원하지 않으므로 적절하지 않습니다.",
    "SelectB": "Amazon CloudFront를 구성하여 요청을 Network Load Balancer로 포워딩합니다. AWS Lambda를 AWS Application Auto Scaling 그룹에서 애플리케이션으로 사용합니다.",
    "SelectB_Commentary": "CloudFront는 주로 HTTP 기반 콘텐츠 캐싱과 전달에 최적화되어 있어 UDP 트래픽 및 고정 IP 제공 측면에서 부적합합니다.",
    "SelectC": "AWS Global Accelerator를 구성하여 요청을 Network Load Balancer로 포워딩합니다. 애플리케이션에는 EC2 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다.",
    "SelectC_Commentary": "AWS Global Accelerator가 UDP 트래픽, 고정 IP, 지연 시간 최소화를 모두 지원해 가장 적합한 솔루션입니다.",
    "SelectD": "Amazon API Gateway를 구성하여 요청을 Application Load Balancer로 포워딩합니다. 애플리케이션에는 EC2 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다.",
    "SelectD_Commentary": "API Gateway는 REST 또는 WebSocket 등 HTTP 기반 API 호출에 최적화되어 있어 UDP 트래픽에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q352",
      "Q268",
      "Q561",
      "Q819",
      "Q261"
    ],
    "SelectA_recommedations": [
      "Q38",
      "Q692",
      "Q12"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q266",
      "Q38"
    ],
    "SelectC_recommedations": [
      "Q261",
      "Q335",
      "Q358"
    ],
    "SelectD_recommedations": [
      "Q141",
      "Q335",
      "Q597"
    ]
  },
  {
    "Question_Number": "Q143",
    "Question_Description": "한 회사가 기존의 온프레미스 모놀리식(monolithic) 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 회사는 기존 프론트엔드 코드와 백엔드 코드를 최대한 유지하면서, 애플리케이션을 더 작은 규모의 애플리케이션들로 분할하고자 합니다. 각 애플리케이션은 서로 다른 팀에서 관리할 예정입니다. 또한 높은 확장성을 갖추고 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86473-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 모놀리식 애플리케이션을 분할해 각 팀이 관리 가능하도록 마이크로서비스 형태로 전환하면서, 높은 확장성과 낮은 운영 부담을 원하는 시나리오입니다. Amazon ECS를 사용하면 컨테이너로 각각의 서비스를 분리해 관리가 용이하며, Application Load Balancer와 결합해 탄력적인 확장이 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "모놀리식 애플리케이션",
      "AWS 마이그레이션",
      "Amazon ECS",
      "마이크로서비스",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon API Gateway",
      "AWS Amplify",
      "Amazon EC2",
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon Elastic Container Service (Amazon ECS)"
    ],
    "SelectA": "AWS Lambda에서 애플리케이션을 호스팅하고, Amazon API Gateway와 연동합니다.",
    "SelectA_Commentary": "서버리스 환경이지만, 기존 코드를 크게 수정해야 할 수 있고, 모놀리식 구조를 그대로 유지하기에는 Lambda로의 전체 마이그레이션이 복잡할 수 있습니다.",
    "SelectB": "AWS Amplify로 애플리케이션을 호스팅하고, Amazon API Gateway와 연동된 AWS Lambda에 연결합니다.",
    "SelectB_Commentary": "Amplify는 프론트엔드 호스팅에 적합하지만, 이미 완성된 백엔드를 크게 분할하기에는 제약이 많아 전체 요구사항을 만족하기 어렵습니다.",
    "SelectC": "Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. Application Load Balancer와 Auto Scaling group으로 구성합니다.",
    "SelectC_Commentary": "EC2 기반 구성은 직접 서버를 관리해야 하므로 운영 오버헤드가 높으며, 마이크로서비스로 자유롭게 분할하기에도 관리 부담이 큽니다.",
    "SelectD": "Amazon Elastic Container Service(Amazon ECS)에서 애플리케이션을 호스팅합니다. Application Load Balancer를 Amazon ECS 대상 그룹으로 설정합니다.",
    "SelectD_Commentary": "컨테이너 기반으로 각 서비스를 분리해 팀별 관리가 가능하며, ECS가 인프라 관리를 상당 부분 자동화하여 확장성과 운영 편의성을 모두 확보할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q443",
      "Q865",
      "Q568",
      "Q631"
    ],
    "SelectA_recommedations": [
      "Q597",
      "Q576",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q576",
      "Q603"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q261",
      "Q461"
    ],
    "SelectD_recommedations": [
      "Q695",
      "Q358",
      "Q852"
    ]
  },
  {
    "Question_Number": "Q144",
    "Question_Description": "한 회사가 글로벌 eCommerce 애플리케이션의 데이터 스토어로 Amazon Aurora를 사용하기 시작했습니다. 대규모 리포트를 실행할 때 개발자들은 eCommerce 애플리케이션이 성능 저하를 겪고 있다고 보고했습니다. Amazon CloudWatch의 지표를 살펴본 결과, 월간 리포트가 실행될 때 ReadIOPS와 CPUUtilization 지표가 급증한다는 사실을 솔루션스 아키텍트가 확인했습니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86781-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 월간 리포트 실행 시 발생하는 높은 읽기 부하로 인해 Aurora 메인 DB에 성능 저하가 일어나는 상황을 해결하면서도 비용 효율을 달성해야 하는 시나리오입니다. Aurora Replica를 활용하면 보고서 트래픽을 오프로딩해 메인 DB의 부하를 줄이면서 추가적인 인프라나 IOPS 비용을 과도하게 발생시키지 않아, 가장 합리적인 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "글로벌 eCommerce 애플리케이션",
      "Amazon Aurora",
      "월간 리포트",
      "성능 저하",
      "비용 효율",
      "Aurora Replica"
    ],
    "Terms": [
      "Amazon Aurora",
      "Amazon Redshift",
      "Aurora Replica",
      "Amazon CloudWatch",
      "ReadIOPS",
      "CPUUtilization",
      "Provisioned IOPS",
      "DB instance class"
    ],
    "SelectA": "월간 리포팅을 Amazon Redshift로 마이그레이션합니다.",
    "SelectA_Commentary": "데이터 웨어하우스 솔루션이지만 마이그레이션과 운영 복잡도가 높고, 규모에 따라 추가 비용이 발생할 수 있어 가장 비용 효율적이지 않습니다.",
    "SelectB": "월간 리포팅을 Aurora Replica로 마이그레이션합니다.",
    "SelectB_Commentary": "리포트 실행 시 읽기 부하를 Replica로 분산해 메인 DB 성능 저하를 최소화하고, 필요한 만큼만 용량을 확장해 비용 효율을 높입니다.",
    "SelectC": "Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다.",
    "SelectC_Commentary": "즉각적인 성능 향상을 기대할 수 있으나, 인스턴스 비용이 지속해서 증가하여 장기적으로는 비용 효율적이지 않습니다.",
    "SelectD": "Aurora 인스턴스의 Provisioned IOPS를 증가시킵니다.",
    "SelectD_Commentary": "IO 성능은 향상되지만 CPUUtilization 문제는 여전히 남을 수 있으며, 프로비저닝된 IOPS 비용이 높아질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q730",
      "Q238",
      "Q671",
      "Q449",
      "Q196"
    ],
    "SelectA_recommedations": [
      "Q728",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q49"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q145",
    "Question_Description": "한 회사가 웹사이트 분석 애플리케이션을 단일 Amazon EC2 On-Demand Instance에서 호스팅하고 있습니다. 이 분석 소프트웨어는 PHP로 작성되었으며, MySQL 데이터베이스를 사용합니다. PHP를 제공하는 웹 서버와 데이터베이스 서버 모두 EC2 인스턴스 안에 함께 배포되어 있습니다. 현재 애플리케이션은 트래픽이 많은 시간대에 성능 저하와 5xx 오류를 보이고 있으며, 회사는 애플리케이션이 끊김 없이 확장되도록 만들고자 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86474-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 EC2 인스턴스에 모든 구성 요소가 모노리틱하게 배포되어 생기는 확장 한계를 해결하고, 트래픽 급증 시 발생하는 성능 저하와 5xx 오류를 방지하려는 상황입니다. 데이터베이스를 Amazon Aurora MySQL로 분리해 성능을 높이고, Auto Scaling group과 Spot Fleet을 활용하여 무중단으로 인스턴스를 확장·축소함으로써 비용 효율성과 확장성을 동시에 달성하는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "EC2 On-Demand Instance",
      "Amazon Aurora MySQL DB instance",
      "AMI",
      "Auto Scaling group",
      "Spot Fleet",
      "Application Load Balancer",
      "비용 효율",
      "5xx 오류",
      "무중단 확장"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instance",
      "MySQL",
      "Amazon RDS for MySQL",
      "Amazon Aurora MySQL",
      "PHP",
      "Application Load Balancer",
      "AWS Lambda",
      "Amazon CloudWatch alarm",
      "AMIs",
      "Auto Scaling group",
      "Spot Fleet",
      "Amazon Route 53"
    ],
    "SelectA": "데이터베이스를 Amazon RDS for MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션을 AMI로 생성한 뒤 두 번째 EC2 On-Demand Instance를 시작합니다. Application Load Balancer로 각 EC2 인스턴스에 부하를 분산합니다.",
    "SelectA_Commentary": "RDS로 DB를 이전하고 인스턴스를 2대로 늘려도 자동 확장이 어렵고 On-Demand만 이용해 비용 면에서 최적이 아닙니다.",
    "SelectB": "데이터베이스를 Amazon RDS for MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션을 AMI로 생성한 뒤 두 번째 EC2 On-Demand Instance를 시작합니다. Amazon Route 53 가중 라우팅을 사용해 두 EC2 인스턴스 간 트래픽을 분산합니다.",
    "SelectB_Commentary": "가중 라우팅으로 부하를 분산하지만 Auto Scaling 지원이 없어 사용량 증감 시 유연한 확장이 어렵습니다.",
    "SelectC": "데이터베이스를 Amazon Aurora MySQL DB instance로 마이그레이션합니다. AWS Lambda 함수를 작성해 EC2 인스턴스를 정지 후 인스턴스 유형을 변경하도록 합니다. CPU 사용률이 75%를 초과하면 Amazon CloudWatch alarm으로 Lambda 함수를 호출합니다.",
    "SelectC_Commentary": "수동에 가까운 인스턴스 유형 변경 방식이라 실시간 트래픽 증가에 부하 대응이 원활하지 않고 운영 부담이 큽니다.",
    "SelectD": "데이터베이스를 Amazon Aurora MySQL DB instance로 마이그레이션합니다. 웹 애플리케이션 AMI를 생성한 뒤 Launch Template에 적용합니다. 해당 Launch Template로 Auto Scaling group을 구성하고 Spot Fleet을 사용하도록 설정합니다. Application Load Balancer를 Auto Scaling group에 연결합니다.",
    "SelectD_Commentary": "Aurora로 DB를 분리해 성능을 확보하고, Spot Fleet 및 Auto Scaling으로 무중단 확장과 비용 효율을 동시에 달성하는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q824",
      "Q654",
      "Q236",
      "Q935",
      "Q790"
    ],
    "SelectA_recommedations": [
      "Q390",
      "Q933",
      "Q955"
    ],
    "SelectB_recommedations": [
      "Q933",
      "Q444",
      "Q518"
    ],
    "SelectC_recommedations": [
      "Q150",
      "Q923",
      "Q462"
    ],
    "SelectD_recommedations": [
      "Q955",
      "Q69",
      "Q390"
    ]
  },
  {
    "Question_Number": "Q146",
    "Question_Description": "회사는 Application Load Balancer 뒤에 Amazon EC2 On-Demand Instances 그룹에서 무상태 웹 애플리케이션을 프로덕션으로 운영하고 있습니다. 애플리케이션은 매 영업일에 8시간 동안 높은 사용량을 기록하고, 야간에는 보통 수준의 일정한 사용량을 유지하며, 주말에는 낮은 사용량을 보입니다. 회사는 애플리케이션 가용성에 영향을 주지 않으면서 EC2 비용을 최소화하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86750-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 수요가 크게 변동하는 웹 애플리케이션 환경에서 비용을 절감하면서 가용성을 유지하는 방법을 묻습니다. 기본 사용량은 Reserved Instances로 확보하고, 추가 수요는 Spot Instances로 처리함으로써 예측 가능한 운영 비용 절감과 높은 가용성을 모두 달성할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 최소화",
      "애플리케이션 가용성",
      "EC2",
      "Spot Instances",
      "Reserved Instances",
      "On-Demand Instances"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Dedicated Instances",
      "Application Load Balancer",
      "Stateless Web Application"
    ],
    "SelectA": "전체 워크로드를 Spot Instances로 사용합니다.",
    "SelectA_Commentary": "Spot 용량은 회수될 수 있어 가용성을 보장하기 어렵고, 고정적으로 필요한 사용량을 덮기에는 위험도가 높아 적합하지 않습니다.",
    "SelectB": "기본적인 사용량 수준에 대해서는 Reserved Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 Spot Instances를 사용합니다.",
    "SelectB_Commentary": "기본적으로 일정량의 사용량을 안정적으로 확보하면서도 필요 시 Spot Instances로 유연하게 대처하여 비용 최적화와 가용성을 모두 달성할 수 있으므로 적합한 솔루션입니다.",
    "SelectC": "기본적인 사용량 수준에 대해서는 On-Demand Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 Spot Instances를 사용합니다.",
    "SelectC_Commentary": "On-Demand Instances만으로 기본 사용량을 처리하면 비용 절감이 제한적입니다. Reserved Instances보다 상대적으로 비용이 높아 최적의 방법은 아닙니다.",
    "SelectD": "기본적인 사용량 수준에 대해서는 Dedicated Instances를 사용하고, 애플리케이션이 필요한 추가 용량에 대해서는 On-Demand Instances를 사용합니다.",
    "SelectD_Commentary": "Dedicated Instances는 물리적 서버 전용 사용으로 비용이 높아 기본 사용량을 처리하기에 비효율적이며, 전반적인 비용 절감에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q1013",
      "Q473",
      "Q894",
      "Q441",
      "Q1008"
    ],
    "SelectA_recommedations": [
      "Q49",
      "Q630",
      "Q767"
    ],
    "SelectB_recommedations": [
      "Q49",
      "Q767",
      "Q630"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q300",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q728",
      "Q1008"
    ]
  },
  {
    "Question_Number": "Q147",
    "Question_Description": "한 회사에서 중요한 애플리케이션의 로그 파일을 10년 동안 보관해야 합니다. 이 애플리케이션 팀은 최근 1개월 이내의 로그는 자주 문제 해결을 위해 접근하지만, 1개월이 지난 로그는 거의 접근하지 않습니다. 애플리케이션은 매달 10TB 이상의 로그를 생성합니다. 비용 효율성을 최대화하면서 이러한 요구 사항을 충족시키는 스토리지 옵션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86864-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주로 월간 10TB 규모의 방대한 로그를 10년 동안 보존하는 동시에 최근 한 달간은 빈번히 조회되는 특성을 고려한 방법을 묻습니다. S3 Lifecycle policy를 활용하면 오래된 로그를 저비용 스토리지인 S3 Glacier Deep Archive로 자동 전환하여 운영 과정과 비용을 모두 효율화할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "로그 보관",
      "10년 보관",
      "코스트 최적화",
      "한 달 지난 로그",
      "저장 비용"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Backup",
      "S3 Glacier Deep Archive",
      "S3 Lifecycle policy",
      "Amazon CloudWatch Logs"
    ],
    "SelectA": "Amazon S3에 로그를 저장하고, 1개월 지난 로그는 AWS Backup을 사용하여 S3 Glacier Deep Archive로 이동합니다.",
    "SelectA_Commentary": "AWS Backup은 S3 Glacier Deep Archive 직접 전환을 지원하지 않으므로 요구 사항을 충족하기 어렵습니다.",
    "SelectB": "Amazon S3에 로그를 저장하고, S3 Lifecycle policy를 통해 1개월 지난 로그를 S3 Glacier Deep Archive로 이동합니다.",
    "SelectB_Commentary": "S3 Lifecycle policy로 자동 전환을 설정하면 장기 보관 비용이 크게 절감되고 운영 부담도 최소화되어 가장 적합한 솔루션입니다.",
    "SelectC": "Amazon CloudWatch Logs에 로그를 저장하고, 1개월 지난 로그는 AWS Backup을 사용하여 S3 Glacier Deep Archive로 이동합니다.",
    "SelectC_Commentary": "AWS Backup이 CloudWatch Logs에 직접 적용되지 않으며, Glacier Deep Archive 전환을 지원하지 않아 비효율적입니다.",
    "SelectD": "Amazon CloudWatch Logs에 로그를 저장하고, Amazon S3 Lifecycle policy를 사용하여 1개월 지난 로그를 S3 Glacier Deep Archive로 이동합니다.",
    "SelectD_Commentary": "CloudWatch Logs에서 직접 S3 Lifecycle policy를 설정할 수 없으므로 요구 사항을 만족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q49",
      "Q794",
      "Q778",
      "Q583",
      "Q630"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q606",
      "Q911"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q606",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q534",
      "Q943",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q534",
      "Q912",
      "Q227"
    ]
  },
  {
    "Question_Number": "Q148",
    "Question_Description": "한 회사는 다음과 같은 컴포넌트로 구성된 데이터 수집 워크플로우를 사용하고 있습니다:\n1) 새로운 데이터가 도착했을 때 알림을 받는 Amazon Simple Notification Service(Amazon SNS) topic\n2) 데이터를 처리하고 저장하는 AWS Lambda function\n\n해당 워크플로우는 가끔 네트워크 연결 문제로 인해 실패가 발생합니다. 한 번 실패가 발생하면, 회사가 수동으로 작업을 재실행하지 않는 이상 데이터가 수집되지 않습니다. 모든 알림이 최종적으로 처리되도록 하려면 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85424-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 일시적인 네트워크 장애가 발생했을 때도 데이터가 유실되지 않도록 알림을 안정적으로 처리하는 방법에 대한 것입니다. SNS에서 Lambda로 직접 전달이 실패했을 때 재시도 또는 보조 경로가 필요합니다. Amazon SQS 큐를 on-failure 대상(DLQ)으로 구성하면 재처리를 자동화하여 모든 알림이 결국 처리되도록 보장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "네트워크 연결 문제",
      "데이터 수집 실패",
      "모든 알림 최종 처리",
      "on-failure 대상",
      "SQS 큐"
    ],
    "Terms": [
      "Amazon SNS",
      "AWS Lambda",
      "Amazon SQS",
      "on-failure destination",
      "SNS topic’s retry strategy",
      "네트워크 연결 문제"
    ],
    "SelectA": "Lambda function을 여러 가용 영역에 배포하도록 구성합니다.",
    "SelectA_Commentary": "Lambda function 자체의 고가용성을 높이지만, 네트워크 문제로 인한 처리 누락을 막지는 못하므로 적절한 해법이 아닙니다.",
    "SelectB": "Lambda function 설정을 수정하여 CPU와 메모리 할당량을 늘립니다.",
    "SelectB_Commentary": "더 많은 리소스를 할당해도 네트워크 장애로 인해 호출 자체가 실패하면 데이터를 재처리할 방법이 없으므로 효과적이지 않습니다.",
    "SelectC": "SNS topic의 재시도 전략을 구성하여 재시도 횟수와 재시도 간 대기 시간을 늘립니다.",
    "SelectC_Commentary": "일정 횟수 이상 실패 시 장기 보관 및 추후 재처리가 어려울 수 있으므로, 근본적으로 알림을 모아두고 재처리할 보조 경로(DLQ)가 필요합니다.",
    "SelectD": "Amazon Simple Queue Service(Amazon SQS) 큐를 on-failure 대상으로 구성하고, Lambda function이 해당 큐에 있는 메시지를 처리하도록 수정합니다.",
    "SelectD_Commentary": "SNS에서 Lambda 호출이 실패하면 알림이 SQS 큐에 쌓여 재처리할 수 있으므로 결국 모든 알림을 놓치지 않고 처리할 수 있는 가장 안정적인 방법입니다.",
    "Question_Description_recommedations": [
      "Q45",
      "Q98",
      "Q636",
      "Q785",
      "Q489"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q531",
      "Q567"
    ],
    "SelectB_recommedations": [
      "Q785",
      "Q8",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q58",
      "Q187",
      "Q917"
    ],
    "SelectD_recommedations": [
      "Q98",
      "Q636",
      "Q404"
    ]
  },
  {
    "Question_Number": "Q149",
    "Question_Description": "한 회사에는 이벤트 데이터를 생성하는 서비스가 있습니다. 이 회사는 수신되는 즉시 AWS를 통해 이벤트 데이터를 처리하고자 합니다. 데이터는 특정 순서로 작성되며, 이 순서를 처리 전 과정에서 반드시 유지해야 합니다. 회사는 운영 오버헤드를 최소화할 수 있는 솔루션을 구현하고자 합니다. 솔루션스 아키텍트는 이를 어떻게 달성해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86784-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이벤트 데이터가 작성된 순서를 반드시 지켜야 하며 운영을 단순화해야 하는 상황입니다. Amazon SQS FIFO 큐는 메시지 순서를 보장하고, AWS Lambda를 사용하면 서버 관리 없이 메시지를 자동으로 처리할 수 있어 운영 오버헤드가 최소화됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이벤트 데이터",
      "FIFO 큐",
      "메시지 순서 유지",
      "운영 오버헤드 최소화",
      "Lambda"
    ],
    "Terms": [
      "Amazon SQS FIFO queue",
      "Amazon SQS standard queue",
      "Amazon SNS topic",
      "AWS Lambda",
      "메시지 순서 보장"
    ],
    "SelectA": "Amazon Simple Queue Service(Amazon SQS) FIFO 큐를 생성해 메시지를 저장합니다. 그리고 AWS Lambda 함수를 설정해 해당 큐에서 메시지를 처리하도록 합니다.",
    "SelectA_Commentary": "FIFO 큐는 순서를 보장하며, Lambda로 자동 처리하면 운영이 간단해집니다. 정답입니다.",
    "SelectB": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하여 처리할 페이로드를 포함하는 알림을 전송합니다. AWS Lambda 함수를 구독자로 설정합니다.",
    "SelectB_Commentary": "SNS는 메시지 순서 보장이 어렵습니다. 순서 유지가 필수이므로 적합하지 않습니다.",
    "SelectC": "Amazon Simple Queue Service(Amazon SQS) standard 큐를 생성해 메시지를 저장합니다. 그리고 AWS Lambda 함수를 설정해 해당 큐의 메시지를 독립적으로 처리하도록 합니다.",
    "SelectC_Commentary": "standard 큐는 순서를 보장하지 않으므로 이벤트 데이터 순서가 어긋날 수 있습니다.",
    "SelectD": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하여 처리할 페이로드를 포함하는 알림을 전송합니다. 구독자로 Amazon Simple Queue Service(Amazon SQS) 큐를 설정합니다.",
    "SelectD_Commentary": "SNS와 standard 큐 조합은 순서를 강제할 수 없으므로 요구 사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q163",
      "Q802",
      "Q786",
      "Q8",
      "Q519"
    ],
    "SelectA_recommedations": [
      "Q98",
      "Q636",
      "Q203"
    ],
    "SelectB_recommedations": [
      "Q636",
      "Q45",
      "Q148"
    ],
    "SelectC_recommedations": [
      "Q98",
      "Q636",
      "Q203"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q98",
      "Q148"
    ]
  },
  {
    "Question_Number": "Q150",
    "Question_Description": "한 회사가 온프레미스 서버에서 Amazon EC2 인스턴스로 애플리케이션을 마이그레이션 중입니다. 마이그레이션 설계 요구 사항으로, 솔루션스 아키텍트는 인프라 메트릭 알람을 구현해야 합니다. 이 회사는 CPU Utilization이 50%를 짧게 초과하는 상황에는 조치를 취할 필요가 없지만, CPU Utilization이 50%를 초과하고 동시에 디스크의 Read IOPS가 높아지는 경우 즉시 대응해야 합니다. 또한 오탐(거짓 경보)을 줄여야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86034-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 지표를 결합해 오탐을 줄이고 즉시 필요한 상황에만 알람을 받도록 구성하는 방법에 관한 것입니다. CPU가 50%를 넘고 Read IOPS가 동시에 높은 상황을 한 번에 감지해야 하므로, CloudWatch Composite Alarms를 사용해 조건을 결합하고 필요시 한 번에 알람을 보낼 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "CPU Utilization",
      "Read IOPS",
      "오탐 감소",
      "인프라 메트릭 알람"
    ],
    "Terms": [
      "Amazon EC2",
      "CloudWatch Composite Alarms",
      "CloudWatch Dashboards",
      "CloudWatch Synthetics",
      "CloudWatch Metric Alarms",
      "CPU Utilization",
      "read IOPS",
      "on-premises"
    ],
    "SelectA": "Amazon CloudWatch Composite Alarms를 이용해 가능한 곳에서 알람을 생성합니다.",
    "SelectA_Commentary": "Composite Alarms를 사용하면 여러 지표 알람을 결합해 CPU와 디스크 사용이 동시에 높을 때만 알람을 보내므로 오탐을 줄이고 즉각적인 대응이 가능합니다.",
    "SelectB": "Amazon CloudWatch Dashboards를 생성해 지표를 시각화하고 신속히 대응합니다.",
    "SelectB_Commentary": "대시보드를 통해 지표를 직관적으로 파악할 수 있지만, 필요한 알람 메커니즘을 줄여주지는 않아 조건 결합이나 오탐 감소 요구 사항을 충족하지 못합니다.",
    "SelectC": "Amazon CloudWatch Synthetics Canaries를 생성해 애플리케이션을 모니터링하고 알람을 발생시킵니다.",
    "SelectC_Commentary": "Synthetics는 주로 애플리케이션 엔드포인트를 모니터링하는 도구로, 인프라 지표인 CPU, IOPS에 대한 결합 알람에는 적합하지 않습니다.",
    "SelectD": "가능한 곳에서 다중 지표 임계값(single metric alarm)으로 Amazon CloudWatch 알람을 생성합니다.",
    "SelectD_Commentary": "단일 메트릭 알람은 특정 지표 한 가지에 대해서만 동작하므로, 여러 지표를 동시에 모니터링하고 조건이 모두 충족될 때만 알람을 발생시키는 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q923",
      "Q892",
      "Q244",
      "Q757",
      "Q584"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q293",
      "Q869"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q194",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q151",
    "Question_Description": "한 회사가 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 회사의 컴플라이언스 요구사항에 따라, 오직 ap-northeast-3 Region만 사용할 수 있습니다. 또한 VPC를 인터넷에 연결하는 것은 허용되지 않습니다. 이 요구사항을 충족하는 솔루션은 어떤 것입니까? (두 개를 고르십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86475-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 특정 Region 사용과 인터넷 연결을 차단해야 하는 보안 정책 설정 요구사항을 다룹니다. 컴플라이언스 상 ap-northeast-3 Region만 사용할 수 있으며, VPC에서 인터넷 연결이 차단되어야 합니다. 따라서 조직 단위의 강력한 제어(예: SCP)를 통해 Region 접근 및 인터넷 액세스를 막는 방안이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "마이그레이션",
      "컴플라이언스",
      "ap-northeast-3 Region",
      "VPC",
      "인터넷 차단",
      "AWS Control Tower",
      "AWS Organizations"
    ],
    "Terms": [
      "AWS Control Tower",
      "AWS Organizations",
      "Service Control Policies (SCPs)",
      "VPC",
      "Internet Access",
      "ap-northeast-3 Region",
      "Network ACL",
      "IAM Policy",
      "AWS WAF",
      "AWS Config"
    ],
    "SelectA": "AWS Control Tower를 사용하여 data residency guardrails를 구현하고, 인터넷 액세스를 거부하며 ap-northeast-3 이외의 모든 AWS Region에 대한 액세스를 거부합니다.",
    "SelectA_Commentary": "AWS Control Tower를 통해 조직 전반에 걸쳐 Region 제한과 인터넷 차단 정책을 쉽게 구성할 수 있어 요구사항을 충족시키는 올바른 솔루션입니다.",
    "SelectB": "AWS WAF에서 인터넷 액세스를 차단하는 규칙을 사용합니다. AWS 계정 설정에서 ap-northeast-3를 제외한 모든 AWS Region에 대한 액세스를 차단합니다.",
    "SelectB_Commentary": "AWS WAF는 주로 웹 트래픽을 제어하며, Region 전체 사용 제한 기능을 직접 제공하지 않으므로 요구사항을 완전히 만족시키지 못합니다.",
    "SelectC": "AWS Organizations에서 SCP를 구성하여 VPC의 인터넷 액세스를 방지합니다. ap-northeast-3 외 모든 AWS Region에 대한 액세스를 거부합니다.",
    "SelectC_Commentary": "조직 단위의 SCP를 통해 특정 Region 외의 사용을 원천적으로 차단하고, VPC가 인터넷에 연결되지 않도록 통제하여 요구사항을 만족시킵니다.",
    "SelectD": "각 VPC에 대하여 Network ACL의 아웃바운드 규칙으로 0.0.0.0/0로부터의 모든 트래픽을 차단합니다. 각 사용자에 대해 ap-northeast-3 이외의 Region 사용을 막는 IAM Policy를 생성합니다.",
    "SelectD_Commentary": "부분적인 NACL 및 IAM 정책 작업이며, 조직 전체 차원의 강제력이 떨어져 관리가 복잡해질 수 있습니다.",
    "SelectE": "AWS Config를 사용하여 internet gateway를 탐지 및 경고하고, ap-northeast-3 밖에서 생성되는 새 리소스에 대해 탐지 및 경고하는 Managed Rules를 활성화합니다.",
    "SelectE_Commentary": "AWS Config 알림은 사후 감지에 가깝고, 근본적으로 Region 또는 인터넷 연결 자체를 막는 직접적인 제어 기능이 부족합니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q15",
      "Q893",
      "Q19",
      "Q135"
    ],
    "SelectA_recommedations": [
      "Q151",
      "Q667",
      "Q889"
    ],
    "SelectB_recommedations": [
      "Q151",
      "Q165",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q151",
      "Q419",
      "Q3"
    ],
    "SelectD_recommedations": [
      "Q151",
      "Q135",
      "Q494"
    ],
    "SelectE_recommedations": [
      "Q1019",
      "Q151",
      "Q974"
    ]
  },
  {
    "Question_Number": "Q152",
    "Question_Description": "한 회사가 신규 직원 교육을 제공하는 3계층 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 하루에 12시간만 접근되며, Amazon RDS for MySQL DB instance를 사용하여 정보를 저장합니다. 회사는 비용을 최소화하고자 합니다. 이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86046-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용 시간이 제한된 DB instance를 자동으로 중지하여 비용을 절감하는 방법을 찾는 것입니다. AWS Lambda와 EventBridge를 활용한 DB 시작/중지 스케줄링이 AWS 권장 방식이며 운영 오버헤드가 가장 낮습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "비용 절감",
      "시간대별 접근",
      "DB 자동 시작/중지",
      "Lambda",
      "EventBridge"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "AWS Systems Manager Session Manager",
      "Amazon ElastiCache for Redis",
      "Amazon EC2",
      "IAM role",
      "AWS Lambda",
      "Amazon EventBridge",
      "cron job"
    ],
    "SelectA": "AWS Systems Manager Session Manager에 대한 IAM 정책을 구성하고, 해당 정책을 가진 IAM role을 생성해 트러스트 관계를 업데이트합니다. 그리고 DB instance에 대한 자동 시작과 중지를 설정합니다.",
    "SelectA_Commentary": "Session Manager만으로는 DB 인스턴스 자동 스케줄링이 적합하지 않습니다. 자동화 기능을 제대로 지원하지 않아 요구사항을 충족하기 어렵습니다.",
    "SelectB": "Amazon ElastiCache for Redis 캐시 클러스터를 생성해 DB instance가 중지되어도 캐시에서 데이터를 제공하도록 합니다. DB instance가 시작되면 캐시를 무효화합니다.",
    "SelectB_Commentary": "캐시를 사용해도 DB instance 비용 절감을 위한 효율적인 자동 중지/시작 기능을 제공하지 못하며 ElastiCache 추가 비용이 발생합니다.",
    "SelectC": "Amazon EC2 인스턴스를 생성하고, Amazon RDS에 액세스 권한을 부여하는 IAM role을 부착합니다. cron job을 구성해 원하는 일정에 EC2 인스턴스를 통해 RDS를 시작 및 중지합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 별도로 운영해야 하므로 오버헤드가 늘어나고, 단순 자동화에 비해 구성과 유지보수가 복잡합니다.",
    "SelectD": "AWS Lambda 함수를 생성해 DB instance를 시작 및 중지하도록 합니다. Amazon EventBridge(또는 Amazon CloudWatch Events)에서 예약 규칙을 생성해 Lambda 함수를 호출하고, 해당 Lambda 함수를 이벤트 대상로 설정합니다.",
    "SelectD_Commentary": "Lambda와 EventBridge 조합은 DB 인스턴스의 자동 시작/중지를 간단하게 스케줄링해 비용 절감을 최적화하는 AWS 모범 사례입니다.",
    "Question_Description_recommedations": [
      "Q574",
      "Q436",
      "Q579",
      "Q943",
      "Q411"
    ],
    "SelectA_recommedations": [
      "Q380",
      "Q979",
      "Q449"
    ],
    "SelectB_recommedations": [
      "Q380",
      "Q520",
      "Q152"
    ],
    "SelectC_recommedations": [
      "Q380",
      "Q940",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q882",
      "Q800",
      "Q520"
    ]
  },
  {
    "Question_Number": "Q153",
    "Question_Description": "한 회사가 인기 있는 노래의 클립으로 만든 벨소리를 판매하고 있습니다. 이 벨소리 파일들은 Amazon S3 Standard에 저장되어 있으며, 각 파일은 최소 128KB 이상의 크기를 갖습니다. 회사에는 수백만 개의 파일이 있지만, 90일이 지난 벨소리들은 다운로드 빈도가 매우 낮습니다. 회사는 가장 자주 사용되는 파일은 사용자에게 즉시 제공하면서도, 스토리지 비용을 절감해야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하기 위해 어떤 조치를 취해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86933-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 벨소리 파일을 저장할 때 자주 액세스되는 파일은 빠르게 제공하고, 90일 이후에는 다운로드 빈도가 낮아지므로 S3 Standard-Infrequent Access (S3 Standard-IA) 같은 저비용 스토리지로 자동 전환하여 비용을 절감하는 방법에 대한 것입니다. 90일 이전에는 S3 Standard에 두어 자주 액세스되는 파일을 효율적으로 제공하고, 이후에는 S3 Lifecycle Policy를 통해 자동으로 S3 Standard-IA로 이동시켜서 스토리지 비용을 크게 절감할 수 있습니다. 이는 관리 오버헤드를 최소화하고, 자주 사용되는 파일들은 그대로 빠르게 접근 가능하도록 유지하는 데 적합한 솔루션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "벨소리 파일",
      "스토리지 비용 절감",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Intelligent-Tiering",
      "S3 Lifecycle Policy",
      "90일 이후"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Intelligent-Tiering",
      "S3 Lifecycle Policy",
      "S3 inventory"
    ],
    "SelectA": "객체의 초기 스토리지 계층으로 S3 Standard-Infrequent Access(S3 Standard-IA)를 구성합니다.",
    "SelectA_Commentary": "파일이 처음부터 S3 Standard-IA에 있으면 자주 액세스되는 90일 미만 파일에 대한 비용이 더 많이 들 수 있으므로 적절치 않습니다.",
    "SelectB": "파일을 S3 Intelligent-Tiering으로 이동하고, 90일 후에 비용이 더 저렴한 스토리지 계층으로 옮기도록 구성합니다.",
    "SelectB_Commentary": "S3 Intelligent-Tiering 자체도 자동 최적화를 제공하지만, 90일 이후로 액세스가 현저히 낮아지는 패턴이 명확할 경우 S3 Lifecycle Policy가 더 단순하고 비용 면에서도 유리합니다.",
    "SelectC": "S3 inventory를 구성하여 객체를 관리하고, 90일 후에 S3 Standard-Infrequent Access(S3 Standard-IA)로 수동 이동합니다.",
    "SelectC_Commentary": "S3 inventory는 객체 목록을 제공하기 위한 도구이며, 이를 통해 수동으로 객체를 옮기는 것은 관리 작업이 더 많아집니다. 자동화된 Lifecycle Policy가 더 효율적입니다.",
    "SelectD": "S3 Lifecycle 정책을 사용해 90일 후 객체를 S3 Standard에서 S3 Standard-Infrequent Access(S3 Standard-IA)로 이동하도록 합니다.",
    "SelectD_Commentary": "자동으로 90일 이전에는 S3 Standard에 두어 빈번히 사용되는 파일에 빠른 액세스를 제공하고, 90일이 지나면 비용이 저렴한 S3 Standard-IA로 이동시키는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q890",
      "Q66",
      "Q126",
      "Q551",
      "Q759"
    ],
    "SelectA_recommedations": [
      "Q415",
      "Q126",
      "Q23"
    ],
    "SelectB_recommedations": [
      "Q953",
      "Q486",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q415",
      "Q651"
    ]
  },
  {
    "Question_Number": "Q154",
    "Question_Description": "한 회사가 의료 시험 결과를 Amazon S3 저장소에 저장해야 합니다. 이 저장소에는 몇몇 과학자만 새 파일을 추가할 수 있어야 하고, 그 외 모든 사용자는 읽기 전용 권한만 가져야 합니다. 또한 누구도 이미 업로드된 파일을 수정하거나 삭제할 수 없어야 하며, 생성일로부터 최소 1년 동안 모든 파일이 보존되어야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86359-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 의료 시험 결과를 Amazon S3에 안전하게 보관하면서, 특정 사용자만 파일 추가가 가능하고 파일의 수정·삭제는 절대 허용되지 않도록 설계해야 합니다. 생성된 파일을 1년 이상 보관하려면 S3 Object Lock의 Compliance mode를 사용하면 됩니다. Compliance mode는 어떤 사용자든지 Lock을 무시하거나 파일을 삭제할 수 없게 보장하므로 가장 적절한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "1년 보관",
      "파일 수정 삭제 방지",
      "S3 Object Lock",
      "compliance mode",
      "의료 시험 결과",
      "읽기 전용 접근"
    ],
    "Terms": [
      "S3 Object Lock",
      "Governance mode",
      "Compliance mode",
      "Retention period",
      "Legal hold",
      "IAM role",
      "S3 bucket policy",
      "AWS Lambda"
    ],
    "SelectA": "S3 Object Lock을 governance mode로 설정하고 1년간 legal hold를 적용합니다.",
    "SelectA_Commentary": "Governance mode는 관리자 권한을 통해 해제할 수 있어 완전한 불변성을 보장하지 못합니다. 따라서 수정·삭제를 완전히 방지할 수 없습니다.",
    "SelectB": "S3 Object Lock을 compliance mode로 설정하고 보존 기간을 365일로 지정합니다.",
    "SelectB_Commentary": "Compliance mode에서는 어떤 사용자도 Lock을 해제할 수 없어, 파일 수정·삭제가 불가능하며 1년 보존 요구사항도 충족합니다.",
    "SelectC": "특정 IAM role을 사용해 S3 버킷에서 객체 삭제·변경을 제한하고, S3 버킷 정책으로 오직 이 IAM role만을 허용합니다.",
    "SelectC_Commentary": "IAM role과 버킷 정책만으로는 객체에 대한 절대적 보호(수정·삭제 불가)와 보존 기간 강제 기능을 완전히 보장하기 어렵습니다.",
    "SelectD": "S3 버킷에 객체가 추가될 때마다 AWS Lambda 함수를 호출해서 해시를 추적하고, 변경된 객체를 표시하도록 구성합니다.",
    "SelectD_Commentary": "객체 변경 여부만 표시할 뿐, 실제 수정·삭제를 방지하거나 1년 보존을 강제할 수 없기 때문에 요구 사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q825",
      "Q696",
      "Q925",
      "Q44",
      "Q856"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q801",
      "Q740"
    ],
    "SelectB_recommedations": [
      "Q740",
      "Q825",
      "Q678"
    ],
    "SelectC_recommedations": [
      "Q982",
      "Q403",
      "Q477"
    ],
    "SelectD_recommedations": [
      "Q289",
      "Q202",
      "Q270"
    ]
  },
  {
    "Question_Number": "Q155",
    "Question_Description": "한 대형 미디어 회사가 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 회사는 전 세계 사용자가 기밀 미디어 파일을 안정적으로 액세스할 수 있도록 파일을 캐싱하고자 합니다. 컨텐츠는 Amazon S3 버킷에 저장되어 있으며, 지리적 위치에 상관없이 빠른 속도로 데이터를 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/86795-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "글로벌 사용자에게 기밀 콘텐츠를 빠르게 전송하기 위해서는 네트워크 엣지에서 캐싱하여 지연을 최소화하는 것이 핵심입니다. Amazon CloudFront는 분산된 엣지 서버를 통해 전 세계적 저지연 접근을 보장하므로 적합한 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "기밀 미디어 파일",
      "글로벌 캐싱",
      "전 세계 사용자",
      "빠른 콘텐츠 전송"
    ],
    "Terms": [
      "Amazon S3",
      "AWS DataSync",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon Simple Queue Service (Amazon SQS)",
      "CloudFront edge server"
    ],
    "SelectA": "AWS DataSync를 사용하여 S3 버킷을 웹 애플리케이션과 연결합니다.",
    "SelectA_Commentary": "DataSync는 주로 파일 서버 간 대규모 파일 전송을 자동화하는 서비스로, 글로벌 지연을 줄이는 캐싱 솔루션으로는 적합하지 않습니다.",
    "SelectB": "AWS Global Accelerator를 배포하여 S3 버킷을 웹 애플리케이션과 연결합니다.",
    "SelectB_Commentary": "Global Accelerator는 주로 TCP/UDP 트래픽 성능 향상을 위한 서비스이며, 객체 캐싱 기능을 제공하지 않아 미디어 파일 캐시에 부적합합니다.",
    "SelectC": "Amazon CloudFront를 배포하여 S3 버킷을 CloudFront 엣지 서버와 연결합니다.",
    "SelectC_Commentary": "글로벌 엣지에서 파일을 캐싱하여 지연을 최소화하고, 사용자가 어디서 요청하든 빠른 미디어 제공이 가능합니다. 정답입니다.",
    "SelectD": "Amazon Simple Queue Service (Amazon SQS)를 사용하여 S3 버킷을 웹 애플리케이션과 연결합니다.",
    "SelectD_Commentary": "SQS는 메시지 큐 서비스로, 캐싱 기능이나 콘텐츠 전송 가속 기능을 제공하지 않습니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q547",
      "Q672",
      "Q501",
      "Q43"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q292",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q687",
      "Q501",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q501",
      "Q38"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q680",
      "Q292"
    ]
  },
  {
    "Question_Number": "Q156",
    "Question_Description": "한 회사는 여러 데이터베이스에서 생성되는 배치 데이터와 네트워크 센서 및 애플리케이션 API에서 오는 실시간 스트림 데이터를 모두 다룹니다. 회사는 이 모든 데이터를 하나의 위치에 통합하여 비즈니스 분석을 수행해야 합니다. 들어오는 데이터를 처리한 후 여러 Amazon S3 버킷에 단계별로 저장해야 하며, 이후 팀이 일회성 쿼리를 실행하고 해당 데이터를 비즈니스 인텔리전스 도구로 가져와 KPI(주요 성과 지표)를 시각화하려고 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하려면 다음 중 어떤 조합을 선택해야 합니까? (두 가지를 고르시오.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/85770-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다양한 소스에서 들어오는 배치 및 실시간 데이터를 효율적으로 처리하고 Amazon S3에 저장해 향후 분석에 활용하는 방법을 묻습니다. 정답 선택지들은 최소한의 관리 부담으로 데이터 레이크를 구성하고, 일회성 쿼리와 대시보드 생성을 손쉽게 지원하는 데 초점을 둡니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "배치 데이터",
      "실시간 스트림 데이터",
      "비즈니스 분석",
      "Amazon S3",
      "일회성 쿼리",
      "비즈니스 인텔리전스(KPI)",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Athena",
      "Amazon QuickSight",
      "Kinesis Data Analytics",
      "AWS Lambda",
      "Amazon Redshift",
      "AWS Glue",
      "ETL",
      "JSON",
      "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "AWS Lake Formation",
      "Crawler",
      "Apache Parquet",
      "Operational Overhead"
    ],
    "SelectA": "Amazon Athena로 일회성 쿼리를 실행하고, Amazon QuickSight로 KPI 대시보드를 생성합니다.",
    "SelectA_Commentary": "서버리스 방식의 Athena로 스키마 없는 쿼리를 수행하고, QuickSight를 통해 시각화할 수 있어 운영 오버헤드를 크게 줄일 수 있으므로 적합합니다.",
    "SelectB": "Amazon Kinesis Data Analytics로 일회성 쿼리를 실행하고, Amazon QuickSight로 KPI 대시보드를 생성합니다.",
    "SelectB_Commentary": "Kinesis Data Analytics는 스트리밍 데이터 실시간 분석에 최적화된 서비스로, 일회성 쿼리에 사용하기에는 오버헤드가 더 높아 맞지 않습니다.",
    "SelectC": "각 데이터베이스의 개별 레코드를 사용자 정의 AWS Lambda 함수로 가져와 Amazon Redshift 클러스터로 전송합니다.",
    "SelectC_Commentary": "Lambda 함수를 직접 작성해 Redshift로 매번 전송하면 관리 및 코드 유지가 복잡해져서 운영 오버헤드가 증가하므로 비효율적입니다.",
    "SelectD": "AWS Glue ETL 작업을 사용하여 데이터를 JSON 형식으로 변환한 뒤, 여러 Amazon OpenSearch Service(Amazon Elasticsearch Service) 클러스터에 로드합니다.",
    "SelectD_Commentary": "OpenSearch Service를 분석 기본 대상으로 사용하는 것은 로그 검색 등 특수 케이스에 적합하며, 여기서는 BI 도구로의 연계와 운영 간소화 측면에서 부적합합니다.",
    "SelectE": "AWS Lake Formation의 블루프린트를 사용해 가져올 수 있는 데이터를 식별하고, AWS Glue를 사용해 소스를 크롤링하여 데이터를 추출한 뒤 Apache Parquet 형식으로 Amazon S3에 적재합니다.",
    "SelectE_Commentary": "Lake Formation과 Glue를 이용해 데이터 레이크를 쉽게 구성하고, Parquet 형식으로 S3에 저장하여 쿼리와 시각화를 위한 기반을 마련하므로 운영 오버헤드가 낮습니다.",
    "Question_Description_recommedations": [
      "Q2",
      "Q302",
      "Q173",
      "Q547",
      "Q1015"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q156",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q156",
      "Q402"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q557",
      "Q631"
    ],
    "SelectD_recommedations": [
      "Q103",
      "Q117",
      "Q695"
    ],
    "SelectE_recommedations": [
      "Q812",
      "Q214",
      "Q687"
    ]
  },
  {
    "Question_Number": "Q157",
    "Question_Description": "한 회사가 Amazon Aurora PostgreSQL DB 클러스터에 데이터를 저장하고 있습니다. 이 회사는 모든 데이터를 5년 동안 보관해야 하며, 5년 후에는 모든 데이터를 삭제해야 합니다. 또한 데이터베이스 내에서 수행되는 작업에 대한 감사 로그(audit logs)를 무기한으로 보관해야 합니다. 현재 회사는 Aurora에 대해 자동 백업을 구성해 두었습니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계를 결합해서 수행해야 합니까? (2개를 선택하세요.)",
    "Answer": "D,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87629-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 5년 동안의 데이터 보존과 만료 시 삭제, 그리고 감사 로그를 무기한 보관해야 하는 요구사항을 동시에 충족하는 방법을 묻습니다. Aurora의 자동 백업 보존 기간은 최대 35일로 제한되므로, 장기 보관을 위해서는 AWS Backup을 사용해야 합니다. 또한 감사 로그는 Amazon CloudWatch Logs로 내보내어 무기한으로 저장할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "DB 클러스터 데이터 5년 보관",
      "무기한 감사 로그",
      "Amazon Aurora PostgreSQL",
      "AWS Backup",
      "CloudWatch Logs export"
    ],
    "Terms": [
      "Amazon Aurora PostgreSQL",
      "자동 백업(automated backups)",
      "manual snapshot",
      "AWS Backup",
      "Amazon CloudWatch Logs export",
      "lifecycle policy"
    ],
    "SelectA": "DB cluster에 대한 manual snapshot을 생성합니다.",
    "SelectA_Commentary": "수동 스냅샷은 필요 시점마다 따로 생성해야 하므로, 5년 동안 자동으로 보관·삭제를 관리하기 어렵습니다.",
    "SelectB": "자동 백업에 대해 lifecycle policy를 생성합니다.",
    "SelectB_Commentary": "Aurora 자동 백업의 최대 보존 기간은 35일이므로 5년 보관 요구사항을 충족할 수 없습니다.",
    "SelectC": "자동화된 백업 보존(backup retention)을 5년으로 설정합니다.",
    "SelectC_Commentary": "Aurora 자동 백업은 보존 기간 상한이 35일이므로 5년 보관 설정은 불가능합니다.",
    "SelectD": "DB cluster에 대한 Amazon CloudWatch Logs export를 구성합니다.",
    "SelectD_Commentary": "CloudWatch Logs를 통해 감사 로그를 무기한 보관할 수 있으므로 로그 보관 요구사항을 충족합니다.",
    "SelectE": "AWS Backup을 사용하여 백업을 수행하고, 5년 동안 해당 백업을 보관합니다.",
    "SelectE_Commentary": "AWS Backup을 이용하면 백업을 장기간(5년) 자동으로 보관하고, 만료 시 자동 삭제도 지원합니다.",
    "Question_Description_recommedations": [
      "Q733",
      "Q336",
      "Q854",
      "Q279",
      "Q994"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q893",
      "Q106"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q122",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q189",
      "Q204",
      "Q678"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q233",
      "Q893"
    ],
    "SelectE_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ]
  },
  {
    "Question_Number": "Q158",
    "Question_Description": "한 솔루션스 아키텍트가 곧 열릴 음악 이벤트를 위해 웹사이트를 최적화하고 있습니다. 공연 영상은 실시간 스트리밍된 후 주문형으로도 제공될 예정입니다. 이번 이벤트는 전 세계 온라인 시청자를 끌어모을 것으로 예상됩니다. 실시간과 주문형 스트리밍 모두의 성능을 향상하려면 어떤 서비스를 사용해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87514-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계적으로 시청되는 실시간 및 주문형 스트리밍 영상의 전달 속도와 품질을 높이기 위한 방안을 묻습니다. 라이브 스트리밍과 VOD 모두 HTTP 기반으로 제공되므로, 글로벌 CDN 기능을 갖춘 Amazon CloudFront가 가장 효율적이며 빠른 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "전 세계 온라인 시청자",
      "실시간 스트리밍",
      "주문형 스트리밍",
      "Amazon CloudFront",
      "성능 최적화"
    ],
    "Terms": [
      "Amazon CloudFront",
      "AWS Global Accelerator",
      "Amazon Route 53",
      "Amazon S3 Transfer Acceleration",
      "VOD (Video on Demand)",
      "실시간 스트리밍"
    ],
    "SelectA": "Amazon CloudFront",
    "SelectA_Commentary": "Amazon CloudFront는 전 세계 엣지 로케이션을 통해 실시간 및 주문형 스트리밍을 빠르고 안정적으로 전달합니다. HTTP 프로토콜을 활용한 라이브와 VOD 서비스 모두에 적합하여 성능 향상에 최적입니다.",
    "SelectB": "AWS Global Accelerator",
    "SelectB_Commentary": "AWS Global Accelerator는 주로 UDP 기반 서비스를 포함한 비-HTTP 애플리케이션 또는 고정 IP가 필요한 HTTP 트래픽에 적합합니다. 단순 스트리밍 속도 개선 목적에는 CloudFront보다 최적이 아닙니다.",
    "SelectC": "Amazon Route 53",
    "SelectC_Commentary": "Amazon Route 53은 주로 DNS 라우팅 서비스로, 사용자가 가장 가까운 리소스로 연결되도록 돕지만 CDN 기능은 제공하지 않습니다. 스트리밍의 직접적인 품질 향상에는 한계가 있습니다.",
    "SelectD": "Amazon S3 Transfer Acceleration",
    "SelectD_Commentary": "Amazon S3 Transfer Acceleration은 S3 버킷으로 객체를 업로드할 때 전송 속도를 높이기 위한 기능입니다. 스트리밍 자체의 속도와 품질 개선에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q888",
      "Q132",
      "Q915",
      "Q506",
      "Q278"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q361",
      "Q443"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q443",
      "Q631"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q38",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q501",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q159",
    "Question_Description": "한 회사가 Amazon API Gateway와 AWS Lambda를 사용해 외부에 공개된 Serverless 애플리케이션을 운영하고 있습니다. 최근 트래픽이 봇넷에서 발생하는 악의적인 요청 때문에 급증했습니다. 솔루션스 아키텍트는 무단 사용자 요청을 차단하기 위해 어떤 단계를 수행해야 합니까? (2개를 고르세요)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87516-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 봇넷으로부터 발생하는 악의적인 요청을 효과적으로 차단하고, 합법적인 사용자의 정상 트래픽만 처리하기 위한 보안 전략에 대한 내용입니다. AWS WAF를 사용하면 미리 정의된 룰셋을 통해 의심스러운 요청이나 악의적인 요청을 자동으로 식별 후 차단할 수 있고, API Key를 통한 Usage Plan 설정으로 인증되지 않은 사용자의 접근을 제한할 수 있습니다. 이 두 가지 방법을 결합하면 서버리스 애플리케이션을 무단 접근으로부터 보다 안전하게 보호할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "API Gateway",
      "AWS Lambda",
      "AWS WAF",
      "API Key",
      "봇넷"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "AWS WAF",
      "Usage Plan",
      "API Key",
      "Private API"
    ],
    "SelectA": "진짜 사용자들과만 공유되는 API Key를 포함한 Usage Plan을 생성합니다.",
    "SelectA_Commentary": "API Key를 이용하면 무단 사용자는 요청을 보낼 수 없어 트래픽을 필터링할 수 있습니다. 완벽한 보안은 아니지만 인증 체계를 강화하는데 유효하므로 정답입니다.",
    "SelectB": "AWS Lambda 함수 내부 로직을 통해 악성 IP 주소에서 오는 요청을 무시하도록 만듭니다.",
    "SelectB_Commentary": "Lambda 함수 내부에서 동적으로 IP를 식별하고 차단하는 것은 관리와 유지보수가 복잡하므로 비효율적입니다. 올바른 접근 방법이 아닙니다.",
    "SelectC": "AWS WAF 룰을 구현하여 악의적인 요청을 식별하고 필터링하는 액션을 트리거합니다.",
    "SelectC_Commentary": "AWS WAF로 봇넷 악의적 트래픽을 지능적으로 차단할 수 있어 정답입니다.",
    "SelectD": "기존의 Public API를 Private API로 변경하고 DNS 레코드를 새 API 엔드포인트로 리다이렉션합니다.",
    "SelectD_Commentary": "Private API로 변경하면 내부 네트워크용 엔드포인트가 되어 원하는 접근 차단이 가능하나, 이미 공개 애플리케이션이라면 구조가 크게 바뀌어 운영 복잡성이 증가합니다.",
    "SelectE": "API에 접근하려는 각 사용자별로 IAM 역할을 생성하고, API 호출 시 해당 역할을 할당하도록 합니다.",
    "SelectE_Commentary": "IAM 역할은 사용자 권한 위임 구조로, 외부 무단 요청 차단과 직접적인 연관이 없으며 복잡성만 높아집니다.",
    "Question_Description_recommedations": [
      "Q936",
      "Q791",
      "Q34",
      "Q428",
      "Q1019"
    ],
    "SelectA_recommedations": [
      "Q34",
      "Q106",
      "Q44"
    ],
    "SelectB_recommedations": [
      "Q936",
      "Q791",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q165",
      "Q313",
      "Q831"
    ],
    "SelectD_recommedations": [
      "Q571",
      "Q468",
      "Q34"
    ],
    "SelectE_recommedations": [
      "Q429",
      "Q476",
      "Q34"
    ]
  },
  {
    "Question_Number": "Q160",
    "Question_Description": "한 전자상거래 회사가 AWS Cloud에서 애널리틱스 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 매달 약 300MB의 데이터를 생성합니다. 데이터는 JSON 형식으로 저장됩니다. 회사는 재해 복구 솔루션을 검토 중이며, 데이터를 백업하려고 합니다. 필요 시 밀리초(ms) 이내로 액세스가 가능해야 하고, 데이터는 30일간 보관되어야 합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87632-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 짧은 보존 기간(30일) 동안 밀리초 단위로 데이터를 즉시 가져와야 하며 비용 최적화도 고려해야 합니다. Amazon S3 Standard는 즉시 액세스가 가능하고 저렴한 비용 구조를 제공해 요구사항에 가장 부합하는 솔루션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "전자상거래",
      "매달 300MB",
      "JSON",
      "밀리초(ms) 이내 액세스",
      "30일 보관",
      "비용 효율"
    ],
    "Terms": [
      "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
      "Amazon S3 Glacier",
      "Amazon S3 Standard",
      "Amazon RDS for PostgreSQL"
    ],
    "SelectA": "Amazon OpenSearch Service (Amazon Elasticsearch Service)",
    "SelectA_Commentary": "데이터를 실시간 분석하기에는 유리하지만, 백업 목적에는 비용과 운영 부담이 더 클 수 있습니다.",
    "SelectB": "Amazon S3 Glacier",
    "SelectB_Commentary": "저장 비용은 저렴하지만 밀리초 단위 액세스가 불가능하여 요구사항을 만족하지 못합니다.",
    "SelectC": "Amazon S3 Standard",
    "SelectC_Commentary": "밀리초 이내로 즉시 액세스가 가능하고 30일 보관에도 적절한 비용 모델로 최적의 솔루션입니다.",
    "SelectD": "Amazon RDS for PostgreSQL",
    "SelectD_Commentary": "관계형 데이터베이스로 JSON 백업을 관리하기에는 비용과 관리가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q153",
      "Q606",
      "Q890",
      "Q285",
      "Q66"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q238",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q23",
      "Q415",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q436",
      "Q940",
      "Q579"
    ]
  },
  {
    "Question_Number": "Q161",
    "Question_Description": "한 회사는 JSON 문서를 처리하고 그 결과를 온프레미스 SQL 데이터베이스에 저장하는 소규모 Python 애플리케이션을 보유하고 있습니다. 이 애플리케이션은 하루에도 수천 번 실행됩니다. 회사는 이 애플리케이션을 AWS Cloud로 이전하여 높은 가용성을 보장하고 확장성을 극대화하며 운영 오버헤드를 최소화할 수 있는 솔루션을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87633-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 JSON 문서를 하루 수천 회 처리하는 애플리케이션을 AWS 환경으로 이전할 때, 고가용성과 확장성, 운영 부담 최소화를 달성하는 방안을 묻습니다. S3 이벤트를 트리거로 Lambda를 활용해 자동으로 확장하고, 결과를 Amazon Aurora에 저장하는 서버리스 방식을 사용하는 B가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Python 애플리케이션",
      "JSON 문서 처리",
      "운영 오버헤드 최소화",
      "고가용성",
      "확장성",
      "Amazon S3",
      "AWS Lambda",
      "Amazon Aurora"
    ],
    "Terms": [
      "Python",
      "JSON",
      "Amazon S3",
      "AWS Lambda",
      "Amazon Aurora DB cluster",
      "Amazon EC2",
      "Amazon EBS",
      "EBS Multi-Attach",
      "Amazon RDS",
      "Amazon SQS",
      "Amazon ECS",
      "Container"
    ],
    "SelectA": "JSON 문서를 Amazon S3 bucket에 저장합니다. 여러 Amazon EC2 instance에서 Python 코드를 실행하여 문서를 처리합니다. 결과를 Amazon Aurora DB cluster에 저장합니다.",
    "SelectA_Commentary": "EC2 인스턴스를 직접 운영하면 스케일링과 장애 관리를 별도로 해야 하므로 운영 오버헤드가 증가합니다.",
    "SelectB": "JSON 문서를 Amazon S3 bucket에 저장합니다. AWS Lambda 함수를 만들어 S3 버킷으로 문서가 전송될 때 Python 코드를 실행하여 처리하도록 합니다. 처리 결과는 Amazon Aurora DB cluster에 저장합니다.",
    "SelectB_Commentary": "S3 이벤트가 Lambda를 자동 트리거하여 확장성과 가용성을 극대화하고, 운영 부담을 최소화하는 서버리스 구성이므로 정답입니다.",
    "SelectC": "JSON 문서를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. EBS Multi-Attach 기능을 이용해 여러 Amazon EC2 instance에 볼륨을 연결합니다. EC2 인스턴스에서 Python 코드를 실행하여 문서를 처리하고 결과를 Amazon RDS DB instance에 저장합니다.",
    "SelectC_Commentary": "EBS를 직접 관리해야 하며 EC2 인스턴스 운영도 필요해 운영 오버헤드가 큽니다.",
    "SelectD": "JSON 문서를 Amazon SQS 큐에 메시지 형태로 저장합니다. Python 코드를 컨테이너로 묶어 Amazon ECS(EC2 런치 타입)에 배포하고, 컨테이너가 SQS 메시지를 처리합니다. 결과는 Amazon RDS DB instance에 저장합니다.",
    "SelectD_Commentary": "SQS와 ECS는 확장성은 좋지만 Lambda 기반 서버리스 방안보다 운영 관리 측면에서 복잡성이 더 높습니다.",
    "Question_Description_recommedations": [
      "Q513",
      "Q114",
      "Q1014",
      "Q94",
      "Q914"
    ],
    "SelectA_recommedations": [
      "Q161",
      "Q194",
      "Q236"
    ],
    "SelectB_recommedations": [
      "Q161",
      "Q94",
      "Q18"
    ],
    "SelectC_recommedations": [
      "Q125",
      "Q944",
      "Q874"
    ],
    "SelectD_recommedations": [
      "Q161",
      "Q67",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q162",
    "Question_Description": "한 회사가 금융 리스크 모델링을 위해 AWS에서 고성능 컴퓨팅(HPC) 인프라를 사용하려고 합니다. 회사의 HPC 워크로드는 Linux에서 실행되며, 각 HPC 워크플로우는 수백 대의 Amazon EC2 Spot 인스턴스에서 짧게 구동되고, 최종적으로 분석 및 장기 보관을 위해 영구 스토리지에 저장되는 수천 개의 출력 파일을 생성합니다. 회사는 모든 EC2 인스턴스에서 처리할 수 있도록 온프레미스 데이터를 장기 영구 스토리지로 복사하며, 데이터셋과 출력 파일을 읽고 쓸 수 있는 고성능 파일 시스템으로 통합된 클라우드 스토리지 솔루션을 원합니다. 이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87634-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 대의 Linux 기반 EC2 Spot 인스턴스를 사용해 대규모 HPC 워크로드를 처리하고, 결과를 영구 스토리지로 안전하게 보존하는 고성능 파일 시스템 구성을 찾는 것입니다. HPC 환경에서는 Lustre 파일 시스템이 고성능 병렬 I/O 처리를 지원하므로, Amazon S3와 연동되는 Amazon FSx for Lustre가 가장 적합한 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2"
    ],
    "Keywords": [
      "HPC",
      "금융 리스크 모델링",
      "EC2 Spot Instances",
      "고성능 파일 시스템",
      "영구 스토리지"
    ],
    "Terms": [
      "Amazon FSx for Lustre",
      "Amazon S3",
      "Amazon FSx for Windows File Server",
      "Amazon EBS",
      "Amazon S3 Glacier",
      "VPC Endpoint"
    ],
    "SelectA": "Amazon FSx for Lustre를 Amazon S3와 통합해 사용합니다.",
    "SelectA_Commentary": "Linux 기반 HPC 워크로드에서 Lustre 파일 시스템은 고성능 병렬 I/O를 지원하며, S3와 연동해 결과 파일을 영구적으로 저장할 수 있어 요구 사항에 부합합니다.",
    "SelectB": "Amazon FSx for Windows File Server를 Amazon S3와 통합해 사용합니다.",
    "SelectB_Commentary": "Windows 환경에 최적화된 파일 시스템으로, Linux 기반 HPC 워크로드에 적합하지 않으며 높은 병렬 처리를 위한 Lustre의 장점을 살릴 수 없습니다.",
    "SelectC": "Amazon S3 Glacier를 Amazon EBS와 통합해 사용합니다.",
    "SelectC_Commentary": "S3 Glacier는 아카이빙 용도로 저비용 장기 보관에 적합하지만, HPC 환경에서 즉시 고성능 파일 접근이 어려워 부적합합니다.",
    "SelectD": "Amazon S3 버킷에 VPC Endpoint를 연결하고 Amazon EBS General Purpose SSD(gp2) 볼륨과 통합해 사용합니다.",
    "SelectD_Commentary": "EBS 볼륨과 S3만으로는 Lustre와 같은 HPC 전용 파일 시스템의 고성능 병렬 I/O 기능을 구현하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q857",
      "Q646",
      "Q795",
      "Q976",
      "Q369"
    ],
    "SelectA_recommedations": [
      "Q407",
      "Q501",
      "Q99"
    ],
    "SelectB_recommedations": [
      "Q301",
      "Q680",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q620",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q690",
      "Q680",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q163",
    "Question_Description": "한 회사가 온프레미스에서 컨테이너화된 애플리케이션을 구축 중이며, 이를 AWS로 이전하기로 결정했습니다. 애플리케이션은 배포 직후 수천 명의 사용자가 접속할 예정입니다. 회사는 대규모 컨테이너 배포를 어떻게 관리할지 확신이 없으며, 높은 가용성을 제공하면서도 운영 오버헤드를 최소화하는 아키텍처로 컨테이너화된 애플리케이션을 배포해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87509-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "온프레미스 컨테이너 애플리케이션을 AWS로 이전할 때, 높은 가용성과 자동 확장을 위한 완전관리형 서비스 활용이 핵심입니다. AWS Fargate를 사용하면 EC2 인스턴스 관리 없이 컨테이너를 실행할 수 있어 운영 부담이 크게 줄어듭니다. 또한 Target Tracking 기반 오토 스케일링을 통해 사용자 증가에 유연하게 대응 가능합니다. 따라서 SelectA가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "컨테이너화된 애플리케이션",
      "수천 명의 사용자",
      "고가용성",
      "운영 오버헤드 최소화",
      "자동 확장"
    ],
    "Terms": [
      "Amazon Elastic Container Registry (Amazon ECR)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "Amazon EC2 launch type",
      "Auto Scaling",
      "Amazon CloudWatch",
      "Availability Zone",
      "AMI"
    ],
    "SelectA": "Amazon ECR 리포지토리에 컨테이너 이미지를 저장합니다. AWS Fargate launch type을 사용하는 Amazon ECS 클러스터에서 컨테이너를 실행합니다. Target Tracking으로 수요에 맞춰 자동 확장합니다.",
    "SelectA_Commentary": "EC2 관리가 필요 없는 Fargate를 통해 운영 오버헤드를 낮추고, Target Tracking으로 컨테이너를 자동 스케일링하여 고가용성을 만족하므로 요구사항에 가장 적합한 방식입니다.",
    "SelectB": "Amazon ECR 리포지토리에 컨테이너 이미지를 저장합니다. Amazon EC2 launch type을 사용하는 Amazon ECS 클러스터에서 컨테이너를 실행합니다. Target Tracking으로 수요에 맞춰 자동 확장합니다.",
    "SelectB_Commentary": "EC2 인스턴스 프로비저닝 및 관리를 직접 해야 하므로 운영 부담이 늘어납니다. Fargate보다 오버헤드가 크고 고가용성 확보에 추가 작업이 필요합니다.",
    "SelectC": "Amazon EC2 인스턴스에서 동작하는 리포지토리에 이미지를 저장합니다. 여러 Availability Zone에 분산된 EC2 인스턴스에서 컨테이너를 실행하고, Amazon CloudWatch로 평균 CPU 사용률을 모니터링하여 필요한 경우 EC2 인스턴스를 추가로 실행합니다.",
    "SelectC_Commentary": "이미지 저장소부터 컨테이너 실행, 확장까지 모두 직접 관리해야 하므로 운영 복잡도가 높고, 확장 자동화 설정도 추가 구성이 필요해 요구사항에 부합하지 않습니다.",
    "SelectD": "컨테이너 이미지를 포함하는 AMI를 생성합니다. 여러 Availability Zone에 걸쳐 Auto Scaling 그룹으로 EC2 인스턴스를 실행합니다. Amazon CloudWatch 알람을 사용하여 평균 CPU 사용률 임계값 초과 시 스케일 아웃합니다.",
    "SelectD_Commentary": "AMI 업데이트 및 EC2 인스턴스 관리가 필요한 방식으로, Fargate 대신 직접 서버를 구성하므로 운영 부담이 커지고, 컨테이너 관리 효율이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q149",
      "Q802",
      "Q8",
      "Q786",
      "Q519"
    ],
    "SelectA_recommedations": [
      "Q303",
      "Q698",
      "Q900"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q900"
    ],
    "SelectC_recommedations": [
      "Q923",
      "Q47",
      "Q639"
    ],
    "SelectD_recommedations": [
      "Q691",
      "Q210",
      "Q762"
    ]
  },
  {
    "Question_Number": "Q164",
    "Question_Description": "한 회사에는 메시지의 페이로드를 전송하는 sender 애플리케이션과, 이 메시지의 페이로드를 처리하도록 설계된 processor 애플리케이션이 있습니다. 이 회사는 두 애플리케이션 간 메시지를 처리하기 위해 AWS 서비스를 도입하고자 합니다. sender 애플리케이션은 시간당 약 1,000개 메시지를 전송할 수 있으며, 메시지를 처리하는 데 최대 2일이 걸릴 수 있습니다. 메시지 처리에 실패한 경우 남은 메시지의 처리를 방해하지 않도록 해당 실패 메시지를 유지해야 합니다. 이러한 요구사항을 만족하면서 가장 운영 효율적인 방안은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87523-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 메시지 지연, 재시도, 실패 메시지 보존 등을 고려해 안정적이고 느슨하게 결합된 아키텍처를 설계하는 것이 목적입니다. Amazon SQS는 메시지 보존 기간 및 Dead-letter Queue 기능을 제공해 최대 14일 동안 메시지를 유지하고, 실패 메시지를 안전하게 격리할 수 있어 운영 부담을 최소화합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "메시지 처리",
      "Dead-letter Queue(DLQ)",
      "느슨한 결합",
      "메시지 유실 방지"
    ],
    "Terms": [
      "Amazon SQS",
      "Dead-letter Queue",
      "Amazon SNS",
      "Kinesis Data Stream",
      "Kinesis Client Library (KCL)",
      "Redis on Amazon EC2"
    ],
    "SelectA": "Amazon EC2 인스턴스에서 Redis 데이터베이스를 구동하고, 두 애플리케이션이 이를 사용하도록 설정해 메시지를 저장, 처리, 삭제합니다.",
    "SelectA_Commentary": "직접 Redis를 운영하면 모니터링, 스케일링, 장애 복구 등 추가 관리가 필요해 운영적 부담이 커집니다.",
    "SelectB": "Amazon Kinesis data stream을 사용하여 sender 애플리케이션에서 메시지를 수신하고, Kinesis Client Library(KCL)를 사용해 processor 애플리케이션을 통합합니다.",
    "SelectB_Commentary": "Kinesis는 실시간 스트리밍 처리에 유리하지만 장시간(최대 2일) 메시지 보관이나 메시지 실패 격리에 특화되지 않아 요구사항을 완전히 충족하기 어렵습니다.",
    "SelectC": "Amazon Simple Queue Service(Amazon SQS) 큐에 sender, processor 애플리케이션을 통합하고, 실패한 메시지를 수집할 수 있도록 dead-letter queue(DLQ)를 구성합니다.",
    "SelectC_Commentary": "SQS는 메시지 보존기간 설정과 DLQ 기능을 통해 실패 메시지를 격리하고, 최대 14일 동안 메시지를 유실 없이 유지할 수 있어 가장 운영 효율적입니다.",
    "SelectD": "Amazon Simple Notification Service(Amazon SNS) 토픽에 processor 애플리케이션을 구독하고, sender 애플리케이션은 해당 SNS 토픽에 메시지를 게시합니다.",
    "SelectD_Commentary": "SNS는 메시지를 여러 구독자에게 전송하는 데 적합하나, 개별 메시지의 장기 보존 및 실패 처리 격리에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q163",
      "Q786",
      "Q112",
      "Q802",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q757"
    ],
    "SelectB_recommedations": [
      "Q351",
      "Q164",
      "Q814"
    ],
    "SelectC_recommedations": [
      "Q98",
      "Q203",
      "Q814"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q148",
      "Q489"
    ]
  },
  {
    "Question_Number": "Q165",
    "Question_Description": "한 솔루션스 아키텍트는 Amazon S3 오리진과 함께 Amazon CloudFront를 사용하여 정적 웹사이트를 저장하는 솔루션을 설계해야 합니다. 회사의 보안 정책에 따라 모든 웹사이트 트래픽은 반드시 AWS WAF로 검사되어야 합니다. 이러한 요구 사항을 만족하려면 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "CloudFront에서 Origin Access Identity(OAI)로 Amazon S3를 보호하고, CloudFront 배포에 AWS WAF를 적용하면 외부 트래픽을 안전하게 검사할 수 있습니다. 이렇게 하면 S3 버킷이 직접 노출되지 않고 모든 트래픽이 WAF를 거쳐 처리되어 안전한 아키텍처를 구현할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon CloudFront",
      "Amazon S3",
      "static website",
      "AWS WAF",
      "Origin Access Identity(OAI)"
    ],
    "Terms": [
      "S3 bucket policy",
      "AWS WAF Amazon Resource Name(ARN)",
      "CloudFront distribution",
      "Security Group",
      "Origin Access Identity(OAI)"
    ],
    "SelectA": "S3 버킷 정책을 구성하여 AWS WAF Amazon Resource Name(ARN)에서 오는 요청만 수락하도록 설정합니다.",
    "SelectA_Commentary": "WAF ARN만 허용하는 방식은 S3 버킷 측면 제어에 그치며, CloudFront 배포와의 직접적인 연동이 제대로 이루어지지 않아 전체 아키텍처 요구를 충족하기 어렵습니다.",
    "SelectB": "Amazon CloudFront를 구성하여 S3 오리진에서 콘텐츠를 요청하기 전에 모든 수신 요청을 AWS WAF로 전달하도록 합니다.",
    "SelectB_Commentary": "CloudFront 자체에서 활성화된 WAF가 아니라 ‘WAF를 먼저 호출 후 S3 요청’ 형태로만 설명되어 있습니다. 단순한 요청 전달만으로는 S3 접근 통제나 안전한 아키텍처 구성이 충분치 않습니다.",
    "SelectC": "Amazon CloudFront IP 주소만 Amazon S3에 액세스하도록 허용하는 Security Group을 구성합니다. AWS WAF를 CloudFront와 연결합니다.",
    "SelectC_Commentary": "Security Group을 통한 IP 기반 접근 제어만으로는 S3 버킷 자체에 대한 직접 접근 제한을 완벽하게 보장하기 어렵습니다. OAI를 활용한 접근 제어가 권장됩니다.",
    "SelectD": "Amazon CloudFront와 Amazon S3가 Origin Access Identity(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 구성합니다. 배포에서 AWS WAF를 활성화합니다.",
    "SelectD_Commentary": "정답입니다. OAI로 S3 버킷을 직접 노출하지 않고 CloudFront만 접근 가능하게 하며, AWS WAF가 CloudFront 배포에 적용되어 모든 트래픽을 검사할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q974",
      "Q291",
      "Q216",
      "Q638",
      "Q889"
    ],
    "SelectA_recommedations": [
      "Q165",
      "Q965",
      "Q862"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q974",
      "Q291"
    ],
    "SelectC_recommedations": [
      "Q165",
      "Q974",
      "Q291"
    ],
    "SelectD_recommedations": [
      "Q165",
      "Q974",
      "Q216"
    ]
  },
  {
    "Question_Number": "Q166",
    "Question_Description": "글로벌 이벤트 주최 측은 매일 보고서를 정적 HTML 페이지 형태로 온라인에 게시하려고 합니다. 전 세계 사용자들이 수백만 건의 조회수를 발생시킬 것으로 예상됩니다. 파일들은 Amazon S3 버킷에 저장되어 있습니다. 솔루션스 아키텍트는 효율적이면서 효과적인 솔루션을 설계해야 합니다. 이를 달성하기 위해 어떤 조치를 취해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87522-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계적으로 많은 사용자가 동시에 정적 콘텐츠(HTML 페이지)에 접근할 때, 빠르고 효율적으로 콘텐츠를 제공하는 방법을 묻습니다. Amazon CloudFront를 사용하면 글로벌 엣지 로케이션을 통해 사용자와 가까운 위치에서 콘텐츠를 제공하기 때문에 대규모 트래픽도 원활히 처리하고 지연 시간을 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "글로벌 이벤트",
      "정적 HTML 페이지",
      "수백만 건의 조회수",
      "Amazon S3",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon S3",
      "Presigned URL",
      "Cross-Region Replication",
      "Amazon Route 53 (Geoproximity)",
      "Amazon CloudFront"
    ],
    "SelectA": "Presigned URL을 생성합니다.",
    "SelectA_Commentary": "Presigned URL은 제한된 권한으로 객체에 접근하도록 할 수 있지만, 글로벌 캐싱 및 트래픽 분산 측면에서 CloudFront만큼 효율적이지 않습니다.",
    "SelectB": "모든 리전에 Cross-Region Replication을 적용합니다.",
    "SelectB_Commentary": "여러 리전으로 데이터를 복제해도 각 리전에서 직접 데이터를 제공하는 데에는 여전히 지연이 발생할 수 있고 관리가 복잡합니다.",
    "SelectC": "Amazon Route 53의 Geoproximity 기능을 활용합니다.",
    "SelectC_Commentary": "Geoproximity를 이용해 트래픽을 분산할 수도 있지만, 정적 콘텐츠 제공을 최적화하고 캐싱 효과를 극대화하기에는 CloudFront가 더 적합합니다.",
    "SelectD": "Amazon CloudFront를 사용하고, 원본으로 해당 S3 버킷을 지정합니다.",
    "SelectD_Commentary": "CloudFront는 글로벌 엣지 로케이션을 통해 정적 콘텐츠를 캐싱하고, 대규모 조회 트래픽도 빠르고 안정적으로 제공할 수 있어 가장 효율적인 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q501",
      "Q43",
      "Q2",
      "Q302"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q501",
      "Q166"
    ],
    "SelectB_recommedations": [
      "Q622",
      "Q77",
      "Q132"
    ],
    "SelectC_recommedations": [
      "Q38",
      "Q361",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q280",
      "Q501",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q167",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스 집합에서 운영 환경 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 Amazon SQS 큐에서 데이터를 읽고, 메시지를 병렬로 처리합니다. 메시지 볼륨은 예측 불가능하며 종종 간헐적으로 트래픽이 발생합니다. 이 애플리케이션은 다운타임 없이 메시지를 계속 처리해야 합니다. 가장 비용 효율적으로 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87510-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능한 트래픽에 대응하면서 비용 최적화가 중요한 상황에서 Amazon EC2 컴퓨팅 자원을 어떻게 할당할지를 묻습니다. 애플리케이션은 다운타임 없이 상시 메시지를 처리해야 하며, 메시지 양이 급증하거나 줄어드는 상황을 고려해야 합니다. 가장 좋은 접근 방식은 안정적으로 필요한 최소한의 용량(베이스라인)은 Reserved Instances로 확보하고, 예기치 않은 추가 트래픽은 저렴하고 탄력적인 Spot Instances로 처리하여 비용을 절감하면서도 서비스 중단 없이 처리 용량을 확장하는 것입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon SQS",
      "간헐적 트래픽",
      "비용 효율성",
      "다운타임 없는 처리"
    ],
    "Terms": [
      "Production Application",
      "Amazon SQS",
      "Amazon EC2",
      "Reserved Instances",
      "Spot Instances",
      "On-Demand Instances",
      "Baseline Capacity",
      "Additional Capacity"
    ],
    "SelectA": "Spot Instances만 사용하여 필요한 최대 용량을 처리합니다.",
    "SelectA_Commentary": "Spot 환경이 회수될 위험이 있어 다운타임 우려가 크며, 안정적인 처리에 적합하지 않습니다.",
    "SelectB": "Reserved Instances만 사용하여 필요한 최대 용량을 처리합니다.",
    "SelectB_Commentary": "고정 비용이 매우 커지며, 트래픽 변동이 심할 때 비효율적이며 비용 부담이 큽니다.",
    "SelectC": "베이스라인 용량은 Reserved Instances로 확보하고, 추가 용량은 Spot Instances로 처리합니다.",
    "SelectC_Commentary": "필요 최소량은 Reserved Instances로 안정성을 확보하고, 변동분은 Spot Instances로 비용 효율을 극대화해 최적의 조합입니다.",
    "SelectD": "베이스라인 용량은 Reserved Instances로 확보하고, 추가 용량은 On-Demand Instances로 처리합니다.",
    "SelectD_Commentary": "On-Demand는 유연성이 있지만 Spot 대비 비용이 높아, 급증하는 트래픽 처리 시 더 비싸집니다.",
    "Question_Description_recommedations": [
      "Q671",
      "Q238",
      "Q993",
      "Q347",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q767",
      "Q49",
      "Q630"
    ],
    "SelectB_recommedations": [
      "Q767",
      "Q49",
      "Q997"
    ],
    "SelectC_recommedations": [
      "Q49",
      "Q630",
      "Q767"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q943",
      "Q1013"
    ]
  },
  {
    "Question_Number": "Q168",
    "Question_Description": "한 보안 팀은 팀의 모든 AWS 계정에서 특정 서비스나 작업에 대한 액세스를 제한하려고 합니다. 이 계정들은 모두 AWS Organizations를 사용하는 대규모 조직에 속해 있습니다. 솔루션은 확장 가능해야 하며, 권한을 한 곳에서만 유지하고 관리할 수 있어야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87512-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에 걸쳐 특정 서비스 또는 작업에 대한 액세스를 제한하여 조직의 거버넌스를 일원화하고자 할 때 가장 적합한 방안을 묻습니다. SCP(Service Control Policy)를 사용하면 조직 전체의 최대 권한 범위를 중앙에서 정의하여, 모든 계정의 접근 권한을 일괄적으로 제어할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "Service Control Policy",
      "권한 관리",
      "단일 지점",
      "특정 서비스 또는 작업 제한"
    ],
    "Terms": [
      "ACL",
      "Security Group",
      "Cross-account roles",
      "Service Control Policy(SCP)",
      "Root Organizational Unit"
    ],
    "SelectA": "ACL을 만들어 해당 서비스나 작업에 대한 액세스를 제공하십시오.",
    "SelectA_Commentary": "ACL은 주로 리소스 수준 접근 제어를 위한 방식이며, 여러 계정을 중앙에서 제어하기에는 적합하지 않습니다.",
    "SelectB": "Security Group을 생성하여 계정들을 허용하고 사용자 그룹에 연결하십시오.",
    "SelectB_Commentary": "Security Group은 네트워크 트래픽을 제어하는 보안 경계로, 서비스나 작업에 대한 IAM 기반 제한과는 다른 목적의 기능입니다.",
    "SelectC": "각 계정에서 cross-account roles를 생성하여 해당 서비스나 작업을 거부하십시오.",
    "SelectC_Commentary": "각 계정별로 cross-account roles를 설정하는 것은 관리 지점이 분산되어 확장성과 단일 관리 포인트 요구사항을 충족하지 못합니다.",
    "SelectD": "Root Organizational Unit에 Service Control Policy를 생성하여 서비스나 작업에 대한 액세스를 거부하십시오.",
    "SelectD_Commentary": "조직 루트의 SCP로 모든 계정에 대해 중앙 집중형 권한 제한이 가능하며, 확장성 및 단일 지점 관리 요구사항을 충족하는 유일한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q945",
      "Q1018",
      "Q548",
      "Q3",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q429",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q423",
      "Q233",
      "Q135"
    ]
  },
  {
    "Question_Number": "Q169",
    "Question_Description": "회사는 최근 웹 공격으로 인해 퍼블릭 웹 애플리케이션의 보안에 대해 우려하고 있습니다. 애플리케이션은 Application Load Balancer(ALB)를 사용하고 있습니다. 솔루션스 아키텍트는 애플리케이션에 대한 DDoS 공격 위험을 줄여야 합니다. 다음 중 이 요구사항을 충족하는 것은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87526-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 퍼블릭 웹 애플리케이션을 보호하기 위해 DDoS 공격 위험을 낮추는 방법을 묻습니다. AWS Shield Advanced는 Application Load Balancer와 같은 리소스에 대해 더 강력한 DDoS 방어를 제공하므로 가장 적합한 해법입니다. 다른 서비스들은 각각 보안 검사, 데이터 식별, 이상 징후 모니터링 용도로 주로 사용되므로 DDoS 완화에는 직접적인 도움이 되지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Application Load Balancer",
      "DDoS 공격",
      "AWS Shield Advanced"
    ],
    "Terms": [
      "Application Load Balancer (ALB)",
      "DDoS",
      "Amazon Inspector",
      "Amazon Macie",
      "AWS Shield Advanced",
      "Amazon GuardDuty"
    ],
    "SelectA": "ALB에 Amazon Inspector 에이전트를 추가합니다.",
    "SelectA_Commentary": "Amazon Inspector는 애플리케이션 보안 취약점을 검사하는 데 사용되지만, DDoS 완화와는 직접적인 연관이 없어 요구사항에 부합하지 않습니다.",
    "SelectB": "Amazon Macie를 구성하여 공격을 방지합니다.",
    "SelectB_Commentary": "Amazon Macie는 S3 내 민감 정보 탐지나 데이터 보안 관리에 초점을 둔 서비스로, DDoS 공격 방어와는 무관합니다.",
    "SelectC": "AWS Shield Advanced를 활성화하여 공격을 방지합니다.",
    "SelectC_Commentary": "AWS Shield Advanced는 ALB 및 기타 리소스에 대한 DDoS 공격을 감지하고 완화하는 강력한 기능을 제공하므로 요구사항에 가장 적합합니다.",
    "SelectD": "Amazon GuardDuty를 구성하여 ALB를 모니터링합니다.",
    "SelectD_Commentary": "Amazon GuardDuty는 악성 활동을 감지하고 알람을 제공하나, 공격을 직접 차단하거나 완화하는 기능은 없어 DDoS 방어 역할을 수행하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q707",
      "Q625",
      "Q927",
      "Q701",
      "Q437"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q893",
      "Q665"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q189"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ]
  },
  {
    "Question_Number": "Q170",
    "Question_Description": "한 회사의 웹 애플리케이션이 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스에서 구동 중입니다. 회사는 최근 정책을 변경하여, 이제 해당 애플리케이션이 오직 한 특정 국가에서만 액세스되도록 해야 합니다. 이를 만족하는 구성은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87528-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션에 대한 접근을 특정 국가로 제한하기 위한 보안 구성이 핵심입니다. Security Group이나 Network ACL은 IP 주소 기반 제어가 주가 되어 국가 제한에 비효율적입니다. 반면 AWS WAF의 Geo Match Condition을 사용하면 지리적 위치로 접근 제한이 가능하여 요구사항을 간단히 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "특정 국가",
      "Application Load Balancer",
      "Amazon EC2",
      "AWS WAF",
      "네트워크 ACL"
    ],
    "Terms": [
      "Security Group",
      "Application Load Balancer",
      "AWS WAF",
      "Geo Match Condition",
      "Network ACL"
    ],
    "SelectA": "Amazon EC2 인스턴스에 대한 Security Group을 구성합니다.",
    "SelectA_Commentary": "Security Group은 IP 주소 또는 포트 기반의 제한만 가능해 국가 기준의 접근 제어에는 적합하지 않습니다.",
    "SelectB": "Application Load Balancer에 대한 Security Group을 구성합니다.",
    "SelectB_Commentary": "역시 IP 주소 기반으로만 제한이 가능해 특정 국가를 선택적으로 허용하기에는 한계가 있습니다.",
    "SelectC": "VPC 내 Application Load Balancer에 AWS WAF를 구성합니다.",
    "SelectC_Commentary": "AWS WAF의 Geo Match Condition을 이용해 특정 국가에서만 접근을 허용할 수 있어 요구사항을 정확히 충족하는 정답입니다.",
    "SelectD": "Amazon EC2 인스턴스가 포함된 서브넷의 Network ACL을 구성합니다.",
    "SelectD_Commentary": "Network ACL 역시 IP 주소 범위를 통한 제한만 가능하므로, 국가별 트래픽 제한에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q625",
      "Q884",
      "Q682",
      "Q437",
      "Q329"
    ],
    "SelectA_recommedations": [
      "Q74",
      "Q318",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q169",
      "Q625",
      "Q170"
    ],
    "SelectC_recommedations": [
      "Q853",
      "Q165",
      "Q170"
    ],
    "SelectD_recommedations": [
      "Q218",
      "Q682",
      "Q251"
    ]
  },
  {
    "Question_Number": "Q171",
    "Question_Description": "한 회사는 사용자들에게 item 가격을 기반으로 세금 계산을 자동화하는 API를 제공합니다. 이 회사는 연휴 시즌에만 폭주하는 문의로 인해 응답 시간이 느려집니다. Solutions Architect는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다. 이를 달성하기 위해 어떤 작업을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87529-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "연휴 시즌에 급증하는 트래픽을 자동으로 처리하려면 서버리스 구조를 고려해야 합니다. Amazon API Gateway와 AWS Lambda는 이벤트 기반 확장으로 탄력적이며, 운영 부담과 비용 절감에도 유리합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "자동화된 세금 계산",
      "API",
      "연휴 시즌",
      "확장 가능",
      "탄력적 솔루션",
      "Amazon API Gateway",
      "AWS Lambda"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon EC2",
      "Application Load Balancer"
    ],
    "SelectA": "Amazon EC2 인스턴스에서 호스팅되는 API를 제공하고, API 요청 시 해당 EC2 인스턴스가 계산을 수행합니다.",
    "SelectA_Commentary": "단일 Amazon EC2 인스턴스는 자동 확장이 어려워 트래픽 폭주 시 성능 저하가 발생할 수 있습니다.",
    "SelectB": "Amazon API Gateway로 REST API를 설계하여 item 이름을 받고, API Gateway가 AWS Lambda로 세금 계산을 전달합니다.",
    "SelectB_Commentary": "서버리스 기반으로 이벤트 발생 시 Lambda가 자동 확장하므로, 높은 트래픽에도 안정적으로 대응하고 비용 효율적입니다.",
    "SelectC": "Application Load Balancer 뒤에 두 개의 Amazon EC2 인스턴스를 배치하여 item 이름을 받고 세금을 계산합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 둘로 늘렸으나 여전히 수동 확장 설정이 필요해 트래픽 급증에 유연하게 대응하기 어렵습니다.",
    "SelectD": "Amazon API Gateway로 REST API를 설계하고, Amazon EC2 인스턴스에서 호스팅된 API에 연결해 item 이름을 전달합니다.",
    "SelectD_Commentary": "API Gateway 뒤의 EC2 인스턴스는 서버리스가 아니어서 자동 확장이 어렵고, Lambda를 사용하는 방식보다 탄력성과 비용 효율이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q323",
      "Q322",
      "Q694",
      "Q798",
      "Q263"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q790"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q739",
      "Q207"
    ],
    "SelectC_recommedations": [
      "Q714",
      "Q405",
      "Q357"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q194",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q172",
    "Question_Description": "한 솔루션스 아키텍트가 애플리케이션을 위해 새로운 Amazon CloudFront distribution을 생성하고 있습니다. 사용자들이 제출하는 정보 중 일부는 민감합니다. 애플리케이션은 HTTPS를 사용하지만 추가적인 보안 계층이 필요합니다. 이 민감한 정보는 애플리케이션 스택 전반에서 보호되어야 하며, 특정 애플리케이션만 이 정보에 액세스할 수 있어야 합니다. 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87517-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "민감 데이터는 단순히 HTTPS로만 보호하기에는 부족합니다. ‘CloudFront field-level encryption’을 사용하면 특정 필드를 선택적으로 암호화하여, 필요한 권한이 있는 서비스만 해당 데이터를 복호화할 수 있습니다. 이는 애플리케이션 스택 전역에서 데이터를 안전하게 유지하고, 특정 애플리케이션으로만 접근을 제한하기 위한 핵심 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "민감한 정보",
      "애플리케이션 스택 보호",
      "HTTPS",
      "CloudFront",
      "Field-level encryption"
    ],
    "Terms": [
      "Amazon CloudFront",
      "CloudFront Distribution",
      "HTTPS",
      "Signed URL",
      "Signed Cookie",
      "Field-level Encryption",
      "Origin Protocol Policy"
    ],
    "SelectA": "CloudFront signed URL을 구성합니다.",
    "SelectA_Commentary": "민감 정보를 직접 필드 단위로 보호하지 않고, 리소스 접근 제한을 위한 방법이므로 요구사항을 만족하지 못합니다.",
    "SelectB": "CloudFront signed cookie를 구성합니다.",
    "SelectB_Commentary": "Signed cookie 역시 접근 제한 중심이므로, 애플리케이션 스택 전반에서의 민감 데이터 암호화에는 충분하지 않습니다.",
    "SelectC": "CloudFront field-level encryption profile을 구성합니다.",
    "SelectC_Commentary": "민감 정보를 edge에서부터 암호화하여, 해당 데이터를 복호화할 수 있는 권한이 있는 애플리케이션만 접근 가능하게 하는 최적의 솔루션입니다.",
    "SelectD": "CloudFront를 구성하고 Origin Protocol Policy를 Viewer Protocol Policy에서 HTTPS Only로 설정합니다.",
    "SelectD_Commentary": "HTTPS 통신으로 전송 구간 암호화만 수행하지만, 필드 단위 암호화까지 제공하지 않아 개별 민감 정보 보호 요구사항을 만족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q855",
      "Q577",
      "Q538",
      "Q291",
      "Q542"
    ],
    "SelectA_recommedations": [
      "Q855",
      "Q538",
      "Q172"
    ],
    "SelectB_recommedations": [
      "Q538",
      "Q855",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q855",
      "Q172",
      "Q538"
    ],
    "SelectD_recommedations": [
      "Q855",
      "Q172",
      "Q538"
    ]
  },
  {
    "Question_Number": "Q173",
    "Question_Description": "한 게임 회사가 AWS에서 브라우저 기반 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션 사용자는 Amazon S3에 저장된 대량의 동영상과 이미지를 소비합니다. 이 컨텐츠는 모든 사용자에게 동일합니다. 애플리케이션의 인기가 높아져 전 세계 수백만 명의 사용자가 이 미디어 파일에 액세스하고 있습니다. 회사는 원본에 대한 부하를 줄이면서 사용자에게 파일을 제공하려고 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87530-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 사용자에게 동일한 정적 콘텐츠(동영상, 이미지)를 효율적으로 전 세계로 배포하는 방법을 묻습니다. CloudFront는 Amazon S3 원본에 대한 부하를 줄이면서 빠른 콘텐츠 전송을 가능하게 합니다. 또한 요청이 집중되는 글로벌 엣지 로케이션을 이용해 지연을 최소화하고, 캐싱 기능으로 비용 효율을 높일 수 있습니다. 다른 옵션들보다 확장성과 경제성을 동시에 충족하기 때문에 가장 적합한 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "브라우저 기반 애플리케이션",
      "Amazon S3",
      "동영상과 이미지",
      "원본 부하 감소",
      "비용 효율",
      "전 세계 사용자",
      "Amazon CloudFront"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon ElastiCache for Redis",
      "Amazon ElastiCache for Memcached",
      "Amazon S3"
    ],
    "SelectA": "웹 서버 앞단에 AWS Global Accelerator를 배포합니다.",
    "SelectA_Commentary": "AWS Global Accelerator는 TCP/UDP 트래픽 가속에 유리하나, 정적 콘텐츠를 전 세계에 캐싱하여 비용을 절감하기에는 적절하지 않습니다.",
    "SelectB": "S3 버킷 앞단에 Amazon CloudFront 웹 배포를 구성합니다.",
    "SelectB_Commentary": "정적 콘텐츠를 캐싱해 전 세계에 빠르게 전달하고, 원본 부하도 줄일 수 있는 가장 비용 효율적 솔루션입니다.",
    "SelectC": "웹 서버 앞단에 Amazon ElastiCache for Redis를 배포합니다.",
    "SelectC_Commentary": "Redis는 빠른 인메모리 캐시지만, 글로벌 캐시에 적합하지 않고 다중 리전에 분산 서비스하기에는 비용이나 구성 측면에서 비효율적입니다.",
    "SelectD": "웹 서버 앞단에 Amazon ElastiCache for Memcached를 배포합니다.",
    "SelectD_Commentary": "Memcached 역시 내부 애플리케이션 캐싱용으로 적합하지만, 전 세계 사용자에게 S3 콘텐츠를 제공하는 CDN 역할은 수행하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q155",
      "Q547",
      "Q43",
      "Q501",
      "Q672"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q865",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q704",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q704",
      "Q229",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q174",
    "Question_Description": "한 회사가 단일 Availability Zone 내에 있는 Application Load Balancer(ALB) 뒤에서, Amazon EC2 Auto Scaling 그룹에 속한 6대의 프론트엔드 웹 서버를 사용하는 다중 계층 애플리케이션을 운영하고 있습니다. 솔루션스 아키텍트는 애플리케이션을 수정하지 않고도 인프라를 고가용성으로 만들기를 원합니다. 이러한 고가용성을 제공하기 위한 아키텍처는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87531-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 AZ에 집중된 웹 서버를 다중 AZ로 확장하여 고가용성을 확보하는 방법을 묻고 있습니다. Auto Scaling 그룹과 ALB를 두 개 이상의 AZ로 확장하면, 한 AZ에 장애가 발생하더라도 다른 AZ에서 트래픽을 처리할 수 있어 중단 없이 서비스를 유지할 수 있습니다. 따라서 다중 AZ를 활용하는 것이 핵심 포인트입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "Amazon EC2 Auto Scaling",
      "Application Load Balancer",
      "Availability Zone",
      "다중 AZ"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Availability Zone",
      "Region"
    ],
    "SelectA": "두 개의 Region에 각각 3개 인스턴스를 사용하는 Auto Scaling 그룹을 생성합니다.",
    "SelectA_Commentary": "Auto Scaling 그룹은 일반적으로 단일 Region 내에서만 구성 가능합니다. Region 단위로 인스턴스를 분산하는 것은 운영상 복잡하며, 간단한 AZ 단위 확장으로도 충분한 고가용성을 확보할 수 있습니다.",
    "SelectB": "Auto Scaling 그룹을 수정하여 두 개의 Availability Zone에 각각 3개의 인스턴스를 사용하도록 설정합니다.",
    "SelectB_Commentary": "두 개의 AZ로 인스턴스를 분산 배치하면, 한 AZ에서 문제가 발생해도 다른 AZ에서 트래픽 처리가 가능해 고가용성을 달성할 수 있는 가장 적합한 방법입니다.",
    "SelectC": "빠르게 다른 Region에서 더 많은 인스턴스를 생성할 수 있도록 Auto Scaling 템플릿을 작성합니다.",
    "SelectC_Commentary": "Region을 넘나드는 구성보다 다중 AZ 구성이 훨씬 간단하고 효율적입니다. 템플릿만으로는 자동으로 다중 AZ 고가용성을 보장할 수 없습니다.",
    "SelectD": "Amazon EC2 인스턴스 앞단의 ALB를 라운드 로빈으로 설정하여 웹 계층으로 트래픽을 분산합니다.",
    "SelectD_Commentary": "기존에 이미 ALB가 존재하므로 라운드 로빈 설정만으로는 여러 AZ로 인스턴스를 분산하지 않습니다. AZ 간 분산 배치를 해야 진정한 고가용성을 확보할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q639",
      "Q246",
      "Q333",
      "Q275",
      "Q405"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q1001",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q729",
      "Q691",
      "Q174"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q1001",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ]
  },
  {
    "Question_Number": "Q175",
    "Question_Description": "한 이커머스 회사는 Amazon API Gateway와 AWS Lambda function을 사용하는 주문 처리 애플리케이션을 운영하고 있습니다. 애플리케이션은 데이터를 Amazon Aurora PostgreSQL 데이터베이스에 저장합니다. 최근 할인 행사 기간에 고객 주문이 급증하여 일부 고객들은 타임아웃을 겪었고, 이 고객들의 주문은 처리되지 않았습니다. 솔루션스 아키텍트는 데이터베이스에 열려 있는 연결이 매우 많아 CPU 및 메모리 사용량이 높다는 사실을 파악했습니다. 솔루션스 아키텍트는 애플리케이션에 대한 변경을 최소화하면서 타임아웃 오류를 방지해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87533-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 주문이 급증할 때 다수의 데이터베이스 연결로 인해 발생하는 과부하를 해결해야 합니다. Amazon RDS Proxy를 사용하면 데이터베이스 연결 풀을 제공하여 Lambda function이 불필요하게 많은 연결을 생성하는 상황을 방지하고, 성능과 확장성을 높일 수 있습니다. 최소한의 애플리케이션 변경으로 타임아웃 문제를 해결할 수 있기 때문에 Amazon RDS Proxy를 사용하는 것이 가장 적절한 방법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "이커머스",
      "주문 처리",
      "타임아웃",
      "CPU 및 메모리 사용량",
      "연결 과부하",
      "Amazon Aurora PostgreSQL"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon Aurora PostgreSQL",
      "Amazon RDS Proxy",
      "Amazon DynamoDB",
      "AWS Database Migration Service (AWS DMS)",
      "글로벌 데이터베이스",
      "Read Replica"
    ],
    "SelectA": "Lambda function에 대해 Provisioned Concurrency를 구성합니다. 데이터베이스를 여러 AWS 리전에 걸친 글로벌 데이터베이스로 수정합니다.",
    "SelectA_Commentary": "Provisioned Concurrency는 Lambda의 실행 시작 지연 문제를 줄여주지만, 데이터베이스 연결 수 문제를 직접 해결해주지 못합니다. 또한 글로벌 데이터베이스로 변경하는 것은 복잡하며, 연결 폭주 자체를 완화하는 핵심 대안이 아닙니다.",
    "SelectB": "Amazon RDS Proxy를 사용하여 데이터베이스 프록시를 생성합니다. Lambda function이 데이터베이스 엔드포인트 대신 RDS Proxy 엔드포인트를 사용하도록 수정합니다.",
    "SelectB_Commentary": "RDS Proxy를 사용하면 연결 풀이 가능해져, 데이터베이스 연결 과부하를 완화하고 CPU/메모리 사용량을 줄일 수 있습니다. 애플리케이션 수정이 최소화되며, 타임아웃 문제를 가장 효과적으로 해결합니다.",
    "SelectC": "다른 AWS 리전에 데이터베이스 Read Replica를 생성합니다. API Gateway에서 쿼리 스트링 파라미터를 사용하여 트래픽을 해당 Read Replica로 라우팅합니다.",
    "SelectC_Commentary": "Read Replica는 읽기 요청을 분산시키지만, 주문 처리는 쓰기 작업이 포함됩니다. 쓰기 트래픽은 그대로 원본 DB로 집중되므로 연결 급증 문제의 근본적 해결책이 되지 못합니다.",
    "SelectD": "AWS Database Migration Service (AWS DMS)를 사용해 Aurora PostgreSQL 데이터를 Amazon DynamoDB로 마이그레이션합니다. Lambda function이 DynamoDB 테이블을 사용하도록 수정합니다.",
    "SelectD_Commentary": "DynamoDB로 이전하면 스케일 이점을 얻을 수 있지만, 데이터베이스 구조 변경이 크고 애플리케이션 수정도 많아집니다. 문제에서 요구하는 ‘최소한의 변경’에는 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q597",
      "Q576",
      "Q379",
      "Q235",
      "Q596"
    ],
    "SelectA_recommedations": [
      "Q597",
      "Q175",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q269",
      "Q661",
      "Q379"
    ],
    "SelectC_recommedations": [
      "Q243",
      "Q337",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q175",
      "Q685",
      "Q177"
    ]
  },
  {
    "Question_Number": "Q176",
    "Question_Description": "어플리케이션이 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되고 있습니다. 이 어플리케이션은 Amazon DynamoDB 테이블에 액세스해야 합니다. 트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 가장 안전하게 테이블에 액세스하려면 어떤 방법을 선택해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87532-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프라이빗 서브넷에서 실행되는 EC2 인스턴스가 DynamoDB에 직접 접근해야 할 때, 해당 트래픽을 AWS 내부에서만 처리하여 보안을 강화하는 방안을 묻습니다. VPC endpoint는 외부 인터넷을 거치지 않고도 DynamoDB에 액세스할 수 있어 가장 안전하고 효율적인 해결책입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "프라이빗 서브넷",
      "DynamoDB 테이블",
      "트래픽 보호",
      "AWS 네트워크",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon DynamoDB",
      "VPC endpoint",
      "NAT gateway",
      "NAT instance",
      "Internet gateway",
      "private subnet",
      "public subnet"
    ],
    "SelectA": "VPC endpoint를 사용하여 DynamoDB에 액세스합니다.",
    "SelectA_Commentary": "트래픽이 외부 인터넷을 거치지 않고 AWS 네트워크 내부에서 안전하게 처리됩니다. 가장 권장되는 방법입니다.",
    "SelectB": "퍼블릭 서브넷에 있는 NAT gateway를 사용합니다.",
    "SelectB_Commentary": "NAT gateway는 사용 시 인터넷 경유가 발생하므로 트래픽이 AWS 네트워크를 벗어날 수 있어 보안 측면에서 비효율적입니다.",
    "SelectC": "프라이빗 서브넷에 NAT 인스턴스를 사용합니다.",
    "SelectC_Commentary": "NAT 인스턴스도 인터넷을 통해 DynamoDB에 연결하게 되므로 트래픽이 AWS 네트워크를 벗어납니다.",
    "SelectD": "VPC에 연결된 internet gateway를 사용합니다.",
    "SelectD_Commentary": "internet gateway는 직접 퍼블릭 인터넷으로 연결되므로 안전하게 내부 통신만 사용하는 방법이 아닙니다.",
    "Question_Description_recommedations": [
      "Q492",
      "Q727",
      "Q17",
      "Q453",
      "Q612"
    ],
    "SelectA_recommedations": [
      "Q562",
      "Q279",
      "Q176"
    ],
    "SelectB_recommedations": [
      "Q803",
      "Q893",
      "Q538"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q15",
      "Q468",
      "Q1019"
    ]
  },
  {
    "Question_Number": "Q177",
    "Question_Description": "한 엔터테인먼트 회사가 미디어 메타데이터를 저장하기 위해 Amazon DynamoDB를 사용하고 있습니다. 애플리케이션이 읽기 중심적이며 지연이 발생하고 있습니다. 이 회사에는 추가 운영 오버헤드를 처리할 인력이 없으며, 애플리케이션을 재구성하지 않고 DynamoDB의 성능 효율을 개선해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87572-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB에서 읽기 지연이 발생하는 상황에서, 애플리케이션 재구성 없이 빠른 응답 시간을 확보할 수 있는 캐싱 솔루션을 찾는 것입니다. 완전관리형 인메모리 캐시인 Amazon DAX가 DynamoDB와 밀접하게 연동되어 운영 부담을 최소화하면서 읽기 성능을 크게 향상시킵니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "성능 효율",
      "읽기 지연",
      "DynamoDB",
      "DAX"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Amazon ElastiCache for Redis",
      "Amazon DynamoDB Accelerator (DAX)",
      "DynamoDB global tables",
      "Amazon ElastiCache for Memcached",
      "In-memory cache",
      "Auto Discovery"
    ],
    "SelectA": "Amazon ElastiCache for Redis를 사용하십시오.",
    "SelectA_Commentary": "Redis는 범용 인메모리 데이터 스토어로서 빠른 성능을 제공하지만, DynamoDB와 직접 연동하려면 애플리케이션 코드 변경 및 추가 구성 작업이 필요합니다.",
    "SelectB": "Amazon DynamoDB Accelerator (DAX)를 사용하십시오.",
    "SelectB_Commentary": "DAX는 DynamoDB 전용 완전관리형 인메모리 캐시 솔루션으로, 애플리케이션 변경을 최소화하면서 읽기 요청의 지연을 극적으로 개선할 수 있습니다.",
    "SelectC": "DynamoDB Global Tables를 사용하여 데이터를 복제하십시오.",
    "SelectC_Commentary": "글로벌 테이블은 다중 리전에 걸친 데이터 복제로 고가용성과 지연 감소에 기여하지만, 단순 캐싱 문제 해결보다는 더 복잡한 구성을 요구합니다.",
    "SelectD": "Auto Discovery가 활성화된 Amazon ElastiCache for Memcached를 사용하십시오.",
    "SelectD_Commentary": "Memcached 역시 캐싱 솔루션이지만, DynamoDB와 직접 연동되는 DAX보다 운영 편의성과 호환성 측면에서 이점이 적습니다.",
    "Question_Description_recommedations": [
      "Q578",
      "Q472",
      "Q731",
      "Q523",
      "Q962"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q704",
      "Q620"
    ],
    "SelectB_recommedations": [
      "Q472",
      "Q578",
      "Q177"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q704",
      "Q229",
      "Q620"
    ]
  },
  {
    "Question_Number": "Q178",
    "Question_Description": "한 회사가 단일 AWS Region 내 Amazon EC2 인스턴스와 Amazon RDS DB 인스턴스로 구성된 인프라를 운영하고 있습니다. 이 회사는 별도의 Region에도 데이터를 백업하려고 합니다. 가장 낮은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87639-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "단일 Region에서 운영되는 EC2와 RDS 데이터를 별도 Region으로 백업하는 방법을 묻는 문제로, 자동화와 운영 복잡도 최소화가 핵심 포인트입니다. AWS Backup은 교차 Region 백업 자동화를 제공하여 최소한의 작업으로 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "Amazon RDS DB",
      "별도 Region 백업",
      "AWS Backup",
      "운영 오버헤드"
    ],
    "Terms": [
      "AWS Backup",
      "Amazon Data Lifecycle Manager (Amazon DLM)",
      "Amazon Machine Images (AMIs)",
      "Read Replica",
      "Amazon EBS Snapshot",
      "S3 Cross-Region Replication (CRR)"
    ],
    "SelectA": "AWS Backup을 사용하여 EC2 백업과 RDS 백업을 별도 Region으로 복사합니다.",
    "SelectA_Commentary": "AWS Backup은 백업 자동화와 교차 Region 복사를 모두 지원해 추가 설정이 적고 운영 오버헤드가 가장 낮습니다.",
    "SelectB": "Amazon Data Lifecycle Manager(Amazon DLM)을 사용하여 EC2 백업과 RDS 백업을 별도 Region으로 복사합니다.",
    "SelectB_Commentary": "Amazon DLM은 주로 EC2 스냅샷 용도로 사용되며, RDS 백업 교차 Region 복사는 직접 지원하지 않아 운영이 복잡해집니다.",
    "SelectC": "EC2 인스턴스의 AMI를 생성하고 이를 별도 Region으로 복사합니다. RDS DB 인스턴스의 리드 레플리카를 별도 Region에 생성합니다.",
    "SelectC_Commentary": "AMI 복사와 별도 리드 레플리카 구성은 자동화가 제한적이고 단계가 많아 운영 오버헤드가 증가합니다.",
    "SelectD": "Amazon EBS 스냅샷을 생성해 별도 Region으로 복사하고, RDS 스냅샷을 만들어 Amazon S3로 내보낸 뒤, S3 Cross-Region Replication(CRR)을 설정합니다.",
    "SelectD_Commentary": "EBS 스냅샷 복사, RDS 스냅샷 내보내기와 CRR 구성 등 단계가 많아 운영 복잡도가 높아집니다.",
    "Question_Description_recommedations": [
      "Q456",
      "Q312",
      "Q593",
      "Q585",
      "Q224"
    ],
    "SelectA_recommedations": [
      "Q178",
      "Q585",
      "Q304"
    ],
    "SelectB_recommedations": [
      "Q178",
      "Q343",
      "Q585"
    ],
    "SelectC_recommedations": [
      "Q178",
      "Q456",
      "Q224"
    ],
    "SelectD_recommedations": [
      "Q178",
      "Q585",
      "Q312"
    ]
  },
  {
    "Question_Number": "Q179",
    "Question_Description": "한 솔루션스 아키텍트는 Amazon RDS DB instance에 액세스하기 위해 애플리케이션이 사용하는 데이터베이스 사용자 이름과 비밀번호를 안전하게 저장해야 합니다. 데이터베이스에 액세스하는 애플리케이션은 Amazon EC2 instance에서 실행됩니다. 솔루션스 아키텍트는 AWS Systems Manager Parameter Store에 보안을 갖춘 파라미터를 생성하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87582-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Parameter Store에서 중요한 자격 정보를 안전하게 관리하면서 Amazon EC2 instance가 해당 정보를 정상적으로 읽어올 수 있도록 하는 방법을 묻습니다. 적절한 보안 액세스와 KMS를 통한 암호화를 적용해야 하며, IAM role을 활용하여 EC2 instance가 필요한 권한만 부여받도록 구성하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon RDS DB instance",
      "Amazon EC2 instance",
      "AWS Systems Manager Parameter Store",
      "데이터베이스 사용자 이름",
      "비밀번호를 안전하게 저장",
      "IAM role",
      "AWS Key Management Service(AWS KMS)",
      "암호화"
    ],
    "Terms": [
      "AWS Systems Manager Parameter Store",
      "Amazon RDS DB instance",
      "Amazon EC2 instance",
      "AWS Key Management Service (AWS KMS)",
      "IAM role",
      "Decrypt",
      "IAM trust relationship"
    ],
    "SelectA": "IAM role을 생성하여 Parameter Store 파라미터에 대한 읽기 권한을 부여하고, 해당 파라미터 암호화에 사용되는 AWS KMS key에 대해 Decrypt 권한을 허용합니다. 이 IAM role을 EC2 instance에 할당합니다.",
    "SelectA_Commentary": "정답입니다. EC2 instance에 할당된 IAM role이 필요 권한을 가진 상태로 Parameter Store와 KMS를 안전하게 사용합니다.",
    "SelectB": "Parameter Store 파라미터에 대해 읽기 권한을 허용하는 IAM policy를 생성하고, 이 파라미터 암호화에 사용되는 AWS KMS key에 대해 Decrypt 권한을 허용합니다. 이 IAM policy를 EC2 instance에 할당합니다.",
    "SelectB_Commentary": "IAM policy만 생성하여 인스턴스에 직접 할당하는 것은 일반적으로 사용하지 않는 방식이며, Instance Profile을 통한 IAM role 할당이 모범 사례입니다.",
    "SelectC": "Parameter Store 파라미터와 EC2 instance 간 IAM trust relationship을 생성하고, Amazon RDS를 트러스트 정책의 주체로 지정합니다.",
    "SelectC_Commentary": "Amazon RDS를 주체로 지정할 이유가 없으며, Parameter Store 파라미터와 EC2 간에 직접적인 신뢰 관계를 구성하는 방식도 적절하지 않습니다.",
    "SelectD": "DB instance와 EC2 instance 간 IAM trust relationship을 생성하고, Systems Manager를 트러스트 정책의 주체로 지정합니다.",
    "SelectD_Commentary": "DB instance와 EC2 사이의 신뢰 관계 설정은 본 문제의 요구사항인 Parameter Store 파라미터 및 KMS 활용과는 관련이 없습니다.",
    "Question_Description_recommedations": [
      "Q723",
      "Q438",
      "Q732",
      "Q330",
      "Q742"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q916",
      "Q494"
    ],
    "SelectC_recommedations": [
      "Q179",
      "Q838",
      "Q732"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q723",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q180",
    "Question_Description": "한 회사가 API 기반의 클라우드 통신 플랫폼을 설계하고 있습니다. 애플리케이션은 Network Load Balancer(NLB) 뒤의 Amazon EC2 인스턴스에서 호스팅됩니다. 회사는 Amazon API Gateway를 통해 외부 사용자들에게 애플리케이션에 대한 접근을 제공합니다. 회사는 SQL injection과 같은 웹 공격을 방어하고, 대규모·고도화된 DDoS 공격을 탐지 및 완화하기를 원합니다. 이러한 요구사항을 가장 효과적으로 충족하는 솔루션 조합은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87640-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 공격(SQL injection)과 대규모 DDoS 공격을 모두 방어하려면 어떤 조합이 필요한지 묻습니다. AWS WAF는 애플리케이션 계층(레이어 7)에서 SQL injection 등 웹 공격을 차단하고, AWS Shield Advanced는 규모가 큰 고도화된 DDoS 공격에 대해 자동 완화와 지원(비용 보호, SRT 연계)을 제공합니다. NLB는 레이어 4에서 동작하기 때문에 웹 계층의 공격 방어를 위해서는 별도로 API Gateway에 WAF를 적용해야 합니다. 따라서 웹 취약점 방어를 위해 AWS WAF를 API Gateway에 적용하고, DDoS에 대한 최상의 방어를 위해 AWS Shield Advanced를 NLB 또는 Gateway에 적용하는 것이 가장 효과적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Network Load Balancer",
      "Amazon API Gateway",
      "AWS WAF",
      "SQL injection",
      "DDoS",
      "AWS Shield Advanced"
    ],
    "Terms": [
      "Amazon EC2",
      "Network Load Balancer(NLB)",
      "Amazon API Gateway",
      "AWS WAF",
      "AWS Shield Advanced",
      "AWS Shield Standard",
      "Amazon GuardDuty",
      "SQL injection",
      "DDoS"
    ],
    "SelectA": "Use AWS WAF to protect the NLB.",
    "SelectA_Commentary": "NLB는 레이어 4 로드 밸런싱이므로 AWS WAF를 직접 적용하기 어렵습니다. 따라서 웹 공격(SQL injection) 방어에 적절하지 않습니다.",
    "SelectB": "Use AWS Shield Advanced with the NLB.",
    "SelectB_Commentary": "대규모·고도화된 DDoS 공격에 대한 가장 강력한 보호 기능을 제공하며, 비용 보호 및 전문가 지원을 받을 수 있어 올바른 선택입니다.",
    "SelectC": "Use AWS WAF to protect Amazon API Gateway.",
    "SelectC_Commentary": "AWS WAF가 웹 계층 공격(SQL injection 등)을 효과적으로 차단할 수 있어, API Gateway에 적용하는 것은 적절한 선택입니다.",
    "SelectD": "Use Amazon GuardDuty with AWS Shield Standard.",
    "SelectD_Commentary": "Amazon GuardDuty는 보안 위협 모니터링에 유용하나, Shield Standard만으로는 고도화된 대규모 DDoS 공격에 대한 완전한 보호가 어렵습니다.",
    "SelectE": "Use AWS Shield Standard with Amazon API Gateway.",
    "SelectE_Commentary": "Shield Standard는 기본적인 DDoS 완화 기능만을 제공하므로, 더욱 강력한 보호가 필요한 시나리오에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q340",
      "Q623",
      "Q927",
      "Q35",
      "Q608"
    ],
    "SelectA_recommedations": [
      "Q180",
      "Q382",
      "Q169"
    ],
    "SelectB_recommedations": [
      "Q60",
      "Q382",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q165",
      "Q623",
      "Q1019"
    ],
    "SelectD_recommedations": [
      "Q313",
      "Q831",
      "Q233"
    ],
    "SelectE_recommedations": [
      "Q1019",
      "Q34",
      "Q623"
    ]
  },
  {
    "Question_Number": "Q181",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 실행되는 레거시 데이터 처리 애플리케이션을 사용하고 있습니다. 데이터는 순차적으로 처리되지만 결과 순서는 중요하지 않습니다. 현재 monolithic 아키텍처를 사용하며, 수요 증가 시 인스턴스 크기를 키우는 방식으로만 확장해 왔습니다. 이제 개발자들은 애플리케이션을 Amazon ECS 기반의 microservices 아키텍처로 재작성하려 합니다. 이때 마이크로서비스 간 통신을 위해 Solutions Architect가 권장해야 할 방법은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87647-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "microservices 간에는 느슨한 결합과 비동기 메시징이 핵심입니다. Amazon SQS는 메시지 순서가 중요하지 않은 환경에서 훌륭한 확장성과 유연성을 제공합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "monolithic 아키텍처",
      "microservices 아키텍처",
      "Amazon ECS",
      "Amazon SQS",
      "스케일링",
      "비동기 통신"
    ],
    "Terms": [
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda",
      "Amazon DynamoDB",
      "DynamoDB Streams",
      "메시지 큐",
      "pub/sub"
    ],
    "SelectA": "Amazon SQS 큐를 생성합니다. 데이터 프로듀서 코드에서 큐로 메시지를 전송하고, 데이터 컨슈머 코드에서 큐에서 메시지를 처리하도록 합니다.",
    "SelectA_Commentary": "마이크로서비스를 느슨하게 결합하고, 순서가 중요치 않은 비동기 처리에 적합한 방법입니다.",
    "SelectB": "Amazon SNS 토픽을 생성합니다. 프로듀서 코드에서 토픽으로 알림을 발행하고, 컨슈머 코드에서 해당 토픽을 구독합니다.",
    "SelectB_Commentary": "SNS는 1:N 형태에 적합한 pub/sub 모델로, 특정 컨슈머 간의 점대점 메시징에 맞지 않습니다.",
    "SelectC": "AWS Lambda 함수를 생성하여 메시지를 전달합니다. 프로듀서 코드에서 Lambda 함수를 호출해 데이터를 넘기고, 컨슈머 코드에서 Lambda가 전달하는 데이터를 받습니다.",
    "SelectC_Commentary": "직접 Lambda 함수를 호출해야 하므로 완전히 비동기적이지 않고, 마이크로서비스 간 분리도가 낮아집니다.",
    "SelectD": "Amazon DynamoDB 테이블을 만들고 DynamoDB Streams를 활성화합니다. 프로듀서 코드에서 테이블에 데이터를 삽입하고, 컨슈머 코드에서 Streams API를 통해 새 항목을 감지해 처리합니다.",
    "SelectD_Commentary": "데이터 처리를 위해 주기적으로 Streams를 확인해야 하므로 큐 기반 비동기 방식에 비해 단순성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q263",
      "Q138",
      "Q375",
      "Q288",
      "Q434"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q363",
      "Q149"
    ],
    "SelectB_recommedations": [
      "Q615",
      "Q967",
      "Q58"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q404",
      "Q531"
    ],
    "SelectD_recommedations": [
      "Q1002",
      "Q78",
      "Q845"
    ]
  },
  {
    "Question_Number": "Q182",
    "Question_Description": "한 회사가 온프레미스의 MySQL 데이터베이스를 AWS로 마이그레이션하려고 합니다. 이 회사는 최근에 데이터베이스 장애가 발생하여 비즈니스에 큰 영향을 받았습니다. 이를 다시 겪지 않도록, 회사는 트랜잭션을 최소 두 개 노드에 저장하며 데이터 손실을 최소화하는 안정적인 AWS 기반 데이터베이스 솔루션을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87641-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 최소 두 노드에 트랜잭션을 동기 복제하여 데이터 손실 위험을 극도로 낮추는 고가용성 아키텍처를 구축하는 것입니다. Amazon RDS for MySQL에서 Multi-AZ를 활성화하면, 기본 노드와 스탠바이 노드 간에 동기 복제가 이루어져 장애 시에도 데이터 손실을 최소화할 수 있습니다. 이 표준 방식은 AWS가 자동으로 관리해주므로 운영 부담도 적고 안정성이 높습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "MySQL 데이터베이스 마이그레이션",
      "데이터 손실 최소화",
      "트랜잭션",
      "Multi-AZ",
      "동기 복제",
      "Amazon RDS"
    ],
    "Terms": [
      "RDS MySQL DB instance",
      "Multi-AZ",
      "Synchronous Replication",
      "Read Replica",
      "Amazon EC2",
      "AWS Lambda",
      "노드",
      "트랜잭션"
    ],
    "SelectA": "Amazon RDS DB 인스턴스를 생성하고, 세 개의 가용 영역(Availability Zones)에 동기 복제를 설정합니다.",
    "SelectA_Commentary": "기본 RDS MySQL 구성만으로는 세 AZ로의 동기 복제는 보장되지 않습니다. 일반적으로 Multi-AZ는 두 AZ 구성이며, 세 AZ는 별도의 구성 또는 Amazon Aurora와 같은 다른 서비스를 고려해야 합니다.",
    "SelectB": "Amazon RDS MySQL DB 인스턴스를 생성하고, Multi-AZ 기능을 활성화하여 데이터를 동기 복제합니다.",
    "SelectB_Commentary": "Multi-AZ 기능은 기본 노드와 스탠바이 노드 간 동기 복제를 제공하여 장애 시 즉시 전환이 가능하고 데이터 손실이 거의 없는 고가용성 솔루션이므로 요구사항에 부합합니다.",
    "SelectC": "Amazon RDS MySQL DB 인스턴스를 생성한 후, 별도의 AWS 리전에 리드 레플리카를 생성하여 데이터를 동기 복제합니다.",
    "SelectC_Commentary": "리드 레플리카는 비동기 복제이므로 동기 복제가 필수인 이 시나리오에 적합하지 않습니다. 데이터 손실 위험이 남아 있습니다.",
    "SelectD": "MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성하고, AWS Lambda 함수를 트리거하여 Amazon RDS MySQL DB 인스턴스로 데이터를 동기 복제합니다.",
    "SelectD_Commentary": "직접 동기 복제를 구현하기 위해 여러 서비스를 연동하는 방식으로 복잡도가 매우 높고, 자동화된 고가용성 기능을 제공하지 않으므로 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q683",
      "Q824",
      "Q843",
      "Q293",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q444",
      "Q466",
      "Q518"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q958",
      "Q466"
    ],
    "SelectC_recommedations": [
      "Q518",
      "Q629",
      "Q259"
    ],
    "SelectD_recommedations": [
      "Q824",
      "Q182",
      "Q683"
    ]
  },
  {
    "Question_Number": "Q183",
    "Question_Description": "한 회사가 새로운 동적 Ordering 웹사이트를 구축하려고 합니다. 이 회사는 서버 유지 관리와 패치를 최소화하고자 합니다. 웹사이트는 고가용성을 가져야 하며, 사용자 수요 변화에 따라 읽기 및 쓰기 용량을 빠르게 확장할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87570-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버 관리를 최소화하면서 고가용성 및 빠른 확장을 요구하는 웹 애플리케이션 아키텍처를 묻습니다. 정답은 서버리스와 Amazon DynamoDB on-demand로 즉시 스케일링이 가능한 A입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "동적 Ordering 웹사이트",
      "서버 유지 관리 최소화",
      "고가용성",
      "빠른 읽기/쓰기 확장",
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB on-demand",
      "Amazon Aurora",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "On-demand capacity",
      "Amazon Aurora",
      "Aurora Auto Scaling",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "Provisioned write capacity",
      "Amazon CloudFront"
    ],
    "SelectA": "static content를 Amazon S3에 호스팅합니다. dynamic content는 Amazon API Gateway와 AWS Lambda를 사용합니다. 데이터베이스로 Amazon DynamoDB(on-demand capacity)를 사용합니다. Amazon CloudFront를 구성하여 웹사이트 콘텐츠를 전달합니다.",
    "SelectA_Commentary": "서버리스 기반 구성으로 서버 유지 관리가 없고, Amazon DynamoDB on-demand로 읽기/쓰기를 즉시 확장하여 고가용성과 민첩성을 모두 만족합니다.",
    "SelectB": "static content를 Amazon S3에 호스팅합니다. dynamic content는 Amazon API Gateway와 AWS Lambda를 사용합니다. 데이터베이스로 Amazon Aurora와 Aurora Auto Scaling을 사용합니다. Amazon CloudFront를 구성하여 웹사이트 콘텐츠를 전달합니다.",
    "SelectB_Commentary": "Aurora Auto Scaling은 읽기 복제본 확장 위주여서 쓰기 확장에는 제한이 있어 요구사항을 충분히 충족하지 못합니다.",
    "SelectC": "모든 웹사이트 콘텐츠를 Amazon EC2 인스턴스에서 호스팅합니다. Auto Scaling group을 생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer로 트래픽을 분산합니다. 데이터베이스로 Amazon DynamoDB(provisioned write capacity)를 사용합니다.",
    "SelectC_Commentary": "EC2 인스턴스는 서버 유지 관리와 패치 부담이 크고, provisioned 용량 모드는 빠른 수요 변화 대응에 제약이 생깁니다.",
    "SelectD": "모든 웹사이트 콘텐츠를 Amazon EC2 인스턴스에서 호스팅합니다. Auto Scaling group을 생성하여 EC2 인스턴스를 확장합니다. Application Load Balancer로 트래픽을 분산합니다. 데이터베이스로 Amazon Aurora와 Aurora Auto Scaling을 사용합니다.",
    "SelectD_Commentary": "EC2 인스턴스 기반으로 서버 패치 부담이 있고, Aurora Auto Scaling은 읽기 위주 확장만 가능하며 쓰기 확장에는 제한이 있어 요구사항 충족이 어렵습니다.",
    "Question_Description_recommedations": [
      "Q917",
      "Q58",
      "Q255",
      "Q491",
      "Q735"
    ],
    "SelectA_recommedations": [
      "Q935",
      "Q354",
      "Q944"
    ],
    "SelectB_recommedations": [
      "Q354",
      "Q944",
      "Q935"
    ],
    "SelectC_recommedations": [
      "Q935",
      "Q1001",
      "Q874"
    ],
    "SelectD_recommedations": [
      "Q69",
      "Q405",
      "Q275"
    ]
  },
  {
    "Question_Number": "Q184",
    "Question_Description": "한 회사가 소프트웨어 엔지니어링을 위해 사용하는 AWS account가 있습니다. 이 AWS account는 두 개의 AWS Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 접속할 수 있습니다. 모든 non-VPC 트래픽은 virtual private gateway로 라우팅됩니다. 최근 개발 팀이 console을 통해 AWS Lambda function을 생성했습니다. 이 Lambda function이 회사 데이터 센터의 private subnet에서 실행 중인 데이터베이스에 접근할 수 있게 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87534-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Lambda function이 온프레미스 DB에 안전하게 연결되려면, 이미 설정된 AWS Direct Connect 및 virtual private gateway를 활용해 VPC 내부에서 실행해야 합니다. 보안 그룹과 VPC 설정을 통해 트래픽을 제어하고 안정적으로 연결할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "AWS account",
      "AWS Direct Connect",
      "AWS Lambda function",
      "private subnet",
      "virtual private gateway",
      "security group",
      "route table"
    ],
    "Terms": [
      "AWS account",
      "AWS Direct Connect",
      "VPC",
      "virtual private gateway",
      "AWS Lambda",
      "private subnet",
      "security group",
      "route table",
      "VPN",
      "Elastic IP",
      "elastic network interface(ENI)",
      "console"
    ],
    "SelectA": "Lambda function을 해당 VPC에서 실행하도록 설정하고, 적절한 security group을 구성합니다.",
    "SelectA_Commentary": "함수를 VPC 내부에 두면 기존 Direct Connect 연결을 활용하여 안전하고 직접적으로 온프레미스 DB에 접근할 수 있습니다.",
    "SelectB": "AWS에서 data center로의 VPN connection을 설정하고, Lambda function 트래픽을 VPN을 통해 전달합니다.",
    "SelectB_Commentary": "이미 Direct Connect가 구성되어 있어 추가 VPN 연결은 불필요하며, 복잡도와 비용만 증가시킵니다.",
    "SelectC": "VPC의 route table을 업데이트하여 Lambda function이 Direct Connect를 통해 온프레미스 데이터 센터에 접근하도록 허용합니다.",
    "SelectC_Commentary": "Route table만 수정해도 Lambda function이 기본적으로 VPC 내에서 실행되지 않으면 온프레미스 DB에 접근할 수 없습니다.",
    "SelectD": "Elastic IP address를 생성하고, Lambda function이 elastic network interface 없이 해당 Elastic IP address를 통해 트래픽을 전송하도록 구성합니다.",
    "SelectD_Commentary": "Lambda function은 자체적으로 ENI를 사용해 VPC와 통신하므로 Elastic IP만으로는 온프레미스 DB 연결이 불가능합니다.",
    "Question_Description_recommedations": [
      "Q782",
      "Q791",
      "Q839",
      "Q712",
      "Q950"
    ],
    "SelectA_recommedations": [
      "Q135",
      "Q791",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q184",
      "Q712"
    ],
    "SelectC_recommedations": [
      "Q184",
      "Q791",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q791",
      "Q96",
      "Q744"
    ]
  },
  {
    "Question_Number": "Q185",
    "Question_Description": "한 회사가 Amazon ECS를 사용하여 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 원본 이미지를 리사이즈한 후, Amazon S3 API 콜을 통해 리사이즈된 이미지를 Amazon S3에 저장합니다. 솔루션스 아키텍트는 어떻게 해야 애플리케이션에 Amazon S3에 대한 접근 권한을 부여할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87648-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ECS 컨테이너가 S3에 직접 접근할 수 있도록 IAM 역할을 올바르게 설정하는 방법을 묻습니다. 가장 단순하고 안전한 방식은 IAM 역할을 생성하여 필요한 권한을 부여한 뒤, 해당 역할을 ECS 태스크 정의에 설정하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon ECS",
      "Amazon S3",
      "IAM role",
      "리사이즈 이미지"
    ],
    "Terms": [
      "Amazon ECS",
      "Amazon S3",
      "IAM role",
      "AWS Identity and Access Management(IAM)",
      "taskRoleArn",
      "Security Group"
    ],
    "SelectA": "AWS IAM에서 S3 role을 업데이트하여 Amazon ECS의 읽기/쓰기 권한을 허용하고, 컨테이너를 다시 시작합니다.",
    "SelectA_Commentary": "S3 role만 수정해서는 ECS 태스크에 자동으로 권한이 부여되지 않습니다. 또한 재시작만으로 태스크별 역할이 반영되지 않습니다.",
    "SelectB": "S3 권한을 가진 IAM role을 생성한 뒤, 해당 role을 태스크 정의의 taskRoleArn으로 지정합니다.",
    "SelectB_Commentary": "IAM 역할을 태스크에 직접 할당하면 컨테이너가 Amazon S3 API 호출을 안전하게 수행할 수 있어 요구사항을 충족합니다.",
    "SelectC": "Amazon ECS에서 Amazon S3로의 액세스를 허용하는 Security Group을 만들고, ECS 클러스터에서 사용하는 런치 구성에 반영합니다.",
    "SelectC_Commentary": "Security Group은 네트워크 트래픽 제어용이며, S3 API 자격 증명 권한 부여와는 직접 관련이 없어 권한 문제를 해결하지 못합니다.",
    "SelectD": "S3 권한이 있는 IAM user를 생성하고, 해당 계정으로 로그인한 상태에서 ECS 클러스터용 Amazon EC2 인스턴스를 재시작합니다.",
    "SelectD_Commentary": "EC2 인스턴스 수준 계정을 사용하는 것은 비효율적이고 보안 모범 사례에 어긋나며, 컨테이너 단위 IAM 권한 관리를 지원하지 못합니다.",
    "Question_Description_recommedations": [
      "Q91",
      "Q612",
      "Q208",
      "Q270",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q185",
      "Q4",
      "Q92"
    ],
    "SelectB_recommedations": [
      "Q982",
      "Q202",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q185",
      "Q92",
      "Q4"
    ],
    "SelectD_recommedations": [
      "Q185",
      "Q612",
      "Q4"
    ]
  },
  {
    "Question_Number": "Q186",
    "Question_Description": "한 회사가 Windows 기반 애플리케이션을 AWS로 마이그레이션해야 합니다. 이 애플리케이션은 여러 가용 영역(Availability Zone)에 배포된 여러 Amazon EC2 Windows 인스턴스에 공유 Windows 파일 시스템을 연결해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87650-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows 환경에서 여러 AZ에 걸친 공유 파일 시스템이 필요할 때 올바른 AWS 서비스 선택을 묻습니다. Amazon FSx for Windows File Server는 SMB 기반 공유 파일 시스템을 제공하므로, Windows 애플리케이션이 요구하는 파일 잠금 및 권한 관리를 제대로 지원합니다. EFS는 Linux용 NFS 기반이므로 부적합하며, EBS는 단일 AZ 자원이기 때문에 다수의 인스턴스에서 동시 사용이 어렵습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Windows 기반 애플리케이션",
      "공유 Windows 파일 시스템",
      "Amazon EC2 Windows 인스턴스",
      "Amazon FSx for Windows File Server",
      "Amazon EFS",
      "AWS Storage Gateway",
      "Amazon EBS"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Volume Gateway mode",
      "Amazon FSx for Windows File Server",
      "SMB 프로토콜",
      "Amazon EFS",
      "NFS 프로토콜",
      "Amazon EBS",
      "멀티 AZ"
    ],
    "SelectA": "AWS Storage Gateway를 volume gateway 모드로 설정하고 각 Windows 인스턴스에 해당 볼륨을 마운트합니다.",
    "SelectA_Commentary": "Storage Gateway는 온프레미스와 클라우드 통합 시 주로 사용되고, Windows 인스턴스에 대한 네이티브 SMB 공유를 제공하지 않아 요구 사항에 부적합합니다.",
    "SelectB": "Amazon FSx for Windows File Server를 구성하고, 각 Windows 인스턴스에 Amazon FSx 파일 시스템을 마운트합니다.",
    "SelectB_Commentary": "FSx for Windows File Server는 SMB 기반 공유 파일 시스템을 제공하며, 멀티 AZ 환경에서도 고가용성과 Windows 파일 잠금을 지원하는 최적의 솔루션입니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS)을 구성하고 각 Windows 인스턴스에 해당 EFS 파일 시스템을 마운트합니다.",
    "SelectC_Commentary": "EFS는 NFS 기반으로 Linux 워크로드에 최적화되어 Windows 인스턴스에서 SMB를 활용해야 하는 요구 사항을 충족하지 못합니다.",
    "SelectD": "필요한 크기의 Amazon EBS 볼륨을 생성한 뒤 각 EC2 인스턴스에 연결하고, 각 Windows 인스턴스에서 볼륨 내 파일 시스템을 마운트합니다.",
    "SelectD_Commentary": "EBS는 단일 가용 영역 리소스이므로 여러 인스턴스가 동시에 공유하기 어렵고, 원하는 공유 파일 시스템 요구를 만족시키기 곤란합니다.",
    "Question_Description_recommedations": [
      "Q54",
      "Q47",
      "Q892",
      "Q508",
      "Q224"
    ],
    "SelectA_recommedations": [
      "Q186",
      "Q10",
      "Q972"
    ],
    "SelectB_recommedations": [
      "Q618",
      "Q54",
      "Q635"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q54"
    ],
    "SelectD_recommedations": [
      "Q602",
      "Q584",
      "Q244"
    ]
  },
  {
    "Question_Number": "Q187",
    "Question_Description": "회사는 로드밸런싱된 프론트엔드, 컨테이너 기반 애플리케이션, 관계형 데이터베이스로 구성된 전자상거래 애플리케이션을 개발 중입니다. 솔루션스 아키텍트는 운영자의 수동 개입이 최소화된 상태로 고가용성을 달성해야 합니다. 다음 중 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (두 가지를 고르십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87695-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전자상거래 애플리케이션에서 고가용성을 구현하고 운영 부담을 최소화하는 방안을 묻습니다. Amazon RDS Multi-AZ 배포를 통해 장애 조치 시 자동화된 복구가 이루어지므로 낮은 수동 개입으로 고가용성을 보장할 수 있습니다. 또한 Amazon ECS를 Fargate launch type으로 사용하면 서버 인프라를 직접 관리할 필요가 없어 운영자가 개입할 부분을 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "로드밸런싱",
      "컨테이너 기반 애플리케이션",
      "관계형 데이터베이스",
      "고가용성",
      "수동 개입 최소화",
      "Multi-AZ",
      "Amazon ECS",
      "Fargate"
    ],
    "Terms": [
      "Amazon RDS",
      "Multi-AZ",
      "Read Replica",
      "Amazon ECS",
      "AWS Fargate",
      "Docker",
      "Amazon EC2"
    ],
    "SelectA": "Create an Amazon RDS DB instance in Multi-AZ mode.",
    "SelectA_Commentary": "Multi-AZ 모드는 장애 발생 시 자동으로 대기 인스턴스로 전환되어 DB 가용성을 높이고 수동 개입을 최소화합니다.",
    "SelectB": "Create an Amazon RDS DB instance and one or more replicas in another Availability Zone.",
    "SelectB_Commentary": "Read Replica는 장애 시 수동으로 프로모션해야 하므로 자동화와 즉각적인 장애 조치가 어렵습니다.",
    "SelectC": "Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load.",
    "SelectC_Commentary": "EC2 인스턴스에서 Docker 클러스터를 직접 운영하면 인프라 관리 부담이 크고 수동 개입 필요성이 증가합니다.",
    "SelectD": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load.",
    "SelectD_Commentary": "AWS Fargate는 서버 관리가 필요 없는 완전관리형 컨테이너 환경이므로, 동적으로 확장 가능하며 수동 개입을 크게 줄입니다.",
    "SelectE": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load.",
    "SelectE_Commentary": "EC2 launch type은 사용자 측에서 클러스터와 EC2 인스턴스를 직접 관리해야 하므로 자동화 측면에서 덜 유리합니다.",
    "Question_Description_recommedations": [
      "Q917",
      "Q58",
      "Q255",
      "Q491",
      "Q735"
    ],
    "SelectA_recommedations": [
      "Q466",
      "Q464",
      "Q390"
    ],
    "SelectB_recommedations": [
      "Q466",
      "Q444",
      "Q298"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q772",
      "Q405"
    ],
    "SelectD_recommedations": [
      "Q303",
      "Q900",
      "Q698"
    ],
    "SelectE_recommedations": [
      "Q900",
      "Q581",
      "Q563"
    ]
  },
  {
    "Question_Number": "Q188",
    "Question_Description": "한 회사는 Amazon S3를 데이터 레이크로 사용하고 있습니다. 회사에는 새로운 파트너가 있으며, 이 파트너는 SFTP를 통해 데이터 파일을 업로드해야 합니다. 솔루션스 아키텍트는 고가용성 SFTP 솔루션을 구현하면서 운영 오버헤드를 최소화할 필요가 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87566-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새 파트너와의 SFTP 데이터 전송을 지원하면서도 운영 복잡성을 줄이고 고가용성을 확보해야 하는 상황을 다룹니다. AWS Transfer Family는 별도 인프라 생성 없이 간단히 SFTP 서버를 구성하고 Amazon S3와 직접 연동하여 고가용성을 자동으로 제공하므로 운영 오버헤드를 최소화할 수 있는 최적의 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "SFTP",
      "고가용성",
      "운영 오버헤드 최소화",
      "AWS Transfer Family",
      "Amazon S3"
    ],
    "Terms": [
      "AWS Transfer Family",
      "Amazon S3 File Gateway",
      "Amazon EC2",
      "Network Load Balancer",
      "cron job script",
      "VPN",
      "SFTP"
    ],
    "SelectA": "AWS Transfer Family를 사용해 SFTP 활성 서버를 구성하고, 공개적으로 접근 가능한 엔드포인트를 설정합니다. Amazon S3 data lake를 대상으로 지정합니다.",
    "SelectA_Commentary": "AWS Transfer Family는 별도 EC2 서버나 로드 밸런서 구성이 필요 없고, Amazon S3로 바로 전송 가능해 운영 비용과 복잡성을 대폭 줄입니다.",
    "SelectB": "Amazon S3 File Gateway를 SFTP 서버로 사용합니다. S3 File Gateway 엔드포인트 URL을 파트너에게 노출하고 공유합니다.",
    "SelectB_Commentary": "S3 File Gateway는 SFTP를 직접 지원하지 않아 추가 설정이 필요하며, 운영 과정도 더 복잡해 최적의 솔루션이 아닙니다.",
    "SelectC": "Amazon EC2 인스턴스를 VPC의 사설 서브넷에 배포하고, 파트너가 VPN으로 접속해 파일을 업로드하도록 합니다. EC2 인스턴스 상의 cron job 스크립트를 통해 S3로 데이터를 전송합니다.",
    "SelectC_Commentary": "VPN 설정과 EC2 유지보수가 필요하며, 고가용성을 위해서는 추가 구성이 복잡해 운영 오버헤드가 크게 늘어납니다.",
    "SelectD": "VPC의 사설 서브넷에 여럿의 Amazon EC2 인스턴스를 띄우고, Network Load Balancer(NLB)를 앞단에 배치해 SFTP 리스너 포트를 엽니다. NLB 호스트네임을 파트너에게 공유한 뒤, cron job으로 S3에 업로드합니다.",
    "SelectD_Commentary": "NLB와 EC2 인스턴스 다중화로 고가용성은 가능하지만, 서버 유지 및 스크립트 작업으로 인한 운영 오버헤드가 크므로 Transfer Family에 비해 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q753",
      "Q94",
      "Q784",
      "Q18",
      "Q110"
    ],
    "SelectA_recommedations": [
      "Q188",
      "Q753",
      "Q717"
    ],
    "SelectB_recommedations": [
      "Q188",
      "Q753",
      "Q10"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q237",
      "Q487"
    ],
    "SelectD_recommedations": [
      "Q639",
      "Q70",
      "Q545"
    ]
  },
  {
    "Question_Number": "Q189",
    "Question_Description": "한 회사에서 계약 문서를 저장해야 합니다. 계약은 5년 동안 유효하며, 이 기간 동안 문서를 절대 덮어쓰거나 삭제할 수 없어야 합니다. 또한 문서는 저장 시점에 암호화되어야 하고, 매년 암호화 키를 자동으로 교체해야 합니다. 회사는 이 모든 요구사항을 충족하면서 운영 오버헤드를 최소화하기를 원합니다. 어떤 솔루션 조합을 선택해야 합니까? (2개를 선택하십시오.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87535-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "S3 Object Lock의 compliance mode로 문서의 변경 및 삭제를 막고, AWS KMS Customer Managed Key 자동 키 회전을 통해 매년 보안 요구사항을 만족하면서 운영 부담을 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "계약 문서",
      "S3 Object Lock",
      "compliance mode",
      "암호화",
      "매년 키 회전",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Object Lock",
      "governance mode",
      "compliance mode",
      "AWS Key Management Service (AWS KMS)",
      "SSE-S3",
      "SSE-KMS",
      "Customer Managed Keys",
      "Imported Keys",
      "WORM(Write Once Read Many)"
    ],
    "SelectA": "문서를 Amazon S3에 저장하고, S3 Object Lock을 governance mode로 사용합니다.",
    "SelectA_Commentary": "governance mode는 관리자 권한으로 잠금 설정을 해제할 수 있어 완전한 불변 보장을 제공하지 않아 요구 사항을 충족하기 어렵습니다.",
    "SelectB": "문서를 Amazon S3에 저장하고, S3 Object Lock을 compliance mode로 사용합니다.",
    "SelectB_Commentary": "compliance mode는 관리자 권한이 있어도 삭제나 덮어쓰기가 불가능해 5년 보존을 완전히 보장합니다. 요구 사항에 부합합니다.",
    "SelectC": "Amazon S3 서버 사이드 암호화(SSE-S3)를 사용하고, 키 회전을 구성합니다.",
    "SelectC_Commentary": "SSE-S3는 AWS가 키를 자동으로 교체하지만 정확히 매년 회전 일자를 보장하지 않아 요구 사항 충족에 불확실성이 있습니다.",
    "SelectD": "AWS KMS Customer Managed Keys를 사용한 서버 사이드 암호화(SSE-KMS)를 적용하고, 키 회전을 구성합니다.",
    "SelectD_Commentary": "KMS Customer Managed Key에 대해 1년 주기의 자동 키 회전을 설정할 수 있어 요구 사항을 만족합니다. 운영 오버헤드도 상대적으로 적습니다.",
    "SelectE": "AWS KMS Customer Provided(Imported) Keys를 사용한 서버 사이드 암호화를 적용하고, 키 회전을 구성합니다.",
    "SelectE_Commentary": "사용자 제공 키를 직접 관리해야 하므로 오버헤드가 증가하며, 매년 키 교체 절차를 직접 진행해야 하므로 구현이 복잡합니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q665",
      "Q57",
      "Q122",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q202",
      "Q740"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q740",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q965",
      "Q202"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q371",
      "Q793"
    ],
    "SelectE_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ]
  },
  {
    "Question_Number": "Q190",
    "Question_Description": "한 회사에 Java와 PHP 기반의 웹 애플리케이션이 있습니다. 회사는 이 애플리케이션을 온프레미스 환경에서 AWS로 이전하려고 합니다. 사이트의 새로운 기능을 자주 테스트해야 하며, 고가용성을 갖추고 운영 오버헤드가 최소화된 매니지드 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/87536-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 Java와 PHP 기반 웹 애플리케이션을 AWS로 이전하면서, 기능 테스트를 자주 하더라도 운영 오버헤드를 최소화하고 고가용성을 유지할 수 있는 서비스를 찾는 것이 핵심입니다. AWS Elastic Beanstalk은 관리형 서비스로 인프라 설정과 운영을 추상화해 주어 운영 오버헤드가 적고, URL swapping 기능으로 여러 환경을 손쉽게 전환하여 새로운 기능을 테스트할 수 있습니다. 다른 선택지는 관리나 설정이 더 복잡하거나, Java와 PHP 기반 웹 애플리케이션을 신속히 테스트하고 운영하기에는 적절치 않습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Java",
      "PHP",
      "고가용성",
      "매니지드 솔루션",
      "자주 기능 테스트",
      "최소 운영 오버헤드",
      "AWS Elastic Beanstalk",
      "URL swapping"
    ],
    "Terms": [
      "Amazon S3",
      "Static web hosting",
      "AWS Lambda",
      "AWS Elastic Beanstalk",
      "URL swapping",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "AWS Load Balancer Controller"
    ],
    "SelectA": "Amazon S3 버킷을 생성하고 static web hosting을 활성화합니다. 정적 컨텐츠를 S3 버킷에 업로드하고, 동적 컨텐츠 처리를 위해 AWS Lambda를 사용합니다.",
    "SelectA_Commentary": "Java와 PHP 웹 애플리케이션에 필요한 동적 처리와 유지 보수 기능을 충분히 제공하지 못합니다. 정적 웹 호스팅에 Lambda만으로 동적 로직을 구현하기에는 제약이 많습니다.",
    "SelectB": "웹 애플리케이션을 AWS Elastic Beanstalk 환경에 배포합니다. 기능 테스트를 위해 여러 Elastic Beanstalk 환경 간 URL swapping을 사용합니다.",
    "SelectB_Commentary": "고가용성을 기본으로 제공하며 인프라 운영 부담이 작습니다. URL swapping 기능을 통해 새로운 기능 테스트를 원활히 진행할 수 있어 요구 사항을 충족합니다.",
    "SelectC": "Java와 PHP가 구성된 Amazon EC2 인스턴스에 웹 애플리케이션을 배포합니다. Auto Scaling group과 Application Load Balancer로 웹사이트 가용성을 관리합니다.",
    "SelectC_Commentary": "직접 EC2 인스턴스를 관리해야 하므로 운영 오버헤드가 늘고, 테스트 환경 전환도 수동 설정이 필요해 요구 조건을 만족하기 어렵습니다.",
    "SelectD": "웹 애플리케이션을 컨테이너화하고 Amazon EC2 인스턴스에 배포합니다. AWS Load Balancer Controller를 사용해 새로운 기능 컨테이너로 트래픽을 동적으로 라우팅합니다.",
    "SelectD_Commentary": "컨테이너 오케스트레이션 및 관리에 대한 추가 부담이 커집니다. 운영 오버헤드가 커져서 요구 사항인 최소화된 운영 부담에 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q914",
      "Q363",
      "Q149",
      "Q163",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q636",
      "Q404",
      "Q18"
    ],
    "SelectB_recommedations": [
      "Q664",
      "Q775",
      "Q545"
    ],
    "SelectC_recommedations": [
      "Q405",
      "Q595",
      "Q275"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q357"
    ]
  },
  {
    "Question_Number": "Q191",
    "Question_Description": "한 회사가 Amazon RDS for MySQL을 사용하여 고객 정보를 저장하는 주문 애플리케이션을 운영하고 있습니다. 업무 시간 동안 직원들이 보고를 위해 일회성 쿼리를 실행하고 있는데, 이 쿼리들이 오래 걸려서 주문 처리를 진행하는 애플리케이션에서 timeout이 발생하고 있습니다. 회사는 직원들이 쿼리를 실행할 수 없게 막지 않으면서도 timeout을 제거해야 합니다. 이러한 요구사항을 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89077-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주문 처리 트랜잭션과 보고(Reporting)용 쿼리를 분리하여 DB 부하와 타임아웃을 해소하는 방법을 묻습니다. 일회성 분석 쿼리 때문에 본 DB에 부하가 가중되어 타임아웃이 발생하므로, 별도의 Read Replica를 사용해 읽기 쿼리를 처리하는 게 효과적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "주문 애플리케이션",
      "보고(Reporting) 쿼리",
      "timeout",
      "read replica"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Read Replica",
      "Amazon DynamoDB",
      "On-demand Capacity"
    ],
    "SelectA": "Read Replica를 생성하고, 보고(Reporting) 쿼리를 Read Replica로 이동합니다.",
    "SelectA_Commentary": "글로벌하게 사용 가능한 Amazon RDS for MySQL의 Read Replica 기능을 활용해 트랜잭션과 읽기 부하를 분리함으로써 시간 초과를 방지하고 보고 쿼리도 계속 수행할 수 있습니다.",
    "SelectB": "Read Replica를 생성합니다. 주문 애플리케이션을 기본 DB 인스턴스와 Read Replica 모두에서 운영합니다.",
    "SelectB_Commentary": "주문 애플리케이션을 Read Replica에서 운영하면 쓰기 연산에 문제가 생길 수 있고, 이는 주된 목적(트랜잭션 처리와 읽기 분리)에 적합하지 않습니다.",
    "SelectC": "주문 애플리케이션을 Amazon DynamoDB로 마이그레이션하고, On-demand Capacity 모드를 사용합니다.",
    "SelectC_Commentary": "RDB 기반의 애플리케이션을 즉시 DynamoDB로 옮기는 것은 구조적 변경이 크며, 문제의 요구사항(쿼리 분리)과 직접적인 해결책이 아닙니다.",
    "SelectD": "보고(Reporting) 쿼리를 비사용 시간대로 예약하여 실행합니다.",
    "SelectD_Commentary": "비사용 시간대로 보고 쿼리를 옮기면 어느 정도 효과가 있을 수 있으나, 업무 시간 동안 보고 쿼리가 필요한 경우에는 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q376",
      "Q590",
      "Q269",
      "Q661",
      "Q389"
    ],
    "SelectA_recommedations": [
      "Q622",
      "Q506",
      "Q888"
    ],
    "SelectB_recommedations": [
      "Q77",
      "Q225",
      "Q243"
    ],
    "SelectC_recommedations": [
      "Q472",
      "Q177",
      "Q578"
    ],
    "SelectD_recommedations": [
      "Q622",
      "Q888",
      "Q132"
    ]
  },
  {
    "Question_Number": "Q192",
    "Question_Description": "한 병원이 방대한 과거 문서 기록을 디지털 사본으로 만들고자 합니다. 매일 수백 건의 새 문서가 계속 추가될 예정이며, 병원의 데이터 팀은 스캔된 문서를 AWS Cloud에 업로드합니다. 솔루션스 아키텍트는 이 문서들을 분석하고, 의료 정보를 추출하며, 애플리케이션이 해당 데이터에 대해 SQL 쿼리를 실행할 수 있도록 문서를 저장해야 합니다. 솔루션은 확장성과 운영 효율성을 극대화해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조합의 단계를 수행해야 합니까? (2개를 고르세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89133-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 의료 문서 스캔 파일에 대한 텍스트 추출과 의료 정보 파싱, 그리고 SQL 기반 조회가 가능하도록 데이터를 저장하는 확장 가능한 아키텍처를 설계하는 방법을 묻습니다. Amazon Textract와 Amazon Comprehend Medical을 사용해 문서에서 텍스트와 의료 정보를 자동 추출하고, Amazon S3 및 Amazon Athena를 통해 손쉽게 SQL 쿼리를 수행할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "디지털 사본",
      "문서 분석",
      "의료 정보 추출",
      "SQL 쿼리",
      "확장성",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon EC2",
      "MySQL",
      "Amazon S3",
      "Amazon Athena",
      "Auto Scaling group",
      "AWS Lambda",
      "Amazon Rekognition",
      "Amazon Transcribe Medical",
      "Amazon Textract",
      "Amazon Comprehend Medical"
    ],
    "SelectA": "MySQL 데이터베이스가 실행 중인 Amazon EC2 인스턴스에 문서 정보를 기록합니다.",
    "SelectA_Commentary": "EC2와 MySQL 기반 접근은 초기 규모가 커질 때 확장성 및 관리 부담이 높아지므로 비효율적입니다.",
    "SelectB": "Amazon S3 버킷에 문서 정보를 저장하고, Amazon Athena를 사용하여 해당 데이터를 쿼리합니다.",
    "SelectB_Commentary": "S3와 Athena를 이용해 스케일이 큰 데이터도 손쉽게 수집·분석 가능한 구조를 제공하므로 적합합니다. (정답)",
    "SelectC": "스캔 파일을 처리하고 의료 정보를 추출하는 커스텀 애플리케이션 실행을 위한 Amazon EC2 Auto Scaling group을 생성합니다.",
    "SelectC_Commentary": "직접 애플리케이션을 개발해 EC2 규모 확장을 관리하면 운영 복잡성이 커져서 덜 효율적입니다.",
    "SelectD": "새 문서가 업로드될 때 실행되는 AWS Lambda 함수를 만들고, Amazon Rekognition으로 문서를 텍스트로 변환 후 Amazon Transcribe Medical로 의료 정보를 추출합니다.",
    "SelectD_Commentary": "Amazon Rekognition은 주로 이미지·영상 분석에, Transcribe Medical은 음성 인식에 특화되어 적합하지 않습니다.",
    "SelectE": "새 문서 업로드 시 실행되는 AWS Lambda 함수를 만들고, Amazon Textract로 문서를 텍스트로 변환한 뒤 Amazon Comprehend Medical을 사용해 의료 정보를 추출합니다.",
    "SelectE_Commentary": "Textract로 텍스트를 정확히 추출하고 Comprehend Medical로 의료 정보를 파악하는 자동화된 확장형 솔루션입니다. (정답)",
    "Question_Description_recommedations": [
      "Q631",
      "Q568",
      "Q565",
      "Q547",
      "Q443"
    ],
    "SelectA_recommedations": [
      "Q229",
      "Q565",
      "Q834"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q43",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q461",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q603",
      "Q631",
      "Q361"
    ],
    "SelectE_recommedations": [
      "Q631",
      "Q603",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q193",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 배치 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 여러 Amazon RDS 데이터베이스로 구성된 백엔드를 포함하고 있습니다. 현재 이 애플리케이션은 데이터베이스에 매우 많은 읽기 요청을 발생시키고 있습니다. 솔루션스 아키텍트는 고가용성을 보장하면서 데이터베이스 읽기 부하를 줄여야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89134-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터베이스에 걸리는 과도한 읽기 부하를 완화하면서 고가용성을 유지해야 하는 시나리오입니다. Redis는 멀티 AZ 구성과 자동 장애 조치(automatic failover)를 제공하여, 읽기 성능 향상과 고가용성을 모두 충족시킬 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "배치 애플리케이션",
      "Amazon EC2",
      "Amazon RDS",
      "읽기 부하 감소",
      "고가용성"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "read replicas",
      "Amazon ElastiCache for Redis",
      "Amazon Route 53",
      "Amazon ElastiCache for Memcached"
    ],
    "SelectA": "Amazon RDS read replicas를 추가합니다.",
    "SelectA_Commentary": "읽기 전용 복제본이 읽기 부담을 낮출 수 있지만, 자체 캐싱 솔루션만큼 효율적이거나 간단하지 않으며, 고가용성 측면에서도 Redis의 자동 장애 조치 대비 제한적입니다.",
    "SelectB": "Amazon ElastiCache for Redis를 사용합니다.",
    "SelectB_Commentary": "Redis는 멀티 AZ를 지원하고, 빈번한 읽기를 캐싱해 RDS 부하를 크게 줄이면서 복제 및 장애 조치를 통해 고가용성을 달성할 수 있어 최적의 선택입니다.",
    "SelectC": "Amazon Route 53 DNS 캐싱을 사용합니다.",
    "SelectC_Commentary": "DNS 캐싱은 데이터베이스 읽기 부하를 줄이는 직접적인 방법이 아니므로, 문제 해결에 적합하지 않습니다.",
    "SelectD": "Amazon ElastiCache for Memcached를 사용합니다.",
    "SelectD_Commentary": "Memcached는 고성능 캐싱을 제공하지만 멀티 AZ 지원과 자동 장애 조치 기능면에서 Redis만큼 고가용성을 보장하지 못합니다.",
    "Question_Description_recommedations": [
      "Q661",
      "Q910",
      "Q269",
      "Q386",
      "Q706"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q501",
      "Q243"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q704",
      "Q620"
    ],
    "SelectC_recommedations": [
      "Q582",
      "Q38",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q704",
      "Q620",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q194",
    "Question_Description": "한 회사가 중요한 애플리케이션을 AWS에서 운영해야 합니다. 회사는 애플리케이션의 데이터베이스용으로 Amazon EC2를 사용해야 합니다. 데이터베이스는 고가용성을 갖춰야 하며, 장애가 발생할 경우 자동으로 장애 조치가 이루어져야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89136-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2로 구축한 데이터베이스에 대해 고가용성과 자동 장애조치 기능을 요구하고 있습니다. 단일 AZ나 Region 간 복제만으로는 신속한 자동 장애조치를 모두 충족하기 어렵습니다. 동일 Region 내 서로 다른 Availability Zone에 여러 인스턴스를 클러스터로 구성하고 데이터베이스를 복제하는 방식이 보다 안정적입니다. 이에 따라 서로 다른 AZ에서 장애가 발생해도 자동으로 다른 인스턴스가 즉시 역할을 넘겨받아 서비스 중단을 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "데이터베이스 고가용성",
      "자동 장애조치",
      "EC2 인스턴스 클러스터링",
      "Availability Zone",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Amazon Machine Image (AMI)",
      "AWS CloudFormation",
      "EC2 automatic recovery",
      "database replication"
    ],
    "SelectA": "두 개의 EC2 인스턴스를 동일 AWS Region 내 서로 다른 Availability Zone에 각각 실행합니다. 각 EC2 인스턴스에 데이터베이스를 설치하고 클러스터 구성 및 데이터베이스 복제를 설정합니다.",
    "SelectA_Commentary": "고가용성을 위해 서로 다른 AZ에서 인스턴스를 클러스터로 구성해 자동 장애조치를 가능케 하며 요구 사항을 충족하는 최적의 방법입니다.",
    "SelectB": "한 Availability Zone에 EC2 인스턴스를 실행하고 데이터베이스를 설치합니다. Amazon Machine Image(AMI)를 사용하여 데이터를 백업하고, AWS CloudFormation으로 장애 발생 시 인스턴스를 자동 프로비저닝합니다.",
    "SelectB_Commentary": "자동 프로비저닝은 가능하지만 다른 AZ에 즉시 대기 중인 인스턴스가 없어 자동 장애조치 요구사항이 완벽히 충족되지 않습니다.",
    "SelectC": "서로 다른 AWS Region에 두 개의 EC2 인스턴스를 각각 실행하고, 데이터베이스를 설치한 뒤 복제를 설정합니다. 두 번째 Region으로 데이터베이스를 장애조치합니다.",
    "SelectC_Commentary": "Region 간 장애조치는 가능하지만 대기 시간이 길 수 있고, 단순 멀티-AZ 구성보다 운영 복잡도가 높아 즉시 자동 장애조치 측면에서 비효율적입니다.",
    "SelectD": "한 Availability Zone에 EC2 인스턴스를 실행하고 데이터베이스를 설치합니다. Amazon Machine Image(AMI)로 데이터를 백업합니다. EC2 automatic recovery를 사용하여 장애가 발생하면 인스턴스를 복구합니다.",
    "SelectD_Commentary": "automatic recovery는 동일 AZ 내에서 하드웨어 이슈와 같은 문제를 복구할 수 있으나, AZ 자체 장애 시 자동 장애조치가 보장되지 않아 고가용성을 만족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q584",
      "Q892",
      "Q757",
      "Q790",
      "Q252"
    ],
    "SelectA_recommedations": [
      "Q47",
      "Q456",
      "Q312"
    ],
    "SelectB_recommedations": [
      "Q639",
      "Q47",
      "Q691"
    ],
    "SelectC_recommedations": [
      "Q456",
      "Q47",
      "Q312"
    ],
    "SelectD_recommedations": [
      "Q639",
      "Q691",
      "Q47"
    ]
  },
  {
    "Question_Number": "Q195",
    "Question_Description": "한 회사의 주문 시스템은 고객으로부터 Amazon EC2 인스턴스로 요청을 전송합니다. EC2 인스턴스는 주문을 처리한 후 Amazon RDS 데이터베이스에 저장합니다. 사용자는 시스템 장애가 발생할 때마다 주문을 다시 처리해야 한다고 보고했습니다. 회사는 시스템 장애가 발생해도 주문을 자동으로 처리할 수 있는 복원력 있는 솔루션을 원합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89138-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주문 처리를 EC2 인스턴스만으로 담당할 때 장애가 발생하면 주문이 유실되어 재처리가 필요한 상황을 해결하려는 것입니다. Amazon SQS를 통해 주문을 비동기적으로 관리하면, 인스턴스가 장애가 나도 메시지는 큐에 남아 복구 후 자동으로 처리될 수 있어 복원력과 내결함성을 갖추게 됩니다. Auto Scaling group으로 EC2 인스턴스를 운영하면 장애나 트래픽 급증에도 자동으로 대체 인스턴스를 확보하고, 큐에 남은 주문들을 차례로 처리할 수 있어 안정적인 서비스가 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Auto Scaling group",
      "Amazon SQS",
      "주문 처리",
      "복원력",
      "내결함성"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Auto Scaling group",
      "Application Load Balancer (ALB)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda",
      "AWS Systems Manager Run Command"
    ],
    "SelectA": "EC2 인스턴스를 Auto Scaling group으로 이동하고, Amazon EventBridge (Amazon CloudWatch Events) 규칙을 생성하여 Amazon ECS 태스크를 대상으로 설정합니다.",
    "SelectA_Commentary": "EventBridge + ECS 태스크만으로는 주문을 안전하게 큐잉해두는 메커니즘이 없어, 장애 발생 시 주문을 재처리해야 하는 문제가 여전히 남습니다.",
    "SelectB": "EC2 인스턴스를 Auto Scaling group 뒤의 Application Load Balancer(ALB)에 배치하고, 주문 시스템이 ALB 엔드포인트로 메시지를 전송하도록 업데이트합니다.",
    "SelectB_Commentary": "ALB로 트래픽을 분산할 순 있지만 메시지가 큐에 저장되지 않아, 인스턴스 장애 시 주문이 유실될 수 있습니다.",
    "SelectC": "EC2 인스턴스를 Auto Scaling group으로 이동합니다. 주문 시스템이 Amazon Simple Queue Service(Amazon SQS) 큐로 메시지를 보내도록 구성하고, EC2 인스턴스가 큐에서 메시지를 소비하도록 설정합니다.",
    "SelectC_Commentary": "Amazon SQS를 활용해 주문을 비동기 처리하면 인스턴스 장애 시에도 큐에 메시지가 남아 자동 재처리가 가능해 복원력이 뛰어난 아키텍처를 구현할 수 있습니다.",
    "SelectD": "Amazon Simple Notification Service(Amazon SNS) 토픽을 생성하고, AWS Lambda 함수를 만들어 SNS 토픽에 구독시킵니다. 주문 시스템이 SNS 토픽으로 메시지를 전송하도록 구성한 후, AWS Systems Manager Run Command를 사용해 EC2 인스턴스가 메시지를 처리하도록 지시합니다.",
    "SelectD_Commentary": "SNS를 사용하면 메시지 전달은 가능하지만 메시지 자동 재처리가 어렵고, EC2 인스턴스로의 처리 연결도 복잡해 장애 대비가 충분치 않습니다.",
    "Question_Description_recommedations": [
      "Q67",
      "Q125",
      "Q584",
      "Q757",
      "Q244"
    ],
    "SelectA_recommedations": [
      "Q581",
      "Q595",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q846",
      "Q174"
    ],
    "SelectC_recommedations": [
      "Q581",
      "Q595",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q45",
      "Q148"
    ]
  },
  {
    "Question_Number": "Q196",
    "Question_Description": "한 회사가 대규모 Amazon EC2 인스턴스 군에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon DynamoDB 테이블에 데이터를 읽고 쓰며, DynamoDB 테이블의 크기는 지속적으로 커지고 있습니다. 그러나 애플리케이션은 최근 30일의 데이터만 필요합니다. 회사는 비용과 개발 노력을 최소화하는 솔루션이 필요합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89140-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB 테이블에서 최근 30일 데이터만 유지해야 할 때, 운영 효율성과 비용 측면에서 가장 적절한 방법을 찾는 것입니다. DynamoDB TTL 기능은 지정한 만료 시간이 지나면 항목을 자동으로 삭제해 추가 개발이나 운영 인프라를 거의 요구하지 않아 비용과 노력을 모두 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "DynamoDB",
      "30일 데이터 유지",
      "비용 최소화",
      "개발 노력 최소화",
      "TTL"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon DynamoDB",
      "AWS CloudFormation",
      "DynamoDB Streams",
      "AWS Lambda",
      "Time to Live (TTL)",
      "AWS Marketplace"
    ],
    "SelectA": "AWS CloudFormation 템플릿을 사용해 전체 솔루션을 배포하고, 30일마다 CloudFormation 스택을 재배포 후 원본 스택을 삭제합니다.",
    "SelectA_Commentary": "주기적으로 스택을 재배포하는 것은 관리가 복잡하고 비용이나 개발 노력이 더 들기 때문에 비효율적입니다.",
    "SelectB": "AWS Marketplace에서 제공되는 모니터링 애플리케이션이 설치된 EC2 인스턴스를 사용합니다. 이 모니터링 애플리케이션으로 DynamoDB Streams를 통해 항목 생성 시점을 기록하고, 30일 이상 지난 항목을 삭제하는 스크립트를 실행합니다.",
    "SelectB_Commentary": "EC2 인스턴스 유지와 자체 스크립트 실행이 필요해 운영과 관리가 복잡해지고 비용도 추가됩니다.",
    "SelectC": "DynamoDB Streams를 구성하여 테이블에 새 항목이 생성될 때 AWS Lambda 함수를 호출합니다. Lambda 함수를 통해 30일 이상 된 항목을 삭제하도록 설정합니다.",
    "SelectC_Commentary": "Lambda 함수 구성으로 어느 정도 자동화할 수 있지만, 불필요한 호출과 로직 작성이 필요해 관리 부담이 남아 있습니다.",
    "SelectD": "새로운 항목이 생성될 때 현재 시각에 30일을 더한 타임스탬프를 속성으로 추가합니다. DynamoDB에서 이 속성을 TTL로 사용하도록 구성합니다.",
    "SelectD_Commentary": "TTL 기능을 활용하면 30일이 지난 항목을 DynamoDB가 자동으로 삭제해, 비용과 운영 노력이 가장 적으며 요구사항을 충족하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q348",
      "Q79",
      "Q520",
      "Q670",
      "Q799"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q485",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q196",
      "Q552",
      "Q520"
    ],
    "SelectC_recommedations": [
      "Q196",
      "Q670",
      "Q348"
    ],
    "SelectD_recommedations": [
      "Q670",
      "Q196",
      "Q348"
    ]
  },
  {
    "Question_Number": "Q197",
    "Question_Description": "한 회사는 온프레미스 Windows Server에서 실행되는 Microsoft .NET 애플리케이션을 보유하고 있으며, 이 애플리케이션은 Oracle Database Standard Edition 서버를 사용하여 데이터를 저장하고 있습니다. 회사는 AWS로 마이그레이션을 계획하고 있으며, 애플리케이션 이전 시 개발 변경을 최소화하고자 합니다. 또한 AWS 애플리케이션 환경은 고가용성을 유지해야 합니다. 이러한 요구사항을 충족하기 위해 취해야 할 조치를 두 가지 고르시오.",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89068-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 .NET 애플리케이션과 Oracle Database Standard Edition을 AWS로 마이그레이션할 때, 최소한의 개발 변경과 고가용성을 어떻게 달성할지를 묻습니다. AWS Elastic Beanstalk에 .NET 플랫폼으로 리호스팅하면 애플리케이션 코드를 거의 수정하지 않고도 고가용성 환경(Multi-AZ)을 쉽게 구성할 수 있습니다. 데이터베이스의 경우, Oracle에서 Oracle on Amazon RDS로 마이그레이션하면 기존 Oracle 기술을 유지하면서 AWS에서 제공하는 Multi-AZ 배포를 통해 높은 가용성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "개발 변경 최소화",
      "고가용성",
      "AWS Elastic Beanstalk",
      "Oracle on Amazon RDS",
      "AWS Database Migration Service",
      "멀티 AZ"
    ],
    "Terms": [
      "AWS Elastic Beanstalk",
      ".NET",
      "Windows Server",
      "AWS Lambda",
      "Amazon EC2",
      "Amazon Linux AMI",
      "AWS Database Migration Service (AWS DMS)",
      "Oracle Database Standard Edition",
      "Amazon DynamoDB",
      "Oracle on Amazon RDS",
      "Multi-AZ 배포"
    ],
    "SelectA": "AWS Lambda에서 .NET Core로 서버리스 방식으로 애플리케이션을 리팩터링합니다.",
    "SelectA_Commentary": "서버리스로 리팩터링하는 것은 코드 변경이 많아지고 구성도 복잡해져, ‘개발 변경 최소화’ 요구사항에 적합하지 않습니다.",
    "SelectB": "AWS Elastic Beanstalk의 .NET 플랫폼으로 애플리케이션을 리호스트하고 멀티 AZ로 배포합니다.",
    "SelectB_Commentary": "애플리케이션 코드 변경을 최소화하면서 고가용성 환경을 쉽게 구성할 수 있어 요구사항을 충족합니다.",
    "SelectC": "Amazon Linux AMI를 사용하는 Amazon EC2에서 애플리케이션을 리플랫폼합니다.",
    "SelectC_Commentary": "Windows 기반 .NET 애플리케이션을 Linux 환경으로 이전하면 코드 변경이 많을 수 있어, 요구사항에 적합하지 않습니다.",
    "SelectD": "AWS DMS를 사용하여 Oracle DB를 Amazon DynamoDB로 멀티 AZ로 마이그레이션합니다.",
    "SelectD_Commentary": "Oracle에서 DynamoDB로의 마이그레이션은 스키마 및 코드 변경이 많아져, ‘개발 변경 최소화’ 요구사항에 부합하지 않습니다.",
    "SelectE": "AWS DMS를 사용하여 Oracle DB를 멀티 AZ로 구성된 Amazon RDS의 Oracle로 마이그레이션합니다.",
    "SelectE_Commentary": "Oracle 기술을 그대로 유지하면서 AWS RDS의 멀티 AZ 기능으로 고가용성을 확보할 수 있어, 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q914",
      "Q97",
      "Q190",
      "Q114",
      "Q843"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q351",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q664",
      "Q194",
      "Q197"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q8",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q133",
      "Q843",
      "Q845"
    ],
    "SelectE_recommedations": [
      "Q133",
      "Q843",
      "Q978"
    ]
  },
  {
    "Question_Number": "Q198",
    "Question_Description": "한 회사는 온프레미스 데이터 센터의 Kubernetes 클러스터에서 컨테이너형 애플리케이션을 운영하고 있으며, MongoDB 데이터베이스를 사용하고 있습니다. 현재 코드 수정이나 배포 방법 변경 없이 AWS로 일부 환경을 마이그레이션하려고 합니다. 이 때 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89078-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Kubernetes 환경에서 MongoDB를 사용하는 애플리케이션을 AWS로 이전하되, 코드나 배포 방식을 바꾸지 않고 운영 오버헤드를 최소화해야 하는 시나리오입니다. MongoDB 호환성을 유지하려면 Amazon DocumentDB를 사용하는 것이 적절하며, Kubernetes 오케스트레이션을 그대로 활용하기 위해 Amazon EKS를 사용하는 것이 가장 간편합니다. 또한, AWS Fargate를 사용하면 워커 노드를 직접 관리할 필요가 없어 운영 부담이 줄어듭니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Kubernetes 기반 컨테이너 마이그레이션",
      "MongoDB",
      "운영 오버헤드 최소화",
      "AWS Fargate",
      "Amazon EKS",
      "Amazon DocumentDB"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon EC2",
      "AWS Fargate",
      "Amazon DynamoDB",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Amazon DocumentDB (with MongoDB compatibility)",
      "Kubernetes",
      "MongoDB"
    ],
    "SelectA": "Amazon ECS를 Amazon EC2 워커 노드와 함께 사용하고, MongoDB를 EC2에 직접 설치하여 운영합니다.",
    "SelectA_Commentary": "EC2에서 MongoDB를 직접 구성해야 하므로 서버와 DB 모두를 관리해야 합니다. 운영 오버헤드가 커지며, Kubernetes 환경을 그대로 활용하지 못합니다.",
    "SelectB": "Amazon ECS를 AWS Fargate로 사용하고, 데이터 스토리지로 Amazon DynamoDB를 사용합니다.",
    "SelectB_Commentary": "MongoDB 코드 기반을 DynamoDB로 바꾸어야 하므로 코드 변경이 필요합니다. 또한 Kubernetes 사용 방식과도 달라 운영 방식을 크게 변경해야 합니다.",
    "SelectC": "Amazon EKS를 Amazon EC2 워커 노드로 사용하고, 데이터 스토리지로 Amazon DynamoDB를 사용합니다.",
    "SelectC_Commentary": "Kubernetes 사용은 그대로 가능하지만, MongoDB 코드 기반을 DynamoDB로 전환해야 하므로 코드 변경이 요구되며, EC2 노드 관리도 필요해 운영 부담이 큽니다.",
    "SelectD": "Amazon EKS를 AWS Fargate로 사용하고, 데이터 스토리지로 Amazon DocumentDB(MongoDB 호환)를 사용합니다.",
    "SelectD_Commentary": "Kubernetes 배포 방식을 유지하면서 MongoDB 호환성을 제공하는 DocumentDB를 사용해 코드 변경이 불필요합니다. Fargate로 노드 관리 부담이 사라져 운영 오버헤드를 최소화할 수 있어 정답입니다.",
    "Question_Description_recommedations": [
      "Q363",
      "Q114",
      "Q914",
      "Q1014",
      "Q293"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q198",
      "Q944"
    ],
    "SelectB_recommedations": [
      "Q768",
      "Q194",
      "Q698"
    ],
    "SelectC_recommedations": [
      "Q768",
      "Q194",
      "Q563"
    ],
    "SelectD_recommedations": [
      "Q698",
      "Q575",
      "Q563"
    ]
  },
  {
    "Question_Number": "Q199",
    "Question_Description": "한 텔레마케팅 회사가 AWS 상에서 고객 콜 센터 기능을 설계하고 있습니다. 회사는 다중 화자 인식을 제공하고, 대화 녹취록(transcript) 파일을 생성할 수 있는 솔루션이 필요합니다. 회사는 녹취록 파일을 쿼리하여 비즈니스 패턴을 분석하고자 합니다. 또한 이 녹취록 파일들은 감사(auditing) 목적으로 7년 동안 보관되어야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89141-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 음성을 자동으로 텍스트로 변환하고(Transcribe), 다중 화자를 구분하여 녹취록을 생성해야 합니다. 생성된 녹취록은 7년 동안 Amazon S3에 저장하며, Amazon Athena로 손쉽게 분석할 수 있습니다. Rekognition, Translate, Textract 등은 음성 인식 대신 시각 자료 분석 혹은 텍스트 번역/추출을 처리하므로 요구 사항에 부합하지 않습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "콜 센터",
      "다중 화자 인식",
      "녹취록 파일",
      "Amazon Transcribe",
      "Amazon Athena",
      "장기간 보관",
      "비즈니스 패턴 분석"
    ],
    "Terms": [
      "Amazon Rekognition",
      "Amazon S3",
      "Amazon Transcribe",
      "Amazon Athena",
      "Amazon Translate",
      "Amazon Redshift",
      "Amazon Textract",
      "SQL"
    ],
    "SelectA": "Amazon Rekognition을 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon S3에 저장합니다. 녹취록 파일 분석에는 machine learning models를 사용합니다.",
    "SelectA_Commentary": "Amazon Rekognition은 이미지·영상 분석 서비스로 음성 녹취 생성 기능이 없어 요구 사항을 만족시키지 못합니다.",
    "SelectB": "Amazon Transcribe를 사용하여 다중 화자 인식을 수행합니다. Amazon Athena를 사용하여 녹취록 파일을 분석합니다.",
    "SelectB_Commentary": "음성 인식 및 다중 화자 구분은 Transcribe가 제공하며, S3에 저장된 데이터는 Athena로 SQL 쿼리 분석이 가능해 요구 사항에 완벽히 부합합니다.",
    "SelectC": "Amazon Translate를 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon Redshift에 저장합니다. SQL 쿼리를 통해 녹취록 파일을 분석합니다.",
    "SelectC_Commentary": "Amazon Translate는 텍스트 번역 서비스여서 음성 인식에 적합하지 않고, Redshift까지 사용할 필요도 없어 비효율적입니다.",
    "SelectD": "Amazon Rekognition을 사용하여 다중 화자 인식을 수행합니다. 녹취록 파일을 Amazon S3에 저장합니다. Amazon Textract를 사용하여 녹취록 파일을 분석합니다.",
    "SelectD_Commentary": "Rekognition과 Textract는 시각 자료 분석용 서비스로, 음성 녹취 생성 및 분석 요구 사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q865",
      "Q361",
      "Q443",
      "Q631",
      "Q568"
    ],
    "SelectA_recommedations": [
      "Q687",
      "Q501",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q568",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q192",
      "Q557"
    ],
    "SelectD_recommedations": [
      "Q687",
      "Q501",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q200",
    "Question_Description": "한 회사가 AWS 환경에서 애플리케이션을 호스팅하고 있습니다. 사용자는 Amazon Cognito를 통해 관리되며, 로그인을 하면 Amazon API Gateway에 호스팅된 REST API를 호출하여 Amazon DynamoDB에서 필요한 데이터를 가져옵니다. 이 때, 개발 노력을 줄이기 위해 AWS에서 제공하는 관리형 솔루션을 활용하여 REST API 접근 제어를 구현하고자 합니다. 가장 낮은 운영 오버헤드를 가지는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89142-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 인증 절차를 간소화하면서 REST API에 대한 접근을 안전하게 제어하려는 시나리오입니다. 가장 관리가 용이한 방식은 Amazon Cognito User Pool Authorizer를 API Gateway와 직접 연동하는 것으로, 별도의 인증 로직이나 추가 인프라가 필요하지 않아 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon Cognito",
      "사용자 인증",
      "REST API 접근 제어",
      "Amazon API Gateway",
      "Least operational overhead"
    ],
    "Terms": [
      "Amazon Cognito",
      "User Pool Authorizer",
      "Amazon DynamoDB",
      "AWS Lambda Authorizer",
      "Amazon API Gateway",
      "API Key",
      "REST API"
    ],
    "SelectA": "API Gateway에서 AWS Lambda 함수를 Authorizer로 설정하여 요청을 보낸 사용자를 검증합니다.",
    "SelectA_Commentary": "Lambda Authorizer를 직접 구현하면 검증 로직과 함수를 별도로 관리해야 하므로 운영 및 개발 오버헤드가 증가합니다.",
    "SelectB": "각 사용자에게 API Key를 발급하여 매 요청 시 전달하도록 하고, AWS Lambda 함수를 통해 키를 검증합니다.",
    "SelectB_Commentary": "API Key를 사용자별로 관리하고 검증 로직도 구현해야 하므로 오버헤드와 복잡성이 높아집니다.",
    "SelectC": "매 요청 시 사용자의 이메일 주소를 헤더에 담아 전송하고, 이 이메일 계정이 올바른지 AWS Lambda 함수로 검증합니다.",
    "SelectC_Commentary": "이메일 정보를 헤더로 직접 전달하는 것은 보안 측면에서 취약할 수 있으며, Lambda 함수로 검증 로직을 계속 관리해야 하므로 비효율적입니다.",
    "SelectD": "API Gateway에서 Amazon Cognito User Pool Authorizer를 설정하여 Amazon Cognito가 각 요청을 검증하도록 구성합니다.",
    "SelectD_Commentary": "Cognito User Pool Authorizer를 사용하면 추가적인 인증 로직이나 인프라가 필요 없고, AWS가 인증 과정을 관리하므로 운영 오버헤드를 크게 줄일 수 있습니다.",
    "Question_Description_recommedations": [
      "Q366",
      "Q34",
      "Q1019",
      "Q211",
      "Q970"
    ],
    "SelectA_recommedations": [
      "Q159",
      "Q871",
      "Q1019"
    ],
    "SelectB_recommedations": [
      "Q34",
      "Q791",
      "Q936"
    ],
    "SelectC_recommedations": [
      "Q936",
      "Q791",
      "Q831"
    ],
    "SelectD_recommedations": [
      "Q200",
      "Q366",
      "Q1019"
    ]
  },
  {
    "Question_Number": "Q201",
    "Question_Description": "회사는 모바일 앱 사용자를 대상으로 하는 마케팅 커뮤니케이션 서비스를 개발 중입니다. 이 회사는 사용자들에게 SMS(Short Message Service)로 확인 메시지를 보낼 필요가 있습니다. 또한 사용자가 이 SMS 메시지에 회신할 수 있어야 하며, 회신된 메시지를 1년간 저장하여 분석해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89080-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "SMS 발송과 회신 저장 및 분석의 요구사항을 동시에 충족하려면 Amazon Pinpoint로 캠페인을 구성하고, Kinesis로 이벤트를 전달하여 1년간 데이터 보관 및 분석을 수행할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "SMS",
      "Amazon Pinpoint",
      "Kinesis Data Stream",
      "마케팅 커뮤니케이션",
      "분석 및 보관"
    ],
    "Terms": [
      "Amazon Connect",
      "AWS Lambda",
      "Amazon Pinpoint",
      "Amazon Kinesis data stream",
      "Amazon SQS",
      "Amazon SNS FIFO"
    ],
    "SelectA": "Amazon Connect를 사용해 컨택트 플로우를 만들고 SMS를 전송합니다. 그리고 AWS Lambda를 이용해 회신을 처리합니다.",
    "SelectA_Commentary": "Amazon Connect는 주로 콜센터 시나리오에 최적화되어 있으며, 대량 마케팅 메시지와 장기 분석 목적에는 적합하지 않습니다.",
    "SelectB": "Amazon Pinpoint Journey를 구축합니다. Amazon Pinpoint가 이벤트를 Amazon Kinesis data stream으로 전송하도록 구성하여 분석 및 보관합니다.",
    "SelectB_Commentary": "마케팅 메시지 전송과 회신 분석에 특화된 Amazon Pinpoint를 활용하며, Kinesis를 통해 데이터를 실시간으로 전송해 장기간 보관 및 분석이 가능합니다.",
    "SelectC": "Amazon Simple Queue Service(Amazon SQS)를 사용해 SMS를 분산하고, AWS Lambda를 이용해 회신을 처리합니다.",
    "SelectC_Commentary": "SQS는 메시지 대기열 서비스로 회신 관리에 적합하지 않으며, 마케팅 메시지 설정 및 장기 저장 기능이 부족합니다.",
    "SelectD": "Amazon Simple Notification Service(Amazon SNS) FIFO 토픽을 생성합니다. Amazon Kinesis data stream을 SNS 토픽에 구독시켜 분석 및 보관합니다.",
    "SelectD_Commentary": "SNS를 이용하면 일대다 메시지 전달은 가능하지만, 회신 기능과 마케팅 흐름 관리가 제한적입니다.",
    "Question_Description_recommedations": [
      "Q506",
      "Q77",
      "Q915",
      "Q622",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q173",
      "Q687"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q402",
      "Q557"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q38",
      "Q249"
    ],
    "SelectD_recommedations": [
      "Q402",
      "Q515",
      "Q2"
    ]
  },
  {
    "Question_Number": "Q202",
    "Question_Description": "한 회사가 데이터를 Amazon S3 버킷으로 이전하려고 합니다. 이 데이터는 S3 버킷에 저장될 때 암호화되어야 하며, 암호화 키는 매년 자동으로 교체되어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89081-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 데이터를 저장할 때 자동으로 키를 교체하며, 운영 오버헤드를 최소화하는 암호화 방법을 고르는 문제입니다. SSE-S3는 AWS가 제공하는 S3 관리형 키를 사용하므로 사용자가 키를 직접 관리하거나 교체할 필요가 없고, 매년 자동으로 키를 교체해 운영 부담을 크게 줄여줍니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "데이터 암호화",
      "자동 키 교체",
      "운영 오버헤드 최소화",
      "서버 사이드 암호화",
      "SSE-S3"
    ],
    "Terms": [
      "Amazon S3",
      "SSE-S3",
      "AWS Key Management Service (AWS KMS)",
      "Customer managed key",
      "S3 bucket’s default encryption",
      "Customer key material",
      "Server-side encryption",
      "Key rotation"
    ],
    "SelectA": "데이터를 S3 버킷으로 옮기고, 서버 사이드 암호화(Amazon S3 managed encryption keys: SSE-S3)를 사용합니다. SSE-S3의 자동 키 교체 기능을 이용합니다.",
    "SelectA_Commentary": "정답입니다. SSE-S3는 아무런 추가 설정 없이도 키를 자동 관리 및 교체하므로 운영 오버헤드가 가장 낮습니다.",
    "SelectB": "AWS KMS customer managed key를 생성하고 자동 키 교체를 활성화합니다. 해당 KMS 키를 S3 버킷의 기본 암호화 키로 설정한 뒤 데이터를 이동합니다.",
    "SelectB_Commentary": "키 관리는 자동 키 교체를 제공하지만, KMS 정책 설정 등 추가 관리가 필요해 상대적으로 운영이 복잡해질 수 있습니다.",
    "SelectC": "AWS KMS customer managed key를 생성하고 S3 버킷의 기본 암호화 키로 설정합니다. 그 후 데이터를 옮긴 뒤 매년 수동으로 KMS 키를 교체합니다.",
    "SelectC_Commentary": "키를 매년 직접 교체해야 하므로 운영 비용이 증가하고 자동화 수준이 낮습니다.",
    "SelectD": "버킷에 옮기기 전 데이터를 고객 키 소재로 암호화합니다. 그 후 키 소재가 없는 KMS 키를 생성하고, 고객 키 소재를 가져와 자동 키 교체를 활성화합니다.",
    "SelectD_Commentary": "고객 키 소재를 자체적으로 준비·관리해야 하므로 운영 절차가 복잡해지고, 요구 사항 대비 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q925",
      "Q412",
      "Q825",
      "Q856",
      "Q270"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q965",
      "Q862"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q916",
      "Q371"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q36",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q478",
      "Q665",
      "Q57"
    ]
  },
  {
    "Question_Number": "Q203",
    "Question_Description": "한 금융 회사의 고객들은 재정 상담사와의 약속을 잡기 위해 문자 메시지를 보냅니다. Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션이 약속 요청을 받아들입니다. 문자 메시지는 웹 애플리케이션을 통해 Amazon Simple Queue Service(Amazon SQS) 큐에 게시됩니다. 그런 다음 Amazon EC2 인스턴스에서 실행되는 또 다른 애플리케이션이 고객에게 회의 초대 및 확인 이메일을 발송합니다. 일정이 성공적으로 잡히면 이 애플리케이션은 회의 정보를 Amazon DynamoDB 데이터베이스에 저장합니다. 회사가 확장됨에 따라 고객들은 회의 초대장이 도착하기까지 시간이 오래 걸린다고 보고했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89082-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 메시지가 증가하면서 초대장을 전달하는 애플리케이션 리소스가 부족해 지연이 발생하는 상황입니다. 수요에 따라 애플리케이션을 자동으로 확장해 처리 성능을 높이는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "고객 약속 요청",
      "Amazon SQS 큐",
      "회의 초대 지연",
      "Auto Scaling",
      "큐 깊이에 따른 확장"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon SQS",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon API Gateway",
      "Amazon CloudFront",
      "Auto Scaling group"
    ],
    "SelectA": "DynamoDB 데이터베이스 앞에 DynamoDB Accelerator(DAX) 클러스터를 추가합니다.",
    "SelectA_Commentary": "데이터베이스 조회 성능 향상에 초점을 맞춘 해결책이므로, 초대장 전송 처리 지연 문제 해결에는 직접적인 도움이 되지 않습니다.",
    "SelectB": "약속 요청을 받는 웹 애플리케이션 앞에 Amazon API Gateway API를 추가합니다.",
    "SelectB_Commentary": "API Gateway는 요청 처리를 표준화하고 보안을 강화하지만, 초대장 전송 애플리케이션 자체의 처리 속도 문제를 해결하지 못합니다.",
    "SelectC": "Amazon CloudFront 배포를 추가하고, 약속 요청을 받는 웹 애플리케이션을 오리진으로 설정합니다.",
    "SelectC_Commentary": "CloudFront는 콘텐츠 캐싱을 제공하나, 데이터 처리를 가속하는 데 직접 관여하지 않아 초대장 지연 문제를 해결하기 어렵습니다.",
    "SelectD": "회의 초대를 전송하는 애플리케이션에 대한 Auto Scaling group을 추가하고, SQS 큐 깊이에 따라 확장되도록 구성합니다.",
    "SelectD_Commentary": "큐에 메시지가 많아질 때 자동으로 인스턴스 수를 늘려 처리 능력을 높이므로, 초대장 지연 문제를 가장 효과적으로 해결합니다.",
    "Question_Description_recommedations": [
      "Q67",
      "Q768",
      "Q111",
      "Q114",
      "Q195"
    ],
    "SelectA_recommedations": [
      "Q78",
      "Q1002",
      "Q845"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q8",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q204",
    "Question_Description": "한 온라인 소매 회사에는 5천만 명 이상의 활성 고객이 있으며, 매일 25,000건 이상의 주문이 접수됩니다. 회사는 고객의 구매 데이터를 Amazon S3에 저장하고, 추가 고객 정보는 Amazon RDS에 저장하고 있습니다. 회사는 이 모든 데이터를 다양한 팀에서 분석할 수 있도록 제공하려고 합니다. 이때 데이터에 대한 세분화된 권한 관리를 구현해야 하며, 운영 오버헤드를 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 고객 데이터(구매 정보와 추가 정보)를 여러 팀이 분석할 수 있도록 제공하면서 데이터에 대한 정교한 권한 제어를 구현하는 방법을 묻습니다. 정답인 AWS Lake Formation은 S3 기반 데이터 레이크를 손쉽게 구축하고, Lake Formation Access Control을 통해 각 팀별로 세분화된 권한 관리를 수행할 수 있습니다. 또한, Glue를 통한 카탈로그 관리와 JDBC 연결로 RDS 데이터까지 통합하여 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "5천만 명의 활성 고객",
      "25,000건 주문",
      "Amazon S3",
      "Amazon RDS",
      "데이터 분석",
      "세분화된 접근 권한",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon RDS",
      "AWS Lake Formation",
      "AWS Glue",
      "Amazon Athena",
      "Amazon Redshift",
      "AWS Lambda",
      "Data Lake"
    ],
    "SelectA": "구매 데이터를 Amazon RDS에 직접 쓰도록 마이그레이션하고, RDS 접근 제어를 사용하여 액세스를 제한합니다.",
    "SelectA_Commentary": "모든 데이터를 RDS로 옮기는 것은 비효율적이고 RDS 스케일 부담이 큽니다. 또한 객체 스토리지에서의 세분화된 권한 관리를 구현하기 어렵습니다.",
    "SelectB": "AWS Lambda 함수를 주기적으로 실행하여 Amazon RDS 데이터를 Amazon S3로 복사합니다. AWS Glue 크롤러를 생성하고, Amazon Athena로 데이터를 쿼리합니다. S3 정책으로 접근을 제한합니다.",
    "SelectB_Commentary": "Lambda와 Athena, S3 정책만으로 세분화된 권한 제어가 가능하긴 하지만, Lake Formation의 통합적 정책 관리 기능만큼 편의성과 세분화 수준이 높지 않습니다.",
    "SelectC": "AWS Lake Formation을 사용하여 Data Lake를 생성합니다. Amazon RDS로의 AWS Glue JDBC 연결을 설정하고, S3 버킷을 Lake Formation에 등록합니다. Lake Formation의 접근 제어를 사용하여 권한을 제한합니다.",
    "SelectC_Commentary": "Lake Formation이 세분화된 접근 권한을 쉽게 관리하고, S3와 RDS 데이터를 통합 분석할 수 있어 운영 오버헤드를 줄이면서 요구사항을 충족하는 최적 솔루션입니다.",
    "SelectD": "Amazon Redshift 클러스터를 생성합니다. AWS Lambda 함수를 주기적으로 실행하여 Amazon S3 및 Amazon RDS 데이터를 Amazon Redshift로 복사합니다. Amazon Redshift 접근 제어를 사용하여 액세스를 제한합니다.",
    "SelectD_Commentary": "Redshift로 모두 통합하면 대량의 임포트 작업과 관리 오버헤드가 증가합니다. 또한 세분화된 권한 요구사항을 만족하기 위해서는 추가 설정이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q154",
      "Q106",
      "Q678",
      "Q893",
      "Q1007"
    ],
    "SelectA_recommedations": [
      "Q330",
      "Q742",
      "Q847"
    ],
    "SelectB_recommedations": [
      "Q289",
      "Q211",
      "Q451"
    ],
    "SelectC_recommedations": [
      "Q609",
      "Q16",
      "Q495"
    ],
    "SelectD_recommedations": [
      "Q821",
      "Q289",
      "Q428"
    ]
  },
  {
    "Question_Number": "Q205",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에서 마케팅 웹사이트를 호스팅하고 있습니다. 이 웹사이트는 정적 문서로 구성되며 단일 서버에서 동작합니다. 관리자는 웹사이트 콘텐츠를 자주 업데이트하지 않고, 새로운 문서를 업로드할 때는 SFTP 클라이언트를 사용합니다. 회사는 이 웹사이트를 AWS로 이전하고 Amazon CloudFront를 사용하기로 결정했습니다. 솔루션스 아키텍트는 CloudFront의 오리진으로 사용할 웹사이트 호스팅에 대해 가장 비용 효율적이고 복원력 있는 아키텍처를 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89085-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 정적 웹사이트의 오리진을 CloudFront로 구성하면서 비용 최적화와 복원성을 모두 달성해야 하는 시나리오입니다. 전통적인 서버 기반 솔루션보다 Amazon S3와 Origin Access Identity(OAI)를 사용하는 방식이 가장 저렴하고 안정성이 높습니다. 특히 사이트 콘텐츠가 자주 변경되지 않는 정적 파일이므로 서버를 직접 운영하지 않아도 되고, S3의 내구성과 가용성을 활용하여 아키텍처를 단순화하면서 비용을 절감할 수 있습니다. 또한 CloudFront를 통해 전 세계 엣지 로케이션에서 빠른 콘텐츠 전송이 가능합니다. SFTP 사용 요구사항을 완전히 유지해야 한다면 AWS Transfer for SFTP를 고려할 수 있으나, 보안성과 관리 측면에서는 S3와 OAI 구성에 CLI 업로드 방식을 사용하는 것이 일반적인 권장사항입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "온프레미스 데이터 센터",
      "마케팅 웹사이트",
      "정적 문서",
      "SFTP 클라이언트",
      "Amazon CloudFront",
      "비용 효율성",
      "복원력 있는 아키텍처",
      "오리진"
    ],
    "Terms": [
      "SFTP",
      "Amazon CloudFront",
      "Amazon S3",
      "Origin Access Identity (OAI)",
      "AWS CLI",
      "Amazon EC2",
      "AWS Auto Scaling",
      "Application Load Balancer",
      "Amazon Lightsail",
      "AWS Transfer for SFTP",
      "Website Hosting"
    ],
    "SelectA": "Amazon Lightsail 인스턴스를 생성하고 웹 서버를 구성합니다. SFTP 클라이언트를 사용하여 웹사이트 콘텐츠를 업로드합니다.",
    "SelectA_Commentary": "Lightsail은 서버 운영 및 관리가 필요한 방식으로, 정적 컨텐츠를 호스팅하기에는 과도한 비용과 유지보수 부담이 생길 수 있습니다.",
    "SelectB": "Amazon EC2 인스턴스용 AWS Auto Scaling 그룹을 생성하고, Application Load Balancer를 사용합니다. SFTP 클라이언트를 이용해 웹사이트 콘텐츠를 업로드합니다.",
    "SelectB_Commentary": "EC2 Auto Scaling과 Load Balancer 구성은 가용성과 확장성은 제공하지만, 정적 파일 호스팅에는 불필요하게 복잡하고 비용이 높아집니다.",
    "SelectC": "비공개 Amazon S3 버킷을 생성하고, CloudFront Origin Access Identity(OAI)를 사용하도록 버킷 정책을 구성합니다. AWS CLI를 통해 웹사이트 콘텐츠를 업로드합니다.",
    "SelectC_Commentary": "비용을 최소화하고 높은 내구성을 제공하며, 서버 없이 정적 웹사이트를 호스팅하기에 가장 적합한 솔루션입니다. OAI를 통해 S3 버킷을 안전하게 보호하면서 CloudFront가 콘텐츠를 제공하도록 할 수 있습니다.",
    "SelectD": "공개 Amazon S3 버킷을 생성하고 AWS Transfer for SFTP를 구성합니다. S3 버킷을 웹사이트 호스팅으로 설정하고, SFTP 클라이언트를 사용하여 웹사이트 콘텐츠를 업로드합니다.",
    "SelectD_Commentary": "SFTP를 그대로 쓰는 방법이지만, S3 버킷 자체가 공개로 설정되어 있어야 하고 CloudFront Origin Access Identity 구성도 누락되어 보안 및 비용 측면에서 최적의 접근은 아닙니다.",
    "Question_Description_recommedations": [
      "Q1003",
      "Q284",
      "Q769",
      "Q993",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q205",
      "Q728",
      "Q1003"
    ],
    "SelectB_recommedations": [
      "Q505",
      "Q822",
      "Q552"
    ],
    "SelectC_recommedations": [
      "Q72",
      "Q415",
      "Q960"
    ],
    "SelectD_recommedations": [
      "Q829",
      "Q498",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q206",
    "Question_Description": "한 회사가 Amazon Machine Images(AMIs)를 관리하려고 합니다. 현재는 AMI가 생성된 동일한 AWS Region으로만 복사하고 있습니다. 이 회사는 AWS API 호출을 포착하고 회사 계정 내에서 Amazon EC2 CreateImage API 오퍼레이션이 호출될 때마다 알림을 보내는 애플리케이션을 설계해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89086-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AMI 생성에 관련된 API 호출을 실시간으로 감시하고 알림을 보내는 방법을 묻습니다. CreateImage API 이벤트를 자동으로 포착하여 SNS 등으로 알림을 보내기 위해서는, 로그 파일을 직접 스캔하거나 여러 단계를 거치는 방식보다 EventBridge 규칙을 활용하는 방식이 가장 간단하고 운영 오버헤드가 적습니다. EventBridge에서 정확히 CreateImage API 호출 이벤트를 인식하고 바로 알림을 전송할 수 있기 때문입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Amazon Machine Image(AMI)",
      "CreateImage API 호출",
      "AWS API 호출 모니터링",
      "운영 오버헤드 최소화",
      "EventBridge 규칙"
    ],
    "Terms": [
      "AWS Lambda",
      "AWS CloudTrail",
      "Amazon Simple Notification Service (SNS)",
      "Amazon Athena",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon EC2 CreateImage API",
      "AMI"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 AWS CloudTrail 로그를 주기적으로 쿼리하고 CreateImage API 호출이 감지되면 알림을 전송합니다.",
    "SelectA_Commentary": "로그 쿼리를 위한 Lambda 구성과 주기적 실행 설정이 필요해 운영 오버헤드가 큽니다.",
    "SelectB": "AWS CloudTrail을 설정해 업데이트된 로그가 Amazon S3에 전송될 때 Amazon SNS 알림을 활성화합니다. 그리고 Amazon Athena로 CreateImage API 호출을 쿼리합니다.",
    "SelectB_Commentary": "S3 업로드 후 Athena 쿼리까지 단계를 거쳐야 해 구성과 관리가 복잡합니다.",
    "SelectC": "Amazon EventBridge(Amazon CloudWatch Events)에서 CreateImage API 호출을 트리거로 하는 규칙을 생성합니다. 대상(Target)으로 Amazon SNS 토픽을 구성해 API 호출이 감지될 때 알림을 전송합니다.",
    "SelectC_Commentary": "EventBridge 규칙로 특정 API 이벤트를 직접 감지하고 SNS에 알림을 보내므로 구성과 관리가 단순하며 운영 오버헤드가 최소화됩니다.",
    "SelectD": "Amazon SQS FIFO 대기열을 AWS CloudTrail 로그의 타겟으로 설정합니다. CreateImage API 호출이 감지되면 Lambda 함수를 통해 Amazon SNS 토픽으로 알림을 전송합니다.",
    "SelectD_Commentary": "SQS 대기열 생성 및 Lambda 트리거 설정 등 단계가 많아지므로 운영 복잡도가 커집니다.",
    "Question_Description_recommedations": [
      "Q889",
      "Q777",
      "Q667",
      "Q492",
      "Q91"
    ],
    "SelectA_recommedations": [
      "Q289",
      "Q936",
      "Q942"
    ],
    "SelectB_recommedations": [
      "Q942",
      "Q862",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q206",
      "Q364",
      "Q211"
    ],
    "SelectD_recommedations": [
      "Q289",
      "Q364",
      "Q942"
    ]
  },
  {
    "Question_Number": "Q207",
    "Question_Description": "어떤 회사는 사용자 요청을 수집하기 위한 비동기식 API를 운영하고 있으며, 요청 유형에 맞춰 적절한 마이크로서비스로 요청을 전달합니다. 이 회사는 Amazon API Gateway를 사용해 API 프런트 엔드를 배포하고, AWS Lambda 함수를 이용해 Amazon DynamoDB에 사용자 요청을 저장한 뒤 처리 마이크로서비스로 전달하고 있습니다. 회사는 예산 범위 내에서 DynamoDB 프로비저닝 용량을 최대치로 설정했지만, 여전히 가용성 문제가 발생하여 사용자 요청이 유실되고 있습니다. 기존 사용자들에게 영향을 주지 않으면서 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89087-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB 쓰기 부담으로 인해 요청이 유실되는 상황에서, 기존 API 동작을 방해하지 않고도 확장성과 내결함성을 높이기 위한 설계를 찾는 것이 핵심입니다. 비동기 구조에 적합한 Amazon SQS를 사용해 쓰기 요청을 버퍼링함으로써 DynamoDB의 부하를 완화하고 사용자 요청 유실을 방지할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "비동기식 API",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "가용성 문제",
      "기존 사용자 영향 최소화",
      "Amazon SQS"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Secondary index",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Throttling",
      "Asynchronous API"
    ],
    "SelectA": "API Gateway에 서버 측 제한(throttling)을 추가합니다.",
    "SelectA_Commentary": "throttling을 추가하면 요청이 제한되어 기존 사용자 요청에 영향을 줄 수 있으므로 적합하지 않습니다.",
    "SelectB": "DynamoDB Accelerator (DAX)와 Lambda를 사용해 DynamoDB로의 쓰기를 버퍼링합니다.",
    "SelectB_Commentary": "DAX는 읽기 성능 캐싱 솔루션이므로 쓰기 부담 문제를 해결하기 어렵습니다.",
    "SelectC": "DynamoDB 테이블에 secondary index를 생성합니다.",
    "SelectC_Commentary": "secondary index는 조회 성능 개선에 도움을 줄 수 있지만 쓰기 처리량 이슈에는 직접적인 해결책이 되지 않습니다.",
    "SelectD": "Amazon SQS 큐와 Lambda를 사용해 DynamoDB로의 쓰기를 버퍼링합니다.",
    "SelectD_Commentary": "비동기식 구조 특성을 활용해 요청을 먼저 SQS에 저장한 뒤 DynamoDB로 안정적으로 쓰기를 처리해 유실을 방지합니다.",
    "Question_Description_recommedations": [
      "Q25",
      "Q10",
      "Q1002",
      "Q354",
      "Q400"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q8",
      "Q798"
    ],
    "SelectB_recommedations": [
      "Q78",
      "Q1002",
      "Q845"
    ],
    "SelectC_recommedations": [
      "Q845",
      "Q78",
      "Q1002"
    ],
    "SelectD_recommedations": [
      "Q845",
      "Q768",
      "Q1002"
    ]
  },
  {
    "Question_Number": "Q208",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 이동해야 합니다. 회사는 어떤 API 호출이나 데이터도 퍼블릭 인터넷 경로를 통해 라우팅되지 않도록 보장해야 합니다. 오직 Amazon EC2 인스턴스만이 S3 버킷으로 데이터 업로드 권한을 가져야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89088-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스에서 Amazon S3 버킷으로 데이터를 안전하게 전송할 때, 퍼블릭 인터넷을 전혀 거치지 않도록 구성하는 방법을 묻습니다. S3에 대한 완전한 사설 연결을 제공하기 위해서는 적절한 타입의 VPC Endpoint를 사용하고, S3 버킷 정책(Resource Policy)에서 특정 IAM Role만 허용하도록 제한해야 합니다. 이를 통해 API 호출 및 데이터 전송이 모두 AWS 내부 경로를 통해서만 이뤄지며, 퍼블릭 인터넷 경로를 사용하지 않게 됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC Endpoint",
      "Private 라우팅",
      "퍼블릭 인터넷 차단",
      "EC2에서 S3로 데이터 전송",
      "IAM Role",
      "Resource Policy"
    ],
    "Terms": [
      "Interface VPC Endpoint",
      "Gateway VPC Endpoint",
      "Resource Policy",
      "IAM Role",
      "Amazon EC2",
      "Amazon S3",
      "nslookup",
      "VPC Route Table",
      "ip-ranges.json"
    ],
    "SelectA": "Amazon S3에 대한 Interface VPC endpoint를 EC2 인스턴스가 위치한 서브넷에 생성합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.",
    "SelectA_Commentary": "Interface VPC Endpoint를 사용하면 EC2와 S3 간 통신이 AWS 내부에서만 이뤄집니다. Resource Policy로 IAM Role을 제한해 보안을 강화할 수 있으며, 요구사항을 완벽히 충족합니다.",
    "SelectB": "Amazon S3에 대한 Gateway VPC endpoint를 EC2 인스턴스가 위치한 가용 영역(Availability Zone)에 생성합니다. 엔드포인트에 적절한 보안 그룹을 연결합니다. 그런 다음 S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.",
    "SelectB_Commentary": "Gateway VPC Endpoint는 S3 전용 경로를 제공하지만, 보안 그룹을 직접 Gateway Endpoint에 적용할 수 없으며 문제에서 요구한 방식과 부합하지 않습니다.",
    "SelectC": "EC2 인스턴스 내부에서 nslookup 도구를 사용해 S3 버킷 서비스 API 엔드포인트의 프라이빗 IP 주소를 확인합니다. VPC 라우트 테이블에 해당 IP 주소로의 경로를 설정합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.",
    "SelectC_Commentary": "nslookup으로 특정 IP를 찾아 직접 라우트를 구성하는 것은 신뢰성과 관리 측면에서 복잡하며, 엔드포인트로의 안정적 전송 보장을 위해 권장되지 않습니다.",
    "SelectD": "AWS에서 제공하는 ip-ranges.json 파일을 사용해 S3 서비스 API 엔드포인트의 프라이빗 IP 주소를 확인합니다. VPC 라우트 테이블에 해당 IP 주소로 라우팅을 설정합니다. S3 버킷에 Resource Policy를 설정해 오직 EC2 인스턴스의 IAM Role만 허용합니다.",
    "SelectD_Commentary": "ip-ranges.json은 각 서비스별 퍼블릭 IP 대역 정보이므로, 엔드포인트 통신에 직접 활용하기 어렵고 유지 보수가 복잡해 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q453",
      "Q17",
      "Q710",
      "Q612",
      "Q91"
    ],
    "SelectA_recommedations": [
      "Q4",
      "Q91",
      "Q980"
    ],
    "SelectB_recommedations": [
      "Q370",
      "Q4",
      "Q980"
    ],
    "SelectC_recommedations": [
      "Q4",
      "Q91",
      "Q980"
    ],
    "SelectD_recommedations": [
      "Q91",
      "Q4",
      "Q92"
    ]
  },
  {
    "Question_Number": "Q209",
    "Question_Description": "한 솔루션스 아키텍트가 새로운 애플리케이션을 AWS Cloud에 배포하기 위한 아키텍처를 설계하고 있습니다. 이 애플리케이션은 Amazon EC2 On-Demand Instances에서 동작하며, 여러 Availability Zone에 걸쳐 자동으로 확장(Scale-out/Scale-in)될 예정입니다. 하루 동안 EC2 인스턴스는 자주 증설되고 축소될 것입니다. Application Load Balancer(ALB)가 트래픽 분산을 처리합니다. 아키텍처는 분산된 세션 데이터 관리를 지원해야 하며, 필요하다면 코드 수정도 가능합니다.\n\n아키텍처가 분산 세션 데이터 관리를 지원하도록 하기 위해서는 솔루션스 아키텍트가 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/89089-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 멀티 AZ 환경에서 자주 확장되는 EC2 인스턴스를 위한 분산 세션 저장 방안을 묻습니다. 세션 정보를 어디에서나 접근 가능하도록 중앙화해 고가용성과 확장성을 보장해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "분산 세션 데이터",
      "자동 확장",
      "다중 AZ",
      "Application Load Balancer",
      "Amazon ElastiCache"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Availability Zone",
      "Application Load Balancer(ALB)",
      "세션 데이터 관리",
      "Amazon ElastiCache",
      "session affinity(sticky sessions)",
      "Session Manager",
      "AWS Systems Manager",
      "GetSessionToken",
      "AWS Security Token Service(AWS STS)"
    ],
    "SelectA": "Amazon ElastiCache를 사용하여 세션 데이터를 관리하고 저장합니다.",
    "SelectA_Commentary": "Amazon ElastiCache를 활용하면 여러 EC2 인스턴스와 AZ에 걸쳐 세션 정보를 공유할 수 있어 확장성과 고가용성을 모두 달성하는 최적의 방법입니다.",
    "SelectB": "ALB의 session affinity(sticky sessions)를 사용해 세션 데이터를 관리합니다.",
    "SelectB_Commentary": "Sticky sessions는 특정 인스턴스에만 세션을 고정해 다른 인스턴스가 접근하기 어려워집니다. 다중 AZ 확장 시 분산 세션을 보장하기 어렵습니다.",
    "SelectC": "AWS Systems Manager의 Session Manager를 사용해 세션을 관리합니다.",
    "SelectC_Commentary": "Session Manager는 EC2 인스턴스에 접속하기 위한 관리 도구이며, 애플리케이션 세션 데이터 관리 용도와는 무관합니다.",
    "SelectD": "AWS STS의 GetSessionToken API를 사용하여 세션을 관리합니다.",
    "SelectD_Commentary": "STS 토큰은 임시 자격 증명을 위한 것이며, 애플리케이션 세션 저장소 대안이 될 수 없어 분산 세션 관리와 직접 관련이 없습니다.",
    "Question_Description_recommedations": [
      "Q639",
      "Q874",
      "Q5",
      "Q537",
      "Q174"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q8",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q589",
      "Q8",
      "Q293"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q194",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q8",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q210",
    "Question_Description": "한 회사가 빠르게 성장 중인 음식 배달 서비스를 제공합니다. 이로 인해 회사의 주문 처리 시스템이 트래픽 피크 시간대에 확장(스케일링) 문제를 겪고 있습니다. 현재 아키텍처는 아래와 같습니다:\n• Amazon EC2 Auto Scaling 그룹에서 동작하는 Amazon EC2 인스턴스 그룹(애플리케이션에서 주문을 수집)\n• Amazon EC2 Auto Scaling 그룹에서 동작하는 또 다른 Amazon EC2 인스턴스 그룹(주문을 처리)\n주문 수집 프로세스는 빠르게 이루어지지만, 주문 처리 프로세스는 더 오래 걸릴 수 있습니다. 스케일링 이벤트로 인해 데이터가 손실되어서는 안 됩니다. 솔루션스 아키텍트는 피크 트래픽 시간대에 주문 수집 프로세스와 주문 처리 프로세스가 모두 적절히 확장 가능하도록 보장해야 합니다. 또한 회사의 AWS 자원 활용을 최적화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94992-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주문 수집과 주문 처리 과정을 각각 확장 가능하게 구성하는 방법이 핵심입니다. 주문이 쌓이는 것(백로그)을 고려해 확장하도록 설계해야 하며, 데이터 손실을 방지하기 위해 풀(Poll) 방식인 Amazon SQS를 활용하는 것이 유리합니다. 특히 ‘backlog per instance’ 지표를 사용하면 인스턴스당 메시지 처리량을 파악해 탄력적인 자동 확장을 구현할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "피크 트래픽",
      "주문 처리",
      "데이터 손실",
      "AWS 자원 활용 최적화",
      "backlog per instance"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EC2 Auto Scaling",
      "Amazon CloudWatch",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "backlog per instance",
      "scaling event"
    ],
    "SelectA": "Amazon CloudWatch 지표로 각 Auto Scaling 그룹 인스턴스의 CPU를 모니터링하고, 피크 워크로드 기준으로 최소 용량을 설정합니다.",
    "SelectA_Commentary": "CPU 사용량만으로 스케일링하면 주문 처리 지연이나 메시지 누락을 제대로 감지하기 어렵고, 무조건 피크 용량을 유지하는 것은 비효율적입니다.",
    "SelectB": "Amazon CloudWatch 지표로 각 Auto Scaling 그룹 인스턴스의 CPU를 모니터링하고, CloudWatch 알람이 Amazon SNS를 호출해 필요 시 Auto Scaling 그룹을 추가 생성합니다.",
    "SelectB_Commentary": "CPU 기반 알람으로만 확장 그룹을 추가 생성하는 것은 주문 처리 속도에 직접적인 대응이 어렵고, 구성 복잡도와 비용이 증가할 수 있습니다.",
    "SelectC": "Amazon SQS 큐를 두 개 생성해(하나는 주문 수집, 다른 하나는 주문 처리용) 각 EC2 인스턴스가 해당 큐를 폴링하도록 구성합니다. 큐에서 전송하는 알림을 기반으로 Auto Scaling 그룹을 확장합니다.",
    "SelectC_Commentary": "전달되는 알림만으로 스케일링하면 주문이 실제로 얼마나 밀려 있는지 구체적으로 파악하기 어려워, 과소 또는 과다 확장이 발생할 수 있습니다.",
    "SelectD": "Amazon SQS 큐를 주문 수집용과 주문 처리용으로 각각 두 개 생성합니다. 각 EC2 인스턴스는 자신이 담당하는 큐를 폴링합니다. 인스턴스당 백로그(backlog per instance) 계산을 위한 지표를 만든 뒤, 이 지표를 기준으로 Auto Scaling 그룹을 확장합니다.",
    "SelectD_Commentary": "큐의 메시지 수를 인스턴스 수로 나눈 백로그을 모니터링함으로써 정확한 스케일링 조정이 가능합니다. 데이터 손실 없이 유연하게 확장하여 AWS 자원을 효율적으로 활용할 수 있어 정답입니다.",
    "Question_Description_recommedations": [
      "Q1001",
      "Q892",
      "Q790",
      "Q581",
      "Q271"
    ],
    "SelectA_recommedations": [
      "Q923",
      "Q595",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q210",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q67",
      "Q203",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q203",
      "Q67",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q211",
    "Question_Description": "한 회사는 여러 프로덕션 애플리케이션을 운영하고 있습니다. 이 중 한 애플리케이션은 여러 AWS 리전에서 Amazon EC2, AWS Lambda, Amazon RDS, Amazon Simple Notification Service(Amazon SNS), Amazon Simple Queue Service(Amazon SQS) 리소스로 구성되어 있습니다. 회사의 모든 리소스에는 태그 이름이 'application'이고, 이 애플리케이션별로 대응되는 값을 가진 태그가 지정되어 있습니다. 솔루션스 아키텍트는 이러한 태그가 설정된 모든 컴포넌트를 가장 빠르게 식별할 수 있는 솔루션을 제시해야 합니다. 어떤 솔루션이 이 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95145-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 태그를 기준으로 여러 리전과 서비스를 통합적으로 검색하고자 할 때 가장 빠른 방법을 찾는 것입니다. Resource Groups Tag Editor는 태그를 한 번에 관리, 검색 및 보고할 수 있도록 도와주는 서비스로, 다양한 리전에 걸친 모든 태그 지정 리소스를 빠르고 효율적으로 찾아줍니다. 따라서 가장 신속하고 편리한 솔루션은 Resource Groups Tag Editor를 활용하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "프로덕션 애플리케이션",
      "AWS 리소스",
      "태그",
      "application"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "Amazon RDS",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS CloudTrail",
      "AWS CLI",
      "Amazon CloudWatch Logs Insights",
      "AWS Resource Groups Tag Editor"
    ],
    "SelectA": "AWS CloudTrail을 사용하여 application 태그가 지정된 리소스 목록을 생성합니다.",
    "SelectA_Commentary": "CloudTrail은 주로 API 호출을 로깅하는 서비스이므로 태그가 지정된 리소스를 즉시 통합적으로 파악하기에는 적합하지 않습니다.",
    "SelectB": "AWS CLI를 사용하여 모든 리전에서 각 서비스를 쿼리해 application 태그가 지정된 컴포넌트를 보고합니다.",
    "SelectB_Commentary": "모든 리전에 걸쳐 CLI로 개별 서비스를 일일이 조회해야 하므로 가장 빠르고 간단한 방법이 아닙니다.",
    "SelectC": "Amazon CloudWatch Logs Insights에서 쿼리를 실행하여 application 태그가 있는 컴포넌트를 보고합니다.",
    "SelectC_Commentary": "로그 분석 솔루션으로 직접 태그 지정 리소스만 조회하기에는 적합하지 않으므로 빠른 식별 방법으로는 부족합니다.",
    "SelectD": "AWS Resource Groups Tag Editor에서 쿼리를 실행하여 application 태그가 지정된 리소스를 전 리전에 걸쳐 보고합니다.",
    "SelectD_Commentary": "Resource Groups Tag Editor는 태그 관리 및 검색에 최적화된 서비스로, 여러 리전에 있는 태그 지정 자원을 가장 빠르게 식별할 수 있는 방법입니다.",
    "Question_Description_recommedations": [
      "Q949",
      "Q34",
      "Q492",
      "Q364",
      "Q451"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q898",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q233",
      "Q34",
      "Q898"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q970",
      "Q529"
    ],
    "SelectD_recommedations": [
      "Q433",
      "Q529",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q212",
    "Question_Description": "한 회사가 매일 한 번씩 데이터베이스를 Amazon S3로 내보내야 하며, 다른 팀들이 접근할 수 있어야 합니다. 내보내지는 객체의 크기는 2GB에서 5GB 사이로 다양합니다. S3에 대한 데이터 접근 패턴은 급격히 변하고 불규칙적입니다. 데이터는 즉시 사용 가능해야 하고, 최대 3개월 동안은 접근이 가능해야 합니다. 회사는 데이터 검색 시간을 늘리지 않으면서도 가장 비용 효율적인 솔루션을 원합니다. 어떤 S3 스토리지 클래스를 사용해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95300-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 변동이 심한 S3 데이터 접근 패턴에서, 검색 시간을 늘리지 않으면서 비용을 최소화하는 스토리지 클래스를 선택하는 질문입니다. S3 Intelligent-Tiering은 자동으로 액세스 패턴을 모니터링해 자주 접근되지 않는 객체를 저렴한 티어로 옮기면서도 필요 시 즉시 검색할 수 있어, 예측하기 어려운 접근 패턴에 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "일일 데이터베이스 백업",
      "즉시 사용 가능",
      "3개월 보관",
      "비용 효율",
      "가변 접근 패턴"
    ],
    "Terms": [
      "S3 Intelligent-Tiering",
      "S3 Glacier Instant Retrieval",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)"
    ],
    "SelectA": "S3 Intelligent-Tiering",
    "SelectA_Commentary": "데이터의 접근 패턴이 자주 변하고, 즉시 검색이 필요한 상황에서 자동으로 적절한 티어로 전환해 주므로 가장 비용 효율적이며 검색 시간에 영향을 주지 않는 솔루션입니다.",
    "SelectB": "S3 Glacier Instant Retrieval",
    "SelectB_Commentary": "Glacier 계열은 주로 아카이빙 용도로 사용됩니다. 즉시 검색이 가능하지만, 빈번한 접근 패턴이 예상된다면 비용 효율이 떨어질 수 있습니다.",
    "SelectC": "S3 Standard",
    "SelectC_Commentary": "즉시 검색이 가능한 일반 스토리지지만, 객체가 자주 접근되지 않을 때 비용 측면에서 최적이라고 보기 어렵습니다.",
    "SelectD": "S3 Standard-Infrequent Access (S3 Standard-IA)",
    "SelectD_Commentary": "자주 액세스하지 않는 객체에 대한 비용 효율성은 우수하나, 접근 빈도가 예측 불가하고 갑작스러운 접근이 잦다면 비용과 성능 면에서 불리할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q88",
      "Q759",
      "Q890",
      "Q469",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q285",
      "Q1003",
      "Q606"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q415",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q213",
    "Question_Description": "한 회사가 새로운 모바일 앱을 개발하고 있습니다. 이 회사는 Application Load Balancer(ALB)를 크로스 사이트 스크립팅(XSS)이나 SQL 인젝션 같은 대표적인 애플리케이션 레벨 공격으로부터 보호하기 위해 적절한 트래픽 필터링을 구현해야 합니다. 또한 이 회사는 인프라 및 운영 인력이 매우 제한적이므로, 서버를 관리·업데이트·보안 유지하는 책임을 최대한 줄여야 합니다. 이러한 요구 사항을 충족하려면 솔루션스 아키텍트는 어떤 해결책을 권장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95301-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB를 애플리케이션 레벨 공격(예: XSS, SQL 인젝션)에서 보호하려 할 때 가장 간단하고 운영 부담이 적은 방식을 찾는 것입니다. AWS WAF를 ALB에 연동해 두면 기본적으로 제공되는 규칙 세트와 함께 사용해 즉시 보안 정책을 적용할 수 있고, 서버를 직접 운영하거나 업데이트할 필요가 없어 회사의 운영 부담과 책임 범위를 줄일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "모바일 앱",
      "트래픽 필터링",
      "ALB 보호",
      "XSS",
      "SQL 인젝션",
      "인프라와 운영 최소화",
      "책임 감소"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "AWS WAF",
      "Amazon S3",
      "AWS Shield Advanced",
      "Amazon EC2",
      "서드파티 방화벽"
    ],
    "SelectA": "AWS WAF 규칙을 구성하고 이를 ALB에 연동합니다.",
    "SelectA_Commentary": "AWS WAF를 사용하면 ALB에서 발생하는 애플리케이션 레벨 공격에 대한 트래픽 필터링을 즉시 제공하며, 운영 부담이 낮고 서버 관리 책임도 대폭 줄일 수 있어 요구 사항에 부합합니다.",
    "SelectB": "Amazon S3를 퍼블릭 호스팅으로 활성화하여 애플리케이션을 배포합니다.",
    "SelectB_Commentary": "S3 호스팅만으로는 ALB를 통한 트래픽 제어와 애플리케이션 레벨 보안을 제공하기 어렵습니다. ALB로의 공격 방어를 설정할 수 없으므로 적절한 보호책이 되기 어렵습니다.",
    "SelectC": "AWS Shield Advanced를 배포하고 ALB를 보호 리소스로 등록합니다.",
    "SelectC_Commentary": "AWS Shield Advanced는 주로 DDoS 공격(네트워크/전송 계층)을 보호하기 위한 서비스로, XSS나 SQL 인젝션 같은 애플리케이션 레벨 공격 방어에는 적합하지 않습니다.",
    "SelectD": "새로운 ALB를 생성하고 트래픽을 서드파티 방화벽이 동작하는 Amazon EC2 인스턴스로 전달한 뒤, 다시 현재 ALB로 전달합니다.",
    "SelectD_Commentary": "서드파티 방화벽 운영 및 EC2 인스턴스 관리가 추가되어 인프라와 운영이 복잡해지며, 회사의 책임 범위도 크게 늘어나므로 요구 사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q169",
      "Q340",
      "Q707",
      "Q180",
      "Q625"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q106",
      "Q678",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q893",
      "Q169"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q492",
      "Q480"
    ]
  },
  {
    "Question_Number": "Q214",
    "Question_Description": "한 회사의 보고 시스템은 매일 수백 개의 .csv 파일을 Amazon S3 버킷으로 전송합니다. 이 회사는 이 파일들을 Apache Parquet 포맷으로 변환하고, 변환된 파일들을 별도의 변환된 데이터 버킷에 저장해야 합니다. 이러한 작업을 최소한의 개발 노력으로 달성할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95154-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 전달되는 CSV 데이터를 Apache Parquet 포맷으로 자동 변환해야 할 때, 가장 손쉽게 구현할 수 있는 방안을 묻습니다. AWS Glue를 활용하면 크롤러와 ETL 기능을 통해 CSV를 Parquet으로 간편하게 변환할 수 있어 개발 부담이 가장 적고 유지보수도 수월합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "CSV 파일",
      "Apache Parquet 변환",
      "최소 개발 노력",
      "Amazon S3 버킷",
      "변환된 데이터 버킷"
    ],
    "Terms": [
      "Amazon EMR",
      "Apache Spark",
      "AWS Glue crawler",
      "AWS Glue ETL job",
      "AWS Batch",
      "Bash",
      "AWS Lambda",
      "Apache Parquet",
      "Amazon S3"
    ],
    "SelectA": "Amazon EMR 클러스터를 구성하고 Apache Spark를 설치합니다. 데이터를 변환하는 Spark 애플리케이션을 작성하고, EMRFS를 사용해 변환된 데이터를 변환된 데이터 버킷으로 저장합니다.",
    "SelectA_Commentary": "Spark 애플리케이션과 EMR 클러스터 구성, 운영 등의 추가 작업이 필요해 개발과 관리 부담이 큽니다.",
    "SelectB": "AWS Glue crawler를 생성하여 데이터를 탐색합니다. AWS Glue Extract, Transform, and Load(ETL) 작업을 생성해 데이터를 변환합니다. 출력 단계에서 변환된 데이터 버킷을 지정합니다.",
    "SelectB_Commentary": "서버리스 기반 Glue를 활용하면 CSV에서 Parquet 변환을 간편하게 자동화할 수 있어 개발 노력이 가장 적은 이상적인 솔루션입니다.",
    "SelectC": "AWS Batch를 사용하여 Bash 스크립트 문법으로 변환 작업을 정의한 job definition을 만듭니다. 변환된 데이터를 변환된 데이터 버킷에 출력합니다. job 유형으로 배열 작업을 지정해 제출합니다.",
    "SelectC_Commentary": "Batch 작업과 Bash 스크립트 작성 및 스케줄링 관리가 필요해 추가적인 개발과 오케스트레이션 부담이 존재합니다.",
    "SelectD": "AWS Lambda 함수를 생성하여 데이터를 변환하고, 변환된 데이터를 변환된 데이터 버킷으로 출력합니다. S3 버킷에 이벤트 알림을 구성하고 Lambda 함수를 대상 함수로 지정합니다.",
    "SelectD_Commentary": "Lambda로 대용량 파일 변환 시 메모리 및 실행 시간 제한 등이 걸림돌이 될 수 있으며, 변환 로직 구현 부담도 커집니다.",
    "Question_Description_recommedations": [
      "Q258",
      "Q414",
      "Q292",
      "Q2",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q229",
      "Q695"
    ],
    "SelectB_recommedations": [
      "Q103",
      "Q687",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q895",
      "Q443"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q173",
      "Q547"
    ]
  },
  {
    "Question_Number": "Q215",
    "Question_Description": "한 회사는 데이터 센터 내의 NAS(Network Attached Storage)에 700TB의 백업 데이터를 저장하고 있습니다. 이 백업 데이터는 드문 규제 요청 시 접근이 필요하며, 7년 동안 보관되어야 합니다. 회사는 이 백업 데이터를 1개월 이내에 데이터 센터에서 AWS로 마이그레이션하기로 결정했습니다. 회사는 퍼블릭 인터넷 연결을 통해 500Mbps의 전용 대역폭을 데이터 전송에 사용할 수 있습니다. 비용을 가장 낮게 유지하면서 데이터를 어떻게 마이그레이션하고 저장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94983-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "대규모 온프레미스 데이터를 저렴하게 장기 보관해야 하는 상황입니다. 700TB의 데이터를 1개월 내 전송하려면 물리적인 전송 방법인 AWS Snowball을 사용하는 것이 가장 빠르고, 이후 Amazon S3 Glacier Deep Archive로 전환해 보관 비용을 최소화할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "700TB 백업 데이터",
      "NAS",
      "규제 요청",
      "7년 보관",
      "1개월 내 마이그레이션",
      "500Mbps 전용 대역폭",
      "AWS Snowball",
      "Amazon S3 Glacier Deep Archive"
    ],
    "Terms": [
      "AWS Snowball",
      "Amazon S3",
      "Amazon S3 Glacier Deep Archive",
      "AWS DataSync",
      "VPN connection",
      "AWS Direct Connect",
      "NAS",
      "Lifecycle policy"
    ],
    "SelectA": "AWS Snowball 디바이스를 주문해 데이터를 전송하고, Lifecycle policy를 사용해 Amazon S3 Glacier Deep Archive로 파일을 전환합니다.",
    "SelectA_Commentary": "Snowball을 통해 대용량 데이터를 빠르게 옮기고, 장기 보관에는 Glacier Deep Archive를 사용해 비용을 절감하는 최적의 선택입니다.",
    "SelectB": "데이터 센터와 Amazon VPC 간에 VPN 연결을 구성하고, AWS CLI로 온프레미스 데이터를 Amazon S3 Glacier로 복사합니다.",
    "SelectB_Commentary": "VPN만으로 700TB를 전송하면 오래 걸리고 대역폭 제약으로 비용과 시간 모두 비효율적입니다.",
    "SelectC": "500Mbps AWS Direct Connect를 프로비저닝하고, 데이터를 Amazon S3로 전송합니다. 이후 Lifecycle policy로 Amazon S3 Glacier Deep Archive로 전환합니다.",
    "SelectC_Commentary": "Direct Connect 구축에는 시간이 걸리고 비용이 높아, 단기 대용량 이전 용도로는 Snowball이 더 경제적입니다.",
    "SelectD": "AWS DataSync를 사용하여 온프레미스에 DataSync 에이전트를 배포하고, NAS 스토리지에서 곧바로 Amazon S3 Glacier로 파일을 복사합니다.",
    "SelectD_Commentary": "DataSync는 네트워크 전송이므로 700TB 전송 시 한 달 내 완료가 어려울 수 있고, 비용도 더 들 수 있습니다.",
    "Question_Description_recommedations": [
      "Q398",
      "Q778",
      "Q583",
      "Q763",
      "Q617"
    ],
    "SelectA_recommedations": [
      "Q912",
      "Q943",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q497",
      "Q471",
      "Q860"
    ],
    "SelectC_recommedations": [
      "Q300",
      "Q778",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q918",
      "Q703",
      "Q719"
    ]
  },
  {
    "Question_Number": "Q216",
    "Question_Description": "한 회사가 Amazon S3 bucket에 수백만 개의 객체를 보유한 서버리스 웹사이트를 운영 중이며, 이 S3 bucket을 Amazon CloudFront 배포의 오리진으로 사용하고 있습니다. 회사는 객체를 업로드하기 전 S3 bucket에 암호화를 설정하지 않았습니다. 솔루션스 아키텍트는 기존 객체와 추후 추가될 모든 객체에 대해 암호화를 활성화해야 합니다. 최소한의 노력으로 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95040-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "S3 bucket에서 기존 객체와 새 객체 암호화를 한 번에 처리하려면 S3 Inventory로 비암호화 객체를 식별하고, S3 Batch Operations로 사본을 생성해 암호화하는 방식이 가장 쉽고 효율적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "S3 버킷 암호화",
      "기존 객체",
      "S3 Inventory",
      "S3 Batch Operations",
      "기본 암호화",
      "서버리스 웹사이트",
      "CloudFront 오리진"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "S3 Inventory",
      "S3 Batch Operations",
      "AWS Key Management Service (AWS KMS)",
      "SSE-KMS",
      "Versioning"
    ],
    "SelectA": "새로운 S3 bucket을 생성하고 기본 암호화를 활성화한 뒤, 기존 객체를 임시 로컬 스토리지로 다운로드 후 새 버킷으로 업로드합니다.",
    "SelectA_Commentary": "기존 객체를 모두 내려받고 새 버킷에 다시 올려야 하므로 번거롭고 시간과 비용이 많이 듭니다.",
    "SelectB": "기존 S3 bucket의 기본 암호화를 활성화합니다. S3 Inventory 기능으로 비암호화 객체 목록 .csv를 생성하고, S3 Batch Operations의 copy 명령어로 이 객체들을 암호화합니다.",
    "SelectB_Commentary": "새 객체에도 자동으로 암호화가 적용되며, 기존 객체는 Batch Job으로 간편하게 일괄 암호화해 가장 효율적인 방법입니다.",
    "SelectC": "AWS KMS로 새로운 암호화 키를 생성하고, S3 bucket 설정을 SSE-KMS로 변경합니다. 그 후 S3 bucket에 Versioning을 활성화합니다.",
    "SelectC_Commentary": "SSE-KMS와 버저닝만으로는 기존 객체에 대한 자동 암호화 적용이 안 돼 추가 작업이 필요합니다.",
    "SelectD": "AWS Management Console의 Amazon S3에서 S3 bucket 객체 목록을 보고, 암호화 필드로 정렬 후 비암호화 객체를 찾아 Modify 기능으로 기본 암호화를 적용합니다.",
    "SelectD_Commentary": "콘솔에서 객체를 일일이 수동 처리해야 하므로 대규모 객체 관리에는 매우 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q291",
      "Q131",
      "Q256",
      "Q542",
      "Q109"
    ],
    "SelectA_recommedations": [
      "Q256",
      "Q825",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q256",
      "Q965",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q640",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q270",
      "Q256",
      "Q412"
    ]
  },
  {
    "Question_Number": "Q217",
    "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스로 구동되는 글로벌 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon Aurora에 데이터를 저장합니다. 회사는 재해 복구(Disaster Recovery) 솔루션을 구축해야 하며, 30분 정도의 다운타임과 일부 데이터 손실을 수용할 수 있습니다. 또한 주(primary) 인프라가 정상일 때는 부하를 처리할 필요가 없습니다. 이러한 요구 사항을 만족하려면 솔루션스 아키텍트가 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95015-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 재해 복구를 위한 대기(active-passive) 환경을 설계하는 상황입니다. 요구 사항에서 주 인프라가 정상일 때 부하 처리가 필요 없으므로, Route 53 Active-Passive 구성을 고려해야 합니다. Aurora Replica를 사용하면 30분 이내 다운타임과 일부 데이터 손실 허용 조건을 충족하면서 복구 시간을 단축할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "글로벌 웹 애플리케이션",
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon Aurora",
      "재해 복구",
      "다운타임 30분",
      "Route 53",
      "Active-Passive Failover"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon Aurora",
      "Aurora Replica",
      "AWS Region",
      "AWS Backup",
      "Route 53 Active-Passive Failover",
      "Active-Active Failover",
      "두 번째 Primary Instance"
    ],
    "SelectA": "필요한 인프라 요소를 미리 배포하고, Amazon Route 53을 사용해 Active-Passive Failover를 구성합니다. 두 번째 AWS Region에 Aurora Replica를 생성합니다.",
    "SelectA_Commentary": "Active-Passive 패턴과 Aurora Replica를 이용해 DR 요구사항을 충족합니다. 주 인프라가 정상일 때는 부하를 처리하지 않아도 되어 운영 비용도 절감됩니다.",
    "SelectB": "두 번째 AWS Region에 축소된 형태의 애플리케이션을 호스팅합니다. Amazon Route 53으로 Active-Active Failover를 구성합니다. 두 번째 Region에 Aurora Replica를 생성합니다.",
    "SelectB_Commentary": "Active-Active는 주 인프라가 정상일 때도 부하를 처리해야 하므로 요구사항과 맞지 않습니다. 불필요한 비용과 복잡도가 증가합니다.",
    "SelectC": "기존 인프라를 두 번째 AWS Region에 그대로 복제합니다. Amazon Route 53으로 Active-Active Failover를 구성합니다. 최신 스냅샷에서 복원한 Aurora DB를 사용합니다.",
    "SelectC_Commentary": "Active-Active 형태로 항상 두 리전 모두 부하를 처리하게 됩니다. 필요 이상의 구성으로, 주 인프라가 정상일 때 부하를 처리하지 않아도 되는 요구사항과 어긋납니다.",
    "SelectD": "AWS Backup을 사용해 데이터를 백업하고, 이 백업으로 두 번째 AWS Region에서 필요한 인프라를 생성합니다. Amazon Route 53으로 Active-Passive Failover를 구성하고, 두 번째 Region에 Aurora 두 번째 Primary 인스턴스를 생성합니다.",
    "SelectD_Commentary": "Aurora 두 번째 Primary 인스턴스를 만드는 것은 과도합니다. 필요한 것은 Replica 수준으로도 충분하며, 백업에서 모든 인프라를 재생성하는 방식은 RTO를 늘릴 수 있습니다.",
    "Question_Description_recommedations": [
      "Q955",
      "Q275",
      "Q639",
      "Q405",
      "Q1012"
    ],
    "SelectA_recommedations": [
      "Q836",
      "Q545",
      "Q224"
    ],
    "SelectB_recommedations": [
      "Q585",
      "Q447",
      "Q527"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q527",
      "Q224"
    ],
    "SelectD_recommedations": [
      "Q836",
      "Q585",
      "Q891"
    ]
  },
  {
    "Question_Number": "Q218",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 웹 서버를 구동하고 있습니다. 이 인스턴스는 Elastic IP 주소가 할당된 퍼블릭 서브넷에 위치해 있으며 기본 보안 그룹이 적용되어 있습니다. 또한 기본 Network ACL이 모든 트래픽을 차단하도록 수정된 상태입니다. 솔루션스 아키텍트는 웹 서버를 전 세계 어디에서나 포트 443(HTTPS)으로 접근 가능하도록 구성해야 합니다. 어떤 조치들의 조합이 이를 달성할 수 있습니까? (두 개를 고르십시오.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95056-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2에 웹 서버를 두고, 기본 Security Group과 Network ACL을 적절히 구성해 HTTPS(443) 포트를 전 세계에서 허용하도록 설정하는 방법을 묻습니다. 루트 원리로, Security Group은 인바운드에서 443을 허용해야 하며, Network ACL은 양방향 트래픽을 모두 처리하기 위해 443과 에페머럴 포트 범위를 열어야 합니다. EC2 인스턴스가 제대로 HTTPS로 접근 가능하려면, 보안 그룹과 Network ACL 양쪽에서 인바운드/아웃바운드를 모두 허용해 주어야 합니다. 따라서 올바른 조합은 Security Group이 443 인바운드를 열고, Network ACL이 443 인바운드와 32768-65535 아웃바운드를 허용하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "웹 서버 접근",
      "보안 그룹",
      "Network ACL",
      "퍼블릭 서브넷",
      "포트 443"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic IP",
      "Security Group",
      "Network ACL",
      "TCP 443",
      "Ephemeral Port (32768-65535)"
    ],
    "SelectA": "Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0.",
    "SelectA_Commentary": "보안 그룹에서 인바운드 443을 열어 전 세계 접근을 허용해 줍니다. 필수 설정이므로 정답에 포함됩니다.",
    "SelectB": "Create a security group with a rule to allow TCP port 443 to destination 0.0.0.0/0.",
    "SelectB_Commentary": "Security Group 설정이지만 목적지 방향 설정이므로 잘못된 방향(아웃바운드) 규칙입니다.",
    "SelectC": "Update the network ACL to allow TCP port 443 from source 0.0.0.0/0.",
    "SelectC_Commentary": "NACL에서 단순히 443 인바운드만 허용하면 반응 패킷이 반환되지 않아 HTTPS 접근이 제대로 동작하지 않습니다.",
    "SelectD": "Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0.",
    "SelectD_Commentary": "NACL에서 443만 열 경우, 에페머럴 포트 범위가 차단되어 실제 통신이 이루어지기 어렵습니다.",
    "SelectE": "Update the network ACL to allow inbound TCP port 443 from source 0.0.0.0/0 and outbound TCP port 32768-65535 to destination 0.0.0.0/0.",
    "SelectE_Commentary": "HTTPS 요청 수락(443 인바운드), 반환(에페머럴 포트 아웃바운드)을 모두 열어야 하므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q697",
      "Q608",
      "Q766",
      "Q115",
      "Q470"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q233",
      "Q385"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q233",
      "Q385"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q218",
      "Q233"
    ],
    "SelectD_recommedations": [
      "Q218",
      "Q774",
      "Q697"
    ],
    "SelectE_recommedations": [
      "Q218",
      "Q774",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q219",
    "Question_Description": "한 회사의 애플리케이션에서 성능 문제가 발생하고 있습니다. 이 애플리케이션은 상태를 저장하며 Amazon EC2 인스턴스에서 인메모리 작업을 수행해야 합니다. 해당 회사는 AWS CloudFormation을 사용해 인프라를 배포했고, M5 EC2 인스턴스 패밀리를 사용했습니다. 트래픽이 증가함에 따라 애플리케이션의 성능이 저하되었으며, 사용자는 애플리케이션 접근 시 지연을 보고하고 있습니다. 이 문제를 가장 운영 효율적인 방식으로 해결하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95162-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "인메모리 기반 애플리케이션 성능 저하 문제를 해결하기 위해 메모리 최적화가 필요한 R5 EC2 인스턴스와 CloudWatch agent를 통한 커스텀 지표 확보가 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "인메모리 작업",
      "EC2 인스턴스 패밀리",
      "성능 문제",
      "CloudFormation",
      "메모리 지표"
    ],
    "Terms": [
      "Amazon EC2",
      "M5 EC2",
      "T3 EC2",
      "R5 EC2",
      "Auto Scaling group",
      "Amazon CloudWatch",
      "CloudWatch agent",
      "AWS Management Console",
      "in-memory tasks",
      "AWS CloudFormation"
    ],
    "SelectA": "T3 EC2 인스턴스로 교체하고 Auto Scaling group을 사용합니다. 변경은 AWS Management Console에서 수행합니다.",
    "SelectA_Commentary": "T3 인스턴스는 버스팅 기반이며 메모리를 많이 사용하는 애플리케이션 요구사항을 만족하기 어렵습니다.",
    "SelectB": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 Auto Scaling group에서 실행합니다. 필요 시 Auto Scaling group의 Desired 및 Maximum capacity를 수동으로 증가시킵니다.",
    "SelectB_Commentary": "Auto Scaling은 확장에 유리하나 메모리 최적화 문제가 해결되지 않아 성능 병목이 해소되지 않습니다.",
    "SelectC": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 R5 EC2로 교체합니다. Amazon CloudWatch의 기본 EC2 메모리 지표를 사용해 향후 용량 계획에 대비합니다.",
    "SelectC_Commentary": "기본 메모리 지표는 기본적으로 지원되지 않으므로 정확한 모니터링이 어렵습니다.",
    "SelectD": "CloudFormation 템플릿을 수정해 EC2 인스턴스를 R5 EC2로 교체합니다. EC2 인스턴스에 Amazon CloudWatch agent를 배포해 커스텀 애플리케이션 지연 시간 지표를 생성해 향후 용량 계획에 사용합니다.",
    "SelectD_Commentary": "메모리 최적화를 위해 R5 패밀리를 사용하고 CloudWatch agent로 세부 지표까지 모니터링해 문제를 효과적으로 해결합니다.",
    "Question_Description_recommedations": [
      "Q746",
      "Q631",
      "Q369",
      "Q910",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q335",
      "Q461",
      "Q257"
    ],
    "SelectB_recommedations": [
      "Q335",
      "Q219",
      "Q130"
    ],
    "SelectC_recommedations": [
      "Q219",
      "Q910",
      "Q857"
    ],
    "SelectD_recommedations": [
      "Q219",
      "Q910",
      "Q976"
    ]
  },
  {
    "Question_Number": "Q220",
    "Question_Description": "한 솔루션스 아키텍트가 Amazon API Gateway를 사용하여 새로운 API를 설계하고 있습니다. 이 API는 사용자로부터 요청을 받으며, 요청 볼륨이 매우 가변적이어서 몇 시간 동안 요청이 없을 수도 있습니다. 데이터 처리는 비동기적으로 이루어지지만, 요청 후 몇 초 내에 완료되어야 합니다. 가장 낮은 비용으로 이 요구 사항을 충족하기 위해 API가 호출해야 할 Compute 서비스는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95306-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 요청이 불규칙하게 발생하는 환경에서 비용 효율적이며 빠른 처리가 가능한 컴퓨팅 서비스를 선택하는 것입니다. 서버리스 방식인 AWS Lambda는 사용된 만큼만 비용을 지불하고, 요청이 없을 때는 추가 비용이 들지 않아 요구 사항을 충족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "새로운 API 설계",
      "비용 최소화",
      "비동기 처리",
      "요청 볼륨 변동"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Glue job",
      "AWS Lambda function",
      "Amazon EKS",
      "Amazon ECS",
      "Amazon EC2"
    ],
    "SelectA": "AWS Glue job",
    "SelectA_Commentary": "AWS Glue job은 ETL 작업에 적합하나 실시간 또는 수 초 내 처리를 요구하는 환경에는 부적합합니다.",
    "SelectB": "AWS Lambda function",
    "SelectB_Commentary": "서버리스 아키텍처로 요청 발생 시에만 동작해 비용 효율적이며, 비동기로 빠르게 확장 가능합니다.",
    "SelectC": "Amazon EKS에 컨테이너 호스팅",
    "SelectC_Commentary": "EKS 클러스터는 유연성이 뛰어나지만, 장시간 대기 상태에서도 최소 인프라 비용이 발생할 수 있습니다.",
    "SelectD": "Amazon EC2에서 Amazon ECS로 컨테이너 호스팅",
    "SelectD_Commentary": "EC2 인스턴스 사용에 따른 상시 비용이 부담되며, 요청이 거의 없을 때도 인프라가 유휴 상태가 됩니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q541",
      "Q985",
      "Q671",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q728",
      "Q284"
    ],
    "SelectB_recommedations": [
      "Q128",
      "Q943",
      "Q284"
    ],
    "SelectC_recommedations": [
      "Q630",
      "Q997",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ]
  },
  {
    "Question_Number": "Q221",
    "Question_Description": "한 회사는 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 운영하고 있습니다. 규정 준수 상의 이유로 모든 애플리케이션 로그 파일을 7년 동안 보존해야 합니다. 이 로그 파일들은 보고 툴에서 동시에 접근할 수 있어야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95307-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 규정상 7년 보존해야 하는 로그 파일을 비용효율적으로 저장하면서 동시 접근해야 하는 상황입니다. Amazon S3는 다수 리소스에서 동시에 접근 가능하며 장기 보관에도 가장 저렴한 옵션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "로그 파일",
      "7년",
      "동시 접근",
      "비용효율성",
      "Amazon S3"
    ],
    "Terms": [
      "Amazon Linux EC2",
      "Amazon EBS",
      "Amazon EFS",
      "Amazon EC2 instance store",
      "Amazon S3"
    ],
    "SelectA": "Amazon Elastic Block Store (Amazon EBS)",
    "SelectA_Commentary": "Amazon EBS는 블록 스토리지로 성능은 우수하지만 장기간 보관 시 비용이 높고 다중 인스턴스 동시 접근이 어렵습니다.",
    "SelectB": "Amazon Elastic File System (Amazon EFS)",
    "SelectB_Commentary": "Amazon EFS는 여러 EC2 인스턴스 간 공유가 가능하지만 장기 보관 시 Amazon S3 대비 비용이 더 높을 수 있습니다.",
    "SelectC": "Amazon EC2 instance store",
    "SelectC_Commentary": "Instance store는 인스턴스 수명과 함께 데이터가 사라지므로 장기간 보관과 동시 접근에 적합하지 않습니다.",
    "SelectD": "Amazon S3",
    "SelectD_Commentary": "Amazon S3는 비용 효율적이며 다수 리소스에서 동시에 접근 가능해 7년 보관 및 동시 접근 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q347",
      "Q238",
      "Q671",
      "Q552",
      "Q167"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q425",
      "Q238"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q277",
      "Q800"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q1013",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q285",
      "Q943",
      "Q1003"
    ]
  },
  {
    "Question_Number": "Q222",
    "Question_Description": "한 회사가 외부 벤더를 고용하여 회사의 AWS 계정에서 작업을 수행하도록 했습니다. 이 벤더는 벤더가 소유한 AWS 계정에 호스팅된 자동화 툴을 사용합니다. 벤더는 회사의 AWS 계정에 대한 IAM 액세스 권한이 없습니다. 이런 상황에서 솔루션스 아키텍트는 어떻게 벤더에게 접근 권한을 부여해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95160-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회사 외부 벤더가 소유한 AWS 계정의 자동화 툴이 회사 계정의 리소스에 안전하게 접근하도록 권한을 부여하는 방법을 묻고 있습니다. 가장 좋은 방법은 회사 계정에서 IAM Role을 생성하고, 해당 Role을 벤더의 IAM Role에 위임하는 신뢰 관계를 설정하여 필요한 권한을 최소 권한 원칙에 따라 부여하는 것입니다. 이를 통해 자격 증리(크리덴셜) 공유 없이도 안전하고 세분화된 접근이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "외부 벤더",
      "IAM 역할 부여",
      "자동화 툴",
      "보안 액세스"
    ],
    "Terms": [
      "IAM Role",
      "IAM User",
      "IAM Group",
      "Identity Provider",
      "AWS Account",
      "Trust Relationship"
    ],
    "SelectA": "회사의 계정에 벤더의 IAM Role에게 위임할 수 있는 IAM Role을 생성하고, 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.",
    "SelectA_Commentary": "트러스트 관계를 설정해 벤더의 Role이 회사 계정의 Role을 Assume하여 필요한 리소스에 접속합니다. 보안성과 필요 권한만 부여하는 최소 권한 원칙을 지킵니다.",
    "SelectB": "회사의 계정에 IAM User를 생성하고, 암호 규칙을 충족하는 비밀번호를 설정합니다. 이후 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.",
    "SelectB_Commentary": "IAM User 계정을 만들어 공유하는 것은 보안상 위험이 크고, 자격 증리 노출 우려가 높아 권장되지 않습니다.",
    "SelectC": "회사의 계정에 IAM Group을 생성하고, 벤더 계정의 IAM User를 그룹에 추가합니다. 이후 벤더가 필요한 권한을 담은 IAM Policy를 연결합니다.",
    "SelectC_Commentary": "벤더 측 User를 직접 그룹에 추가하면 신뢰 관계 설정 없이 접근이 이뤄져 관리가 복잡하고 안전하지 않습니다.",
    "SelectD": "IAM 콘솔에서 'AWS account' 유형으로 새 Identity Provider를 생성하고, 벤더의 AWS account ID와 사용자 이름을 입력합니다. 벤더가 필요한 권한을 담은 IAM Policy를 새 Provider에 연결합니다.",
    "SelectD_Commentary": "Identity Provider는 주로 외부 IdP 연동(페더레이션)용이며, 단순 권한 위임 목적으로 사용하기에는 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q780",
      "Q548",
      "Q484",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q423",
      "Q429",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q476",
      "Q423"
    ],
    "SelectC_recommedations": [
      "Q395",
      "Q476",
      "Q429"
    ],
    "SelectD_recommedations": [
      "Q780",
      "Q222",
      "Q750"
    ]
  },
  {
    "Question_Number": "Q223",
    "Question_Description": "한 회사가 사설 서브넷에서 Amazon Elastic Kubernetes Service(Amazon EKS)에서 동작하는 파드로 Java Spring Boot 애플리케이션을 배포했습니다. 이 애플리케이션은 Amazon DynamoDB 테이블에 데이터를 써야 합니다. 솔루션스 아키텍트는 인터넷에 트래픽을 노출하지 않고 애플리케이션이 DynamoDB 테이블과 상호 작용하도록 보장해야 합니다. 다음 중 이를 달성하기 위해 솔루션스 아키텍트가 수행해야 할 조합은 무엇입니까? (2개를 선택하십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95310-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사설 서브넷에 있는 EKS 파드가 인터넷을 통하지 않고 DynamoDB에 안전하게 접근하도록 구성하는 방법을 묻습니다. IAM role을 사용해 파드에 권한을 부여하고 VPC endpoint로 사설 경로를 설정하면 인터넷 노출 없이 DynamoDB에 접근할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Amazon EKS",
      "Java Spring Boot",
      "IAM role",
      "Amazon DynamoDB",
      "VPC endpoint",
      "사설 서브넷",
      "인터넷 비노출"
    ],
    "Terms": [
      "Amazon EKS",
      "Java Spring Boot",
      "IAM role",
      "Amazon DynamoDB",
      "VPC endpoint",
      "Network ACL"
    ],
    "SelectA": "권한이 충분한 IAM role을 EKS 파드에 연결합니다.",
    "SelectA_Commentary": "EKS 파드가 DynamoDB에 쓰기 권한을 갖도록 하는 올바른 접근 방식입니다. 하드코딩 없이 안전하게 권한을 부여합니다.",
    "SelectB": "권한이 충분한 IAM user를 EKS 파드에 연결합니다.",
    "SelectB_Commentary": "IAM user 대신 IAM role을 사용하는 것이 모범 사례이므로 적절치 않습니다.",
    "SelectC": "사설 서브넷의 network ACL을 통해 DynamoDB 테이블로의 아웃바운드 연결을 허용합니다.",
    "SelectC_Commentary": "Network ACL을 통한 아웃바운드 허용만으로는 인터넷을 우회해 DynamoDB로 트래픽을 보내는 것을 완전히 보장하지 못합니다.",
    "SelectD": "DynamoDB용 VPC endpoint를 생성합니다.",
    "SelectD_Commentary": "VPC endpoint를 통해 트래픽을 사설 경로로 라우팅하므로 인터넷에 노출되지 않고 DynamoDB에 액세스할 수 있습니다.",
    "SelectE": "Java Spring Boot 코드에 액세스 키를 하드코딩합니다.",
    "SelectE_Commentary": "하드코딩된 액세스 키는 보안상 취약하므로 권장되지 않는 접근 방식입니다.",
    "Question_Description_recommedations": [
      "Q176",
      "Q805",
      "Q675",
      "Q371",
      "Q681"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q893",
      "Q106"
    ],
    "SelectC_recommedations": [
      "Q279",
      "Q176",
      "Q727"
    ],
    "SelectD_recommedations": [
      "Q562",
      "Q279",
      "Q176"
    ],
    "SelectE_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q224",
    "Question_Description": "한 회사가 웹 애플리케이션을 AWS로 마이그레이션하여, 단일 AWS Region의 Amazon EC2 인스턴스에서 애플리케이션을 리호스팅했습니다. 이 회사는 애플리케이션 아키텍처를 고가용성 및 내결함성( fault tolerant )으로 재설계하고자 합니다. 트래픽은 실행 중인 모든 EC2 인스턴스에 무작위로 분산되어야 합니다. 이러한 요구사항을 충족하기 위해 어떤 조합의 단계를 수행해야 합니까? (두 가지를 고르세요.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95311-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스를 여러 AZ에 분산 배치하고, 트래픽을 무작위로 분산할 방법을 묻습니다. multivalue answer routing policy를 사용하면 DNS 응답에 여러 IP를 무작위로 반환해 트래픽을 분산할 수 있고, 여러 AZ에 인스턴스를 배포해 고가용성과 내결함성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "내결함성",
      "트래픽 무작위 분산",
      "Amazon EC2",
      "Amazon Route 53",
      "multivalue answer routing policy",
      "Availability Zone"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Route 53",
      "failover routing policy",
      "weighted routing policy",
      "multivalue answer routing policy",
      "Availability Zone"
    ],
    "SelectA": "Create an Amazon Route 53 failover routing policy.",
    "SelectA_Commentary": "failover routing은 기본 리소스가 실패했을 때 보조 리소스로 트래픽을 전환하는 용도로, 무작위 분배나 이중화 배포와는 목적이 다릅니다.",
    "SelectB": "Create an Amazon Route 53 weighted routing policy.",
    "SelectB_Commentary": "weighted routing은 가중치에 따라 트래픽을 배분하는 것으로, 난수 방식으로 무작위 배분하기엔 적절하지 않습니다.",
    "SelectC": "Create an Amazon Route 53 multivalue answer routing policy.",
    "SelectC_Commentary": "multivalue answer routing policy를 사용하면 DNS 응답 시 여러 IP들을 무작위 순서로 반환하여 트래픽을 분산할 수 있어 요구사항에 부합합니다.",
    "SelectD": "Launch three EC2 instances: two instances in one Availability Zone and one instance in another Availability Zone.",
    "SelectD_Commentary": "AZ를 이중화한 것은 좋지만, 세 개의 인스턴스만으로는 무작위 분산 시 리소스 활용이 불균형해질 수 있습니다.",
    "SelectE": "Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.",
    "SelectE_Commentary": "두 개의 AZ에 각각 두 개의 인스턴스를 배포하여 고가용성과 부하 분산을 확보하므로 요구사항에 적합합니다.",
    "Question_Description_recommedations": [
      "Q312",
      "Q892",
      "Q456",
      "Q47",
      "Q570"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q836",
      "Q242"
    ],
    "SelectB_recommedations": [
      "Q242",
      "Q545",
      "Q544"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q544",
      "Q242"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q570",
      "Q48"
    ],
    "SelectE_recommedations": [
      "Q660",
      "Q570",
      "Q48"
    ]
  },
  {
    "Question_Number": "Q225",
    "Question_Description": "한 미디어 회사가 온프레미스에서 사용자 활동 데이터를 수집하고 분석해 왔습니다. 이 데이터는 페타바이트(PB) 규모까지 계속 증가할 예정입니다. 회사는 고가용성의 데이터 수집 솔루션을 구축해야 하며, 기존 데이터와 신규 데이터를 SQL로 온디맨드 분석할 수 있어야 합니다. 또한 운영 오버헤드를 최소화해야 합니다. 이 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94985-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 증가하는 대규모 데이터를 안정적으로 수집하고 곧바로 SQL 기반 분석을 해야 하는 상황에서, 가장 단순하고 자동화된 파이프라인을 구성하는 방안을 묻습니다. Kinesis Data Firehose를 통해 Amazon Redshift로 직접 스트리밍하면 페타바이트 규모의 데이터도 빠르게 적재하고 SQL로 분석이 가능합니다. 완전관리형 서비스 조합으로 운영 오버헤드를 최소화할 수 있다는 점이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "미디어 회사",
      "사용자 활동 데이터",
      "페타바이트 규모",
      "고가용성 데이터 수집",
      "온디맨드 분석",
      "SQL",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Kinesis Data Stream",
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "Amazon Redshift",
      "AWS Lambda",
      "Amazon EC2",
      "Amazon RDS",
      "Multi-AZ"
    ],
    "SelectA": "Amazon Kinesis Data Stream에 활동 데이터를 전송합니다. 스트림을 Amazon S3 버킷으로 전달하도록 구성합니다.",
    "SelectA_Commentary": "Kinesis Data Stream을 사용하면 별도의 소비자 애플리케이션 설정이 필요해 운영 부담이 큽니다. 또한 수집 후 SQL 분석 환경(예: Redshift, Athena) 구성이 추가로 필요합니다.",
    "SelectB": "Amazon Kinesis Data Firehose 스트림에 활동 데이터를 전송합니다. 스트림을 Amazon Redshift 클러스터로 전달하도록 구성합니다.",
    "SelectB_Commentary": "Kinesis Data Firehose는 완전관리형으로 데이터를 대규모로 실시간 적재할 수 있고, Redshift를 통해 손쉽게 SQL 분석이 가능합니다. 운영 오버헤드를 크게 줄이는 최적의 솔루션입니다.",
    "SelectC": "Amazon S3 버킷에 활동 데이터를 저장합니다. 데이터가 도착하면 Amazon S3에서 AWS Lambda 함수를 실행하도록 구성합니다.",
    "SelectC_Commentary": "Lambda로 후처리를 할 수 있지만, 바로 SQL 분석을 제공하지 않습니다. 추가 서비스(Athena 등) 구성이 필요하고 실시간 적재 측면에서도 Firehose보다 관리 포인트가 많습니다.",
    "SelectD": "멀티 AZ에 분산된 Amazon EC2 인스턴스에서 자체 인제션 서비스를 실행하고, 이 서비스를 Amazon RDS Multi-AZ 데이터베이스로 전달되도록 구성합니다.",
    "SelectD_Commentary": "EC2 기반 자체 서비스와 대규모 RDS 운영은 복잡도가 높습니다. 페타바이트 규모 데이터에 대한 SQL 분석용으로는 확장성 측면에서 부적합합니다.",
    "Question_Description_recommedations": [
      "Q192",
      "Q523",
      "Q77",
      "Q472",
      "Q292"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q402",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q523"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q173",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q633",
      "Q193",
      "Q386"
    ]
  },
  {
    "Question_Number": "Q226",
    "Question_Description": "한 회사가 RESTful web services 애플리케이션을 Amazon EC2 인스턴스에서 실행하여 수천 대의 원격 디바이스로부터 데이터를 수집하고 있습니다. EC2 인스턴스는 수집된 원시 데이터를 받아 변환하여 Amazon S3 버킷에 저장하고 있습니다. 원격 디바이스의 수가 곧 수백만 대로 증가할 예정이므로, 회사는 운영 오버헤드를 최소화하면서 고도로 확장 가능한 솔루션이 필요합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 단계 조합은 다음 중 무엇일까요? (2개 선택)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95312-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "수집 장치가 대폭 늘어나는 시나리오에서 API Gateway와 Kinesis를 통한 무중단 확장성을 확보하고, 데이터를 S3에 저장한 뒤 Glue로 간편하게 변환하는 방안이 가장 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "고도로 확장 가능한 솔루션",
      "운영 오버헤드 최소화",
      "RESTful 웹 서비스",
      "Amazon EC2",
      "Amazon S3"
    ],
    "Terms": [
      "AWS Glue",
      "Amazon Route 53",
      "Amazon SQS",
      "Amazon EC2",
      "Amazon API Gateway",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon S3"
    ],
    "SelectA": "AWS Glue를 사용하여 Amazon S3의 원시 데이터를 처리합니다.",
    "SelectA_Commentary": "AWS Glue를 통해 S3에 적재된 원시 데이터를 손쉽게 추출·변환·적재(ETL)할 수 있어, 개발 및 운영 부담을 줄이고 자동 확장도 용이합니다.",
    "SelectB": "Amazon Route 53을 사용하여 다른 EC2 인스턴스로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "Route 53만으로는 확장에 필요한 데이터 처리 파이프라인이 마련되지 않으며, 단순 DNS 라우팅만으로는 운영 오버헤드를 크게 줄이지 못합니다.",
    "SelectC": "증가하는 데이터 처리를 위해 EC2 인스턴스를 추가 배치합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 직접 늘리는 방식은 서버 관리 부담과 확장 한계가 커지므로 운영 오버헤드가 증가합니다.",
    "SelectD": "Amazon SQS로 원시 데이터를 보내고, EC2 인스턴스로 데이터를 처리합니다.",
    "SelectD_Commentary": "SQS만으로 다량의 스트리밍 데이터를 실시간으로 처리하기에는 한계가 있으며, 서버 운영 복잡성을 완전히 해소하지 못합니다.",
    "SelectE": "Amazon API Gateway를 사용하여 원시 데이터를 Amazon Kinesis Data Streams로 전송하고, Amazon Kinesis Data Firehose를 사용해 데이터를 Amazon S3로 전달하도록 구성합니다.",
    "SelectE_Commentary": "API Gateway와 Kinesis를 조합하여 무중단 확장성을 확보하고, Firehose로 실시간 데이터를 안정적으로 S3에 적재할 수 있으므로 운영이 단순해집니다.",
    "Question_Description_recommedations": [
      "Q41",
      "Q910",
      "Q193",
      "Q320",
      "Q746"
    ],
    "SelectA_recommedations": [
      "Q155",
      "Q103",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q582",
      "Q746",
      "Q367"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q361",
      "Q568"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q292",
      "Q361"
    ],
    "SelectE_recommedations": [
      "Q402",
      "Q597",
      "Q576"
    ]
  },
  {
    "Question_Number": "Q227",
    "Question_Description": "한 회사는 AWS CloudTrail logs를 3년 동안 보관해야 합니다. 이 회사는 부모 계정에서 AWS Organizations를 사용해 여러 AWS 계정에 대해 CloudTrail을 강제 적용하고 있습니다. CloudTrail이 기록되는 대상 S3 bucket에는 S3 Versioning이 활성화되어 있으며, 현재 객체에 대해서는 3년 후 삭제되도록 S3 Lifecycle Policy가 설정되어 있습니다. 그런데 4년차가 되었을 때 S3 bucket 메트릭에서 확인해보니, 새로운 CloudTrail logs의 증가량은 동일함에도 불구하고 객체 수가 계속 증가하고 있습니다. 가장 비용 효율적인 방식으로 3년이 지난 객체들을 삭제하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95314-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Versioning이 활성화된 S3에서 3년 후 현재 객체만 삭제하면 이전 버전은 계속 남아 비용이 증가합니다. 따라서 이전 버전까지 제거하도록 Lifecycle Policy를 설정해주는 것이 가장 간단하고 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "AWS CloudTrail logs",
      "S3 Versioning",
      "S3 Lifecycle Policy",
      "3년 보관",
      "비용 효율"
    ],
    "Terms": [
      "AWS CloudTrail",
      "AWS Organizations",
      "S3 Versioning",
      "S3 Lifecycle Policy",
      "S3 bucket",
      "AWS Lambda",
      "Object Ownership"
    ],
    "SelectA": "조직에서 중앙 집중화된 CloudTrail trail을 구성해 3년 후 객체가 만료되도록 설정합니다.",
    "SelectA_Commentary": "CloudTrail trail 설정만으로 이전 버전을 삭제할 수 없으며, Versioning 및 Lifecycle 통합이 필요하므로 적절한 해법이 아닙니다.",
    "SelectB": "S3 Lifecycle Policy를 이전 버전뿐 아니라 현재 버전도 함께 삭제하도록 구성합니다.",
    "SelectB_Commentary": "Versioning이 활성화된 환경에서 이전 버전까지 삭제해주는 Lifecycle Policy 설정이 필요하므로 가장 효율적이고 간단한 해결책입니다.",
    "SelectC": "3년 이상 된 객체를 Amazon S3에서 열거 후 삭제하는 AWS Lambda 함수를 만듭니다.",
    "SelectC_Commentary": "Lambda 함수를 통해 자동화할 수 있지만, 별도의 구축·유지 비용이 들며, S3 Lifecycle Policy에 비해 관리가 복잡합니다.",
    "SelectD": "배포 계정을 S3 bucket에 전달되는 모든 객체의 소유자로 설정합니다.",
    "SelectD_Commentary": "Object Owner를 부모 계정으로 변경해도 이전 버전 삭제 문제는 해결되지 않으므로, 비용 최적화에 직접적인 도움이 되지 않습니다.",
    "Question_Description_recommedations": [
      "Q534",
      "Q651",
      "Q455",
      "Q498",
      "Q960"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q486",
      "Q1003"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q943",
      "Q993"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q993",
      "Q769"
    ],
    "SelectD_recommedations": [
      "Q1003",
      "Q911",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q228",
    "Question_Description": "한 회사에 모니터링 디바이스로부터 실시간 데이터를 수신하는 API가 있습니다. 이 API는 수집된 데이터를 나중의 분석을 위해 Amazon RDS DB instance에 저장합니다. 모니터링 디바이스에서 전송되는 데이터량은 변동이 있으며, 트래픽이 많은 시기에는 API가 종종 타임아웃 에러를 반환합니다. 로그를 확인한 결과, DB가 API에서 발생하는 대량의 쓰기 트래픽을 처리하지 못하는 것으로 파악되었습니다. 솔루션스 아키텍트는 DB에 대한 연결 수를 최소화하고, 트래픽 급증 시에도 데이터가 손실되지 않도록 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95318-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트래픽 급증 시 DB 과부하를 막고 데이터 유실을 방지하기 위해 아키텍처를 느슨하게 결합해야 함을 보여줍니다. Amazon SQS가 적절한 버퍼 역할을 하여 DB 연결을 줄이고 메시지를 안전하게 처리할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "실시간 데이터",
      "Amazon RDS",
      "DB 인스턴스",
      "트래픽 변동",
      "쓰기 트래픽",
      "연결 수 최소화",
      "데이터 손실 방지"
    ],
    "Terms": [
      "Amazon RDS",
      "Multi-AZ DB",
      "Amazon SQS",
      "AWS Lambda",
      "Amazon SNS"
    ],
    "SelectA": "더 많은 메모리를 사용할 수 있는 인스턴스 타입으로 DB 인스턴스 크기를 늘립니다.",
    "SelectA_Commentary": "DB 인스턴스 스펙 업그레이드는 일시적 성능 향상을 줄 뿐, 트래픽 스파이크와 연결 수 제한에 근본적인 해답이 되지 못합니다.",
    "SelectB": "DB 인스턴스를 Multi-AZ로 수정합니다. 애플리케이션을 모든 활성 RDS DB 인스턴스에 쓰도록 구성합니다.",
    "SelectB_Commentary": "Multi-AZ 구성은 장애 복원을 위한 것이지 쓰기 처리량 증가나 연결 수 제한을 해결하기에 적합하지 않습니다.",
    "SelectC": "API가 들어오는 데이터를 Amazon Simple Queue Service(Amazon SQS) 큐에 쓰도록 수정합니다. Amazon SQS에서 AWS Lambda 함수를 호출하여 큐에서 DB로 데이터를 쓰도록 합니다.",
    "SelectC_Commentary": "SQS 큐를 사용하여 트래픽 변동을 흡수하고, Lambda 함수로 연결을 단순화해 DB 부하를 줄이며, 데이터 유실을 방지할 수 있는 최적의 솔루션입니다.",
    "SelectD": "API가 들어오는 데이터를 Amazon Simple Notification Service(Amazon SNS) 토픽에 쓰도록 수정합니다. Amazon SNS에서 AWS Lambda 함수를 호출하여 토픽에서 DB로 데이터를 쓰도록 합니다.",
    "SelectD_Commentary": "SNS는 주로 메시지 브로드캐스트(퍼블리시/서브스크라이브) 용도이며, 큐잉 방식이 아니라 트래픽 급증 시 데이터 처리 지연이나 연결 부담이 여전히 발생할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q108",
      "Q259",
      "Q114",
      "Q400",
      "Q444"
    ],
    "SelectA_recommedations": [
      "Q917",
      "Q58",
      "Q491"
    ],
    "SelectB_recommedations": [
      "Q466",
      "Q518",
      "Q259"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q207",
      "Q203"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q45",
      "Q148"
    ]
  },
  {
    "Question_Number": "Q229",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 MySQL 데이터베이스를 운영하고 있습니다. 현재는 수요 변화에 따라 수동으로 복제와 확장을 관리하고 있습니다. 회사는 필요에 따라 데이터베이스 계층의 컴퓨트 용량을 쉽게 추가하거나 제거할 수 있는 새로운 솔루션이 필요합니다. 또한 운영의 노력은 최소화하면서 성능, 확장성, 내구성을 개선해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95319-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 자체 EC2 환경에서 MySQL 데이터베이스를 유지하며, 복제와 확장을 수동으로 관리하는 비효율성을 해결하는 목적입니다. 운영 부담을 줄이면서 성능, 확장성, 내구성을 높이는 해법을 찾아야 합니다. 정답인 Amazon Aurora Serverless for Aurora MySQL로 이전하면 자동 확장과 복제를 지원하므로, 수요 변화에 따라 쉽고 빠르게 컴퓨트 용량을 조정할 수 있고, 내장된 고가용성 및 내구성 덕분에 운영적으로 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon EC2",
      "MySQL",
      "복제",
      "확장성",
      "성능",
      "내구성",
      "Aurora MySQL",
      "Aurora Serverless"
    ],
    "Terms": [
      "Amazon EC2",
      "MySQL",
      "Amazon Aurora",
      "Aurora MySQL",
      "Aurora PostgreSQL",
      "Aurora Serverless",
      "EC2 Auto Scaling"
    ],
    "SelectA": "Amazon Aurora Serverless for Aurora MySQL로 데이터베이스를 마이그레이션합니다.",
    "SelectA_Commentary": "Aurora Serverless for Aurora MySQL은 자동 복제와 자동 확장을 제공하여 운영 복잡성을 최소화하고 성능, 내구성까지 보장하므로 요구사항에 부합합니다.",
    "SelectB": "Amazon Aurora Serverless for Aurora PostgreSQL로 데이터베이스를 마이그레이션합니다.",
    "SelectB_Commentary": "다른 데이터베이스 엔진으로 전환하면 호환성 문제가 발생할 수 있고 코드 수정이 필요하여 요구사항을 만족시키기 어렵습니다.",
    "SelectC": "모든 데이터베이스를 하나의 대형 MySQL 데이터베이스로 통합하고, 더 큰 EC2 인스턴스를 사용합니다.",
    "SelectC_Commentary": "단순히 인스턴스 크기를 늘려도 자동 확장과 복제 측면에서 장점이 부족하고 운영 부담이 계속 높게 유지됩니다.",
    "SelectD": "데이터베이스 계층을 위한 EC2 Auto Scaling 그룹을 생성하고, 기존 데이터베이스를 새 환경으로 마이그레이션합니다.",
    "SelectD_Commentary": "EC2 Auto Scaling만으로는 데이터베이스 복제와 확장을 자동화하기가 어렵고, 여전히 수동 관리가 필요합니다.",
    "Question_Description_recommedations": [
      "Q565",
      "Q834",
      "Q596",
      "Q746",
      "Q192"
    ],
    "SelectA_recommedations": [
      "Q834",
      "Q565",
      "Q235"
    ],
    "SelectB_recommedations": [
      "Q235",
      "Q886",
      "Q603"
    ],
    "SelectC_recommedations": [
      "Q229",
      "Q565",
      "Q834"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q335",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q230",
    "Question_Description": "회사는 두 개의 NAT instance가 회사 애플리케이션에 필요한 트래픽을 더 이상 처리할 수 없을 것을 우려하고 있습니다. 솔루션스 아키텍트는 고가용성, 내결함성, 자동 확장을 제공하는 솔루션을 구현하려고 합니다. 어떤 방안을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95322-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "NAT instance 대신 NAT gateway를 사용하면 AWS가 직접 관리하므로 유지 보수 부담이 줄어듭니다. 여러 AZ에 배포하면 장애가 발생해도 서비스가 지속되며 자동 확장까지 지원되어 트래픽 증가를 원활히 처리할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "NAT instance",
      "NAT gateway",
      "고가용성",
      "내결함성",
      "자동 확장",
      "트래픽"
    ],
    "Terms": [
      "NAT instance",
      "NAT gateway",
      "Auto Scaling group",
      "Network Load Balancer",
      "Availability Zone",
      "Spot Instances",
      "고가용성",
      "내결함성",
      "자동 확장"
    ],
    "SelectA": "두 NAT instance를 제거하고 동일한 AZ에 두 NAT gateway를 배포합니다.",
    "SelectA_Commentary": "같은 AZ에만 배포하면 AZ 장애 시 유연성이 제한되어 고가용성을 보장하기 어렵습니다.",
    "SelectB": "서로 다른 AZ에 NAT instance를 두고 Network Load Balancer와 Auto Scaling group을 구성합니다.",
    "SelectB_Commentary": "NAT instance는 직접 관리가 필요하며, 완전관리형 NAT gateway보다 운영 부담이 큽니다.",
    "SelectC": "두 NAT instance를 제거하고 다른 AZ에 두 NAT gateway를 배포합니다.",
    "SelectC_Commentary": "고가용성과 자동 확장을 지원하는 완전관리형 솔루션으로, 여러 AZ에 배포해 내결함성과 확장성을 보장합니다.",
    "SelectD": "다른 AZ에 Spot Instances로 NAT instance를 대체하고 Network Load Balancer를 배포합니다.",
    "SelectD_Commentary": "Spot Instances는 비용 효율적이지만 일시 중단 위험이 있어 안정성과 가용성을 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q8",
      "Q149",
      "Q163",
      "Q252",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q230",
      "Q708",
      "Q487"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q275",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q230",
      "Q708",
      "Q487"
    ],
    "SelectD_recommedations": [
      "Q230",
      "Q545",
      "Q275"
    ]
  },
  {
    "Question_Number": "Q231",
    "Question_Description": "한 애플리케이션이 VPC A에 있는 Elastic IP 주소를 가진 Amazon EC2 인스턴스에서 실행 중이며, 해당 애플리케이션은 VPC B에 있는 데이터베이스에 액세스해야 합니다. 두 VPC는 동일한 AWS 계정 내에 있습니다. 가장 안전하게 필요한 액세스를 제공할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95323-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "VPC 간 안전한 연결 방법을 묻는 문제로, 같은 AWS 계정 내에서 트래픽이 인터넷을 거치지 않고 직접 통신할 수 있도록 VPC 피어링을 구성하는 것이 가장 보안상 유리합니다. 각 VPC 간 네트워크 트래픽이 내부적으로만 오가므로, 외부 노출 위험 없이 DB 액세스를 안전하게 구성할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "애플리케이션",
      "Amazon EC2 인스턴스",
      "Elastic IP",
      "VPC A",
      "VPC B",
      "데이터베이스",
      "VPC 피어링 연결"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic IP",
      "VPC 피어링(VPC Peering)",
      "DB 인스턴스",
      "보안 그룹(Security Group)",
      "Public IP",
      "프록시(Proxy)"
    ],
    "SelectA": "VPC의 애플리케이션 서버 퍼블릭 IP 주소에서 모든 트래픽을 허용하도록 DB 인스턴스 보안 그룹을 생성합니다.",
    "SelectA_Commentary": "퍼블릭 IP를 통한 공개 인터넷 트래픽 허용은 보안상 취약하며, 트래픽이 인터넷을 거치므로 안전하지 않습니다.",
    "SelectB": "VPC A와 VPC B 간 VPC 피어링 연결을 구성합니다.",
    "SelectB_Commentary": "VPC 피어링을 사용하면 인터넷을 거치지 않고 두 VPC 간 직접 통신이 가능하므로, 가장 안전하고 간단한 접근 방식입니다.",
    "SelectC": "DB 인스턴스를 퍼블릭 액세스가 가능하도록 설정하고, 퍼블릭 IP를 할당합니다.",
    "SelectC_Commentary": "DB를 직접 퍼블릭으로 노출하면 매우 위험하며, 공격 표면이 크게 넓어집니다.",
    "SelectD": "Elastic IP 주소를 가진 Amazon EC2 인스턴스를 VPC B에 추가로 실행하고, 모든 요청을 새 EC2 인스턴스 통해 프록시합니다.",
    "SelectD_Commentary": "프록시 서버를 두는 방식은 복잡도가 높고 보안 이점이 적어 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q327",
      "Q950",
      "Q980",
      "Q866",
      "Q19"
    ],
    "SelectA_recommedations": [
      "Q950",
      "Q19",
      "Q15"
    ],
    "SelectB_recommedations": [
      "Q803",
      "Q122",
      "Q510"
    ],
    "SelectC_recommedations": [
      "Q803",
      "Q893",
      "Q106"
    ],
    "SelectD_recommedations": [
      "Q231",
      "Q327",
      "Q610"
    ]
  },
  {
    "Question_Number": "Q232",
    "Question_Description": "한 회사가 고객에게 제공하는 시연 환경을 Amazon EC2 인스턴스에서 운영하고 있습니다. 각 환경은 자체 VPC로 격리되어 있습니다. 회사 운영팀은 어떤 환경에서 RDP나 SSH 액세스가 이루어졌을 때 알림을 받아야 합니다. 이에 대한 올바른 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95324-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "RDP나 SSH 액세스를 확인하려면 네트워크 트래픽을 모니터링하고 해당 이벤트 발생 시 알림을 설정해야 합니다. VPC Flow Logs를 CloudWatch Logs로 전송 후 지표 필터와 알람을 구성하면 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "RDP 접근",
      "SSH 접근",
      "VPC 격리",
      "운영팀 알림"
    ],
    "Terms": [
      "VPC Flow Logs",
      "Amazon CloudWatch Logs",
      "Amazon CloudWatch Metric Alarm",
      "EC2 Instance State-change Notification",
      "Amazon SNS",
      "IAM Instance Profile",
      "AmazonSSMManagedInstanceCore",
      "CloudWatch Application Insights"
    ],
    "SelectA": "Amazon CloudWatch Application Insights를 구성하여 RDP나 SSH 액세스가 감지될 때 AWS Systems Manager OpsItems를 생성하도록 설정합니다.",
    "SelectA_Commentary": "Application Insights는 애플리케이션 성능 모니터링에 초점이 있어 RDP/SSH 세션 알림에 직접 특화되지 않았습니다.",
    "SelectB": "AmazonSSMManagedInstanceCore 정책이 연결된 IAM 역할을 가진 IAM 인스턴스 프로파일을 EC2 인스턴스에 구성합니다.",
    "SelectB_Commentary": "이는 EC2 인스턴스 관리 및 명령 실행 권한에 대한 설정이므로, RDP나 SSH 세션이 열릴 때 알림을 보내기 위한 직접적인 해결책이 아닙니다.",
    "SelectC": "VPC Flow Logs를 Amazon CloudWatch Logs로 퍼블리싱합니다. 필요한 Metric Filter를 생성합니다. 그리고 ALARM 상태일 때 알림 동작이 설정된 Amazon CloudWatch Metric Alarm을 생성합니다.",
    "SelectC_Commentary": "VPC Flow Logs로 RDP·SSH 트래픽을 감지하고 지표 필터 및 알람을 이용해 운영팀에 즉시 알릴 수 있는 가장 적합한 솔루션입니다.",
    "SelectD": "EC2 Instance State-change Notification 타입 이벤트를 수신하는 Amazon EventBridge 룰을 구성합니다. Amazon SNS 토픽을 대상으로 지정하고, 운영팀을 구독시킵니다.",
    "SelectD_Commentary": "이는 인스턴스의 시작·중지 상태 변화만을 알릴 뿐, RDP/SSH 세션이 성립될 때를 감지·알림하지는 못합니다.",
    "Question_Description_recommedations": [
      "Q866",
      "Q92",
      "Q697",
      "Q91",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q232",
      "Q179",
      "Q723"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q96",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q950",
      "Q15"
    ],
    "SelectD_recommedations": [
      "Q364",
      "Q612",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q233",
    "Question_Description": "한 솔루션스 아키텍트가 새 AWS 계정을 생성했고, AWS account root user의 액세스를 안전하게 보호해야 합니다. 아래 제시된 조치 중 두 가지를 선택하십시오. (두 가지 선택)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95084-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS account root user 계정의 불법적 접근을 막기 위해 가장 기본적인 보안 설정을 묻습니다. root user 접근은 강력 비밀번호와 MFA 활성화로 보호해야 하며, IAM 사용자를 생성해 일상 업무에 사용하도록 권장합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "root user 보안",
      "강력한 비밀번호",
      "multi-factor authentication",
      "AWS 계정 보호"
    ],
    "Terms": [
      "AWS account root user",
      "multi-factor authentication(MFA)",
      "access key",
      "Amazon S3",
      "inline policy document"
    ],
    "SelectA": "root user가 복잡하고 강력한 비밀번호를 사용하도록 설정합니다.",
    "SelectA_Commentary": "root user의 비밀번호를 복잡하게 설정하면 계정 탈취 위험을 크게 줄여줘 필수적인 보안 조치입니다. (정답)",
    "SelectB": "root user에 multi-factor authentication(MFA)를 활성화합니다.",
    "SelectB_Commentary": "MFA를 사용하면 추가 인증 요소가 요구되어 보안이 한층 강화됩니다. (정답)",
    "SelectC": "root user access key를 암호화된 Amazon S3 버킷에 저장합니다.",
    "SelectC_Commentary": "root user access key 자체 사용을 지양해야 하며, 별도 보관보다는 IAM 권한 관리를 통해 접근 권한을 위임하는 것이 안전합니다.",
    "SelectD": "관리자 권한이 있는 그룹에 root user를 추가합니다.",
    "SelectD_Commentary": "root user는 이미 모든 권한을 가지고 있으므로 추가 권한 부여는 불필요하며 보안상 위험만 가중시킵니다.",
    "SelectE": "inline policy document를 통해 root user에 필요한 권한을 부여합니다.",
    "SelectE_Commentary": "root user에 별도 권한을 부여할 필요가 없으며, IAM 사용자에게 필요한 권한을 부여해 일상 업무를 수행하는 방식이 최선입니다.",
    "Question_Description_recommedations": [
      "Q745",
      "Q831",
      "Q313",
      "Q780",
      "Q922"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q122",
      "Q665"
    ],
    "SelectB_recommedations": [
      "Q797",
      "Q233",
      "Q745"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q825",
      "Q740"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q332",
      "Q825"
    ],
    "SelectE_recommedations": [
      "Q233",
      "Q423",
      "Q774"
    ]
  },
  {
    "Question_Number": "Q234",
    "Question_Description": "한 회사가 새로운 웹 기반 고객 관계 관리 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 Application Load Balancer(ALB) 뒤에서 Amazon EBS 볼륨을 사용하는 여러 Amazon EC2 인스턴스를 사용하고, Amazon Aurora 데이터베이스도 사용할 예정입니다. 이 애플리케이션의 모든 데이터는 저장 시(at rest)와 전송 시(in transit) 모두 암호화되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95325-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 데이터가 저장 시와 전송 시 모두 안전하게 보호되도록 구성하는 방법을 묻습니다. EBS와 Aurora에는 AWS KMS로 암호화를 적용하고, 전송 암호화는 ALB에 ACM 인증서를 적용해야 하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "EBS 암호화",
      "Aurora 암호화",
      "Application Load Balancer",
      "AWS KMS",
      "ACM",
      "전송 중 암호화"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Application Load Balancer (ALB)",
      "Amazon Aurora",
      "AWS Key Management Service (AWS KMS)",
      "AWS Certificate Manager (ACM)",
      "BitLocker",
      "TLS",
      "SSL"
    ],
    "SelectA": "AWS KMS 인증서를 ALB에 사용하여 전송 시 데이터를 암호화하고, AWS Certificate Manager(ACM)으로 EBS 볼륨과 Aurora 데이터베이스 스토리지를 저장 시 암호화합니다.",
    "SelectA_Commentary": "ACM은 주로 인증서 관리를 위한 서비스이며, EBS 암호화에는 적절하지 않습니다. 이 방법은 EBS 암호화 부분이 올바르지 않습니다.",
    "SelectB": "AWS root 계정으로 AWS Management Console에 로그인한 뒤, 회사의 암호화 인증서를 업로드하고, 루트 계정에서 전체 계정에 대해 저장 시와 전송 시 암호화를 활성화 옵션을 선택합니다.",
    "SelectB_Commentary": "루트 계정을 사용하는 것은 보안 모범 사례가 아니며, 계정 전체에 대한 일괄 암호화 활성화 옵션은 존재하지 않습니다.",
    "SelectC": "AWS Key Management Service(AWS KMS)를 사용하여 EBS 볼륨과 Aurora 데이터베이스 스토리지를 저장 시 암호화합니다. ALB에는 AWS Certificate Manager(ACM) 인증서를 연결하여 전송 시 데이터를 암호화합니다.",
    "SelectC_Commentary": "가장 적절한 방법으로, EBS와 Aurora는 KMS로 암호화하고, ALB에 ACM 인증서를 연결해 전송 데이터를 암호화하여 요구 사항을 충족합니다.",
    "SelectD": "BitLocker로 모든 데이터를 저장 시 암호화합니다. 회사의 TLS 인증서 키를 AWS KMS로 가져와 ALB에 연결하여 전송 시 데이터를 암호화합니다.",
    "SelectD_Commentary": "BitLocker는 주로 Windows 기반 운영체제용 암호화 도구이며, AWS EBS 및 Aurora 암호화 용도로 적합하지 않습니다. 인증서 키를 KMS에 직접 연결하여 ALB를 암호화하는 방식도 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q884",
      "Q977",
      "Q60",
      "Q801",
      "Q170"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ],
    "SelectB_recommedations": [
      "Q233",
      "Q745",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q681",
      "Q550"
    ]
  },
  {
    "Question_Number": "Q235",
    "Question_Description": "한 회사가 온프레미스 Oracle 데이터베이스를 Amazon Aurora PostgreSQL로 이전하려고 합니다. 이 데이터베이스에는 동일한 테이블에 데이터를 쓰는 여러 애플리케이션이 있으며, 각 애플리케이션은 한 달 간격으로 하나씩 마이그레이션해야 합니다. 경영진은 해당 데이터베이스가 읽기와 쓰기가 매우 빈번하다는 점에 우려를 표했습니다. 또한 마이그레이션 기간 동안 두 데이터베이스의 데이터는 동기화 상태를 유지해야 합니다. 솔루션스 아키텍트는 어떤 구성을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95326-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Oracle에서 Amazon Aurora PostgreSQL로 단계별 마이그레이션을 진행하면서, 대규모 읽기·쓰기가 발생하는 상황에서 두 데이터베이스 간 동기화 상태를 유지해야 하는 시나리오입니다. AWS Schema Conversion Tool로 스키마 변환을 수행하고, AWS DMS를 통해 full load 뒤 CDC 방식으로 변경 내용을 실시간 복제하면 두 DB를 지속적으로 동기화할 수 있습니다. 특히 memory optimized replication instance는 고빈도 트랜잭션 환경에서 빠른 복제를 지원하므로 대규모 I/O 처리에 유리합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "온프레미스 Oracle 데이터베이스",
      "Amazon Aurora PostgreSQL",
      "마이그레이션",
      "동기화 유지",
      "다수의 읽기·쓰기",
      "full load plus CDC",
      "memory optimized replication instance"
    ],
    "Terms": [
      "Oracle database",
      "Amazon Aurora PostgreSQL",
      "AWS DataSync",
      "AWS Database Migration Service (AWS DMS)",
      "AWS Schema Conversion Tool",
      "change data capture (CDC)",
      "memory optimized replication instance",
      "compute optimized replication instance",
      "full load"
    ],
    "SelectA": "초기 마이그레이션에 AWS DataSync를 사용하고, AWS DMS에서 change data capture(CDC) 복제 작업과 테이블 매핑을 생성해 모든 테이블을 선택합니다.",
    "SelectA_Commentary": "DataSync로 초기 파일 이동은 가능하지만, CDC만으로는 전체 스키마 변환이 부족합니다. 메모리 최적화 설정도 없어 트랜잭션 처리 부하가 큰 환경에는 적합하지 않습니다.",
    "SelectB": "초기 마이그레이션에 AWS DataSync를 사용하고, AWS DMS에서 full load plus CDC 복제 작업과 테이블 매핑을 생성해 모든 테이블을 선택합니다.",
    "SelectB_Commentary": "파일 기반 마이그레이션 후 full load plus CDC는 어느 정도 동기화를 지원하지만, 스키마 호환성 점검을 위한 AWS Schema Conversion Tool과 메모리 최적화 옵션이 없어 대규모 트랜잭션엔 비효율적입니다.",
    "SelectC": "AWS Schema Conversion Tool과 AWS DMS를 memory optimized replication instance로 구성합니다. 모든 테이블을 선택해 full load plus CDC 복제 작업을 생성합니다.",
    "SelectC_Commentary": "스키마 변환 후 full load plus CDC로 기존 DB와 새 DB를 동기화하며, 메모리 최적화 인스턴스를 사용해 대규모 읽기·쓰기 부하에서도 빠른 복제가 가능합니다.",
    "SelectD": "AWS Schema Conversion Tool과 AWS DMS를 compute optimized replication instance로 구성합니다. 가장 큰 테이블만 선택해 full load plus CDC 복제 작업을 생성합니다.",
    "SelectD_Commentary": "일부 테이블만 복제하면 전반적 동기화가 어려우며, compute optimized 인스턴스는 CPU 중심이어서 빈번한 읽기·쓰기 트랜잭션이 많은 환경에는 부적합합니다.",
    "Question_Description_recommedations": [
      "Q886",
      "Q192",
      "Q523",
      "Q472",
      "Q229"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q578",
      "Q33"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q361",
      "Q386"
    ],
    "SelectC_recommedations": [
      "Q386",
      "Q143",
      "Q776"
    ],
    "SelectD_recommedations": [
      "Q386",
      "Q143",
      "Q776"
    ]
  },
  {
    "Question_Number": "Q236",
    "Question_Description": "한 회사가 이미지 공유 용도의 3티어 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 프론트엔드 계층에 Amazon EC2 인스턴스, 애플리케이션 계층에 Amazon EC2 인스턴스, 그리고 MySQL 데이터베이스로 사용되는 또 다른 Amazon EC2 인스턴스로 구성되어 있습니다. 솔루션스 아키텍트는 최소한의 애플리케이션 수정으로도 확장 가능하고 고가용성을 갖춘 솔루션을 설계해야 합니다. 다음 중 어떤 솔루션이 이 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94990-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 Amazon EC2 기반 3티어 애플리케이션을 크게 수정하지 않고도 확장성과 고가용성을 확보해야 하는 시나리오입니다. Multi-AZ 배포와 Amazon RDS로 데이터베이스 인프라를 구성하거나, AWS Elastic Beanstalk로 계층을 운영함으로써 서비스 중단 위험을 줄이고 자동 확장을 지원할 수 있습니다. 정답은 최소한의 코드 변경으로 이러한 요구 사항을 만족하는 방안을 찾는 데 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "3티어 애플리케이션",
      "이미지 공유",
      "확장 가능",
      "고가용성",
      "애플리케이션 변경 최소화",
      "AWS Elastic Beanstalk",
      "Multi-AZ",
      "Amazon RDS"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon S3",
      "AWS Elastic Beanstalk",
      "Amazon RDS",
      "Multi-AZ",
      "read replica",
      "Auto Scaling group",
      "MySQL"
    ],
    "SelectA": "프론트엔드 계층을 Amazon S3에서 호스팅하고, 애플리케이션 계층은 AWS Lambda를 사용합니다. 데이터베이스는 Amazon DynamoDB 테이블로 이전하며, 사용자 이미지는 Amazon S3에 저장 및 제공하세요.",
    "SelectA_Commentary": "Lambda와 DynamoDB로 전환하면 기존 애플리케이션 로직을 대폭 수정해야 하며, MySQL에서 DynamoDB로의 마이그레이션도 부담이 큽니다. 최소 변경이라는 요구 사항에 부합하지 않습니다.",
    "SelectB": "프론트엔드 계층과 애플리케이션 계층을 로드 밸런싱된 Multi-AZ AWS Elastic Beanstalk 환경으로 구성합니다. 데이터베이스는 여러 read replica가 있는 Amazon RDS DB 인스턴스로 이전하여 사용자 이미지를 제공합니다.",
    "SelectB_Commentary": "AWS Elastic Beanstalk를 Multi-AZ로 배포해 애플리케이션 변경을 최소화하면서 자동 확장과 로드 밸런싱을 얻을 수 있습니다. 또한 Amazon RDS DB 인스턴스와 read replica를 활용해 확장성과 가용성을 높일 수 있어 가장 적은 코드 변경으로 목표를 달성하는 솔루션입니다.",
    "SelectC": "Amazon S3에서 프론트엔드 계층을 호스팅하고, 애플리케이션 계층은 Auto Scaling group에 속한 다수의 Amazon EC2 인스턴스를 사용합니다. 데이터베이스는 메모리 최적화된 인스턴스 유형으로 이전하여 사용자 이미지를 저장하고 제공합니다.",
    "SelectC_Commentary": "S3 정적 호스팅으로 프론트엔드 변경이 필요하고, DB 층도 단순히 인스턴스 사양만 변경하기 때문에 고가용성이나 Multi-AZ 구성 측면에서 다소 부족합니다. 기존 애플리케이션 흐름 변경도 필요합니다.",
    "SelectD": "프론트엔드 계층과 애플리케이션 계층을 로드 밸런싱된 Multi-AZ AWS Elastic Beanstalk 환경으로 구성합니다. 데이터베이스는 Amazon RDS Multi-AZ DB 인스턴스로 이전하고, 사용자 이미지는 Amazon S3에 저장 및 제공하세요.",
    "SelectD_Commentary": "Multi-AZ와 S3를 활용해 안정적이고 빠른 이미지 제공이 가능하지만, 기존 MySQL에 이미지를 저장했던 방식을 S3로 옮기려면 추가적인 애플리케이션 코드 변경이 필요해 요구 사항인 ‘최소 변경’에 약간 더 벗어납니다.",
    "Question_Description_recommedations": [
      "Q110",
      "Q114",
      "Q194",
      "Q824",
      "Q252"
    ],
    "SelectA_recommedations": [
      "Q768",
      "Q490",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q958",
      "Q518",
      "Q390"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q390",
      "Q236",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q237",
    "Question_Description": "Amazon EC2 인스턴스가 위치한 VPC-A에서 다른 AWS 계정의 VPC-B에 있는 EC2 인스턴스에 접근해야 합니다. 두 VPC는 각각 별도의 AWS 계정에 있으며, 보안 방식으로 접근을 구성해야 하고, 단일 장애 지점이나 대역폭 문제가 없어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95144-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 AWS 계정에 있는 두 VPC 간 안전하고 고가용성의 네트워크 연결 방안을 묻습니다. VPC Peering은 별도 하드웨어가 필요 없고 단일 장애 지점이 없는 연결 방식이므로, 고가용성과 대역폭 우려 없이 직접 통신이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "VPC 피어링",
      "EC2 인스턴스 간 접근",
      "단일 장애 지점 방지",
      "AWS 계정 간 네트워크"
    ],
    "Terms": [
      "VPC Peering",
      "VPC Gateway Endpoint",
      "Virtual Private Gateway",
      "Private Virtual Interface (VIF)"
    ],
    "SelectA": "VPC-A와 VPC-B 간에 VPC Peering Connection을 설정합니다.",
    "SelectA_Commentary": "정답입니다. VPC Peering은 별도의 게이트웨이나 물리적 연결 없이 양방향 통신이 가능하고, 단일 장애 지점이 없어 대역폭 병목이나 가용성 문제를 최소화합니다.",
    "SelectB": "VPC-B의 EC2 인스턴스에 대해 VPC Gateway Endpoint를 설정합니다.",
    "SelectB_Commentary": "Gateway Endpoint는 S3 또는 DynamoDB와 같은 특정 AWS 서비스로의 전용 경로를 구성하기 위한 것입니다. VPC 간 직접 통신 용도로는 적합하지 않습니다.",
    "SelectC": "VPC-B에 Virtual Private Gateway를 연결하고 VPC-A에서 라우팅을 설정합니다.",
    "SelectC_Commentary": "Virtual Private Gateway는 온프레미스 VPN 연결 등의 시나리오에 적합합니다. 별도 VPN 터널이 필요하며 설정이 복잡해지고, 단일 장애 지점 없이 연결하기엔 VPC Peering보다 비효율적입니다.",
    "SelectD": "VPC-B의 EC2 인스턴스를 위한 Private Virtual Interface를 생성하고, VPC-A에서 적절한 라우트를 추가합니다.",
    "SelectD_Commentary": "Private VIF는 AWS Direct Connect를 통해 온프레미스와 VPC를 연결할 때 주로 사용됩니다. VPC 간 네트워크 통신을 단순화하기 위해서는 VPC Peering이 더 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q504",
      "Q439",
      "Q312",
      "Q892",
      "Q639"
    ],
    "SelectA_recommedations": [
      "Q237",
      "Q448",
      "Q439"
    ],
    "SelectB_recommedations": [
      "Q237",
      "Q504",
      "Q439"
    ],
    "SelectC_recommedations": [
      "Q237",
      "Q504",
      "Q439"
    ],
    "SelectD_recommedations": [
      "Q237",
      "Q439",
      "Q504"
    ]
  },
  {
    "Question_Number": "Q238",
    "Question_Description": "한 회사는 엔지니어 팀을 위해 개별 AWS 계정을 실험적으로 사용하려 합니다. 회사는 특정 달에 각 계정의 Amazon EC2 인스턴스 사용량이 특정 임계값을 초과하면 즉시 알림을 받고 싶어 합니다. 가장 비용 효율적인 방법은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "각 계정별로 EC2 사용 비용이 월간 임계값을 초과할 경우 즉시 알림을 보내는 요구사항입니다. AWS Budgets를 활용하면 각 계정별로 쉽게 비용 한도를 설정하고 알림을 보낼 수 있어 추가 리소스가 필요 없어 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "엔지니어 개별 계정",
      "Amazon EC2",
      "월별 사용량 임계값",
      "비용 초과 알림",
      "가장 비용 효율적"
    ],
    "Terms": [
      "Cost Explorer",
      "Amazon Simple Email Service (Amazon SES)",
      "AWS Budgets",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Cost and Usage Reports",
      "Amazon Athena",
      "Amazon EventBridge"
    ],
    "SelectA": "Cost Explorer를 사용하여 서비스별 일간 비용 보고서를 생성하고, EC2 인스턴스만 필터링합니다. 임계값 초과 시 Amazon SES 알림을 설정합니다.",
    "SelectA_Commentary": "일간 비용 보고서 활용은 가능하나, 자동화된 예산 관리 기능이 없어 알림 설정과 모니터링 면에서 부담이 클 수 있습니다.",
    "SelectB": "Cost Explorer를 사용하여 서비스별 월간 비용 보고서를 생성하고, EC2 인스턴스만 필터링합니다. 임계값 초과 시 Amazon SES 알림을 설정합니다.",
    "SelectB_Commentary": "월간 보고서이지만 예산 기능이 아닌 단순 보고서로, 임계값 알림 비용 관리에 대한 자동화나 세밀한 제어가 부족합니다.",
    "SelectC": "AWS Budgets를 사용하여 각 계정별로 cost budget을 생성하고, 기간을 월별로 설정합니다. EC2 인스턴스만 대상으로 설정하고 알림 임계값을 지정합니다. 임계값 초과 시 Amazon SNS 토픽으로 알림을 전송하도록 구성합니다.",
    "SelectC_Commentary": "AWS Budgets는 개별 계정의 월별 EC2 사용량 모니터링을 자동화하고, 임계값 초과 시 즉시 SNS를 통해 알림을 보내기 때문에 가장 비용 효율적이고 간단한 방법입니다.",
    "SelectD": "AWS Cost and Usage Reports를 사용해 시간 단위 보고서를 생성하고 Amazon Athena로 통합합니다. Amazon EventBridge를 이용해 Athena 쿼리를 스케줄링하고, 임계값 초과 시 Amazon SNS로 알림을 전송합니다.",
    "SelectD_Commentary": "Athena와 EventBridge 등 여러 서비스를 연동해야 하므로 추가 비용 및 복잡도가 증가하여, 가장 비용 효율적이지는 않습니다.",
    "Question_Description_recommedations": [
      "Q671",
      "Q167",
      "Q993",
      "Q552",
      "Q347"
    ],
    "SelectA_recommedations": [
      "Q459",
      "Q552",
      "Q662"
    ],
    "SelectB_recommedations": [
      "Q459",
      "Q552",
      "Q662"
    ],
    "SelectC_recommedations": [
      "Q543",
      "Q459",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q641",
      "Q31",
      "Q880"
    ]
  },
  {
    "Question_Number": "Q239",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 애플리케이션을 위한 새로운 마이크로서비스를 설계해야 합니다. 클라이언트는 HTTPS 엔드포인트를 통해 마이크로서비스에 접근할 수 있어야 하며, 이 마이크로서비스는 호출을 인증하기 위해 AWS Identity and Access Management(IAM)을 사용해야 합니다. 솔루션스 아키텍트는 Go 1.x로 작성된 단일 AWS Lambda 함수를 이용하여 이 마이크로서비스 로직을 작성하려고 합니다. 이 함수를 가장 운영 효율적으로 배포할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95365-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HTTPS 엔드포인트가 필요하고, AWS IAM을 통한 인증이 필수적인 마이크로서비스를 운영 효율적으로 배포하는 방법을 묻습니다. API Gateway REST API를 사용하면 HTTPS 엔드포인트와 IAM 인증 설정을 손쉽게 통합하여 운영 복잡도를 줄이고 추가 기능(캐싱, 모니터링 등)까지 활용할 수 있어 효율적입니다. 다른 옵션들은 추가 구성 또는 별도의 배포 단계가 필요해 운영 편의성이 떨어지거나 IAM 인증을 직접 구현해야 하는 부담이 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "마이크로서비스",
      "HTTPS 엔드포인트",
      "AWS IAM",
      "Lambda 함수"
    ],
    "Terms": [
      "Amazon API Gateway",
      "Lambda function URL",
      "IAM 인증",
      "Amazon CloudFront",
      "Lambda@Edge",
      "CloudFront Functions"
    ],
    "SelectA": "Amazon API Gateway REST API를 생성합니다. 메서드를 이 Lambda 함수로 연동합니다. 그리고 API에 대해 IAM 인증을 활성화합니다.",
    "SelectA_Commentary": "API Gateway를 사용하면 HTTPS 엔드포인트를 쉽게 제공하고, IAM 인증 연동도 간편하게 적용할 수 있어 운영 복잡도를 크게 줄일 수 있는 최적의 솔루션입니다.",
    "SelectB": "해당 함수에 대해 Lambda function URL을 생성합니다. 인증 타입으로 AWS_IAM을 지정합니다.",
    "SelectB_Commentary": "Lambda function URL은 간편한 옵션이나, API Gateway 기능(캐싱, 모니터링 등)을 활용하기 어려워 추가 기능 제공 측면에서 다소 제한적입니다.",
    "SelectC": "Amazon CloudFront 배포를 생성하고, 마이크로서비스 로직을 Lambda@Edge에 배포합니다. Lambda@Edge 함수 내부에 IAM 인증 로직을 통합합니다.",
    "SelectC_Commentary": "Lambda@Edge를 사용할 경우 CloudFront를 중간에 두어야 하므로 구성 복잡도가 올라가고, IAM 인증 로직 역시 직접 구현해야 하여 운영 효율이 떨어집니다.",
    "SelectD": "Amazon CloudFront 배포를 생성하고, 함수를 CloudFront Functions로 배포합니다. 인증 타입으로 AWS_IAM을 지정합니다.",
    "SelectD_Commentary": "CloudFront Functions는 Edge에서 가벼운 작업 수행에 초점을 두며, IAM 통합이나 API 엔드포인트로서의 기능이 제약되어 운영면에서 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q222",
      "Q403",
      "Q871",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q159",
      "Q1019",
      "Q428"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q403",
      "Q936"
    ],
    "SelectC_recommedations": [
      "Q403",
      "Q936",
      "Q159"
    ],
    "SelectD_recommedations": [
      "Q172",
      "Q291",
      "Q165"
    ]
  },
  {
    "Question_Number": "Q240",
    "Question_Description": "한 회사는 이전에 데이터 웨어하우스 솔루션을 AWS로 마이그레이션했습니다. 이 회사는 AWS Direct Connect도 보유하고 있습니다. 본사 사용자는 시각화 도구를 통해 데이터 웨어하우스를 쿼리합니다. 데이터 웨어하우스에서 반환되는 쿼리 결과의 평균 크기는 50MB이며, 시각화 도구가 전송하는 각 웹페이지는 약 500KB입니다. 데이터 웨어하우스가 반환하는 결과 세트는 캐싱되지 않습니다. 이 회사에 가장 낮은 데이터 전송(egress) 비용을 제공하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/94998-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "대규모 쿼리 결과(50MB)는 AWS 내부 트래픽으로 처리하고, 외부로 나가는 트래픽을 최소화해야 egress 비용을 줄일 수 있습니다. 시각화 도구와 데이터 웨어하우스를 동일 리전에 두고, Direct Connect를 사용하면 웹페이지 크기만큼만 외부로 전송되어 가장 낮은 비용을 달성합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 웨어하우스",
      "AWS Direct Connect",
      "시각화 도구",
      "데이터 전송 비용",
      "동일 리전",
      "최소 egress 비용"
    ],
    "Terms": [
      "AWS Direct Connect",
      "On premises",
      "Data warehouse",
      "Visualization tool",
      "Internet egress",
      "AWS Region",
      "Egress cost"
    ],
    "SelectA": "시각화 도구를 온프레미스에 배포하고, 인터넷을 통해 직접 데이터 웨어하우스를 쿼리합니다.",
    "SelectA_Commentary": "50MB 쿼리 결과가 인터넷으로 매번 전송되어 egress 비용이 매우 높아집니다.",
    "SelectB": "시각화 도구를 데이터 웨어하우스와 동일한 AWS Region에 배포하고, 인터넷으로 접속합니다.",
    "SelectB_Commentary": "같은 리전에 있지만 인터넷을 통해 결과를 가져오므로 여전히 데이터 전송 egress 비용이 발생합니다.",
    "SelectC": "시각화 도구를 온프레미스에 배포하고, 같은 AWS Region에 있는 Direct Connect 연결을 사용해 데이터 웨어하우스를 쿼리합니다.",
    "SelectC_Commentary": "쿼리 결과(50MB)를 온프레미스로 전송하므로 egress 비용이 크게 발생합니다.",
    "SelectD": "시각화 도구를 데이터 웨어하우스와 동일한 AWS Region에 배포하고, 동일 리전의 Direct Connect 위치를 통해 접속합니다.",
    "SelectD_Commentary": "큰 쿼리 결과는 내부 트래픽으로 처리되고, 외부로는 웹페이지(500KB)만 전송되어 egress 비용이 최소화됩니다.",
    "Question_Description_recommedations": [
      "Q499",
      "Q205",
      "Q835",
      "Q541",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q485",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q728",
      "Q284",
      "Q499"
    ],
    "SelectD_recommedations": [
      "Q728",
      "Q284",
      "Q240"
    ]
  },
  {
    "Question_Number": "Q241",
    "Question_Description": "한 온라인 학습 회사가 AWS Cloud로 마이그레이션을 진행하려고 합니다. 해당 회사는 학생 기록을 PostgreSQL 데이터베이스에 보관하고 있으며, 여러 AWS Region에 걸쳐 데이터가 항상 온라인 상태로 유지되어야 합니다. 또한 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95000-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS Region에서 동시 가용성을 보장하고 운영 오버헤드를 최소화하는 RDS 구성을 찾는 것입니다. Multi-AZ는 동일 리전 내 고가용성일 뿐 다중 리전 가용성을 보장하지 않습니다. Cross-Region Read Replica를 활용하면 별도 Region에 대한 읽기 복제를 통해 데이터를 항상 온라인 상태로 유지할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "다중 리전",
      "항상 온라인",
      "운영 오버헤드 최소화",
      "Amazon RDS for PostgreSQL",
      "Read Replica"
    ],
    "Terms": [
      "PostgreSQL",
      "AWS Cloud",
      "Amazon RDS for PostgreSQL",
      "Multi-AZ",
      "read replica",
      "DB snapshot",
      "Amazon EC2",
      "운영 오버헤드"
    ],
    "SelectA": "Amazon EC2 인스턴스에서 PostgreSQL 클러스터를 운영합니다.",
    "SelectA_Commentary": "EC2 기반 클러스터 구성은 직접 서버와 복제를 관리해야 하므로 운영 오버헤드가 커집니다.",
    "SelectB": "Amazon RDS for PostgreSQL에서 Multi-AZ 기능을 활성화합니다.",
    "SelectB_Commentary": "Multi-AZ는 동일 리전 내에서만 장애 조치가 가능하므로 다중 리전 가용성을 제공하지 못합니다.",
    "SelectC": "Amazon RDS for PostgreSQL 인스턴스로 마이그레이션 후 다른 Region에 Read Replica를 생성합니다.",
    "SelectC_Commentary": "Cross-Region Read Replica를 통해 다른 Region에서도 읽기 트래픽을 처리하고, 실시간에 가까운 복제를 유지하므로 다중 리전 가용성과 낮은 운영 오버헤드를 달성합니다.",
    "SelectD": "Amazon RDS for PostgreSQL 인스턴스로 마이그레이션 후 다른 Region으로 DB 스냅샷을 복사합니다.",
    "SelectD_Commentary": "스냅샷은 주기적 백업이므로 실시간 동기화가 불가능하고, 다중 Region에서 즉각적인 온라인 가용성을 만족시키지 못합니다.",
    "Question_Description_recommedations": [
      "Q843",
      "Q879",
      "Q683",
      "Q1014",
      "Q513"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q236",
      "Q768"
    ],
    "SelectB_recommedations": [
      "Q958",
      "Q601",
      "Q464"
    ],
    "SelectC_recommedations": [
      "Q178",
      "Q601",
      "Q241"
    ],
    "SelectD_recommedations": [
      "Q601",
      "Q178",
      "Q241"
    ]
  },
  {
    "Question_Number": "Q242",
    "Question_Description": "한 회사가 AWS에서 7개의 Amazon EC2 인스턴스로 웹 애플리케이션을 호스팅하고 있습니다. 이 회사는 DNS query에 대해 모든 healthy Amazon EC2 인스턴스의 IP 주소가 반환되길 요구합니다. 어떤 Routing Policy를 사용해야 이 요구사항을 충족할 수 있습니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95001-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DNS query에 대해 여러 개의 healthy Amazon EC2 인스턴스 IP 주소를 동시에 반환하는 방법을 묻습니다. Multivalue routing policy는 여러 IP 주소를 무작위 순서로 반환하여 트래픽을 분산시키므로, 고가용성과 분산이 필요한 시나리오에 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DNS query",
      "IP 주소 반환",
      "Amazon EC2",
      "healthy 인스턴스",
      "Multivalue routing policy"
    ],
    "Terms": [
      "Amazon Route 53",
      "Multivalue routing policy",
      "Simple routing policy",
      "Latency routing policy",
      "Geolocation routing policy",
      "DNS",
      "EC2 instances",
      "IP addresses"
    ],
    "SelectA": "Simple routing policy",
    "SelectA_Commentary": "단일 IP 주소만 반환하므로 모든 healthy 인스턴스 IP 주소를 같이 제공하지 못해 조건에 부합하지 않습니다.",
    "SelectB": "Latency routing policy",
    "SelectB_Commentary": "지연 시간이 가장 낮은 리전을 기반으로 라우팅하며, 모든 IP 주소를 반환한다는 요구사항과는 맞지 않습니다.",
    "SelectC": "Multivalue routing policy",
    "SelectC_Commentary": "여러 IP 주소를 동시에 반환하며, healthy 상태만 확인해 자동 분산이 가능해 요구사항에 가장 적합합니다.",
    "SelectD": "Geolocation routing policy",
    "SelectD_Commentary": "사용자의 지리적 위치를 기반으로 라우팅하며, 모든 healthy 인스턴스의 IP 주소를 반환하려는 목적과 다릅니다.",
    "Question_Description_recommedations": [
      "Q264",
      "Q456",
      "Q312",
      "Q224",
      "Q67"
    ],
    "SelectA_recommedations": [
      "Q58",
      "Q187",
      "Q491"
    ],
    "SelectB_recommedations": [
      "Q58",
      "Q491",
      "Q917"
    ],
    "SelectC_recommedations": [
      "Q58",
      "Q491",
      "Q187"
    ],
    "SelectD_recommedations": [
      "Q58",
      "Q567",
      "Q491"
    ]
  },
  {
    "Question_Number": "Q243",
    "Question_Description": "한 의료 연구소에서 새로운 연구와 관련된 데이터를 생성합니다. 연구소는 전국에 위치한 온프레미스 파일 기반 애플리케이션을 사용하는 여러 클리닉에게 최소 지연으로 데이터를 제공하고자 합니다. 데이터 파일은 각 클리닉에 대해 read-only 권한이 부여된 Amazon S3 버킷에 저장되어 있습니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 추천해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95002-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전국적으로 분산된 클리닉에서 S3 데이터를 파일 형태로 최소 지연으로 이용하고자 할 때, 어떤 AWS 서비스를 사용해 효율적인 액세스를 제공할 수 있는지를 묻습니다. File Gateway를 사용하면 온프레미스에 가상 어플라이언스를 배포하여 장비와 S3 간의 통신을 투명하게 처리하므로, 클리닉들은 파일 기반 애플리케이션 환경에서 간편하고 빠르게 데이터를 읽을 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "의료 연구소",
      "최소 지연",
      "Amazon S3",
      "온프레미스 파일 기반 애플리케이션",
      "read-only 권한"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "File Gateway",
      "Volume Gateway",
      "AWS DataSync",
      "Amazon EFS",
      "Amazon S3"
    ],
    "SelectA": "각 클리닉의 온프레미스 환경에 AWS Storage Gateway file gateway를 가상 머신(VM)으로 배포합니다.",
    "SelectA_Commentary": "AWS Storage Gateway file gateway를 배포하면 S3 버킷의 파일을 온프레미스에 캐싱하여 빠르고 간편하게 접근할 수 있어 최소 지연을 달성하고 read-only 설정을 유지하기 쉽습니다.",
    "SelectB": "AWS DataSync를 사용하여 파일을 각 클리닉의 온프레미스 애플리케이션으로 마이그레이션합니다.",
    "SelectB_Commentary": "DataSync는 대용량 데이터를 신속하게 옮기는 데 유용하지만, 지속적으로 파일 기반 접근을 해야 하는 이 상황에서는 매번 데이터를 옮겨야 하므로 관리가 복잡해집니다.",
    "SelectC": "각 클리닉의 온프레미스 환경에 AWS Storage Gateway volume gateway를 가상 머신(VM)으로 배포합니다.",
    "SelectC_Commentary": "Volume Gateway는 블록 스토리지 기반으로 동작하므로 파일 기반 애플리케이션과의 직접 연동에 적합하지 않아 요구사항에 부적절합니다.",
    "SelectD": "각 클리닉의 온프레미스 서버에 Amazon Elastic File System(Amazon EFS) 파일 시스템을 연결합니다.",
    "SelectD_Commentary": "EFS는 주로 VPC 내에서 사용하며, 온프레미스 환경에서의 직접 연결 시 VPN 등 추가 구성이 필요하여 지연과 구현 복잡도가 증가할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q501",
      "Q43",
      "Q173",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q957",
      "Q361",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q361",
      "Q472"
    ],
    "SelectC_recommedations": [
      "Q957",
      "Q686",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q695",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q244",
    "Question_Description": "회사는 단일 Amazon EC2 인스턴스에서 웹 서버와 데이터베이스 소프트웨어를 모두 구동하는 콘텐츠 관리 시스템을 사용 중입니다. 이 회사는 웹사이트 플랫폼을 고가용성으로 구성해야 하며, 사용자 수요에 맞춰 확장 가능하게 만들어야 합니다. 이를 위해 솔루션스 아키텍트는 어떤 구성을 제안해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95336-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 EC2 인스턴스에 웹 서버와 DB를 동시 운영 중인 환경을 고가용성과 확장성 있는 구조로 전환하는 요구사항입니다. DB를 Aurora로 분리하고, 다중 AZ에서 ALB와 Auto Scaling을 구성해 장애나 트래픽 증가에도 유연히 대응해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "확장성",
      "Aurora",
      "AMI",
      "Auto Scaling",
      "ALB"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon Aurora",
      "Read Replica",
      "Amazon Machine Image (AMI)",
      "Application Load Balancer (ALB)",
      "Auto Scaling group",
      "Amazon S3"
    ],
    "SelectA": "데이터베이스를 Amazon RDS로 이전하고 자동 백업을 활성화합니다. 동일한 가용 영역에 수동으로 다른 EC2 인스턴스를 생성합니다. Application Load Balancer를 구성하고 두 인스턴스를 대상으로 설정합니다.",
    "SelectA_Commentary": "하나의 AZ만 사용해 가용성 측면에서 부족하며, 확장 시에도 다중 AZ 구성이 없어 고가용성을 충분히 달성하기 어렵습니다.",
    "SelectB": "데이터베이스를 Amazon Aurora 인스턴스로 마이그레이션하고, 기존 EC2 인스턴스와 동일한 가용 영역에 리드 레플리카를 둡니다. 동일한 가용 영역에 수동으로 다른 EC2 인스턴스를 생성합니다. Application Load Balancer를 구성하고 두 EC2 인스턴스를 대상으로 설정합니다.",
    "SelectB_Commentary": "DB를 Aurora로 이전하더라도 같은 AZ에만 리드 레플리카를 두면 고가용성을 확보하기 어렵고, EC2 확장 역시 수동으로 관리해야 하므로 요구사항을 완벽히 충족하지 못합니다.",
    "SelectC": "데이터베이스를 Amazon Aurora로 이전하고, 다른 가용 영역에 리드 레플리카를 둡니다. 기존 EC2 인스턴스로부터 Amazon Machine Image(AMI)를 생성합니다. 두 개의 가용 영역에 Application Load Balancer를 구성합니다. 이 AMI를 사용하는 Auto Scaling group을 두 개의 AZ에 걸쳐 배치합니다.",
    "SelectC_Commentary": "DB를 다중 AZ Aurora 배포로 구성해 장애 대응력이 높아지고, ALB와 Auto Scaling group으로 웹 서버 레이어도 자동화하며 트래픽 변화에 유연하게 대응 가능합니다. 고가용성과 확장성 요구사항을 모두 충족하므로 정답입니다.",
    "SelectD": "별도의 EC2 인스턴스에 데이터베이스를 이전하고, Amazon S3로 백업을 스케줄링합니다. 기존 EC2 인스턴스로부터 Amazon Machine Image(AMI)를 생성합니다. 두 개의 가용 영역에 Application Load Balancer를 구성합니다. 이 AMI를 사용하는 Auto Scaling group을 두 개의 AZ에 걸쳐 배치합니다.",
    "SelectD_Commentary": "DB를 여전히 EC2에 직접 운영하고 있으므로 전문 DB 관리 서비스인 RDS나 Aurora 대비 관리 부담이 크고 확장성도 낮습니다. 고가용성을 위한 다중 AZ Aurora 구성보다 부족합니다.",
    "Question_Description_recommedations": [
      "Q757",
      "Q584",
      "Q252",
      "Q413",
      "Q790"
    ],
    "SelectA_recommedations": [
      "Q195",
      "Q67",
      "Q298"
    ],
    "SelectB_recommedations": [
      "Q217",
      "Q69",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q69",
      "Q217",
      "Q955"
    ],
    "SelectD_recommedations": [
      "Q405",
      "Q275",
      "Q390"
    ]
  },
  {
    "Question_Number": "Q245",
    "Question_Description": "한 회사가 AWS에서 애플리케이션을 출시하려고 합니다. 이 애플리케이션은 Application Load Balancer(ALB)를 사용하여 단일 target group에 있는 최소 두 개의 Amazon EC2 인스턴스로 트래픽을 라우팅합니다. 인스턴스들은 각각의 환경에 대해 Auto Scaling group에 속해 있습니다. 회사는 개발 환경과 프로덕션 환경이 필요합니다. 프로덕션 환경은 높은 트래픽이 발생하는 기간이 있을 예정입니다. 개발 환경을 가장 비용 효율적으로 구성하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95337-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "비용을 절감하면서도 개발 환경의 기능을 유지하려면, 개발 환경의 Auto Scaling group에서 인스턴스 사용량을 줄여 필요한 최소 규모만 유지하는 것이 핵심입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "개발 환경",
      "프로덕션 환경",
      "비용 효율",
      "Application Load Balancer",
      "Amazon EC2",
      "Auto Scaling group"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Auto Scaling group",
      "target group"
    ],
    "SelectA": "개발 환경의 target group을 재구성하여 하나의 Amazon EC2 인스턴스만 target으로 지정합니다.",
    "SelectA_Commentary": "최소 두 개 인스턴스를 사용하는 구조 요구사항을 침해할 수 있고, 장애 허용력을 낮추기 때문에 권장되지 않습니다.",
    "SelectB": "ALB 로드 밸런싱 알고리즘을 'least outstanding requests'로 변경합니다.",
    "SelectB_Commentary": "로드 밸런싱 알고리즘을 변경해도 인스턴스 비용이 크게 줄지 않아 비용 최적화 효과가 미미합니다.",
    "SelectC": "두 환경 모두에서 Amazon EC2 인스턴스의 크기를 줄입니다.",
    "SelectC_Commentary": "프로덕션 환경에도 영향을 주어 성능 저하 우려가 있어, 확대 트래픽을 감당하기 어려울 수 있습니다.",
    "SelectD": "개발 환경의 Auto Scaling group에서 최대 Amazon EC2 인스턴스 수를 줄입니다.",
    "SelectD_Commentary": "개발 환경은 낮은 트래픽을 예상하므로, 인스턴스 수를 제한해 불필요한 비용을 절감하며 필요한 기능은 유지할 수 있는 가장 효과적인 방법입니다.",
    "Question_Description_recommedations": [
      "Q984",
      "Q473",
      "Q894",
      "Q441",
      "Q290"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q943",
      "Q238"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q728",
      "Q767"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q290",
      "Q937",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q246",
    "Question_Description": "한 회사가 여러 가용 영역(Availability Zone)에 있는 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있습니다. 이 EC2 인스턴스들은 사설 서브넷에 위치해 있습니다. 솔루션스 아키텍트가 인터넷 연결형(Application Load Balancer, ALB)을 구현하고, 대상 그룹으로 해당 EC2 인스턴스들을 지정했지만 인터넷에서 들어오는 트래픽이 EC2 인스턴스에 도달하지 않습니다. 이러한 문제를 해결하기 위해 아키텍처를 어떻게 재구성해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95003-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB를 인터넷에서 직접 연결하기 위해, ALB가 위치한 서브넷이 인터넷 게이트웨이에 연결된 공용 서브넷이어야 함을 묻고 있습니다. EC2 인스턴스는 사설 서브넷에 위치하고, ALB가 공용 서브넷에서 인터넷 트래픽을 수신하여 사설 서브넷의 인스턴스로 전달해야 동작합니다. 따라서 ALB를 공용 서브넷에 배치하고 사설 서브넷과의 로컬 라우팅을 통해 트래픽을 전달하는 구성이 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "인터넷 연결형 ALB",
      "사설 서브넷",
      "공용 서브넷",
      "라우팅",
      "보안 그룹"
    ],
    "Terms": [
      "Internet-facing Application Load Balancer(ALB)",
      "Amazon EC2",
      "NAT gateway",
      "Network Load Balancer(NLB)",
      "Security Group",
      "Subnet",
      "Internet Gateway(IGW)",
      "Route Table"
    ],
    "SelectA": "ALB를 Network Load Balancer로 교체하고, 공용 서브넷에 NAT gateway를 구성하여 인터넷 트래픽을 허용합니다.",
    "SelectA_Commentary": "NAT gateway는 인스턴스가 인터넷에 나가는 용도로 사용하며, 수신 트래픽을 허용하는 역할에는 적합하지 않아 문제 해결에 맞지 않습니다.",
    "SelectB": "EC2 인스턴스들을 공용 서브넷으로 이동하고, EC2 인스턴스들의 보안 그룹에 0.0.0.0/0으로의 아웃바운드 트래픽 허용 규칙을 추가합니다.",
    "SelectB_Commentary": "인스턴스를 공용 서브넷으로 직접 노출하면 보안 위험이 커지고, ALB를 통한 트래픽 분산 이점이 줄어듭니다.",
    "SelectC": "EC2 인스턴스들이 있는 서브넷의 라우트 테이블을 수정하여 0.0.0.0/0 트래픽을 인터넷 게이트웨이로 보내고, 보안 그룹에 0.0.0.0/0 아웃바운드 트래픽 허용 규칙을 추가합니다.",
    "SelectC_Commentary": "사설 서브넷에서 직접 인터넷 게이트웨이로 라우팅하면 결국 공용 서브넷처럼 되어버려 사설 서브넷의 이점을 잃습니다.",
    "SelectD": "각 가용 영역마다 공용 서브넷을 생성하고, 해당 서브넷들을 ALB에 매핑합니다. 공용 서브넷의 라우트 테이블을 사설 서브넷으로 라우팅하도록 업데이트합니다.",
    "SelectD_Commentary": "인터넷 연결형 ALB는 공용 서브넷에서 동작해야 하며, 사설 서브넷에 있는 EC2 인스턴스까지 로컬 라우팅으로 연결해 주는 구조가 올바른 해결책입니다.",
    "Question_Description_recommedations": [
      "Q639",
      "Q174",
      "Q333",
      "Q5",
      "Q275"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q405",
      "Q174"
    ],
    "SelectB_recommedations": [
      "Q584",
      "Q244",
      "Q757"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q244",
      "Q757"
    ],
    "SelectD_recommedations": [
      "Q917",
      "Q187",
      "Q58"
    ]
  },
  {
    "Question_Number": "Q247",
    "Question_Description": "한 회사가 Amazon RDS for MySQL에 데이터베이스를 배포했습니다. 거래량 증가로 인해 DB 인스턴스에서 읽기 응답이 지연되고 있으며, 데이터베이스 지원 팀은 성능 개선을 위해 Read Replica 추가를 권장하고 있습니다. 이 변경을 구현하기 전에 솔루션스 아키텍트가 취해야 할 조치로 옳은 조합은 무엇일까요? (두 개를 선택하십시오.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95004-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL에서 읽기 성능을 확장하기 위해 Read Replica를 설정하기 전에 필요한 조건들을 묻습니다. Read Replica는 MySQL 엔진의 복제(binlog)를 사용하여 데이터를 복제하므로 소스 인스턴스에서 binlog를 활성화해야 합니다. 또한 Read Replica 생성을 위해서는 백업 유지를 위해 Backup Retention Period가 0이 아닌 값으로 설정되어 있어야 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "Read Replica",
      "자동 백업",
      "binlog replication",
      "backup retention"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Read replica",
      "자동 백업(Backup Retention)",
      "binlog replication",
      "소스 DB 인스턴스",
      "장기 실행 트랜잭션"
    ],
    "SelectA": "RDS 기본 노드에서 binlog replication을 활성화합니다.",
    "SelectA_Commentary": "MySQL의 읽기 복제는 binlog를 사용하므로 소스 DB 인스턴스에서 binlog가 활성화되어 있어야 Read Replica 생성이 가능합니다.",
    "SelectB": "소스 DB 인스턴스에 대해 장애 조치 우선순위를 지정합니다.",
    "SelectB_Commentary": "Multi-AZ 배포에서 장애 조치(Failover)를 제어하는 옵션이며, Read Replica 구성과 직접적인 연관은 없습니다.",
    "SelectC": "소스 DB 인스턴스에서 장기 실행 트랜잭션이 완료되도록 합니다.",
    "SelectC_Commentary": "장기 실행 트랜잭션이 종료되면 성능에 유리할 수 있지만, Read Replica 생성을 위해 반드시 필요한 사전 조건은 아닙니다.",
    "SelectD": "글로벌 테이블을 생성하고 테이블을 사용할 AWS 리전을 지정합니다.",
    "SelectD_Commentary": "이는 DynamoDB 글로벌 테이블에 관한 설정으로, Amazon RDS MySQL의 Read Replica 구성과 무관합니다.",
    "SelectE": "소스 인스턴스에서 자동 백업을 활성화하고 백업 보관 기간을 0이 아닌 값으로 설정합니다.",
    "SelectE_Commentary": "Read Replica를 만들려면 소스 DB 인스턴스에 자동 백업이 활성화되어야 하므로 백업 보관 기간(Backup Retention Period)을 0이 아닌 값으로 설정해야 합니다.",
    "Question_Description_recommedations": [
      "Q337",
      "Q376",
      "Q590",
      "Q269",
      "Q389"
    ],
    "SelectA_recommedations": [
      "Q776",
      "Q386",
      "Q95"
    ],
    "SelectB_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectC_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q568",
      "Q631"
    ],
    "SelectE_recommedations": [
      "Q888",
      "Q158",
      "Q506"
    ]
  },
  {
    "Question_Number": "Q248",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 분석 소프트웨어를 실행하고 있습니다. 이 소프트웨어는 Amazon S3에 업로드된 데이터를 처리하기 위해 사용자로부터 작업 요청을 받습니다. 사용자들은 일부 제출된 데이터가 처리되지 않는다고 보고합니다. Amazon CloudWatch 모니터링 결과, EC2 인스턴스의 CPU 사용률이 100% 근처에서 지속적으로 유지되고 있습니다. 회사는 시스템 성능을 개선하고, 사용자 로드에 따라 시스템을 확장하기를 원합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95329-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스의 높은 CPU 부하로 인해 일부 작업 요청이 처리되지 않는 상황에서, 사용자 로드에 따라 확장 가능한 아키텍처를 제시해야 합니다. 정답인 Amazon SQS를 사용하면 요청을 대기열에 넣고, EC2 Auto Scaling 그룹을 대기열 크기에 따라 자동으로 확장함으로써 과부하 없이 작업을 처리할 수 있습니다. 또한 작업과 인스턴스 간 결합도를 낮추어 더욱 유연하고 성능 좋은 구조를 만들 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "시스템 성능 개선",
      "사용자 로드 기반 확장",
      "분석 소프트웨어",
      "Amazon EC2",
      "Amazon S3",
      "Amazon SQS",
      "EC2 Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "Amazon CloudWatch",
      "Application Load Balancer",
      "S3 VPC Endpoint",
      "EC2 Auto Scaling",
      "Amazon Simple Queue Service (Amazon SQS)"
    ],
    "SelectA": "인스턴스를 복제하고, 모든 인스턴스를 Application Load Balancer 뒤에 두십시오.",
    "SelectA_Commentary": "단순히 인스턴스를 복제해서 ALB 뒤에 두더라도 CPU 사용률이 계속 100%면 병목이 해소되지 않고, 로드 밸런싱만으로는 작업 큐잉 문제를 해결할 수 없습니다.",
    "SelectB": "Amazon S3에 대한 S3 VPC 엔드포인트를 생성하고, 소프트웨어를 해당 엔드포인트를 참조하도록 업데이트하십시오.",
    "SelectB_Commentary": "S3 접근 경로를 최적화하는 방법이지만, 이 문제의 핵심인 처리량 부족과 확장 이슈는 해결되지 않습니다.",
    "SelectC": "EC2 인스턴스를 중지하고, CPU가 더 강력하고 메모리가 더 많은 인스턴스 유형으로 변경한 후 인스턴스를 재시작하십시오.",
    "SelectC_Commentary": "인스턴스 타입을 올리는 것은 일시적인 해결책이나, 계속 증가하는 사용자 로드에 맞춰 자동 확장하기에는 한계가 있으며 비용 효율도 떨어집니다.",
    "SelectD": "수신되는 요청을 Amazon SQS로 라우팅하십시오. 대기열 크기를 기준으로 EC2 Auto Scaling 그룹을 구성하십시오. 소프트웨어를 대기열에서 읽도록 업데이트하십시오.",
    "SelectD_Commentary": "대기열을 사용해 작업을 비동기로 처리하고, 대기열 크기에 비례해 인스턴스를 자동 확장함으로써 성능과 확장성을 모두 확보할 수 있는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q818",
      "Q690",
      "Q921",
      "Q857",
      "Q219"
    ],
    "SelectA_recommedations": [
      "Q141",
      "Q823",
      "Q261"
    ],
    "SelectB_recommedations": [
      "Q672",
      "Q501",
      "Q155"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q857",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q292",
      "Q229"
    ]
  },
  {
    "Question_Number": "Q249",
    "Question_Description": "한 회사가 AWS Cloud에 호스팅되는 미디어 애플리케이션을 위해 공유 스토리지 솔루션을 구현하려고 합니다. 회사는 SMB 클라이언트를 사용하여 데이터에 액세스해야 하며, 솔루션은 완전관리형이어야 합니다. 이러한 요구사항을 충족하는 AWS 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95006-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SMB 프로토콜을 사용하는 애플리케이션 환경에 대해 완전관리형 공유 스토리지 솔루션을 선정하는 것이 핵심입니다. Amazon FSx for Windows File Server는 Windows 환경과 SMB 접근을 모두 지원하며 완전관리형 서비스로 운영 부담을 낮춥니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "공유 스토리지",
      "SMB 클라이언트",
      "완전관리형",
      "Amazon FSx for Windows File Server"
    ],
    "Terms": [
      "AWS Storage Gateway volume gateway",
      "AWS Storage Gateway tape gateway",
      "Amazon EC2 Windows",
      "Amazon FSx for Windows File Server",
      "SMB"
    ],
    "SelectA": "AWS Storage Gateway volume gateway를 생성하고, 필요한 클라이언트 프로토콜을 사용하는 파일 공유를 생성한 뒤 애플리케이션 서버를 연결합니다.",
    "SelectA_Commentary": "Storage Gateway volume gateway는 온프레미스 및 클라우드 하이브리드 시나리오에 유용하지만, 완전관리형 SMB 파일 스토어로서는 적합하지 않습니다.",
    "SelectB": "AWS Storage Gateway tape gateway를 생성하고, 테이프를 Amazon S3로 설정합니다. 애플리케이션 서버를 tape gateway에 연결합니다.",
    "SelectB_Commentary": "Tape gateway는 백업 및 아카이브 목적에 특화된 형태로, 직접 SMB 프로토콜을 제공하지 않습니다.",
    "SelectC": "Amazon EC2 Windows 인스턴스를 생성합니다. 해당 인스턴스에 Windows file share 역할을 설치 및 구성하고, 애플리케이션 서버를 공유에 연결합니다.",
    "SelectC_Commentary": "EC2에 직접 Windows 파일 공유를 설치하면 관리 오버헤드와 유지보수 비용이 올라가 완전관리형 솔루션이 아닙니다.",
    "SelectD": "Amazon FSx for Windows File Server 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결한 뒤, 애플리케이션 서버를 해당 파일 시스템에 연결합니다.",
    "SelectD_Commentary": "FSx for Windows File Server는 SMB 프로토콜과 Windows 파일 서비스 기능을 완전관리형으로 제공하여 요구사항을 충족하는 가장 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q895",
      "Q305",
      "Q747",
      "Q631",
      "Q361"
    ],
    "SelectA_recommedations": [
      "Q957",
      "Q361",
      "Q597"
    ],
    "SelectB_recommedations": [
      "Q155",
      "Q38",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q369",
      "Q283"
    ],
    "SelectD_recommedations": [
      "Q301",
      "Q361",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q250",
    "Question_Description": "한 회사의 보안 팀이 VPC Flow Logs에 네트워크 트래픽을 기록할 것을 요청했습니다. 이 로그는 90일 동안 자주 액세스되고, 이후에는 간헐적으로 액세스됩니다. 이 요구사항을 충족하기 위해 로그를 구성할 때 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95007-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 90일간 자주 조회되는 로그를 이후에 간헐적으로 조회하면서도 비용을 절감할 수 있도록 저장하는 방법을 묻습니다. Amazon S3에 저장하고 S3 Lifecycle 정책을 통해 S3 Standard-IA로 전환하면 보존 기간 후에도 필요한 때에만 저비용으로 접근 가능해집니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "VPC Flow Logs",
      "90일",
      "간헐적 액세스",
      "비용 최적화",
      "S3 Lifecycle"
    ],
    "Terms": [
      "VPC Flow Logs",
      "Amazon CloudWatch",
      "Amazon Kinesis",
      "AWS CloudTrail",
      "Amazon S3",
      "S3 Intelligent-Tiering",
      "S3 Lifecycle policy",
      "S3 Standard-Infrequent Access (S3 Standard-IA)"
    ],
    "SelectA": "Amazon CloudWatch를 대상으로 사용합니다. CloudWatch 로그 그룹을 설정하여 90일 만료를 적용합니다.",
    "SelectA_Commentary": "CloudWatch 로그 그룹에 만료 기간을 설정할 수 있지만, 장기 보관 및 간헐적 액세스 측면에서 비용 최적화가 충분치 않습니다.",
    "SelectB": "Amazon Kinesis를 대상으로 사용합니다. Kinesis 스트림을 구성하여 항상 로그를 90일 동안 보관하도록 설정합니다.",
    "SelectB_Commentary": "Kinesis는 실시간 데이터 스트리밍에 적합하지만, 장기적으로 로그를 보관하고 간헐적으로 조회하기에는 효율적이지 않습니다.",
    "SelectC": "AWS CloudTrail을 대상으로 사용합니다. CloudTrail에서 Amazon S3 버킷에 저장하도록 설정하고, S3 Intelligent-Tiering을 활성화합니다.",
    "SelectC_Commentary": "CloudTrail은 API 호출 이력을 추적하는 서비스이므로 VPC Flow Logs와는 용도가 다릅니다. 요구사항에 직접 부합하지 않습니다.",
    "SelectD": "Amazon S3를 대상으로 사용합니다. S3 Lifecycle 정책을 활성화하여 90일 후에 로그를 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환합니다.",
    "SelectD_Commentary": "S3에 로그를 저장하고 90일 후 Lifecycle 정책으로 S3 Standard-IA로 전환하면 자주 조회되지 않는 기간에도 비용을 절감하며 간헐적으로 필요한 접근을 지원합니다.",
    "Question_Description_recommedations": [
      "Q534",
      "Q471",
      "Q374",
      "Q485",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q485",
      "Q486",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q486",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q227",
      "Q534",
      "Q31"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q251",
    "Question_Description": "Amazon EC2 인스턴스가 새로운 VPC의 private subnet에 위치해 있습니다. 이 subnet은 아웃바운드 인터넷 액세스가 없지만, 해당 EC2 인스턴스는 외부 벤더로부터 매월 보안 업데이트를 다운로드해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95023-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "private subnet에서 외부로 데이터를 전송하기 위해서는 NAT 구성과 internet gateway가 필요합니다. 일반적으로 public subnet에 NAT gateway를 두고, private subnet이 해당 NAT gateway를 통해 인터넷에 접근하도록 구성하는 것이 표준적이고 안전합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "private subnet",
      "NAT gateway",
      "public subnet",
      "internet gateway",
      "월간 보안 업데이트"
    ],
    "Terms": [
      "VPC",
      "private subnet",
      "public subnet",
      "NAT gateway",
      "NAT instance",
      "internet gateway",
      "route table"
    ],
    "SelectA": "internet gateway를 VPC에 연결하고, private subnet의 route table을 internet gateway로 기본 라우팅하도록 구성합니다.",
    "SelectA_Commentary": "단순히 internet gateway만 붙여서는 private subnet이 직접 인터넷에 나갈 수 없습니다. NAT 역할이 없으므로 요구사항을 충족하기 어렵습니다.",
    "SelectB": "public subnet에 NAT gateway를 생성하고, private subnet의 route table을 NAT gateway로 기본 라우팅하도록 구성합니다.",
    "SelectB_Commentary": "표준 솔루션으로, NAT gateway가 외부로의 트래픽을 중계하고 internet gateway와 연동되어 private subnet에서 안전하게 아웃바운드 연결을 제공합니다.",
    "SelectC": "동일한 subnet(EC2가 위치한)에 NAT instance를 생성하고, private subnet의 route table을 NAT instance로 기본 라우팅하도록 구성합니다.",
    "SelectC_Commentary": "NAT instance가 private subnet 안에 있으면 자체 인터넷 연결을 확보하기 어렵고, 관리 복잡성이 증가해 적절하지 않습니다.",
    "SelectD": "internet gateway를 VPC에 연결하고, 동일한 subnet(EC2가 위치한)에 NAT instance를 생성합니다. private subnet의 route table을 internet gateway로 기본 라우팅하도록 구성합니다.",
    "SelectD_Commentary": "NAT instance와 internet gateway를 같은 private subnet에 배치해도 올바른 NAT 구조가 형성되지 않으며, 라우팅이 맞지 않아 목적을 달성하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q875",
      "Q610",
      "Q327",
      "Q115",
      "Q866"
    ],
    "SelectA_recommedations": [
      "Q468",
      "Q950",
      "Q712"
    ],
    "SelectB_recommedations": [
      "Q468",
      "Q875",
      "Q774"
    ],
    "SelectC_recommedations": [
      "Q251",
      "Q875",
      "Q839"
    ],
    "SelectD_recommedations": [
      "Q251",
      "Q875",
      "Q1016"
    ]
  },
  {
    "Question_Number": "Q252",
    "Question_Description": "한 솔루션스 아키텍트가 클라이언트 케이스 파일을 저장하기 위한 시스템을 설계해야 합니다. 이 파일들은 회사의 핵심 자산으로서 매우 중요하며, 시간이 지남에 따라 파일의 수가 증가할 것입니다. 이 파일들은 Amazon EC2 인스턴스에서 동작하는 여러 애플리케이션 서버에서 동시에 액세스할 수 있어야 합니다. 또한 솔루션은 자체 내장된 내결함성을 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95024-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 중요한 파일을 여러 Amazon EC2 인스턴스에서 동시에 접근해야 하며, 파일 수가 지속적으로 증가하는 상황에 대한 스토리지 선택을 묻습니다. Amazon EFS는 완전관리형 파일 시스템으로 자동 확장과 다중 AZ 내결함성을 제공해 운영 복잡성을 줄이고 고가용성을 보장하므로 요구사항을 충족하는 최적의 해법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "클라이언트 케이스 파일",
      "동시 액세스",
      "자동 확장",
      "내결함성"
    ],
    "Terms": [
      "Amazon EFS",
      "Amazon EC2",
      "Amazon EBS",
      "Amazon S3 Glacier Deep Archive",
      "AWS Backup"
    ],
    "SelectA": "Amazon Elastic File System (Amazon EFS)",
    "SelectA_Commentary": "NFS 기반 공유 스토리지로 동시 액세스와 자동 확장, 내결함성을 모두 제공하므로 요구사항에 부합하는 정답입니다.",
    "SelectB": "Amazon Elastic Block Store (Amazon EBS)",
    "SelectB_Commentary": "단일 인스턴스 전용 볼륨이 기본이며, 자동 확장이 어렵고 다중 인스턴스 동시 액세스가 제한적입니다.",
    "SelectC": "Amazon S3 Glacier Deep Archive",
    "SelectC_Commentary": "장기 보관 및 아카이브용이며 즉시 액세스가 필요한 운영 환경에 적합하지 않습니다.",
    "SelectD": "AWS Backup",
    "SelectD_Commentary": "백업 및 복구 전용 서비스로, 실시간 파일 공유나 내결함성 파일시스템으로 활용하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q413",
      "Q757",
      "Q584",
      "Q244",
      "Q110"
    ],
    "SelectA_recommedations": [
      "Q842",
      "Q194",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q584",
      "Q194",
      "Q244"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q869",
      "Q244"
    ],
    "SelectD_recommedations": [
      "Q512",
      "Q194",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q253",
    "Question_Description": "한 Solutions Architect가 두 개의 IAM Policy(Policy1과 Policy2)를 생성했습니다. 두 Policy는 모두 하나의 IAM Group에 연결되어 있습니다. 한 Cloud Engineer가 새로 IAM User로 추가되어 해당 IAM Group에 속해 있습니다. 이 Cloud Engineer가 수행할 수 있는 작업은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95008-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM Policy를 통해 어떤 작업이 허용되는지 확인하는 문제입니다. Policy1이 ec2:* 권한을 포함하여 Amazon EC2 리소스에 대한 완전한 액세스를 허용하므로, Cloud Engineer는 Amazon EC2 인스턴스를 삭제할 수 있습니다. 다른 작업들은 IAM, Directory Service, CloudWatch Logs 관련 권한이 제한되어 있어 수행이 불가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM Policy",
      "IAM Group",
      "Amazon EC2 인스턴스 삭제",
      "CloudWatch Logs",
      "디렉터리 삭제"
    ],
    "Terms": [
      "IAM Policy",
      "IAM Group",
      "IAM User",
      "Amazon EC2",
      "CloudWatch Logs",
      "ds:Delete"
    ],
    "SelectA": "Deleting IAM users",
    "SelectA_Commentary": "IAM User 관련 권한은 get과 list 권한만 있으므로 삭제 권한은 허용되지 않습니다.",
    "SelectB": "Deleting directories",
    "SelectB_Commentary": "ds:DeleteDirectory에 대한 권한이 명시적으로 거부(deny)되어 있으므로 디렉터리 삭제는 불가능합니다.",
    "SelectC": "Deleting Amazon EC2 instances",
    "SelectC_Commentary": "ec2:* 권한이 허용되어 Amazon EC2 인스턴스 삭제가 가능합니다.",
    "SelectD": "Deleting logs from Amazon CloudWatch Logs",
    "SelectD_Commentary": "로그에 대해서는 get과 describe 권한만 주어졌으므로 삭제 권한이 없습니다.",
    "Question_Description_recommedations": [
      "Q924",
      "Q423",
      "Q751",
      "Q89",
      "Q395"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q321",
      "Q682",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q321",
      "Q682",
      "Q453"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q321",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q254",
    "Question_Description": "한 회사가 세 계층으로 구성된 애플리케이션을 VPC로 이전한 후 이를 검토하고 있습니다. 보안 팀은 애플리케이션 계층 간 Amazon EC2 보안 그룹 인바운드와 아웃바운드 규칙이 최소 권한 원칙(least privilege)을 적용하지 않고 있다고 지적했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95009-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 계층 간 트래픽을 최소 권한 원칙으로 제한하는 방법을 묻습니다. 보안 그룹 간 통신 시 Security Group ID를 사용하면 필요한 계층 간 트래픽만 허용할 수 있어 보안을 강화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "VPC",
      "3티어 애플리케이션",
      "보안 그룹",
      "최소 권한 원칙"
    ],
    "Terms": [
      "Amazon EC2",
      "Security Group",
      "Ingress Rule",
      "Egress Rule",
      "Security Group ID",
      "VPC CIDR",
      "Subnet CIDR",
      "Instance ID"
    ],
    "SelectA": "인스턴스 ID를 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
    "SelectA_Commentary": "인스턴스별로 규칙을 지정하면 운영이 번거롭고, 확장성도 떨어지므로 최소 권한 구현에 적합하지 않습니다.",
    "SelectB": "Security Group ID를 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
    "SelectB_Commentary": "보안 그룹 간의 통신만 허용하므로 필요 최소한의 액세스만 부여할 수 있어 가장 안전하고 유연한 방식입니다.",
    "SelectC": "VPC CIDR 블록을 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
    "SelectC_Commentary": "VPC 전체 대역을 허용하면 범위가 너무 넓어 최소 권한 원칙에 어긋납니다.",
    "SelectD": "서브넷 CIDR 블록을 소스나 대상으로 사용하여 보안 그룹 규칙을 생성합니다.",
    "SelectD_Commentary": "서브넷 단위로 허용해도 필요 이상으로 많은 트래픽을 허용하게 되어 최소 권한 규칙을 만족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q866",
      "Q370",
      "Q92",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q803",
      "Q395"
    ],
    "SelectC_recommedations": [
      "Q950",
      "Q15",
      "Q657"
    ],
    "SelectD_recommedations": [
      "Q803",
      "Q657",
      "Q538"
    ]
  },
  {
    "Question_Number": "Q255",
    "Question_Description": "한 회사가 전자상거래 체크아웃 워크플로우를 운영하고 있습니다. 이 워크플로우는 주문 정보를 데이터베이스에 저장하고, 결제를 처리하기 위해 별도의 서비스를 호출합니다. 현재 사용자가 결제 화면에서 시간 초과를 겪고 있으며, 사용자가 체크아웃 양식을 다시 제출하면 동일한 거래에 대해 여러 개의 고유 주문이 생성되는 문제가 발생하고 있습니다. 이러한 중복 주문 생성을 어떻게 방지할 수 있도록 워크플로우를 재구성해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95026-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "주문 처리와 결제를 분리하여 중복 주문을 방지하려면 메시지 큐를 사용해 느슨하게 결합된 워크플로우로 설계해야 합니다. Amazon SQS FIFO 큐를 이용하면 중복을 방지하고 순서대로 메시지를 처리하여 여러 주문 생성을 막을 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "전자상거래",
      "체크아웃",
      "중복 주문 방지",
      "결제 서비스",
      "데이터베이스",
      "Amazon SQS FIFO"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "AWS CloudTrail",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS) FIFO queue"
    ],
    "SelectA": "웹 애플리케이션이 주문 메시지를 Amazon Kinesis Data Firehose로 전송하도록 구성합니다. 결제 서비스가 Kinesis Data Firehose에서 메시지를 가져와 주문을 처리합니다.",
    "SelectA_Commentary": "Kinesis Data Firehose는 대량 데이터를 실시간으로 처리하기 위한 서비스이지만, 중복 방지와 메시지 순서 보장에는 적합하지 않습니다.",
    "SelectB": "AWS CloudTrail에 기록된 애플리케이션 경로 요청을 기반으로 Lambda 함수를 호출하는 규칙을 만듭니다. Lambda가 데이터베이스를 조회하고 결제 서비스를 호출하여 주문 정보를 전달합니다.",
    "SelectB_Commentary": "CloudTrail은 API 호출 로깅 서비스로, 주문 중복 방지와 순서 제어를 지원하지 않아 문제 해결에 적합하지 않습니다.",
    "SelectC": "주문을 데이터베이스에 저장한 후, 주문 번호를 포함한 메시지를 Amazon SNS에 전송합니다. 결제 서비스가 Amazon SNS를 폴링하여 메시지를 가져와 주문을 처리합니다.",
    "SelectC_Commentary": "SNS는 주로 게시-구독 모델로 즉시 알림 전달에는 유용하지만 중복 방지나 순서 보장 기능이 부족합니다.",
    "SelectD": "주문을 데이터베이스에 저장한 후, 주문 번호를 포함하는 메시지를 Amazon SQS FIFO 큐에 전송합니다. 결제 서비스가 메시지를 조회하여 주문을 처리하고, 메시지를 큐에서 삭제합니다.",
    "SelectD_Commentary": "FIFO 큐는 메시지를 순서대로 처리하고 중복 전달을 방지합니다. 결제 서비스와 주문 처리를 분리해 중복 주문 문제를 해결하는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q735",
      "Q58",
      "Q917",
      "Q491",
      "Q967"
    ],
    "SelectA_recommedations": [
      "Q845",
      "Q10",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q785",
      "Q404",
      "Q531"
    ],
    "SelectC_recommedations": [
      "Q615",
      "Q363",
      "Q967"
    ],
    "SelectD_recommedations": [
      "Q363",
      "Q8",
      "Q784"
    ]
  },
  {
    "Question_Number": "Q256",
    "Question_Description": "한 솔루션스 아키텍트가 Amazon S3 bucket을 스토리지로 사용하는 문서 검토 애플리케이션을 구현하려고 합니다. 솔루션은 문서가 실수로 삭제되는 것을 방지하고, 모든 문서 버전을 보존해야 합니다. 또한 사용자가 문서를 다운로드, 수정, 업로드할 수 있어야 합니다. 이러한 요구 사항을 충족하기 위해 어떤 조합의 작업을 수행해야 합니까? (2개를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95460-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 문서가 실수로 삭제되지 않도록 보호하면서 모든 버전을 남겨야 하는 S3 구성 방안을 묻습니다. Versioning은 각각의 변경 이력을 남겨 복원이 가능하게 하며, MFA Delete는 삭제 시 다단계 인증을 요구해 우발적이거나 악의적인 삭제를 방지합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "문서 검토",
      "실수로 삭제 방지",
      "Versioning",
      "MFA Delete",
      "S3 버킷"
    ],
    "Terms": [
      "Amazon S3 bucket",
      "Bucket ACL",
      "Versioning",
      "IAM policy",
      "MFA Delete",
      "AWS KMS"
    ],
    "SelectA": "read-only bucket ACL을 활성화합니다.",
    "SelectA_Commentary": "문서를 수정하거나 업로드해야 하므로 read-only 구성은 요구사항을 충족하지 못합니다.",
    "SelectB": "버킷에 Versioning을 활성화합니다.",
    "SelectB_Commentary": "모든 문서 버전을 보존해 실수로 삭제되더라도 이전 버전을 복원할 수 있어 필수적인 설정입니다.",
    "SelectC": "버킷에 IAM policy를 연결합니다.",
    "SelectC_Commentary": "접근 권한을 세밀하게 제어할 수 있지만, 삭제 방지와 버전 보존을 직접적으로 보장하지 않으므로 핵심 요구사항을 단독으로 해결하진 못합니다.",
    "SelectD": "버킷에 MFA Delete를 활성화합니다.",
    "SelectD_Commentary": "버킷 및 객체 삭제 시 추가 인증 과정을 요구하여 실수 또는 무단 삭제를 예방하므로 Versioning과 함께 매우 효과적인 보호를 제공합니다.",
    "SelectE": "버킷을 AWS KMS로 암호화합니다.",
    "SelectE_Commentary": "암호화는 데이터 보호 측면에 유용하지만, 실수로 인한 삭제 방지나 버전 보존 기능을 제공하지 않으므로 요구사항과 직접적인 연관이 없습니다.",
    "Question_Description_recommedations": [
      "Q154",
      "Q44",
      "Q965",
      "Q678",
      "Q106"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q233",
      "Q256"
    ],
    "SelectB_recommedations": [
      "Q106",
      "Q678",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q423",
      "Q476"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q122",
      "Q678"
    ],
    "SelectE_recommedations": [
      "Q893",
      "Q550",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q257",
    "Question_Description": "한 회사가 전체 AWS 계정의 모든 애플리케이션에서 발생하는 Amazon EC2 Auto Scaling 이벤트를 보고하는 솔루션을 구축하려 합니다. 회사는 서버리스 솔루션을 통해 EC2 Auto Scaling 상태 데이터를 Amazon S3에 저장해야 합니다. 이후 이 데이터는 Amazon S3에서 거의 실시간으로 대시보드에 반영되어야 합니다. 또한 이 솔루션은 EC2 인스턴스가 시작되는 속도에 영향을 주어서는 안 됩니다. 이러한 요구사항을 충족하기 위해, 데이터를 Amazon S3로 옮기는 가장 적합한 방법은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95027-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 Auto Scaling 이벤트 데이터가 EC2 인스턴스 시작 시간을 지연시키지 않으면서도 거의 실시간으로 수집·저장되어야 한다는 점이 핵심입니다. 가장 빠르고 단순한 서버리스 아키텍처로 데이터를 전송하기 위해서는 CloudWatch metric stream과 Kinesis Data Firehose를 사용하는 방법이 적합합니다. 이는 데이터를 직접 스트리밍하여 거의 실시간으로 Amazon S3에 저장하도록 하며, 추가적인 오버헤드가 없어 인스턴스의 시작 시간을 방해하지 않습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "EC2 Auto Scaling",
      "Amazon S3",
      "서버리스",
      "실시간 대시보드",
      "이벤트 스트리밍"
    ],
    "Terms": [
      "Amazon CloudWatch metric stream",
      "Amazon Kinesis Data Firehose",
      "Amazon EMR",
      "Amazon EventBridge",
      "AWS Lambda",
      "Amazon Kinesis Agent",
      "EC2 Auto Scaling",
      "Bootstrap script"
    ],
    "SelectA": "Amazon CloudWatch metric stream을 사용해 EC2 Auto Scaling 상태 데이터를 Amazon Kinesis Data Firehose로 전송합니다. 데이터를 Amazon S3에 저장합니다.",
    "SelectA_Commentary": "CloudWatch metric stream과 Kinesis Data Firehose를 연계하여 서버리스 방식으로 실시간 이벤트를 S3로 전달하므로, 인스턴스 시작과정에 부하를 주지 않으며 실시간 대시보드 요구를 만족합니다.",
    "SelectB": "Amazon EMR 클러스터를 시작하여 EC2 Auto Scaling 상태 데이터를 수집하고, Amazon Kinesis Data Firehose로 데이터를 전송해 Amazon S3에 저장합니다.",
    "SelectB_Commentary": "EMR은 대규모 데이터 처리를 위한 빅데이터 플랫폼이므로, 실시간 이벤트 중심의 가벼운 데이터 전송에 과도하며 운영 복잡도도 증가합니다.",
    "SelectC": "Amazon EventBridge 규칙을 생성하여 스케줄에 따라 AWS Lambda 함수를 호출합니다. Lambda 함수에서 EC2 Auto Scaling 상태 데이터를 직접 Amazon S3로 전송하도록 구성합니다.",
    "SelectC_Commentary": "스케줄 기반 호출은 이벤트 발생 시점에 맞추어 실시간 처리를 보장하기 어렵고, 거의 실시간 대시보드 요구사항을 충족하기에 부족합니다.",
    "SelectD": "EC2 인스턴스 시작 시 부트스트랩 스크립트를 사용하여 Amazon Kinesis Agent를 설치합니다. Kinesis Agent가 EC2 Auto Scaling 상태 데이터를 수집해 Amazon Kinesis Data Firehose로 전송하고, S3에 저장합니다.",
    "SelectD_Commentary": "각 EC2 인스턴스마다 별도 설정과 설치 과정이 필요하므로 인스턴스 시작 시간을 지연시킬 수 있어 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q690",
      "Q680",
      "Q818",
      "Q248",
      "Q226"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q257",
      "Q695"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q402",
      "Q335"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q603",
      "Q41"
    ],
    "SelectD_recommedations": [
      "Q402",
      "Q695",
      "Q257"
    ]
  },
  {
    "Question_Number": "Q258",
    "Question_Description": "한 회사가 매시간 수백 개의 .csv 파일을 Amazon S3 버킷에 저장하는 애플리케이션을 운영하고 있습니다. 각 파일의 크기는 1GB입니다. 회사는 매번 파일이 업로드될 때마다 해당 파일을 Apache Parquet 형식으로 변환하고, 변환된 파일을 S3 버킷에 저장해야 합니다. 이러한 요구사항을 만족하면서 운영 오버헤드를 최소화할 수 있는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95028-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 매시간 대량으로 업로드되는 1GB 크기의 CSV 파일을 자동으로 Parquet 형식으로 변환하면서 운영 부담을 최소화하는 것입니다. AWS Glue ETL job을 활용하면 서버리스 방식으로 확장성과 자동화가 가능하며, Lambda를 통해 업로드 이벤트마다 Glue job을 손쉽게 호출할 수 있어 최소한의 운영 작업으로 요구사항을 충족시킬 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "파일 변환",
      "Apache Parquet",
      "Amazon S3",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Lambda",
      "Apache Spark",
      "AWS Glue",
      "ETL job",
      "Amazon Athena",
      "AWS Glue Crawler",
      ".csv 파일",
      "Parquet 형식"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 .csv 파일을 다운로드하고, 해당 파일을 Parquet 형식으로 변환한 뒤 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 Lambda 함수를 호출합니다.",
    "SelectA_Commentary": "Lambda만으로 대용량 파일을 처리하면 메모리, 시간 제한 등 관리가 복잡해져 운영 오버헤드가 증가하므로 가장 적합하지 않습니다.",
    "SelectB": "Apache Spark 잡을 생성하여 .csv 파일을 읽고 Parquet 형식으로 변환한 뒤 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 Spark 잡을 호출하는 Lambda 함수를 생성합니다.",
    "SelectB_Commentary": "Spark 클러스터 운영이 필요해 관리가 번거롭고, 구성도 복잡해져 운영 오버헤드가 높아집니다.",
    "SelectC": "AWS Glue 테이블과 AWS Glue 크롤러를 만들어 .csv 파일이 있는 S3 버킷을 인식하게 합니다. 주기적으로 Lambda 함수를 호출하여 Amazon Athena로 Glue 테이블을 쿼리한 후, 결과를 Parquet 형식으로 변환해 S3 버킷에 저장합니다.",
    "SelectC_Commentary": "주기적 Athena 쿼리 방식을 사용하면 실시간 변환이 어려우며, 관리 대상(크롤러, 쿼리 예약)이 많아져 운영 오버헤드가 증가합니다.",
    "SelectD": "AWS Glue ETL job을 생성하여 .csv 파일을 Parquet 형식으로 변환하고 결과 파일을 S3 버킷에 저장합니다. 각 S3 PUT 이벤트마다 ETL job을 호출하는 Lambda 함수를 생성합니다.",
    "SelectD_Commentary": "서버리스인 AWS Glue가 확장성과 자동화를 제공하므로 파일 변환 작업과 파이프라인 관리가 간소화되어 운영 오버헤드를 최소화합니다.",
    "Question_Description_recommedations": [
      "Q214",
      "Q292",
      "Q414",
      "Q155",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q214",
      "Q258",
      "Q414"
    ],
    "SelectB_recommedations": [
      "Q214",
      "Q258",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q214",
      "Q103",
      "Q258"
    ],
    "SelectD_recommedations": [
      "Q103",
      "Q214",
      "Q258"
    ]
  },
  {
    "Question_Number": "Q259",
    "Question_Description": "한 회사가 Amazon RDS DB 인스턴스에서 실행 중인 모든 데이터베이스에 대하여 새로운 데이터 보존 정책을 도입하려고 합니다. 회사는 매일 백업을 최소 2년간 보존해야 하며, 백업이 일관되고 복원 가능해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 솔루션을 권장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95030-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS DB 인스턴스에 대한 장기 백업 보존 정책을 구현해 매일 백업을 최소 2년간 유지하고, 복원 가능하도록 하는 방법을 묻습니다. AWS Backup을 사용하면 중앙 집중식 백업 관리와 자동화된 일정 설정이 가능해, 백업 일관성과 쉽게 복원 가능한 환경을 보장합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "RDS DB 인스턴스",
      "일일 백업",
      "2년 보존",
      "일관성",
      "복원 가능",
      "AWS Backup"
    ],
    "Terms": [
      "AWS Backup",
      "Backup vault",
      "Backup plan",
      "Amazon RDS",
      "Amazon Data Lifecycle Manager(Amazon DLM)",
      "AWS Database Migration Service(AWS DMS)",
      "Change Data Capture(CDC)",
      "S3 Lifecycle"
    ],
    "SelectA": "AWS Backup에서 RDS 백업을 보존할 백업 볼트를 생성합니다. 일일 스케줄과 생성 후 2년 만료 기간을 갖는 새로운 백업 플랜을 만든 뒤, 해당 RDS DB 인스턴스를 백업 플랜에 할당합니다.",
    "SelectA_Commentary": "AWS Backup은 일관된 백업과 자동화를 제공하므로 매일 백업을 수행하고 2년간 보관하며 쉽게 복원할 수 있습니다. 요구사항을 충족하는 최적의 솔루션입니다.",
    "SelectB": "RDS DB 인스턴스에 대해 백업 윈도우를 구성해 일일 스냅샷을 생성합니다. 각 RDS DB 인스턴스에 2년 스냅샷 보존 정책을 할당하고, Amazon Data Lifecycle Manager(Amazon DLM)로 스냅샷 삭제를 예약합니다.",
    "SelectB_Commentary": "스냅샷은 특정 시점의 백업이며, 완전한 일관성과 자동 복원 시나리오를 보장하기 어렵습니다. 게다가 DLM을 통한 삭제 일정만 관리하며, 중앙화된 자동화가 부족합니다.",
    "SelectC": "데이터베이스 트랜잭션 로그를 자동으로 Amazon CloudWatch Logs에 백업하도록 구성하고, 2년 만료 기간을 설정합니다.",
    "SelectC_Commentary": "트랜잭션 로그 백업만으로 전체 데이터베이스 복원이 보장되지 않으며, 자동화된 일관성 백업과 쉽게 복구할 방법도 제공되지 않습니다.",
    "SelectD": "AWS Database Migration Service(AWS DMS) 복제 태스크를 구성합니다. 복제 인스턴스를 배포하고, Change Data Capture(CDC) 태스크를 설정해 Amazon S3를 대상으로 데이터베이스 변경 사항을 스트리밍합니다. 그리고 S3 Lifecycle 정책으로 2년 후 스냅샷을 삭제합니다.",
    "SelectD_Commentary": "이 방식은 복제와 변경 데이터 캡처(CDC)에 집중된 솔루션으로, 매일 백업을 일관성 있게 유지하고 복원하는 용도로는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q629",
      "Q518",
      "Q108",
      "Q195",
      "Q228"
    ],
    "SelectA_recommedations": [
      "Q259",
      "Q518",
      "Q125"
    ],
    "SelectB_recommedations": [
      "Q259",
      "Q365",
      "Q518"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q194",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q490",
      "Q874",
      "Q636"
    ]
  },
  {
    "Question_Number": "Q260",
    "Question_Description": "한 회사의 컴플라이언스 팀이 Windows Server SMB 파일 공유로 운영 중인 파일 공유를 AWS로 이전해야 합니다. 사내에서 자체 관리하는 온프레미스 Active Directory가 파일과 폴더에 대한 액세스를 제어하고 있습니다. 이 회사는 솔루션의 일부로 Amazon FSx for Windows File Server를 사용하려고 합니다. 마이그레이션 후에도 온프레미스 Active Directory 그룹이 FSx for Windows File Server SMB 컴플라이언스 공유, 폴더 및 파일에 대한 액세스를 계속 제한해야 합니다. 이미 FSx for Windows File Server 파일 시스템을 생성해두었습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95343-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon FSx for Windows File Server를 기존 온프레미스 Active Directory와 연동하여 이전과 동일한 접근 제어 정책을 유지하는 방법을 묻습니다. FSx 파일 시스템을 도메인에 조인하면, 이미 정의된 AD 그룹과 보안 정책을 그대로 적용해 마이그레이션의 편의성과 보안을 동시에 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Windows Server SMB 파일 공유",
      "온프레미스 Active Directory",
      "Amazon FSx for Windows File Server",
      "컴플라이언스",
      "액세스 제어",
      "파일 시스템 조인"
    ],
    "Terms": [
      "FSx for Windows File Server",
      "SMB",
      "Active Directory",
      "Active Directory Connector",
      "IAM",
      "Service-linked Role"
    ],
    "SelectA": "Active Directory Connector를 생성하여 Active Directory에 연결합니다. AD 그룹을 IAM 그룹과 매핑해 액세스를 제한합니다.",
    "SelectA_Commentary": "AD Connector는 AWS Directory Service에 연결을 제공하지만, AD 그룹을 IAM 그룹과 각각 매핑해야 하므로 설정이 복잡해지고 온프레미스 권한을 그대로 살리기에 적합하지 않습니다.",
    "SelectB": "Restrict라는 태그 키와 Compliance라는 태그 값을 지정합니다. AD 그룹을 IAM 그룹과 매핑해 액세스를 제한합니다.",
    "SelectB_Commentary": "태그를 활용한 접근 제한은 일반적으로 역할 기반 액세스 제어와 조합되어야 하며, 온프레미스 AD의 기존 구조를 그대로 반영하지 못합니다.",
    "SelectC": "IAM service-linked role을 생성해 FSx for Windows File Server와 직접 연결해 액세스를 제한합니다.",
    "SelectC_Commentary": "Service-linked role은 FSx 자원에 대한 권한 위임을 돕지만, 기존 AD 보안 그룹과 ACL을 그대로 사용하기 위한 접점이 부족합니다.",
    "SelectD": "파일 시스템을 Active Directory에 조인해 액세스를 제한합니다.",
    "SelectD_Commentary": "온프레미스 Active Directory에 FSx 파일 시스템을 조인하면 기존 AD 그룹과 ACL을 그대로 활용할 수 있어, 마이그레이션 후에도 동일한 정책과 관리 방식을 유지할 수 있는 가장 적합한 방법입니다.",
    "Question_Description_recommedations": [
      "Q500",
      "Q832",
      "Q334",
      "Q826",
      "Q1018"
    ],
    "SelectA_recommedations": [
      "Q826",
      "Q28",
      "Q429"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q429",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q500",
      "Q260",
      "Q429"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q898",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q261",
    "Question_Description": "한 회사가 최근 리테일 웹사이트를 전 세계 고객에게 공개했습니다. 이 웹사이트는 Elastic Load Balancer 뒤에서 다수의 Amazon EC2 인스턴스에서 구동되며, 여러 Availability Zone에 걸친 Auto Scaling group으로 운영됩니다. 회사는 고객들이 웹사이트에 접속하는 기기에 따라 다른 버전의 콘텐츠를 제공하고자 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect가 수행해야 할 조치는 무엇입니까? (두 가지를 고르세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95011-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자 기기에 따라 다른 버전의 웹 콘텐츠를 효율적으로 제공하는 방법을 묻습니다. Amazon CloudFront와 Lambda@Edge를 사용하면 캐시에 여러 버전을 저장하고, User-Agent 헤더를 기반으로 동적으로 다른 콘텐츠를 제공할 수 있습니다. NLB는 TCP/UDP 레벨의 라우팅만 지원하므로 호스트 기반이나 경로 기반 라우팅을 제공하기 어렵습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "글로벌 웹사이트",
      "기기별 콘텐츠",
      "Elastic Load Balancer",
      "Auto Scaling group",
      "Amazon CloudFront",
      "Lambda@Edge",
      "User-Agent 헤더"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic Load Balancer",
      "Auto Scaling group",
      "Amazon CloudFront",
      "Lambda@Edge",
      "AWS Global Accelerator",
      "Network Load Balancer(NLB)",
      "User-Agent 헤더",
      "호스트 기반 라우팅",
      "경로 기반 라우팅"
    ],
    "SelectA": "Amazon CloudFront를 구성하여 여러 버전의 콘텐츠를 캐시합니다.",
    "SelectA_Commentary": "CloudFront 캐싱은 전 세계적으로 분산된 Edge Location을 통해 다양한 버전의 콘텐츠를 빠르게 전달할 수 있어 요구사항에 부합합니다.",
    "SelectB": "Network Load Balancer에서 호스트 헤더를 구성하여 트래픽을 다른 인스턴스로 전달합니다.",
    "SelectB_Commentary": "NLB는 Layer 4 로드 밸런싱만 지원하므로 호스트 헤더 기반 라우팅을 제공하지 못해 요구사항을 충족하기 어렵습니다.",
    "SelectC": "Lambda@Edge 함수를 구성하여 User-Agent 헤더에 따라 특정 객체를 사용자에게 전달합니다.",
    "SelectC_Commentary": "Lambda@Edge는 CloudFront에서 요청을 가로채 사용자 기기에 따라 다른 콘텐츠를 반환할 수 있어 올바른 접근입니다.",
    "SelectD": "AWS Global Accelerator를 구성합니다. 요청을 NLB로 전달합니다. NLB를 구성하여 호스트 기반 라우팅으로 다른 EC2 인스턴스에 트래픽을 전달하도록 합니다.",
    "SelectD_Commentary": "NLB는 호스트 기반 라우팅을 제공하지 않아, Layer 7 라우팅이 필요한 이 요구사항에 적합하지 않습니다.",
    "SelectE": "AWS Global Accelerator를 구성합니다. 요청을 NLB로 전달합니다. NLB를 구성하여 경로 기반 라우팅으로 다른 EC2 인스턴스에 트래픽을 전달하도록 합니다.",
    "SelectE_Commentary": "NLB는 경로 기반 라우팅 또한 지원하지 않으므로, HTTP 헤더 기반의 맞춤 콘텐츠 제공에는 사용할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q268",
      "Q461",
      "Q141",
      "Q335",
      "Q818"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q280",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q352",
      "Q530",
      "Q815"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q352",
      "Q77"
    ],
    "SelectD_recommedations": [
      "Q815",
      "Q857",
      "Q358"
    ],
    "SelectE_recommedations": [
      "Q815",
      "Q857",
      "Q358"
    ]
  },
  {
    "Question_Number": "Q262",
    "Question_Description": "한 회사가 다중 계층 웹 애플리케이션에 Amazon ElastiCache를 사용하려고 합니다. 솔루션스 아키텍트는 ElastiCache cluster를 위한 Cache VPC와 애플리케이션의 Amazon EC2 인스턴스를 위한 App VPC를 생성했습니다. 두 VPC는 us-east-1 Region에 있습니다. 솔루션스 아키텍트는 애플리케이션의 EC2 인스턴스가 ElastiCache cluster에 액세스하도록 구현해야 합니다. 아래 어느 솔루션이 가장 비용 효율적으로 이러한 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95463-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "VPC 간 연결을 할 때 Transit VPC를 구성하면 추가 비용과 구성이 필요해 복잡도가 높아집니다. VPC Peering은 간단하고 비용이 들지 않아 가장 경제적인 연결 방식입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "Amazon ElastiCache",
      "VPC Peering",
      "비용 효율"
    ],
    "Terms": [
      "Amazon ElastiCache",
      "Cache VPC",
      "App VPC",
      "Amazon EC2",
      "VPC 피어링(VPC Peering)",
      "Transit VPC",
      "Security Group",
      "Inbound Rule",
      "Route Table"
    ],
    "SelectA": "두 VPC 간에 peering connection을 생성합니다. 양쪽 VPC에 route table 항목을 추가하고, ElastiCache cluster의 security group에 애플리케이션 security group에서 오는 인바운드 트래픽을 허용합니다.",
    "SelectA_Commentary": "별도 인프라 없이 간단히 연결할 수 있고 추가 요금이 없어 비용 측면에서 유리합니다. 보안 그룹 설정만으로 접근을 제어할 수 있어 안전하며 요구사항을 충족합니다.",
    "SelectB": "Transit VPC를 생성합니다. Cache VPC와 App VPC의 route table을 Transit VPC를 거치도록 설정하고, ElastiCache cluster의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.",
    "SelectB_Commentary": "Transit VPC를 유지하는 데 추가 비용과 구성이 필요해 비효율적입니다. 비용 효율성보다 복잡성과 비용이 증가하므로 적절하지 않습니다.",
    "SelectC": "두 VPC 간에 peering connection을 생성합니다. 양쪽 VPC에 route table 항목을 추가하고, peering connection의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.",
    "SelectC_Commentary": "VPC Peering 자체에는 별도의 security group이 없으므로 설정이 맞지 않습니다. ElastiCache cluster가 속한 security group에 규칙을 두어야 하므로 오답입니다.",
    "SelectD": "Transit VPC를 생성합니다. Cache VPC와 App VPC의 route table을 Transit VPC를 거치도록 설정하고, Transit VPC의 security group에 애플리케이션 security group에서 오는 인바운드를 허용합니다.",
    "SelectD_Commentary": "Transit VPC 구성이 필요해 추가 비용과 관리가 복잡해집니다. 단순 VPC Peering보다 운영 및 비용 면에서 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q860",
      "Q552",
      "Q42",
      "Q290",
      "Q773"
    ],
    "SelectA_recommedations": [
      "Q262",
      "Q860",
      "Q471"
    ],
    "SelectB_recommedations": [
      "Q262",
      "Q471",
      "Q937"
    ],
    "SelectC_recommedations": [
      "Q860",
      "Q374",
      "Q471"
    ],
    "SelectD_recommedations": [
      "Q471",
      "Q374",
      "Q250"
    ]
  },
  {
    "Question_Number": "Q263",
    "Question_Description": "한 기업이 여러 microservice로 구성된 애플리케이션을 만들고 있습니다. 이 기업은 container 기술을 사용하여 AWS에서 소프트웨어를 배포하기로 결정했습니다. 이 기업은 유지 관리와 확장을 위한 지속적인 노력을 최소화하는 솔루션이 필요합니다. 추가 인프라를 관리할 수 없습니다. 이러한 요구 사항을 충족하기 위해 solutions architect가 취해야 할 조치 조합은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95012-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컨테이너 기반 마이크로서비스 환경에서 인프라 관리 없이도 자동으로 확장 가능하고 유지 보수를 최소화할 수 있는 방법을 묻습니다. Amazon ECS와 Fargate launch type을 결합하면 서버 관리 걱정 없이 애플리케이션을 손쉽게 확장하고 운영 복잡성을 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "컨테이너",
      "유지 보수 최소화",
      "확장",
      "인프라 관리 불가",
      "Fargate"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "Kubernetes",
      "Amazon EC2",
      "Fargate",
      "Microservices"
    ],
    "SelectA": "Amazon Elastic Container Service (Amazon ECS) cluster를 배포합니다.",
    "SelectA_Commentary": "ECS cluster를 통해 컨테이너를 통합 관리할 수 있으며, Fargate와 결합하면 서버 관리 없이도 확장이 가능합니다.",
    "SelectB": "여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 Kubernetes control plane을 배포합니다.",
    "SelectB_Commentary": "Kubernetes control plane을 직접 운영하면 EC2 인스턴스 관리 부담이 커지므로 유지 보수 노력이 증가합니다.",
    "SelectC": "Amazon EC2 launch type을 사용하여 Amazon Elastic Container Service (Amazon ECS) service를 배포하고 작업 수를 2 이상으로 지정합니다.",
    "SelectC_Commentary": "EC2 launch type을 사용하면 기본 인스턴스 관리를 직접 해야 하므로, 추가 인프라 관리가 필요한 점이 문제 요구사항에 부합하지 않습니다.",
    "SelectD": "Fargate launch type을 사용하여 Amazon Elastic Container Service (Amazon ECS) service를 배포하고 작업 수를 2 이상으로 지정합니다.",
    "SelectD_Commentary": "Fargate launch type은 서버리스로 동작하여 인프라 관리를 제거하고 자동 확장이 가능해 요구사항에 가장 부합하는 솔루션입니다.",
    "SelectE": "여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에 Kubernetes worker node를 배포합니다. 각 microservice에 대해 두 개 이상의 replica를 지정하는 deployment를 생성합니다.",
    "SelectE_Commentary": "Kubernetes node 역시 EC2 인스턴스를 직접 관리해야 하므로 유지 보수와 스케일링 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q288",
      "Q181",
      "Q375",
      "Q323",
      "Q322"
    ],
    "SelectA_recommedations": [
      "Q900",
      "Q194",
      "Q563"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q198",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q900",
      "Q892",
      "Q602"
    ],
    "SelectD_recommedations": [
      "Q303",
      "Q698",
      "Q900"
    ],
    "SelectE_recommedations": [
      "Q721",
      "Q194",
      "Q198"
    ]
  },
  {
    "Question_Number": "Q264",
    "Question_Description": "한 회사가 10개의 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있고, Amazon Route 53으로 트래픽을 라우팅하고 있습니다. 회사는 애플리케이션에 접속하려고 시도할 때 가끔 타임아웃 오류가 발생합니다. 네트워크 팀은 일부 DNS 쿼리가 비정상 인스턴스의 IP 주소를 반환하여 타임아웃 오류가 생긴다는 점을 발견했습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 구현해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95345-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 비정상 EC2 인스턴스에도 트래픽이 라우팅되어 발생하는 타임아웃 오류를 해결하기 위한 고가용성 디자인을 요구합니다. Route 53의 단순 또는 페일오버 라우팅만으로는 모든 경우에 즉각적인 비정상 인스턴스 감지가 어려울 수 있습니다. ALB를 사용하면 자체적인 health check로 비정상 인스턴스를 제외하고 동적으로 트래픽을 분산할 수 있으므로 타임아웃 오류를 최소화하고 운영을 단순화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "타임아웃 오류",
      "DNS 쿼리",
      "비정상 인스턴스",
      "Route 53",
      "ALB"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Route 53",
      "Simple routing policy",
      "Failover routing policy",
      "Amazon CloudFront",
      "Application Load Balancer (ALB)",
      "health check"
    ],
    "SelectA": "각 EC2 인스턴스마다 Route 53 Simple Routing Policy 레코드를 생성하고, 각 레코드에 health check를 연결합니다.",
    "SelectA_Commentary": "단순 라우팅은 레코드별 헬스 체크로 제한적이어서, 인스턴스 증설이나 관리 면에서 복잡성이 높아집니다.",
    "SelectB": "각 EC2 인스턴스마다 Route 53 Failover Routing Policy 레코드를 생성하고, 각 레코드에 health check를 연결합니다.",
    "SelectB_Commentary": "Failover 라우팅은 주·보조 설정을 위해 적합하지만, 다수의 인스턴스 관리에는 복잡하고 탄력성이 떨어집니다.",
    "SelectC": "Amazon CloudFront 배포를 생성하고, EC2 인스턴스를 오리진으로 사용합니다. EC2 인스턴스에 health check를 연결합니다.",
    "SelectC_Commentary": "CloudFront는 글로벌 엣지 캐싱과 배포에 유리하지만, 인스턴스 헬스 체크로 인한 타임아웃 문제 해결에는 적합하지 않습니다.",
    "SelectD": "EC2 인스턴스 앞에 health check를 설정한 Application Load Balancer(ALB)를 생성하고, Route 53에서 ALB로 라우팅합니다.",
    "SelectD_Commentary": "ALB가 비정상 인스턴스를 health check로 분리해주어, 타임아웃 문제를 효과적으로 방지하고 고가용성을 구현합니다.",
    "Question_Description_recommedations": [
      "Q545",
      "Q627",
      "Q836",
      "Q195",
      "Q244"
    ],
    "SelectA_recommedations": [
      "Q242",
      "Q545",
      "Q264"
    ],
    "SelectB_recommedations": [
      "Q242",
      "Q545",
      "Q264"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q174",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q265",
    "Question_Description": "한 솔루션스 아키텍트가 웹, 애플리케이션, 데이터베이스 계층으로 구성된 고가용성 애플리케이션을 설계해야 합니다. HTTPS 콘텐츠는 가능한 한 에지(Edge)에 가깝게 배포되어 가장 짧은 전송 시간을 가져야 하며, 동시에 가장 안전해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95013-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹, 애플리케이션, 데이터베이스 계층을 안전하면서도 고가용성으로 구성하고, 에지(Edge)에 가까운 HTTPS 전송을 통해 지연 시간을 최소화해야 합니다. ALB와 EC2를 어디에 배치하느냐에 따라 보안 수준과 응답 속도가 달라집니다. 정답인 C는 Public ALB 뒤에 Private subnet의 EC2를 배치하여 직접 노출을 피하면서 CloudFront를 통해 글로벌 에지 전송을 지원해 고가용성과 보안을 모두 만족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "2.2"
    ],
    "Keywords": [
      "고가용성 애플리케이션",
      "웹·애플리케이션·데이터베이스 계층",
      "HTTPS 콘텐츠",
      "에지(Edge) 전송",
      "가장 안전한 솔루션"
    ],
    "Terms": [
      "Application Load Balancer (ALB)",
      "Amazon CloudFront",
      "Amazon EC2",
      "private subnets",
      "public subnets",
      "HTTPS",
      "고가용성",
      "에지(Edge)"
    ],
    "SelectA": "public Application Load Balancer (ALB)를 구성하고 여러 Amazon EC2 인스턴스를 public subnets에 배포합니다. Amazon CloudFront를 사용하여 public ALB를 오리진으로 HTTPS 콘텐츠를 전송합니다.",
    "SelectA_Commentary": "EC2 인스턴스가 public subnets에 위치하므로 인터넷에 직접 노출되어 보안 측면이 약화됩니다.",
    "SelectB": "public Application Load Balancer를 구성하고 여러 Amazon EC2 인스턴스를 private subnets에 배포합니다. Amazon CloudFront를 사용하여 EC2 인스턴스를 오리진으로 HTTPS 콘텐츠를 전송합니다.",
    "SelectB_Commentary": "CloudFront가 직접 EC2 인스턴스에 연결해야 하므로 추가적으로 EC2를 외부에 노출하는 설정이 필요하며, 관리 복잡도가 증가합니다.",
    "SelectC": "public Application Load Balancer (ALB)를 구성하고 여러 Amazon EC2 인스턴스를 private subnets에 배포합니다. Amazon CloudFront를 사용하여 public ALB를 오리진으로 HTTPS 콘텐츠를 전송합니다.",
    "SelectC_Commentary": "ALB만 Public subnet에 배치하고 EC2는 Private subnet에 격리하여 보안과 고가용성을 모두 달성하는 가장 안전하고 효율적인 방식입니다.",
    "SelectD": "public Application Load Balancer를 구성하고 여러 Amazon EC2 인스턴스를 public subnets에 배포합니다. Amazon CloudFront를 사용하여 EC2 인스턴스를 오리진으로 HTTPS 콘텐츠를 전송합니다.",
    "SelectD_Commentary": "EC2 인스턴스가 Public subnet에 존재하여 인터넷 노출 범위가 너무 커지고, 공격 표면이 확대됩니다.",
    "Question_Description_recommedations": [
      "Q803",
      "Q893",
      "Q564",
      "Q538",
      "Q592"
    ],
    "SelectA_recommedations": [
      "Q282",
      "Q60",
      "Q927"
    ],
    "SelectB_recommedations": [
      "Q60",
      "Q170",
      "Q927"
    ],
    "SelectC_recommedations": [
      "Q282",
      "Q60",
      "Q927"
    ],
    "SelectD_recommedations": [
      "Q60",
      "Q170",
      "Q927"
    ]
  },
  {
    "Question_Number": "Q266",
    "Question_Description": "한 회사가 AWS에서 인기 있는 게이밍 플랫폼을 운영 중입니다. 이 애플리케이션은 지연(latency)에 매우 민감하여, 지연이 사용자 경험에 영향을 미치거나 일부 플레이어에게 불공정한 이점을 줄 수 있습니다. 이 애플리케이션은 모든 AWS Region에 배포되어 있으며, Amazon EC2 인스턴스를 사용하고, Auto Scaling group에 속해 있으며 Application Load Balancer(ALB) 뒤에서 동작합니다. 솔루션스 아키텍트는 애플리케이션의 상태(health)를 모니터링하고 트래픽을 정상 동작 중인 엔드포인트(healthy endpoints)로 리다이렉트하는 메커니즘을 구현해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95014-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계로 배포된 게이밍 플랫폼의 지연을 최소화하고, 건강 상태를 모니터링해 정상적인 엔드포인트로 트래픽을 유도하는 고성능 네트워크 아키텍처 설계를 묻고 있습니다. AWS Global Accelerator를 사용하면 전역적으로 트래픽을 빠르고 안정적으로 라우팅할 수 있으며, 각 리전에 있는 ALB 상태를 확인해 자동으로 정상 엔드포인트로 연결함으로써 사용자 경험을 향상시킵니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "게이밍 플랫폼",
      "지연(latency) 민감",
      "AWS Region",
      "Application Load Balancer(ALB)",
      "정상 엔드포인트",
      "트래픽 리다이렉트",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "AWS Lambda",
      "Amazon S3",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon EC2",
      "Auto Scaling",
      "Application Load Balancer(ALB)"
    ],
    "SelectA": "AWS Global Accelerator에서 accelerator를 구성합니다. 애플리케이션이 사용하는 포트용 listener를 추가하고, 각 Region에 Regional endpoint를 등록합니다. ALB를 해당 endpoint로 추가합니다.",
    "SelectA_Commentary": "AWS Global Accelerator는 글로벌 Anycast IP로 트래픽을 받고, 상태 확인을 통해 가장 가까운 정상 엔드포인트로 라우팅해 지연을 줄이고 유연한 장애 조치가 가능합니다.",
    "SelectB": "Amazon CloudFront 배포를 생성하고 ALB를 오리진 서버로 지정합니다. 캐시 동작을 origin cache header로 설정합니다. AWS Lambda 함수를 사용해 트래픽을 최적화합니다.",
    "SelectB_Commentary": "CloudFront는 주로 정적 콘텐츠 캐싱과 전송 최적화용으로 적합하지만, 동적 애플리케이션 상태 모니터링과 리전별 즉각적인 라우팅을 구현하기에는 제약이 큽니다.",
    "SelectC": "Amazon CloudFront 배포를 생성하고 Amazon S3를 오리진 서버로 지정합니다. 캐시 동작을 origin cache header로 설정합니다. AWS Lambda 함수를 사용해 트래픽을 최적화합니다.",
    "SelectC_Commentary": "S3를 오리진으로 사용하면 정적 파일 배포에는 유리하나, 게임 서버의 실시간 동작 및 지연 모니터링에는 부적합하며 정상 엔드포인트 라우팅도 어렵습니다.",
    "SelectD": "Amazon DynamoDB를 애플리케이션의 데이터 스토어로 사용하도록 구성합니다. DynamoDB Accelerator(DAX) 클러스터를 만들어 인메모리 캐시로 사용합니다.",
    "SelectD_Commentary": "DynamoDB+DAX는 데이터 접근 속도를 높일 수 있지만 네트워크 트래픽을 건강 상태에 따라 전 세계적으로 라우팅하고 지연을 줄이는 데는 직접적인 도움을 주지 못합니다.",
    "Question_Description_recommedations": [
      "Q358",
      "Q461",
      "Q38",
      "Q141",
      "Q976"
    ],
    "SelectA_recommedations": [
      "Q266",
      "Q358",
      "Q597"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q358",
      "Q280"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q38",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q472",
      "Q578",
      "Q177"
    ]
  },
  {
    "Question_Number": "Q267",
    "Question_Description": "한 회사에 백만 명의 모바일 앱 사용자가 있습니다. 회사는 거의 실시간으로 데이터 사용량을 분석해야 합니다. 또한 데이터를 거의 실시간으로 암호화하고, 이후 분석을 위해 Apache Parquet 형식으로 데이터를 중앙 위치에 저장해야 합니다. 이 요구 사항을 최소의 운영 오버헤드로 충족할 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95347-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모바일 앱에서 발생하는 대량 데이터를 거의 실시간으로 암호화하고 분석하며, Parquet 형식으로 S3에 저장하는 저오버헤드 솔루션을 묻습니다. Kinesis Data Firehose와 Kinesis Data Analytics를 결합하면 서버 관리 부담을 최소화하고 실시간 처리 요구사항을 만족할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "모바일 앱",
      "실시간 분석",
      "암호화",
      "Apache Parquet",
      "중앙화 저장"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "Amazon EMR",
      "Amazon Kinesis Data Analytics",
      "AWS Lambda",
      "Amazon S3",
      "Apache Parquet"
    ],
    "SelectA": "Amazon Kinesis data stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 해당 데이터를 Kinesis Data Analytics 애플리케이션으로 전송합니다.",
    "SelectA_Commentary": "Kinesis Data Stream에 직접 데이터가 들어가기 때문에 실시간 처리는 가능하나, Kinesis Data Stream과 Kinesis Data Analytics를 연결하기 위해 Lambda 함수를 추가로 관리해야 하므로 오버헤드가 증가합니다.",
    "SelectB": "Amazon Kinesis data stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다. AWS Lambda 함수를 호출하여 EMR 클러스터로 데이터를 전송합니다.",
    "SelectB_Commentary": "EMR 클러스터를 직접 운영하고 Lambda 함수를 별도 호출해야 하므로 운영 복잡도가 높고 실시간 처리에도 비효율적입니다.",
    "SelectC": "Amazon Kinesis Data Firehose delivery stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon EMR 클러스터를 생성하여 데이터를 분석합니다.",
    "SelectC_Commentary": "Kinesis Data Firehose는 자동 암호화와 Parquet 변환을 지원하지만, EMR 클러스터 구성 및 관리가 추가되어 운영 오버헤드가 큽니다.",
    "SelectD": "Amazon Kinesis Data Firehose delivery stream을 생성하여 Amazon S3에 데이터를 저장합니다. Amazon Kinesis Data Analytics 애플리케이션을 생성하여 데이터를 분석합니다.",
    "SelectD_Commentary": "완전관리형 서비스인 Kinesis Data Firehose로 실시간 암호화 및 Parquet 변환이 가능하고, Kinesis Data Analytics로 별도 인프라 관리 없이 빠르게 분석할 수 있어 운영 오버헤드가 가장 적습니다.",
    "Question_Description_recommedations": [
      "Q506",
      "Q915",
      "Q132",
      "Q888",
      "Q158"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q515",
      "Q687"
    ],
    "SelectB_recommedations": [
      "Q402",
      "Q515",
      "Q687"
    ],
    "SelectC_recommedations": [
      "Q402",
      "Q515",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q402",
      "Q515",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q268",
    "Question_Description": "한 게임 회사는 점수를 표시하는 웹 애플리케이션을 운영하고 있습니다. 해당 웹 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 Amazon RDS for MySQL 데이터베이스에 데이터를 저장합니다. 사용자는 데이터베이스 읽기 성능 저하로 인해 지연이 길어지거나 중단이 발생하고 있습니다. 회사는 사용자 경험을 개선하면서 애플리케이션 아키텍처 변경을 최소화하고자 합니다. 이러한 요구 사항을 충족하기 위해 Solutions Architect는 어떤 조치를 취해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95016-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 MySQL 데이터베이스의 읽기 성능 문제로 인해 사용자 지연이 발생하는 상황에서, 기존 아키텍처 변경을 최소화하여 빠르게 읽기 성능을 개선하는 방안을 묻습니다. 캐싱 계층을 도입하면 DB 부하를 줄이고 빠른 응답을 제공할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "데이터베이스 읽기 성능",
      "사용자 경험 개선",
      "아키텍처 변경 최소화",
      "점수 표시 웹 애플리케이션"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon RDS for MySQL",
      "Amazon ElastiCache",
      "RDS Proxy",
      "AWS Lambda",
      "Amazon DynamoDB"
    ],
    "SelectA": "데이터베이스 앞단에 Amazon ElastiCache를 사용합니다.",
    "SelectA_Commentary": "ElastiCache를 활용해 자주 조회되는 데이터를 캐싱하면 DB의 읽기 부하가 줄어 응답 속도가 크게 향상되며, 전체 아키텍처 변경도 최소화됩니다.",
    "SelectB": "애플리케이션과 데이터베이스 사이에 RDS Proxy를 사용합니다.",
    "SelectB_Commentary": "RDS Proxy는 연결 관리와 보안을 개선하지만, 주로 연결 수 급증을 완화하는 역할이며 본질적인 읽기 성능 문제 해결에는 제한적입니다.",
    "SelectC": "애플리케이션을 EC2 인스턴스에서 AWS Lambda로 마이그레이션합니다.",
    "SelectC_Commentary": "Lambda로 이전해도 데이터베이스 읽기 성능 문제 자체는 해결되지 않으므로, 요구 사항을 충족하기 어렵습니다.",
    "SelectD": "Amazon RDS for MySQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.",
    "SelectD_Commentary": "관계형 DB에서 NoSQL로 전환은 아키텍처상의 큰 변경이며, 요구사항인 최소 변경과 어긋납니다.",
    "Question_Description_recommedations": [
      "Q261",
      "Q861",
      "Q561",
      "Q431",
      "Q819"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q501",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q706",
      "Q95",
      "Q77"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q361",
      "Q857"
    ],
    "SelectD_recommedations": [
      "Q376",
      "Q590",
      "Q386"
    ]
  },
  {
    "Question_Number": "Q269",
    "Question_Description": "한 전자상거래 회사의 Amazon RDS 기반 웹 애플리케이션에서 성능 저하가 감지되었습니다. 성능 저하의 원인은 비즈니스 분석가들이 실행하는 읽기 전용 SQL 쿼리 증가에 있습니다. 솔루션스 아키텍트는 기존 웹 애플리케이션에 최소한의 변경으로 이 문제를 해결해야 합니다. 어떤 솔루션을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95032-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "읽기 부하가 급증하여 RDS의 성능 저하가 발생합니다. 해결 방법으로는 읽기 전용 트래픽을 다른 대상에게 오프로드하는 것이 적합합니다. Read Replica를 사용하면 기본 DB에 미치는 영향 없이 분석 쿼리를 실행할 수 있어, 웹 애플리케이션 코드 변경 없이 쉽게 적용 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS",
      "읽기 전용 SQL 쿼리",
      "성능 저하",
      "기존 웹 애플리케이션",
      "최소 변경"
    ],
    "Terms": [
      "Amazon RDS",
      "Read Replica",
      "Amazon DynamoDB",
      "Amazon ElastiCache",
      "Amazon Redshift"
    ],
    "SelectA": "데이터를 Amazon DynamoDB로 내보내고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.",
    "SelectA_Commentary": "데이터 구조 변경 및 애플리케이션 로직 수정이 필요해 최소 변경 목표에 어긋납니다.",
    "SelectB": "데이터를 Amazon ElastiCache에 적재하고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.",
    "SelectB_Commentary": "ElastiCache는 캐시 서비스로 주로 빠른 조회용이며, SQL 쿼리 수행을 직접 지원하지 않는 등 사용 사례가 맞지 않습니다.",
    "SelectC": "기본 데이터베이스의 Read Replica를 생성하고 비즈니스 분석가들이 그 Replica에서 쿼리를 실행하도록 합니다.",
    "SelectC_Commentary": "읽기 전용 부하를 Replica로 오프로드하여 기본 DB의 성능 저하를 방지하며 최소한의 변경으로 구현 가능합니다.",
    "SelectD": "데이터를 Amazon Redshift 클러스터로 복사하고 비즈니스 분석가들이 그 데이터를 조회하게 합니다.",
    "SelectD_Commentary": "Redshift로의 마이그레이션에는 스키마 및 분석 워크플로우 변경이 필요해 최소 변경 요구사항에 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q661",
      "Q376",
      "Q590",
      "Q706",
      "Q193"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q888",
      "Q158",
      "Q506"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q557",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q270",
    "Question_Description": "한 회사가 중앙화된 AWS 계정을 사용하여 여러 Amazon S3 버킷에 로그 데이터를 저장하고 있습니다. 솔루션스 아키텍트는 데이터가 S3 버킷에 업로드되기 전에 암호화되도록 보장해야 하며, 또한 전송 중에도 암호화되어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95031-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 데이터를 업로드하기 전에 이미 암호화가 되어 있어야 하며(‘before the data is uploaded’), 업로드 중에도 암호화(SSL/TLS)로 보호되어야 함을 요구합니다. Server-side encryption은 객체가 S3에 도달한 후에 암호화됩니다. 따라서 요구사항을 만족하려면 Client-side encryption을 사용해 로컬에서 데이터를 암호화한 뒤 HTTPS로 전송해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "데이터 암호화",
      "전송 중 암호화",
      "업로드 전 암호화",
      "Client-side encryption",
      "Server-side encryption"
    ],
    "Terms": [
      "Amazon S3",
      "Client-side encryption",
      "Server-side encryption (SSE)",
      "SSE-S3",
      "AWS KMS"
    ],
    "SelectA": "S3 버킷에 업로드되는 데이터를 Client-side encryption으로 암호화합니다.",
    "SelectA_Commentary": "클라이언트 측에서 먼저 데이터를 암호화한 후 업로드하면 ‘업로드 전 암호화’와 전송 암호화를 모두 충족하므로 요구사항에 부합합니다.",
    "SelectB": "S3 버킷에 업로드되는 데이터를 Server-side encryption으로 암호화합니다.",
    "SelectB_Commentary": "Server-side encryption은 S3에 도착한 이후 암호화를 적용하므로, ‘업로드 전 암호화’ 요구사항과는 맞지 않습니다.",
    "SelectC": "SSE-S3를 반드시 사용하도록 버킷 정책을 생성하여 업로드하도록 합니다.",
    "SelectC_Commentary": "이 방법 역시 업로드 후 서버에서 암호화가 수행되므로, 사전에 암호화 상태로 업로드하는 요구사항을 만족하지 못합니다.",
    "SelectD": "기본 AWS KMS 키를 사용하여 S3 버킷 암호화를 활성화합니다.",
    "SelectD_Commentary": "AWS KMS를 통한 서버 측 암호화 또한 업로드 후 암호화되므로, ‘업로드 전’ 암호화 요구사항과 일치하지 않습니다.",
    "Question_Description_recommedations": [
      "Q412",
      "Q109",
      "Q202",
      "Q638",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q965",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q740",
      "Q678",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectD_recommedations": [
      "Q1009",
      "Q965",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q271",
    "Question_Description": "한 솔루션스 아키텍트가 야간에 실행되는 배치 처리 작업이 원하는 Amazon EC2 용량에 도달하기까지 자동으로 스케일업되는 데 1시간이 걸리는 것을 관찰했습니다. 최대 용량은 매일 밤 동일하며, 배치 작업은 항상 오전 1시에 시작됩니다. 솔루션스 아키텍트는 원하는 EC2 용량에 빠르게 도달하면서, 배치 작업이 완료된 후 Auto Scaling group이 스케일다운될 수 있도록 하는 비용 효율적인 솔루션을 찾아야 합니다. 이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/95018-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 일정한 시간(오전 1시)에 시작되는 배치 작업을 빠르게 처리하기 위해, 미리 원하는 EC2 용량에 도달하도록 스케줄 기반으로 Auto Scaling 설정을 최적화하는 방법을 묻습니다. 배치 작업이 끝나면 자동으로 스케일다운해 비용을 절감해야 합니다. 따라서 사전에 스케줄을 설정해 필요한 EC2 인스턴스를 즉시 확보하는 것이 가장 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "야간 배치 작업",
      "EC2 용량",
      "Auto Scaling group",
      "스케줄 기반 스케일링",
      "비용 효율"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "scheduled scaling",
      "minimum capacity",
      "maximum capacity",
      "scaling policy"
    ],
    "SelectA": "Auto Scaling group의 minimum capacity를 늘립니다.",
    "SelectA_Commentary": "minimum capacity만 늘리면 항상 비용이 들며 작업이 없을 때도 필요 이상의 인스턴스를 유지하게 되어 비효율적입니다.",
    "SelectB": "Auto Scaling group의 maximum capacity를 늘립니다.",
    "SelectB_Commentary": "maximum capacity는 상한 설정일 뿐, 빠르게 스케일업하는 것과 직결되지 않아 작업 시작 시점에 즉각적인 용량 확보가 어렵습니다.",
    "SelectC": "원하는 컴퓨팅 수준까지 스케일업하도록 scheduled scaling을 구성합니다.",
    "SelectC_Commentary": "배치 작업이 시작되기 전인 일정 시간에 맞춰 EC2 용량을 미리 늘려둘 수 있어, 빠른 작업 처리와 비용 효율을 모두 충족하는 정답입니다.",
    "SelectD": "각 스케일링 동작마다 더 많은 EC2 인스턴스를 추가하도록 스케일링 정책을 변경합니다.",
    "SelectD_Commentary": "정책 수정을 통해 더 빠른 스케일업이 가능할 수 있지만, 예상되는 부하 시간대가 명확하므로 scheduled scaling이 더 안정적이고 비용 효과적입니다.",
    "Question_Description_recommedations": [
      "Q581",
      "Q595",
      "Q1001",
      "Q660",
      "Q210"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q149",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q584",
      "Q252",
      "Q757"
    ]
  },
  {
    "Question_Number": "Q272",
    "Question_Description": "한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스 풀에서 동적 웹사이트를 제공하고 있습니다. 이 웹사이트는 전 세계 고객에게 다중 언어를 지원해야 하며, 현재 us-west-1 리전에서만 운영되어 다른 지역 사용자에게 높은 지연 시간이 발생하고 있습니다. 사용자의 위치와 관계없이 빠르고 효율적인 응답 속도를 제공해야 하지만, 여러 리전에 기존 아키텍처를 재구성하고 싶지는 않습니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99865-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "멀리 떨어진 사용자는 웹 요청 시 레이턴시가 증가합니다. ALB 뒤의 EC2 환경을 유지하면서 CloudFront를 사용해 전 세계 엣지 네트워크에서 콘텐츠를 캐싱하면, 다중 리전 재구성 없이 지연 시간을 크게 단축하고 Accept-Language 헤더 기준으로 다국어 캐싱도 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "동적 웹사이트",
      "글로벌 사용자",
      "다중 언어 지원",
      "지연 시간 단축",
      "기존 아키텍처 유지",
      "Amazon CloudFront",
      "Accept-Language"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Amazon CloudFront",
      "Accept-Language",
      "Amazon S3",
      "Amazon API Gateway",
      "NGINX",
      "Amazon Route 53",
      "Geolocation routing",
      "HTTP integration",
      "API Gateway cache",
      "CloudFront distribution",
      "cache behavior",
      "S3 bucket"
    ],
    "SelectA": "기존 아키텍처를 Amazon S3에서 호스팅되는 웹사이트로 교체하고, Amazon S3 버킷을 오리진으로 하는 Amazon CloudFront distribution을 설정한 뒤, Accept-Language 요청 헤더를 기준으로 캐시를 구성합니다.",
    "SelectA_Commentary": "S3 정적 호스팅으로 전환하면 동적 웹사이트의 기존 구조가 사라질 수 있어 요구사항을 만족하지 못합니다.",
    "SelectB": "ALB를 오리진으로 하는 Amazon CloudFront distribution을 구성하고, Accept-Language 요청 헤더를 기준으로 캐시 동작(cache behavior)을 설정합니다.",
    "SelectB_Commentary": "기존 ALB 뒤 EC2 아키텍처를 유지하면서 CloudFront로 글로벌 캐싱 및 다국어 지원을 구현하는 최적의 방법입니다.",
    "SelectC": "ALB와 연동된 Amazon API Gateway API를 생성하고, HTTP 통합 방식을 사용하도록 구성합니다. 그리고 Accept-Language 요청 헤더를 기반으로 API 캐시를 활성화합니다.",
    "SelectC_Commentary": "API Gateway를 거치는 구성은 불필요한 복잡성을 일으키며 CloudFront만큼 효율적이지 않습니다.",
    "SelectD": "각 추가 리전에 EC2 인스턴스를 실행하고, 해당 리전에서 NGINX를 캐시 서버로 구성합니다. 모든 EC2 인스턴스와 ALB를 Amazon Route 53 지리 위치 라우팅(geolocation) 정책으로 연결합니다.",
    "SelectD_Commentary": "각 리전에 인프라를 배포하기 때문에 회사가 원치 않는 다중 리전 아키텍처가 되어 운영 부담이 늘어납니다.",
    "Question_Description_recommedations": [
      "Q141",
      "Q358",
      "Q12",
      "Q815",
      "Q14"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q672",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q280",
      "Q141"
    ],
    "SelectC_recommedations": [
      "Q576",
      "Q597",
      "Q141"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q12",
      "Q530"
    ]
  },
  {
    "Question_Number": "Q273",
    "Question_Description": "한 빠르게 성장하는 전자상거래 회사가 현재 단일 AWS 리전에서 워크로드를 운영하고 있습니다. 이제 다른 AWS 리전을 포함하는 재해 복구(Disaster Recovery, DR) 전략을 마련해야 합니다. 솔루션스 아키텍트는 DR 리전에서도 최소 지연으로 최신 상태의 데이터베이스를 유지해야 하며, DR 리전의 나머지 인프라는 축소된 용량으로 가동되지만 필요할 경우 확장 가능해야 합니다. 이러한 요구사항을 만족하면서 가장 낮은 RTO(복구 시간 목표)를 보장하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99505-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DR(재해 복구) 환경에서 데이터베이스를 최신 상태로 유지하고, 필요 시 빠르게 서비스를 재개하는 방법을 묻습니다. Aurora Global Database는 리전 간 복제를 통해 지연을 최소화하며, Warm Standby 방식은 이미 핵심 서비스를 DR 리전에 미리 배치해 두어 RTO를 낮출 수 있습니다. Pilot Light보다 Warm Standby가 더 빠른 전환이 가능하며, Multi-AZ 옵션은 동일 리전 내 고가용성만 보장할 뿐 다른 리전에서의 즉각적인 복구 기능은 제한적입니다. 따라서 최소 지연 및 신속한 확장을 위해 Amazon Aurora global database와 Warm Standby를 조합하는 것이 최적의 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "재해 복구",
      "최소 지연",
      "낮은 RTO",
      "Aurora global database",
      "파일럿 라이트",
      "웜 스탠바이"
    ],
    "Terms": [
      "Amazon Aurora global database",
      "Pilot light deployment",
      "Warm standby deployment",
      "Amazon RDS Multi-AZ DB instance",
      "RTO",
      "DR(Disaster Recovery)",
      "Region",
      "Scale up",
      "RPO"
    ],
    "SelectA": "Amazon Aurora global database를 파일럿 라이트(pilot light) 방식으로 구성합니다.",
    "SelectA_Commentary": "Aurora Global Database는 지연을 줄일 수 있지만, 파일럿 라이트는 추가 설정이 필요해 RTO가 더 길어집니다.",
    "SelectB": "Amazon Aurora global database를 웜 스탠바이(warm standby) 방식으로 구성합니다.",
    "SelectB_Commentary": "DR 리전에 이미 핵심 리소스가 가동 중이며, Aurora Global Database 덕분에 지연이 최소화되어 가장 짧은 RTO를 달성합니다.",
    "SelectC": "Amazon RDS Multi-AZ DB 인스턴스를 파일럿 라이트(pilot light) 방식으로 구성합니다.",
    "SelectC_Commentary": "Multi-AZ는 동일 리전 내 장애 대비용으로, 다른 리전에서는 직접 복구 과정이 필요해 DR 관점에서 RTO가 길어집니다.",
    "SelectD": "Amazon RDS Multi-AZ DB 인스턴스를 웜 스탠바이(warm standby) 방식으로 구성합니다.",
    "SelectD_Commentary": "다른 리전에서도 일부 리소스를 가동해 두지만, Aurora Global Database에 비해 지연 및 RTO 개선 효과가 제한됩니다.",
    "Question_Description_recommedations": [
      "Q274",
      "Q539",
      "Q133",
      "Q896",
      "Q343"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q194",
      "Q293"
    ],
    "SelectB_recommedations": [
      "Q462",
      "Q843",
      "Q768"
    ],
    "SelectC_recommedations": [
      "Q958",
      "Q466",
      "Q390"
    ],
    "SelectD_recommedations": [
      "Q466",
      "Q958",
      "Q518"
    ]
  },
  {
    "Question_Number": "Q274",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 회사는 애플리케이션에 대한 Disaster Recovery(DR) 솔루션을 구현해야 합니다. DR 솔루션은 4시간 미만의 Recovery Time Objective(RTO)를 충족해야 하며, 평상시에는 가능한 한 적은 수의 AWS 리소스를 사용해야 합니다. 이러한 요구사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스 기반 애플리케이션의 DR 전략 중, 4시간 미만 RTO 달성과 평시 AWS 리소스 최소 사용이 핵심입니다. AMI를 사용해 백업을 유지하고, 필요 시 자동으로 해당 이미지를 사용해 재빨리 인프라를 복원할 수 있도록 설계하는 방안이 요구됩니다. 특히 AWS CloudFormation으로 자동화를 구성하면 인프라를 신속하게 프로비저닝하여 RTO를 효율적으로 만족시킬 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DR 솔루션",
      "Amazon EC2",
      "RTO 4시간 미만",
      "AWS 리소스 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Disaster Recovery(DR)",
      "Recovery Time Objective(RTO)",
      "Amazon Machine Images(AMIs)",
      "AWS Region",
      "AWS Lambda",
      "AWS CloudFormation",
      "Availability Zone"
    ],
    "SelectA": "Amazon EC2 인스턴스를 백업하기 위해 Amazon Machine Images(AMIs)를 생성합니다. 이 AMI들을 보조 AWS Region으로 복사합니다. AWS Lambda와 사용자 지정 스크립트를 사용하여 보조 Region에서 인프라 배포를 자동화합니다.",
    "SelectA_Commentary": "Lambda와 커스텀 스크립트를 사용하는 방법도 가능하나, CloudFormation에 비해 표준화와 유지보수 측면에서 복잡도가 높을 수 있습니다.",
    "SelectB": "Amazon EC2 인스턴스를 백업하기 위해 Amazon Machine Images(AMIs)를 생성합니다. 이 AMI들을 보조 AWS Region으로 복사합니다. AWS CloudFormation을 사용하여 보조 Region에서 인프라 배포를 자동화합니다.",
    "SelectB_Commentary": "AMI를 통해 백업을 간단히 유지하면서, 필요 시 CloudFormation 템플릿으로 빠른 인프라 재구성을 할 수 있어 4시간 미만의 RTO와 운영 효율, 그리고 리소스 최소화를 모두 달성할 수 있습니다. (정답)",
    "SelectC": "보조 AWS Region에 Amazon EC2 인스턴스를 시작합니다. 이 보조 Region의 EC2 인스턴스를 항상 활성 상태로 유지합니다.",
    "SelectC_Commentary": "DR이 아닌 멀티-Region 활성 상태로 운영하게 되므로 평시 리소스 비용이 크게 증가합니다. RTO는 만족해도 요구사항인 ‘AWS 리소스 최소화’를 충족하지 못합니다.",
    "SelectD": "보조 Availability Zone에 Amazon EC2 인스턴스를 시작합니다. 이 보조 AZ의 EC2 인스턴스를 항상 활성 상태로 유지합니다.",
    "SelectD_Commentary": "Region 단위 재해에 대응하기 어렵고, 인스턴스를 항상 구동해야 하므로 평시 비용이 높습니다. DR 요구사항을 충족하기에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q273",
      "Q475",
      "Q539",
      "Q588",
      "Q585"
    ],
    "SelectA_recommedations": [
      "Q762",
      "Q456",
      "Q224"
    ],
    "SelectB_recommedations": [
      "Q762",
      "Q456",
      "Q224"
    ],
    "SelectC_recommedations": [
      "Q456",
      "Q47",
      "Q224"
    ],
    "SelectD_recommedations": [
      "Q47",
      "Q987",
      "Q570"
    ]
  },
  {
    "Question_Number": "Q275",
    "Question_Description": "한 회사는 내부 브라우저 기반 애플리케이션을 운영하고 있으며, 이 애플리케이션은 Application Load Balancer 뒤에서 동작하는 Amazon EC2 인스턴스에서 구동됩니다. 인스턴스들은 여러 Availability Zone에 분산된 Amazon EC2 Auto Scaling group에서 실행되며, 근무 시간 중에는 최대 20개의 인스턴스로 스케일 업하고, 야간에는 2개의 인스턴스로 스케일 다운합니다. 직원들은 업무 시작 시 애플리케이션이 매우 느려서 불편을 겪지만, 오전 중반이 되면 정상 속도로 작동한다고 보고합니다. 직원들의 불만을 해결하면서도 비용을 최소화하기 위해 스케일링 설정을 어떻게 변경해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99584-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2 Auto Scaling 그룹을 활용해 아침 시간의 지연 문제를 해결하면서도 불필요한 인스턴스 비용을 줄이는 방법을 묻습니다. Target Tracking Scaling은 특정 지표(예: CPU 사용률)를 기반으로 즉각적인 확장을 제공해 성능 저하가 발생하기 전에 충분한 인스턴스를 확보하며, 부하가 줄면 자동으로 스케일 다운하여 비용을 절감합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Auto Scaling 그룹",
      "Application Load Balancer",
      "Amazon EC2 인스턴스",
      "근무 시간",
      "야간 스케일 다운",
      "Target Tracking",
      "CPU 임계값",
      "Cooldown 기간",
      "비용 절감"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon EC2 Auto Scaling group",
      "Availability Zone",
      "Scheduled Action",
      "Step Scaling",
      "Target Tracking",
      "Cooldown period",
      "Desired Capacity",
      "Minimum Capacity",
      "Maximum Capacity"
    ],
    "SelectA": "사무실이 열리기 직전에 Desired Capacity를 20으로 설정하는 Scheduled Action을 구현합니다.",
    "SelectA_Commentary": "아침 지연 문제는 해결되지만, 하루 종일 20개 인스턴스를 유지해 오히려 비용이 증가할 수 있습니다.",
    "SelectB": "더 낮은 CPU 임계값에서 트리거되는 Step Scaling 액션을 구현하고, Cooldown 기간을 단축합니다.",
    "SelectB_Commentary": "Step Scaling은 임계값 범위를 세밀히 설정해야 하며, 부하 패턴 변화에 즉각 대응하기가 어렵고 관리가 복잡합니다.",
    "SelectC": "더 낮은 CPU 임계값에서 트리거되는 Target Tracking 액션을 구현하고, Cooldown 기간을 줄입니다.",
    "SelectC_Commentary": "Target Tracking은 설정한 지표 수준에 맞춰 자동으로 확장·축소하므로 아침 부하를 빠르게 처리하고, 부하가 감소하면 자동으로 줄여 비용을 절감할 수 있습니다.",
    "SelectD": "사무실이 열리기 직전에 Scheduled Action으로 Minimum Capacity와 Maximum Capacity를 모두 20으로 설정합니다.",
    "SelectD_Commentary": "인스턴스를 20개로 고정해 두어 운영하며, 부하가 줄어도 스케일 다운이 불가능해 오히려 비용이 크게 상승합니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q691",
      "Q69",
      "Q174",
      "Q298"
    ],
    "SelectA_recommedations": [
      "Q183",
      "Q362",
      "Q845"
    ],
    "SelectB_recommedations": [
      "Q363",
      "Q664",
      "Q52"
    ],
    "SelectC_recommedations": [
      "Q363",
      "Q664",
      "Q252"
    ],
    "SelectD_recommedations": [
      "Q362",
      "Q183",
      "Q7"
    ]
  },
  {
    "Question_Number": "Q276",
    "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스를 Auto Scaling 그룹으로 구성하여 다중 계층 애플리케이션을 운영하고 있습니다. 데이터 계층으로 Amazon RDS for Oracle을 사용하며, Oracle 전용 PL/SQL 함수를 활용합니다. 애플리케이션으로 유입되는 트래픽이 꾸준히 증가하여 EC2 인스턴스는 과부하 상태가 되고, RDS 인스턴스는 스토리지가 부족해지고 있습니다. 현재 Auto Scaling 그룹에는 별도의 스케일링 지표가 없으며 최소 정상 인스턴스 수만 정의되어 있습니다. 회사 측은 트래픽이 계속 일정하면서도 예측 불가능한 비율로 증가하다가 결국 안정화될 것으로 예상합니다. 증가한 트래픽에 대비해 시스템이 자동으로 확장되도록 하려면 어떻게 해야 합니까? (두 가지를 선택하십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99739-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 갑작스럽게 늘어나는 트래픽 상황에서 EC2와 RDS 인스턴스 모두 확장 가능하도록 설정해야 하는 시나리오입니다. RDS for Oracle에 Storage Auto Scaling을 적용하면 스토리지 공간 부족 문제를 자동으로 해결할 수 있으며, Auto Scaling 그룹에 올바른 지표(예: CPU 사용률)를 설정하면 인스턴스가 과부하 전에 늘어나도록 유연하게 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Auto Scaling 그룹",
      "Amazon RDS for Oracle",
      "Oracle 전용 PL/SQL",
      "스토리지 부족",
      "꾸준히 증가하는 트래픽",
      "자동 확장"
    ],
    "Terms": [
      "Auto Scaling group",
      "Amazon RDS for Oracle",
      "Amazon Aurora",
      "PL/SQL",
      "Storage Auto Scaling",
      "CloudWatch Alarm",
      "Average CPU",
      "Average Free Memory"
    ],
    "SelectA": "RDS for Oracle 인스턴스에 Storage Auto Scaling을 구성합니다.",
    "SelectA_Commentary": "RDS 스토리지가 부족해질 경우 자동으로 확장하도록 설정해둠으로써 공간 문제를 근본적으로 해결할 수 있는 올바른 선택입니다.",
    "SelectB": "Auto Scaling 스토리지를 사용하기 위해 데이터베이스를 Amazon Aurora로 마이그레이션합니다.",
    "SelectB_Commentary": "Oracle 전용 PL/SQL 함수를 사용하므로 Aurora로 이전하면 호환성 문제가 발생합니다. 요구사항에 부합하지 않는 선택입니다.",
    "SelectC": "RDS for Oracle 인스턴스의 유휴 스토리지가 부족할 때 경보가 울리도록 설정합니다.",
    "SelectC_Commentary": "단순 알람 설정으로는 스토리지 부족 상태가 해결되지 않으며 자동 확장을 보장하지 못합니다.",
    "SelectD": "Auto Scaling 그룹이 평균 CPU 사용률을 스케일링 지표로 사용하도록 구성합니다.",
    "SelectD_Commentary": "CPU 활용도는 인스턴스 부담 정도를 대표하는 핵심 지표입니다. 과부하 전 자동으로 확장하기 적절한 선택입니다.",
    "SelectE": "Auto Scaling 그룹이 평균 유휴 메모리를 스케일링 지표로 사용하도록 구성합니다.",
    "SelectE_Commentary": "메모리가 아니라 CPU 사용률이 주요 과부하 지표이므로, 이 선택은 상대적으로 덜 적합합니다.",
    "Question_Description_recommedations": [
      "Q210",
      "Q581",
      "Q195",
      "Q67",
      "Q595"
    ],
    "SelectA_recommedations": [
      "Q978",
      "Q276",
      "Q518"
    ],
    "SelectB_recommedations": [
      "Q1001",
      "Q595",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q978",
      "Q518",
      "Q629"
    ],
    "SelectD_recommedations": [
      "Q1001",
      "Q595",
      "Q8"
    ],
    "SelectE_recommedations": [
      "Q1001",
      "Q595",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q277",
    "Question_Description": "한 회사가 온라인 비디오 게시 및 이를 모든 모바일 플랫폼에서 사용할 수 있도록 트랜스코딩하는 서비스를 제공합니다. 애플리케이션 아키텍처는 Amazon EFS Standard를 사용하여 비디오를 수집하고 저장하며, 여러 Amazon EC2 Linux 인스턴스가 이 비디오 콘텐츠에 액세스하여 처리합니다. 시간이 지남에 따라 서비스가 인기를 얻으면서 스토리지 비용이 너무 비싸졌습니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99509-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 비디오 파일 저장에 발생하는 높은 비용을 줄이기 위한 방안을 묻습니다. 사용 빈도가 낮은 데이터는 Amazon S3에 저장하고, 처리 시에만 Amazon EBS를 활용하여 비용 부담을 크게 낮출 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "온라인 비디오 서비스",
      "트랜스코딩",
      "스토리지 비용",
      "Amazon EFS",
      "Amazon S3"
    ],
    "Terms": [
      "Amazon EFS",
      "Amazon EC2",
      "Linux",
      "AWS Storage Gateway",
      "Amazon S3",
      "Amazon Elastic Block Store (Amazon EBS)"
    ],
    "SelectA": "AWS Storage Gateway for files를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.",
    "SelectA_Commentary": "파일 게이트웨이는 온프레미스 환경과 AWS를 연결하는 데 주로 쓰이며, 장기 스토리지로 사용하기에는 적합하지 않아 비용 효율성을 기대하기 어렵습니다.",
    "SelectB": "AWS Storage Gateway for volumes를 사용하여 비디오 콘텐츠를 저장하고 처리합니다.",
    "SelectB_Commentary": "볼륨 게이트웨이는 블록 스토리지 형식으로 온프레미스에서 AWS로 데이터를 이전할 때 주로 사용되며, 이 역시 장기 스토리지로 활용하기에는 적합하지 않습니다.",
    "SelectC": "비디오 콘텐츠를 Amazon EFS에 저장합니다. 처리 완료 후 파일을 Amazon EBS로 전송합니다.",
    "SelectC_Commentary": "EFS를 계속 사용하면 비용이 높게 유지됩니다. 처리 후 EBS로 옮기더라도 S3보다 비용 효율이 떨어집니다.",
    "SelectD": "비디오 콘텐츠를 Amazon S3에 저장합니다. 처리 시에는 서버에 연결된 Amazon EBS 볼륨으로 임시로 옮겨서 처리합니다.",
    "SelectD_Commentary": "장기 저장은 Amazon S3가 가장 저렴하고, 필요한 시점에만 EBS를 사용해 파일을 처리하므로 비용과 운영 편의성 모두 충족시킵니다.",
    "Question_Description_recommedations": [
      "Q238",
      "Q671",
      "Q822",
      "Q167",
      "Q221"
    ],
    "SelectA_recommedations": [
      "Q300",
      "Q728",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q486",
      "Q943",
      "Q485"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q1003",
      "Q911",
      "Q993"
    ]
  },
  {
    "Question_Number": "Q278",
    "Question_Description": "한 회사가 계층적으로 구조화된 관계로 사원 데이터를 저장할 애플리케이션을 구축하려고 합니다. 이 회사는 대규모 트래픽이 발생하는 쿼리에 대해 최소 지연 시간으로 응답해야 하며, 민감한 데이터를 보호해야 합니다. 또한 사원 데이터 중 재무 정보가 포함되어 있는 경우 매달 이메일 메시지를 받아야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 취해야 할 단계 조합은 무엇입니까? (2개를 선택하십시오.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99940-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 구조적으로 계층화된 데이터를 빠르게 조회해야 하며, 동시에 민감한 정보(재무 데이터 등)의 보안을 유지하려는 요구 사항을 다룹니다. Amazon DynamoDB는 고성능의 NoSQL DB로 계층적 구조를 효율적으로 처리하고 트래픽이 많은 읽기·쓰기 워크로드를 최소 지연 시간으로 처리합니다. Amazon Macie는 저장된 데이터 중 민감한 정보를 찾아내고, 그 결과를 EventBridge에서 SNS 등으로 알림을 보낼 수 있어, 월별 보고 요구 사항을 충족합니다. 따라서 DynamoDB로 실시간 고성능 처리를 담당하면서, Macie를 통해 민감 데이터 식별과 알림을 자동화하는 접근이 최적의 조합입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3"
    ],
    "Keywords": [
      "계층적 데이터",
      "최소 지연 시간",
      "민감한 데이터 보호",
      "재무 정보",
      "월별 알림"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Amazon Redshift",
      "Amazon Macie",
      "Amazon EventBridge",
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon SNS",
      "Export to Amazon S3"
    ],
    "SelectA": "Amazon Redshift를 사용하여 계층 구조로 사원 데이터를 저장합니다. 매달 Amazon S3로 데이터를 Unload합니다.",
    "SelectA_Commentary": "Amazon Redshift는 대규모 데이터웨어하우징에 적합하지만, 빠른 단일 레코드 조회와 계층적 구조를 위해서는 DynamoDB가 더 적합합니다.",
    "SelectB": "Amazon DynamoDB를 사용하여 계층 구조로 사원 데이터를 저장합니다. 매달 Amazon S3로 데이터를 Export합니다.",
    "SelectB_Commentary": "DynamoDB는 고성능으로 계층적 데이터를 처리할 수 있고, Export to Amazon S3 기능을 통해 사원 데이터를 정기적으로 백업하거나 분석용으로 옮길 수 있습니다.",
    "SelectC": "AWS 계정에 Amazon Macie를 구성합니다. Macie를 Amazon EventBridge와 연동하여 매달 이벤트를 AWS Lambda로 전송합니다.",
    "SelectC_Commentary": "Macie로 민감 정보 식별은 가능하지만, Lambda를 통한 알림보다는 SNS를 통한 직접 알림이 월별 이메일 요구사항에 더 적합합니다.",
    "SelectD": "Amazon S3에 있는 사원 데이터를 Amazon Athena로 분석합니다. Athena를 Amazon QuickSight와 연동하여 분석 대시보드를 게시하고 사용자와 공유합니다.",
    "SelectD_Commentary": "데이터 분석과 대시보드 공유에는 유용하지만, 실시간 최소 지연 처리와 민감 정보 보호 요구사항을 동시에 만족하기에는 부족합니다.",
    "SelectE": "AWS 계정에 Amazon Macie를 구성합니다. Macie를 Amazon EventBridge와 연동하여 매달 Amazon Simple Notification Service(Amazon SNS) 구독을 통해 알림을 전송합니다.",
    "SelectE_Commentary": "Macie가 재무 등 민감 정보 여부를 식별하고, EventBridge를 통해 월별 SNS 알림을 자동화할 수 있어 보안·알림 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q915",
      "Q158",
      "Q132",
      "Q506",
      "Q888"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q515",
      "Q335"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q173",
      "Q292"
    ],
    "SelectE_recommedations": [
      "Q305",
      "Q249",
      "Q335"
    ]
  },
  {
    "Question_Number": "Q279",
    "Question_Description": "한 회사는 Amazon DynamoDB 테이블로 뒷받침되는 애플리케이션을 운영하고 있습니다. 이 회사의 컴플라이언스 요구 사항에 따라 데이터베이스 백업은 매달 진행되어야 하며, 6개월간 사용 가능해야 하고, 7년간 보관되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99793-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB 테이블의 정기 백업 및 장기 보존 정책을 어떻게 구현할지 묻습니다. 컴플라이언스 준수를 위해 매달 백업, 6개월간 접근 가능, 그리고 7년 보관이 필요합니다. AWS Backup을 사용하면 백업 일정을 손쉽게 관리하고, 라이프사이클을 지정해 cold storage로 전환하며, 장기 보존까지 자동화할 수 있습니다. 이는 추가 스크립트 작성이나 S3 Glacier 전환처럼 복잡한 절차 없이 간단히 대응 가능하므로 운영 부담을 크게 줄여줍니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "DynamoDB",
      "컴플라이언스 요구 사항",
      "매달 백업",
      "6개월 유지",
      "7년 보존",
      "AWS Backup",
      "cold storage",
      "라이프사이클 정책"
    ],
    "Terms": [
      "AWS Backup",
      "DynamoDB on-demand backup",
      "Amazon S3 Glacier Flexible Retrieval",
      "cold storage",
      "retention period",
      "Amazon EventBridge",
      "AWS SDK",
      "AWS CLI",
      "라이프사이클 정책",
      "cron expression"
    ],
    "SelectA": "매달 첫 번째 날에 DynamoDB 테이블 백업을 진행하도록 AWS Backup 계획을 생성합니다. 6개월 후 백업이 cold storage로 전환되도록 라이프사이클 정책을 지정하고, 각 백업의 보존 기간을 7년으로 설정합니다.",
    "SelectA_Commentary": "AWS Backup만으로 백업 일정, cold storage 전환, 7년 보존을 모두 자동화하여 간단하며 안정적으로 컴플라이언스를 충족합니다.",
    "SelectB": "매달 첫 번째 날에 DynamoDB 테이블의 DynamoDB 온디맨드 백업을 생성합니다. 6개월 후에 백업을 Amazon S3 Glacier Flexible Retrieval로 전환합니다. 7년보다 오래된 백업을 삭제하기 위해 S3 라이프사이클 정책을 생성합니다.",
    "SelectB_Commentary": "DynamoDB 백업을 직접 S3 Glacier로 전환하는 것은 네이티브 기능이 아니므로 적용이 어렵고, 별도의 관리가 필요하여 적합하지 않습니다.",
    "SelectC": "AWS SDK를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성하는 스크립트를 개발합니다. 매달 첫 번째 날에 이 스크립트가 실행되도록 Amazon EventBridge 규칙을 설정합니다. 6개월보다 오래된 DynamoDB 백업을 cold storage로 전환하고 7년보다 오래된 백업을 삭제하기 위해 매달 두 번째 날에 실행되는 두 번째 스크립트를 작성합니다.",
    "SelectC_Commentary": "사용자 정의 스크립트, 일정 규칙, 2단계 관리가 모두 필요해 복잡도가 높고 오류 가능성이 커서 효율적이지 못합니다.",
    "SelectD": "AWS CLI를 사용하여 DynamoDB 테이블의 온디맨드 백업을 생성합니다. cron 표현식을 사용하여 매달 첫 번째 날에 해당 명령이 실행되도록 Amazon EventBridge 규칙을 설정합니다. 명령에서 6개월 후 백업을 cold storage로 전환하고 7년 후 백업을 삭제하도록 지정합니다.",
    "SelectD_Commentary": "CLI와 EventBridge로 구현은 가능하지만 여전히 스크립트 기반이며, AWS Backup을 활용하는 것에 비해 운영 부담이 크고 관리가 까다롭습니다.",
    "Question_Description_recommedations": [
      "Q727",
      "Q176",
      "Q204",
      "Q521",
      "Q856"
    ],
    "SelectA_recommedations": [
      "Q279",
      "Q176",
      "Q727"
    ],
    "SelectB_recommedations": [
      "Q279",
      "Q1007",
      "Q176"
    ],
    "SelectC_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q176",
      "Q727"
    ]
  },
  {
    "Question_Number": "Q280",
    "Question_Description": "한 회사가 웹사이트에 Amazon CloudFront를 사용하고 있으며 CloudFront distribution에서 로깅을 활성화하고 있습니다. 이 로깅 데이터는 회사의 Amazon S3 버킷 중 하나에 저장됩니다. 이 회사는 이 로그에 대해 고급 분석을 수행하고 시각화도 구축해야 합니다. 이러한 요구사항을 충족하기 위해서는 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99508-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudFront 로깅 데이터를 S3에 저장한 뒤, 그 데이터를 분석하고 시각화하는 방법을 묻습니다. Athena는 S3에 저장된 데이터를 표준 SQL로 분석할 수 있는 서비스이고, QuickSight는 시각화 도구로 적합합니다. 따라서 Athena로 로그를 분석하고 QuickSight로 시각화하는 것이 운영 부담을 줄이며 효율적인 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "Amazon CloudFront",
      "로그",
      "Amazon S3",
      "고급 분석",
      "시각화",
      "Amazon Athena",
      "Amazon QuickSight"
    ],
    "Terms": [
      "Amazon CloudFront",
      "CloudFront distribution",
      "Amazon S3",
      "Amazon Athena",
      "AWS Glue",
      "Amazon QuickSight",
      "Amazon DynamoDB"
    ],
    "SelectA": "S3 버킷에 저장된 CloudFront 로그를 Amazon Athena에서 표준 SQL 쿼리로 분석하고, 결과를 AWS Glue로 시각화합니다.",
    "SelectA_Commentary": "AWS Glue는 ETL 작업과 Data Catalog에 특화되어 있으며, 시각화 도구로 사용하기에는 적합하지 않습니다.",
    "SelectB": "S3 버킷에 저장된 CloudFront 로그를 Amazon Athena에서 표준 SQL 쿼리로 분석하고, 결과를 Amazon QuickSight로 시각화합니다.",
    "SelectB_Commentary": "정답입니다. Athena를 통해 로그를 쉽게 분석하고, QuickSight를 활용하면 간편하게 보고서나 대시보드를 만들 수 있습니다.",
    "SelectC": "S3 버킷에 저장된 CloudFront 로그를 Amazon DynamoDB의 표준 SQL 쿼리로 분석하고, 결과를 AWS Glue로 시각화합니다.",
    "SelectC_Commentary": "DynamoDB는 NoSQL 데이터베이스로, S3에 저장된 로그를 직접 SQL로 분석하기 어렵고 Glue는 시각화 도구가 아닙니다.",
    "SelectD": "S3 버킷에 저장된 CloudFront 로그를 Amazon DynamoDB의 표준 SQL 쿼리로 분석하고, 결과를 Amazon QuickSight로 시각화합니다.",
    "SelectD_Commentary": "DynamoDB는 S3에 저장된 로그 분석용으로 적합하지 않으며, Athena가 제공하는 편의성과 확장성을 얻기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q155",
      "Q672",
      "Q547",
      "Q43"
    ],
    "SelectA_recommedations": [
      "Q292",
      "Q38",
      "Q280"
    ],
    "SelectB_recommedations": [
      "Q292",
      "Q280",
      "Q38"
    ],
    "SelectC_recommedations": [
      "Q38",
      "Q292",
      "Q280"
    ],
    "SelectD_recommedations": [
      "Q292",
      "Q38",
      "Q280"
    ]
  },
  {
    "Question_Number": "Q281",
    "Question_Description": "한 회사가 Amazon RDS for PostgreSQL DB 인스턴스를 사용해 웹 서버 팩을 운영하고 있습니다. 일상적인 컴플라이언스 점검 후, 모든 프로덕션 데이터베이스에 대해 RPO를 1초 미만으로 유지해야 한다는 표준을 설정했습니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99511-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DB 장애 발생 시 데이터 손실 최소화(RPO)를 요구합니다. Amazon RDS Multi-AZ 배포는 동기식 복제로 거의 실시간에 가까운 RPO(1초 미만)를 보장하여 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "RPO 1초 미만",
      "Amazon RDS for PostgreSQL",
      "Multi-AZ 배포",
      "프로덕션 데이터베이스"
    ],
    "Terms": [
      "Multi-AZ deployment",
      "Auto Scaling",
      "Read Replica",
      "AWS Database Migration Service (AWS DMS)",
      "Change Data Capture (CDC)"
    ],
    "SelectA": "DB 인스턴스에 Multi-AZ 배포를 활성화합니다.",
    "SelectA_Commentary": "동기식 복제를 통해 거의 동시에 데이터가 복제되어 RPO가 1초 미만으로 유지되므로 요구사항을 만족합니다.",
    "SelectB": "단일 가용 영역에 대해 DB 인스턴스 자동 확장을 활성화합니다.",
    "SelectB_Commentary": "Auto Scaling은 성능 또는 트래픽 대비 용량 확장에 대한 기능이며, RPO(데이터 손실 허용 범위) 보장과는 직접적인 관련이 없습니다.",
    "SelectC": "한 가용 영역에 DB 인스턴스를 구성하고, 별도 가용 영역에 여러 Read Replica를 구성합니다.",
    "SelectC_Commentary": "Read Replica는 비동기식 복제로 RPO가 1초 미만 보장을 하지 못하며, 장애 시 데이터 손실 가능성이 있습니다.",
    "SelectD": "한 가용 영역에 DB 인스턴스를 구성하고, AWS DMS Change Data Capture(CDC)를 구성합니다.",
    "SelectD_Commentary": "AWS DMS CDC 역시 비동기 방식으로 동작하므로 RPO가 1초 미만 수준으로 엄격히 보장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q71",
      "Q420",
      "Q601",
      "Q464",
      "Q958"
    ],
    "SelectA_recommedations": [
      "Q845",
      "Q8",
      "Q843"
    ],
    "SelectB_recommedations": [
      "Q917",
      "Q58",
      "Q187"
    ],
    "SelectC_recommedations": [
      "Q845",
      "Q400",
      "Q228"
    ],
    "SelectD_recommedations": [
      "Q843",
      "Q133",
      "Q490"
    ]
  },
  {
    "Question_Number": "Q282",
    "Question_Description": "한 회사가 VPC의 private subnet에 Amazon EC2 인스턴스를 배포해 웹 애플리케이션을 운영 중입니다. public subnet에 걸쳐 구성된 Application Load Balancer(ALB)가 웹 트래픽을 EC2 인스턴스로 전달합니다. 회사는 ALB로부터 EC2 인스턴스로 들어오는 인바운드 트래픽만 허용하고, EC2 인스턴스의 private subnet 내부나 외부의 다른 소스에서는 접근하지 못하도록 새로운 보안 방안을 구현하고자 합니다. 이러한 요구사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99660-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 내부 네트워크의 EC2 인스턴스에 ALB만이 접근하도록 보안을 강화하는 방법을 묻습니다. 즉, EC2 인스턴스의 Security Group에서 ALB의 Security Group만 신뢰하도록 설정하여, 그 외 소스는 모두 차단하는 구성을 해야 합니다. 따라서 EC2 인스턴스 보안 그룹에서 ALB 보안 그룹만 허용하는 B가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "private subnet",
      "Application Load Balancer",
      "Amazon EC2",
      "Security Group",
      "인바운드 트래픽"
    ],
    "Terms": [
      "VPC",
      "public subnet",
      "private subnet",
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Security Group",
      "Elastic IP"
    ],
    "SelectA": "라우트 테이블에서 인터넷 트래픽을 EC2 인스턴스의 private IP 주소로 전달하도록 라우트를 설정합니다.",
    "SelectA_Commentary": "이 방법은 보안 그룹이 아닌 라우팅 레벨에서 인터넷 트래픽을 직접 private IP로 보내는 것으로, 외부 접근을 제한할 수 없으므로 요구사항을 충족하지 못합니다.",
    "SelectB": "EC2 인스턴스의 Security Group을 설정하여 ALB의 Security Group에서 오는 트래픽만 허용하도록 구성합니다.",
    "SelectB_Commentary": "필요한 트래픽만 ALB를 통해 들여보내고 나머지를 차단해 보안을 강화하는 가장 적절한 솔루션입니다.",
    "SelectC": "EC2 인스턴스를 public subnet으로 옮기고 Elastic IP 주소를 할당합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 public subnet으로 옮기면 외부 접근이 가능해져 보안을 강화하려는 요건과 반대되는 결과를 초래합니다.",
    "SelectD": "ALB의 Security Group을 설정하여 어떤 포트든지 TCP 트래픽을 모두 허용하도록 구성합니다.",
    "SelectD_Commentary": "ALB에 전 포트 허용은 보안 범위를 과도하게 넓혀 EC2 인스턴스에 대한 무분별한 접근 가능성을 열어두므로 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q251",
      "Q509",
      "Q610",
      "Q1016",
      "Q875"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q96",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q973",
      "Q318",
      "Q60"
    ],
    "SelectC_recommedations": [
      "Q875",
      "Q251",
      "Q96"
    ],
    "SelectD_recommedations": [
      "Q169",
      "Q774",
      "Q60"
    ]
  },
  {
    "Question_Number": "Q283",
    "Question_Description": "한 연구 회사는 시뮬레이션 애플리케이션과 시각화 애플리케이션을 사용해 실험을 수행하고 있습니다. 시뮬레이션 애플리케이션은 Linux에서 실행되며, 5분마다 중간 데이터를 NFS 공유에 출력합니다. 시각화 애플리케이션은 Windows 데스크톱 애플리케이션으로, 시뮬레이션 출력을 표시하며 SMB 파일 시스템을 필요로 합니다. 현재는 NFS와 SMB를 각각 사용해 데이터 동기화를 수행하고 있어 데이터 중복과 리소스가 비효율적으로 사용되고 있습니다. 회사는 두 애플리케이션 모두 코드 수정 없이 AWS로 마이그레이션해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99512-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 파일 시스템(NFS와 SMB)을 사용하는 두 애플리케이션을 어떻게 통합된 방식으로 AWS에 마이그레이션할지를 묻습니다. Amazon FSx for NetApp ONTAP은 Linux와 Windows 환경 모두에서 접근할 수 있는 공유 스토리지를 제공하므로, 두 애플리케이션 모두를 코드 수정 없이 통합된 파일 시스템에 연결할 수 있습니다. 이를 통해 데이터 중복과 불필요한 동기화 작업을 제거하고 운영 효율성을 높일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "시뮬레이션 애플리케이션",
      "시각화 애플리케이션",
      "NFS 공유",
      "SMB 파일 시스템",
      "데이터 동기화",
      "코드 수정 없이 마이그레이션"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon FSx for NetApp ONTAP",
      "NFS",
      "SMB",
      "Linux",
      "Windows"
    ],
    "SelectA": "두 애플리케이션을 AWS Lambda로 마이그레이션하고, 애플리케이션 간 데이터를 교환하기 위해 Amazon S3 버킷을 생성합니다.",
    "SelectA_Commentary": "Lambda 기반으로 시뮬레이션 애플리케이션을 그대로 옮기기 어렵고, S3만으로 NFS와 SMB 요구사항을 동시에 해결하기 어렵습니다.",
    "SelectB": "두 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션하고, 스토리지를 위해 Amazon FSx File Gateway를 구성합니다.",
    "SelectB_Commentary": "Amazon FSx File Gateway는 온프레미스 NAS 환경과의 연결에 용이하나, NFS와 SMB를 동시 지원하는 NetApp ONTAP만큼 직접적이고 효율적인 해결책은 아닙니다.",
    "SelectC": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로, 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션하고, 애플리케이션 간 데이터 교환을 위해 Amazon SQS를 구성합니다.",
    "SelectC_Commentary": "SQS는 메시지 기반 서비스로, 파일 I/O 동기화가 필요한 NFS와 SMB 요구사항을 충족시키기 부족합니다.",
    "SelectD": "시뮬레이션 애플리케이션을 Linux Amazon EC2 인스턴스로, 시각화 애플리케이션을 Windows EC2 인스턴스로 마이그레이션하고, 스토리지를 위해 Amazon FSx for NetApp ONTAP을 구성합니다.",
    "SelectD_Commentary": "Amazon FSx for NetApp ONTAP은 NFS와 SMB 프로토콜을 모두 지원하므로, 두 애플리케이션이 단일 파일 시스템을 공유해 코드 수정 없이 효율적으로 운영 가능합니다.",
    "Question_Description_recommedations": [
      "Q990",
      "Q496",
      "Q528",
      "Q173",
      "Q895"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q173",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q680",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q229",
      "Q41"
    ],
    "SelectD_recommedations": [
      "Q299",
      "Q857",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q284",
    "Question_Description": "예산 수립의 일환으로 경영진은 사용자를 기준으로 나열된 AWS 청구 항목 보고서를 원합니다. 이 데이터는 각 부서별 예산을 생성하는 데 사용될 예정입니다. 솔루션스 아키텍트는 이 보고서 정보를 가장 효율적으로 얻을 수 있는 방법을 결정해야 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99513-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자를 기준으로 한 AWS 청구 항목을 효과적으로 조회하고 예산 수립에 활용하기 위한 보고서 생성 방법을 묻습니다. Cost Explorer를 이용하면 원하는 기준(사용자별 등)으로 쉽게 보고서를 생성하고 다운로드할 수 있어 가장 간편하고 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [],
    "Keywords": [
      "AWS 청구 항목",
      "사용자별 보고서",
      "부서별 예산",
      "Cost Explorer"
    ],
    "Terms": [
      "Amazon Athena",
      "Cost Explorer",
      "Billing Dashboard",
      "AWS Budgets",
      "Amazon Simple Email Service (Amazon SES)"
    ],
    "SelectA": "Amazon Athena로 쿼리를 실행하여 보고서를 생성합니다.",
    "SelectA_Commentary": "AWS Cost and Usage Report를 먼저 S3에 내보낸 뒤 Athena로 분석해야 하므로 설정이 복잡합니다.",
    "SelectB": "Cost Explorer에서 보고서를 생성하고 다운로드합니다.",
    "SelectB_Commentary": "필요한 청구 정보를 사용자별로 손쉽게 필터링하고 바로 다운로드할 수 있으므로 가장 효율적인 방법입니다.",
    "SelectC": "Billing 대시보드에서 청구 세부 정보를 확인하고 청구서를 다운로드합니다.",
    "SelectC_Commentary": "대시보드 청구서는 항목별 세분화가 제한적이어서 사용자별 구분 보고서로 활용하기 불편합니다.",
    "SelectD": "AWS Budgets에서 Cost Budget을 수정하여 Amazon Simple Email Service(Amazon SES)로 알림을 보냅니다.",
    "SelectD_Commentary": "알림 발송 용도로 사용되는 Budgets 기능이며, 사용자별 청구 항목 보고서를 생성하는 데는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q985",
      "Q728",
      "Q541",
      "Q525",
      "Q485"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectB_recommedations": [
      "Q630",
      "Q997",
      "Q49"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ],
    "SelectD_recommedations": [
      "Q591",
      "Q31",
      "Q543"
    ]
  },
  {
    "Question_Number": "Q285",
    "Question_Description": "한 회사가 Amazon S3를 사용하여 정적 웹사이트를 호스팅하고 있습니다. 회사는 웹페이지에 이름, 이메일 주소, 전화번호, 사용자 메시지를 입력할 수 있는 서버 측 로직이 있는 동적 연락처 양식을 추가하려고 합니다. 해당 웹사이트는 한 달에 100회 미만의 방문이 예상됩니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 방법은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99680-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "트래픽이 극히 적으므로 서버리스 구조가 가장 경제적입니다. API Gateway와 Lambda를 통해 동적 기능을 구현하고 Amazon SES로 이메일 송신까지 처리하는 방식이 비용을 최소화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "정적 웹사이트",
      "동적 서버 측 로직",
      "문의 양식",
      "비용 효율",
      "100회 미만 방문",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon SES"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon ECS",
      "Amazon SES",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon Lightsail",
      "Amazon WorkMail",
      "Amazon EC2",
      "LAMP"
    ],
    "SelectA": "Amazon Elastic Container Service(Amazon ECS)에서 동적 연락처 양식을 호스팅하고 Amazon Simple Email Service(Amazon SES)를 써드파티 이메일에 연결합니다.",
    "SelectA_Commentary": "ECS 클러스터 유지 비용이 들 수 있으며, 요청 수가 적어 서버리스보다 비효율적입니다.",
    "SelectB": "Amazon API Gateway 엔드포인트를 생성하고, AWS Lambda 백엔드가 Amazon Simple Email Service(Amazon SES)에 호출을 수행하도록 구성합니다.",
    "SelectB_Commentary": "서버리스 방식으로 트래픽이 적을 때 비용이 매우 낮아 요구사항을 가장 효율적으로 충족합니다.",
    "SelectC": "Amazon Lightsail로 정적 웹페이지를 동적 형태로 전환하고, 클라이언트 사이드 스크립팅으로 연락처 폼을 만든 다음 Amazon WorkMail과 통합합니다.",
    "SelectC_Commentary": "Lightsail 인스턴스 비용이 지속적으로 청구되어, 방문자가 적은 사이트에는 과도한 구성입니다.",
    "SelectD": "t2.micro Amazon EC2 인스턴스를 만들고, LAMP 스택으로 웹페이지를 호스팅합니다. 클라이언트 사이드 스크립팅으로 폼을 만들고 Amazon WorkMail로 연동합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 상시 운영해야 하므로, 저트래픽 환경에는 비용 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q606",
      "Q911",
      "Q1003",
      "Q769",
      "Q759"
    ],
    "SelectA_recommedations": [
      "Q591",
      "Q552",
      "Q926"
    ],
    "SelectB_recommedations": [
      "Q140",
      "Q220",
      "Q300"
    ],
    "SelectC_recommedations": [
      "Q728",
      "Q485",
      "Q985"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q300",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q286",
    "Question_Description": "한 회사가 Amazon S3 앞단에 Amazon CloudFront를 사용하여 정적 웹사이트를 호스팅하고 있습니다. 이 정적 웹사이트에는 데이터베이스 백엔드가 있습니다. 회사는 웹사이트가 Git 리포지토리에서 변경한 내용을 반영하지 않는다고 확인했습니다. 회사는 Git 리포지토리와 Amazon S3 간 CI/CD 파이프라인의 webhook 설정이 정상 동작하고, 성공적인 배포 메시지를 전송하는 것도 확인했습니다. 솔루션스 아키텍트는 웹사이트가 업데이트 내용을 표시하도록 해결책을 구현해야 합니다. 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99669-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CI/CD 파이프라인이 정상적으로 작동해도 CloudFront 캐시가 이전 콘텐츠를 계속 제공할 수 있다는 점이 핵심입니다. 새로운 콘텐츠를 사용자에게 즉시 반영하기 위해서는 CloudFront 캐시 무효화(Invalidate)를 수행하여 최신 버전을 제공하도록 해야 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "정적 웹사이트",
      "Amazon CloudFront",
      "Amazon S3",
      "CI/CD 파이프라인",
      "캐시 무효화"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Amazon S3",
      "CI/CD",
      "webhook",
      "Application Load Balancer",
      "Amazon ElastiCache",
      "Redis",
      "Memcached",
      "Invalidate the CloudFront cache",
      "AWS Certificate Manager(ACM)"
    ],
    "SelectA": "Application Load Balancer를 추가합니다.",
    "SelectA_Commentary": "Application Load Balancer는 트래픽 분산 용도로 적합하지만, 이미 CloudFront와 S3 조합이 사용 중이므로 캐시 문제 해결과 직접적인 관련이 없습니다.",
    "SelectB": "Amazon ElastiCache for Redis나 Memcached를 웹 애플리케이션의 데이터베이스 계층에 추가합니다.",
    "SelectB_Commentary": "데이터베이스 성능을 개선하는 옵션이며, 웹사이트 데이터가 즉시 반영되지 않는 문제와는 직접적인 연관이 없습니다.",
    "SelectC": "CloudFront 캐시를 무효화(Invalidate)합니다.",
    "SelectC_Commentary": "CloudFront 캐시가 이전 콘텐츠를 제공 중이므로, 캐시를 무효화하면 배포된 최신 버전이 사용자에게 즉시 반영됩니다.",
    "SelectD": "AWS Certificate Manager(ACM)을 사용하여 웹사이트의 SSL 인증서를 검증합니다.",
    "SelectD_Commentary": "SSL 인증서 검증은 보안과 신뢰성에 관련되어 있으나, 사이트 업데이트가 반영되지 않는 문제의 원인을 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q280",
      "Q155",
      "Q173",
      "Q547",
      "Q672"
    ],
    "SelectA_recommedations": [
      "Q141",
      "Q352",
      "Q704"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q704",
      "Q229"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q280",
      "Q684"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q305",
      "Q865"
    ]
  },
  {
    "Question_Number": "Q287",
    "Question_Description": "한 회사가 온프레미스에서 Windows 기반 애플리케이션을 AWS Cloud로 마이그레이션하려고 합니다. 이 애플리케이션은 애플리케이션 티어, 비즈니스 티어, Microsoft SQL Server를 사용하는 데이터베이스 티어의 세 가지 티어로 구성되어 있습니다. 회사는 SQL Server의 native backups, Data Quality Services 등의 특정 기능을 활용하기 원하며, 각 티어 간에 파일을 공유하며 처리해야 합니다. 이러한 요구사항을 만족하는 아키텍처 설계는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99670-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "문제 의도는 SQL Server 고유 기능을 사용하고 Windows 환경에서 SMB 기반 파일 공유를 제공하는 방안을 찾는 것입니다. 본격적인 배포 전 Windows 파일 공유가 필요하며, RDS 대신 EC2 기반 SQL Server로 구성 시 요구사항을 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3"
    ],
    "Keywords": [
      "Windows 기반 애플리케이션",
      "SQL Server",
      "native backups",
      "Data Quality Services",
      "파일 공유",
      "3티어 구조",
      "Amazon FSx for Windows File Server"
    ],
    "Terms": [
      "Amazon EC2",
      "Microsoft SQL Server",
      "Amazon FSx for Windows File Server",
      "Amazon FSx File Gateway",
      "Amazon RDS",
      "Amazon EFS",
      "Amazon EBS",
      "io2"
    ],
    "SelectA": "모든 티어를 Amazon EC2 인스턴스에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon FSx File Gateway를 사용합니다.",
    "SelectA_Commentary": "Amazon FSx File Gateway는 온프레미스에서 클라우드의 FSx 공유 폴더에 접근할 때 적합하며, 모두 클라우드에 위치한 경우에는 적절하지 않아 비효율적입니다.",
    "SelectB": "모든 티어를 Amazon EC2 인스턴스에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon FSx for Windows File Server를 사용합니다.",
    "SelectB_Commentary": "Windows용 SMB 파일 공유를 바로 제공하고, SQL Server 특화 기능도 EC2 환경에서 자유롭게 활용 가능하여 요구사항에 부합합니다.",
    "SelectC": "애플리케이션 티어와 비즈니스 티어는 Amazon EC2에서 호스팅하고, 데이터베이스 티어는 Amazon RDS에서 호스팅합니다. 티어 간 파일 공유를 위해 Amazon EFS를 사용합니다.",
    "SelectC_Commentary": "Amazon EFS는 NFS 프로토콜을 사용하며 Windows 환경에서 SMB 공유를 직접 지원하지 않아 파일 공유 요구사항에 적합하지 않습니다.",
    "SelectD": "애플리케이션 티어와 비즈니스 티어는 Amazon EC2에서 호스팅하고, 데이터베이스 티어는 Amazon RDS에서 호스팅합니다. 티어 간 파일 공유를 위해 Provisioned IOPS SSD(io2) Amazon EBS 볼륨을 사용합니다.",
    "SelectD_Commentary": "Amazon EBS는 서버 간 파일 공유용보다는 개별 인스턴스에 붙여 쓰는 블록 스토리지로, 멀티 인스턴스와의 공유가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q192",
      "Q554",
      "Q886",
      "Q650",
      "Q603"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q173",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q301",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q386",
      "Q910",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q386",
      "Q910",
      "Q193"
    ]
  },
  {
    "Question_Number": "Q288",
    "Question_Description": "한 회사가 Linux 기반 웹 서버 그룹을 AWS로 마이그레이션하고 있습니다. 웹 서버들은 일부 콘텐츠를 위해 공유 파일 스토어에 접근해야 합니다. 회사는 애플리케이션에 어떤 변경도 가하지 않으려 합니다. 이 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99671-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 여러 웹 서버가 동시에 접근할 수 있는 파일 스토어를 제공하고, 애플리케이션 변경 없이 기존처럼 NFS 마운트 형태로 사용해야 한다는 점입니다. Amazon EFS는 Linux 서버 환경에서 공유 파일 시스템을 간편하게 제공하며, 스케일 및 가용성 측면에서도 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Linux 기반 웹 서버",
      "공유 파일 스토어",
      "Amazon EFS",
      "애플리케이션 무변경"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon Elastic File System(Amazon EFS)",
      "Amazon EBS",
      "General Purpose SSD(gp3)"
    ],
    "SelectA": "Amazon S3 Standard 버킷을 생성하고 웹 서버에서 접근하도록 설정합니다.",
    "SelectA_Commentary": "Object 스토리지인 Amazon S3는 파일 시스템 마운트 방식이 아니므로 애플리케이션 코드 변경 없이 사용하기 어렵습니다.",
    "SelectB": "Amazon CloudFront 배포를 Amazon S3 버킷을 오리진으로 구성합니다.",
    "SelectB_Commentary": "CloudFront는 정적 콘텐츠 배포에 유리하지만, 웹 서버 간 공유 파일 시스템 기능을 제공하지 않습니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 모든 웹 서버에 이 EFS 파일 시스템을 마운트합니다.",
    "SelectC_Commentary": "Linux 기반 서버들이 NFS 방식으로 공유 스토어를 사용할 수 있어 애플리케이션을 수정할 필요가 없으며 확장성과 고가용성도 충족합니다.",
    "SelectD": "General Purpose SSD (gp3) Amazon EBS 볼륨을 구성합니다. 모든 웹 서버에 이 EBS 볼륨을 마운트합니다.",
    "SelectD_Commentary": "Amazon EBS는 단일 EC2 인스턴스에 연결되는 블록 스토리지로, 여러 웹 서버가 동시에 마운트하기에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q263",
      "Q375",
      "Q454",
      "Q479",
      "Q711"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q194",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q8",
      "Q784"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q986",
      "Q602",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q289",
    "Question_Description": "어느 회사에서 동일한 AWS 계정 내에 위치한 Amazon S3 버킷에 대한 읽기 권한이 필요한 AWS Lambda 함수가 있습니다. 가장 안전한 방식으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99756-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda 함수가 특정 S3 버킷에만 안전하게 접근하도록 구성하는 방법을 묻습니다. IAM role을 사용하면 Lambda 함수에 임시 자격 증명을 부여하여, 필요한 버킷에만 최소 권한으로 접근할 수 있습니다. 이러한 방식은 보안 및 위험 완화 측면에서 가장 우수하며, 액세스 키를 코드에 직접 포함시키는 것보다 안전합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Lambda 함수",
      "S3 버킷",
      "IAM role",
      "정책",
      "보안"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "S3 bucket policy",
      "IAM role",
      "IAM policy",
      "Access Key",
      "Secret Key",
      "Least Privilege"
    ],
    "SelectA": "S3 버킷에 읽기 권한을 부여하는 S3 bucket policy를 적용합니다.",
    "SelectA_Commentary": "버킷 정책만으로는 Lambda 함수에 대한 세분화된 제어가 어렵고 IAM role을 통한 임시 자격 증명 방식을 활용하지 않아 보안상 취약합니다.",
    "SelectB": "Lambda 함수에 IAM role을 적용하고, 해당 role에 S3 버킷에 대한 읽기 권한을 부여하는 IAM policy를 적용합니다.",
    "SelectB_Commentary": "IAM role을 통해 필요한 S3 버킷만 읽을 권한을 부여하는 최소 권한 원칙을 만족하며, 함수가 안전한 임시 자격 증명을 사용하므로 보안 측면에서 가장 적합합니다.",
    "SelectC": "Lambda 함수 코드에 접근 키와 비밀 키를 하드코딩하여 필요한 IAM 권한을 부여합니다.",
    "SelectC_Commentary": "코드에 키를 직접 포함하면 노출 위험이 크고, 키 관리를 어렵게 만듭니다. 보안 모범 사례에 어긋납니다.",
    "SelectD": "Lambda 함수에 IAM role을 적용하고, 계정 내 모든 S3 버킷에 대한 읽기 권한을 부여하는 IAM policy를 적용합니다.",
    "SelectD_Commentary": "필요 이상의 광범위한 권한을 부여하므로 최소 권한 원칙을 지키지 못해 보안 취약점이 발생할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q638",
      "Q412",
      "Q403",
      "Q936"
    ],
    "SelectA_recommedations": [
      "Q256",
      "Q965",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q403",
      "Q289",
      "Q913"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q936",
      "Q476"
    ],
    "SelectD_recommedations": [
      "Q403",
      "Q289",
      "Q936"
    ]
  },
  {
    "Question_Number": "Q290",
    "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 이 EC2 인스턴스들은 Auto Scaling group에 속해 있으며, 사용자 트래픽에 따라 확장됩니다. 회사는 장기 약정 없이 비용 절감을 최적화하고자 합니다. 이러한 요구 사항을 충족하기 위한 EC2 인스턴스 구매 옵션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100006-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 장기 약정(Reserved Instances) 없이费用을 절감해야 하는 요구사항을 어떻게 충족할지 묻습니다. On-Demand Instances만 사용하면 유연성은 높지만 비용 절감 폭이 크지 않습니다. Spot Instances는 중단 가능성을 감수해야 하지만, 사용하지 않는 EC2 용량을 저렴하게 활용할 수 있으므로 비용 절감 효과가 큽니다. 따라서 일정 부분 On-Demand로 안정성을 확보하고, 나머지를 Spot으로 확보하는 혼합 구성이 장기 약정 없이 비용 최적화를 달성하는 적절한 해법입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Auto Scaling group",
      "On-Demand Instances",
      "Spot Instances",
      "비용 절감",
      "장기 약정 없이"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "On-Demand Instances",
      "Spot Instances",
      "Reserved Instances",
      "Dedicated Instances"
    ],
    "SelectA": "Dedicated Instances만 사용",
    "SelectA_Commentary": "전용 물리 호스트를 이용하므로 비용이 높고 장기 약정이 없어도 목적에 부합하지 않습니다.",
    "SelectB": "On-Demand Instances만 사용",
    "SelectB_Commentary": "유연성은 좋으나 Spot Instances를 활용하지 않으므로 비용 절감 효과가 제한적입니다.",
    "SelectC": "On-Demand Instances와 Spot Instances 혼합 사용",
    "SelectC_Commentary": "장기 약정 없이 일부 안정성을 확보하면서도 Spot Instances로 높은 비용 절감 효과를 누릴 수 있어 최적입니다.",
    "SelectD": "On-Demand Instances와 Reserved Instances 혼합 사용",
    "SelectD_Commentary": "Reserved Instances 구매 시 장기 약정이 필요하므로 문제의 요구사항인 '장기 약정 없음'에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q937",
      "Q238",
      "Q671",
      "Q552",
      "Q24"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q630",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q1008",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q300",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q943",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q291",
    "Question_Description": "한 미디어 회사는 공개적으로 스트리밍되는 비디오 콘텐츠를 Amazon CloudFront를 통해 제공합니다. 이 회사는 Amazon S3에 호스팅된 비디오 콘텐츠에 대해 접근 권한을 제어해 보안을 강화하고자 합니다. 일부 사용자는 쿠키를 지원하지 않는 커스텀 HTTP 클라이언트를 사용하고, 일부 사용자는 이미 사용 중인 고정된 URL을 변경할 수 없습니다. 사용자에게 미치는 영향을 최소화하며 이 요구사항을 만족하는 서비스나 방법은 무엇입니까? (2개를 고르시오.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99831-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudFront와 S3 간 콘텐츠 접근 제어를 어떻게 구현할지 묻습니다. 일부 사용자는 쿠키를 지원하지 않고, 일부는 URL 변경이 불가능하므로, Signed cookies와 Signed URLs을 병행 사용해 다양한 상황을 지원하도록 설계해야 합니다. 그 외 솔루션인 AWS AppSync, JWT, AWS Secrets Manager는 요청 로직 변경이나 추가 로직 구현이 필요해 사용자에게 더 많은 영향을 줄 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "CloudFront",
      "쿠키 미지원",
      "고정된 URL",
      "접근 보안",
      "사용자 영향 최소화"
    ],
    "Terms": [
      "Signed cookies",
      "Signed URLs",
      "AWS AppSync",
      "JSON Web Token (JWT)",
      "AWS Secrets Manager"
    ],
    "SelectA": "Signed cookies",
    "SelectA_Commentary": "쿠키를 지원하는 환경에서 URL 변경 없이 접근을 제어할 수 있어, URL 고정 이슈가 있는 사용자 대응에 유리합니다.",
    "SelectB": "Signed URLs",
    "SelectB_Commentary": "쿠키를 지원하지 않는 사용자나 외부 클라이언트에게 개별 URL에 짧은 만료 시간 등을 부여해 안전하게 접근을 제어할 수 있습니다.",
    "SelectC": "AWS AppSync",
    "SelectC_Commentary": "GraphQL 기반 API 서비스를 제공하지만, 기존 URL 구조나 인증 방식 변경이 필요하여 사용자 영향이 큽니다.",
    "SelectD": "JSON Web Token (JWT)",
    "SelectD_Commentary": "JWT는 토큰 기반 인증을 위한 추가 구현이 필요하므로, 크고 작은 코드 수정과 로직 변경이 따라가 사용자에게 부담이 됩니다.",
    "SelectE": "AWS Secrets Manager",
    "SelectE_Commentary": "민감한 정보를 안전하게 저장·관리하는 서비스로, 직접 URL 접근 제어 기능과는 거리가 멀어 해결책으로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q131",
      "Q542",
      "Q216",
      "Q172",
      "Q974"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q564",
      "Q265"
    ],
    "SelectB_recommedations": [
      "Q855",
      "Q321",
      "Q265"
    ],
    "SelectC_recommedations": [
      "Q321",
      "Q970",
      "Q34"
    ],
    "SelectD_recommedations": [
      "Q321",
      "Q564",
      "Q122"
    ],
    "SelectE_recommedations": [
      "Q321",
      "Q970",
      "Q898"
    ]
  },
  {
    "Question_Number": "Q292",
    "Question_Description": "한 회사가 여러 소스로부터 실시간 스트리밍 데이터로 새 데이터 플랫폼을 준비하고 있습니다. 회사는 Amazon S3에 데이터를 기록하기 전에 데이터를 변환해야 하며, 변환된 데이터에 대해 SQL로 질의할 수 있어야 합니다. 어떤 솔루션들이 이 요구사항을 충족할 수 있습니까? (정답은 두 개를 고르십시오.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99834-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다수의 소스에서 발생하는 실시간 스트리밍 데이터를 받아 변환한 후, Amazon S3에 저장하고 Athena를 통해 SQL 질의를 수행하는 아키텍처를 설계하는 것입니다. 고성능 스트리밍 처리와 간단한 ETL 과정을 동시에 충족해야 하므로 Kinesis 또는 MSK와 같은 스트리밍 서비스, Kinesis Data Analytics나 Glue와 같은 데이터 변환 서비스, 그리고 최종적으로 S3와 Athena가 결합되어야 합니다. 정답인 A와 B는 모두 실시간 스트리밍, 변환, S3에 저장, 그리고 Athena로 질의가 가능하도록 구성됩니다. 반면 C는 AWS DMS가 주로 데이터베이스 마이그레이션·복제에 초점이 맞춰져 있고, D와 E는 RDS query editor를 사용하는데 이는 S3 저장 데이터를 직접 SQL 질의하는 방식과 어긋납니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "실시간 스트리밍 데이터",
      "데이터 변환",
      "Amazon S3",
      "SQL 질의",
      "새로운 데이터 플랫폼"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Analytics",
      "Amazon Kinesis Data Firehose",
      "Amazon MSK",
      "AWS Glue",
      "Amazon EMR",
      "AWS DMS",
      "Amazon S3",
      "Amazon Athena",
      "Amazon RDS query editor"
    ],
    "SelectA": "Amazon Kinesis Data Streams로 데이터를 스트리밍합니다. Amazon Kinesis Data Analytics로 데이터를 변환합니다. Amazon Kinesis Data Firehose로 데이터를 Amazon S3에 기록합니다. Amazon Athena를 사용해 변환된 데이터를 질의합니다.",
    "SelectA_Commentary": "Kinesis 서비스 라인업을 활용한 전형적인 실시간 ETL 흐름이며, Athena로 손쉽게 SQL 질의를 수행할 수 있어 요구사항을 완벽히 충족합니다.",
    "SelectB": "Amazon Managed Streaming for Apache Kafka(Amazon MSK)로 데이터를 스트리밍합니다. AWS Glue를 사용해 데이터를 변환하고, Amazon S3에 기록합니다. Amazon Athena로 변환된 데이터를 질의합니다.",
    "SelectB_Commentary": "MSK를 통한 스트리밍과 Glue의 스트리밍 ETL 조합으로 실시간 처리와 변환이 가능하고, Athena로 손쉽게 SQL 질의가 가능합니다.",
    "SelectC": "AWS Database Migration Service(AWS DMS)로 데이터를 수집합니다. Amazon EMR로 데이터를 변환 후 Amazon S3에 기록합니다. Amazon Athena로 변환된 데이터를 질의합니다.",
    "SelectC_Commentary": "AWS DMS는 주로 DB 간 복제·마이그레이션에 특화되어 있으므로, 다수 스트리밍 소스 대상의 실시간 변환 요건에는 부적합합니다.",
    "SelectD": "Amazon MSK로 데이터를 스트리밍합니다. Amazon Kinesis Data Analytics로 데이터를 변환해 Amazon S3에 기록합니다. Amazon RDS query editor로 S3의 변환된 데이터를 질의합니다.",
    "SelectD_Commentary": "RDS query editor는 RDS나 Aurora 같은 DB에 SQL 질의를 수행하는 서비스이므로, S3에 직접 저장된 데이터를 바로 질의하는 요건과 맞지 않습니다.",
    "SelectE": "Amazon Kinesis Data Streams로 데이터를 스트리밍합니다. AWS Glue로 데이터를 변환합니다. Amazon Kinesis Data Firehose로 Amazon S3에 기록합니다. Amazon RDS query editor로 S3의 변환된 데이터를 질의합니다.",
    "SelectE_Commentary": "S3 데이터를 RDS query editor로 직접 질의할 수 없으므로, Athena 대신 RDS query editor를 사용하는 이 방법은 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q672",
      "Q155",
      "Q501",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q515",
      "Q687"
    ],
    "SelectB_recommedations": [
      "Q305",
      "Q695",
      "Q603"
    ],
    "SelectC_recommedations": [
      "Q386",
      "Q834",
      "Q910"
    ],
    "SelectD_recommedations": [
      "Q402",
      "Q515",
      "Q292"
    ],
    "SelectE_recommedations": [
      "Q402",
      "Q910",
      "Q515"
    ]
  },
  {
    "Question_Number": "Q293",
    "Question_Description": "한 회사의 온프레미스 볼륨 백업 솔루션이 수명이 다했습니다. 회사는 새로운 백업 솔루션의 일부로 AWS를 사용하고자 하며, AWS로 백업되는 동안에도 모든 데이터에 대한 로컬 액세스를 유지하기를 원합니다. 또한 백업이 AWS로 자동적이고 안전하게 전송되도록 보장해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99692-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 AWS로 백업을 진행하면서도 전체 데이터를 로컬에서 그대로 사용할 수 있는 방안을 찾는 것입니다. Stored Volume Gateway는 모든 데이터를 온프레미스에 보관하면서 비동기적으로 AWS에 백업하므로, 요구 사항을 모두 충족하는 최적의 선택입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "로컬 액세스",
      "자동 백업",
      "안전한 전송",
      "온프레미스",
      "AWS Storage Gateway",
      "Stored Volume Gateway"
    ],
    "Terms": [
      "AWS Snowball",
      "AWS Snowball Edge",
      "AWS Storage Gateway",
      "Cached Volume Gateway",
      "Stored Volume Gateway",
      "S3",
      "백업 솔루션"
    ],
    "SelectA": "AWS Snowball을 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. 온프레미스 시스템이 Snowball S3 엔드포인트를 마운트하여 데이터에 로컬로 액세스하도록 구성합니다.",
    "SelectA_Commentary": "Snowball은 주로 대용량 데이터 마이그레이션에 사용되며, 지속적인 로컬 액세스를 보장하는 솔루션으로는 적합하지 않습니다.",
    "SelectB": "AWS Snowball Edge를 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. Snowball Edge 파일 인터페이스를 사용하여 온프레미스 시스템에 로컬 액세스를 제공합니다.",
    "SelectB_Commentary": "Snowball Edge는 일시적인 오프라인 전송에 유용하나, 상시 백업 및 전송 자동화 그리고 모든 데이터의 상시 로컬 액세스를 장기간 유지하기에는 제한적입니다.",
    "SelectC": "AWS Storage Gateway를 사용하고 Cached Volume Gateway를 구성합니다. 온프레미스에 Storage Gateway 소프트웨어 어플라이언스를 실행하고 일정 비율의 데이터를 로컬에 캐시하도록 구성합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 로컬로 액세스합니다.",
    "SelectC_Commentary": "Cached Volume Gateway는 자주 액세스되는 데이터만 로컬에 두므로 전체 데이터를 로컬에서 모두 이용해야 하는 요구사항과 맞지 않습니다.",
    "SelectD": "AWS Storage Gateway를 사용하고 Stored Volume Gateway를 구성합니다. 온프레미스에 Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 해당 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 로컬로 액세스합니다.",
    "SelectD_Commentary": "Stored Volume Gateway는 모든 데이터를 온프레미스에 보관하면서 AWS로 비동기 백업을 수행하므로, 로컬 액세스와 안전한 백업을 동시에 충족합니다.",
    "Question_Description_recommedations": [
      "Q149",
      "Q8",
      "Q163",
      "Q802",
      "Q363"
    ],
    "SelectA_recommedations": [
      "Q188",
      "Q636",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q188",
      "Q194",
      "Q18"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q354",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q354",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q294",
    "Question_Description": "Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 Amazon S3 버킷에 액세스해야 합니다. 트래픽은 인터넷을 통과하면 안 됩니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 어떻게 액세스를 구성해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99954-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스와 S3 버킷 간의 트래픽이 인터넷을 우회하지 않고 안전하게 내부 경로로만 전달되도록 설정하는 방안을 묻고 있습니다. Gateway VPC endpoint를 사용하면 트래픽이 곧바로 VPC 내부에서 S3와 통신하여 보안과 성능을 모두 만족시킵니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "Amazon S3 버킷",
      "트래픽 인터넷 미통과",
      "Gateway VPC endpoint"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "Gateway VPC endpoint",
      "NAT gateway",
      "AWS Site-to-Site VPN",
      "Amazon Route 53",
      "Private hosted zone"
    ],
    "SelectA": "Amazon Route 53을 사용하여 private hosted zone을 생성합니다.",
    "SelectA_Commentary": "이는 내부 DNS 이름 해석에 사용될 수 있지만, S3로의 트래픽이 인터넷을 우회하게 설정해 주지는 못합니다.",
    "SelectB": "VPC 내에서 Amazon S3용 Gateway VPC endpoint를 설정합니다.",
    "SelectB_Commentary": "Gateway VPC endpoint를 사용하면 EC2 인스턴스가 인터넷에 노출되지 않고 내부적으로 S3와 직접 통신할 수 있습니다. 이 요구사항에 부합하며 정답입니다.",
    "SelectC": "EC2 인스턴스가 S3 버킷에 액세스하기 위해 NAT gateway를 사용하도록 구성합니다.",
    "SelectC_Commentary": "NAT gateway를 사용하면 사설 서브넷에서 인터넷에 나갈 수 있지만, 트래픽은 결국 인터넷을 통해 S3에 도달할 수 있으므로 요구사항에 어긋납니다.",
    "SelectD": "VPC와 S3 버킷 간에 AWS Site-to-Site VPN 연결을 설정합니다.",
    "SelectD_Commentary": "Site-to-Site VPN은 온프레미스와 VPC 간 연결 시 주로 사용됩니다. S3 버킷에 VPN을 직접 연결하는 방식은 일반적이지 않으며 복잡도와 비용이 높습니다.",
    "Question_Description_recommedations": [
      "Q26",
      "Q11",
      "Q393",
      "Q17",
      "Q89"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q91",
      "Q92",
      "Q866"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q612",
      "Q17"
    ],
    "SelectD_recommedations": [
      "Q782",
      "Q92",
      "Q866"
    ]
  },
  {
    "Question_Number": "Q295",
    "Question_Description": "한 전자 상거래 회사가 AWS Cloud에 테라바이트 규모의 고객 데이터를 저장하고 있습니다. 데이터에는 개인 식별 정보(PII)가 포함되어 있습니다. 이 데이터는 3개의 애플리케이션에서 사용되어야 하며, 이 중 오직 하나의 애플리케이션만이 PII를 처리해야 합니다. 나머지 두 애플리케이션에서 데이터를 처리하기 전에 PII를 제거해야 합니다. 운영 오버헤드를 최소화하면서 이를 구현하려면 어떤 솔루션이 적합합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99956-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 하나의 데이터셋에서 애플리케이션별로 PII 노출을 제어해야 하는 시나리오입니다. Amazon S3 Object Lambda를 사용하면 데이터를 요청하는 시점에 필요한 형태로 변환하여 반환할 수 있어, 애플리케이션별 요구사항(PII 필요 여부)에 따른 처리를 간소화할 수 있습니다. 여러 버킷이나 별도 Proxy 애플리케이션, 혹은 테이블을 운영하는 방법은 관리 부담이 크게 늘어납니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "개인 식별 정보 제거",
      "테라바이트 규모 데이터",
      "운영 오버헤드 최소화",
      "3개의 애플리케이션"
    ],
    "Terms": [
      "PII",
      "Amazon S3",
      "S3 Object Lambda",
      "Amazon DynamoDB",
      "Proxy application layer",
      "데이터 변환",
      "Macie"
    ],
    "SelectA": "데이터를 Amazon DynamoDB 테이블에 저장합니다. 각 애플리케이션이 요청하는 데이터를 가로채어 처리하는 proxy application layer를 생성합니다.",
    "SelectA_Commentary": "별도의 프록시 계층을 두는 것은 운영 과정이 복잡해지고 DynamoDB에서 적절히 필터링하기 위한 추가 로직이 필요해 오버헤드가 큽니다.",
    "SelectB": "데이터를 Amazon S3 버킷에 저장합니다. S3 Object Lambda를 사용해 요청하는 데이터에 대해 처리 및 변환을 수행한 뒤, 변환된 데이터를 요청 애플리케이션에 반환합니다.",
    "SelectB_Commentary": "S3 Object Lambda를 이용해 필요할 때만 PII를 제거하여 반환하므로, 별도 데이터 사본을 유지할 필요가 없으며 운영 오버헤드가 최소화됩니다.",
    "SelectC": "데이터를 처리한 뒤 3개의 별도 Amazon S3 버킷에 변환된 데이터를 각각 저장하고, 각 애플리케이션이 해당 버킷을 사용하도록 설정합니다.",
    "SelectC_Commentary": "애플리케이션 수만큼 별도 버킷을 운영하면 데이터 동기화 및 관리가 복잡해지고, 스토리지 및 운영 비용이 증가합니다.",
    "SelectD": "데이터를 처리한 뒤 3개의 별도 Amazon DynamoDB 테이블에 변환된 데이터를 각각 저장하고, 각 애플리케이션이 해당 테이블을 사용하도록 설정합니다.",
    "SelectD_Commentary": "별도의 테이블 세 개를 관리하는 것은 DynamoDB 용량 조절, 동기화 등 운영 부담이 증가하여 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q533",
      "Q756",
      "Q893",
      "Q898",
      "Q838"
    ],
    "SelectA_recommedations": [
      "Q279",
      "Q176",
      "Q727"
    ],
    "SelectB_recommedations": [
      "Q289",
      "Q202",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q44",
      "Q825",
      "Q106"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ]
  },
  {
    "Question_Number": "Q296",
    "Question_Description": "개발 팀이 개발용 VPC 내의 Amazon EC2 인스턴스에서 호스팅되는 새로운 애플리케이션을 출시했습니다. 솔루션스 아키텍트는 같은 계정에 새 VPC를 생성해야 하며, 이 새 VPC는 기존 개발 VPC와 피어링될 예정입니다. 개발 VPC의 CIDR 블록은 192.168.0.0/24입니다. 새 VPC에 대한 CIDR 블록을 생성해야 하며, 개발 VPC와 VPC 피어링 연결이 가능하려면 CIDR 블록이 겹치지 않아야 합니다. 이러한 요구사항을 충족하는 가장 작은 CIDR 블록은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99651-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 VPC 간 피어링을 위해 CIDR 블록이 겹치지 않으면서, VPC로서 유효한 최소 크기를 찾아야 한다는 점에 주목해야 합니다. /32는 VPC에 불가능하고, 기존 VPC 대역(192.168.0.0/24)과 겹치지 않으면서 충분한 IP 주소 범위를 제공하는 10.0.1.0/24가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "VPC 피어링",
      "CIDR 블록",
      "10.0.1.0/24",
      "개발 VPC"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC Peering",
      "CIDR Block",
      "192.168.0.0/24",
      "10.0.1.0/24",
      "/32 Network"
    ],
    "SelectA": "10.0.1.0/32",
    "SelectA_Commentary": "/32는 호스트가 1개만 가능한 너무 작은 네트워크입니다. 유효한 VPC CIDR 블록이 될 수 없습니다.",
    "SelectB": "192.168.0.0/24",
    "SelectB_Commentary": "이미 개발 VPC가 사용하는 CIDR 블록과 동일하여 피어링이 불가능합니다.",
    "SelectC": "192.168.1.0/32",
    "SelectC_Commentary": "/32 역시 네트워크가 1개 호스트만 가능한 사이즈로, 유효한 VPC CIDR 블록이 될 수 없습니다.",
    "SelectD": "10.0.1.0/24",
    "SelectD_Commentary": "기존 VPC 대역과 겹치지 않고, /24로 충분한 IP 주소 수를 제공하므로 새 VPC로 사용하기에 적합합니다.",
    "Question_Description_recommedations": [
      "Q101",
      "Q439",
      "Q722",
      "Q504",
      "Q237"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q567",
      "Q917"
    ],
    "SelectB_recommedations": [
      "Q362",
      "Q567",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q362",
      "Q567",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q362",
      "Q567",
      "Q917"
    ]
  },
  {
    "Question_Number": "Q297",
    "Question_Description": "한 회사는 5개의 Amazon EC2 인스턴스에 애플리케이션을 배포했습니다. Application Load Balancer(ALB)는 target group을 사용하여 인스턴스로 트래픽을 분산하고 있습니다. 각 인스턴스의 평균 CPU 사용률은 대부분 10% 미만이지만, 가끔 65%까지 급등합니다. 솔루션스 아키텍트는 애플리케이션의 확장성을 자동화하면서 아키텍처 비용을 최적화하고, 급등 시 애플리케이션에 충분한 CPU 리소스를 보장할 수 있는 솔루션을 구현해야 합니다. 다음 중 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99652-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션이 사용하는 EC2 리소스를 효율적으로 조절하는 방법을 묻습니다. EC2 Auto Scaling과 타겟 추적 스케일링 정책을 사용하면 급등 시 신속히 인스턴스를 늘리고, 평시에는 비용을 절감할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "자동화된 확장",
      "비용 최적화",
      "CPU 급등",
      "EC2 Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Target Group",
      "CPUUtilization",
      "Amazon CloudWatch",
      "AWS Lambda",
      "EC2 Auto Scaling",
      "ASGAverageCPUUtilization",
      "Amazon Simple Notification Service(Amazon SNS)"
    ],
    "SelectA": "CPUUtilization 지표가 20% 미만일 때 ALARM 상태가 되도록 Amazon CloudWatch alarm을 생성하고, 해당 alarm이 AWS Lambda 함수를 호출해 ALB 대상 그룹 내 EC2 인스턴스 하나를 종료하도록 구성합니다.",
    "SelectA_Commentary": "CPU 사용률이 낮을 때만 인스턴스를 종료하며, 높은 사용률 시 자동 확장이 없습니다. 스케일 인/아웃 균형을 맞추지 못해 요구사항을 충족하지 못합니다.",
    "SelectB": "EC2 Auto Scaling group을 생성합니다. 기존 ALB와 target group을 선택하고, ASGAverageCPUUtilization 지표 기반 타겟 추적 스케일링 정책을 설정합니다. 최소 인스턴스를 2, 원하는 용량을 3, 최대 인스턴스를 6, 타겟 값을 50%로 지정한 뒤, 기존 EC2 인스턴스들을 Auto Scaling 그룹에 추가합니다.",
    "SelectB_Commentary": "타겟 추적 스케일링 정책으로 CPU가 한계에 근접하면 자동으로 인스턴스가 증가하고, 여유 시 축소하여 비용을 절감하므로 요구사항에 부합합니다.",
    "SelectC": "EC2 Auto Scaling group을 생성합니다. 기존 ALB와 target group을 선택하고, 최소 인스턴스를 2, 원하는 용량을 3, 최대 인스턴스를 6으로 설정합니다. 기존 EC2 인스턴스들을 Auto Scaling 그룹에 추가합니다.",
    "SelectC_Commentary": "스케일링 정책이 없어서 CPU 급등 시 자동 확장이 이뤄지지 않습니다. 동적 스케일링이 필요하므로 요구사항을 만족하지 못합니다.",
    "SelectD": "두 개의 Amazon CloudWatch alarm을 생성합니다. 첫 번째는 평균 CPUUtilization이 20% 미만일 때, 두 번째는 50% 초과일 때 ALARM 상태가 되도록 설정합니다. alarm이 Amazon SNS 토픽으로 이메일을 발송하도록 구성하고, 이메일을 받으면 수동으로 EC2 인스턴스를 줄이거나 늘립니다.",
    "SelectD_Commentary": "수동 작업이 필요하여 자동화된 확장이 불가능합니다. 즉각적이고 효율적인 비용 최적화를 이룰 수 없습니다.",
    "Question_Description_recommedations": [
      "Q333",
      "Q813",
      "Q639",
      "Q405",
      "Q174"
    ],
    "SelectA_recommedations": [
      "Q923",
      "Q150",
      "Q333"
    ],
    "SelectB_recommedations": [
      "Q342",
      "Q846",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q846",
      "Q405",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q923",
      "Q150",
      "Q820"
    ]
  },
  {
    "Question_Number": "Q298",
    "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon EC2 인스턴스로 구동되는 중요한 비즈니스 애플리케이션을 운영하고 있습니다. 이 EC2 인스턴스들은 Auto Scaling group으로 동작하며, Amazon RDS DB instance에 액세스합니다. 그러나 현재 설계에서는 EC2 인스턴스와 DB instance 모두가 하나의 Availability Zone에만 위치해 있어 운영 검토에서 통과하지 못했습니다. 솔루션스 아키텍트는 두 번째 Availability Zone을 사용하도록 설계를 업데이트해야 합니다. 어떤 솔루션이 애플리케이션을 고가용성으로 만들 수 있습니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99653-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 Availability Zone에서 호스팅하던 EC2 인스턴스들과 RDS DB instance를 다중 AZ로 구성하여 고가용성을 달성하는 방법에 관한 것입니다. VPC 구성에서 subnet은 반드시 단일 Availability Zone에 속해야 합니다. 또한 RDS DB instance를 Multi-AZ로 설정하면 장애가 발생해도 자동으로 다른 AZ에서 서비스가 지속되므로 다운타임을 크게 줄일 수 있습니다. 이를 통해 EC2 측면과 DB 측면에서 모두 이중화·고가용성을 갖춘 아키텍처로 개선할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Application Load Balancer",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon RDS DB instance",
      "Availability Zone",
      "Multi-AZ"
    ],
    "Terms": [
      "Application Load Balancer",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon RDS DB instance",
      "Multi-AZ deployment",
      "Availability Zone",
      "subnet"
    ],
    "SelectA": "각 Availability Zone에 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 각 네트워크에 연결되도록 구성합니다.",
    "SelectA_Commentary": "DB instance를 단순히 각 네트워크에 연결하는 것만으로는 장애 발생 시 고가용성을 보장하지 못합니다. Multi-AZ 설정이 필요합니다.",
    "SelectB": "두 AZ에 걸쳐 확장되는 두 개의 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 각 네트워크에 연결되도록 구성합니다.",
    "SelectB_Commentary": "subnet은 단일 AZ 안에만 속해야 하므로, 'AZ에 걸쳐 확장되는 subnet'은 유효하지 않습니다.",
    "SelectC": "각 Availability Zone에 subnet을 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 Multi-AZ로 구성합니다.",
    "SelectC_Commentary": "두 AZ에 각각 subnet을 두어 EC2를 이중화하고, DB instance를 Multi-AZ 설정으로 구성하여 장애 시에도 데이터를 안전하게 보호하고 고가용성을 달성할 수 있는 옳은 솔루션입니다.",
    "SelectD": "두 AZ에 걸쳐 확장되는 subnet을 하나 프로비저닝합니다. Auto Scaling group을 구성해 두 AZ에 걸쳐 EC2 인스턴스를 배치합니다. DB instance를 Multi-AZ로 구성합니다.",
    "SelectD_Commentary": "subnet은 단일 AZ 안에만 존재해야 하므로 이 구성이 불가능합니다. Multi-AZ 설정은 적절하지만 subnet 구성 자체가 잘못되었습니다.",
    "Question_Description_recommedations": [
      "Q275",
      "Q5",
      "Q69",
      "Q174",
      "Q405"
    ],
    "SelectA_recommedations": [
      "Q691",
      "Q69",
      "Q298"
    ],
    "SelectB_recommedations": [
      "Q69",
      "Q691",
      "Q390"
    ],
    "SelectC_recommedations": [
      "Q691",
      "Q298",
      "Q729"
    ],
    "SelectD_recommedations": [
      "Q390",
      "Q466",
      "Q691"
    ]
  },
  {
    "Question_Number": "Q299",
    "Question_Description": "한 연구소가 약 8TB의 데이터를 처리해야 합니다. 이 연구소는 스토리지 서브시스템에서 서브밀리초 지연 시간과 최소 6GBps 이상의 처리량을 요구합니다. 수백 대의 Amazon EC2(Amazon Linux) 인스턴스가 이 데이터를 분산 처리할 예정입니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99676-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고성능 저장소를 요구하는 대용량 데이터 처리 시나리오입니다. 서브밀리초 지연 시간과 6GBps 이상의 처리량을 만족하기 위해서는 SSD 기반 FSx for Lustre가 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "서브밀리초 지연 시간",
      "6GBps 처리량",
      "Amazon FSx for Lustre",
      "SSD",
      "Amazon S3",
      "Amazon EC2",
      "고성능 저장소"
    ],
    "Terms": [
      "Amazon FSx for NetApp ONTAP",
      "Tiering Policy",
      "Amazon FSx for Lustre",
      "Persistent SSD Storage",
      "Persistent HDD Storage",
      "Amazon S3",
      "Amazon EC2",
      "Amazon Linux"
    ],
    "SelectA": "Amazon FSx for NetApp ONTAP 파일 시스템을 생성하고, 각 볼륨의 tiering policy를 ALL로 설정한 후 원시 데이터를 가져옵니다. 이후 EC2 인스턴스에서 해당 파일 시스템을 마운트합니다.",
    "SelectA_Commentary": "NetApp ONTAP은 뛰어난 기능이 있지만 Lustre SSD만큼의 고성능(6GBps 이상) 달성이 어려워 요구 사항을 만족하기 어렵습니다.",
    "SelectB": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. SSD 스토리지 유형의 Amazon FSx for Lustre 파일 시스템을 생성하고, S3로부터의 데이터 가져오기 옵션을 활성화한 뒤, EC2 인스턴스에 마운트합니다.",
    "SelectB_Commentary": "SSD 기반 FSx for Lustre는 서브밀리초 지연 시간과 6GBps 이상의 처리량을 구현할 수 있으므로 요구 사항을 충족하는 최적의 솔루션입니다.",
    "SelectC": "원시 데이터를 저장할 Amazon S3 버킷을 생성합니다. HDD 스토리지 유형의 Amazon FSx for Lustre 파일 시스템을 생성하고, S3로부터의 데이터 가져오기 옵션을 활성화한 뒤, EC2 인스턴스에 마운트합니다.",
    "SelectC_Commentary": "HDD는 SSD 대비 지연 시간과 처리량이 낮아 6GBps 요구 사항을 만족하기 어렵습니다.",
    "SelectD": "Amazon FSx for NetApp ONTAP 파일 시스템을 생성하고, 각 볼륨의 tiering policy를 NONE으로 설정한 후 원시 데이터를 가져옵니다. 이후 EC2 인스턴스에서 해당 파일 시스템을 마운트합니다.",
    "SelectD_Commentary": "tiering을 끄면 일부 성능 향상이 가능하지만 FSx for Lustre SSD만큼의 고성능 요구 사항(6GBps)을 달성하기에는 제한이 있습니다.",
    "Question_Description_recommedations": [
      "Q919",
      "Q604",
      "Q632",
      "Q369",
      "Q113"
    ],
    "SelectA_recommedations": [
      "Q990",
      "Q680",
      "Q818"
    ],
    "SelectB_recommedations": [
      "Q407",
      "Q155",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q407",
      "Q173",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q990",
      "Q680",
      "Q818"
    ]
  },
  {
    "Question_Number": "Q300",
    "Question_Description": "한 회사는 온프레미스 데이터 센터에서 하드웨어 용량 부족 문제로 인해 레거시 애플리케이션을 AWS Cloud로 마이그레이션해야 합니다. 이 애플리케이션은 연중무휴(24시간, 주7일)로 동작합니다. 데이터베이스 스토리지는 시간이 지날수록 계속 확장됩니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99948-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "장기적으로 24시간 상시 구동되는 애플리케이션은 Reserved Instances를 활용하면 큰 비용 절감 효과를 얻을 수 있으며, 스토리지 요구사항이 계속 증가하므로 Amazon Aurora의 자동 확장 기능이 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "장기 실행 워크로드",
      "비용 절감",
      "리저브드 인스턴스",
      "자동 스토리지 확장",
      "Aurora"
    ],
    "Terms": [
      "Amazon EC2 Spot Instances",
      "Amazon S3",
      "Amazon EC2 Reserved Instances",
      "Amazon RDS On-Demand Instances",
      "Amazon Aurora Reserved Instances",
      "Amazon RDS Reserved Instances"
    ],
    "SelectA": "애플리케이션 계층을 Amazon EC2 Spot Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon S3로 마이그레이션합니다.",
    "SelectA_Commentary": "Spot Instances는 저렴하지만 언제든지 인스턴스가 중단될 수 있어 24시간 상시 구동 애플리케이션에는 부적합합니다. 데이터베이스로 S3를 사용하는 것도 일반적이지 않습니다.",
    "SelectB": "애플리케이션 계층을 Amazon EC2 Reserved Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon RDS On-Demand Instances로 마이그레이션합니다.",
    "SelectB_Commentary": "애플리케이션에 Reserved Instances는 적절하나, RDS를 On-Demand로 사용하면 장기적으로 비용이 더 많이 들 수 있습니다.",
    "SelectC": "애플리케이션 계층을 Amazon EC2 Reserved Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon Aurora Reserved Instances로 마이그레이션합니다.",
    "SelectC_Commentary": "24시간 상시 구동 환경에는 Reserved Instances가 비용을 절감해 주고, Aurora의 자동 확장 기능으로 스토리지 요구 증가에도 효율적이며 장기적으로 가장 경제적입니다.",
    "SelectD": "애플리케이션 계층을 Amazon EC2 On-Demand Instances로 마이그레이션하고, 데이터 스토리지 계층을 Amazon RDS Reserved Instances로 마이그레이션합니다.",
    "SelectD_Commentary": "애플리케이션이 항상 동작하므로 On-Demand보다는 Reserved Instances가 더 적합합니다. 한쪽만 리저브드로 사용하는 것은 최적의 비용 절감에 미치지 못합니다.",
    "Question_Description_recommedations": [
      "Q486",
      "Q485",
      "Q728",
      "Q943",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q993",
      "Q1013"
    ],
    "SelectB_recommedations": [
      "Q380",
      "Q1013",
      "Q940"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q1013",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q380",
      "Q940"
    ]
  },
  {
    "Question_Number": "Q301",
    "Question_Description": "한 대학교 연구실이 온프레미스 Windows 파일 서버에 있는 30 TB 데이터를 Amazon FSx for Windows File Server로 마이그레이션해야 합니다. 연구실은 다른 부서와 공유하는 1 Gbps 네트워크 링크를 사용 중이며, 데이터 전송 성능을 최대화하면서도 다른 부서에 미치는 영향(대역폭 사용량)을 제어해야 합니다. 또한 데이터 이전은 5일 안에 완료되어야 합니다. 어떤 AWS 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99659-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 제한된 네트워크 대역폭을 공유하면서 대용량 데이터를 높은 성능으로 옮겨야 하는 시나리오입니다. AWS DataSync는 네트워크 전송 속도를 조정하고 안정적으로 30 TB를 5일 이내에 전송 가능하므로 가장 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "Amazon FSx for Windows File Server",
      "30 TB",
      "데이터 마이그레이션",
      "1 Gbps 네트워크",
      "데이터 전송 대역폭 조절"
    ],
    "Terms": [
      "AWS Snowcone",
      "Amazon FSx File Gateway",
      "AWS DataSync",
      "AWS Transfer Family",
      "Amazon FSx for Windows File Server"
    ],
    "SelectA": "AWS Snowcone을 사용하여 데이터를 이전합니다.",
    "SelectA_Commentary": "AWS Snowcone은 물리적 장비이므로 대용량인 30 TB를 신속히 전송하기에는 적합하지 않습니다.",
    "SelectB": "Amazon FSx File Gateway를 구성해 데이터를 전송합니다.",
    "SelectB_Commentary": "FSx File Gateway는 온프레미스 애플리케이션과 FSx를 연결하는 게이트웨이일 뿐, 대역폭 조절과 대규모 데이터 이전에 최적화되지 않았습니다.",
    "SelectC": "AWS DataSync를 사용하여 데이터를 전송합니다.",
    "SelectC_Commentary": "AWS DataSync는 전송 속도를 조절하고 대량 데이터도 네트워크를 통해 빠르게 복사할 수 있어 요구 사항에 부합합니다.",
    "SelectD": "AWS Transfer Family를 활용해 데이터를 이전합니다.",
    "SelectD_Commentary": "AWS Transfer Family는 SFTP, FTP 등의 프로토콜 전송용이므로 대역폭 제어와 대규모 파일 전송 자동화에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q64",
      "Q113",
      "Q331",
      "Q283",
      "Q844"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q865",
      "Q620"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q501",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q361",
      "Q515"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q865",
      "Q620"
    ]
  },
  {
    "Question_Number": "Q302",
    "Question_Description": "한 회사는 모바일 기기에서 슬로우 모션 동영상을 스트리밍할 수 있는 모바일 앱을 만들고자 합니다. 현재 앱은 비디오 클립을 촬영한 후 원본(Raw) 형식으로 Amazon S3 버킷에 업로드하고, 사용자는 해당 S3 버킷에서 직접 비디오 클립을 가져와 재생합니다. 그러나 원본 동영상 파일 크기가 커서 모바일 기기에서 버퍼링과 재생 문제가 발생하고 있습니다. 회사는 앱의 성능과 확장성을 극대화하며, 동시에 운영 오버헤드를 최소화할 수 있는 솔루션을 도입하려고 합니다. 다음 중 어떠한 솔루션 조합이 이러한 요구사항을 충족합니까? (두 가지를 고르시오.)",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99693-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 큰 원본 동영상을 모바일 환경에 맞게 효율적으로 제공하고 처리하는 방법을 결정하는 문제입니다. CloudFront를 통한 글로벌 캐싱과 Elastic Transcoder를 사용한 포맷 변환이 운영 오버헤드를 낮추면서 성능과 확장성을 극대화하는 최적의 조합입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4",
      "3.5"
    ],
    "Keywords": [
      "슬로우 모션 동영상",
      "모바일 스트리밍",
      "성능 및 확장성",
      "CloudFront",
      "Elastic Transcoder"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "AWS DataSync",
      "AWS Regions",
      "Amazon Elastic Transcoder",
      "Auto Scaling group",
      "Amazon EC2",
      "Local Zones"
    ],
    "SelectA": "Amazon CloudFront를 사용해 콘텐츠를 전송하고 캐싱합니다.",
    "SelectA_Commentary": "글로벌 엣지 로케이션을 통해 대기 시간을 낮추고 캐싱으로 성능이 개선됩니다. 운영 오버헤드도 낮아서 대용량 동영상 스트리밍에 유리합니다.",
    "SelectB": "AWS DataSync를 사용해 다른 AWS Regions의 여러 S3 버킷에 동영상 파일을 복제합니다.",
    "SelectB_Commentary": "DataSync는 주로 파일 동기화나 복제에 쓰이며 스트리밍 성능 개선에 직접적인 도움이 되지 않습니다.",
    "SelectC": "Amazon Elastic Transcoder를 사용해 동영상 파일을 더 적합한 형식으로 변환합니다.",
    "SelectC_Commentary": "원본 동영상을 모바일 친화적 포맷으로 인코딩해 파일 크기를 줄이고, 재생 품질과 스트리밍 성능을 높일 수 있어 효과적입니다.",
    "SelectD": "Local Zones에 Auto Scaling group을 구성한 Amazon EC2 인스턴스로 콘텐츠를 전송·캐싱합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 직접 설정해 캐싱하는 것은 운영이 복잡해지고, CloudFront를 활용한 글로벌 캐싱만큼 효율적이지 못합니다.",
    "SelectE": "Auto Scaling group의 Amazon EC2 인스턴스를 사용해 더 적합한 형식으로 동영상을 변환합니다.",
    "SelectE_Commentary": "직접 EC2로 트랜스코딩하면 관리 부담과 운영 비용이 커지며, 서비스 확장성도 Elastic Transcoder만큼 간편하지 않습니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q43",
      "Q501",
      "Q547",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q280",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q818",
      "Q155",
      "Q38"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q501",
      "Q631"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q461",
      "Q818"
    ],
    "SelectE_recommedations": [
      "Q335",
      "Q674",
      "Q461"
    ]
  },
  {
    "Question_Number": "Q303",
    "Question_Description": "한 회사가 새로운 애플리케이션을 Amazon ECS 클러스터에 배포하고 있으며, ECS 태스크에는 Fargate launch type을 사용하고 있습니다. 회사는 런칭 시 높은 트래픽이 예상되어 CPU와 메모리 사용량을 모니터링하고 있지만, 사용량이 감소할 때 비용을 절감하고 싶어 합니다. 솔루션스 아키텍트가 권장해야 할 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99813-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon ECS Fargate를 사용하는 애플리케이션에서 트래픽이 많을 때 확장하고, 트래픽이 적을 때 자동으로 리소스를 축소하여 비용을 절감하고자 하는 시나리오입니다. AWS Application Auto Scaling의 타깃 추적 정책을 사용하면 CPU, 메모리 등의 지표를 기준으로 ECS 태스크 수를 자동으로 조정하여 유연하고 비용 효율적인 아키텍처를 구축할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon ECS",
      "Fargate",
      "자동 확장",
      "CPU와 메모리",
      "비용 절감"
    ],
    "Terms": [
      "Amazon ECS",
      "Fargate launch type",
      "CPU and memory usage",
      "Amazon EC2 Auto Scaling",
      "AWS Lambda",
      "Amazon CloudWatch alarm",
      "AWS Application Auto Scaling",
      "Target tracking policy"
    ],
    "SelectA": "이전 트래픽 패턴을 기준으로 특정 시점에 확장하기 위해 Amazon EC2 Auto Scaling을 사용합니다.",
    "SelectA_Commentary": "정해진 스케줄에 따라 확장하므로 실시간 리소스 사용량 반영이 어려워, 트래픽 급증/감소에 즉각적으로 대응하기 어렵습니다.",
    "SelectB": "AWS Lambda 함수를 사용하여 Amazon CloudWatch 알람을 트리거하는 지표 초과 시 Amazon ECS를 확장합니다.",
    "SelectB_Commentary": "Lambda 함수를 직접 작성하고 관리해야 하므로 오버헤드가 늘어납니다. ECS에 대한 자동 확장 관리에 가장 적합한 방식은 아닙니다.",
    "SelectC": "Amazon EC2 Auto Scaling과 간단한 스케일링 정책을 사용하여 ECS 지표 초과 시 Amazon CloudWatch 알람으로 확장합니다.",
    "SelectC_Commentary": "EC2 Auto Scaling은 EC2 인스턴스에 초점을 맞추고 있으며, Fargate 태스크 자동 확장에는 적합하지 않아 운영이 복잡합니다.",
    "SelectD": "AWS Application Auto Scaling에 타깃 추적 정책을 사용하여 ECS 지표 초과 시 Amazon CloudWatch 알람으로 확장합니다.",
    "SelectD_Commentary": "Fargate 태스크에 최적화된 자동 확장을 제공하며 CPU, 메모리 사용률에 따라 빠르게 스케일 업/다운하여 비용을 효율적으로 관리할 수 있는 권장 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q698",
      "Q892",
      "Q584",
      "Q757",
      "Q244"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q1001",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q775",
      "Q900",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q581",
      "Q595",
      "Q210"
    ],
    "SelectD_recommedations": [
      "Q210",
      "Q595",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q304",
    "Question_Description": "한 회사가 다른 AWS Region에 재해 복구(Disaster Recovery) 사이트를 최근에 구축했습니다. 이 회사는 주기적으로 두 Region 간 NFS 파일 시스템에 저장된 대용량 데이터를 양방향으로 전송해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99949-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "주기적으로 대규모 데이터를 양방향으로 복제해야 하는 재해 복구 시나리오에서는 자동화와 최소 운영 오버헤드가 핵심입니다. AWS DataSync는 완전관리형 서비스로서, 별도 인프라 구성 없이 대량 데이터를 신속하고 안정적으로 전송하도록 지원합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "NFS 파일 시스템",
      "재해 복구",
      "AWS DataSync",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS DataSync",
      "AWS Snowball",
      "SFTP server on Amazon EC2",
      "AWS Database Migration Service (AWS DMS)",
      "NFS file system"
    ],
    "SelectA": "AWS DataSync를 사용합니다.",
    "SelectA_Commentary": "AWS DataSync는 두 Region 간 대규모 파일 전송을 자동화하고 운영 overhead를 최소화합니다. 완전관리형이므로 설정이 간단하고, 주기적인 동기화에도 적합합니다.",
    "SelectB": "AWS Snowball 디바이스를 사용합니다.",
    "SelectB_Commentary": "물리적 디바이스 배송이 필요하며 양방향 전송에도 반복 사용이 번거로워서 운영 오버헤드가 증가합니다.",
    "SelectC": "Amazon EC2에서 SFTP 서버를 구성합니다.",
    "SelectC_Commentary": "직접 서버를 구성·운영해야 하므로 유지보수 부담이 크고 자동화 측면에서 효율적이지 않습니다.",
    "SelectD": "AWS Database Migration Service(AWS DMS)를 사용합니다.",
    "SelectD_Commentary": "AWS DMS는 주로 데이터베이스 마이그레이션에 최적화되어 있으며, 파일 기반의 NFS 전송에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q585",
      "Q68",
      "Q891",
      "Q178",
      "Q842"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q845",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q188",
      "Q753",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q843",
      "Q133",
      "Q182"
    ]
  },
  {
    "Question_Number": "Q305",
    "Question_Description": "한 회사가 AWS Cloud에 호스팅된 게임 애플리케이션용 공유 스토리지 솔루션을 설계하고 있습니다. 이 회사는 SMB 클라이언트를 사용하여 데이터에 액세스할 수 있어야 합니다. 솔루션은 완전관리형(Fully Managed)이어야 합니다. 이러한 요구 사항을 충족하는 AWS 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99809-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SMB 프로토콜을 지원하는 완전관리형 공유 스토리지 솔루션을 구축하는 상황을 묻습니다. Amazon FSx for Windows File Server는 Windows 네이티브 SMB 공유를 완전관리형으로 제공하기 때문에 가장 적합합니다. 다른 옵션들은 직접 서버를 구성하거나 SMB와 호환되지 않거나 관리 부담이 크므로 적합하지 않습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "게임 애플리케이션",
      "공유 스토리지",
      "SMB 클라이언트",
      "완전관리형"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon EC2 Windows instance",
      "Windows file share role",
      "Amazon FSx for Windows File Server",
      "Amazon S3",
      "IAM role"
    ],
    "SelectA": "AWS DataSync 작업을 생성하여 데이터를 마운트 가능한 파일시스템으로 공유합니다. 이 파일시스템을 애플리케이션 서버에 마운트합니다.",
    "SelectA_Commentary": "AWS DataSync는 데이터 전송 및 동기화 서비스로 SMB 공유를 완전관리형 파일시스템 형태로 제공하지 않으므로 요구사항에 부합하지 않습니다.",
    "SelectB": "Amazon EC2 Windows 인스턴스를 생성합니다. 인스턴스에 Windows 파일 공유 역할을 설치하고 구성합니다. 애플리케이션 서버를 파일 공유에 연결합니다.",
    "SelectB_Commentary": "EC2 인스턴스에 Windows 파일 공유를 구성하면 사용자가 직접 OS와 파일 서버를 관리해야 하므로 완전관리형 솔루션이 아닙니다.",
    "SelectC": "Amazon FSx for Windows File Server 파일시스템을 생성합니다. 해당 파일시스템을 원본 서버에 연결합니다. 애플리케이션 서버를 파일시스템에 연결합니다.",
    "SelectC_Commentary": "Amazon FSx for Windows File Server는 SMB 프로토콜을 완전히 지원하고 완전관리형이므로 요구사항에 가장 부합하며 올바른 선택지입니다.",
    "SelectD": "Amazon S3 버킷을 생성합니다. 애플리케이션에 IAM role을 할당하여 S3 버킷에 대한 액세스를 부여합니다. S3 버킷을 애플리케이션 서버에 마운트합니다.",
    "SelectD_Commentary": "Amazon S3는 객체 스토리지로서 SMB 파일 공유 프로토콜을 직접 제공하지 않으며, 완전관리형 SMB 접근 방식과는 거리가 있습니다.",
    "Question_Description_recommedations": [
      "Q249",
      "Q603",
      "Q895",
      "Q631",
      "Q620"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q501",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q301",
      "Q361",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q672",
      "Q501",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q306",
    "Question_Description": "한 회사에서 Amazon EC2 인스턴스에서 실행되는 지연 시간에 민감한 애플리케이션을 위해 in-memory database를 사용하려고 합니다. 이 애플리케이션은 분당 100,000건 이상의 트랜잭션을 처리하며 높은 network throughput이 필요합니다. Solutions Architect는 data transfer charges를 최소화하면서 비용 효율적인 네트워크 설계를 제시해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "지연 시간에 민감하고 대규모 트랜잭션을 처리하는 환경에서, 동일 AZ에 모아 두고 cluster placement group을 사용하는 것이 비용을 낮추면서도 높은 처리량을 보장하는 핵심 포인트입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "인메모리 데이터베이스",
      "지연 시간 민감",
      "100,000건 트랜잭션",
      "높은 네트워크 처리량",
      "비용 효율적인 네트워크 설계",
      "데이터 전송 비용 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "in-memory database",
      "Availability Zone",
      "AWS Region",
      "placement group",
      "cluster strategy",
      "partition strategy",
      "Auto Scaling group",
      "step scaling policy",
      "network throughput",
      "data transfer charges"
    ],
    "SelectA": "동일한 AWS Region의 동일한 Availability Zone에 모든 EC2 인스턴스를 배포합니다. EC2 인스턴스를 시작할 때 cluster strategy가 적용된 placement group을 지정합니다.",
    "SelectA_Commentary": "모든 인스턴스를 하나의 AZ와 cluster placement group에 배치하면 네트워크 지연을 최소화하고, AZ 간 트래픽 비용을 피하면서 높은 처리량을 달성할 수 있는 최적의 해법입니다.",
    "SelectB": "동일한 AWS Region의 서로 다른 Availability Zone에 모든 EC2 인스턴스를 배포합니다. EC2 인스턴스를 시작할 때 partition strategy가 적용된 placement group을 지정합니다.",
    "SelectB_Commentary": "서로 다른 AZ에 분산하면 AZ 간 데이터 전송 비용이 증가하고, partition strategy는 동일 AZ 내에서의 높은 처리량을 극대화하기 어렵습니다.",
    "SelectC": "Auto Scaling group을 설정하여 네트워크 사용량 기준치에 따라 서로 다른 Availability Zone에 EC2 인스턴스를 배포합니다.",
    "SelectC_Commentary": "다수의 AZ로 확장되면 AZ 간 트래픽 비용이 증가하고, 지연 시간 및 네트워크 처리량 측면에서도 일관성 유지가 어려워집니다.",
    "SelectD": "step scaling policy를 적용한 Auto Scaling group을 사용하여 서로 다른 Availability Zone에 EC2 인스턴스를 배포합니다.",
    "SelectD_Commentary": "step scaling을 적용해도 Availability Zone이 달라지면 데이터 전송 비용이 늘어나고, 인스턴스 간 네트워크 성능을 극대화하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q124",
      "Q872",
      "Q196",
      "Q671",
      "Q1013"
    ],
    "SelectA_recommedations": [
      "Q773",
      "Q984",
      "Q290"
    ],
    "SelectB_recommedations": [
      "Q984",
      "Q773",
      "Q290"
    ],
    "SelectC_recommedations": [
      "Q290",
      "Q441",
      "Q984"
    ],
    "SelectD_recommedations": [
      "Q290",
      "Q441",
      "Q984"
    ]
  },
  {
    "Question_Number": "Q307",
    "Question_Description": "한 회사는 주로 온프레미스에서 애플리케이션 서버를 운영해 왔습니다. 이 회사는 AWS로 마이그레이션하면서 로컬 iSCSI 스토리지를 확장해야 하는 상황을 최소화하고자 합니다. 이때 최근에 액세스한 데이터만 로컬에 남기길 원합니다. 이러한 요구사항을 만족할 수 있는 AWS 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99611-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "회사는 온프레미스 iSCSI 스토리지 확장을 최소화하면서 자주 사용하는 데이터는 로컬에 캐싱하고 싶어 합니다. AWS Storage Gateway Volume Gateway cached volumes는 최근에 액세스한 데이터만 로컬에 저장하고 나머지를 Amazon S3에 보관하여 비용과 운영 부담을 줄이는 최적의 방식입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "온프레미스 iSCSI",
      "최근에 액세스된 데이터",
      "AWS Storage Gateway Volume Gateway",
      "cached volumes"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Volume Gateway",
      "Tape Gateway",
      "cached volumes",
      "stored volumes",
      "S3 File Gateway",
      "Amazon S3",
      "iSCSI",
      "마이그레이션"
    ],
    "SelectA": "Amazon S3 File Gateway",
    "SelectA_Commentary": "S3 File Gateway는 NFS나 SMB 프로토콜을 사용해 파일 스토리지를 제공하므로 iSCSI 기반으로 최근 데이터만 로컬에 보관하려는 요건과 맞지 않습니다.",
    "SelectB": "AWS Storage Gateway Tape Gateway",
    "SelectB_Commentary": "Tape Gateway는 백업 테이프 환경을 클라우드로 확장하는 솔루션으로, 최근에 자주 사용하는 데이터를 로컬에만 두는 요구사항을 만족하기 어렵습니다.",
    "SelectC": "AWS Storage Gateway Volume Gateway stored volumes",
    "SelectC_Commentary": "Stored volumes 모드는 전체 데이터를 온프레미스에 보관하고 AWS에 백업하므로 로컬 iSCSI 확장을 줄이려는 요구조건과 반대됩니다.",
    "SelectD": "AWS Storage Gateway Volume Gateway cached volumes",
    "SelectD_Commentary": "최근에 액세스된 데이터만 로컬에 캐싱하고 나머지는 Amazon S3에 저장하여 로컬 스토리지 확장을 최소화하는 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q728",
      "Q985",
      "Q238",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q703",
      "Q285",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q552",
      "Q238"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q308",
    "Question_Description": "한 회사가 통합 청구(Consolidated Billing)를 사용하는 여러 개의 AWS 계정을 보유하고 있습니다. 이 회사는 90일 동안 여러 개의 활성 고성능 Amazon RDS for Oracle 온디맨드(On-Demand) DB 인스턴스를 실행해 왔습니다. 회사의 재무 팀은 통합 청구 계정 및 모든 다른 AWS 계정에서 AWS Trusted Advisor에 접근할 수 있습니다. 재무 팀은 RDS 비용을 절감하기 위해 합리적인 AWS 계정에서 Trusted Advisor 체크 권장 사항을 확인하고, 적절한 Trusted Advisor 체크를 검토해야 합니다. 이 요구사항을 만족하기 위해 재무 팀이 수행해야 할 조합으로 적절한 것은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99936-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 실행되고 있는 On-Demand RDS 인스턴스의 비용을 절감하기 위해 어떤 Trusted Advisor 체크와 어느 계정에서 확인해야 하는지를 묻습니다. 통합 청구 계정을 통해 전체 RDS 사용 현황을 모니터링하고, 유휴(Idle) DB 인스턴스 체크를 통해 불필요한 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "RDS 비용 절감",
      "온디맨드 인스턴스",
      "통합 청구",
      "AWS Trusted Advisor",
      "활성 DB 인스턴스",
      "Idle DB Instances 체크"
    ],
    "Terms": [
      "Consolidated Billing",
      "Amazon RDS",
      "AWS Trusted Advisor",
      "Oracle On-Demand DB Instances",
      "Amazon RDS Reserved Instance Optimization",
      "Amazon RDS Idle DB Instances",
      "Amazon Redshift Reserved Node Optimization"
    ],
    "SelectA": "RDS 인스턴스가 실제로 실행 중인 계정에서만 Trusted Advisor 권장 사항을 확인합니다.",
    "SelectA_Commentary": "각 계정으로 따로 들어가서 확인하는 방식은 비효율적이며, 전체 사용 현황을 한눈에 보기가 어렵습니다. 또한 통합 청구 계정에서 일괄적으로 RDS 체크를 보는 것이 더 적합합니다.",
    "SelectB": "통합 청구 계정을 사용하여 모든 RDS 인스턴스 체크를 동시에 확인합니다.",
    "SelectB_Commentary": "통합 청구 계정에서는 여러 계정에 걸친 자원 사용량과 비용을 한 번에 모니터링할 수 있으므로 전체 RDS 비용 최적화 작업에 유리하며, 정답 중 하나입니다.",
    "SelectC": "Amazon RDS Reserved Instance Optimization 체크를 검토합니다.",
    "SelectC_Commentary": "Reserved Instance 최적화 체크는 유효한 방법이지만, 이 문제의 정답 두 가지 중 하나로 지목되지는 않았습니다. Reference에 따르면 더 긴 기간 사용하거나 다른 체크와 함께 검토할 수 있습니다.",
    "SelectD": "Amazon RDS Idle DB Instances 체크를 검토합니다.",
    "SelectD_Commentary": "오랫동안 유휴 상태로 유지되는 RDS 인스턴스가 있는지 확인하고, 필요 없다면 중지하거나 크기를 줄임으로써 비용 절감이 가능합니다. 정답 중 하나입니다.",
    "SelectE": "Amazon Redshift Reserved Node Optimization 체크를 검토합니다.",
    "SelectE_Commentary": "이 체크는 Amazon Redshift 전용이며, 현재 문제에서 다루는 Amazon RDS 비용 최적화와 직접 관련이 없으므로 오답입니다.",
    "Question_Description_recommedations": [
      "Q859",
      "Q948",
      "Q574",
      "Q959",
      "Q449"
    ],
    "SelectA_recommedations": [
      "Q959",
      "Q574",
      "Q579"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ],
    "SelectC_recommedations": [
      "Q152",
      "Q31",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q380",
      "Q959",
      "Q152"
    ],
    "SelectE_recommedations": [
      "Q943",
      "Q485",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q309",
    "Question_Description": "한 Solutions Architect가 스토리지 비용을 최적화해야 합니다. 이 Solutions Architect는 더 이상 사용되지 않거나 거의 사용되지 않는 Amazon S3 버킷을 식별해야 합니다. 가장 적은 운영 오버헤드로 이 목표를 달성할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99803-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷 사용 패턴을 파악하여 비용을 절감하려는 상황에서, 가장 적은 운영 오버헤드로 작동하는 기능을 찾는 것입니다. S3 Storage Lens는 S3 버킷 사용량과 액세스 패턴을 종합적으로 분석하고 보고서를 자동으로 제공하므로, 추가 설정 및 유지 관리 부담이 적습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "스토리지 비용 최적화",
      "Amazon S3 버킷 접근 패턴",
      "S3 Storage Lens",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "S3 Storage Lens",
      "S3 dashboard",
      "AWS Management Console",
      "Amazon CloudWatch BucketSizeBytes metric",
      "Amazon Athena",
      "AWS CloudTrail",
      "Amazon CloudWatch Logs"
    ],
    "SelectA": "S3 Storage Lens 대시보드를 사용하여 고급 액티비티 지표로 버킷 액세스 패턴을 분석합니다.",
    "SelectA_Commentary": "S3 Storage Lens는 완전관리형 분석 도구로 버킷 액세스 데이터를 간단히 시각화 및 분석 가능하여, 운영 오버헤드를 최소화하며 비용 최적화에 적합합니다.",
    "SelectB": "AWS Management Console의 S3 대시보드를 사용하여 버킷 액세스 패턴을 분석합니다.",
    "SelectB_Commentary": "기본 S3 대시보드는 버킷의 단순 지표만 제공하므로, 고급 액세스 분석이나 장기 사용 통계를 쉽게 확인하기 어렵습니다.",
    "SelectC": "각 버킷에 대해 Amazon CloudWatch BucketSizeBytes 지표를 활성화하고, Amazon Athena를 사용해 지표 데이터를 분석합니다.",
    "SelectC_Commentary": "CloudWatch 및 Athena를 함께 사용하는 것은 설정과 쿼리 작성 등 추가 작업이 필요하여 운영 오버헤드가 높아집니다.",
    "SelectD": "S3 객체 모니터링을 위해 AWS CloudTrail을 활성화하고, Amazon CloudWatch Logs와 통합된 CloudTrail 로그로 버킷 액세스 패턴을 분석합니다.",
    "SelectD_Commentary": "CloudTrail 로그 분석 방식은 설정, 로그 보관 및 분석 절차가 복잡하여 운영 부담이 증가합니다.",
    "Question_Description_recommedations": [
      "Q22",
      "Q872",
      "Q124",
      "Q643",
      "Q63"
    ],
    "SelectA_recommedations": [
      "Q88",
      "Q285",
      "Q911"
    ],
    "SelectB_recommedations": [
      "Q993",
      "Q829",
      "Q469"
    ],
    "SelectC_recommedations": [
      "Q160",
      "Q904",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q534",
      "Q227",
      "Q993"
    ]
  },
  {
    "Question_Number": "Q310",
    "Question_Description": "한 회사에서 AI/ML 연구를 수행하는 고객들에게 대규모로 포맷된 데이터셋을 판매하고 있습니다. 이러한 데이터셋은 us-east-1 리전의 Amazon S3 버킷에 저장되어 있으며, 회사는 Application Load Balancer 뒤의 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 호스팅하고 있습니다. 고객들은 웹 애플리케이션에서 데이터셋 열람권을 구매한 뒤, 해당 파일에 접근할 수 있도록 Amazon S3 signed URL을 받습니다. 고객들은 북미 및 유럽 전역에 분포해 있으며, 회사는 데이터 전송에 드는 비용을 줄이고 성능을 유지하거나 개선하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99697-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계에 분산된 고객에게 대규모 데이터셋을 제공하면서, 데이터 전송 비용을 낮추고 성능을 유지 또는 향상하려는 상황에서 최적의 방법을 찾아야 합니다. Amazon CloudFront는 엣지 로케이션을 통해 데이터를 캐싱하고, 가까운 위치에서 콘텐츠를 전달해 전송 비용을 절감하고 응답 속도를 높입니다. 따라서 CloudFront를 사용해 S3 버킷의 정적 파일을 배포하고 CloudFront signed URL로 보안 액세스를 제어하는 것이 가장 효과적인 접근 방식입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 전송 비용 절감",
      "성능 유지 및 개선",
      "Amazon CloudFront",
      "S3 signed URL",
      "Application Load Balancer"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2",
      "Application Load Balancer",
      "S3 signed URL",
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "Cross-Region Replication"
    ],
    "SelectA": "기존 S3 버킷에 S3 Transfer Acceleration을 구성하고, 고객 요청을 해당 가속화 엔드포인트로 유도합니다. 접근 제어에는 계속 S3 signed URL을 사용합니다.",
    "SelectA_Commentary": "S3 Transfer Acceleration은 특정 상황에서 전송 속도를 높일 수 있지만, CloudFront보다 전송 비용 절감과 글로벌 성능 향상 측면에서 이점이 작습니다.",
    "SelectB": "기존 S3 버킷을 오리진으로 하는 Amazon CloudFront 배포를 구성합니다. 고객 요청을 CloudFront URL로 유도하고, CloudFront signed URL을 이용해 액세스를 제어합니다.",
    "SelectB_Commentary": "전 세계 엣지 로케이션을 통한 캐싱으로 데이터 전송 비용 절감과 성능 개선을 모두 달성할 수 있는 최적의 솔루션입니다.",
    "SelectC": "eu-central-1 리전에 두 번째 S3 버킷을 생성하고, 두 버킷 간 S3 Cross-Region Replication을 설정합니다. 가장 가까운 리전에 고객 요청을 유도하고, S3 signed URL을 계속 사용합니다.",
    "SelectC_Commentary": "리전을 이중화해 지연 시간을 낮추는 효과는 있으나, 전 세계 고객 대상 앞단 캐싱이 없어 비용 절감 효과와 전송 성능 측면에서 부족합니다.",
    "SelectD": "웹 애플리케이션에서 사용자가 데이터를 스트리밍으로 받을 수 있도록 수정합니다. 웹 애플리케이션이 기존 S3 버킷에서 데이터를 읽도록 설정하고, 애플리케이션 내에서 직접 액세스 제어를 구현합니다.",
    "SelectD_Commentary": "데이터 스트리밍 로직을 애플리케이션에 구현하면 복잡성이 증가하고, CloudFront 활용에 비해 전송 비용 및 성능 최적화 효과가 제한적입니다.",
    "Question_Description_recommedations": [
      "Q993",
      "Q469",
      "Q736",
      "Q829",
      "Q960"
    ],
    "SelectA_recommedations": [
      "Q415",
      "Q829",
      "Q498"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q205",
      "Q829"
    ],
    "SelectC_recommedations": [
      "Q72",
      "Q415",
      "Q736"
    ],
    "SelectD_recommedations": [
      "Q997",
      "Q1003",
      "Q656"
    ]
  },
  {
    "Question_Number": "Q311",
    "Question_Description": "한 회사에서 AWS를 사용하여 보험 견적(quote)을 처리하는 웹 애플리케이션을 설계하려고 합니다. 사용자들은 애플리케이션을 통해 견적을 요청합니다. 견적은 견적 유형별로 분리되어야 하고, 24시간 내에 응답해야 하며, 유실되지 않아야 합니다. 또한 운영 효율성을 극대화하고 유지 보수를 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99627-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 메시지를 견적 유형별로 분리하고, 24시간 내에 처리 가능하며, 메시지가 유실되지 않도록 하는 안정적인 메시지 전송 및 소비 구조를 설계하는 것입니다. Amazon SNS와 SQS를 결합하여 SNS Message Filtering을 활용하면, 유지 보수를 최소화하면서도 견적 유형별로 메시지를 효율적으로 분리하고 안정적으로 처리할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "보험 견적",
      "견적 유형 분리",
      "24시간 내 응답",
      "유실 방지",
      "운영 효율성",
      "유지 보수 최소화",
      "SNS",
      "SQS",
      "Message Filtering"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "Kinesis Client Library (KCL)",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "SNS Message Filtering",
      "Amazon Kinesis Data Firehose",
      "Amazon OpenSearch Service"
    ],
    "SelectA": "견적 유형별로 여러 Amazon Kinesis data stream을 생성합니다. 웹 애플리케이션이 적절한 data stream으로 메시지를 전송하도록 구성합니다. 각 백엔드 애플리케이션 서버 그룹은 Kinesis Client Library(KCL)을 사용해 해당 data stream에서 메시지를 풀링합니다.",
    "SelectA_Commentary": "Kinesis Data Streams는 실시간 처리에 용이하지만, 견적 유형별 분리 후 메시지 보관이나 24시간 응답 보장에는 추가 고려가 필요해 유지 비용이 더 높아질 수 있습니다.",
    "SelectB": "각 견적 유형별로 AWS Lambda 함수와 Amazon SNS 주제를 생성합니다. Lambda 함수를 해당 SNS 주제에 구독시킵니다. 애플리케이션에서 적절한 SNS 주제로 견적 요청을 퍼블리시하도록 구성합니다.",
    "SelectB_Commentary": "Lambda와 SNS만으로는 메시지 보관 및 긴 대기열 처리가 부족하여 24시간 내 처리 보장에 제약이 있을 수 있으며, 유형별 분리가 더 복잡해질 수 있습니다.",
    "SelectC": "단일 Amazon SNS 주제를 생성하고, Amazon SQS 대기열들을 SNS 주제에 구독시킵니다. SNS Message Filtering을 사용하여 견적 유형에 따라 적절한 SQS 대기열로 메시지를 전달합니다. 각 백엔드 애플리케이션 서버는 자체 SQS 대기열을 사용합니다.",
    "SelectC_Commentary": "SNS와 SQS를 결합하고 Message Filtering을 활용해 견적 유형별로 메시지를 분리하고, 안정적인 메시지 보관과 24시간 내 처리 보장을 모두 충족하는 최적 솔루션입니다.",
    "SelectD": "견적 유형별로 여러 Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon OpenSearch Service로 데이터를 전송합니다. 애플리케이션에서 올바른 전송 스트림으로 메시지를 보냅니다. 각 백엔드 서버 그룹은 OpenSearch Service에서 메시지를 검색해 처리합니다.",
    "SelectD_Commentary": "OpenSearch Service와 Kinesis Data Firehose를 사용해 검색 기능을 제공할 수 있지만, 견적별 보장 처리 및 재시도가 복잡해지고 유지 보수가 늘어납니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q8",
      "Q163",
      "Q869",
      "Q802"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q351",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q45",
      "Q636",
      "Q148"
    ],
    "SelectC_recommedations": [
      "Q489",
      "Q636",
      "Q98"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q845",
      "Q400"
    ]
  },
  {
    "Question_Number": "Q312",
    "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 각 EC2 인스턴스는 여러 Amazon EBS 데이터 볼륨을 연결해 사용 중입니다. 매일 밤 애플리케이션의 EC2 인스턴스 구성과 데이터를 백업해야 하며, 다른 AWS Region에서도 애플리케이션을 복구할 수 있어야 합니다. 가장 운영 효율성이 높은 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99785-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스의 설정(구성)과 EBS 볼륨 데이터를 함께 백업하고, 다른 리전에서도 신속히 복원해 재해 복구 기능을 확보하는 방법을 묻습니다. AWS Backup을 사용해 EC2 인스턴스 자체를 백업 대상으로 지정하면 인스턴스 구성과 연결된 EBS 볼륨을 함께 백업∙복사할 수 있어 운영 부담을 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "백업",
      "Amazon EC2 인스턴스",
      "EBS 볼륨",
      "다른 리전 복구",
      "AWS Backup",
      "운영 효율"
    ],
    "Terms": [
      "AWS Backup",
      "Amazon EC2",
      "Amazon EBS",
      "스냅샷",
      "Region",
      "Availability Zone",
      "AWS Lambda",
      "백업 플랜"
    ],
    "SelectA": "매일 밤 애플리케이션 EBS 볼륨의 스냅샷을 생성하고, 다른 리전으로 스냅샷을 복사하는 AWS Lambda 함수를 작성합니다.",
    "SelectA_Commentary": "직접 Lambda 함수를 작성해 스냅샷을 관리해야 하므로 운영 복잡도가 높습니다. 또한 인스턴스 구성이 아닌 EBS 볼륨만 백업합니다.",
    "SelectB": "AWS Backup을 사용해 백업 플랜을 생성하고, 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EC2 인스턴스를 리소스로 추가합니다.",
    "SelectB_Commentary": "EC2 인스턴스를 대상으로 지정하면 인스턴스 설정과 EBS 볼륨 데이터가 함께 자동 백업되며, 리전 간 복사도 간편하게 설정 가능하여 가장 효율적입니다.",
    "SelectC": "AWS Backup을 사용해 백업 플랜을 생성하고, 매일 밤 백업을 수행합니다. 백업을 다른 리전으로 복사합니다. 애플리케이션의 EBS 볼륨을 리소스로 추가합니다.",
    "SelectC_Commentary": "EBS 볼륨만 백업 대상이 되어 EC2 인스턴스 구성은 포함되지 않아, 재해 복구 시 완벽한 복원이 어렵습니다.",
    "SelectD": "매일 밤 애플리케이션 EBS 볼륨의 스냅샷을 생성하고, 다른 가용 영역(Availability Zone)으로 스냅샷을 복사하는 AWS Lambda 함수를 작성합니다.",
    "SelectD_Commentary": "AZ 단위 복사는 리전 자체 문제가 발생하면 복구가 어려워 재해 복구에 적합하지 않으며, Lambda 함수를 직접 구현해야 해 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q456",
      "Q602",
      "Q224",
      "Q47",
      "Q5"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q785"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q892",
      "Q790"
    ],
    "SelectC_recommedations": [
      "Q602",
      "Q512",
      "Q843"
    ],
    "SelectD_recommedations": [
      "Q775",
      "Q639",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q313",
    "Question_Description": "한 회사가 AWS 상에서 모바일 앱을 구축하고 있으며, 수백만 명의 사용자에게 도달하기를 원합니다. 회사는 승인된 사용자만이 모바일 기기에서 회사의 콘텐츠를 시청할 수 있도록 플랫폼을 구축해야 합니다. 이를 위해 솔루션스 아키텍트는 어떤 방법을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100130-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 대규모 사용자에게 콘텐츠를 제공하면서 오직 승인된 사용자만 접근할 수 있도록 안정적으로 보호하고 확장성 있게 스트리밍하는 것입니다. Amazon CloudFront와 Signed URLs 조합은 글로벌 엣지 로케이션을 통해 빠른 콘텐츠 전송과 안전한 액세스 제어 모두를 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "모바일 앱",
      "승인된 사용자",
      "콘텐츠 스트리밍",
      "CloudFront",
      "Signed URL"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Signed URLs",
      "AWS Key Management Service (AWS KMS)",
      "IPsec VPN",
      "AWS Client VPN"
    ],
    "SelectA": "퍼블릭 Amazon S3 버킷에 콘텐츠를 게시하고, AWS KMS 키를 이용해 콘텐츠를 스트리밍합니다.",
    "SelectA_Commentary": "S3 버킷을 퍼블릭으로 설정하면 접근 제어가 충분치 않아, 승인되지 않은 사용자도 데이터에 접근할 수 있습니다.",
    "SelectB": "모바일 앱과 AWS 환경 간 IPsec VPN을 설정하여 콘텐츠를 스트리밍합니다.",
    "SelectB_Commentary": "VPN은 대규모 사용자에게 적용하기 어렵고, 각 사용자마다 VPN 연결이 필요하므로 확장성이 떨어집니다.",
    "SelectC": "Amazon CloudFront를 사용하고, Signed URLs을 제공하여 콘텐츠를 스트리밍합니다.",
    "SelectC_Commentary": "전 세계 사용자에게 빠르게 콘텐츠를 제공하면서, Signed URLs로 승인된 사용자만 접근하도록 제한하는 가장 적합한 솔루션입니다.",
    "SelectD": "모바일 앱과 AWS 환경 간 AWS Client VPN을 설정하여 콘텐츠를 스트리밍합니다.",
    "SelectD_Commentary": "Client VPN도 다수 사용자에게 적용하기 복잡하며, 스트리밍 요구에 맞는 확장성을 제공하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q922",
      "Q831",
      "Q592",
      "Q548",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q825",
      "Q44",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q782",
      "Q712",
      "Q15"
    ],
    "SelectC_recommedations": [
      "Q855",
      "Q172",
      "Q538"
    ],
    "SelectD_recommedations": [
      "Q782",
      "Q970",
      "Q529"
    ]
  },
  {
    "Question_Number": "Q314",
    "Question_Description": "한 회사에는 전 세계 세일즈 팀이 사용하며 접근 빈도가 낮은 on-premises MySQL database가 있습니다. 세일즈 팀은 이 데이터베이스가 최소한의 다운타임을 갖기를 요구합니다. 데이터베이스 관리자는 향후 더 많은 사용자가 늘어날 것을 예상하여 특정 인스턴스 타입을 선택하지 않고 이 데이터베이스를 AWS로 마이그레이션하고 싶어 합니다. 솔루션스 아키텍트는 어떤 서비스를 추천해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99769-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 on-premises MySQL database를 AWS로 이전하면서도 향후 확장성과 최소 다운타임을 모두 만족하는 해결책을 찾는 것입니다. Amazon Aurora Serverless for MySQL은 인스턴스 타입을 미리 정할 필요 없이 자동으로 확장·축소가 가능하므로 요구사항에 가장 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "온프레미스 MySQL database",
      "글로벌 세일즈 팀",
      "드문 접근 패턴",
      "최소 다운타임",
      "인스턴스 타입 미선택",
      "미래 사용자 증가",
      "Amazon Aurora Serverless for MySQL"
    ],
    "Terms": [
      "on-premises MySQL database",
      "Amazon Aurora MySQL",
      "Amazon Aurora Serverless for MySQL",
      "Amazon Redshift Spectrum",
      "Amazon RDS for MySQL",
      "minimal downtime",
      "infrequent access patterns",
      "serverless"
    ],
    "SelectA": "Amazon Aurora MySQL",
    "SelectA_Commentary": "Aurora MySQL은 고성능이지만 인스턴스 타입을 직접 선택해야 하므로 향후 사용자 증가에 대한 자동 확장 측면에서 Serverless 버전만큼 유연하지 않습니다.",
    "SelectB": "Amazon Aurora Serverless for MySQL",
    "SelectB_Commentary": "사용량에 따라 자동으로 확장하고 축소되어 특정 인스턴스 타입을 선택할 필요가 없습니다. 드문 접근 패턴과 증가할 수 있는 사용자 수를 모두 만족할 수 있는 최적의 솔루션입니다.",
    "SelectC": "Amazon Redshift Spectrum",
    "SelectC_Commentary": "Redshift Spectrum은 대규모 데이터 분석에 특화된 솔루션이며, MySQL 호환 DB로의 마이그레이션 및 최소 다운타임 요구사항을 충족하는 데 적절하지 않습니다.",
    "SelectD": "Amazon RDS for MySQL",
    "SelectD_Commentary": "RDS for MySQL은 관리가 간편하지만 인스턴스 타입을 사전에 선택해야 하며, 자동 확장 기능은 Aurora Serverless만큼 유연하지 않습니다.",
    "Question_Description_recommedations": [
      "Q565",
      "Q229",
      "Q834",
      "Q192",
      "Q95"
    ],
    "SelectA_recommedations": [
      "Q886",
      "Q472",
      "Q565"
    ],
    "SelectB_recommedations": [
      "Q886",
      "Q565",
      "Q229"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q361",
      "Q557"
    ],
    "SelectD_recommedations": [
      "Q229",
      "Q565",
      "Q386"
    ]
  },
  {
    "Question_Number": "Q315",
    "Question_Description": "한 회사는 온프레미스 데이터 센터에서 여러 애플리케이션에 영향을 미치는 침해 사고를 겪었습니다. 공격자는 서버에서 실행 중인 커스텀 애플리케이션의 취약점을 악용했습니다. 이제 이 회사는 애플리케이션을 Amazon EC2 인스턴스에서 실행하도록 마이그레이션하는 중입니다. 이 회사는 EC2 인스턴스에서 활발하게 취약점을 스캔하고, 그 결과를 자세히 알려주는 리포트를 전송하는 솔루션을 구현하기를 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99808-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서의 침해 사고를 EC2로 마이그레이션한 뒤에도 재발하지 않도록, 자동으로 취약점을 분석하고 리포트를 제공하는 솔루션을 요구합니다. Amazon Inspector는 EC2 인스턴스의 보안 취약점을 지속적으로 평가하고 결과 리포트를 자동화할 수 있어 적합한 해답이 됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "침해 사고",
      "취약점 스캔",
      "보고서 전송",
      "Amazon EC2",
      "Amazon Inspector"
    ],
    "Terms": [
      "AWS Shield",
      "Amazon Macie",
      "Amazon GuardDuty",
      "Amazon Inspector",
      "AWS Lambda",
      "AWS CloudTrail",
      "EC2 인스턴스",
      "Agent"
    ],
    "SelectA": "AWS Shield를 배포하여 EC2 인스턴스를 스캔합니다. AWS Lambda 함수를 생성하여 모든 발견사항을 AWS CloudTrail에 로깅합니다.",
    "SelectA_Commentary": "AWS Shield는 DDoS 공격 방어에 특화된 서비스로, 애플리케이션 취약점 스캔 기능은 제공하지 않습니다.",
    "SelectB": "Amazon Macie와 AWS Lambda 함수를 배포하여 EC2 인스턴스를 스캔합니다. 발견사항을 AWS CloudTrail에 로깅합니다.",
    "SelectB_Commentary": "Amazon Macie는 민감 데이터 식별에 중점을 둔 서비스이며, 일반적인 시스템 취약점 스캔 기능은 지원하지 않습니다.",
    "SelectC": "Amazon GuardDuty를 활성화하고 GuardDuty Agent를 EC2 인스턴스에 배포합니다. AWS Lambda 함수를 구성해 발견사항에 대한 상세 리포트를 자동 생성 및 배포합니다.",
    "SelectC_Commentary": "Amazon GuardDuty는 계정 및 네트워크 수준의 위협 탐지 서비스로, 애플리케이션 취약점 분석보다는 이상 트래픽 모니터링에 집중합니다.",
    "SelectD": "Amazon Inspector를 활성화하고 Amazon Inspector Agent를 EC2 인스턴스에 배포합니다. AWS Lambda 함수를 구성해 발견사항에 대한 상세 리포트를 자동 생성 및 배포합니다.",
    "SelectD_Commentary": "Amazon Inspector는 EC2 인스턴스를 대상으로 자동화된 취약점 평가를 수행하고 결과를 리포트로 생성해 운영 측면에서 효율적인 보안 솔루션을 제공합니다.",
    "Question_Description_recommedations": [
      "Q100",
      "Q682",
      "Q329",
      "Q480",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q970",
      "Q936",
      "Q492"
    ],
    "SelectB_recommedations": [
      "Q682",
      "Q453",
      "Q480"
    ],
    "SelectC_recommedations": [
      "Q936",
      "Q791",
      "Q682"
    ],
    "SelectD_recommedations": [
      "Q936",
      "Q492",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q316",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스를 사용하여 Amazon Simple Queue Service (Amazon SQS) 큐의 메시지를 폴링하고 처리하는 스크립트를 실행하고 있습니다. 이 회사는 큐에 추가되는 증가하는 메시지를 처리할 수 있는 능력을 유지하면서 운영 비용을 절감하기를 원합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트가 권장해야 하는 방법은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99698-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AWS Lambda로 마이그레이션하면 이벤트 기반으로만 비용을 지불하고, 대규모 메시지가 도착해도 자동으로 확장되어 운영 비용과 관리 부담을 효과적으로 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "운영 비용 절감",
      "자동 확장",
      "메시지 처리",
      "AWS Lambda"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon SQS",
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS Systems Manager Run Command",
      "Auto-scaling"
    ],
    "SelectA": "EC2 인스턴스의 크기를 늘려 메시지를 더 빠르게 처리하도록 합니다.",
    "SelectA_Commentary": "인스턴스 크기를 늘리면 순간 처리 속도는 높아지지만 비용이 급증하고 메시지 양 증가에 따른 자동 확장성이 충분히 보장되지 않습니다.",
    "SelectB": "Amazon EventBridge를 사용하여 EC2 인스턴스가 과소 활용될 때 인스턴스를 종료하도록 합니다.",
    "SelectB_Commentary": "EventBridge 스케줄링으로 인스턴스를 중지하는 것은 일부 비용 절감이 가능하나, 메시지 급증 시 즉시 확장과 자동 처리 기능을 제공하지 못해 한계가 있습니다.",
    "SelectC": "EC2 인스턴스에서 동작하는 스크립트를 적절한 런타임을 사용하여 AWS Lambda 함수로 마이그레이션합니다.",
    "SelectC_Commentary": "AWS Lambda는 이벤트 기반 실행과 자동 확장을 지원하여 증가하는 메시지를 효율적으로 처리하고, 실행한 만큼만 비용을 지불하므로 요구사항에 가장 적합한 솔루션입니다.",
    "SelectD": "AWS Systems Manager Run Command를 사용하여 스크립트를 온디맨드로 실행합니다.",
    "SelectD_Commentary": "온디맨드 실행은 특정 시점에만 처리 가능하며, 메시지 량 증가 시 즉각적인 자동 확장과 비용 효율성을 충분히 담보하지 못하므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q167",
      "Q238",
      "Q671",
      "Q867",
      "Q993"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ],
    "SelectC_recommedations": [
      "Q238",
      "Q552",
      "Q671"
    ],
    "SelectD_recommedations": [
      "Q284",
      "Q728",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q317",
    "Question_Description": "한 회사는 오래된(legacy) 애플리케이션으로부터 .csv 형식의 데이터를 생성하고, 이 데이터를 Amazon S3에 저장하고 있습니다. 회사는 Amazon Redshift와 Amazon S3에 저장된 데이터를 대상으로 복잡한 SQL 쿼리를 수행할 수 있는 신규 COTS(상용 오프더셸프) 애플리케이션을 배포하려고 합니다. 하지만 신규 COTS 애플리케이션은 기존 애플리케이션이 생성하는 .csv 파일을 처리할 수 없습니다. 또한 기존 애플리케이션에서 다른 형식을 생성하도록 업데이트하는 것은 불가능합니다. 회사는 신규 COTS 애플리케이션에서 기존 애플리케이션이 생성하는 데이터를 활용할 수 있도록 해야 하며, 이때 운영 오버헤드를 최소화해야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족할 수 있습니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99817-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 레거시 애플리케이션이 생성하는 .csv 파일을 Amazon Redshift에서 분석 가능하도록 변환하는 최적의 방법을 찾는 것입니다. 신규 COTS 애플리케이션은 Redshift와 S3만 지원하므로, 자동화된 ETL 파이프라인이 필요합니다. AWS Glue는 완전관리형 ETL 서비스로 스케줄 기반으로 작업을 수행할 수 있어 운영 오버헤드를 최소화합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "CSV 형식",
      "Amazon S3",
      "Amazon Redshift",
      "COTS 애플리케이션",
      "운영 오버헤드 최소화",
      "ETL"
    ],
    "Terms": [
      "AWS Glue",
      "ETL",
      "Amazon Redshift",
      "Amazon S3",
      "Amazon EMR",
      "Python 스크립트",
      "Amazon EC2",
      "Amazon DynamoDB",
      "Amazon EventBridge",
      "크론(cron) 스케줄"
    ],
    "SelectA": "스케줄에 따라 실행되는 AWS Glue ETL 잡을 생성합니다. .csv 파일을 처리하고 처리된 데이터를 Amazon Redshift에 저장하도록 구성합니다.",
    "SelectA_Commentary": "AWS Glue는 자동화된 ETL 파이프라인을 제공하므로 운영 관리를 최소화할 수 있습니다. 적은 노력으로 CSV 데이터를 Redshift 형식으로 변환 가능해 정답입니다.",
    "SelectB": "Amazon EC2 인스턴스에서 Python 스크립트를 실행하여 .csv 파일을 .sql 형식으로 변환합니다. cron 스케줄을 설정하여 변환 결과 파일을 Amazon S3에 저장합니다.",
    "SelectB_Commentary": "개발·배포 및 EC2 인스턴스 관리가 필요해 운영 오버헤드가 큽니다.",
    "SelectC": "AWS Lambda 함수와 Amazon DynamoDB 테이블을 생성합니다. S3 이벤트로 Lambda를 트리거해 CSV 파일을 ETL 작업으로 처리하고 DynamoDB에 저장합니다.",
    "SelectC_Commentary": "COTS 애플리케이션은 DynamoDB를 지원하지 않아 목적지로 적절치 않으며, 데이터베이스도 Redshift가 필요하므로 부적합합니다.",
    "SelectD": "Amazon EventBridge로 주간 스케줄에 따라 Amazon EMR 클러스터를 실행합니다. CSV 파일을 ETL 작업으로 처리하여 Amazon Redshift 테이블에 저장하도록 구성합니다.",
    "SelectD_Commentary": "EMR 클러스터 설정 및 관리가 필요하므로 Glue보다 운영 오버헤드가 더 큽니다.",
    "Question_Description_recommedations": [
      "Q214",
      "Q292",
      "Q414",
      "Q557",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q103",
      "Q557"
    ],
    "SelectB_recommedations": [
      "Q214",
      "Q414",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q804",
      "Q177",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q557",
      "Q414"
    ]
  },
  {
    "Question_Number": "Q318",
    "Question_Description": "한 회사가 최근 IT 환경 전체를 AWS Cloud로 마이그레이션했습니다. 이 회사는 사용자가 적절한 변경 제어 프로세스를 거치지 않고 용량이 과도하게 큰 Amazon EC2 인스턴스를 프로비저닝하고 security group 규칙을 수정하고 있음을 발견했습니다. 솔루션스 아키텍트는 이러한 인벤토리 및 configuration 변경 사항을 추적하고 감사(auditing)할 수 있는 전략을 마련해야 합니다. 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까? (2개를 선택하십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99804-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 환경에서 무분별하게 생성·수정되는 자원과 보안 설정을 추적·감사하는 방법을 묻습니다. AWS CloudTrail은 사용자 활동과 API 호출 이력을 기록하여 누가 어떻게 변경했는지 파악하게 해주며, AWS Config는 리소스 설정 변경 내용을 지속적으로 모니터링하고 규칙 기반 평가를 제공해 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "AWS Cloud",
      "Amazon EC2",
      "security group",
      "configuration 변경 추적",
      "auditing",
      "compliance"
    ],
    "Terms": [
      "AWS CloudTrail",
      "Amazon EC2",
      "security group",
      "AWS Config",
      "AWS Trusted Advisor",
      "AWS CloudFormation",
      "data lifecycle policies",
      "auditing",
      "compliance"
    ],
    "SelectA": "AWS CloudTrail을 활성화하고 이를 auditing에 활용합니다.",
    "SelectA_Commentary": "AWS CloudTrail은 계정 내 활동 이력을 기록하여 누가 어떤 작업을 수행했는지 쉽게 추적할 수 있습니다. 보안 이벤트 감시 및 감사에 핵심적인 역할을 하므로 적합합니다.",
    "SelectB": "Amazon EC2 인스턴스에 data lifecycle policies를 사용합니다.",
    "SelectB_Commentary": "data lifecycle policies는 주로 스토리지 관리와 보존 기간 등에 초점을 맞추므로, EC2 인스턴스나 보안 구성 변경 추적 및 감사와는 직접적인 관련이 없습니다.",
    "SelectC": "AWS Trusted Advisor를 활성화하고 security dashboard를 참고합니다.",
    "SelectC_Commentary": "AWS Trusted Advisor는 비용 최적화, 보안 모범 사례 등을 제안하지만, 실시간 변경 추적 및 세부 감사 기능을 직접 제공하지 않으므로 요구사항에 부합하지 않습니다.",
    "SelectD": "AWS Config를 활성화하고 auditing 및 compliance 목적을 위한 규칙을 생성합니다.",
    "SelectD_Commentary": "AWS Config는 리소스 구성 변경 이력을 추적하고 규칙 기반으로 이를 평가할 수 있습니다. 원하는 보안 규칙이나 구성 상태를 정의하면 자동으로 감사와 모니터링이 가능해집니다.",
    "SelectE": "AWS CloudFormation template을 사용하여 이전 resource configuration을 복원합니다.",
    "SelectE_Commentary": "AWS CloudFormation은 리소스 구성 자동화에 유용하지만, 이미 발생한 임의 변경 사항을 추적하고 감사하는 주 기능과는 거리가 멉니다.",
    "Question_Description_recommedations": [
      "Q624",
      "Q37",
      "Q15",
      "Q988",
      "Q395"
    ],
    "SelectA_recommedations": [
      "Q426",
      "Q898",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q453",
      "Q682",
      "Q710"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q529",
      "Q426"
    ],
    "SelectD_recommedations": [
      "Q426",
      "Q970",
      "Q529"
    ],
    "SelectE_recommedations": [
      "Q387",
      "Q893",
      "Q898"
    ]
  },
  {
    "Question_Number": "Q319",
    "Question_Description": "한 회사는 AWS Cloud에 수백 개의 Amazon EC2 Linux 기반 instance를 보유하고 있습니다. 시스템 관리자들은 이 instance들을 관리하기 위해 공유 SSH 키를 사용했습니다. 최근 감사 이후, 회사의 보안 팀은 모든 공유 키를 제거하도록 요구했습니다. 솔루션스 아키텍트는 EC2 instance에 대한 안전한 액세스를 제공하는 솔루션을 설계해야 합니다. 가장 적은 관리 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99628-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2에 대한 안전한 연결 방식을 최소한의 관리 부담으로 구성하는 방법을 묻습니다. Session Manager를 사용하면 SSH 키나 포트를 따로 관리할 필요가 없어 보안과 편의성을 동시에 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "공유 SSH 키",
      "EC2 인스턴스",
      "보안 액세스",
      "Session Manager",
      "관리 오버헤드"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Systems Manager Session Manager",
      "SSH 키",
      "AWS Security Token Service (AWS STS)",
      "Bastion Host",
      "Amazon Cognito",
      "AWS Lambda"
    ],
    "SelectA": "AWS Systems Manager Session Manager를 사용하여 EC2 인스턴스에 연결합니다.",
    "SelectA_Commentary": "Session Manager를 통해 SSH 포트를 열지 않고도 EC2에 안전하게 접속할 수 있으며, 키 관리 필요도 없어 관리 오버헤드가 최소화됩니다.",
    "SelectB": "AWS Security Token Service(AWS STS)를 사용하여 필요할 때마다 일회용 SSH 키를 생성합니다.",
    "SelectB_Commentary": "임시 키를 생성해도 각 사용자별 키를 발급·회수하는 절차가 필요해 관리 오버헤드가 증가합니다.",
    "SelectC": "Bastion 인스턴스 집합에 공유 SSH 접근을 허용하고, 다른 인스턴스는 bastion 인스턴스에서만 SSH를 허용하도록 구성합니다.",
    "SelectC_Commentary": "Bastion 호스트를 따로 운영하고 재설정해야 하므로, 공유 SSH 키 폐지가 충분치 않고 운영 복잡성이 커집니다.",
    "SelectD": "Amazon Cognito custom authorizer로 사용자 인증 후, AWS Lambda 함수를 호출하여 임시 SSH 키를 생성합니다.",
    "SelectD_Commentary": "Cognito와 Lambda 연동 구성이 복잡하며, 임시 키 생성·관리 절차로 인해 관리 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q766",
      "Q232",
      "Q492",
      "Q329",
      "Q453"
    ],
    "SelectA_recommedations": [
      "Q517",
      "Q873",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q793",
      "Q916",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q893",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q366",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q320",
    "Question_Description": "한 회사는 온프레미스 데이터 소스로부터 데이터를 수집하기 위해 여러 Amazon EC2 인스턴스를 사용하고 있습니다. 데이터는 JSON 형식이며, 최대 초당 1MB까지 수집 속도가 가능합니다. EC2 인스턴스가 재부팅될 경우, 전송 중이던 데이터가 손실됩니다. 회사의 데이터 사이언스 팀은 수집된 데이터를 거의 실시간으로 조회하길 원합니다. 최소한의 데이터 손실로 확장 가능하며 거의 실시간으로 데이터를 조회할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99752-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스에서 지속적으로 유입되는 데이터를 EC2 인스턴스에서 안전하게 처리하고, 거의 실시간으로 조회하기 위한 방법을 묻습니다. Kinesis Data Streams를 사용하면 데이터를 안정적으로 스트리밍하면서, Kinesis Data Analytics로 실시간 분석이 가능해 데이터 손실을 최소화하고 확장성도 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "JSON 데이터",
      "1MB/s",
      "근실시간 데이터 조회",
      "데이터 손실 최소화",
      "확장성"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "Kinesis Data Analytics",
      "Amazon Kinesis Data Firehose",
      "Amazon Redshift",
      "Amazon S3",
      "Amazon Athena",
      "Amazon ElastiCache for Redis",
      "Amazon EC2",
      "Amazon EBS",
      "JSON"
    ],
    "SelectA": "데이터를 Amazon Kinesis Data Streams로 전송하고, Kinesis Data Analytics를 사용하여 데이터를 조회합니다.",
    "SelectA_Commentary": "Kinesis Data Streams는 데이터가 빠르게 유입되어도 확장 가능하며, Kinesis Data Analytics를 통해 거의 실시간 데이터 처리가 가능합니다. EC2 인스턴스 재부팅 시에도 데이터 손실이 최소화됩니다.",
    "SelectB": "데이터를 Amazon Kinesis Data Firehose로 전송하고, 대상은 Amazon Redshift로 설정합니다. Amazon Redshift에서 데이터를 조회합니다.",
    "SelectB_Commentary": "Redshift로 대량 데이터 분석은 가능하지만, Firehose 배치는 일정 간격으로 수행되어 실시간성 측면에서 A보다 느리고, 구성 복잡도가 더 높아질 수 있습니다.",
    "SelectC": "수집된 데이터를 EC2 인스턴스 스토어에 저장한 뒤, Amazon Kinesis Data Firehose를 통해 Amazon S3로 전송합니다. Amazon Athena를 사용해 데이터를 조회합니다.",
    "SelectC_Commentary": "인스턴스 스토어는 EC2 인스턴스 종료나 재부팅 시 데이터 유실 위험이 큽니다. S3와 Athena로 조회가 가능하나, 근실시간 처리에는 다소 비효율적입니다.",
    "SelectD": "수집된 데이터를 Amazon EBS 볼륨에 저장하고, Amazon ElastiCache for Redis에 전송합니다. Redis 채널을 구독하여 데이터를 조회합니다.",
    "SelectD_Commentary": "Redis를 실시간 캐시로 활용할 수 있지만, EBS 저장 및 Redis 전송 과정이 복잡하고 재부팅 시 데이터 내구성이 보장되지 않아 손실 위험이 큽니다.",
    "Question_Description_recommedations": [
      "Q746",
      "Q2",
      "Q173",
      "Q547",
      "Q155"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q515",
      "Q177"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q402",
      "Q515",
      "Q557"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q386",
      "Q193"
    ]
  },
  {
    "Question_Number": "Q321",
    "Question_Description": "솔루션스 아키텍트가 Amazon S3 버킷에 업로드되는 모든 객체가 반드시 암호화되도록 하려면 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99685-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷 정책을 통해 객체 암호화를 보장하는 방법을 묻습니다. S3 버킷에 업로드될 때 x-amz-server-side-encryption 헤더가 없으면 요청을 거부하여 반드시 서버 측 암호화를 강제합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "암호화",
      "Bucket Policy",
      "x-amz-server-side-encryption"
    ],
    "Terms": [
      "Bucket Policy",
      "PutObject",
      "s3:x-amz-acl",
      "aws:SecureTransport",
      "x-amz-server-side-encryption"
    ],
    "SelectA": "PutObject 요청에 s3:x-amz-acl 헤더를 설정하지 않으면 거부하도록 버킷 정책을 업데이트합니다.",
    "SelectA_Commentary": "ACL 설정은 객체의 접근 권한을 정의할 뿐, 암호화 적용 여부와 직접적으로 관련이 없어 요구사항을 충족하지 못합니다.",
    "SelectB": "PutObject 요청에 s3:x-amz-acl 헤더가 private으로 설정되지 않으면 거부하도록 버킷 정책을 업데이트합니다.",
    "SelectB_Commentary": "ACL을 private으로 설정하는 것은 접근 제어에 대한 설정이지, 객체 암호화를 강제하지 못하므로 정답이 아닙니다.",
    "SelectC": "PutObject 요청에 aws:SecureTransport 헤더가 true가 아니면 거부하도록 버킷 정책을 업데이트합니다.",
    "SelectC_Commentary": "SecureTransport는 HTTPS 전송을 강제하지만, 암호화 적용(서버 측 암호화)과 직접적인 연관이 없어 정확한 요구사항을 만족시키지 못합니다.",
    "SelectD": "PutObject 요청에 x-amz-server-side-encryption 헤더가 없으면 거부하도록 버킷 정책을 업데이트합니다.",
    "SelectD_Commentary": "서버 측 암호화가 적용되지 않으면 요청을 거부하여 객체가 무조건 암호화되도록 보장하므로 이 옵션이 정답입니다.",
    "Question_Description_recommedations": [
      "Q202",
      "Q412",
      "Q270",
      "Q925",
      "Q825"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q740",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q740",
      "Q965",
      "Q678"
    ],
    "SelectC_recommedations": [
      "Q740",
      "Q965",
      "Q801"
    ],
    "SelectD_recommedations": [
      "Q740",
      "Q855",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q322",
    "Question_Description": "한 회사의 Solutions Architect가 다중 계층 애플리케이션을 설계하고 있습니다. 사용자는 모바일 기기에서 이미지를 업로드하며, 애플리케이션은 각 이미지에 대한 썸네일을 생성한 뒤 업로드 성공 메시지를 사용자에게 반환합니다. 썸네일 생성에 최대 60초가 걸릴 수 있지만, 사용자에게 원본 이미지가 성공적으로 접수되었음을 더 빨리 알리고 싶어 합니다. 따라서 애플리케이션은 서로 다른 계층에 비동기 방식으로 요청을 전달할 수 있어야 합니다. 이러한 요구사항을 충족하기 위해 어떤 솔루션을 구성해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99753-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자 요청에 대한 빠른 응답과 뒤에서 진행되는 긴 작업(썸네일 생성)을 분리하는 비동기 아키텍처 설계를 묻습니다. Amazon SQS는 느슨한 결합과 확장성을 제공하여 프런트엔드에서 빠른 응답 이후에 썸네일 생성 작업을 독립적으로 처리할 수 있도록 합니다. 이를 통해 사용자 경험을 개선하면서 애플리케이션 계층 간의 의존성을 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "비동기 처리",
      "이미지 업로드",
      "썸네일 생성",
      "모바일 사용자"
    ],
    "Terms": [
      "AWS Lambda",
      "AWS Step Functions",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)"
    ],
    "SelectA": "사용자 이미지 업로드 과정을 이벤트 소스로 하여 커스텀 AWS Lambda 함수를 호출하고, Lambda에서 썸네일을 생성한 뒤 사용자에게 알림을 보냅니다.",
    "SelectA_Commentary": "Lambda 하나로 모든 작업을 직접 처리하면 그 자체로는 간단해 보이지만, 썸네일 생성 시간 때문에 응답이 지연될 수 있으며 이벤트 소스 매핑만으로는 원하는 비동기 분리가 충분치 않습니다.",
    "SelectB": "AWS Step Functions 워크플로우를 생성하고, 애플리케이션 계층 간 오케스트레이션 및 썸네일 생성 완료 후 사용자 알림을 처리하도록 구성합니다.",
    "SelectB_Commentary": "Step Functions는 상태 기계 기반 오케스트레이션에 유용하나, 단순 썸네일 생성 트리거에는 오버엔지니어링일 수 있으며 빠른 사용자 응답과 완전한 비동기 처리에 초점을 맞추기에는 복잡합니다.",
    "SelectC": "Amazon SQS 메시지 큐를 생성하고, 이미지 업로드 시 SQS 큐에 메시지를 넣어 썸네일 생성을 처리합니다. 이후 애플리케이션 메시지로 사용자에게 업로드 완료를 알립니다.",
    "SelectC_Commentary": "SQS로 비동기 처리를 구현하면 신속한 사용자 응답 후 백그라운드에서 썸네일을 생성할 수 있어 구조가 단순하고 확장성도 우수합니다.",
    "SelectD": "Amazon SNS 토픽과 구독을 생성합니다. 하나의 구독으로 이미지 업로드 완료 후 애플리케이션에서 썸네일을 생성하고, 두 번째 구독으로 썸네일 생성 후 모바일 앱에 푸시 알림을 보냅니다.",
    "SelectD_Commentary": "SNS는 주로 팬아웃(Fan-out)이나 다중 구독 시나리오에 적합하지만, 여기서는 썸네일 작업 큐로 사용하는 데 오버헤드가 크고 정확한 작업 분리와 큐 관리는 어려울 수 있습니다.",
    "Question_Description_recommedations": [
      "Q323",
      "Q171",
      "Q288",
      "Q263",
      "Q454"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q531",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q363",
      "Q869",
      "Q785"
    ],
    "SelectC_recommedations": [
      "Q363",
      "Q869",
      "Q67"
    ],
    "SelectD_recommedations": [
      "Q615",
      "Q967",
      "Q149"
    ]
  },
  {
    "Question_Number": "Q323",
    "Question_Description": "한 회사 시설은 건물 전체의 각 출입구마다 배지 리더기를 설치해 두었습니다. 배지를 스캔하면, 해당 리더기는 누가 그 출입구에 접근했는지 HTTPS를 통해 메시지를 전송합니다. Solutions Architect는 이 센서로부터 오는 메시지를 처리할 시스템을 설계해야 합니다. 이 솔루션은 높은 가용성을 가지며, 결과를 회사의 보안팀이 분석할 수 있도록 제공되어야 합니다. 이러한 요구사항을 충족하는 시스템 아키텍처로 어떤 것을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99699-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 각 출입구에서 전송되는 센서 메시지를 안정적으로 처리해야 하는 시나리오입니다. 고가용성과 확장성을 보장하기 위해서는 서버리스 패턴을 사용하는 것이 최적입니다. Amazon API Gateway를 HTTPS endpoint로 구성하고, AWS Lambda에서 메시지를 처리함으로써 자동으로 확장되고 단일 장애 지점을 피할 수 있습니다. 처리 후 결과는 Amazon DynamoDB에 영구 보관되어 보안팀이 쉽게 분석할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "배지 리더기",
      "HTTPS 메시지",
      "높은 가용성",
      "보안팀 분석",
      "API Gateway",
      "DynamoDB"
    ],
    "Terms": [
      "Amazon EC2",
      "HTTPS endpoint",
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon Route 53",
      "VPC endpoint",
      "Site-to-Site VPN"
    ],
    "SelectA": "Amazon EC2 인스턴스를 시작하여 HTTPS endpoint 역할과 메시지 처리 역할을 수행하도록 합니다. 그리고 해당 EC2 인스턴스가 처리 결과를 Amazon S3 bucket에 저장하도록 구성합니다.",
    "SelectA_Commentary": "단일 Amazon EC2 인스턴스를 사용하면 단일 장애 지점이 생겨 고가용성을 보장하기 어렵습니다.",
    "SelectB": "Amazon API Gateway에서 HTTPS endpoint를 생성합니다. 그리고 API Gateway endpoint에서 AWS Lambda function을 호출하여 메시지를 처리하고 그 결과를 Amazon DynamoDB table에 저장하도록 구성합니다.",
    "SelectB_Commentary": "서버리스 아키텍처로 자동 확장 및 무중단 환경을 제공하므로 고가용성과 확장성을 충족하며 결과도 빠르게 저장하고 분석할 수 있어 가장 적합합니다.",
    "SelectC": "Amazon Route 53를 사용하여 들어오는 센서 메시지를 AWS Lambda function으로 라우팅합니다. 그리고 Lambda function을 구성하여 메시지를 처리한 후 그 결과를 Amazon DynamoDB table에 저장하도록 합니다.",
    "SelectC_Commentary": "Lambda 함수를 직접 Public Internet에 노출하는 것은 권장되지 않는 접근 방식이며, API Gateway가 제공하는 추가 보안 및 제어 기능을 활용하기 어렵습니다.",
    "SelectD": "Amazon S3를 위한 gateway VPC endpoint를 생성합니다. 시설 네트워크에서 VPC로의 Site-to-Site VPN connection을 설정하여, 센서 데이터가 VPC endpoint를 통해 S3 bucket에 직접 기록될 수 있도록 구성합니다.",
    "SelectD_Commentary": "VPN 설정과 VPC endpoint 구성으로 복잡도가 높아지고, 실시간 처리보다는 단순 원시 데이터 저장 방식이므로 요구사항에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q322",
      "Q171",
      "Q567",
      "Q149",
      "Q798"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q207",
      "Q25"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q207",
      "Q544"
    ],
    "SelectD_recommedations": [
      "Q487",
      "Q188",
      "Q891"
    ]
  },
  {
    "Question_Number": "Q324",
    "Question_Description": "한 회사는 온프레미스 주요 파일 스토리지 볼륨에 대한 재해 복구(Disaster Recovery) 계획을 구현하려고 합니다. 해당 파일 스토리지 볼륨은 로컬 스토리지 서버의 iSCSI 디바이스에 마운트되어 있으며, 수백TB에 달하는 데이터를 보유하고 있습니다. 회사는 온프레미스 시스템에서 모든 파일 유형에 대해 지연 없이 즉시 액세스가 가능하도록 유지하고 싶어 합니다. 기존 인프라에 대한 변경을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99711-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 전체 데이터를 완전히 유지하면서 즉시 액세스를 보장할 수 있는 재해 복구 솔루션을 찾는 것입니다. Volume Gateway stored 볼륨은 모든 데이터를 온프레미스에 저장하고, 주기적 스냅샷을 사용해 클라우드로 백업함으로써 로컬 환경에서의 성능 저하 없이 DR을 구현합니다. 재해 발생 시 스냅샷을 Amazon EBS 볼륨으로 복원해 빠르게 서비스를 재개할 수 있어, 기존 인프라 변경이 최소화되면서 즉시 액세스 요건을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "재해 복구",
      "온프레미스 파일 스토리지",
      "iSCSI",
      "수백TB",
      "지연 없이 즉시 액세스",
      "AWS Storage Gateway Volume Gateway stored volume"
    ],
    "Terms": [
      "Disaster Recovery",
      "iSCSI",
      "AWS Storage Gateway",
      "Amazon S3 File Gateway",
      "Volume Gateway (cached volume, stored volume)",
      "Tape Gateway",
      "Amazon EC2",
      "Amazon EBS",
      "NFS",
      "Snapshot"
    ],
    "SelectA": "온프레미스에 Amazon S3 File Gateway를 VM으로 프로비저닝하고 로컬 캐시 용량을 10TB로 설정합니다. 기존 애플리케이션이 NFS 프로토콜을 사용하도록 수정하고, 재해 시에는 Amazon EC2 인스턴스를 프로비저닝하여 S3 버킷을 마운트합니다.",
    "SelectA_Commentary": "기존 iSCSI 프로토콜 사용 환경을 NFS로 변경해야 하므로 인프라 변경 범위가 큽니다. 전체 데이터를 로컬에 모두 저장하지 않아 즉시 액세스에 제한이 있습니다.",
    "SelectB": "AWS Storage Gateway tape gateway를 프로비저닝합니다. 데이터 백업 솔루션을 이용해 기존 데이터를 가상 테이프 라이브러리에 백업하고, 수동으로 EBS 볼륨에 복원합니다.",
    "SelectB_Commentary": "테이프 백업은 주로 장기 보관용이며, 필요 시 즉시 액세스가 어렵고 복원 과정이 길어지는 단점이 있습니다.",
    "SelectC": "AWS Storage Gateway Volume Gateway cached volume을 프로비저닝하고 로컬 캐시를 10TB로 설정합니다. iSCSI로 파일 서버에 마운트 후 파일을 복사하고, 스냅샷을 예약합니다. 재해 시 스냅샷을 복원해 Amazon EBS 볼륨으로 사용합니다.",
    "SelectC_Commentary": "Cached 볼륨은 자주 액세스하는 데이터를 로컬에 두지만, 전체 데이터를 온프레미스에 보관하지 않아 네트워크 의존도가 커질 수 있고 즉시 액세스에 지연이 발생할 수 있습니다.",
    "SelectD": "AWS Storage Gateway Volume Gateway stored volume을 기존 파일 스토리지 볼륨만큼 디스크 공간으로 프로비저닝하고, iSCSI로 기존 파일 서버에 마운트합니다. 모든 파일을 저장한 후 스냅샷을 예약합니다. 재해 시 이 스냅샷을 Amazon EBS 볼륨으로 복원해 Amazon EC2 인스턴스에 연결합니다.",
    "SelectD_Commentary": "Stored 볼륨은 전체 데이터를 온프레미스에 보관하므로 애플리케이션 수정 없이 즉시 액세스가 가능합니다. DR 시 스냅샷을 통해 신속히 복원할 수 있어 요구 사항을 최적 충족합니다.",
    "Question_Description_recommedations": [
      "Q133",
      "Q52",
      "Q752",
      "Q1014",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q102",
      "Q934",
      "Q188"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q194",
      "Q892"
    ],
    "SelectC_recommedations": [
      "Q52",
      "Q934",
      "Q102"
    ],
    "SelectD_recommedations": [
      "Q944",
      "Q10",
      "Q934"
    ]
  },
  {
    "Question_Number": "Q325",
    "Question_Description": "한 회사가 Amazon S3 버킷에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon Cognito를 ID 공급자로 사용하여 사용자를 인증하고, 보호된 리소스(다른 S3 버킷에 저장됨)에 액세스할 수 있는 JSON Web Token(JWT)을 반환합니다. 애플리케이션 배포 후, 사용자들은 오류가 발생하여 보호된 콘텐츠에 액세스할 수 없다고 보고했습니다. 솔루션스 아키텍트는 사용자가 보호된 콘텐츠에 액세스할 수 있도록 적절한 권한을 부여해 이 문제를 해결해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99754-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon Cognito로 인증 후, JWT를 통해 다른 S3 버킷에 있는 보호된 리소스에 액세스할 수 있는 권한 설정이 제대로 되어 있지 않아 발생했습니다. Amazon Cognito Identity Pool이 올바른 IAM 역할을 사용하도록 구성해야만, 인증된 사용자들이 S3 버킷의 보호된 콘텐츠에 접근할 수 있습니다. 이는 Amazon Cognito를 통한 보안 액세스의 핵심 개념이며, 정답은 Identity Pool에 권한을 위임하는 방식으로 해결됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "웹 애플리케이션",
      "Amazon S3",
      "Amazon Cognito",
      "JSON Web Token(JWT)",
      "보호된 콘텐츠",
      "IAM 역할",
      "권한"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Cognito",
      "JSON Web Token(JWT)",
      "Identity Pool",
      "IAM Role",
      "ACL"
    ],
    "SelectA": "Amazon Cognito Identity Pool을 업데이트하여 보호된 콘텐츠에 액세스할 수 있는 적절한 IAM 역할을 할당합니다.",
    "SelectA_Commentary": "Cognito Identity Pool이 적절한 IAM 역할을 사용하여 인증된 사용자에게 필요한 권한을 부여함으로써 버킷의 보호된 리소스에 접근이 가능합니다.",
    "SelectB": "S3 ACL을 업데이트하여 애플리케이션이 보호된 콘텐츠에 액세스하도록 허용합니다.",
    "SelectB_Commentary": "ACL 단순 수정으로는 사용자 권한이 아닌 객체 수준 정책만 변경될 뿐이므로, Cognito 기반 인증 사용자에게 적절한 권한을 부여하는 근본 해결책이 되지 못합니다.",
    "SelectC": "Amazon S3에 애플리케이션을 다시 배포하여 Eventually Consistent Reads가 사용자 액세스에 영향을 주지 않도록 합니다.",
    "SelectC_Commentary": "재배포나 S3의 일시적 일관성 문제는 권한 부여와 직접적인 관련이 없으므로, 보호된 컨텐츠 접근 문제 해결과는 무관합니다.",
    "SelectD": "Amazon Cognito Pool에서 커스텀 속성 매핑을 사용하도록 업데이트하고 사용자들에게 보호된 콘텐츠 접속 권한을 부여합니다.",
    "SelectD_Commentary": "커스텀 속성 매핑은 사용자 속성만 정의할 뿐, 올바른 IAM 역할 부여와 직접 연결되지 않아 필요한 권한을 제대로 설정하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q982",
      "Q109",
      "Q862",
      "Q270",
      "Q740"
    ],
    "SelectA_recommedations": [
      "Q222",
      "Q476",
      "Q429"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q825",
      "Q678",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q898",
      "Q548",
      "Q313"
    ]
  },
  {
    "Question_Number": "Q326",
    "Question_Description": "한 이미지 호스팅 회사가 대용량 에셋을 Amazon S3 Standard 버킷에 업로드하고 있습니다. 해당 회사는 S3 API를 사용하여 multipart upload를 병렬로 수행하며, 같은 객체가 다시 업로드되면 덮어씁니다. 업로드 후 처음 30일 동안은 객체에 대한 액세스가 빈번하게 발생합니다. 30일 이후에는 객체를 덜 사용하지만, 각 객체마다 액세스 패턴이 일관적이지 않습니다. 이 회사는 저장된 에셋의 높은 가용성과 복원력을 유지하면서도 S3 스토리지 비용을 최적화해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트가 추천해야 할 조합은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99755-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 업로드되는 대용량 객체의 액세스 빈도가 30일 이후에 불규칙적으로 감소하는 상황에서, 비용을 효율적으로 줄이면서도 높은 가용성과 복원력을 유지하는 스토리지 전략을 찾는 것입니다. S3 Intelligent-Tiering은 액세스 패턴이 일정치 않은 객체를 자동으로 적절한 티어로 이동시켜 비용과 성능을 모두 만족합니다. 또한 불완전 multipart upload를 자동으로 정리하면 쓸데없이 발생하는 스토리지 비용을 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon S3 Standard",
      "multipart upload",
      "30일 후 액세스 감소",
      "액세스 패턴 불규칙",
      "S3 Intelligent-Tiering",
      "incomplete multipart uploads",
      "비용 최적화",
      "높은 가용성",
      "복원력"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Intelligent-Tiering",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "Multipart Upload",
      "Incomplete Multipart Upload",
      "Lifecycle Policy"
    ],
    "SelectA": "30일 후에 S3 Intelligent-Tiering으로 에셋을 이동합니다.",
    "SelectA_Commentary": "액세스 패턴이 불규칙한 객체를 자동으로 가장 적절한 티어로 전환해 비용을 절감하면서도 가용성과 복원력을 유지하므로 적합합니다.",
    "SelectB": "S3 Lifecycle 정책을 구성하여 불완전 multipart upload를 정리합니다.",
    "SelectB_Commentary": "병렬로 진행되는 multipart upload 중 불완전하게 남은 파트를 제거함으로써 스토리지 비용을 줄이고 운영 효율성을 높일 수 있습니다.",
    "SelectC": "S3 Lifecycle 정책으로 만료된 객체 삭제 마커를 정리합니다.",
    "SelectC_Commentary": "삭제 마커 정리는 버킷 정리에 유용하지만, 현재 요구사항인 액세스 패턴 최적화와 직접적인 연관이 크지 않습니다.",
    "SelectD": "30일 후에 S3 Standard-Infrequent Access (S3 Standard-IA)로 에셋을 이동합니다.",
    "SelectD_Commentary": "S3 Standard-IA로 전환 시 일관적으로 적은 액세스에 효과적이지만, 불규칙한 패턴에는 Intelligent-Tiering이 더 적합합니다.",
    "SelectE": "30일 후에 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 에셋을 이동합니다.",
    "SelectE_Commentary": "One Zone-IA는 가용 영역 하나만 활용해 복원력이 떨어집니다. 높은 가용성을 유지해야 하므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q725",
      "Q415",
      "Q890",
      "Q829",
      "Q498"
    ],
    "SelectA_recommedations": [
      "Q486",
      "Q943",
      "Q953"
    ],
    "SelectB_recommedations": [
      "Q326",
      "Q725",
      "Q829"
    ],
    "SelectC_recommedations": [
      "Q469",
      "Q829",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q126",
      "Q890"
    ],
    "SelectE_recommedations": [
      "Q943",
      "Q486",
      "Q606"
    ]
  },
  {
    "Question_Number": "Q327",
    "Question_Description": "한 솔루션스 아키텍트가 Amazon EC2 인스턴스를 호스팅하는 VPC 네트워크를 안전하게 구성해야 합니다. 이 EC2 인스턴스들은 매우 민감한 데이터를 포함하고, 프라이빗 서브넷에서 동작하고 있습니다. 회사 정책에 따르면, VPC에서 동작하는 EC2 인스턴스는 소프트웨어 제품 업데이트를 위해 해당 서드파티의 URL을 사용하는 승인된 서드파티 소프트웨어 레포지토리에만 인터넷 접속이 가능해야 합니다. 그 외 모든 인터넷 트래픽은 차단되어야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99795-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프라이빗 서브넷 내 민감 데이터를 보유한 EC2 인스턴스가 특정 서드파티 소프트웨어 레포지토리 URL만을 사용하도록 보안 정책을 구성하는 시나리오입니다. AWS Network Firewall을 통해 도메인 기반 아웃바운드 필터링을 수행하면, 승인된 도메인만 허용하고 나머지 인터넷 트래픽을 차단할 수 있어 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC 네트워크 보안",
      "민감한 데이터",
      "프라이빗 서브넷",
      "승인된 서드파티 레포지토리",
      "인터넷 트래픽 차단"
    ],
    "Terms": [
      "VPC",
      "Amazon EC2",
      "AWS Network Firewall",
      "domain list rule groups",
      "AWS WAF",
      "web ACL",
      "Application Load Balancer (ALB)",
      "Security Group",
      "Private Subnet"
    ],
    "SelectA": "프라이빗 서브넷의 라우트 테이블을 업데이트하여 아웃바운드 트래픽을 AWS Network Firewall로 라우팅합니다. 그리고 domain list rule groups를 구성합니다.",
    "SelectA_Commentary": "AWS Network Firewall에서 허용된 도메인만 아웃바운드로 접근하게 제어할 수 있으므로, 회사 정책을 가장 효과적으로 만족합니다.",
    "SelectB": "AWS WAF web ACL을 설정합니다. 소스 및 대상 IP 주소 범위 세트 기반으로 트래픽 요청을 필터링하는 커스텀 규칙 세트를 만듭니다.",
    "SelectB_Commentary": "AWS WAF는 주로 웹 어플리케이션 레이어 보호에 적합하며, IP 기반 필터링만으로 특정 도메인만 허용하기는 어렵습니다.",
    "SelectC": "엄격한 인바운드 보안 그룹 규칙을 구현합니다. 아웃바운드 규칙을 구성하여 인터넷 허가된 소프트웨어 레포지토리로만 트래픽을 허용하도록 URL을 지정합니다.",
    "SelectC_Commentary": "보안 그룹은 도메인 이름 기반의 제어가 불가능하므로, URL을 직접 지정해도 원하는 도메인만 필터링하기 어렵습니다.",
    "SelectD": "Amazon EC2 인스턴스 앞에 Application Load Balancer(ALB)를 구성합니다. 모든 아웃바운드 트래픽을 ALB로 전달하고 ALB의 타겟 그룹에서 URL 기반 룰 리스너를 사용하여 인터넷으로의 아웃바운드 액세스를 제어합니다.",
    "SelectD_Commentary": "ALB는 주로 인바운드 트래픽 처리를 위한 로드 밸런싱 서비스이며, 아웃바운드 트래픽 제어에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q866",
      "Q697",
      "Q92",
      "Q980",
      "Q610"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q831",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q1019",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q60",
      "Q884",
      "Q437"
    ]
  },
  {
    "Question_Number": "Q328",
    "Question_Description": "한 회사가 AWS Cloud 상에서 3티어 e-commerce 애플리케이션을 운영하고 있습니다. 회사는 Amazon S3에 웹사이트를 호스팅하고, 판매 요청을 처리하는 API와 연동하고 있습니다. 이 회사는 해당 API를 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스 3대로 호스팅하고 있습니다. 이 API는 정적 및 동적 프론트엔드 콘텐츠와 함께 백엔드 워커들이 비동기로 판매 요청을 처리하는 구조를 갖추고 있습니다. 이 회사는 신제품 출시 이벤트 기간 중 많은 수의 판매 요청이 갑작스레 증가할 것으로 예상하고 있습니다. 모든 요청이 성공적으로 처리되도록 하기 위해서는 어떤 솔루션을 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99704-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 및 API 레이어에서 엄청난 트래픽 증가에도 안정적으로 모든 요청을 처리할 수 있는 방법을 묻습니다. 비동기 처리를 위해 큐를 도입하거나 Auto Scaling으로 탄력적으로 확장하는 것이 주요 고려사항이며, 정적 콘텐츠를 CloudFront로 오프로드하면 트래픽 부담을 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "3티어 ecommerce",
      "Amazon S3",
      "갑작스러운 트래픽 증가",
      "비동기 요청 처리",
      "Application Load Balancer",
      "EC2 인스턴스",
      "CloudFront",
      "Auto Scaling",
      "Amazon SQS"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront",
      "Auto Scaling group",
      "Amazon ElastiCache",
      "Amazon Simple Queue Service(Amazon SQS)"
    ],
    "SelectA": "Amazon CloudFront를 동적 콘텐츠에 적용하고, EC2 인스턴스 수를 늘려 트래픽 증가를 처리합니다.",
    "SelectA_Commentary": "정적 리소스 캐싱에는 적합하지 않고, 단순히 EC2 인스턴스를 늘리는 것은 갑작스러운 폭증을 모두 처리하기엔 확장 시점이 늦어질 수 있습니다.",
    "SelectB": "Amazon CloudFront를 정적 콘텐츠에 적용하고, EC2 인스턴스를 Auto Scaling group에 배치하여 네트워크 트래픽에 따라 새 인스턴스를 시작합니다.",
    "SelectB_Commentary": "정적 콘텐츠 캐싱과 Auto Scaling으로 기본적인 확장은 가능하지만, 비동기 처리 보장을 위한 메시지 큐가 없어 트래픽 폭증 시 요청 손실 위험이 남아 있습니다.",
    "SelectC": "Amazon CloudFront를 동적 콘텐츠에 적용하고, ALB 앞단에 Amazon ElastiCache 인스턴스를 추가해 API 트래픽을 줄입니다.",
    "SelectC_Commentary": "동적 콘텐츠는 캐싱 효율이 낮아 효과가 제한적이며, 비동기 처리 측면에서 큐가 없어 요청이 몰릴 경우 모든 요청을 안전하게 처리하기 어렵습니다.",
    "SelectD": "Amazon CloudFront를 정적 콘텐츠에 적용하고, Amazon Simple Queue Service(Amazon SQS)를 추가해 웹사이트에서 들어오는 요청을 큐에 저장한 뒤 EC2 인스턴스가 나중에 처리하도록 합니다.",
    "SelectD_Commentary": "정적 콘텐츠를 CloudFront로 오프로드해 트래픽 부담을 줄이고, 비동기 처리를 위한 SQS 큐를 사용해 갑작스런 요청 증가에도 요청을 안전하게 받아 처리할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q537",
      "Q1012",
      "Q209",
      "Q775",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q757"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q944",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q203",
      "Q67",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q329",
    "Question_Description": "보안 감사 결과 Amazon EC2 인스턴스들이 정기적으로 패치되지 않고 있음이 확인되었습니다. 대규모 EC2 인스턴스 그룹에 대해 정기적인 보안 스캔을 수행해야 하며, EC2 인스턴스를 정기 일정에 맞춰 패치하고 각 인스턴스의 패치 상태 보고서도 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99796-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스의 취약성을 정기적으로 스캔하고 자동 패치를 적용하며 보고서까지 제공해야 하는 시나리오입니다. Amazon Inspector와 AWS Systems Manager Patch Manager의 조합이 이 요구사항을 만족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "정기적인 보안 스캔",
      "EC2 인스턴스 패치",
      "Amazon Inspector",
      "AWS Systems Manager Patch Manager"
    ],
    "Terms": [
      "Amazon Macie",
      "Amazon GuardDuty",
      "Amazon Detective",
      "Amazon Inspector",
      "AWS Systems Manager",
      "Patch Manager",
      "EC2",
      "소프트웨어 취약성",
      "cron job",
      "Amazon EventBridge"
    ],
    "SelectA": "Amazon Macie를 설정하여 EC2 인스턴스를 소프트웨어 취약성에 대해 스캔합니다. 각 EC2 인스턴스에서 정기 일정으로 패치하기 위해 cron job을 설정합니다.",
    "SelectA_Commentary": "Amazon Macie는 주로 데이터 분류와 유출 모니터링에 특화된 서비스라 취약성 스캔에 적합하지 않고, cron job은 개별 인스턴스마다 설정이 필요해 관리가 복잡합니다.",
    "SelectB": "Amazon GuardDuty를 계정에서 활성화합니다. GuardDuty가 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 구성합니다. EC2 인스턴스를 정기적으로 패치하기 위해 AWS Systems Manager Session Manager를 설정합니다.",
    "SelectB_Commentary": "GuardDuty는 악의적인 활동 모니터링에 특화되어 있을 뿐, 소프트웨어 취약성 스캔이나 패치 자동화를 직접 제공하지 않습니다. Session Manager는 원격 접속 도구이므로 자동 패치에는 적합하지 않습니다.",
    "SelectC": "Amazon Detective를 설정하여 EC2 인스턴스를 소프트웨어 취약성에 대해 스캔합니다. Amazon EventBridge 스케줄 규칙을 설정하여 EC2 인스턴스를 정기 일정으로 패치합니다.",
    "SelectC_Commentary": "Amazon Detective는 보안 이슈 상관관계 분석 서비스이므로 취약성 스캔 및 패치 기능을 제공하지 않습니다.",
    "SelectD": "Amazon Inspector를 계정에서 활성화합니다. Amazon Inspector가 소프트웨어 취약성에 대해 EC2 인스턴스를 스캔하도록 구성합니다. 정기 일정에 따라 EC2 인스턴스를 패치하기 위해 AWS Systems Manager Patch Manager를 설정합니다.",
    "SelectD_Commentary": "Amazon Inspector는 EC2 인스턴스의 보안 취약성 점검에, Patch Manager는 정기 패치 자동화와 보고서 기능에 특화되어 모두 필요한 기능을 충족합니다.",
    "Question_Description_recommedations": [
      "Q682",
      "Q315",
      "Q492",
      "Q453",
      "Q100"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q329",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q517",
      "Q681",
      "Q329"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q480",
      "Q453"
    ],
    "SelectD_recommedations": [
      "Q492",
      "Q329",
      "Q682"
    ]
  },
  {
    "Question_Number": "Q330",
    "Question_Description": "한 회사가 Amazon RDS DB 인스턴스에 데이터를 저장하려고 합니다. 이 회사는 저장 시 데이터를 반드시 암호화해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99702-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS에서 저장 시 데이터를 암호화하는 방법입니다. AWS KMS key를 이용해 RDS DB 인스턴스를 생성 시 암호화를 활성화하면, 자동으로 저장 중인 데이터가 암호화됩니다. Secrets Manager는 비밀번호와 같은 시크릿을 안전하게 보관하기 위해 사용되고, SSL/TLS 인증서는 전송 중인 데이터를 암호화하기 위한 것이므로 저장 시 암호화 요구사항과는 맞지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon RDS DB 인스턴스",
      "저장 시 데이터 암호화",
      "AWS KMS",
      "Secrets Manager",
      "SSL/TLS",
      "인증서"
    ],
    "Terms": [
      "Amazon RDS",
      "AWS KMS",
      "AWS Secrets Manager",
      "SSL/TLS",
      "AWS Certificate Manager(ACM)",
      "IAM",
      "Encryption at rest"
    ],
    "SelectA": "AWS Key Management Service(AWS KMS)에서 key를 생성합니다. DB 인스턴스에 암호화를 활성화합니다.",
    "SelectA_Commentary": "AWS KMS key로 RDS 암호화를 활성화하면 at-rest 상태에서도 데이터가 보호됩니다. 요구사항을 직접적으로 만족하는 올바른 방법입니다.",
    "SelectB": "암호화 key를 생성하고 이 key를 AWS Secrets Manager에 저장합니다. 이 key를 사용하여 DB 인스턴스를 암호화합니다.",
    "SelectB_Commentary": "Secrets Manager는 암호화된 시크릿을 저장하기 위한 서비스입니다. DB 인스턴스의 at-rest 암호화는 KMS를 통해 직접 설정하는 것이 올바른 접근입니다.",
    "SelectC": "AWS Certificate Manager(ACM)에서 인증서를 생성합니다. 이 인증서를 사용하여 DB 인스턴스에서 SSL/TLS를 활성화합니다.",
    "SelectC_Commentary": "SSL/TLS는 전송 중 암호화를 위한 것이며, 저장 시 암호화와는 직접 관련이 없습니다.",
    "SelectD": "AWS Identity and Access Management(IAM)에서 인증서를 생성합니다. 이 인증서를 사용하여 DB 인스턴스에서 SSL/TLS를 활성화합니다.",
    "SelectD_Commentary": "IAM에서 인증서를 생성해도 이는 데이터 전송 경로 암호화용이며, 저장 시 암호화 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q742",
      "Q732",
      "Q847",
      "Q61",
      "Q406"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q793"
    ],
    "SelectB_recommedations": [
      "Q645",
      "Q233",
      "Q740"
    ],
    "SelectC_recommedations": [
      "Q855",
      "Q681",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q331",
    "Question_Description": "한 회사가 30일 이내에 20TB의 데이터를 데이터 센터에서 AWS Cloud로 마이그레이션해야 합니다. 이 회사는 네트워크 대역폭이 15Mbps로 제한되어 있으며 70% 이상 사용하지 못합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99603-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 제한된 네트워크 대역폭(15Mbps 중 70%만 사용 가능)으로 30일 안에 20TB를 전송하는 시나리오입니다. 단순 계산으로 이 속도로는 약 3.4TB 정도만 전송 가능해 충분하지 않습니다. 따라서 대용량 물리 장비인 AWS Snowball을 사용하면 인터넷 대역폭 제약 없이 빠르고 안전하게 데이터를 옮길 수 있어 문제의 요구 사항을 충족시킵니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "데이터 마이그레이션",
      "30일 이내",
      "20TB",
      "제한된 네트워크",
      "15Mbps"
    ],
    "Terms": [
      "AWS Snowball",
      "AWS DataSync",
      "VPN",
      "Amazon S3 Transfer Acceleration",
      "MB와 Mb 혼동",
      "네트워크 대역폭"
    ],
    "SelectA": "AWS Snowball을 사용합니다.",
    "SelectA_Commentary": "AWS Snowball은 대량의 데이터를 네트워크 제한 없이 물리적으로 간편하게 전송할 수 있으므로 30일 이내에 20TB를 옮길 수 있습니다.",
    "SelectB": "AWS DataSync를 사용합니다.",
    "SelectB_Commentary": "DataSync는 네트워크를 통해 데이터 전송을 자동화하지만, 사용 가능한 대역폭이 매우 제한적이므로 목표 기간 내 전송량을 달성하기 어렵습니다.",
    "SelectC": "보안 VPN 연결을 사용합니다.",
    "SelectC_Commentary": "VPN 연결만으로는 제한된 대역폭을 능가할 수 없으므로 30일 안에 20TB를 전송하기에는 적합하지 않습니다.",
    "SelectD": "Amazon S3 Transfer Acceleration을 사용합니다.",
    "SelectD_Commentary": "Transfer Acceleration은 전송 속도를 높일 수 있으나, 네트워크 자체의 물리적 한계(15Mbps)의 근본적 제약을 넘어서기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q113",
      "Q604",
      "Q747",
      "Q127",
      "Q865"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q865",
      "Q620"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q501",
      "Q515"
    ],
    "SelectC_recommedations": [
      "Q77",
      "Q888",
      "Q158"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q38",
      "Q1015"
    ]
  },
  {
    "Question_Number": "Q332",
    "Question_Description": "한 회사가 직원들에게 기밀 및 민감한 파일에 대해 안전한 접근을 제공해야 합니다. 회사는 이러한 파일에 오직 승인된 사용자만 접근할 수 있도록 하고, 직원들의 기기에 안전하게 다운로드할 수 있도록 해야 합니다. 현재 파일들은 온프레미스 Windows 파일 서버에 저장되어 있는데, 원격 사용 증가로 인해 해당 파일 서버가 용량 부족 상태에 이르렀습니다. 이러한 요구 사항을 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99792-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Windows 파일 서버의 용량 부족과 직원들의 원격 접근 필요성을 동시에 해결하면서, 기밀 파일에 대한 접근 권한을 엄격히 통제하고 안전하게 다운로드하도록 보장하는 아키텍처 설계가 핵심입니다. Amazon FSx for Windows File Server에 데이터를 마이그레이션하고, 온프레미스 Active Directory와 통합 후, AWS Client VPN을 통해 안전한 연결을 제공하는 방법이 최적의 해법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "기밀 파일",
      "민감 데이터",
      "안전한 다운로드",
      "온프레미스 Windows 파일 서버",
      "용량 부족",
      "원격 사용",
      "Amazon FSx for Windows File Server",
      "AWS Client VPN",
      "Active Directory 통합"
    ],
    "Terms": [
      "Amazon FSx for Windows File Server",
      "AWS Client VPN",
      "Amazon EC2",
      "VPC Endpoint",
      "AWS IAM Identity Center (AWS Single Sign-On)"
    ],
    "SelectA": "Amazon EC2 퍼블릭 서브넷에 파일 서버를 마이그레이션하고, 보안 그룹으로 직원 IP 주소만 허용.",
    "SelectA_Commentary": "퍼블릭 서브넷의 EC2 인스턴스 자체 운영은 보안 및 확장성에 부담이 크고, 사용자 인증을 추가로 설계해야 하므로 기밀 파일에 대한 안정적인 접근 제어가 어렵습니다.",
    "SelectB": "Amazon FSx for Windows File Server로 파일을 마이그레이션하고 온프레미스 Active Directory와 통합. AWS Client VPN을 구성하여 안전하게 접속.",
    "SelectB_Commentary": "FSx for Windows File Server는 완전 관리형 파일 서비스로 기존 Windows 환경과 호환성을 제공하고, AD 통합으로 권한 관리를 단순화합니다. AWS Client VPN을 통해 원격 사용자는 안전하게 접근할 수 있어 요구 사항을 모두 충족합니다.",
    "SelectC": "Amazon S3로 파일을 마이그레이션하고 프라이빗 VPC Endpoint 사용. 서명된 URL을 생성하여 다운로드 허용.",
    "SelectC_Commentary": "서명된 URL로 안전한 다운로드가 가능하지만, Windows 파일 서버의 권한 구조를 직접적으로 반영하기 어렵고, AD 기반 권한 관리를 그대로 활용하기가 제한적입니다.",
    "SelectD": "Amazon S3로 파일을 마이그레이션하고 퍼블릭 VPC Endpoint 설정. 직원들은 AWS IAM Identity Center(AWS Single Sign-On)로 로그인.",
    "SelectD_Commentary": "퍼블릭 VPC Endpoint 사용 시 외부 노출 가능성이 높고, 세밀한 파일 서버 기반 권한 관리를 그대로 유지하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q57",
      "Q478",
      "Q665",
      "Q803",
      "Q122"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q96",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q500",
      "Q260",
      "Q832"
    ],
    "SelectC_recommedations": [
      "Q91",
      "Q92",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q982",
      "Q92",
      "Q91"
    ]
  },
  {
    "Question_Number": "Q333",
    "Question_Description": "한 회사의 애플리케이션이 Application Load Balancer (ALB) 뒤에서 Amazon EC2 인스턴스에서 동작하고 있습니다. 이 인스턴스들은 여러 Availability Zone에 걸쳐 Amazon EC2 Auto Scaling group 안에서 실행되고 있습니다. 매달 첫째 날 자정에 월말 재무 계산 배치가 실행될 때 애플리케이션이 매우 느려집니다. 이로 인해 EC2 인스턴스의 CPU 사용률이 즉시 100%로 치솟아 애플리케이션이 장애를 겪습니다. 솔루션스 아키텍트는 워크로드를 처리하고 다운타임을 방지하기 위해 무엇을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99791-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매달 특정 시점에 대규모 연산 부하가 집중되는 상황에서, 사전에 인스턴스 용량을 확장해 CPU 과부하를 방지해야 하는 것이 핵심입니다. Scheduled scaling policy를 사용해 정해진 시간에 자동으로 확장함으로써 서비스 장애 없이 높은 가용성을 유지할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EC2 Auto Scaling",
      "Application Load Balancer (ALB)",
      "CPU 사용률 100%",
      "매달 첫째 날 자정",
      "Scheduled scaling policy"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer (ALB)",
      "Amazon EC2 Auto Scaling",
      "Availability Zone",
      "Amazon CloudFront",
      "Amazon ElastiCache",
      "Simple scaling policy",
      "Scheduled scaling policy",
      "CPU utilization"
    ],
    "SelectA": "Application Load Balancer 앞에 Amazon CloudFront 배포를 구성합니다.",
    "SelectA_Commentary": "CloudFront는 정적 콘텐츠를 캐싱하여 전송 속도를 높이지만, 월말 계산처럼 CPU 자원이 필요한 부하에는 큰 효과가 없습니다.",
    "SelectB": "CPU 사용률을 기준으로 하는 EC2 Auto Scaling simple scaling policy를 구성합니다.",
    "SelectB_Commentary": "CPU가 이미 100%에 도달한 뒤에야 인스턴스를 확장하므로, 순간적인 과부하와 다운타임을 방지하기 어렵습니다.",
    "SelectC": "매달 일정에 따라 EC2 Auto Scaling scheduled scaling policy를 구성합니다.",
    "SelectC_Commentary": "월말 부하 시점을 미리 알고 있으므로, 사전에 리소스를 확장해 CPU 과부하 없이 안정적으로 애플리케이션을 운영할 수 있는 최적의 솔루션입니다.",
    "SelectD": "Amazon ElastiCache를 구성해 일부 워크로드를 EC2 인스턴스에서 분산시킵니다.",
    "SelectD_Commentary": "ElastiCache는 데이터 조회 부하를 줄일 수 있지만, 월말 재무 계산과 같은 고 CPU 사용 작업을 충분히 오프로딩하기엔 부족합니다.",
    "Question_Description_recommedations": [
      "Q174",
      "Q405",
      "Q275",
      "Q246",
      "Q589"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q357",
      "Q405"
    ],
    "SelectB_recommedations": [
      "Q660",
      "Q595",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q595",
      "Q581"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ]
  },
  {
    "Question_Number": "Q334",
    "Question_Description": "한 회사는 고객이 on-premises Microsoft Active Directory를 사용하여 Amazon S3에 저장된 파일을 다운로드할 수 있도록 하려고 합니다. 고객 애플리케이션은 파일 다운로드를 위해 SFTP 클라이언트를 사용하고 있습니다. 운영 오버헤드를 최소화하고 고객 애플리케이션에는 아무런 변경 사항이 없도록 하려면 다음 중 어떤 솔루션이 가장 적합합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99703-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SFTP를 통한 파일 다운로드 환경에서 on-premises Microsoft Active Directory와 연동해 Amazon S3 파일에 접근하도록 만드는 방법을 묻습니다. 운영 오버헤드를 최소화하고 기존 어플리케이션 변경 없이 SFTP를 제공해야 하므로, AWS Transfer Family를 통한 SFTP 구성이 가장 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "on-premises Microsoft Active Directory",
      "SFTP 클라이언트",
      "Amazon S3",
      "운영 오버헤드 최소화",
      "애플리케이션 변경 없음"
    ],
    "Terms": [
      "AWS Transfer Family",
      "SFTP",
      "Amazon S3",
      "Microsoft Active Directory",
      "AWS Database Migration Service (AWS DMS)",
      "AWS DataSync",
      "IAM Identity Center (AWS Single Sign-On)",
      "Amazon EC2",
      "IAM"
    ],
    "SelectA": "AWS Transfer Family에서 Amazon S3를 대상으로 SFTP를 설정하고, on-premises Active Directory 인증을 통합합니다.",
    "SelectA_Commentary": "AWS Transfer Family는 별도의 서버 운영 없이도 SFTP 서비스를 제공하고, Microsoft Active Directory 연동으로 인증을 간소화합니다.",
    "SelectB": "AWS Database Migration Service(AWS DMS)를 설정하여 on-premises 클라이언트와 Amazon S3를 동기화합니다. 통합 Active Directory 인증을 구성합니다.",
    "SelectB_Commentary": "DMS는 주로 데이터베이스 마이그레이션용 서비스로, SFTP 다운로드 요구사항과 맞지 않으며 오버헤드가 높습니다.",
    "SelectC": "AWS DataSync를 사용해 on-premises 위치와 S3 위치 간 동기화를 수행하고, AWS IAM Identity Center(AWS Single Sign-On)를 사용합니다.",
    "SelectC_Commentary": "DataSync는 대규모 데이터 전송 자동화에 적합하나, SFTP 접근을 직접 제공하지 않아 애플리케이션 측을 바꿔야 할 수 있습니다.",
    "SelectD": "Windows Amazon EC2 인스턴스에서 SFTP 서버를 구성하여 on-premises 클라이언트와 Amazon S3를 연동합니다. AWS Identity and Access Management(IAM)를 통합합니다.",
    "SelectD_Commentary": "EC2 서버 구성 및 유지보수 등 운영 부담이 크고, 별도의 SFTP 서버 운영이 필요해 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q832",
      "Q816",
      "Q270",
      "Q826",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q334",
      "Q832",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q334",
      "Q681",
      "Q826"
    ],
    "SelectC_recommedations": [
      "Q982",
      "Q688",
      "Q981"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q832",
      "Q1017"
    ]
  },
  {
    "Question_Number": "Q335",
    "Question_Description": "한 회사가 갑작스러운 수요 증가를 경험하고 있습니다. 회사는 Amazon Machine Image(AMI)에서 대형 Amazon EC2 인스턴스를 프로비저닝해야 합니다. 이 인스턴스들은 Auto Scaling group에서 실행됩니다. 회사는 이러한 수요를 충족하기 위해 초기화 지연 시간이 최소화되는 솔루션이 필요합니다. 어떤 솔루션이 이 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99686-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Auto Scaling group에서 대형 Amazon EC2 인스턴스를 빠르게 시작해야 할 때, EBS 볼륨 초기화를 최소화하는 방법을 묻습니다. EBS Fast Snapshot Restore를 활성화하면 인스턴스 부팅 지연이 크게 감소하여 갑작스러운 수요 증가에도 빠르게 대응할 수 있습니다. 따라서 B가 최소 초기화 지연을 달성하는 최적의 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Auto Scaling group",
      "초기화 지연 시간",
      "EBS fast snapshot restore",
      "AMI"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Machine Image(AMI)",
      "Auto Scaling group",
      "Amazon Elastic Block Store(Amazon EBS)",
      "Fast Snapshot Restore",
      "Amazon Data Lifecycle Manager(Amazon DLM)",
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS Backup lifecycle policies",
      "AWS Step Functions"
    ],
    "SelectA": "aws ec2 register-image 명령을 사용해 스냅샷에서 AMI를 생성합니다. AWS Step Functions를 사용해 Auto Scaling group의 AMI를 교체합니다.",
    "SelectA_Commentary": "AMI를 직접 등록해서 교체하는 방법이지만, 스냅샷 초기화 속도를 개선하지 않아 인스턴스 부팅 시간이 길어질 수 있습니다.",
    "SelectB": "Amazon Elastic Block Store(Amazon EBS) fast snapshot restore를 스냅샷에 대해 활성화합니다. 해당 스냅샷을 사용해 AMI를 프로비저닝한 후, 새로운 AMI로 Auto Scaling group을 업데이트합니다.",
    "SelectB_Commentary": "EBS fast snapshot restore를 통해 스냅샷 데이터를 미리 준비해두어 인스턴스 부팅 시간을 최소화할 수 있는 올바른 솔루션입니다.",
    "SelectC": "Amazon Data Lifecycle Manager(Amazon DLM)에서 AMI 생성을 활성화하고, 수명 주기 규칙을 정의합니다. AWS Lambda 함수를 만들어 Auto Scaling group에 설정된 AMI를 수정합니다.",
    "SelectC_Commentary": "AMI 관리를 자동화할 수 있지만, EBS 볼륨 초기화 지연을 근본적으로 해결하지 못하므로 요구사항에 부합하지 않습니다.",
    "SelectD": "Amazon EventBridge를 사용하여 AWS Backup 수명 주기 정책을 호출해 AMI를 생성하도록 합니다. Auto Scaling group 용량 제한을 EventBridge 이벤트 소스로 구성합니다.",
    "SelectD_Commentary": "AMI 생성 자동화를 지원하지만, EBS fast snapshot restore와 같은 초기화 지연 단축 기능을 언급하지 않아 적절한 솔루션이 아닙니다.",
    "Question_Description_recommedations": [
      "Q461",
      "Q219",
      "Q261",
      "Q746",
      "Q857"
    ],
    "SelectA_recommedations": [
      "Q335",
      "Q461",
      "Q674"
    ],
    "SelectB_recommedations": [
      "Q335",
      "Q695",
      "Q680"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q143",
      "Q461"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q461",
      "Q249"
    ]
  },
  {
    "Question_Number": "Q336",
    "Question_Description": "한 회사는 Amazon Aurora MySQL DB cluster를 스토리지로 사용하는 다중 계층 웹 애플리케이션을 운영 중입니다. 애플리케이션 계층은 Amazon EC2 인스턴스에서 동작합니다. 회사의 IT 보안 지침에 따르면 데이터베이스 자격 증명은 암호화되어야 하며, 14일마다 회전되어야 합니다. 운영 노력을 최소화하면서 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99790-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DB 자격 증명을 안전하게 보호하고 주기적으로 자동 회전해야 하는 요구사항을 해결하는 방식에 대한 것입니다. 가장 적은 운영 노력으로 구현하려면 AWS Secrets Manager를 사용하여 자격 증명을 암호화하고, 설정된 일정에 맞춰 자동 회전하도록 구성하는 것이 효과적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon Aurora MySQL",
      "암호화",
      "자격 증명 회전",
      "14일 주기",
      "AWS Secrets Manager",
      "운영 부담 최소화"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "SecureString",
      "AWS Lambda",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon S3",
      "Amazon Aurora MySQL DB cluster"
    ],
    "SelectA": "새로운 AWS Key Management Service (AWS KMS) 암호화 키를 생성합니다. AWS Secrets Manager를 사용하여 해당 KMS 키와 적절한 자격 증명을 사용하는 새로운 시크릿을 생성합니다. 이 시크릿을 Aurora DB cluster에 연결하고, 14일의 커스텀 회전 주기를 구성합니다.",
    "SelectA_Commentary": "Secrets Manager를 사용하면 데이터베이스 자격 증명을 안전하게 저장하고 자동으로 회전할 수 있습니다. KMS 키를 통해 암호화 가능하며, 14일 회전 주기를 쉽게 설정할 수 있어 운영 부담이 적습니다.",
    "SelectB": "AWS Systems Manager Parameter Store에서 두 개의 파라미터를 생성합니다: 하나는 user name을 위한 string 파라미터, 다른 하나는 password를 위한 SecureString 타입입니다. password 파라미터에 AWS KMS 암호화를 적용하고, 애플리케이션 계층에서 이 파라미터들을 로드합니다. 14일마다 password를 회전하는 AWS Lambda 함수를 구현합니다.",
    "SelectB_Commentary": "AWS Systems Manager Parameter Store에 수동 설정과 Lambda 함수를 사용해 직접 회전 로직을 구현해야 하므로 운영 부담이 늘어나고 관리가 복잡해집니다.",
    "SelectC": "AWS KMS로 암호화된 Amazon EFS 파일 시스템에 자격 증명이 들어 있는 파일을 저장합니다. 이를 애플리케이션 계층의 모든 EC2 인스턴스에 마운트하고, 파일 시스템 권한을 제한합니다. 14일마다 Aurora의 키를 회전하고 새로운 자격 증명을 파일에 기록하는 AWS Lambda 함수를 구현합니다.",
    "SelectC_Commentary": "EFS 파일을 마운트하고 Lambda 함수를 통해 자격 증명을 갱신해야 하므로 설정이 복잡해지고 운영 단계가 많아집니다.",
    "SelectD": "AWS KMS로 암호화된 Amazon S3 버킷에 자격 증명이 저장된 파일을 두고, 애플리케이션은 이 파일에서 자격 증명을 로드합니다. 주기적으로 파일을 다운로드해 올바른 자격 증명을 사용하도록 하고, 14일마다 Aurora 자격 증명을 회전한 뒤 이를 S3 버킷 상의 파일에 업로드하는 AWS Lambda 함수를 구현합니다.",
    "SelectD_Commentary": "S3에 파일 형태로 저장하고 필요 시 재다운로드해야 하므로, 자격 증명 동기화와 Lambda 회전 로직까지 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q994",
      "Q854",
      "Q176",
      "Q733",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectB_recommedations": [
      "Q640",
      "Q916",
      "Q550"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q681",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q1009",
      "Q550",
      "Q640"
    ]
  },
  {
    "Question_Number": "Q337",
    "Question_Description": "한 회사가 AWS에 웹 애플리케이션을 배포했습니다. 회사는 백엔드 데이터베이스로 Amazon RDS for MySQL을 사용하며, 기본(primary) DB 인스턴스와 다섯 개의 read replica를 통해 확장성을 지원하고 있습니다. 이 read replica들은 기본 DB 인스턴스와 1초 이상 차이가 나지 않도록 유지해야 합니다. 해당 데이터베이스는 정기적으로 스케줄된 stored procedure들을 실행합니다. 웹사이트 트래픽이 증가함에 따라 피크 부하 시점에 read replica 지연이 커지고 있습니다. 솔루션스 아키텍트는 지연을 가능한 한 줄이고, 애플리케이션 코드 변경을 최소화하며, 지속적인 운영 오버헤드를 최소화해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99871-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS for MySQL에서 발생하는 read replica 지연을 줄이기 위해서 어떻게 해야 하는지를 묻습니다. 트래픽 증가 시에도 최소한의 코딩 수정과 운영 부담으로 최대한의 성능을 낼 수 있어야 합니다. Aurora MySQL은 MySQL과 호환되면서 고성능, 저지연 읽기 복제를 제공합니다. 따라서 애플리케이션 코드 변경을 최소화하고, 복제 지연 문제를 완화하는 데 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "RDS for MySQL",
      "Replication Lag",
      "Read Replica",
      "Stored Procedure",
      "고성능"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Aurora MySQL",
      "Aurora Replicas",
      "Aurora Auto Scaling",
      "Amazon ElastiCache for Redis",
      "AWS Lambda",
      "Amazon EC2",
      "Amazon DynamoDB",
      "DynamoDB Streams",
      "Stored Procedure"
    ],
    "SelectA": "데이터베이스를 Amazon Aurora MySQL로 마이그레이션합니다. read replica들을 Aurora Replica로 대체하고, Aurora Auto Scaling을 구성합니다. 스토어드 프로시저를 Aurora MySQL의 네이티브 함수로 대체합니다.",
    "SelectA_Commentary": "Aurora MySQL은 MySQL 호환성을 제공하므로 애플리케이션 측의 변경이 적고, Aurora Replica의 고성능 복제로 1초 미만의 지연을 달성하기 쉽습니다. 운영 오버헤드도 상대적으로 적습니다.",
    "SelectB": "데이터베이스 앞단에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 애플리케이션이 DB를 쿼리하기 전에 캐시를 확인하도록 수정합니다. 스토어드 프로시저를 AWS Lambda 함수로 대체합니다.",
    "SelectB_Commentary": "캐시를 앞단에 두면 읽기 부하를 줄일 수 있지만, 애플리케이션 코드 수정이 많고, 스토어드 프로시저를 Lambda로 옮기는 작업도 복잡하므로 요구사항인 '최소 변경'에 부합하지 않습니다.",
    "SelectC": "Amazon EC2 인스턴스에서 MySQL을 직접 구동하는 방식으로 마이그레이션하고, 모든 replica 노드에 대규모 컴퓨트 최적화 EC2 인스턴스를 선택합니다. 스토어드 프로시저는 그대로 EC2 인스턴스에서 유지합니다.",
    "SelectC_Commentary": "EC2에서 MySQL을 직접 운영하는 것은 더 높은 관리 오버헤드를 야기하며, RDS의 자동 복제 및 관리 기능을 잃게 되어 운영 부담이 큽니다. 지연 해결에도 도움이 제한적입니다.",
    "SelectD": "데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. 필요한 처리량을 지원하기 위해 많은 수의 읽기 용량 단위를 프로비저닝하고, 온디맨드 용량 스케일링을 구성합니다. 스토어드 프로시저를 DynamoDB Streams로 대체합니다.",
    "SelectD_Commentary": "관계형 DB를 DynamoDB로 전환하면 애플리케이션 및 쿼리 로직을 대대적으로 수정해야 하며, 기존 스토어드 프로시저를 대체하는 과정도 쉽지 않습니다. 요구사항인 최소 변경에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q247",
      "Q376",
      "Q776",
      "Q590",
      "Q386"
    ],
    "SelectA_recommedations": [
      "Q946",
      "Q337",
      "Q247"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q386"
    ],
    "SelectC_recommedations": [
      "Q229",
      "Q386",
      "Q565"
    ],
    "SelectD_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ]
  },
  {
    "Question_Number": "Q338",
    "Question_Description": "한 솔루션스 아키텍트는 대규모 Software as a Service (SaaS) 플랫폼에 대한 재해 복구(DR) 계획을 수립해야 합니다. 이 플랫폼의 모든 데이터는 Amazon Aurora MySQL DB cluster에 저장되어 있습니다. DR 계획은 데이터를 보조 AWS Region으로 복제해야 합니다. 가장 비용 효율적으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99758-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SaaS 환경에서의 DR 구축 방안을 고민하는 상황으로, 비용 효율성을 극대화하면서 Aurora MySQL DB cluster 데이터를 다른 리전에 복제해야 합니다. Aurora global database를 설정한 뒤 보조 리전의 DB 인스턴스를 제거하면, 필요 시 빠르게 장애 조치(Failover)를 수행하면서도 비활성 상태에서는 불필요한 비용을 줄일 수 있어 가장 경제적인 해법이 됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "재해 복구 계획",
      "Amazon Aurora MySQL DB cluster",
      "비용 효율성",
      "보조 AWS Region",
      "Aurora global database"
    ],
    "Terms": [
      "Amazon Aurora MySQL",
      "MySQL Binary Log",
      "Aurora global database",
      "AWS Database Migration Service (AWS DMS)",
      "DB instance",
      "Secondary Region"
    ],
    "SelectA": "MySQL binary log replication을 사용하여 Secondary Region의 Aurora cluster로 데이터를 복제하고, DB 인스턴스를 하나 프로비저닝합니다.",
    "SelectA_Commentary": "Binary log 복제 구성을 직접 유지관리해야 하며, 인스턴스가 상시 동작 중이므로 비용이 높을 수 있습니다.",
    "SelectB": "DB cluster에 대해 Aurora global database를 설정한 후, 설정이 완료되면 Secondary Region에서 DB 인스턴스를 제거합니다.",
    "SelectB_Commentary": "정상 시점에는 무사용 인스턴스로 인한 비용을 절감하고, 장애 시에는 빠르게 인스턴스를 생성해 서비스 연속성을 확보할 수 있어 가장 비용 효율적입니다.",
    "SelectC": "AWS DMS를 사용하여 Secondary Region의 Aurora cluster로 데이터를 지속적으로 복제하고, DB 인스턴스를 제거합니다.",
    "SelectC_Commentary": "DMS 과금과 Aurora 인프라 유지 비용이 이중으로 발생하며, 별도 엔드포인트 관리 및 DMS 작업 유지관리에 따른 부담이 존재합니다.",
    "SelectD": "DB cluster에 대해 Aurora global database를 설정하고, Secondary Region에 최소 한 개의 DB 인스턴스를 지정합니다.",
    "SelectD_Commentary": "보조 리전 인스턴스를 상시 확보해야 하므로 비용이 꾸준히 발생해 요구사항의 ‘가장 비용 효율적' 측면을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q343",
      "Q955",
      "Q879",
      "Q874",
      "Q896"
    ],
    "SelectA_recommedations": [
      "Q338",
      "Q955",
      "Q136"
    ],
    "SelectB_recommedations": [
      "Q338",
      "Q462",
      "Q136"
    ],
    "SelectC_recommedations": [
      "Q338",
      "Q343",
      "Q241"
    ],
    "SelectD_recommedations": [
      "Q338",
      "Q527",
      "Q462"
    ]
  },
  {
    "Question_Number": "Q339",
    "Question_Description": "한 회사의 맞춤형 애플리케이션이 Amazon RDS MySQL DB instance에서 정보를 가져오도록 애플리케이션 내부에 자격 증명(embedded credentials)이 포함되어 있습니다. 경영진은 최소한의 프로그래밍 노력으로 애플리케이션을 더 안전하게 만들어야 한다고 요구합니다. 이를 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99705-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션에 직접 포함된 DB 자격 증명을 안전하게 관리하면서, 코드를 크게 수정하지 않고 자동화된 자격 증명 로테이션을 도입하는 방안을 묻습니다. Amazon RDS MySQL에 대한 AWS Secrets Manager의 자동 자격 증명 로테이션 기능을 활용하는 것이 핵심이며, 이를 사용하면 별도의 복잡한 코딩 없이도 자격 증명을 안전하게 보호하고 주기적으로 교체할 수 있어 최소한의 프로그래밍 노력이 요구됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "임베디드 자격 증명",
      "보안 강화",
      "최소 프로그래밍",
      "자동 자격 증명 로테이션"
    ],
    "Terms": [
      "Amazon RDS MySQL",
      "AWS KMS",
      "AWS Secrets Manager",
      "AWS Lambda",
      "AWS Systems Manager Parameter Store",
      "Credentials Rotation"
    ],
    "SelectA": "AWS KMS를 사용해 키를 생성하고, 애플리케이션이 이 키를 통해 데이터베이스 자격 증명을 로드하도록 구성합니다. 자동 키 로테이션을 활성화합니다.",
    "SelectA_Commentary": "AWS KMS는 암호화 키 관리 서비스로, DB 자격 증명 자체를 자동으로 교체해 주는 기능은 없습니다.",
    "SelectB": "RDS for MySQL DB에서 애플리케이션 사용자 자격 증명을 생성하고, 이를 AWS Secrets Manager에 저장합니다. 애플리케이션이 Secrets Manager에서 DB 자격 증명을 로드하도록 구성합니다. 그리고 AWS Lambda 함수를 만들어 Secrets Manager 내 자격 증명을 로테이션합니다.",
    "SelectB_Commentary": "직접 Lambda 함수를 작성해야 하므로 추가 프로그래밍이 필요합니다. 그러나 자동화된 로테이션은 가능합니다.",
    "SelectC": "RDS for MySQL DB에서 애플리케이션 사용자 자격 증명을 생성하고, 이를 AWS Secrets Manager에 저장합니다. 애플리케이션이 Secrets Manager에서 DB 자격 증명을 로드하도록 구성합니다. 그리고 Secrets Manager를 사용해 RDS for MySQL DB에서 자격 증명을 자동으로 로테이션하도록 스케줄을 설정합니다.",
    "SelectC_Commentary": "Secrets Manager와 RDS를 연동하여 손쉽게 자동 로테이션을 설정할 수 있어 추가 코딩이 최소화되며, 요구사항을 가장 잘 충족하는 솔루션입니다.",
    "SelectD": "RDS for MySQL DB에서 애플리케이션 사용자 자격 증명을 생성하고, 이를 AWS Systems Manager Parameter Store에 저장합니다. 애플리케이션이 Parameter Store에서 DB 자격 증명을 로드하도록 구성합니다. 그리고 Parameter Store를 사용해 RDS for MySQL DB에서 자격 증명을 자동으로 로테이션하도록 스케줄을 설정합니다.",
    "SelectD_Commentary": "Parameter Store는 기본적으로 자격 증명 자동 로테이션을 제공하지 않으므로 요구사항을 만족하지 않습니다.",
    "Question_Description_recommedations": [
      "Q951",
      "Q330",
      "Q743",
      "Q86",
      "Q742"
    ],
    "SelectA_recommedations": [
      "Q916",
      "Q550",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q951",
      "Q743",
      "Q330"
    ],
    "SelectC_recommedations": [
      "Q951",
      "Q743",
      "Q339"
    ],
    "SelectD_recommedations": [
      "Q179",
      "Q951",
      "Q847"
    ]
  },
  {
    "Question_Number": "Q340",
    "Question_Description": "한 미디어 회사가 AWS에 웹사이트를 호스팅하고 있습니다. 웹사이트 애플리케이션 아키텍처는 Application Load Balancer(ALB) 뒤에 여러 Amazon EC2 인스턴스로 구성되어 있으며, 데이터베이스는 Amazon Aurora에서 호스팅되고 있습니다. 회사의 사이버보안 팀이 해당 애플리케이션이 SQL injection에 취약하다고 보고했습니다. 이것을 어떻게 해결해야 할까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99708-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션 계층에서 발생하는 SQL injection 취약점을 해결하는 방법을 묻습니다. AWS WAF를 ALB 앞에 두고 적절한 web ACL을 구성하면 SQL injection 패턴을 차단할 수 있습니다. 다른 서비스들은 주로 DDoS 방어나 취약점 스캔 용도이므로 실시간 필터링 기능이 부족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Amazon Aurora",
      "SQL injection",
      "AWS WAF",
      "web ACL"
    ],
    "Terms": [
      "SQL injection",
      "AWS WAF",
      "web ACL",
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Amazon Aurora",
      "AWS Shield Advanced",
      "Amazon Inspector"
    ],
    "SelectA": "ALB 앞단에 AWS WAF를 사용하고, 적절한 web ACL을 AWS WAF와 연결하세요.",
    "SelectA_Commentary": "AWS WAF는 SQL injection 탐지와 차단 규칙을 제공하므로, 애플리케이션 계층 보안을 실시간으로 강화할 수 있는 가장 적합한 해법입니다.",
    "SelectB": "ALB 리스너 규칙을 생성해 SQL injection 시도를 고정된 응답으로 회신하도록 설정하세요.",
    "SelectB_Commentary": "고정된 응답만으로 SQL injection을 실제로 차단하거나 탐지하지 못하므로 보안을 충분히 보장하지 못합니다.",
    "SelectC": "AWS Shield Advanced에 가입해 모든 SQL injection 시도를 자동으로 차단하세요.",
    "SelectC_Commentary": "AWS Shield는 주로 DDoS 공격 방어용이며, SQL injection과 같은 애플리케이션 계층 공격에 대한 규칙은 제한적입니다.",
    "SelectD": "Amazon Inspector를 설정해 모든 SQL injection 시도를 자동으로 차단하세요.",
    "SelectD_Commentary": "Amazon Inspector는 주로 애플리케이션 보안 취약점을 스캔하고 평가하는 도구이며, 실시간 차단 기능은 제공하지 않습니다.",
    "Question_Description_recommedations": [
      "Q749",
      "Q180",
      "Q884",
      "Q213",
      "Q60"
    ],
    "SelectA_recommedations": [
      "Q60",
      "Q749",
      "Q165"
    ],
    "SelectB_recommedations": [
      "Q340",
      "Q213",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q340",
      "Q623",
      "Q180"
    ],
    "SelectD_recommedations": [
      "Q623",
      "Q340",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q341",
    "Question_Description": "한 회사는 AWS Lake Formation으로 거버넌스가 적용된 Amazon S3 data lake를 운영하고 있습니다. 회사는 Amazon Aurora MySQL 데이터베이스에 저장된 운영 데이터와 data lake에 있는 데이터를 결합하여 Amazon QuickSight에서 시각화를 생성하려고 합니다. 회사는 column-level authorization을 적용해 마케팅 팀이 데이터베이스의 특정 컬럼에만 접근하도록 제어하려고 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/99710-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터 레이크와 Aurora MySQL 데이터를 통합해 컬럼 단위 접근 제어를 구현하는 방법을 묻습니다. Lake Formation으로 보안과 거버넌스를 간소화해 운영 오버헤드를 크게 줄일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3 data lake",
      "AWS Lake Formation",
      "Amazon QuickSight",
      "Amazon Aurora MySQL",
      "column-level authorization",
      "운영 데이터",
      "마케팅 팀"
    ],
    "Terms": [
      "Amazon S3 data lake",
      "AWS Lake Formation",
      "Amazon QuickSight",
      "Amazon Aurora MySQL",
      "column-level authorization",
      "Amazon EMR",
      "AWS Glue Studio",
      "IAM policy",
      "AWS Glue Elastic Views",
      "materialized view",
      "S3 bucket policy",
      "Lake Formation blueprint",
      "Amazon Athena"
    ],
    "SelectA": "Amazon EMR을 사용해 데이터베이스에서 QuickSight SPICE 엔진으로 직접 데이터를 가져옵니다. 필요한 컬럼만 포함합니다.",
    "SelectA_Commentary": "컬럼 수준 접근 제어가 EMR과 SPICE로 분산되어 관리되어야 하므로 보안 및 운영 복잡도가 높아집니다.",
    "SelectB": "AWS Glue Studio를 사용하여 데이터베이스에서 S3 data lake로 데이터를 가져옵니다. QuickSight 사용자에게 부착된 IAM policy로 컬럼 접근을 제어하고 Amazon S3를 데이터 소스로 사용합니다.",
    "SelectB_Commentary": "IAM policy만으로 정밀한 컬럼 단위 권한을 설정하기 어려우며, Lake Formation과의 통합이 없어 운영 오버헤드가 커질 수 있습니다.",
    "SelectC": "AWS Glue Elastic Views를 사용하여 데이터베이스의 materialized view를 Amazon S3에 생성합니다. S3 bucket policy를 통해 컬럼 수준 접근 제어를 적용하고 Amazon S3를 데이터 소스로 사용합니다.",
    "SelectC_Commentary": "S3 bucket policy로 컬럼 단위 접근을 제어하기에는 한계가 있으며, Glue Elastic Views 구성과 관리가 추가로 필요해 복잡해집니다.",
    "SelectD": "Lake Formation blueprint를 사용해 데이터베이스의 데이터를 S3 data lake로 가져옵니다. Lake Formation을 통해 QuickSight 사용자의 컬럼 수준 접근 제어를 적용하고 Amazon Athena를 데이터 소스로 사용합니다.",
    "SelectD_Commentary": "Lake Formation으로 컬럼 단위 권한을 간결하게 설정하고 Athena로 편리하게 조회할 수 있어 운영 오버헤드가 최소화됩니다.",
    "Question_Description_recommedations": [
      "Q609",
      "Q16",
      "Q495",
      "Q733",
      "Q442"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q831",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q982",
      "Q16",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q256",
      "Q216",
      "Q862"
    ],
    "SelectD_recommedations": [
      "Q609",
      "Q495",
      "Q341"
    ]
  },
  {
    "Question_Number": "Q342",
    "Question_Description": "한 트랜잭션 처리 회사에서 매주 스크립트 기반 배치 작업을 Amazon EC2 인스턴스에서 실행하고 있습니다. 이 인스턴스들은 Auto Scaling group 내에 있습니다. 처리되는 트랜잭션 수는 가변적이지만, 각 실행 시 확인되는 기본 CPU 활용률은 최소 60%입니다. 회사는 배치 작업이 실행되기 30분 전에 미리 용량을 할당해야 합니다. 현재는 엔지니어들이 Auto Scaling group 파라미터를 수동으로 수정하여 이 작업을 수행하고 있으나, Auto Scaling group의 적절한 용량 트렌드를 분석할 리소스가 없습니다. 회사는 Auto Scaling group의 Desired Capacity를 자동으로 수정하는 방법이 필요하며, 운영 오버헤드를 최소화해야 합니다. 어떤 솔루션이 이러한 요구사항을 가장 적은 운영 오버헤드로 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100204-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매주 정해진 시간에 배치 작업이 실행되며, 사전에 적절한 용량을 확보해 두어야 하는 시나리오입니다. Manual 작업 없이 CPU 활용률 예측과 함께 인스턴스를 미리 확장하려면 Predictive Scaling이 가장 적합합니다. Scheduled Scaling은 용량 추세 분석이 이미 되어 있어야 하므로 비현실적이고, Dynamic Scaling은 사전 확장을 보장하기 어렵습니다. EventBridge와 Lambda 결합은 즉각 반응만 가능해 사전 확장이 어렵습니다. 따라서 사전 할당이 가능한 Predictive Scaling이 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Auto Scaling group",
      "주간 배치 작업",
      "CPU 활용률 60%",
      "사전 용량 할당",
      "운영 오버헤드 최소화",
      "Predictive scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Dynamic Scaling",
      "Scheduled Scaling",
      "Predictive Scaling",
      "Amazon EventBridge",
      "AWS Lambda",
      "CPU Utilization Metric"
    ],
    "SelectA": "Auto Scaling group에 Dynamic Scaling Policy를 생성하고, CPU 활용률 메트릭을 기준으로 Target Value를 60%로 설정합니다.",
    "SelectA_Commentary": "실시간 CPU 활용률만으로 확장하면 사전 확장이 어렵고, 작업 시작 전 용량 확보를 보장하지 못합니다.",
    "SelectB": "Auto Scaling group에 Scheduled Scaling Policy를 생성합니다. 매주 원하는 Desired Capacity, Minimum, Maximum 용량을 설정하고, 배치 작업 시작 30분 전에 스케줄을 설정합니다.",
    "SelectB_Commentary": "회사에서 필요한 용량 트렌드 분석이 불가능하므로 적절한 용량 값을 수동으로 설정하기 어렵습니다.",
    "SelectC": "Auto Scaling group에 Predictive Scaling Policy를 생성합니다. Forecast를 기반으로 확장하도록 설정하고, CPU 활용률 메트릭의 Target Value를 60%로 지정합니다. 정책에서 배치 작업 실행 30분 전에 인스턴스를 미리 시작하도록 설정합니다.",
    "SelectC_Commentary": "Predictive Scaling을 통해 CPU 활용률 트렌드를 자동 분석하고, 작업 전 사전에 용량을 확보합니다. 이 방법이 가장 적은 운영 오버헤드로 요구사항을 충족합니다.",
    "SelectD": "Auto Scaling group의 CPU 활용률이 60%에 도달하면 Amazon EventBridge 이벤트가 AWS Lambda 함수를 호출하도록 설정합니다. Lambda 함수에서 Desired Capacity와 Maximum Capacity를 20%씩 증가시킵니다.",
    "SelectD_Commentary": "CPU 지표가 이미 60%가 되어야 동작하기 때문에 사전 확장 효과가 없으며, 즉각적 확장만 가능해 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q595",
      "Q581",
      "Q271",
      "Q1001",
      "Q660"
    ],
    "SelectA_recommedations": [
      "Q342",
      "Q660",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q342",
      "Q595",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q342",
      "Q660",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q342",
      "Q595",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q343",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 디재스터 리커버리(DR) 아키텍처를 설계하고 있습니다. 이 회사는 사설 서브넷에서 Amazon EC2 인스턴스로 구동되는 MySQL 데이터베이스를 보유하고 있으며, 정기 백업이 예약되어 있습니다. DR 설계는 여러 AWS Region을 포함해야 합니다. 운영 오버헤드를 가장 적게 하면서 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100302-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다중 Region을 고려한 DR 아키텍처를 설계할 때, 최소한의 운영 오버헤드로 데이터베이스를 안정적이고 신속하게 복원할 수 있는 방안을 찾는 방식으로 출제되었습니다. Amazon Aurora 글로벌 데이터베이스는 MySQL 호환성을 제공하며, 관리형 서비스로 자동 장애 조치와 실시간 데이터 복제를 지원하므로 별도의 대기 인스턴스 구성 및 운영 부담을 크게 줄일 수 있습니다. 이로써 운영팀이 직접 복제나 백업 복원 과정을 최소화하면서, 여러 Region에서의 고가용성과 빠른 복구를 동시에 달성할 수 있도록 돕습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "디재스터 리커버리",
      "MySQL",
      "멀티 Region",
      "Amazon Aurora 글로벌 데이터베이스",
      "운영 오버헤드"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon Aurora 글로벌 데이터베이스",
      "Multi-AZ",
      "S3 Cross-Region Replication(CRR)"
    ],
    "SelectA": "여러 Amazon EC2 인스턴스로 MySQL 데이터베이스를 마이그레이션하고, DR Region에 대기 EC2 인스턴스를 구성한 후 복제를 활성화합니다.",
    "SelectA_Commentary": "운영자가 직접 EC2를 구성, 복제, 장애 조치를 관리해야 하므로 운영 오버헤드가 높고, 자동화된 글로벌 복원 능력이 부족합니다.",
    "SelectB": "Amazon RDS로 MySQL 데이터베이스를 마이그레이션하고, Multi-AZ 배포를 사용합니다. 다른 가용 영역에 있는 기본 DB 인스턴스에 대한 읽기 복제를 활성화합니다.",
    "SelectB_Commentary": "Multi-AZ는 단일 Region 내 장애 대비에 특화되어 있어, 다중 Region DR 구성을 위해서는 추가 설정과 관리가 필요합니다.",
    "SelectC": "Amazon Aurora 글로벌 데이터베이스로 MySQL 데이터베이스를 마이그레이션하고, 기본 Region에 기본 DB 클러스터를, DR Region에 보조 DB 클러스터를 호스팅합니다.",
    "SelectC_Commentary": "글로벌 데이터베이스 기능으로 다중 Region에서 자동화된 장애 조치와 실시간 복제가 이루어지므로, 운영 오버헤드가 최소화되고 DR에도 효율적입니다.",
    "SelectD": "S3 Cross-Region Replication(CRR)이 설정된 Amazon S3 버킷에 MySQL 데이터베이스의 예약된 백업을 보관하고, 이 데이터 백업으로 DR Region에서 데이터베이스를 복원합니다.",
    "SelectD_Commentary": "백업이동과 복원 과정에서 수동 작업이 많고, RPO/RTO가 상대적으로 길어져 운영 오버헤드가 증가하고 복구 시간도 늘어납니다.",
    "Question_Description_recommedations": [
      "Q585",
      "Q338",
      "Q133",
      "Q241",
      "Q843"
    ],
    "SelectA_recommedations": [
      "Q343",
      "Q585",
      "Q824"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q958",
      "Q629"
    ],
    "SelectC_recommedations": [
      "Q338",
      "Q896",
      "Q343"
    ],
    "SelectD_recommedations": [
      "Q343",
      "Q585",
      "Q891"
    ]
  },
  {
    "Question_Number": "Q344",
    "Question_Description": "한 회사에서 Amazon SQS를 사용하여 메시지를 처리하는 Java 애플리케이션을 운영하고 있습니다. 현재 애플리케이션은 256 KB를 초과하는 메시지는 파싱할 수 없습니다. 이 회사는 최대 50 MB까지 메시지를 파싱할 수 있도록 애플리케이션에 대한 솔루션을 도입하려고 합니다. 가장 적은 코드 변경으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100202-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon SQS는 메시지 크기에 기본 제한이 있으므로, Extended Client Library를 사용해 256KB를 초과하는 메시지를 Amazon S3에 저장하고 SQS에는 메타데이터만 전달함으로써 최소한의 코드 수정으로도 최대 50MB까지 처리 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon SQS",
      "256 KB",
      "50 MB",
      "Amazon SQS Extended Client Library for Java",
      "Amazon S3",
      "적은 코드 변경"
    ],
    "Terms": [
      "Amazon SQS",
      "Java Application",
      "256 KB limit",
      "Amazon SQS Extended Client Library for Java",
      "Amazon S3",
      "Amazon EventBridge",
      "Amazon EFS"
    ],
    "SelectA": "256KB보다 큰 메시지를 Amazon S3에 저장하기 위해 Amazon SQS Extended Client Library for Java를 사용합니다.",
    "SelectA_Commentary": "대용량 메시지를 Amazon S3에 저장하고 SQS에는 해당 위치 정보만 담아 전송하므로 코드 변경이 최소화됩니다.",
    "SelectB": "애플리케이션에서 Amazon EventBridge를 사용하여 큰 메시지를 게시하도록 대체합니다.",
    "SelectB_Commentary": "기존에 Amazon SQS 구조를 사용하던 애플리케이션 로직에 큰 변화를 줘야 하므로 적은 코드 변경이라는 요구사항에 부합하지 않습니다.",
    "SelectC": "Amazon SQS의 메시지 크기 제한을 256KB 이상으로 변경합니다.",
    "SelectC_Commentary": "Amazon SQS 자체 제한은 사용자가 임의로 변경할 수 없으므로 이 방법은 불가능합니다.",
    "SelectD": "256KB보다 큰 메시지는 Amazon EFS에 저장하고, Amazon SQS 메시지에는 해당 경로를 참조하도록 구성합니다.",
    "SelectD_Commentary": "EFS 연결 및 별도의 관리 로직 도입이 필요하여 구조가 복잡해지고 코드 수정이 많이 요구됩니다.",
    "Question_Description_recommedations": [
      "Q94",
      "Q203",
      "Q67",
      "Q784",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q344",
      "Q784",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q569",
      "Q8",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q344",
      "Q784",
      "Q52"
    ],
    "SelectD_recommedations": [
      "Q52",
      "Q784",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q345",
    "Question_Description": "한 회사는 주요 웹 애플리케이션 중 하나의 콘텐츠에 대한 접근을 제한하고, AWS에서 제공하는 Authorization 기능을 사용해 콘텐츠를 보호하고자 합니다. 해당 회사는 서버리스 아키텍처를 구현하고 100명 미만의 사용자를 대상으로 Authentication 솔루션을 도입하려고 합니다. 이 솔루션은 주요 웹 애플리케이션과 통합되어야 하며, 전 세계적으로 웹 콘텐츠를 제공해야 하고, 회사 사용자 수가 증가하더라도 확장 가능해야 합니다. 또한 가능한 한 낮은 로그인 지연 시간을 제공해야 합니다. 이 요구사항을 가장 비용 효율적으로 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100341-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 소규모(100명 미만) 사용자 수에서 시작하더라도 확장 가능하고, 낮은 지연 시간을 제공하며 전 세계적으로 웹 콘텐츠를 안전하게 제공하는 서버리스 인증·인가 방안을 찾는 것입니다. Amazon Cognito는 사용자 인증에 적합하고, Lambda@Edge는 전 세계 Edge Location에서 트래픽을 처리해 지연 시간을 줄입니다. Amazon CloudFront를 사용하면 글로벌 콘텐츠 제공이 가능하므로, 비용 및 성능 면에서 가장 적합한 조합이 SelectA입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "서버리스 아키텍처",
      "인증(Authentication)",
      "권한 부여(Authorization)",
      "글로벌 웹 콘텐츠",
      "낮은 지연 시간"
    ],
    "Terms": [
      "Amazon Cognito",
      "AWS Directory Service for Microsoft Active Directory",
      "AWS Lambda",
      "Lambda@Edge",
      "Amazon CloudFront",
      "Application Load Balancer",
      "Amazon S3 Transfer Acceleration",
      "AWS Elastic Beanstalk"
    ],
    "SelectA": "Amazon Cognito로 Authentication을 처리하고, Lambda@Edge로 Authorization을 진행합니다. Amazon CloudFront를 통해 전 세계에 웹 애플리케이션을 제공합니다.",
    "SelectA_Commentary": "서버리스 구조로 확장성과 낮은 지연 시간이 보장됩니다. Cognito는 최대한 간단하고 비용 효율적으로 사용자 인증을 지원하며, Lambda@Edge를 통한 Authorization은 지리적 이점을 활용합니다.",
    "SelectB": "AWS Directory Service for Microsoft Active Directory로 Authentication을 처리하고, AWS Lambda로 Authorization을 수행합니다. Application Load Balancer를 통해 전 세계에 웹 애플리케이션을 제공합니다.",
    "SelectB_Commentary": "Active Directory는 100명 미만 사용자 환경에서 비용 효율성이 낮고, 글로벌 콘텐츠 전달 시 로드 밸런서를 통해서는 보다 높은 지연 시간이 발생할 수 있어 최적이 아닙니다.",
    "SelectC": "Amazon Cognito로 Authentication을 처리하고, AWS Lambda로 Authorization을 수행합니다. Amazon S3 Transfer Acceleration을 통해 전 세계에 웹 애플리케이션을 제공합니다.",
    "SelectC_Commentary": "S3 Transfer Acceleration은 대용량 데이터 전송에 유리하지만, 엣지 수준 실행인 Lambda@Edge만큼 빠른 Authorization 처리와 지연 시간 절감 효과를 누리기 어렵습니다.",
    "SelectD": "AWS Directory Service for Microsoft Active Directory로 Authentication을 처리하고, Lambda@Edge로 Authorization을 진행합니다. AWS Elastic Beanstalk를 통해 전 세계에 웹 애플리케이션을 제공합니다.",
    "SelectD_Commentary": "Elastic Beanstalk는 서버리스보다 관리 오버헤드와 비용이 높아질 수 있으며, Active Directory 역시 소규모 사용자 환경에서는 비용 효율성이 떨어져 비적합합니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q222",
      "Q871",
      "Q313",
      "Q922"
    ],
    "SelectA_recommedations": [
      "Q871",
      "Q366",
      "Q855"
    ],
    "SelectB_recommedations": [
      "Q927",
      "Q884",
      "Q826"
    ],
    "SelectC_recommedations": [
      "Q366",
      "Q871",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q826",
      "Q211"
    ]
  },
  {
    "Question_Number": "Q346",
    "Question_Description": "한 기업이 데이터 센터에서 사용 중인 오래된 NAS(Network-Attached Storage) 시스템이 있습니다. 이 NAS는 SMB 공유와 NFS 공유를 클라이언트 워크스테이션에 제공합니다. 기업은 새로운 NAS를 구매하거나 기존 NAS 지원 계약을 갱신하는 비용을 부담하고 싶지 않습니다. 일부 데이터는 자주 액세스되지만 상당량의 데이터는 비활성 상태입니다. Solutions Architect는 데이터를 Amazon S3로 마이그레이션하고, S3 Lifecycle 정책을 사용하며, 클라이언트 워크스테이션에는 동일한 SMB/NFS 인터페이스 경험을 제공해야 합니다. 이를 위해 AWS Storage Gateway를 도입하려고 합니다. 이 요구사항을 충족하기 위해 어떤 유형의 Storage Gateway를 구성해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100220-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기업의 오래된 NAS를 대체하면서 비용과 운영 부담을 줄이는 데 초점을 둡니다. SMB/NFS 공유가 필요하므로 Amazon S3 File Gateway를 통해 기존 환경과 유사한 방식으로 데이터를 S3로 이전하고 관리할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "오래된 NAS 대체",
      "SMB 공유",
      "NFS 공유",
      "S3 Lifecycle 정책",
      "AWS Storage Gateway",
      "Amazon S3 File Gateway"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Amazon S3 File Gateway",
      "Amazon FSx File Gateway",
      "Volume Gateway",
      "Tape Gateway",
      "SMB",
      "NFS",
      "S3 Lifecycle policies"
    ],
    "SelectA": "Volume Gateway",
    "SelectA_Commentary": "Volume Gateway는 블록 스토리지 볼륨을 제공하므로 SMB/NFS 파일 공유를 그대로 대체하기 어렵습니다.",
    "SelectB": "Tape Gateway",
    "SelectB_Commentary": "Tape Gateway는 백업 테이프 아키텍처를 가상화합니다. 파일 공유용으로는 적합하지 않습니다.",
    "SelectC": "Amazon FSx File Gateway",
    "SelectC_Commentary": "Amazon FSx 기반 파일시스템으로 연결하며, Amazon S3로 직접 저장하는 구조가 아니어서 요구사항에 부합하지 않습니다.",
    "SelectD": "Amazon S3 File Gateway",
    "SelectD_Commentary": "SMB/NFS 파일 인터페이스를 그대로 유지하며, 백엔드는 Amazon S3로 동기화해 S3 Lifecycle 정책을 사용할 수 있어 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q22",
      "Q497",
      "Q309",
      "Q398",
      "Q719"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q1003"
    ],
    "SelectC_recommedations": [
      "Q703",
      "Q552",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q703",
      "Q285",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q347",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 실행하고 있습니다. 솔루션스 아키텍트는 회사의 현재 요구 사항을 바탕으로 특정 인스턴스 패밀리와 다양한 인스턴스 크기로 표준화를 진행했습니다. 회사는 향후 3년 동안 애플리케이션 비용을 최대한 절감하고자 합니다. 또한 애플리케이션의 인기도와 사용량에 따라 6개월 후 인스턴스 패밀리와 크기를 변경할 수 있어야 합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100221-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 3년 동안의 비용 절감 효과와 6개월 내 인스턴스 패밀리 변경 가능성이 핵심입니다. Compute Savings Plan은 특정 인스턴스 패밀리에 국한되지 않고 유연하게 인스턴스를 변경할 수 있어 장기적인 비용 절감과 변경 요구사항을 동시에 충족할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "비용 절감",
      "인스턴스 패밀리",
      "인스턴스 크기 변경",
      "3년 약정",
      "Compute Savings Plan"
    ],
    "Terms": [
      "Compute Savings Plan",
      "EC2 Instance Savings Plan",
      "Zonal Reserved Instances",
      "Standard Reserved Instances",
      "Amazon EC2",
      "On-Demand",
      "Instance Family",
      "Instance Size"
    ],
    "SelectA": "Compute Savings Plan",
    "SelectA_Commentary": "특정 인스턴스 패밀리에 구애받지 않고, Amazon EC2 및 AWS Fargate 등 다양한 Compute 옵션에 유연하게 적용되어 장기적인 비용 절감과 변경 가능성을 모두 확보할 수 있습니다.",
    "SelectB": "EC2 Instance Savings Plan",
    "SelectB_Commentary": "인스턴스 패밀리를 특정해야 하므로 6개월 내 패밀리 변경 시 제약이 큽니다. 그만큼 할인률은 높지만 문제의 요구 사항을 모두 충족시키지는 못합니다.",
    "SelectC": "Zonal Reserved Instances",
    "SelectC_Commentary": "예약 구역(Availability Zone)에 종속되며, 인스턴스 패밀리와 크기를 유연하게 변경하기 어렵습니다. 6개월 후 변경 요구 사항에 부적합합니다.",
    "SelectD": "Standard Reserved Instances",
    "SelectD_Commentary": "글로벌 리전 차원에서 인스턴스 패밀리 변경이 어려우며, 할인 효과는 있지만 문제에서 제시된 유연성 요건에 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q552",
      "Q671",
      "Q238",
      "Q993",
      "Q221"
    ],
    "SelectA_recommedations": [
      "Q543",
      "Q997",
      "Q885"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q543",
      "Q1013"
    ],
    "SelectC_recommedations": [
      "Q767",
      "Q630",
      "Q997"
    ],
    "SelectD_recommedations": [
      "Q767",
      "Q997",
      "Q630"
    ]
  },
  {
    "Question_Number": "Q348",
    "Question_Description": "한 회사가 웨어러블 디바이스를 사용하는 다수의 참가자로부터 데이터를 수집하고 있습니다. 이 회사는 Amazon DynamoDB 테이블에 데이터를 저장하고, 애플리케이션을 통해 해당 데이터를 분석합니다. 데이터 워크로드는 일정하고 예측 가능합니다. 회사는 DynamoDB 사용 비용을 예측된 예산 범위 내로 유지하고자 합니다. 다음 중 가장 비용 효율적으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100222-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 일정하고 예측 가능한 작업량을 가진 DynamoDB 워크로드를 가장 경제적으로 운영하는 방법을 묻습니다. provisioned 모드를 사용해 필요한 용량을 정확히 설정한 뒤, reserved capacity를 구매하면 장기적인 비용 절감 효과를 볼 수 있습니다. 또한 자주 액세스되지 않는 항목은 DynamoDB Standard-IA를 활용해 비용을 추가로 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "웨어러블 디바이스",
      "DynamoDB 테이블",
      "일정하고 예측 가능한 워크로드",
      "비용 효율",
      "예상 예산",
      "provisioned mode",
      "DynamoDB Standard-IA",
      "reserved capacity",
      "on-demand mode"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA)",
      "read capacity units (RCUs)",
      "write capacity units (WCUs)",
      "provisioned mode",
      "on-demand mode",
      "reserved capacity"
    ],
    "SelectA": "provisioned mode와 DynamoDB Standard-Infrequent Access를 사용하고, 예상된 워크로드에 대해 reserved capacity를 구매합니다.",
    "SelectA_Commentary": "일정한 워크로드를 가진 환경에서 provisioned mode와 reserved capacity 조합이 가장 경제적입니다. 자주 조회되지 않는 데이터를 DynamoDB Standard-IA로 저장하면 추가 비용도 절감할 수 있습니다.",
    "SelectB": "provisioned mode를 사용하고, read capacity units (RCUs)와 write capacity units (WCUs)를 직접 지정합니다.",
    "SelectB_Commentary": "provisioned mode만으로도 예측 가능한 트래픽 대응은 가능하지만, reserved capacity와 DynamoDB Standard-IA를 함께 사용하지 않아 비용 절감 효과가 떨어집니다.",
    "SelectC": "on-demand mode를 사용하며, 워크로드 변화에 대비하여 RCU와 WCU를 충분히 높게 설정합니다.",
    "SelectC_Commentary": "on-demand mode는 유연하지만, 일정하고 예측 가능한 워크로드에는 필요 이상의 비용이 발생할 수 있어 예산을 초과할 우려가 있습니다.",
    "SelectD": "on-demand mode와 reserved capacity를 함께 사용하여 RCU와 WCU를 지정합니다.",
    "SelectD_Commentary": "on-demand 모드에 reserved capacity를 동시에 사용하는 시나리오는 일반적이지 않고 설정도 복잡합니다. 일정한 워크로드에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q79",
      "Q670",
      "Q799",
      "Q196",
      "Q411"
    ],
    "SelectA_recommedations": [
      "Q670",
      "Q196",
      "Q348"
    ],
    "SelectB_recommedations": [
      "Q40",
      "Q147",
      "Q778"
    ],
    "SelectC_recommedations": [
      "Q49",
      "Q630",
      "Q997"
    ],
    "SelectD_recommedations": [
      "Q486",
      "Q943",
      "Q300"
    ]
  },
  {
    "Question_Number": "Q349",
    "Question_Description": "한 회사가 ap-southeast-3 리전의 Amazon Aurora PostgreSQL 데이터베이스에 기밀 데이터를 저장하고 있습니다. 이 데이터베이스는 AWS Key Management Service(AWS KMS) customer managed key로 암호화되어 있습니다. 이 회사는 최근에 다른 회사에 인수되었으며, 인수한 회사의 AWS 계정(ap-southeast-3)으로 데이터베이스 백업을 안전하게 공유해야 합니다. 이러한 요구 사항을 충족하기 위해 Solutions Architect는 어떤 작업을 수행해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100299-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Aurora PostgreSQL 데이터베이스가 AWS KMS customer managed key로 암호화되어 있는 상황에서, 다른 회사와 안전하게 스냅샷을 공유해야 하는 시나리오입니다. AWS KMS를 활용하면 별도의 복호화 과정 없이도 (단, KMS 정책 설정이 적절히 되어 있어야) 공유된 스냅샷을 안전하게 액세스할 수 있습니다. 정답인 SelectB에서는 인수 회사의 AWS 계정을 KMS key policy에 추가함으로써, 해당 스냅샷을 암호화 상태로 안전하게 공유할 수 있습니다. 다른 옵션들은 암호화를 해제하거나, 별도의 위험이 큰 데이터 이동 과정을 요구하기 때문에 권장되지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Aurora PostgreSQL",
      "AWS KMS",
      "customer managed key",
      "데이터베이스 스냅샷",
      "기밀 데이터"
    ],
    "Terms": [
      "Amazon Aurora PostgreSQL",
      "AWS Key Management Service(AWS KMS)",
      "customer managed key",
      "KMS key policy",
      "데이터베이스 스냅샷",
      "Amazon S3"
    ],
    "SelectA": "데이터베이스 스냅샷을 생성합니다. 스냅샷을 새로 생성한 암호화되지 않은 스냅샷으로 복사합니다. 새 스냅샷을 인수 회사의 AWS 계정과 공유합니다.",
    "SelectA_Commentary": "암호화되지 않은 상태로 복사하면 기밀 데이터 보호가 약화됩니다. 보안 요구사항을 만족시키기 어렵습니다.",
    "SelectB": "데이터베이스 스냅샷을 생성합니다. 인수 회사의 AWS 계정을 KMS 키 정책에 추가합니다. 스냅샷을 인수 회사의 AWS 계정과 공유합니다.",
    "SelectB_Commentary": "고객 관리형 KMS 키에 계정 권한을 부여하여 암호화된 스냅샷을 안전하게 공유하는 올바른 접근 방식입니다.",
    "SelectC": "다른 AWS managed KMS key를 사용하는 데이터베이스 스냅샷을 생성합니다. 인수 회사의 AWS 계정을 KMS 키 alias에 추가합니다. 스냅샷을 인수 회사의 AWS 계정과 공유합니다.",
    "SelectC_Commentary": "다른 KMS 키로 재암호화하면 복잡성이 증가하며, key alias만으로는 접근 제어가 완전히 해결되지 않습니다.",
    "SelectD": "데이터베이스 스냅샷을 생성합니다. 이 데이터베이스 스냅샷을 다운로드합니다. 인수 회사의 AWS 계정이 액세스할 수 있도록 S3 버킷 정책을 업데이트한 후 해당 스냅샷을 Amazon S3 버킷에 업로드합니다.",
    "SelectD_Commentary": "스냅샷을 내려받아 전달하는 과정에서 보안 리스크가 커지고, 운영이 복잡해지며 안전한 암호화를 유지하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q36",
      "Q916",
      "Q681",
      "Q733",
      "Q82"
    ],
    "SelectA_recommedations": [
      "Q592",
      "Q831",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q831"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q825",
      "Q44",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q350",
    "Question_Description": "한 회사는 us-east-1 리전에 있는 Single-AZ 형태의 Amazon RDS for Microsoft SQL Server(용량 100GB)를 사용해 고객 트랜잭션을 저장하고 있습니다. 이 회사는 해당 DB instance에 대해 고가용성(High Availability)과 자동 복구(Automatic Recovery)가 필요합니다. 또한 매년 여러 차례 RDS 데이터베이스에서 리포트를 실행해야 하는데, 이 리포트 프로세스로 인해 고객 계정에 트랜잭션이 게시되는 시간이 평소보다 길어지고 있습니다. 회사는 리포트 프로세스의 성능을 개선할 수 있는 솔루션이 필요합니다. 어떤 조합의 단계가 이러한 요구 사항을 충족합니까? (2개를 선택하십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100300-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS에서 고가용성과 리포트 워크로드 성능이 모두 중요한 상황입니다. Multi-AZ 구성을 통해 자동 복구를 보장하고, read replica를 통해 보고 조회 부하를 분산해 성능을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2",
      "3.3"
    ],
    "Keywords": [
      "고가용성",
      "자동 복구",
      "리포트 작업 성능 개선",
      "Multi-AZ 배포",
      "read replica"
    ],
    "Terms": [
      "Amazon RDS for Microsoft SQL Server",
      "Single-AZ",
      "Multi-AZ deployment",
      "read replica",
      "RDS Proxy",
      "RDS Custom",
      "snapshot"
    ],
    "SelectA": "기존 Single-AZ DB instance를 Multi-AZ 배포로 변경합니다.",
    "SelectA_Commentary": "Multi-AZ 배포를 통해 장애 시 자동 복구와 고가용성을 얻을 수 있습니다.",
    "SelectB": "현재 DB instance의 스냅샷을 생성하고, 이를 다른 가용 영역에 위치한 새 RDS 배포로 복원합니다.",
    "SelectB_Commentary": "스냅샷 복원은 단순 백업 및 복원 방식으로, 리포트 부하를 분산하거나 고가용성을 지속적으로 확보하기에는 적합하지 않습니다.",
    "SelectC": "다른 가용 영역에 DB instance의 read replica를 생성하고, 모든 리포트 요청을 read replica로 전달합니다.",
    "SelectC_Commentary": "read replica로 읽기 트래픽을 오프로딩해, 본 DB에서의 트랜잭션 처리 속도를 저하하지 않고 리포트 성능을 높일 수 있습니다.",
    "SelectD": "데이터베이스를 RDS Custom으로 마이그레이션합니다.",
    "SelectD_Commentary": "RDS Custom은 특정 요구 사항에 맞춤 구성이 가능하지만, Multi-AZ나 read replica를 통한 고가용성과 보고 부하 최적화를 직접 해결하지는 못합니다.",
    "SelectE": "RDS Proxy를 사용하여 리포트 요청을 점검 윈도우로 제한합니다.",
    "SelectE_Commentary": "RDS Proxy는 연결 풀링 및 대규모 연결 관리에 유용하지만, 보고 부하 자체를 줄이거나 병렬적으로 처리해 성능을 개선하지는 못합니다.",
    "Question_Description_recommedations": [
      "Q464",
      "Q536",
      "Q958",
      "Q933",
      "Q444"
    ],
    "SelectA_recommedations": [
      "Q466",
      "Q843",
      "Q464"
    ],
    "SelectB_recommedations": [
      "Q444",
      "Q228",
      "Q518"
    ],
    "SelectC_recommedations": [
      "Q48",
      "Q228",
      "Q843"
    ],
    "SelectD_recommedations": [
      "Q863",
      "Q108",
      "Q362"
    ],
    "SelectE_recommedations": [
      "Q108",
      "Q863",
      "Q518"
    ]
  },
  {
    "Question_Number": "Q351",
    "Question_Description": "한 회사가 데이터 관리 애플리케이션을 AWS로 이전하려고 합니다. 회사는 이벤트 기반(event-driven) 아키텍처로 전환하기를 원합니다. 이 아키텍처는 더 분산된 형태로 서버리스(serverless) 개념을 사용하여 워크플로우의 각 단계를 수행해야 합니다. 또한 운영 오버헤드를 최소화하고 싶어 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100371-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버리스 기반의 이벤트 드리븐 아키텍처를 구축하고자 할 때, 최소한의 운영 오버헤드로 워크플로우를 분산 처리하는 방법을 묻는 질문입니다. 여러 AWS 서비스 중 AWS Step Functions와 AWS Lambda를 조합하여 단계별 작업을 서버리스로 실행하고 상태 관리를 자동화하는 솔루션이 가장 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이벤트 기반 아키텍처",
      "서버리스",
      "분산",
      "운영 오버헤드 최소화",
      "AWS Step Functions",
      "AWS Lambda"
    ],
    "Terms": [
      "AWS Glue",
      "AWS Step Functions",
      "Amazon EC2",
      "Amazon EventBridge",
      "AWS Lambda"
    ],
    "SelectA": "AWS Glue에서 워크플로우를 구성하고 AWS Glue가 AWS Lambda 함수를 호출하여 워크플로우 단계를 처리합니다.",
    "SelectA_Commentary": "AWS Glue는 주로 데이터 처리에 최적화된 서비스이지만, 전체 워크플로우 오케스트레이션용으로 설계되지 않아 이벤트 기반 아키텍처 전반을 유연하게 구현하기 어렵습니다.",
    "SelectB": "AWS Step Functions에서 워크플로우를 구성하고 애플리케이션을 Amazon EC2 인스턴스에 배포합니다. Step Functions로 EC2 인스턴스에서 워크플로우 단계를 호출합니다.",
    "SelectB_Commentary": "EC2 인스턴스는 직접 서버 관리가 필요해 서버리스를 지향하는 요구사항과 맞지 않으며, 운영 오버헤드가 늘어날 수 있습니다.",
    "SelectC": "Amazon EventBridge에서 워크플로우를 구성하고, 일정 스케줄에 따라 EventBridge가 AWS Lambda 함수를 호출하여 워크플로우 단계를 처리합니다.",
    "SelectC_Commentary": "EventBridge는 이벤트 라우팅에 강점이 있으나, 복잡한 워크플로우 상태 관리를 위해서는 Step Functions처럼 전용 오케스트레이션 서비스가 더 적합합니다.",
    "SelectD": "AWS Step Functions에서 워크플로우를 구성하고 상태 머신(state machine)을 만듭니다. 상태 머신을 통해 AWS Lambda 함수를 호출하여 워크플로우 단계를 처리합니다.",
    "SelectD_Commentary": "Step Functions와 Lambda를 함께 사용하면 서버리스 기반의 이벤트 드리븐 아키텍처를 쉽게 구현할 수 있고 상태 관리를 자동화하여 운영 오버헤드를 최소화할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q720",
      "Q293",
      "Q194",
      "Q8",
      "Q18"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q293",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q790",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q569",
      "Q351",
      "Q785"
    ],
    "SelectD_recommedations": [
      "Q351",
      "Q18",
      "Q785"
    ]
  },
  {
    "Question_Number": "Q352",
    "Question_Description": "한 회사가 온라인 멀티플레이어 게임을 위한 네트워크를 설계하고 있습니다. 이 게임은 UDP 네트워킹 프로토콜을 사용하며, 8개의 AWS 리전에 배포될 예정입니다. 네트워크 아키텍처는 지연 시간과 패킷 손실을 최소화하여 최종 사용자들에게 높은 품질의 게임 환경을 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100197-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 멀티플레이어 게임에서 UDP 트래픽의 지연과 패킷 손실을 줄이는 네트워크 설계를 묻습니다. AWS Global Accelerator는 전 세계적인 AWS 전용 네트워크를 활용해 UDP 트래픽을 가속화하므로, 낮은 지연 시간과 안정적인 연결을 제공하여 요구사항을 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "온라인 멀티플레이어 게임",
      "UDP 프로토콜",
      "지연 시간 최소화",
      "패킷 손실 최소화",
      "네트워크 아키텍처",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "UDP",
      "AWS Global Accelerator",
      "Transit Gateway",
      "Amazon CloudFront",
      "VPC Peering"
    ],
    "SelectA": "각 리전에 Transit Gateway를 설정하고, 리전 간 피어링 연결을 생성합니다.",
    "SelectA_Commentary": "Transit Gateway는 VPC와 온프레미스 간 연결을 통합하지만, 글로벌 지연을 줄이는 전용 네트워크 가속 기능을 제공하지 못합니다.",
    "SelectB": "각 리전에 대한 UDP 리스너와 엔드포인트 그룹을 갖춘 AWS Global Accelerator를 설정합니다.",
    "SelectB_Commentary": "AWS Global Accelerator는 UDP 트래픽을 지원하며 AWS의 글로벌 네트워크를 통해 지연 시간과 패킷 손실을 최소화하는 최적의 솔루션입니다.",
    "SelectC": "UDP가 활성화된 Amazon CloudFront를 설정하고 각 리전에 오리진을 구성합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS 기반 콘텐츠에 최적화되어 있으며, 실시간 UDP 전송 가속 용도로는 적합하지 않습니다.",
    "SelectD": "각 리전 간 VPC 피어링 메쉬를 설정하고 UDP를 활성화합니다.",
    "SelectD_Commentary": "VPC 피어링을 모든 리전에 구성하면 복잡도가 크게 증가하며, 글로벌 지연을 최소화하기 위한 전용 가속 경로를 제공하지 못합니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q568",
      "Q443",
      "Q865",
      "Q1015"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q622",
      "Q506"
    ],
    "SelectB_recommedations": [
      "Q352",
      "Q704",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q352",
      "Q704",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q352",
      "Q704",
      "Q600"
    ]
  },
  {
    "Question_Number": "Q353",
    "Question_Description": "한 회사가 단일 Availability Zone의 Amazon EC2 인스턴스에서 3계층 웹 애플리케이션을 호스팅하고 있습니다. 이 웹 애플리케이션은 Amazon Elastic Block Store(Amazon EBS) 볼륨이 연결된 EC2 인스턴스에서 자체적으로 관리하는 MySQL 데이터베이스를 사용해 데이터를 저장합니다. 현재 MySQL 데이터베이스는 1TB 용량의 Provisioned IOPS SSD(io2) EBS 볼륨을 사용하며, 최대 트래픽 시점에 읽기와 쓰기 각각 1,000 IOPS가 발생할 것으로 예상됩니다. 회사는 장애를 최소화하고, 성능을 안정화하며, 비용을 절감하되, 현재 IOPS의 두 배를 처리할 수 있는 용량을 유지하기를 원합니다. 또한 DB 계층을 고가용성과 내결함성을 갖춘 완전관리형 솔루션으로 이전하고 싶어 합니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100225-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 현재 EC2에서 자체 관리하던 MySQL 환경을 고가용성, 내결함성, 비용 절감까지 충족하는 완전관리형 DB 서비스로 전환하는 상황을 묻습니다. Amazon RDS for MySQL Multi-AZ 구성과 gp2 스토리지로 충분한 IOPS를 확보하고, 운영 관리 부담과 비용을 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "3계층 웹 애플리케이션",
      "IOPS",
      "비용 절감",
      "고가용성",
      "내결함성",
      "Amazon RDS for MySQL",
      "Multi-AZ"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Provisioned IOPS SSD(io2)",
      "MySQL",
      "Amazon RDS",
      "Multi-AZ",
      "General Purpose SSD(gp2)",
      "Amazon S3 Intelligent-Tiering",
      "active-passive mode"
    ],
    "SelectA": "Amazon RDS for MySQL DB 인스턴스를 Multi-AZ로 배포하고, io2 Block Express EBS 볼륨을 사용합니다.",
    "SelectA_Commentary": "io2 Block Express 스토리지는 성능이 뛰어나지만 비용이 높아 gp2 대비 비용 효율성이 떨어집니다.",
    "SelectB": "Amazon RDS for MySQL DB 인스턴스를 Multi-AZ로 배포하고, General Purpose SSD (gp2) EBS 볼륨을 사용합니다.",
    "SelectB_Commentary": "gp2는 필요한 IOPS를 충분히 지원하며, Multi-AZ로 고가용성과 내결함성을 확보해 가장 비용 효율적인 솔루션입니다.",
    "SelectC": "Amazon S3 Intelligent-Tiering 액세스 티어를 사용합니다.",
    "SelectC_Commentary": "데이터베이스 대신 오브젝트 스토리지 솔루션을 제안하는 것으로 요구 사항인 MySQL 환경 대체에 부적합합니다.",
    "SelectD": "크기가 큰 두 대의 EC2 인스턴스를 사용하여 active-passive 모드로 데이터베이스를 호스팅합니다.",
    "SelectD_Commentary": "직접 EC2를 운영하면 관리 부담이 크고 완전관리형 서비스 대비 장애 복구나 비용 효율 측면에서 불리합니다.",
    "Question_Description_recommedations": [
      "Q425",
      "Q841",
      "Q867",
      "Q118",
      "Q773"
    ],
    "SelectA_recommedations": [
      "Q574",
      "Q607",
      "Q353"
    ],
    "SelectB_recommedations": [
      "Q607",
      "Q940",
      "Q574"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q552",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ]
  },
  {
    "Question_Number": "Q354",
    "Question_Description": "한 회사가 AWS에서 서버리스 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon API Gateway, AWS Lambda, 그리고 Amazon RDS for PostgreSQL을 사용합니다. 최근 피크 트래픽 또는 예측 불가능한 트래픽 시에 데이터베이스 연결 시간 초과로 인해 애플리케이션 오류가 증가하고 있습니다. 회사는 코드 변경을 최소화하면서 애플리케이션 장애를 줄여야 합니다. 어떤 솔루션스 아키텍트가 이 요구 사항을 충족하기 위해 해야 할 일은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100198-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버리스 환경에서 예측 불가능한 트래픽으로 인해 RDS 데이터베이스 연결이 한계에 부딪혀 발생하는 시간 초과 오류를 최소화하기 위한 방법을 묻습니다. Amazon RDS Proxy를 구성하면 데이터베이스 연결을 풀링, 공유하여 Lambda 함수를 대규모로 운영할 때 발생하는 연결 수 증가 문제를 효과적으로 완화할 수 있고, 코드 변경도 매우 적습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "서버리스 애플리케이션",
      "데이터베이스 연결 시간 초과",
      "피크 트래픽",
      "RDS Proxy",
      "코드 변경 최소화"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon RDS for PostgreSQL",
      "RDS Proxy",
      "Lambda concurrency",
      "Amazon DynamoDB",
      "on-demand scaling"
    ],
    "SelectA": "Lambda 동시성(Lambda concurrency) 제한을 낮춥니다.",
    "SelectA_Commentary": "동시성 설정을 무작정 줄이면 트래픽이 많은 시점에 애플리케이션 성능이 저하될 수 있고, 문제의 근본 해결책이 아닙니다.",
    "SelectB": "RDS DB 인스턴스에서 RDS Proxy를 활성화합니다.",
    "SelectB_Commentary": "RDS Proxy를 사용하면 Lambda 함수가 데이터베이스와 연결을 풀링해 효율적으로 관리할 수 있으므로, 연결 부담 완화 및 오류 감소에 가장 효과적이며 코드 변화도 최소화됩니다.",
    "SelectC": "RDS DB 인스턴스 클래스를 더 큰 용량으로 조정해 더 많은 연결을 허용합니다.",
    "SelectC_Commentary": "DB 인스턴스 사이즈를 키우는 것은 임시방편일 수 있지만, 근본적으로 연결 수가 잦은 서버리스 환경에서 풀링 메커니즘이 없이 확장하기에는 한계가 있을 수 있습니다.",
    "SelectD": "데이터베이스를 Amazon DynamoDB(on-demand scaling)로 마이그레이션합니다.",
    "SelectD_Commentary": "DynamoDB로 마이그레이션하면 큰 코드 변경이 필요하며, 기존 PostgreSQL 기반 로직들과 호환성을 유지하기 어려워 최소한의 코드 변경이라는 목표에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q944",
      "Q207",
      "Q879",
      "Q198",
      "Q25"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q833",
      "Q351"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q228",
      "Q108"
    ],
    "SelectC_recommedations": [
      "Q108",
      "Q259",
      "Q863"
    ],
    "SelectD_recommedations": [
      "Q768",
      "Q845",
      "Q1002"
    ]
  },
  {
    "Question_Number": "Q355",
    "Question_Description": "한 회사가 오래된 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 매시간 CPU 집약적인 배치 작업을 수행하며, 온프레미스 서버에서는 평균 15분이 소요됩니다. 해당 서버는 64 vCPU와 512 GiB 메모리를 보유하고 있습니다. 이 배치 작업을 15분 내에 실행하면서 운영 오버헤드를 최소화할 수 있는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100227-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 CPU와 메모리를 요구하는 배치 작업을 AWS 상에서 최소한의 운영 오버헤드로 처리하는 방법을 묻습니다. AWS Batch는 필요한 EC2 리소스를 자동으로 프로비저닝하고 스케줄링까지 관리해주어, 배치 작업을 15분 이내에 수행하도록 설계할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "배치 작업",
      "CPU 집약적",
      "15분 내",
      "64 vCPU",
      "512 GiB 메모리",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "Amazon Lightsail",
      "AWS Auto Scaling",
      "AWS Batch",
      "Amazon EC2"
    ],
    "SelectA": "AWS Lambda를 사용하여 함수형 확장(functinal scaling)을 적용합니다.",
    "SelectA_Commentary": "Lambda는 동시 실행과 확장이 가능하지만, 메모리와 실행 시간 제약 때문에 64 vCPU와 대용량 메모리 요구 사항을 충족하기 어렵습니다.",
    "SelectB": "Amazon Elastic Container Service(Amazon ECS)에서 AWS Fargate를 사용합니다.",
    "SelectB_Commentary": "Fargate는 서버 관리 부담을 줄여주지만, 세밀한 옵션 구성과 리소스 제한으로 매우 큰 CPU/메모리 요구사항에 맞추기가 까다로울 수 있습니다.",
    "SelectC": "Amazon Lightsail과 AWS Auto Scaling을 사용합니다.",
    "SelectC_Commentary": "Lightsail은 간단한 워크로드에 적합하지만, 64 vCPU 및 512 GiB 메모리가 필요한 대규모 배치 작업에는 리소스가 제한적입니다.",
    "SelectD": "AWS Batch를 Amazon EC2에서 사용합니다.",
    "SelectD_Commentary": "AWS Batch가 필요한 리소스를 자동으로 프로비저닝하고 작업 스케줄링까지 처리해주어 가장 적은 운영 오버헤드로 15분 내 배치 완료가 가능합니다.",
    "Question_Description_recommedations": [
      "Q865",
      "Q113",
      "Q361",
      "Q127",
      "Q443"
    ],
    "SelectA_recommedations": [
      "Q620",
      "Q361",
      "Q143"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q857",
      "Q704"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q335",
      "Q620"
    ],
    "SelectD_recommedations": [
      "Q857",
      "Q746",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q356",
    "Question_Description": "한 회사가 Amazon S3 Standard 스토리지에 데이터를 저장하고 있습니다. 솔루션스 아키텍트는 30일 이후에 75%의 데이터가 거의 액세스되지 않는다는 사실을 발견했습니다. 회사는 모든 데이터를 즉시 액세스 가능한 상태로 유지하길 원하며, S3 Standard와 동일한 높은 가용성과 내구성을 원합니다. 동시에 저장 비용을 최소화하고자 합니다. 이러한 요구사항을 충족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100229-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터를 장기간 보관하면서 동시에 즉각적인 액세스와 높은 가용성, 내구성을 유지해야 하는 상황에서 비용을 최소화하는 적절한 스토리지 클래스를 찾는 것입니다. 30일 이후 자주 액세스되지 않는 데이터를 비용 효율적으로 관리하면서도, 필요 시 바로 사용할 수 있는 옵션이 중요합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon S3 Standard",
      "S3 Standard-IA",
      "저장 비용 절감",
      "즉시 액세스",
      "고가용성",
      "내구성"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Glacier Deep Archive",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "High Availability",
      "Resiliency",
      "Storage Costs"
    ],
    "SelectA": "30일 후에 데이터 객체를 S3 Glacier Deep Archive로 이동합니다.",
    "SelectA_Commentary": "Deep Archive는 가장 저렴하지만 즉각적인 액세스가 불가능합니다. 복원 시간이 길어 즉시 사용해야 하는 요구사항을 충족하기 어렵습니다.",
    "SelectB": "30일 후에 데이터 객체를 S3 Standard-Infrequent Access (S3 Standard-IA)로 이동합니다.",
    "SelectB_Commentary": "S3 Standard-IA는 여러 AZ에 걸쳐 높은 내구성과 가용성을 보장하며, 드물게 액세스되는 데이터를 보다 저렴하게 저장할 수 있어 요구사항에 부합합니다.",
    "SelectC": "30일 후에 데이터 객체를 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 이동합니다.",
    "SelectC_Commentary": "한 AZ에만 저장되어 재해 발생 시 데이터 손실 위험이 있습니다. 회사가 원하는 ‘동일한 수준의 가용성 및 내구성’ 요건에 부합하지 않습니다.",
    "SelectD": "데이터 객체를 즉시 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 이동합니다.",
    "SelectD_Commentary": "마찬가지로 한 AZ만 사용하기 때문에 내구성과 가용성 면에서 회사의 요구사항을 충족하지 못합니다. 또한 30일 동안 자주 액세스되는 프리퀀트 데이터를 고려하지 못했습니다.",
    "Question_Description_recommedations": [
      "Q415",
      "Q23",
      "Q126",
      "Q890",
      "Q606"
    ],
    "SelectA_recommedations": [
      "Q606",
      "Q1003",
      "Q551"
    ],
    "SelectB_recommedations": [
      "Q356",
      "Q126",
      "Q890"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q606"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q357",
    "Question_Description": "한 게임 회사가 데이터 센터에서 운영하던 공용 스코어보드를 AWS Cloud로 이전하려고 합니다. 회사는 Application Load Balancer 뒤에서 Amazon EC2 Windows Server 인스턴스를 사용하여 동적 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션에는 정적 파일과 동적으로 동작하는 서버 사이드 코드가 포함되어 있으며, 높은 가용성을 갖춘 스토리지 솔루션이 필요합니다. 요구 사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 할 조치 두 가지는 무엇입니까?",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100230-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows Server 기반 애플리케이션의 정적 파일과 동적 코드를 안정적으로 호스팅하기 위한 고가용성 스토리지를 설계하는 방법을 묻습니다. 정적 콘텐츠는 Amazon S3에 저장하고, 글로벌 엣지로 빠르게 배포하기 위해 Amazon CloudFront를 사용하는 것이 적합합니다. 또한 Windows 환경에서 서버 사이드 코드를 공유하려면 Amazon FSx for Windows File Server가 고성능과 Windows 호환성을 제공하므로 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "높은 가용성",
      "정적 파일",
      "서버 사이드 코드",
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon FSx for Windows File Server"
    ],
    "Terms": [
      "Amazon EC2 Windows Server",
      "Application Load Balancer",
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon ElastiCache",
      "Amazon EFS",
      "Amazon FSx for Windows File Server",
      "Amazon EBS"
    ],
    "SelectA": "정적 파일을 Amazon S3에 저장하고, Amazon CloudFront를 사용하여 엣지에서 오브젝트를 캐시합니다.",
    "SelectA_Commentary": "정적 파일을 S3에 두고 CloudFront로 배포하면 글로벌 엣지 로케이션을 통한 빠르고 가용성 높은 콘텐츠 제공이 가능합니다. (정답)",
    "SelectB": "정적 파일을 Amazon S3에 저장하고, Amazon ElastiCache를 사용하여 엣지에서 오브젝트를 캐시합니다.",
    "SelectB_Commentary": "ElastiCache는 응답 속도를 개선하는 캐시 서비스지만, 직접 엣지 로케이션을 활용하지 않으므로 적절하지 않습니다.",
    "SelectC": "서버 사이드 코드를 Amazon Elastic File System(Amazon EFS)에 저장하고, 각 EC2 인스턴스에서 EFS 볼륨을 마운트합니다.",
    "SelectC_Commentary": "EFS는 Linux 기반에 적합하며, Windows Server 환경 완전 호환을 위해서는 FSx for Windows File Server가 더 적합합니다.",
    "SelectD": "서버 사이드 코드를 Amazon FSx for Windows File Server에 저장하고, 각 EC2 인스턴스에서 FSx 볼륨을 마운트합니다.",
    "SelectD_Commentary": "Windows Server 환경에 최적화된 완전관리형 파일 시스템으로 고성능과 높은 가용성을 제공하므로 올바른 선택입니다. (정답)",
    "SelectE": "서버 사이드 코드를 General Purpose SSD (gp2) Amazon EBS 볼륨에 저장하고, 각 EC2 인스턴스에서 EBS 볼륨을 마운트합니다.",
    "SelectE_Commentary": "EBS는 단일 인스턴스 전용 스토리지로, 여러 인스턴스 간 공유가 까다로우며 고가용성 및 공유 스토리지 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q537",
      "Q714",
      "Q405",
      "Q275",
      "Q5"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q194",
      "Q110"
    ],
    "SelectB_recommedations": [
      "Q784",
      "Q110",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q618",
      "Q54",
      "Q635"
    ],
    "SelectE_recommedations": [
      "Q986",
      "Q602",
      "Q837"
    ]
  },
  {
    "Question_Number": "Q358",
    "Question_Description": "한 소셜 미디어 회사가 Amazon EC2 인스턴스 위에 애플리케이션을 운영하고 있으며, 이 인스턴스들은 Application Load Balancer(ALB) 뒤에 배치되어 있습니다. 이 ALB는 Amazon CloudFront 배포의 오리진으로 설정되어 있습니다. 애플리케이션은 Amazon S3 버킷에 10억 개 이상의 이미지를 보유하고 있으며, 매초 수천 장의 이미지를 처리합니다. 이 회사는 이미지를 동적으로 리사이징하고, 클라이언트에게 적합한 이미지 포맷으로 제공하기를 원합니다. 이 요구 사항을 충족하면서 운영 오버헤드를 최소화하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100231-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 이미지를 빠르게 변환하여 사용자별로 적합한 형식(포맷)을 제공해야 하는 시나리오입니다. 최소한의 인프라 관리와 자동 스케일링을 위해 Lambda@Edge를 활용해 CloudFront 레벨에서 이미지를 동적으로 리사이징하고 적절한 포맷으로 제공하는 것이 가장 효율적인 방법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "소셜 미디어 회사",
      "10억 개 이상의 이미지",
      "동적 이미지 리사이징",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront",
      "Amazon S3",
      "Lambda@Edge",
      "이미지 리사이징",
      "User-Agent HTTP header",
      "CloudFront origin request policy",
      "CloudFront response headers policy"
    ],
    "SelectA": "EC2 인스턴스에 외부 이미지 관리 라이브러리를 설치하여 이미지를 처리합니다.",
    "SelectA_Commentary": "EC2에 직접 라이브러리를 설치하면 서버 운영과 확장 부담이 증가하여 운영 오버헤드가 높아집니다.",
    "SelectB": "CloudFront 오리진 요청 정책(Origin Request Policy)을 생성하여 요청의 User-Agent HTTP 헤더를 기반으로 자동으로 이미지를 리사이징하고 적절한 포맷을 제공합니다.",
    "SelectB_Commentary": "단순 요청 정책만으로 실제 동적 변환 기능을 수행하기 어렵고, 사용자 맞춤 처리 로직이 제한적입니다.",
    "SelectC": "Lambda@Edge 함수와 외부 이미지 관리 라이브러리를 사용하고, 해당 함수를 이미지를 제공하는 CloudFront 동작(Behavior)에 연결합니다.",
    "SelectC_Commentary": "서버리스 환경에서 CloudFront 엣지 위치에서 동시에 확장 가능하며, 동적 이미지 처리에 최적화된 방식으로 운영 오버헤드가 가장 낮습니다.",
    "SelectD": "CloudFront 응답 헤더 정책(Response Headers Policy)을 생성하여 요청의 User-Agent HTTP 헤더를 기반으로 자동으로 이미지를 리사이징하고 적절한 포맷을 제공합니다.",
    "SelectD_Commentary": "응답 헤더 정책만으로는 이미지 자체를 변환하기 어려우며, 실제 리사이징 로직을 처리하는 기능이 부족합니다.",
    "Question_Description_recommedations": [
      "Q12",
      "Q141",
      "Q272",
      "Q815",
      "Q266"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q361",
      "Q857"
    ],
    "SelectB_recommedations": [
      "Q280",
      "Q704",
      "Q352"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q280",
      "Q576"
    ],
    "SelectD_recommedations": [
      "Q280",
      "Q352",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q359",
    "Question_Description": "한 병원이 환자 기록을 Amazon S3 버킷에 저장해야 합니다. 병원의 컴플라이언스 팀은 모든 PHI(Protected Health Information)가 전송 중 및 저장 중에 암호화되어야 한다고 요구합니다. 또한 컴플라이언스 팀은 저장 중 데이터에 대한 암호화 키를 직접 관리해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100232-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 병원에서 의료 정보(PHI)를 안전하게 저장하기 위해 전송 중(HTTPS/TLS) 및 저장 중(SSE-KMS) 암호화를 모두 만족해야 함을 묻습니다. 특히 컴플라이언스 팀이 암호화 키를 직접 관리해야 하므로 KMS 키를 활용한 SSE-KMS 방식이 필요합니다. 또한 S3 버킷 정책에 aws:SecureTransport 조건을 추가하여 HTTPS를 통한 안전한 연결을 강제할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "병원",
      "PHI",
      "S3 버킷",
      "암호화 in transit",
      "암호화 at rest",
      "aws:SecureTransport",
      "SSE-KMS",
      "KMS 키"
    ],
    "Terms": [
      "Amazon S3",
      "SSL/TLS",
      "AWS Certificate Manager (ACM)",
      "aws:SecureTransport",
      "SSE-KMS",
      "SSE-S3",
      "Amazon Macie",
      "KMS keys"
    ],
    "SelectA": "AWS Certificate Manager에서 퍼블릭 SSL/TLS 인증서를 생성하고 Amazon S3에 연결합니다. 각 S3 버킷의 기본 암호화를 AWS KMS 키(SSE-KMS)로 설정합니다. 이후 컴플라이언스 팀이 KMS 키를 관리하게 합니다.",
    "SelectA_Commentary": "S3 자체에 ACM 인증서를 직접 연결하는 방식은 일반적이지 않고, aws:SecureTransport로 HTTPS 요구사항을 쉽게 충족할 수 없으므로 최적 해법이 아닙니다.",
    "SelectB": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용해 HTTPS(TLS)를 통한 암호화 연결만 허용합니다. 각 S3 버킷의 기본 암호화를 SSE-S3로 설정하고 컴플라이언스 팀이 SSE-S3 키를 관리하게 합니다.",
    "SelectB_Commentary": "SSE-S3는 AWS가 키를 전적으로 관리하므로 팀이 키를 직접 관리해야 하는 요건을 충족하지 못합니다.",
    "SelectC": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용해 HTTPS(TLS)를 통한 암호화 연결만 허용합니다. 각 S3 버킷의 기본 암호화를 AWS KMS 키(SSE-KMS)로 설정하고 컴플라이언스 팀이 KMS 키를 관리하게 합니다.",
    "SelectC_Commentary": "전송 중 HTTPS 암호화와 SSE-KMS를 통한 저장 중 암호화, 그리고 KMS 키에 대한 컴플라이언스 팀의 직접 관리까지 모두 충족하는 최적 답안입니다.",
    "SelectD": "S3 버킷 정책에서 aws:SecureTransport 조건을 사용해 HTTPS(TLS)를 통한 암호화 연결만 허용합니다. Amazon Macie를 사용해 Amazon S3에 저장된 민감 정보를 보호하고 컴플라이언스 팀이 Macie를 관리하게 합니다.",
    "SelectD_Commentary": "Macie는 데이터 식별 및 분류가 주 목적이며, 컴플라이언스 팀이 원하는 키 직접 관리는 제공하지 못해 요건을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q756",
      "Q533",
      "Q678",
      "Q106",
      "Q154"
    ],
    "SelectA_recommedations": [
      "Q1009",
      "Q640",
      "Q681"
    ],
    "SelectB_recommedations": [
      "Q185",
      "Q965",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q640",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q740",
      "Q862"
    ]
  },
  {
    "Question_Number": "Q360",
    "Question_Description": "한 회사가 동일한 VPC 내에서 두 개의 REST API를 사용하는 Private Gateway를 Amazon API Gateway로 운영하고 있습니다. BuyStock RESTful 웹 서비스는 주식을 구매하기 전에 충분한 자금이 있는지 확인하기 위해 CheckFunds RESTful 웹 서비스를 호출합니다. 그런데 VPC Flow Logs를 확인해 보니, BuyStock RESTful 웹 서비스가 VPC 내부가 아닌 인터넷을 통해 CheckFunds RESTful 웹 서비스를 호출하고 있음을 발견했습니다. 이 두 API가 VPC 내부에서 통신하도록 구현해야 합니다. 코드 변경을 최소화하면서 이 요구사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/100238-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부에서 REST API 간 통신을 유지하여 인터넷 경유를 방지해야 하는 시나리오입니다. Interface Endpoint는 AWS 서비스에 대한 사설 연결 지점으로 설정되며, 트래픽이 퍼블릭 인터넷을 거치지 않고 VPC 내부를 통해 안전하게 전달되도록 합니다. 따라서 코드 변경을 최소화하면서도 사설 연결을 달성하기에 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Private Gateway",
      "VPC 내부 통신",
      "코드 변경 최소화",
      "Interface Endpoint",
      "Gateway Endpoint",
      "Amazon SQS"
    ],
    "Terms": [
      "Amazon API Gateway",
      "VPC",
      "RESTful 웹 서비스",
      "VPC Flow Logs",
      "Interface Endpoint",
      "Gateway Endpoint",
      "Amazon SQS"
    ],
    "SelectA": "인증을 위해 HTTP 헤더에 X-API-Key 헤더를 추가합니다.",
    "SelectA_Commentary": "X-API-Key 헤더는 권한 부여를 위한 추가 설정일 뿐, VPC 내부 통신을 강제하지 못하므로 문제 해결에 직접 도움이 되지 않습니다.",
    "SelectB": "Interface Endpoint를 사용합니다.",
    "SelectB_Commentary": "Interface Endpoint는 사설 IP 주소를 통해 API 트래픽을 VPC 내부로 라우팅할 수 있으며, 코드 변경을 거의 요구하지 않으면서도 인터넷 경유 없이 안전하게 통신할 수 있어 적합한 솔루션입니다.",
    "SelectC": "Gateway Endpoint를 사용합니다.",
    "SelectC_Commentary": "Gateway Endpoint는 Amazon S3나 DynamoDB와 같은 특정 AWS 서비스에 대한 사설 연결에만 사용 가능합니다. RESTful 웹 서비스 간 사설 연결에는 적합하지 않습니다.",
    "SelectD": "두 REST API 간에 Amazon SQS 큐를 추가합니다.",
    "SelectD_Commentary": "Amazon SQS를 사용해도 메시지를 비동기로 주고받을 수 있지만, 직접적인 API 호출 경로를 사설로 전환하는 데에는 적합하지 않으며 오버헤드가 추가됩니다.",
    "Question_Description_recommedations": [
      "Q792",
      "Q468",
      "Q950",
      "Q15",
      "Q91"
    ],
    "SelectA_recommedations": [
      "Q571",
      "Q265",
      "Q34"
    ],
    "SelectB_recommedations": [
      "Q803",
      "Q122",
      "Q665"
    ],
    "SelectC_recommedations": [
      "Q265",
      "Q893",
      "Q803"
    ],
    "SelectD_recommedations": [
      "Q765",
      "Q34",
      "Q364"
    ]
  },
  {
    "Question_Number": "Q361",
    "Question_Description": "한 회사가 AWS에서 멀티플레이어 게임 애플리케이션을 운영하고 있습니다. 이 회사는 애플리케이션이 데이터를 서브 밀리초 지연으로 읽고, 과거 데이터에 대해 일회성 쿼리를 실행할 수 있길 바랍니다. 이 요구사항을 만족하며 운영 오버헤드를 가장 적은 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102119-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실시간 분석을 위한 서브 밀리초 읽기 성능과 장기간 보관된 데이터를 위한 일회성 쿼리를 동시에 만족하려고 할 때 어떤 AWS 서비스를 조합해야 하는지 묻습니다. Amazon DynamoDB와 DAX를 사용하면 트래픽이 많은 멀티플레이어 게임에서 서브 밀리초 지연 시간으로 데이터를 조회할 수 있고, DynamoDB 테이블 데이터를 Amazon S3로 내보내어 Amazon Athena로 과거 데이터를 간단히 쿼리할 수 있어 운영 오버헤드가 최소화됩니다. 따라서 C가 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3"
    ],
    "Keywords": [
      "멀티플레이어 게임",
      "서브 밀리초 지연",
      "일회성 쿼리",
      "Amazon DynamoDB Accelerator (DAX)",
      "Amazon S3",
      "Amazon Athena",
      "DynamoDB 테이블 내보내기"
    ],
    "Terms": [
      "Amazon RDS",
      "Amazon S3",
      "S3 Glacier Deep Archive",
      "Amazon Athena",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "DynamoDB table export",
      "Kinesis Data Streams",
      "Kinesis Data Firehose",
      "S3 Lifecycle"
    ],
    "SelectA": "Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.",
    "SelectA_Commentary": "Amazon RDS는 서브 밀리초 수준의 지연 시간을 보장하기 어렵고, 커스텀 스크립트로 주기적 내보내기는 추가 운영 작업이 많아 효율적이지 않습니다.",
    "SelectB": "Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for long-term storage. Run one-time queries on the data in Amazon S3 using Amazon Athena.",
    "SelectB_Commentary": "Amazon S3 단독으로는 서브 밀리초 지연을 보장하기 어렵습니다. 장기 보관 및 Athena로의 쿼리는 가능하지만 실시간 응답을 만족하지 못합니다.",
    "SelectC": "Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.",
    "SelectC_Commentary": "DynamoDB와 DAX는 서브 밀리초 읽기를 지원하고, 데이터를 손쉽게 Amazon S3로 내보내어 Athena로 일회성 쿼리를 할 수 있어 운영 오버헤드가 가장 적은 최적의 솔루션입니다.",
    "SelectD": "Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket.",
    "SelectD_Commentary": "Kinesis Data Streams와 Firehose를 통한 전달 파이프라인은 추가 설정과 운영 비용이 발생하며, Athena 쿼리를 위한 별도 처리 과정이 필요해 더 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q443",
      "Q568",
      "Q631",
      "Q865",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q292",
      "Q386",
      "Q95"
    ],
    "SelectB_recommedations": [
      "Q292",
      "Q214",
      "Q804"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q292",
      "Q578"
    ],
    "SelectD_recommedations": [
      "Q177",
      "Q292",
      "Q578"
    ]
  },
  {
    "Question_Number": "Q362",
    "Question_Description": "한 회사에서 결제 처리 시스템을 사용 중이며, 특정 결제 ID에 대한 메시지가 전송된 순서대로 수신되어야 합니다. 그렇지 않으면 결제가 잘못 처리될 수 있습니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까? (2개를 고르시오.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102121-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 특정 결제 ID의 메시지 순서를 보장하기 위한 솔루션을 찾는 것입니다. Amazon Kinesis Data Streams는 파티션 키를 통해 순서를 유지하고, Amazon SQS FIFO 큐는 메시지 그룹 기능을 통해 순서를 보장합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "메시지 순서",
      "결제 ID",
      "Amazon Kinesis Data Streams",
      "SQS FIFO 큐",
      "파티션 키",
      "메시지 그룹"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Amazon Kinesis Data Streams",
      "Amazon ElastiCache for Memcached",
      "Amazon SQS",
      "FIFO Queue",
      "결제 ID",
      "Partition Key",
      "Message Group"
    ],
    "SelectA": "Amazon DynamoDB 테이블에 메시지를 기록하고 결제 ID를 파티션 키로 사용합니다.",
    "SelectA_Commentary": "DynamoDB는 파티션 키를 통해 데이터를 분산 저장하지만 레코드 순서를 보장하지 못하므로 요구사항을 충족하기 어렵습니다.",
    "SelectB": "Amazon Kinesis data stream에 메시지를 기록하고 결제 ID를 파티션 키로 사용합니다.",
    "SelectB_Commentary": "Kinesis Data Streams는 동일한 파티션 키 메시지를 동일한 샤드에 기록하여 메시지 순서를 보장하므로 요구사항에 부합합니다.",
    "SelectC": "Amazon ElastiCache for Memcached 클러스터에 메시지를 기록하고 결제 ID를 키로 사용합니다.",
    "SelectC_Commentary": "캐시 서비스인 Memcached는 순서 보장 기능이 없으므로 메시지 순서를 보장할 수 없습니다.",
    "SelectD": "Amazon SQS 큐에 메시지를 기록합니다. 메시지 속성으로 결제 ID를 설정합니다.",
    "SelectD_Commentary": "일반 SQS 큐는 기본적으로 FIFO가 아니며, 메시지 순서를 보장하지 못해 결제 처리 오류가 발생할 수 있습니다.",
    "SelectE": "Amazon SQS FIFO 큐에 메시지를 기록하고 메시지 그룹을 결제 ID로 사용합니다.",
    "SelectE_Commentary": "SQS FIFO 큐는 메시지 그룹을 기반으로 하는 순서 보장 기능을 제공하여 메시지를 전송 순서대로 처리할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q967",
      "Q917",
      "Q58",
      "Q491",
      "Q255"
    ],
    "SelectA_recommedations": [
      "Q78",
      "Q845",
      "Q1002"
    ],
    "SelectB_recommedations": [
      "Q845",
      "Q10",
      "Q798"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q48",
      "Q824"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q843",
      "Q293"
    ],
    "SelectE_recommedations": [
      "Q10",
      "Q8",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q363",
    "Question_Description": "한 회사가 게임 시스템을 구축하고 있으며, 리더보드, 매칭, 인증 서비스를 각각 동시에 호출해야 하는 고유한 이벤트를 전송해야 합니다. 또한 AWS 이벤트 기반 시스템에서 이벤트 순서를 반드시 보장해야 합니다. 이 조건을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102124-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이벤트가 여러 서비스(리더보드, 매칭, 인증)로 동시에 전달되면서도 이벤트가 발생한 순서를 꼭 지켜야 하는 이벤트 드리븐 아키텍처에 대한 내용입니다. Amazon SNS FIFO topics는 메시지의 순서를 보장하며, 주제-구독 방식으로 여러 서비스에 동시에 메시지를 전송할 수 있어 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "게임 시스템",
      "이벤트 순서",
      "동시 전송",
      "리더보드",
      "매칭",
      "인증",
      "Amazon SNS FIFO topics"
    ],
    "Terms": [
      "Amazon EventBridge",
      "Amazon SNS FIFO topics",
      "Amazon SNS standard topics",
      "Amazon SQS FIFO queues"
    ],
    "SelectA": "Amazon EventBridge event bus",
    "SelectA_Commentary": "EventBridge는 다양한 소스에서 이벤트를 수집해 전송하지만, 메시지의 순서를 보장하지 않습니다.",
    "SelectB": "Amazon Simple Notification Service (Amazon SNS) FIFO topics",
    "SelectB_Commentary": "FIFO 토픽은 메시지의 순서를 보장하며 여러 서비스로 동시 전송 가능해 요구사항을 충족하는 정답입니다.",
    "SelectC": "Amazon Simple Notification Service (Amazon SNS) standard topics",
    "SelectC_Commentary": "인터넷 기반 발행-구독 모델로 확장성은 좋지만 순서 보장은 지원하지 않습니다.",
    "SelectD": "Amazon Simple Queue Service (Amazon SQS) FIFO queues",
    "SelectD_Commentary": "SQS FIFO 큐는 순서 보장을 지원하지만 단일 큐 소비 구조로 멀티 서비스 동시 전달에 대한 구현이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q149",
      "Q786",
      "Q163",
      "Q519",
      "Q802"
    ],
    "SelectA_recommedations": [
      "Q569",
      "Q351",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q148",
      "Q636",
      "Q45"
    ],
    "SelectC_recommedations": [
      "Q148",
      "Q636",
      "Q45"
    ],
    "SelectD_recommedations": [
      "Q814",
      "Q584",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q364",
    "Question_Description": "한 병원이 환자로부터 증상을 수집하는 새로운 애플리케이션을 설계하고 있습니다. 병원은 아키텍처에 Amazon Simple Queue Service(Amazon SQS)와 Amazon Simple Notification Service(Amazon SNS)를 사용하기로 결정했습니다. 솔루션스 아키텍트가 인프라 디자인을 검토하고 있으며, 데이터는 저장 시(At Rest)와 전송 시(In Transit) 모두 암호화되어야 합니다. 또한 병원의 허가된 인원만이 데이터에 접근할 수 있어야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 단계를 결합해야 합니까? (2개를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102125-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "병원 환경에서 Amazon SQS와 Amazon SNS 데이터의 안전한 전송 및 저장을 위해서는 서버 사이드 암호화와 KMS Key Policy 제한, 그리고 TLS를 통한 전송 계층 보안이 필요합니다. 정답인 C와 D는 각각 SNS와 SQS에 대한 암호화 설정 및 TLS 제한 조건을 적용하여 모든 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "병원",
      "데이터 암호화",
      "저장 시 암호화",
      "전송 시 암호화",
      "Amazon SQS",
      "Amazon SNS",
      "AWS KMS",
      "Key Policy",
      "TLS",
      "Authorized Principals"
    ],
    "Terms": [
      "Amazon SQS",
      "Amazon SNS",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key",
      "Server-Side Encryption (SSE)",
      "Key Policy",
      "TLS",
      "IAM Policy"
    ],
    "SelectA": "SQS 컴포넌트에서 서버 사이드 암호화를 활성화합니다. 기본 키 정책을 업데이트해 허가된 Principal에게만 키 사용을 제한합니다.",
    "SelectA_Commentary": "저장 시 암호화는 되지만 전송 시 암호화(TLS 허용)에 대한 조건이 없어 요구사항을 모두 충족하지 못합니다.",
    "SelectB": "SNS 컴포넌트에서 AWS KMS Customer Managed Key를 사용해 서버 사이드 암호화를 활성화합니다. 키 사용을 허가된 Principal에게만 제한하는 키 정책을 적용합니다.",
    "SelectB_Commentary": "SNS 암호화는 가능하나 전송 시 TLS 필수 조건이 언급되지 않아, 전체 보안 요구사항을 충족하지 못합니다.",
    "SelectC": "SNS 컴포넌트에서 암호화를 활성화하고 기본 키 정책을 업데이트해 허가된 Principal만 키를 사용할 수 있도록 제한합니다. Topic 정책에 조건을 설정해 TLS를 통한 암호화 연결만 허용합니다.",
    "SelectC_Commentary": "SNS의 저장 및 전송 암호화를 모두 구현하므로 해당 요구사항을 충족합니다. 정답 중 하나입니다.",
    "SelectD": "SQS 컴포넌트에서 AWS KMS Customer Managed Key를 사용해 서버 사이드 암호화를 활성화합니다. 허가된 Principal만 키를 사용할 수 있도록 키 정책을 적용합니다. Queue 정책에 조건을 설정해 TLS를 통한 암호화 연결만 허용합니다.",
    "SelectD_Commentary": "SQS의 저장 및 전송 암호화를 모두 구현하므로 해당 요구사항을 충족합니다. 정답 중 하나입니다.",
    "SelectE": "SQS 컴포넌트에서 AWS KMS Customer Managed Key를 사용해 서버 사이드 암호화를 활성화합니다. 키 사용을 허가된 Principal에게만 제한하는 IAM 정책을 적용합니다. Queue 정책에 조건을 설정해 TLS를 통한 암호화 연결만 허용합니다.",
    "SelectE_Commentary": "IAM 정책만으로는 KMS Key Policy에 준하는 제어가 충분치 않을 수 있어, 보안 요구사항을 완전히 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q765",
      "Q211",
      "Q977",
      "Q801",
      "Q965"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q793",
      "Q916",
      "Q929"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q803",
      "Q592"
    ],
    "SelectD_recommedations": [
      "Q793",
      "Q916",
      "Q371"
    ],
    "SelectE_recommedations": [
      "Q793",
      "Q916",
      "Q371"
    ]
  },
  {
    "Question_Number": "Q365",
    "Question_Description": "한 회사에서 Amazon RDS를 사용해 웹 애플리케이션을 운영하고 있습니다. 새로 온 Database Administrator(DBA)가 데이터베이스 테이블의 정보를 실수로 수정하여 데이터 손실이 발생했습니다. 이 같은 사고에서 복구하기 위해, 회사는 최근 30일 이내에 일어난 어느 변경에 대해서든, 변경이 발생하기 5분 전 상태로 데이터베이스를 복원할 수 있는 기능이 필요합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트가 설계에 포함해야 하는 기능은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102127-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon RDS의 Automated backups 기능은 최대 35일까지 Point-in-time Recovery(PITR)를 지원해, 특정 시점(최대 초 단위)까지 데이터베이스를 복원할 수 있습니다. 이를 30일로 설정하면 최근 30일 중에서 원하는 시점, 예를 들어 변경 발생 5분 전 등으로 쉽게 복원할 수 있어, 문제에서 요구하는 복원 시점을 만족시킵니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS",
      "데이터 복원",
      "자동화된 백업",
      "Point-in-time Recovery(PITR)",
      "30일 보존 기간"
    ],
    "Terms": [
      "Read replicas",
      "Manual snapshots",
      "Automated backups",
      "Multi-AZ deployments",
      "Point-in-time recovery (PITR)",
      "Retention period"
    ],
    "SelectA": "Read replicas",
    "SelectA_Commentary": "Read replicas는 읽기 성능 확장과 부담 분산을 위한 기능입니다. 손상된 데이터 복원에 직접적인 도움을 주지 못하므로 요구사항에 부합하지 않습니다.",
    "SelectB": "Manual snapshots",
    "SelectB_Commentary": "手動으로 찍는 스냅샷은 지속적인 시점 복원(Point-in-time Recovery)을 보장하지 않습니다. 매번 스냅샷을 찍어도 5분 단위로 복원하기는 어렵습니다.",
    "SelectC": "Automated backups",
    "SelectC_Commentary": "정답입니다. Automated backups는 Point-in-time Recovery를 지원하여 30일 이내의 원하는 시점으로 쉽게 복원할 수 있습니다.",
    "SelectD": "Multi-AZ deployments",
    "SelectD_Commentary": "Multi-AZ는 가용성과 장애 조치를 위한 기능으로, 데이터가 잘못 수정된 경우 시점 복원을 직접 제공하지 못하므로 본 문제의 해법이 되지 못합니다.",
    "Question_Description_recommedations": [
      "Q259",
      "Q629",
      "Q518",
      "Q863",
      "Q108"
    ],
    "SelectA_recommedations": [
      "Q752",
      "Q187",
      "Q58"
    ],
    "SelectB_recommedations": [
      "Q58",
      "Q187",
      "Q917"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q324",
      "Q244"
    ],
    "SelectD_recommedations": [
      "Q466",
      "Q584",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q366",
    "Question_Description": "한 회사의 웹 애플리케이션은 AWS Lambda 함수와 Amazon DynamoDB 데이터베이스 앞에 Amazon API Gateway API로 구성되어 있습니다. Lambda 함수는 비즈니스 로직을 처리하고, DynamoDB 테이블은 데이터를 저장합니다. 애플리케이션은 Amazon Cognito user pools를 사용하여 애플리케이션의 개별 사용자를 식별합니다. 솔루션스 아키텍트는 구독이 있는 사용자만 프리미엄 콘텐츠에 액세스하도록 애플리케이션을 업데이트해야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102128-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 레벨에서 구독 유무에 따라 사용자의 프리미엄 콘텐츠 접근을 제어해야 하는 시나리오입니다. 정답은 최소한의 아키텍처 변경과 운영 부담으로 특정 구독 사용자만 접근을 제한하는 방법을 구현하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "구독",
      "프리미엄 콘텐츠",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon Cognito user pools",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon Cognito user pools",
      "AWS WAF",
      "API usage plans",
      "API keys",
      "IAM permissions"
    ],
    "SelectA": "API Gateway API에서 API 캐싱과 제한(Throttling)을 활성화합니다.",
    "SelectA_Commentary": "캐싱과 Throttling은 성능 관리는 가능하지만 구독 기반 접근 제어 기능을 직접 제공하지 못하므로 요구사항을 만족하기 어렵습니다.",
    "SelectB": "API Gateway API에 AWS WAF를 구성하고, 구독이 있는 사용자를 필터링하는 규칙을 생성합니다.",
    "SelectB_Commentary": "AWS WAF를 통한 필터링은 가능하지만, 사용자 인증·인가 로직과 구독 정보를 직접 통합해야 해 복잡도가 높아집니다.",
    "SelectC": "DynamoDB 테이블의 프리미엄 콘텐츠에 대해 세부적인 IAM 권한을 적용합니다.",
    "SelectC_Commentary": "IAM 기반 세부 권한으로 조정이 가능하지만, 데이터별 접근 관리를 세밀히 구성해야 하므로 운영 오버헤드가 증가합니다.",
    "SelectD": "API usage plans와 API keys를 사용해 구독이 없는 사용자의 접근을 제한합니다.",
    "SelectD_Commentary": "API Gateway 레벨에서 손쉽게 구독 기반 접근 제어를 적용할 수 있는 방법으로, 최소한의 구조 변경으로 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q200",
      "Q428",
      "Q211",
      "Q159",
      "Q936"
    ],
    "SelectA_recommedations": [
      "Q571",
      "Q159",
      "Q34"
    ],
    "SelectB_recommedations": [
      "Q34",
      "Q1019",
      "Q159"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q279"
    ],
    "SelectD_recommedations": [
      "Q34",
      "Q571",
      "Q898"
    ]
  },
  {
    "Question_Number": "Q367",
    "Question_Description": "한 회사는 전 세계 사용자들을 위해 UDP 기반 애플리케이션 요청을 Amazon Route 53 지연 시간 기반 라우팅으로 처리하고 있습니다. 해당 애플리케이션은 미국, 아시아, 유럽의 온프레미스 데이터 센터에서冗여 서버로 호스팅되며, 컴플라이언스 요건상 반드시 온프레미스에 위치해야 합니다. 이 회사는 애플리케이션의 성능과 가용성을 개선하고자 합니다. 이러한 요구 사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102131-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "NLB는 UDP 트래픽을 지원하며 Global Accelerator와 함께 사용하면 전 세계적으로 단일 Anycast IP를 통해 최적의 엔드포인트로 라우팅 가능합니다. 이를 통해 유저 접근 지연을 최소화하고 가용성을 높일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "UDP 기반 애플리케이션",
      "온프레미스",
      "지연 시간 기반 라우팅",
      "성능 개선",
      "가용성 개선",
      "AWS Global Accelerator",
      "Network Load Balancer"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Route 53 Latency-Based Routing",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Amazon CloudFront",
      "UDP traffic",
      "Anycast IP addresses"
    ],
    "SelectA": "세 개의 AWS 리전에 각각 Network Load Balancer(NLB)를 구성하여 온프레미스 엔드포인트를 연결합니다. 이후 AWS Global Accelerator를 생성하고, NLB들을 엔드포인트로 등록합니다. 해당 Accelerator의 DNS에 매핑된 CNAME을 통해 애플리케이션에 접근합니다.",
    "SelectA_Commentary": "NLB는 UDP를 지원하고, Global Accelerator는 Anycast IP 기반의 글로벌 네트워크로 요청을 최적화하여 라우팅해 성능과 가용성을 모두 향상시킵니다.",
    "SelectB": "세 개의 AWS 리전에 각각 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 연결합니다. 이후 AWS Global Accelerator를 생성하고, ALB들을 엔드포인트로 등록합니다. 해당 Accelerator의 DNS에 매핑된 CNAME을 통해 애플리케이션에 접근합니다.",
    "SelectB_Commentary": "ALB는 UDP 트래픽을 직접 지원하지 않으므로, UDP 기반 애플리케이션에는 적합하지 않습니다.",
    "SelectC": "세 개의 AWS 리전에 각각 Network Load Balancer(NLB)를 구성하여 온프레미스 엔드포인트를 연결합니다. Route 53에서 지연 시간 기반 레코드를 생성하여 이 NLB들에게 트래픽을 라우팅하고, 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS에 매핑된 CNAME을 통해 애플리케이션에 접근합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS 프로토콜 가속을 위해 설계되었으므로, UDP 트래픽 가속에는 적합하지 않습니다.",
    "SelectD": "세 개의 AWS 리전에 각각 Application Load Balancer(ALB)를 구성하여 온프레미스 엔드포인트를 연결합니다. Route 53에서 지연 시간 기반 레코드를 생성하여 이 ALB들에게 트래픽을 라우팅하고, 이를 Amazon CloudFront 배포의 오리진으로 사용합니다. CloudFront DNS에 매핑된 CNAME을 통해 애플리케이션에 접근합니다.",
    "SelectD_Commentary": "ALB는 UDP 트래픽을 처리할 수 없어 문제에서 요구하는 UDP 애플리케이션 가속 요건을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q582",
      "Q530",
      "Q352",
      "Q704",
      "Q600"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q530",
      "Q358"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q12",
      "Q141"
    ],
    "SelectC_recommedations": [
      "Q530",
      "Q815",
      "Q582"
    ],
    "SelectD_recommedations": [
      "Q12",
      "Q358",
      "Q530"
    ]
  },
  {
    "Question_Number": "Q368",
    "Question_Description": "솔루션스 아키텍트는 모든 신규 사용자에게 IAM user 비밀번호에 대해 특정 복잡성 요구사항과 의무적인 rotation 기간을 갖도록 하고 싶어 합니다. 이를 달성하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102132-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "IAM user 비밀번호의 복잡성과 주기적 교체를 강제하려면 전체 AWS 계정 기반의 Password Policy를 설정해야 합니다. 이 정책은 모든 신규 사용자에게 동일하게 적용되어, 복잡성과 rotation 요구사항을 자동으로 만족시킵니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM user 비밀번호",
      "복잡성 요구사항",
      "rotation 기간",
      "AWS 계정 비밀번호 정책"
    ],
    "Terms": [
      "IAM user",
      "Password Policy",
      "비밀번호 복잡성",
      "Rotation",
      "Amazon CloudWatch"
    ],
    "SelectA": "전체 AWS 계정에 대한 Password Policy를 설정합니다.",
    "SelectA_Commentary": "정답입니다. 계정 수준 Password Policy는 신규 사용자가 생성될 때 자동으로 적용되어, 비밀번호 복잡성 및 rotation 규칙을 일관되게 시행합니다.",
    "SelectB": "AWS 계정의 각 IAM user별로 Password Policy를 설정합니다.",
    "SelectB_Commentary": "비효율적이고 관리가 복잡합니다. 각 사용자마다 따로 설정해야 하므로 운영 부담이 크게 증가합니다.",
    "SelectC": "타사 소프트웨어를 사용하여 비밀번호 요구사항을 설정합니다.",
    "SelectC_Commentary": "AWS IAM의 기본 기능을 대신해 별도 소프트웨어를 사용하는 것은 복잡성과 비용을 높일 뿐, 권장되지 않는 방법입니다.",
    "SelectD": "Create_newuser 이벤트에 Amazon CloudWatch 규칙을 연결하여 적절한 요구사항으로 비밀번호를 설정합니다.",
    "SelectD_Commentary": "이벤트 기반으로 매번 별도 로직을 구성해야 하므로 일관성과 효율이 떨어지며 구현이 복잡합니다.",
    "Question_Description_recommedations": [
      "Q429",
      "Q476",
      "Q222",
      "Q395",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q893",
      "Q780"
    ],
    "SelectB_recommedations": [
      "Q780",
      "Q233",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q233",
      "Q748"
    ]
  },
  {
    "Question_Number": "Q369",
    "Question_Description": "한 회사가 Amazon EC2 Linux 인스턴스로 애플리케이션을 마이그레이션했습니다. 이 중 하나의 EC2 인스턴스에서 여러 개의 1시간짜리 작업이 스케줄에 따라 실행됩니다. 이 작업들은 서로 다른 팀에 의해 작성되었고, 공통 프로그래밍 언어가 없습니다. 회사는 이러한 작업이 단일 인스턴스에서 실행될 때의 성능과 확장성에 대해 우려하고 있습니다. 솔루션스 아키텍트는 이 문제를 해결하기 위한 해결책을 구현해야 합니다. 가장 적은 운영 오버헤드로 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102133-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 언어로 작성된 1시간 분량의 작업들을 확장 가능하며 간단하게 운영하려는 시나리오입니다. AWS Batch는 다양한 언어와 런타임을 지원하고, 작업 스케줄링을 EventBridge로 자동화할 수 있으므로 운영 부담을 크게 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "1시간 작업",
      "서로 다른 언어",
      "성능과 확장성",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "AWS Batch",
      "Amazon EventBridge (Amazon CloudWatch Events)",
      "AWS App Runner",
      "AWS Lambda",
      "Amazon EC2",
      "Amazon Machine Image (AMI)",
      "Auto Scaling group"
    ],
    "SelectA": "AWS Batch를 사용하여 작업들을 job으로 실행하고, Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 스케줄링합니다.",
    "SelectA_Commentary": "AWS Batch는 장시간 배치 처리와 다양한 언어 지원이 가능하며, EventBridge로 정기적으로 작업을 트리거할 수 있어 최소 운영 오버헤드로 문제를 해결합니다.",
    "SelectB": "EC2 인스턴스를 컨테이너로 변환한 후, AWS App Runner로 필요 시 컨테이너를 생성하여 작업들을 job으로 실행합니다.",
    "SelectB_Commentary": "App Runner는 컨테이너 기반 애플리케이션에 용이하지만, 기존 다양한 언어의 작업을 하나로 통합하는 과정과 컨테이너 제작이 추가적인 운영 부담을 초래할 수 있습니다.",
    "SelectC": "작업들을 AWS Lambda 함수로 복사하고, Amazon EventBridge(Amazon CloudWatch Events)를 사용하여 스케줄링합니다.",
    "SelectC_Commentary": "Lambda는 최대 실행 시간이 15분으로 제한되어 1시간짜리 작업에는 적합하지 않아 성능 요구사항을 충족하기 어렵습니다.",
    "SelectD": "작업을 실행하는 EC2 인스턴스의 Amazon Machine Image(AMI)를 생성합니다. 해당 AMI로 Auto Scaling group을 생성하여 여러 인스턴스를 실행합니다.",
    "SelectD_Commentary": "Auto Scaling으로 확장성과 가용성은 확보되나, 인스턴스 생성·관리와 리소스 비용이 커지고, 작업 간 관리 자동화도 상대적으로 복잡합니다.",
    "Question_Description_recommedations": [
      "Q632",
      "Q746",
      "Q229",
      "Q596",
      "Q857"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q117",
      "Q305"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q857",
      "Q910"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q515",
      "Q576"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q461",
      "Q219"
    ]
  },
  {
    "Question_Number": "Q370",
    "Question_Description": "한 회사가 VPC에서 퍼블릭 3티어 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 여러 Availability Zones에 걸쳐 Amazon EC2 인스턴스에서 동작합니다. 프라이빗 서브넷에서 동작하는 EC2 인스턴스들은 인터넷을 통해 라이선스 서버와 통신해야 합니다. 회사는 운영 유지 관리를 최소화할 수 있는 매니지드 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102134-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프라이빗 서브넷에 있는 EC2 인스턴스가 인터넷의 라이선스 서버와 통신해야 할 때, 운영 부담을 최소화하는 해결책을 찾는 상황입니다. NAT instance는 직접 관리와 유지보수가 필요하지만, NAT gateway는 매니지드 서비스로 패치나 확장 등 운영 관리가 훨씬 간소화됩니다. 따라서 퍼블릭 서브넷에 NAT gateway를 구성하면 최소한의 운영 유지 관리로 안전하게 인터넷에 액세스할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "퍼블릭 3티어 웹 애플리케이션",
      "프라이빗 서브넷",
      "라이선스 서버",
      "인터넷 통신",
      "운영 유지 관리 최소화",
      "NAT Gateway",
      "NAT Instance"
    ],
    "Terms": [
      "VPC",
      "Amazon EC2",
      "Availability Zones",
      "private subnet",
      "public subnet",
      "NAT instance",
      "NAT gateway",
      "route table"
    ],
    "SelectA": "퍼블릭 서브넷에 NAT instance를 프로비저닝합니다. 각 프라이빗 서브넷의 route table에 NAT instance로의 기본 라우트를 설정합니다.",
    "SelectA_Commentary": "NAT instance는 직접 확장, 패치 등을 관리해야 하므로 운영 비용이 큽니다. 매니지드 솔루션 요건을 충족하지 못합니다.",
    "SelectB": "프라이빗 서브넷에 NAT instance를 프로비저닝합니다. 각 프라이빗 서브넷의 route table에 NAT instance로의 기본 라우트를 설정합니다.",
    "SelectB_Commentary": "NAT instance가 인터넷과 통신하려면 퍼블릭 서브넷에 있어야 하므로 올바른 설정이 아닙니다. 또한 직접 관리가 필요합니다.",
    "SelectC": "퍼블릭 서브넷에 NAT gateway를 프로비저닝합니다. 각 프라이빗 서브넷의 route table에 NAT gateway로의 기본 라우트를 설정합니다.",
    "SelectC_Commentary": "NAT gateway는 매니지드 서비스로 운영 유지 관리가 매우 적고, 퍼블릭 서브넷에서 프라이빗 서브넷의 인터넷 액세스를 안전하게 제공합니다. 정답입니다.",
    "SelectD": "프라이빗 서브넷에 NAT gateway를 프로비저닝합니다. 각 프라이빗 서브넷의 route table에 NAT gateway로의 기본 라우트를 설정합니다.",
    "SelectD_Commentary": "NAT gateway가 인터넷에 접속하려면 인터넷 게이트웨이가 연결된 퍼블릭 서브넷에 위치해야 합니다. 프라이빗 서브넷에 두는 것은 불가능합니다.",
    "Question_Description_recommedations": [
      "Q866",
      "Q92",
      "Q610",
      "Q980",
      "Q327"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q625",
      "Q468"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q625",
      "Q468"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q625",
      "Q803"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q625",
      "Q803"
    ]
  },
  {
    "Question_Number": "Q371",
    "Question_Description": "한 기업이 디지털 미디어 스트리밍 애플리케이션을 호스팅하기 위해 Amazon EKS 클러스터를 생성해야 합니다. 이 EKS 클러스터는 Amazon EBS 볼륨 기반의 관리형 노드 그룹을 사용합니다. 회사는 모든 정적 데이터를 AWS KMS에 저장된 고객 관리형 키(customer managed key)를 사용하여 암호화해야 합니다. 다음 중 어떤 조합을 통해 가장 적은 운영 오버헤드로 이 요구사항을 충족할 수 있습니까? (2개를 선택하십시오)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102135-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EKS 클러스터의 EBS 볼륨 암호화를 고객 관리형 키(KMS)로 구성해 운영 오버헤드를 최소화하는 방법을 묻습니다. EBS 기본 암호화를 활성화하고 IAM 권한을 부여하면 모든 새 볼륨이 자동으로 암호화됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon EKS",
      "Amazon EBS",
      "AWS KMS",
      "고객 관리형 키",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EKS",
      "AWS KMS",
      "Amazon EBS",
      "Encryption at rest",
      "Customer managed key",
      "IAM role",
      "Kubernetes secret",
      "Kubernetes plugin",
      "EBS encryption by default",
      "EKS managed node group"
    ],
    "SelectA": "쿠버네티스 플러그인을 사용하여 고객 관리형 키로 데이터 암호화를 수행합니다.",
    "SelectA_Commentary": "별도의 플러그인 관리 및 설정이 필요하므로 운영 오버헤드가 증가하며, EBS 기본 암호화를 활용하지 못합니다.",
    "SelectB": "EKS 클러스터를 생성한 후 EBS 볼륨을 찾아 고객 관리형 키를 사용해 암호화를 활성화합니다.",
    "SelectB_Commentary": "이미 생성된 볼륨을 직접 찾고 암호화해야 하므로 추가 작업이 늘어 오버헤드가 큽니다.",
    "SelectC": "EKS 클러스터가 생성될 AWS 리전에 대해 EBS 기본 암호화를 활성화하고, 고객 관리형 키를 기본 키로 지정합니다.",
    "SelectC_Commentary": "새로 생성되는 모든 EBS 볼륨을 자동으로 암호화해 운영 부담을 크게 줄일 수 있습니다.",
    "SelectD": "EKS 클러스터를 생성합니다. 고객 관리형 키에 대한 권한이 있는 IAM 역할을 만들고 EKS 클러스터에 연결합니다.",
    "SelectD_Commentary": "클러스터가 KMS 키를 사용하려면 적절한 IAM 권한 구성이 필수입니다.",
    "SelectE": "고객 관리형 키를 EKS 클러스터의 Kubernetes secret으로 저장하고, EBS 볼륨을 암호화합니다.",
    "SelectE_Commentary": "비밀 정보 노출 위험과 추가 설정이 필요해 운영 복잡도가 높아 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q681",
      "Q916",
      "Q805",
      "Q535",
      "Q793"
    ],
    "SelectA_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q689",
      "Q805",
      "Q371"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q665",
      "Q122"
    ],
    "SelectE_recommedations": [
      "Q535",
      "Q613",
      "Q371"
    ]
  },
  {
    "Question_Number": "Q372",
    "Question_Description": "회사는 Oracle 데이터베이스를 AWS로 마이그레이션하려고 합니다. 이 데이터베이스에는 단일 테이블에 수백만 건의 고해상도 GIS(geographic information systems) 이미지가 있으며, 각 이미지는 지리 코드를 통해 식별됩니다. 자연재해가 발생하면 수만 건의 이미지가 몇 분 간격으로 업데이트됩니다. 각 지리 코드에는 연결된 단일 이미지(또는 행)가 존재합니다. 회사는 이러한 긴급 상황에서 고가용성과 확장성을 갖추면서도 가능한 한 비용 효율적인 솔루션을 원합니다. 어떤 솔루션이 이 요구사항을 MOST cost-effectively 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102136-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 GIS 이미지를 빠르게 업데이트해야 할 때, 고가용성과 확장성을 갖추면서 비용을 절감할 수 있는 스토리지와 DB 구조를 선택하는 것입니다. Oracle 대신 Amazon S3와 Amazon DynamoDB 조합이 더욱 경제적이고 확장성도 우수합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.3"
    ],
    "Keywords": [
      "Oracle 데이터베이스",
      "GIS 이미지",
      "고해상도",
      "지리 코드",
      "Amazon S3",
      "Amazon DynamoDB",
      "비용 효율성",
      "확장성"
    ],
    "Terms": [
      "Oracle",
      "Amazon RDS Multi-AZ DB instance",
      "Amazon S3",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)"
    ],
    "SelectA": "이미지와 지리 코드를 데이터베이스 테이블에 저장하고 Amazon RDS Multi-AZ DB instance에서 Oracle을 운영합니다.",
    "SelectA_Commentary": "Oracle DB에 직접 대용량 이미지를 저장하면 비용과 확장이 부담되며, 업데이트 빈도가 높을 때 비효율적입니다.",
    "SelectB": "이미지를 Amazon S3 버킷에 저장하고, 지리 코드를 키로, 이미지 S3 URL을 값으로 하는 Amazon DynamoDB를 사용합니다.",
    "SelectB_Commentary": "S3로 이미지 저장 비용을 최소화하고, DynamoDB로 메타데이터를 관리해 확장성과 고가용성을 제공하는 최적의 솔루션입니다.",
    "SelectC": "이미지와 지리 코드를 Amazon DynamoDB 테이블에 모두 저장하고, 고부하 시 DynamDB Accelerator(DAX)를 구성합니다.",
    "SelectC_Commentary": "이미지를 DynamoDB에 직접 저장하면 스토리지 비용이 커지고, 높은 트래픽 시 비용 효율성이 떨어집니다.",
    "SelectD": "이미지를 Amazon S3 버킷에 저장하고, 지리 코드와 이미지 S3 URL을 데이터베이스 테이블에 저장한 뒤, Amazon RDS Multi-AZ DB instance에서 Oracle을 운영합니다.",
    "SelectD_Commentary": "DB 인스턴스 유지 비용이 추가로 발생하며, Oracle 환경 유지로 운영 부담이 커서 가장 비용 효율적인 방법은 아닙니다.",
    "Question_Description_recommedations": [
      "Q449",
      "Q485",
      "Q985",
      "Q486",
      "Q728"
    ],
    "SelectA_recommedations": [
      "Q449",
      "Q152",
      "Q574"
    ],
    "SelectB_recommedations": [
      "Q799",
      "Q469",
      "Q829"
    ],
    "SelectC_recommedations": [
      "Q670",
      "Q79",
      "Q348"
    ],
    "SelectD_recommedations": [
      "Q993",
      "Q799",
      "Q469"
    ]
  },
  {
    "Question_Number": "Q373",
    "Question_Description": "한 회사에는 자동차의 IoT 센서로부터 데이터를 수집하는 애플리케이션이 있습니다. 이 데이터는 Amazon Kinesis Data Firehose를 통해 스트리밍되어 Amazon S3에 저장됩니다. 매년 수조(Trillions) 개의 S3 객체가 생성됩니다. 회사는 매일 아침 이전 30일간의 데이터를 사용해 머신 러닝(ML) 모델 그룹을 재학습합니다. 또한 매년 4번, 이전 12개월의 데이터를 사용해 추가 분석 및 다른 ML 모델들을 학습합니다. 최대 1년 동안은 데이터에 지연 없이 접근할 수 있어야 하며, 1년이 지난 후에는 데이터를 기록 보관 목적으로 보관해야 합니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102137-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 일정 기간 동안 자주 사용(30일, 12개월)되는 데이터를 저비용으로 보관하면서도 즉시 접근이 가능해야 하는 스토리지 전략 설계입니다. 30일 이후에는 적은 빈도로 접근하므로 S3 Standard-Infrequent Access로 전환하여 비용을 줄일 수 있고, 1년 이후에는 장기 보관용인 S3 Glacier Deep Archive로 옮겨 추가 비용을 최소화합니다. Intelligent-Tiering은 접근 패턴이 예측 불가능할 때 유용하지만, 본 문제처럼 사용 주기가 명확하면 수동 Lifecycle 전환이 더 경제적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "자동차 IoT 센서",
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "머신 러닝(ML) 모델",
      "1년 보관",
      "비용 효율",
      "S3 Standard",
      "S3 Standard-Infrequent Access",
      "S3 Glacier Deep Archive",
      "Lifecycle 정책"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "Machine Learning (ML)",
      "S3 Intelligent-Tiering",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Glacier Deep Archive",
      "S3 Lifecycle"
    ],
    "SelectA": "S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후 객체를 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle 정책을 생성합니다.",
    "SelectA_Commentary": "Intelligent-Tiering은 접근 패턴이 예측 불가능할 때 자동으로 계층을 변경하는 것이 장점입니다. 하지만 본 시나리오에서는 30일, 1년 주기가 명확해 추가 비용이 더 들 수 있습니다.",
    "SelectB": "S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 1년 후 자동으로 S3 Glacier Deep Archive로 이동하도록 설정합니다.",
    "SelectB_Commentary": "Intelligent-Tiering 자체 정책으로 1년 후 Deep Archive로 이동이 가능하지만, 접근 주기가 뚜렷하여 불필요한 모니터링 비용이 발생할 수 있어 최적의 선택은 아닙니다.",
    "SelectC": "S3 Standard-Infrequent Access (S3 Standard-IA) 스토리지 클래스를 사용합니다. 1년 후 객체를 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle 정책을 만듭니다.",
    "SelectC_Commentary": "30일 내 자주 접근이 필요한 데이터에 대해 바로 S3 Standard-IA를 사용하면, 단기 접근 빈도 대비 조회 비용이 더 들 수 있고, 30일 이전 활용이 비효율적일 수 있습니다.",
    "SelectD": "S3 Standard 스토리지 클래스를 사용합니다. 30일 후 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환하고, 1년 후 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle 정책을 만듭니다.",
    "SelectD_Commentary": "가장 합리적인 접근 주기별 전략입니다. 30일 동안은 자주 학습이 이뤄지므로 S3 Standard가 적합하고, 이후에는 S3 Standard-IA와 S3 Glacier Deep Archive로 단계적 전환해 비용을 절감합니다.",
    "Question_Description_recommedations": [
      "Q463",
      "Q430",
      "Q285",
      "Q606",
      "Q769"
    ],
    "SelectA_recommedations": [
      "Q912",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q486",
      "Q943",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q912",
      "Q356",
      "Q415"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q374",
    "Question_Description": "회사는 us-east-1 리전 내 세 개의 별도 VPC에서 여러 비즈니스 애플리케이션을 운영 중입니다. 애플리케이션들은 반드시 서로 다른 VPC 간에도 통신할 수 있어야 합니다. 또한 매일 수백 기가바이트의 데이터를 온프레미스 데이터 센터에서 동작하는 레이턴시에 민감한 애플리케이션으로 안정적으로 전송해야 합니다. 솔루션스 아키텍트는 비용 효율성을 극대화하는 네트워크 연결 솔루션을 설계해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102138-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 세 개 VPC 간 통신과 동시에 고용량 데이터를 온프레미스 데이터 센터로 안정적으로 전송해야 하며, 비용 효율성을 극대화해야 하는 상황입니다. AWS Direct Connect를 한 회선만 사용하고 Transit Gateway를 통해 각 VPC를 연결하면 매일 대량 데이터를 전송하는 데 필요한 안정적이고 저지연인 통신 환경을 구현하면서도, VPN이나 다중 Direct Connect를 구성하는 것보다 훨씬 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "비용 효율성",
      "VPC 간 통신",
      "온프레미스 데이터 센터",
      "수백 기가바이트 전송",
      "레이턴시 민감"
    ],
    "Terms": [
      "AWS Site-to-Site VPN",
      "IPsec VPN",
      "AWS Direct Connect",
      "Direct Connect gateway",
      "Transit Gateway",
      "VPC"
    ],
    "SelectA": "온프레미스 데이터 센터에서 AWS로 세 개의 AWS Site-to-Site VPN을 구성하고, 각 VPC별로 하나씩 VPN 연결을 설정합니다.",
    "SelectA_Commentary": "VPN만으로 수백 기가바이트 데이터 전송과 레이턴시 요구사항을 안정적으로 충족하기 어렵고, VPC마다 개별 연결을 구성해야 해서 운용이 복잡해집니다.",
    "SelectB": "각 VPC에 서드파티 가상 네트워크 어플라이언스를 띄우고, 온프레미스 데이터 센터와 각 가상 어플라이언스 간 IPsec VPN 터널을 구성합니다.",
    "SelectB_Commentary": "VPC마다 가상 어플라이언스를 구성해야 하므로 관리 및 비용 부담이 커지고, 대규모 트래픽에 대한 성능 보장도 제한적입니다.",
    "SelectC": "온프레미스 데이터 센터에서 us-east-1에 있는 Direct Connect gateway로 향하는 세 개의 AWS Direct Connect를 구성하고, 각 VPC가 해당 Direct Connect 중 하나를 사용하도록 설정합니다.",
    "SelectC_Commentary": "VPC별로 각각 Direct Connect를 배정하면 전용 회선이 3개나 필요해 초기 비용과 운영 비용이 높아집니다.",
    "SelectD": "온프레미스 데이터 센터에서 AWS로 하나의 AWS Direct Connect를 구성합니다. Transit Gateway를 생성하고, 각 VPC를 Transit Gateway에 연결합니다. 그리고 해당 Transit Gateway와 Direct Connect 간 연결을 설정합니다.",
    "SelectD_Commentary": "Transit Gateway 한 곳으로 연결해 모든 VPC가 공유하므로 비용이 절감되고, 대규모 트래픽 처리와 저지연 전송에 유리하여 요구사항을 모두 만족합니다.",
    "Question_Description_recommedations": [
      "Q713",
      "Q728",
      "Q985",
      "Q284",
      "Q525"
    ],
    "SelectA_recommedations": [
      "Q860",
      "Q471",
      "Q497"
    ],
    "SelectB_recommedations": [
      "Q860",
      "Q471",
      "Q374"
    ],
    "SelectC_recommedations": [
      "Q499",
      "Q835",
      "Q240"
    ],
    "SelectD_recommedations": [
      "Q240",
      "Q835",
      "Q499"
    ]
  },
  {
    "Question_Number": "Q375",
    "Question_Description": "한 이커머스 회사가 주문 처리 작업을 완료하기 위해 여러 serverless 함수와 AWS 서비스를 포함하는 분산 애플리케이션을 구축하고 있습니다. 이 작업에는 워크플로의 일부로 수동 승인이 필요합니다. 한 solutions architect가 주문 처리 애플리케이션을 위한 아키텍처를 설계해야 합니다. 이 솔루션은 여러 AWS Lambda 함수를 조합하여 반응형 serverless 애플리케이션을 구성할 수 있어야 하며, 또한 Amazon EC2 인스턴스, 컨테이너, 온프레미스 서버에서 실행되는 데이터와 서비스를 오케스트레이션할 수 있어야 합니다. 운영 오버헤드를 가장 적게 두고 이를 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102139-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 serverless 함수와 다양한 서비스(EC2, 컨테이너 등)를 하나의 워크플로로 간편하게 결합해야 하는 주문 처리 애플리케이션의 아키텍처를 묻습니다. 수동 승인 과정을 포함해야 하며 운영 오버헤드를 최소화하는 것이 중요합니다. AWS Step Functions는 시각적 워크플로를 통해 Lambda 함수와 기타 컴퓨팅 리소스를 간단히 오케스트레이션하고, 수동 승인 단계를 구현하기에도 용이합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이커머스",
      "주문 처리",
      "serverless 함수",
      "수동 승인",
      "AWS Lambda",
      "오케스트레이션",
      "운영 오버헤드 최소화",
      "AWS Step Functions"
    ],
    "Terms": [
      "AWS Step Functions",
      "AWS Glue",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon EC2",
      "containers",
      "on-premises servers",
      "manual approvals"
    ],
    "SelectA": "AWS Step Functions를 사용하여 애플리케이션을 빌드합니다.",
    "SelectA_Commentary": "AWS Step Functions는 분산 애플리케이션 구성 요소를 시각적으로 오케스트레이션하여 서버리스 애플리케이션을 쉽게 구축할 수 있고, 수동 승인 같은 복잡한 워크플로도 간단하게 관리할 수 있습니다.",
    "SelectB": "모든 애플리케이션 구성 요소를 AWS Glue job으로 통합합니다.",
    "SelectB_Commentary": "AWS Glue는 ETL 작업에 최적화된 서비스로, 수동 승인이나 다양한 컴퓨팅 리소스를 함께 오케스트레이션하는 데는 적합하지 않습니다.",
    "SelectC": "Amazon Simple Queue Service (Amazon SQS)를 사용하여 애플리케이션을 빌드합니다.",
    "SelectC_Commentary": "Amazon SQS는 메시지 큐 서비스로, 워크플로 제어 및 상태 관리를 위한 별도 로직이 필요하고 수동 승인 관리에도 추가 구현이 필요하여 운영 오버헤드가 증가합니다.",
    "SelectD": "AWS Lambda 함수와 Amazon EventBridge 이벤트를 사용하여 애플리케이션을 빌드합니다.",
    "SelectD_Commentary": "EventBridge는 이벤트 중심 구조를 지원하지만, 여러 스텝으로 이루어진 워크플로와 수동 승인 과정을 체계적으로 오케스트레이션하기에는 관리가 복잡해질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q263",
      "Q288",
      "Q404",
      "Q181",
      "Q138"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q149",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q203",
      "Q67",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q569",
      "Q785",
      "Q351"
    ]
  },
  {
    "Question_Number": "Q376",
    "Question_Description": "한 회사에서 Amazon RDS for MySQL DB 인스턴스를 만들었습니다. 대부분의 연결은 서버리스 애플리케이션에서 발생합니다. 애플리케이션 트래픽이 무작위 시점에 크게 변동되며, 수요가 높아질 때 사용자들은 데이터베이스 연결 거부 오류가 발생한다고 보고합니다. 운영 오버헤드를 최소화하면서 이 문제를 해결할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102140-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 불규칙적인 트래픽 급증으로 인한 연결 거부 오류를 최소 운영 부담으로 해결하는 방식에 대한 것입니다. RDS Proxy를 도입하면 연결 풀링과 자동 스케일링을 통해 DB 부하를 효율적으로 관리합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "서버리스 애플리케이션",
      "데이터베이스 연결 거부 오류",
      "RDS Proxy"
    ],
    "Terms": [
      "RDS Proxy",
      "Amazon ElastiCache for Memcached",
      "Multi-AZ",
      "DB instance class"
    ],
    "SelectA": "RDS Proxy에서 프록시를 생성합니다. 사용자의 애플리케이션을 RDS Proxy를 통해 DB 인스턴스에 연결하도록 구성합니다.",
    "SelectA_Commentary": "RDS Proxy는 연결 풀링을 제공해 DB 연결 수를 효율적으로 관리하므로 가장 적은 운영 오버헤드로 연결 거부 문제를 완화할 수 있는 솔루션입니다.",
    "SelectB": "Amazon ElastiCache for Memcached를 사용자 애플리케이션과 DB 인스턴스 사이에 배포합니다.",
    "SelectB_Commentary": "ElastiCache는 캐싱 솔루션으로 읽기 부하를 줄일 순 있지만, DB 연결 자체를 제어하지 않으므로 연결 거부 오류 해결엔 직접적 도움이 되지 않습니다.",
    "SelectC": "DB 인스턴스를 더 높은 I/O 용량의 인스턴스 클래스로 마이그레이션합니다. 사용자의 애플리케이션에서 새 DB 인스턴스를 사용하도록 구성합니다.",
    "SelectC_Commentary": "더 큰 인스턴스로 전환할 수 있지만, 트래픽 변동이 심하면 여전히 너무 많은 연결이 몰릴 때 문제 발생 가능성이 남아있고, 운영 비용도 상승합니다.",
    "SelectD": "DB 인스턴스에 Multi-AZ를 구성하고, 사용자 애플리케이션에서 DB 인스턴스를 스위칭하도록 구성합니다.",
    "SelectD_Commentary": "Multi-AZ는 장애 복구에 유리하지만, 과도한 연결 요청 자체를 줄이는 해결책은 아니므로 연결 거부를 근본적으로 해소하긴 어렵습니다.",
    "Question_Description_recommedations": [
      "Q590",
      "Q269",
      "Q95",
      "Q661",
      "Q726"
    ],
    "SelectA_recommedations": [
      "Q590",
      "Q95",
      "Q269"
    ],
    "SelectB_recommedations": [
      "Q229",
      "Q472",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q225",
      "Q578",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q225",
      "Q578",
      "Q472"
    ]
  },
  {
    "Question_Number": "Q377",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에 대한 운영 체제 버전, 패치 현황, 설치된 소프트웨어를 중앙화하여 관리하기 위해 새로운 auditing system을 배포했습니다. Solutions Architect는 EC2 Auto Scaling 그룹을 통해 프로비저닝되는 모든 인스턴스가 시작되자마자, 그리고 종료될 때 auditing system에 보고서를 성공적으로 전송하도록 보장해야 합니다. 이러한 요구사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102142-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 Auto Scaling 그룹에서 인스턴스가 시작·종료되는 즉시 auditing system에 데이터를 전송하도록 보장하는 방법을 묻습니다. 가장 자동화되고 확실한 메커니즘이 필요합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "EC2 Auto Scaling",
      "auditing system",
      "인스턴스 시작",
      "인스턴스 종료",
      "보고서 전송"
    ],
    "Terms": [
      "Amazon EC2",
      "EC2 Auto Scaling lifecycle hooks",
      "AWS Lambda",
      "EC2 Auto Scaling launch configuration",
      "user data",
      "auditing system"
    ],
    "SelectA": "AWS Lambda 함수를 일정 주기로 실행하여 모든 EC2 인스턴스에서 스크립트를 원격으로 실행해 audit system에 데이터를 전송합니다.",
    "SelectA_Commentary": "Lambda를 일정 간격으로 실행하면 모든 이벤트를 즉시 포착하기 어렵고, 주기 사이에 종료된 인스턴스 데이터가 누락될 수 있어 효율적이지 않습니다.",
    "SelectB": "EC2 Auto Scaling lifecycle hooks를 사용하여 인스턴스가 시작되고 종료될 때 audit system에 데이터를 전송하는 사용자 정의 스크립트를 실행합니다.",
    "SelectB_Commentary": "정답입니다. lifecycle hook이 인스턴스 종료 전까지 실행을 지연해주어 데이터 전송 누락을 방지하고, 시작 시점에도 자동으로 트리거되어 효율적입니다.",
    "SelectC": "EC2 Auto Scaling launch configuration에서 user data를 통해 인스턴스가 시작되고 종료될 때 audit system에 데이터를 전송하는 사용자 정의 스크립트를 실행합니다.",
    "SelectC_Commentary": "user data는 인스턴스 시작 시점만 처리되므로 종료 시점 보고 처리가 보장되지 않아 모든 이벤트를 완벽히 커버하기 어렵습니다.",
    "SelectD": "인스턴스 운영 체제 상에서 custom script를 실행해 audit system에 데이터를 전송합니다. 이 스크립트가 인스턴스 시작 및 종료 시 EC2 Auto Scaling 그룹에 의해 호출되도록 구성합니다.",
    "SelectD_Commentary": "인스턴스 내부 설정으로만 처리하면 종료 시점 제어가 쉽지 않고, lifecycle hook이 제공하는 지연 메커니즘이 없어 데이터 누락 가능성이 높습니다.",
    "Question_Description_recommedations": [
      "Q294",
      "Q11",
      "Q26",
      "Q549",
      "Q82"
    ],
    "SelectA_recommedations": [
      "Q936",
      "Q289",
      "Q791"
    ],
    "SelectB_recommedations": [
      "Q377",
      "Q426",
      "Q614"
    ],
    "SelectC_recommedations": [
      "Q377",
      "Q426",
      "Q614"
    ],
    "SelectD_recommedations": [
      "Q377",
      "Q426",
      "Q614"
    ]
  },
  {
    "Question_Number": "Q378",
    "Question_Description": "한 회사에서는 UDP를 사용해 클라이언트와 Auto Scaling group 내 서버 간 통신을 처리하는 실시간 멀티플레이어 게임을 개발 중입니다. 낮 시간대에 수요 급증이 예상되어, 게임 서버 플랫폼은 이를 대비해 확장할 수 있어야 합니다. 또한 개발자들은 게이머 점수 및 기타 비관계형 데이터를 저장하기 위해 별도의 개입 없이 자동으로 확장 가능한 데이터베이스 솔루션을 원합니다. 솔루션스 아키텍트는 어떤 솔루션을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102143-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 UDP 트래픽을 지원하고 비관계형 데이터를 자동으로 확장하여 저장할 수 있는 아키텍처를 설계하는 것이 핵심입니다. 빠른 스케일링과 고가용성을 동시에 만족해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "실시간 멀티플레이어 게임",
      "UDP",
      "Auto Scaling group",
      "비관계형 데이터",
      "데이터베이스 솔루션",
      "수요 급증",
      "Network Load Balancer",
      "DynamoDB on-demand"
    ],
    "Terms": [
      "UDP",
      "Network Load Balancer",
      "Auto Scaling group",
      "Amazon DynamoDB",
      "Amazon Aurora Serverless",
      "Aurora Global Database",
      "Application Load Balancer",
      "Amazon Route 53",
      "On-demand",
      "Global tables"
    ],
    "SelectA": "트래픽 분산을 위해 Amazon Route 53을 사용하고, 데이터 저장을 위해 Amazon Aurora Serverless를 사용합니다.",
    "SelectA_Commentary": "Route 53은 DNS 서비스로 UDP 트래픽의 직접적 로드 밸런싱에 부적합하고, Aurora Serverless는 관계형 DB로 비관계형 구조를 원하는 요구사항과 맞지 않습니다.",
    "SelectB": "트래픽 분산을 위해 Network Load Balancer를 사용하고, 데이터 저장을 위해 Amazon DynamoDB on-demand를 사용합니다.",
    "SelectB_Commentary": "UDP 트래픽은 Network Load Balancer로 처리 가능하며, DynamoDB on-demand는 비관계형 데이터를 자동으로 확장할 수 있어 요구사항에 최적입니다.",
    "SelectC": "트래픽 분산을 위해 Network Load Balancer를 사용하고, 데이터 저장을 위해 Amazon Aurora Global Database를 사용합니다.",
    "SelectC_Commentary": "UDP 트래픽은 NLB로 처리 가능하지만, Aurora Global Database는 관계형 DB로 비관계형 데이터를 자동 확장한다는 요구사항에 적합하지 않습니다.",
    "SelectD": "트래픽 분산을 위해 Application Load Balancer를 사용하고, 데이터 저장을 위해 Amazon DynamoDB global tables를 사용합니다.",
    "SelectD_Commentary": "Application Load Balancer는 UDP를 지원하지 않아 게임 서버 간 트래픽 처리에 부적합하며, global tables는 다중 리전 동기화에 초점이 있어 과도한 기능입니다.",
    "Question_Description_recommedations": [
      "Q595",
      "Q642",
      "Q408",
      "Q1001",
      "Q271"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q194",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q768",
      "Q1002"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q69",
      "Q955"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q405",
      "Q1012"
    ]
  },
  {
    "Question_Number": "Q379",
    "Question_Description": "한 회사가 Amazon API Gateway API 백엔드를 사용하여 AWS Lambda와 연동한 프론트엔드 애플리케이션을 호스팅하고 있습니다. API가 요청을 받을 때 Lambda 함수는 여러 라이브러리를 로드합니다. 이후 Lambda 함수는 Amazon RDS 데이터베이스에 연결하여 데이터를 처리하고, 그 결과를 프론트엔드 애플리케이션에 반환합니다. 회사는 모든 사용자에 대해 응답 지연 시간을 가능한 한 낮게 유지하고 싶으며, 회사 운영에 변경이 가장 적은 방법을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102144-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda 함수가 요청 시 매번 여러 라이브러리를 로드하며 발생하는 콜드 스타트를 줄여 전체 응답 시간을 낮추고자 하는 상황입니다. 회사 운영 변경을 최소화하면서도 모든 사용자의 지연 시간을 단축하려면 Lambda에 Provisioned Concurrency를 설정하여 자주 호출될 가능성이 높은 인스턴스를 미리 준비해 두는 것이 가장 효과적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "응답 지연 시간",
      "Provisioned Concurrency",
      "AWS Lambda 콜드 스타트",
      "Amazon RDS",
      "Amazon API Gateway"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon RDS",
      "Provisioned Concurrency"
    ],
    "SelectA": "프론트엔드 애플리케이션이 데이터베이스와 직접 연결해 API를 우회하여 더 빠르게 쿼리를 처리합니다.",
    "SelectA_Commentary": "API Gateway를 우회하면 기존 API 아키텍처를 변경해야 하며 보안·운영상의 복잡도가 커집니다. 요구사항인 최소 운영 변경에도 부합하지 않습니다.",
    "SelectB": "요청을 처리하는 Lambda 함수에 Provisioned Concurrency를 구성합니다.",
    "SelectB_Commentary": "미리 실행 상태의 Lambda 인스턴스를 확보해 콜드 스타트를 제거하여 지연 시간을 크게 낮춥니다. 운영상의 변경도 적어 요구사항에 가장 부합합니다.",
    "SelectC": "쿼리 결과를 Amazon S3에 캐싱하여 유사한 데이터세트를 더 빠르게 조회합니다.",
    "SelectC_Commentary": "Cache 기법은 재사용되는 쿼리에는 효과적이지만, 전체적으로 Lambda 콜드 스타트나 라이브러리 로드 문제를 근본적으로 해결하지 못합니다.",
    "SelectD": "Lambda가 한 번에 더 많은 연결을 맺을 수 있도록 데이터베이스 크기를 늘립니다.",
    "SelectD_Commentary": "데이터베이스 확장은 동시 연결 처리에만 도움이 되며, 라이브러리 로드로 인한 Lambda 콜드 스타트 문제 해결에는 직접적인 효과가 없습니다.",
    "Question_Description_recommedations": [
      "Q576",
      "Q597",
      "Q175",
      "Q685",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q516",
      "Q107"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q704",
      "Q746"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q626",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ]
  },
  {
    "Question_Number": "Q380",
    "Question_Description": "어떤 회사가 온프레미스 워크로드를 AWS Cloud로 마이그레이션 중입니다. 이미 여러 Amazon EC2 instances와 Amazon RDS DB instances를 사용하고 있습니다. 이 회사는 업무 시간 외에 EC2 instances와 DB instances를 자동으로 시작하고 중지해 비용을 절감하고 싶어 합니다. 이 솔루션은 비용과 인프라 운영 부담이 최소화되어야 합니다. 어떤 솔루션이 이러한 요구사항을 충족할까요?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102145-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 EC2와 RDS DB 인스턴스를 업무 시간 외에 자동 중지하여 비용을 절감하는 것입니다. AWS Lambda와 EventBridge를 이용하면 스케줄 기반으로 손쉽게 자동화가 가능하며, 추가 인프라 없이 유지보수 부담과 비용을 최소화할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "자동 시작 및 중지",
      "EC2 인스턴스",
      "RDS DB 인스턴스",
      "비용 최소화",
      "AWS Lambda",
      "Amazon EventBridge",
      "스케줄링"
    ],
    "Terms": [
      "AWS Cloud",
      "Amazon EC2",
      "Amazon RDS",
      "AWS Marketplace",
      "crontab schedule",
      "AWS Lambda function",
      "Amazon EventBridge",
      "elastic resize"
    ],
    "SelectA": "EC2 instances는 elastic resize를 사용해 스케일링하고, 업무 시간 외에는 DB 인스턴스를 0으로 스케일링합니다.",
    "SelectA_Commentary": "Amazon RDS DB 인스턴스를 0으로 스케일링하는 옵션은 존재하지 않으므로 적용할 수 없습니다.",
    "SelectB": "AWS Marketplace에서 EC2와 DB 인스턴스를 스케줄에 맞춰 자동으로 시작 및 중지해주는 서드파티 솔루션을 탐색합니다.",
    "SelectB_Commentary": "추가적인 서비스 비용과 유지보수가 발생할 수 있어 가장 효율적인 방식이라 보기 어렵습니다.",
    "SelectC": "다른 EC2 인스턴스를 구동하고, crontab 스케줄을 사용해 기존 EC2와 DB 인스턴스를 시작/중지하는 쉘 스크립트를 실행합니다.",
    "SelectC_Commentary": "서버를 추가로 운영해야 하며 스크립트 유지보수 부담도 상승하기 때문에 비용 절감과 운영 최소화 관점에서 비효율적입니다.",
    "SelectD": "AWS Lambda 함수를 작성하여 EC2와 RDS DB 인스턴스를 시작/중지하도록 구성합니다. Amazon EventBridge로 함수를 스케줄에 맞춰 실행하도록 설정합니다.",
    "SelectD_Commentary": "추가 서버 없이 자동화할 수 있어 비용과 인프라 부담을 줄이는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q238",
      "Q671",
      "Q449",
      "Q520",
      "Q1013"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q520",
      "Q1013"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q196"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q196",
      "Q167"
    ],
    "SelectD_recommedations": [
      "Q31",
      "Q380",
      "Q770"
    ]
  },
  {
    "Question_Number": "Q381",
    "Question_Description": "한 회사가 PostgreSQL 데이터베이스가 포함된 3티어 웹 애플리케이션을 운영하고 있습니다. 데이터베이스는 문서의 메타데이터를 저장하며, 문서는 Amazon S3에 보관됩니다. 문서는 보통 한 번 작성된 후 자주 업데이트되며, 매월 보고서에 필요한 문서를 검색하기 위해 메타데이터에서 키워드를 조회합니다. 이 관계형 쿼리를 통한 보고 프로세스는 몇 시간 걸리지만, 문서 수정이나 신규 문서 추가가 지연되면 안 됩니다. 솔루션스 아키텍트는 애플리케이션 코드 변경을 최소화하면서 보고 프로세스를 가속화해야 합니다. 어떤 솔루션이 이 요구사항을 충족할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102147-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 PostgreSQL 워크로드를 별도 인프라 없이 확장해 고성능의 보고 작업을 처리하는 방법을 묻습니다. 애플리케이션 측 수정이 최소화되어야 하므로 PostgreSQL 호환성과 별도 읽기 노드 분산이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "PostgreSQL 데이터베이스",
      "문서 메타데이터",
      "읽기 부하 분산",
      "어플리케이션 코드 변경 최소화",
      "Amazon S3"
    ],
    "Terms": [
      "PostgreSQL",
      "Amazon S3",
      "Amazon DocumentDB",
      "Amazon Aurora PostgreSQL",
      "Aurora Replica",
      "Amazon RDS",
      "Multi-AZ DB instance",
      "Amazon DynamoDB"
    ],
    "SelectA": "Amazon DocumentDB(MongoDB 호환) 클러스터를 생성하고 read replica를 추가합니다. 보고서는 해당 read replica로 생성합니다.",
    "SelectA_Commentary": "PostgreSQL에서 MongoDB 구조로 전환 시 큰 코드 변경이 필요하며, 기존 SQL 쿼리를 그대로 사용하기 어렵습니다.",
    "SelectB": "Amazon Aurora PostgreSQL DB 클러스터를 생성하고 Aurora Replica를 추가합니다. 보고서를 Aurora Replica에서 생성합니다.",
    "SelectB_Commentary": "Aurora는 PostgreSQL 호환이므로 코드 변경이 적고, Replica로 읽기 부하를 분산해 메인 DB 업데이트 성능에 영향 없이 보고가 가능합니다.",
    "SelectC": "Amazon RDS for PostgreSQL Multi-AZ DB 인스턴스를 설정하고, 보조 노드에서 보고 쿼리를 실행하도록 합니다.",
    "SelectC_Commentary": "Multi-AZ는 주로 장애 조치(HA)를 위해 사용되며 읽기 부하 분산에 최적화되지 않았습니다.",
    "SelectD": "Amazon DynamoDB 테이블을 새로 생성해 문서를 저장하고, 신규 문서에 대해 고정된 쓰기 용량을 설정하며 보고를 위한 읽기 용량은 자동 확장합니다.",
    "SelectD_Commentary": "관계형 구조를 NoSQL로 전환하려면 코드와 스키마 변경이 커서, 최소 변경 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q292",
      "Q596",
      "Q173",
      "Q547",
      "Q501"
    ],
    "SelectA_recommedations": [
      "Q247",
      "Q337",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q235",
      "Q946",
      "Q886"
    ],
    "SelectC_recommedations": [
      "Q633",
      "Q726",
      "Q481"
    ],
    "SelectD_recommedations": [
      "Q472",
      "Q578",
      "Q731"
    ]
  },
  {
    "Question_Number": "Q382",
    "Question_Description": "한 회사가 AWS에서 사용자 디바이스의 센서 데이터를 수집하는 3티어 애플리케이션을 운영 중입니다. 트래픽은 Network Load Balancer (NLB)를 거쳐 웹 계층용 Amazon EC2 인스턴스, 그리고 애플리케이션 계층용 EC2 인스턴스로 전달됩니다. 애플리케이션 계층은 데이터베이스를 호출합니다. 데이터 전송 중의 보안을 향상하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102149-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자 기기부터 NLB, 그리고 EC2 인스턴스까지의 데이터 흐름을 안전하게 보호하는 방법을 묻습니다. TLS를 통해 트래픽을 암호화하면 전송 중 데이터 보안을 크게 강화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "데이터 전송 중 보안",
      "TLS",
      "NLB",
      "서버 인증서",
      "암호화"
    ],
    "Terms": [
      "Network Load Balancer (NLB)",
      "TLS Listener",
      "AWS WAF",
      "AWS Shield Advanced",
      "Application Load Balancer (ALB)",
      "Amazon EBS",
      "AWS Key Management Service (AWS KMS)"
    ],
    "SelectA": "TLS listener를 구성하고, 서버 인증서를 NLB에 배포합니다.",
    "SelectA_Commentary": "NLB에서 TLS를 종료하여 트래픽을 암호화하면 데이터 전송 중 보안을 강화할 수 있습니다. 서버 인증서 설정으로 효율적인 암호화 오버헤드 처리와 안전한 연결이 가능합니다.",
    "SelectB": "AWS Shield Advanced를 구성하고, NLB에서 AWS WAF를 활성화합니다.",
    "SelectB_Commentary": "이 방법은 주로 DDoS 등 네트워크 공격 방어 및 웹 계층 보안을 강화하지만, 전송 중 데이터를 암호화하는 TLS 구성과 직접적인 관련이 없습니다.",
    "SelectC": "Load Balancer를 Application Load Balancer (ALB)로 변경하고, ALB에서 AWS WAF를 활성화합니다.",
    "SelectC_Commentary": "ALB에 WAF를 적용해 웹 계층 보안을 확장할 수 있지만, 데이터 암호화(전송 계층 보안) 설정 자체가 이 옵션에서 제대로 언급되지 않아 요구사항을 충족하지 못합니다.",
    "SelectD": "Amazon EC2 인스턴스의 Amazon EBS 볼륨을 AWS Key Management Service (AWS KMS)를 사용해 암호화합니다.",
    "SelectD_Commentary": "이는 저장 데이터(At Rest) 암호화 방식으로, 전송 중 데이터를 보호하는 TLS 구성과는 직접적인 관련이 없어 문제의 요구사항을 충족하지 않습니다.",
    "Question_Description_recommedations": [
      "Q884",
      "Q928",
      "Q170",
      "Q35",
      "Q744"
    ],
    "SelectA_recommedations": [
      "Q571",
      "Q855",
      "Q265"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q707",
      "Q884"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q371",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q383",
    "Question_Description": "한 회사가 상용 범용(commercial off-the-shelf) 애플리케이션을 온프레미스 데이터센터에서 AWS로 마이그레이션하려고 합니다. 이 소프트웨어는 소켓과 코어 수를 기준으로 하는 소프트웨어 라이선싱 모델과 예측 가능한 용량 및 가동 시간 요구 사항이 있습니다. 회사는 올해 초에 구매한 기존 라이선스를 계속 사용하고자 합니다. 가장 비용 효율적인 Amazon EC2 요금 옵션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102150-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 소프트웨어 라이선싱 모델상 물리적 소켓과 코어 단위로 라이선스가 관리되어야 하며, EC2 자원도 꾸준히 예상되는 사용량이 있는 상황을 전제합니다. 이러한 요구사항 하에서 Dedicated Host로 물리적 서버를 제어하고, Reserved 형태로 사전에 용량을 확보함으로써 가장 비용 효과적이고 정확한 라이선스 할당이 가능합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "기존 라이선스",
      "소켓과 코어",
      "예측 가능한 용량",
      "Amazon EC2",
      "비용 효율적"
    ],
    "Terms": [
      "Dedicated Host",
      "Reserved Host",
      "On-Demand Host",
      "Dedicated Instance",
      "On-Demand Instance",
      "Reserved Instance"
    ],
    "SelectA": "Dedicated Reserved Hosts",
    "SelectA_Commentary": "소켓과 코어 중심 라이선스를 활용해야 하므로 Dedicated Host가 필수이며, 예측 가능한 용량을 사전에 예약하여 비용 최적화를 이룰 수 있어 정답입니다.",
    "SelectB": "Dedicated On-Demand Hosts",
    "SelectB_Commentary": "Dedicated Host 요구사항은 충족하지만 On-Demand 특성상 꾸준한 수요 예측이 가능한 상황에서 비용 효율이 떨어집니다.",
    "SelectC": "Dedicated Reserved Instances",
    "SelectC_Commentary": "물리적 호스트 단위 라이선스 제어가 필요한 소켓·코어 라이선싱 모델에는 적합하지 않습니다.",
    "SelectD": "Dedicated On-Demand Instances",
    "SelectD_Commentary": "Dedicated 환경이지만 On-Demand는 장기적 안정 수요를 가진 경우 비용 효율성이 낮아 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q671",
      "Q505",
      "Q238",
      "Q552",
      "Q347"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q300",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q300",
      "Q943",
      "Q552"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q552",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q128",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q384",
    "Question_Description": "한 회사가 여러 Availability Zone에 걸쳐 Amazon EC2 Linux 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 고가용성이면서 POSIX 규격을 준수하는 스토리지 계층이 필요합니다. 스토리지 계층은 최대 데이터 내구성을 제공해야 하고, 여러 EC2 인스턴스에서 공유가 가능해야 합니다. 또한 이 스토리지 계층의 데이터는 처음 30일 동안은 자주 액세스되지만, 이후에는 드물게 액세스될 예정입니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102152-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 POSIX 규격과 다중 AZ의 고가용성, 그리고 30일 후 드문 액세스를 고려해 비용 효율을 극대화해야 합니다. EFS Standard를 사용하고, lifecycle 관리를 통해 EFS Standard-IA로 이전하는 것이 모든 요구사항을 만족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "2.2",
      "4.1"
    ],
    "Keywords": [
      "고가용성",
      "POSIX",
      "Amazon EFS",
      "데이터 내구성",
      "lifecycle management",
      "비용 효율성",
      "EC2 인스턴스 공유"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "S3 Standard",
      "S3 Glacier",
      "S3 Standard-IA",
      "Amazon Elastic File System (Amazon EFS)",
      "POSIX",
      "EFS Standard",
      "EFS Standard-Infrequent Access (EFS Standard-IA)",
      "EFS One Zone",
      "EFS One Zone-IA",
      "Lifecycle policy",
      "Multi-AZ"
    ],
    "SelectA": "Amazon S3 Standard 스토리지 클래스를 사용합니다. S3 Lifecycle 정책을 생성하여 드물게 액세스되는 데이터를 S3 Glacier로 이동시킵니다.",
    "SelectA_Commentary": "S3는 오브젝트 스토리지로 POSIX 규격을 만족하지 못해 여러 EC2 인스턴스에서 공유 파일 스토어로는 적합하지 않습니다.",
    "SelectB": "Amazon S3 Standard 스토리지 클래스를 사용합니다. S3 Lifecycle 정책을 생성하여 드물게 액세스되는 데이터를 S3 Standard-Infrequent Access (S3 Standard-IA)로 이동시킵니다.",
    "SelectB_Commentary": "S3는 여전히 파일 수준의 POSIX 규격을 지원하지 않아 고가용성 POSIX 파일 스토어로 적합하지 않습니다.",
    "SelectC": "Amazon Elastic File System (Amazon EFS) Standard 스토리지 클래스를 사용합니다. lifecycle management 정책을 생성하여 드물게 액세스되는 데이터를 EFS Standard-Infrequent Access (EFS Standard-IA)로 이동시킵니다.",
    "SelectC_Commentary": "정답입니다. EFS는 POSIX 준수, 다중 AZ, 높은 내구성을 제공하며, EFS Standard-IA로 이동해 비용을 절감할 수 있습니다.",
    "SelectD": "Amazon Elastic File System (Amazon EFS) One Zone 스토리지 클래스를 사용합니다. lifecycle management 정책을 생성하여 드물게 액세스되는 데이터를 EFS One Zone-Infrequent Access (EFS One Zone-IA)로 이동시킵니다.",
    "SelectD_Commentary": "One Zone은 단일 AZ를 사용하므로 고가용성과 최대 내구성 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q773",
      "Q118",
      "Q221",
      "Q277",
      "Q671"
    ],
    "SelectA_recommedations": [
      "Q415",
      "Q23",
      "Q356"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q277",
      "Q822",
      "Q800"
    ],
    "SelectD_recommedations": [
      "Q800",
      "Q277",
      "Q822"
    ]
  },
  {
    "Question_Number": "Q385",
    "Question_Description": "한 Solutions Architect가 새로운 VPC 디자인을 구성하고 있습니다. 두 개의 public subnet은 Load Balancer 용이고, 두 개의 private subnet은 web servers 용, 그리고 두 개의 private subnet은 MySQL 용입니다. web servers는 HTTPS만 사용합니다. 이미 Load Balancer에 대해, 0.0.0.0/0에서 오는 443 포트를 허용하는 security group이 생성되어 있습니다. 회사 정책상 각 리소스는 작업을 수행하기 위해 필요한 최소 권한만 가져야 합니다. 이 요구사항을 만족하기 위해 추가로 어떤 구성 전략이 필요합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102153-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 최소 권한 원칙에 따라 AWS 보안 구성을 어떻게 해야 하는지 묻습니다. 이미 Load Balancer에 대해 443 포트를 개방했으므로, web servers는 Load Balancer에서 오는 443 트래픽만 허용해야 합니다. 이후 MySQL은 오직 web servers security group에서 오는 3306 트래픽만 허용하도록 구성해 DB를 보호해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "최소 권한",
      "Load Balancer",
      "web servers",
      "HTTPS",
      "MySQL",
      "private subnets",
      "security group",
      "port 443",
      "port 3306",
      "VPC"
    ],
    "Terms": [
      "VPC",
      "subnet",
      "security group",
      "HTTPS",
      "Load Balancer",
      "MySQL",
      "port 443",
      "port 3306",
      "network ACL (NACL)"
    ],
    "SelectA": "web servers용 security group을 생성해 0.0.0.0/0에서 오는 443 포트를 허용합니다. MySQL 서버용 security group을 생성해 web servers security group에서 오는 3306 포트를 허용합니다.",
    "SelectA_Commentary": "web servers에 0.0.0.0/0에서 오는 모든 443 트래픽을 허용하므로 최소 권한 원칙 위배입니다.",
    "SelectB": "web servers용 network ACL을 생성해 0.0.0.0/0에서 오는 443 포트를 허용합니다. MySQL 서버용 network ACL을 생성해 web servers security group에서 오는 3306 포트를 허용합니다.",
    "SelectB_Commentary": "network ACL 대신 security group을 제한적으로 활용해야 더 세분화된 접근 제어가 가능합니다.",
    "SelectC": "web servers용 security group을 생성해 Load Balancer에서만 오는 443 포트를 허용합니다. MySQL 서버용 security group을 생성해 web servers security group에서 오는 3306 포트를 허용합니다.",
    "SelectC_Commentary": "필요한 트래픽만 엄격히 허용하여 최소 권한을 유지하는 모범적인 구성으로, 올바른 답안입니다.",
    "SelectD": "web servers용 network ACL을 생성해 Load Balancer에서 오는 443 포트를 허용합니다. MySQL 서버용 network ACL을 생성해 web servers security group에서 오는 3306 포트를 허용합니다.",
    "SelectD_Commentary": "network ACL 레벨에서 제한하기보다는 security group을 활용하는 것이 실제로 더 세분화와 관리가 용이합니다.",
    "Question_Description_recommedations": [
      "Q388",
      "Q928",
      "Q676",
      "Q55",
      "Q35"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q385",
      "Q74"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q385",
      "Q406"
    ],
    "SelectC_recommedations": [
      "Q385",
      "Q774",
      "Q169"
    ],
    "SelectD_recommedations": [
      "Q385",
      "Q169",
      "Q644"
    ]
  },
  {
    "Question_Number": "Q386",
    "Question_Description": "한 전자상거래 회사가 AWS에서 멀티 티어 애플리케이션을 운영하고 있습니다. 프론트엔드와 백엔드 계층은 모두 Amazon EC2에서 실행되고, 데이터베이스는 Amazon RDS for MySQL에서 구동됩니다. 백엔드 계층은 RDS 인스턴스와 통신합니다. 데이터베이스에서 동일한 데이터세트를 자주 호출하여 성능 저하가 발생합니다. 백엔드의 성능을 개선하기 위해 어떤 조치를 취해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102154-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터베이스에서 반복 호출되는 동일한 데이터세트로 인한 지연을 해결하는 것이 핵심입니다. Amazon ElastiCache를 통해 자주 요청되는 데이터를 인메모리에 캐시하여 백엔드 응답 속도를 크게 개선할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "멀티 티어 애플리케이션",
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "백엔드 성능",
      "Amazon ElastiCache",
      "캐싱"
    ],
    "Terms": [
      "Multi-tier application",
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "Amazon SNS",
      "Amazon ElastiCache",
      "RDS for MySQL read replica",
      "Amazon Kinesis Data Firehose"
    ],
    "SelectA": "Amazon SNS를 구현하여 데이터베이스 호출을 저장합니다.",
    "SelectA_Commentary": "SNS는 메시징 서비스로, 캐싱 기능을 제공하지 않아 반복 호출 문제를 해결하기에는 적합하지 않습니다.",
    "SelectB": "Amazon ElastiCache를 구현하여 큰 데이터세트를 캐시합니다.",
    "SelectB_Commentary": "인메모리 캐싱을 통해 동일한 데이터 요청 시 데이터를 빠르게 반환하므로, 백엔드 성능 개선에 가장 효과적인 방법입니다.",
    "SelectC": "RDS for MySQL 읽기 전용 리드 레플리카를 구현하여 데이터베이스 호출을 캐시합니다.",
    "SelectC_Commentary": "읽기 부하 분산에는 유용하지만, 반복 호출되는 데이터를 메모리에 저장해 즉시 반환하기에는 적합하지 않습니다.",
    "SelectD": "Amazon Kinesis Data Firehose를 구현하여 데이터베이스로의 호출을 스트리밍합니다.",
    "SelectD_Commentary": "스트리밍은 데이터 전송과 적재가 주 목적이며, 캐싱을 통한 빠른 재사용을 제공하지 않아 성능 문제를 직접 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q910",
      "Q193",
      "Q95",
      "Q590",
      "Q229"
    ],
    "SelectA_recommedations": [
      "Q622",
      "Q888",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q620"
    ],
    "SelectC_recommedations": [
      "Q376",
      "Q590",
      "Q95"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q472",
      "Q523"
    ]
  },
  {
    "Question_Number": "Q387",
    "Question_Description": "한 회사에 새로운 직원이 배포 엔지니어로 입사했습니다. 이 배포 엔지니어는 AWS CloudFormation 템플릿을 사용하여 여러 AWS 리소스를 생성할 예정입니다. 솔루션스 아키텍트는 이 배포 엔지니어가 최소 권한 원칙(Principle of Least Privilege)을 준수하면서 업무를 수행하기를 원합니다. 이 목표를 달성하기 위해 솔루션스 아키텍트는 다음 중 어떤 조합의 조치를 취해야 합니까? (2개를 고르시오)",
    "Answer": "D,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102155-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새로 합류한 배포 엔지니어에게 필요한 권한만 부여해 AWS CloudFormation을 사용하도록 하는 최소 권한 원칙의 적용 방안을 묻습니다. root user를 사용하거나 과도한 권한(AdministratorAccess, PowerUsers)을 부여하면 보안 위험이 커집니다. IAM user와 IAM role을 통한 세분화된 권한 설정이 핵심이며, 정답은 D와 E 조합입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS CloudFormation",
      "IAM user",
      "IAM policy",
      "root user",
      "AdministratorAccess",
      "PowerUsers",
      "IAM role",
      "최소 권한 원칙"
    ],
    "Terms": [
      "AWS CloudFormation",
      "IAM user",
      "IAM policy",
      "root user",
      "PowerUsers IAM policy",
      "AdministratorAccess IAM policy",
      "IAM role"
    ],
    "SelectA": "배포 엔지니어가 AWS account root user 자격 증명을 사용하여 AWS CloudFormation 스택 작업을 수행하도록 합니다.",
    "SelectA_Commentary": "root user는 절대 사용해서는 안 됩니다. 최소 권한 원칙에 위배됩니다.",
    "SelectB": "배포 엔지니어를 위한 새로운 IAM user를 생성한 뒤, PowerUsers IAM policy가 연결된 그룹에 추가합니다.",
    "SelectB_Commentary": "PowerUsers는 광범위한 권한을 부여하므로 최소 권한 원칙에 위배됩니다.",
    "SelectC": "배포 엔지니어를 위한 새로운 IAM user를 생성한 뒤, AdministratorAccess IAM policy가 연결된 그룹에 추가합니다.",
    "SelectC_Commentary": "AdministratorAccess는 모든 작업 권한이 포함되어 있어 최소 권한 기준을 훨씬 초과합니다.",
    "SelectD": "배포 엔지니어를 위한 새로운 IAM user를 생성한 뒤, AWS CloudFormation 작업만 허용하는 IAM policy가 연결된 그룹에 추가합니다.",
    "SelectD_Commentary": "CloudFormation에 필요한 권한만 할당하여 최소 권한 원칙을 만족하는 올바른 선택입니다.",
    "SelectE": "배포 엔지니어를 위한 IAM role을 생성하여 AWS CloudFormation 스택에 필요한 권한을 명시적으로 정의하고, 해당 IAM role로 스택을 실행합니다.",
    "SelectE_Commentary": "IAM role을 사용해 정확히 필요한 권한만 부여함으로써 보안을 강화하는 또 다른 합리적 방법입니다.",
    "Question_Description_recommedations": [
      "Q254",
      "Q913",
      "Q484",
      "Q893",
      "Q970"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q745",
      "Q387"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q429",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q233"
    ],
    "SelectD_recommedations": [
      "Q780",
      "Q476",
      "Q222"
    ],
    "SelectE_recommedations": [
      "Q222",
      "Q476",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q388",
    "Question_Description": "회사가 VPC에 2티어 웹 애플리케이션을 배포하고 있습니다. 웹 티어는 여러 Availability Zones에 걸쳐 public subnets을 사용하는 Amazon EC2 Auto Scaling group으로 구성되어 있습니다. 데이터베이스 티어는 별도의 private subnets에 Amazon RDS for MySQL DB instance로 구성되어 있습니다. 웹 티어는 데이터베이스에 액세스해 제품 정보를 조회해야 합니다. 현재 웹 애플리케이션이 정상 작동하지 않으며, 데이터베이스에 연결할 수 없다는 오류가 발생하고 있습니다. 데이터베이스는 정상적으로 동작 중임이 확인되었습니다. network ACL, security group, route table 설정은 모두 기본값 상태로 유지되고 있습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102156-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 디폴트 설정 상태의 security group이 모든 인바운드 트래픽을 차단하기 때문에 웹 티어에서 DB 티어로의 연결이 실패하는 상황입니다. 따라서 DB 티어의 security group에 웹 티어 security group으로부터의 인바운드를 허용하는 규칙을 추가해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EC2 Auto Scaling group",
      "public subnet",
      "private subnet",
      "Amazon RDS for MySQL",
      "security group",
      "inbound rule"
    ],
    "Terms": [
      "Amazon EC2 Auto Scaling",
      "Availability Zones",
      "Amazon RDS for MySQL",
      "network ACL",
      "security group",
      "route table",
      "VPC",
      "VPC peering",
      "inbound rule"
    ],
    "SelectA": "private subnet의 network ACL에 웹 티어의 EC2 인스턴스 트래픽을 허용하는 명시적 규칙을 추가합니다.",
    "SelectA_Commentary": "기본 network ACL은 아웃바운드, 인바운드 모두 허용 상태이며 문제의 원인이 아니므로 이 규칙 추가만으로는 해결되지 않습니다.",
    "SelectB": "VPC route table에 웹 티어 EC2 인스턴스와 DB 티어 간 트래픽을 허용하는 라우트를 추가합니다.",
    "SelectB_Commentary": "기본 route table은 이미 동일 VPC 내 통신을 허용합니다. 별도의 라우트 추가는 필요하지 않습니다.",
    "SelectC": "웹 티어의 EC2 인스턴스와 DB 티어의 RDS 인스턴스를 서로 다른 VPC에 배포하고, VPC peering을 구성합니다.",
    "SelectC_Commentary": "두 리소스가 이미 동일 VPC 내에 있으므로 VPC를 분리하거나 VPC peering을 구성할 이유가 없습니다.",
    "SelectD": "DB 티어의 RDS 인스턴스 security group에 웹 티어 security group에서 오는 트래픽을 허용하는 inbound rule을 추가합니다.",
    "SelectD_Commentary": "security group은 기본적으로 모든 인바운드를 차단하므로, 웹 티어에서 오는 연결을 허용하는 규칙이 필수입니다. 이 방법이 문제 해결에 적합합니다.",
    "Question_Description_recommedations": [
      "Q55",
      "Q370",
      "Q614",
      "Q810",
      "Q676"
    ],
    "SelectA_recommedations": [
      "Q251",
      "Q875",
      "Q218"
    ],
    "SelectB_recommedations": [
      "Q562",
      "Q866",
      "Q950"
    ],
    "SelectC_recommedations": [
      "Q562",
      "Q232",
      "Q810"
    ],
    "SelectD_recommedations": [
      "Q330",
      "Q847",
      "Q438"
    ]
  },
  {
    "Question_Number": "Q389",
    "Question_Description": "한 회사가 온라인 광고 비즈니스를 위해 Amazon RDS for MySQL DB 인스턴스(단일 Availability Zone)에 대규모 데이터 세트를 저장하고 있습니다. 회사는 프로덕션 DB 인스턴스에 대한 쓰기 작업에 영향을 주지 않고 비즈니스 보고 쿼리를 실행하기를 원합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102157-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프로덕션 DB 인스턴스의 쓰기 성능을 유지하며 보고 쿼리를 처리해야 하는 상황입니다. RDS Read Replica를 사용하면 읽기 요청을 분산하여 주 데이터베이스의 쓰기 작업에 영향을 주지 않고 보고 쿼리를 처리할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "RDS Read Replica",
      "프로덕션 DB 인스턴스",
      "쓰기 작업",
      "비즈니스 보고 쿼리"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "DB Instance",
      "Availability Zone",
      "RDS Read Replica",
      "Elastic Load Balancer",
      "Multi-AZ"
    ],
    "SelectA": "비즈니스 보고 쿼리를 처리하도록 RDS read replicas를 배포합니다.",
    "SelectA_Commentary": "읽기 부하를 별도의 Read Replica로 분산해 프로덕션 DB의 쓰기 성능에 영향을 주지 않고 보고 쿼리를 처리할 수 있어 최적의 솔루션입니다.",
    "SelectB": "DB 인스턴스를 Elastic Load Balancer 뒤에 두어서 수평 확장합니다.",
    "SelectB_Commentary": "RDS 인스턴스는 ELB로 단순 확장되지 않으며, 쓰기와 읽기가 동시에 증가하면 근본적 해법이 되기 어렵습니다.",
    "SelectC": "쓰기 작업과 쿼리를 처리하기 위해 DB 인스턴스의 인스턴스 유형을 크게 확장합니다.",
    "SelectC_Commentary": "인스턴스 유형을 확장해도 쓰기와 읽기가 같은 인스턴스에서 처리돼 여전히 부하가 큽니다.",
    "SelectD": "DB 인스턴스를 다중 Availability Zone에 배포해 비즈니스 보고 쿼리를 처리합니다.",
    "SelectD_Commentary": "Multi-AZ 배포는 고가용성 구성을 위한 것으로, 읽기 부하 분산이 아닌 장애 조치 지원이 주 목적입니다.",
    "Question_Description_recommedations": [
      "Q376",
      "Q590",
      "Q269",
      "Q386",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q247",
      "Q95",
      "Q337"
    ],
    "SelectB_recommedations": [
      "Q472",
      "Q578",
      "Q229"
    ],
    "SelectC_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectD_recommedations": [
      "Q818",
      "Q578",
      "Q389"
    ]
  },
  {
    "Question_Number": "Q390",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스 집합에 3티어 전자상거래 애플리케이션을 호스팅하고 있습니다. 인스턴스들은 Application Load Balancer(ALB)의 뒤에 위치한 Auto Scaling group에서 실행 중입니다. 모든 전자상거래 데이터는 Amazon RDS for MariaDB Multi-AZ DB instance에 저장되어 있습니다. 회사는 트랜잭션 중 고객 세션 관리를 최적화하고자 하며, 애플리케이션은 세션 데이터를 영구적으로 저장해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102213-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트랜잭션 중에도 안정적이고 효율적으로 세션 데이터를 유지하기 위한 방법을 묻는 것입니다. Sticky Sessions(ALB session affinity)을 통해 동일 사용자는 같은 인스턴스로 연결되어 인스턴스 내에 세션을 저장할 수 있고, Amazon ElastiCache for Redis를 사용하면 내결함성과 확장성을 갖춘 인메모리 세션 저장소를 구성할 수 있습니다. 둘 다 세션 유지 및 성능 측면에서 뛰어나며, Redis는 영구화 옵션도 지원해 내결함성을 더욱 높입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Amazon RDS for MariaDB Multi-AZ",
      "고객 세션",
      "Sticky Sessions",
      "Amazon ElastiCache for Redis",
      "영구적 저장"
    ],
    "Terms": [
      "Sticky Sessions (Session Affinity)",
      "Amazon DynamoDB",
      "Amazon Cognito user pool",
      "Amazon ElastiCache for Redis",
      "AWS Systems Manager Application Manager"
    ],
    "SelectA": "ALB에서 Sticky Sessions(session affinity) 기능을 활성화합니다.",
    "SelectA_Commentary": "Sticky Sessions를 활성화하면 동일 사용자가 같은 EC2 인스턴스로 라우팅되어, 세션 데이터가 일관성 있게 유지됩니다.",
    "SelectB": "고객 세션 정보를 저장하기 위해 Amazon DynamoDB 테이블을 사용합니다.",
    "SelectB_Commentary": "DynamoDB도 세션 정보를 저장할 수 있지만, 고속의 지속 연결 세션 관리에는 Sticky Sessions와 인메모리 캐시 방식이 더 효율적입니다.",
    "SelectC": "사용자 세션 정보를 관리하기 위해 Amazon Cognito user pool을 배포합니다.",
    "SelectC_Commentary": "Amazon Cognito user pool은 인증 및 사용자 관리를 주로 담당하며, 전자상거래 애플리케이션의 세션 데이터 관리를 위한 직접적인 솔루션으로는 부적합합니다.",
    "SelectD": "고객 세션 정보를 저장하기 위해 Amazon ElastiCache for Redis 클러스터를 배포합니다.",
    "SelectD_Commentary": "ElastiCache for Redis는 인메모리 데이터 저장소로 고성능 세션 관리가 가능하고, 영구화 설정으로 내결함성도 강화할 수 있어 적합한 솔루션입니다.",
    "SelectE": "애플리케이션 내에서 사용자 세션 정보를 관리하기 위해 AWS Systems Manager Application Manager를 사용합니다.",
    "SelectE_Commentary": "Systems Manager Application Manager는 애플리케이션 구성 및 모니터링 중심으로, 세션 저장소 전용 솔루션이 아니므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q955",
      "Q298",
      "Q874",
      "Q69"
    ],
    "SelectA_recommedations": [
      "Q589",
      "Q8",
      "Q52"
    ],
    "SelectB_recommedations": [
      "Q1002",
      "Q845",
      "Q400"
    ],
    "SelectC_recommedations": [
      "Q363",
      "Q8",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q593",
      "Q584",
      "Q194"
    ],
    "SelectE_recommedations": [
      "Q8",
      "Q194",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q391",
    "Question_Description": "한 회사가 3티어 stateless 웹 애플리케이션에 대한 백업 전략이 필요합니다. 웹 애플리케이션은 Auto Scaling group에서 동적으로 Amazon EC2 인스턴스를 실행하며, 각 인스턴스는 임시 로컬 스토리지(temporary local storage)를 필요로 하지 않습니다. 데이터베이스 계층은 Amazon RDS for PostgreSQL로 구성되어 있습니다. 회사의 RPO(Recovery Point Objective)는 2시간이며, 백업 전략은 높은 확장성과 리소스 활용 최적화를 달성해야 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 임시 로컬 스토리지를 필요로 하지 않는 Stateless 웹 계층과 Amazon RDS for PostgreSQL 기반 데이터베이스 계층의 백업 및 복원 전략을 묻습니다. 웹 계층은 Stateless 특성상 Amazon EBS Snapshot이 필수가 아니므로, 고정 애플리케이션 이미지를 최신 AMI로 유지하면 재해 발생 시 신속 복원이 가능합니다. RDS for PostgreSQL는 Automated Backup 및 Point-in-time recovery(PITR)를 통해 2시간 RPO 요구사항을 충족할 수 있습니다. 이러한 방식은 확장성과 리소스 사용을 모두 최적화합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "백업 전략",
      "Stateless 웹 애플리케이션",
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon Machine Image(AMI)",
      "Amazon RDS for PostgreSQL",
      "Recovery Point Objective(RPO)",
      "Point-in-time recovery"
    ],
    "Terms": [
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon EBS",
      "Amazon RDS for PostgreSQL",
      "Snapshot",
      "Lifecycle Policy",
      "Automated Backup",
      "Point-in-time recovery",
      "AMI"
    ],
    "SelectA": "Amazon EBS 볼륨(EC2 및 데이터베이스)의 스냅샷을 2시간마다 수행하여 RPO를 충족합니다.",
    "SelectA_Commentary": "Stateless 웹 계층까지 EBS Snapshot을 매번 찍으면 과도한 오버헤드가 발생하며 확장성도 떨어집니다.",
    "SelectB": "Snapshot Lifecycle Policy로 Amazon EBS 스냅샷을 자동화하고, Amazon RDS에서 Automated Backup을 활성화하여 RPO를 충족합니다.",
    "SelectB_Commentary": "웹 계층이 stateless한데 EBS Snapshot 자동화는 불필요 작업이 많아 리소스 사용이 비효율적입니다.",
    "SelectC": "웹, 애플리케이션 계층의 최신 Amazon Machine Image(AMI)를 유지하고, Amazon RDS에 Automated Backup과 Point-in-time recovery를 설정하여 RPO를 충족합니다.",
    "SelectC_Commentary": "Stateless 웹 계층은 AMI 사용이 최적이며, RDS의 Automated Backup과 PITR로 2시간 RPO를 맞추면서 리소스 사용과 확장성을 극대화합니다.",
    "SelectD": "EC2 인스턴스 Amazon EBS 볼륨을 2시간 주기로 스냅샷하고, RDS Automated Backup과 Point-in-time recovery를 사용하는 방식으로 RPO를 충족합니다.",
    "SelectD_Commentary": "Stateless 웹 계층의 데이터를 EBS 스냅샷으로 백업하는 것은 과도한 오버헤드로 최적화에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q764",
      "Q955",
      "Q475",
      "Q281",
      "Q274"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q71",
      "Q602"
    ],
    "SelectB_recommedations": [
      "Q588",
      "Q391",
      "Q475"
    ],
    "SelectC_recommedations": [
      "Q475",
      "Q391",
      "Q588"
    ],
    "SelectD_recommedations": [
      "Q475",
      "Q391",
      "Q274"
    ]
  },
  {
    "Question_Number": "Q392",
    "Question_Description": "한 회사가 AWS에 새로운 public web application을 배포하려고 합니다. 이 application은 Amazon EC2 인스턴스를 사용하는 web server tier와 Amazon RDS for MySQL DB instance를 사용하는 database tier로 구성됩니다. 전 세계의 고객들은 dynamic IP addresses를 사용하며, 이 application은 보안을 유지하면서도 글로벌 고객들이 접속할 수 있어야 합니다. 이런 요구사항을 만족하기 위해 solutions architect는 security groups를 어떻게 구성해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102160-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 네트워크 계층을 보안하면서도 전 세계의 동적 IP 주소를 가진 사용자들이 접속 가능하도록 security group을 설정하는 방법을 묻습니다. 일반적으로 웹 서버는 0.0.0.0/0로 HTTPS(443)를 허용하고, DB는 웹 서버와 통신하는 security group만 허용하는 것이 보안est practices에 부합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "public web application",
      "dynamic IP addresses",
      "global customer",
      "secure",
      "AWS",
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "security group",
      "port 443",
      "port 3306"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "security groups",
      "port 443",
      "port 3306",
      "0.0.0.0/0",
      "dynamic IP addresses",
      "web server tier",
      "database tier",
      "inbound traffic"
    ],
    "SelectA": "web servers의 security group에서 포트 443에 대해 0.0.0.0/0에서의 inbound traffic을 허용합니다. DB instance의 security group에서는 포트 3306에 대해 web servers의 security group에서의 inbound traffic만 허용합니다.",
    "SelectA_Commentary": "전 세계 동적 IP 주소를 가진 사용자 접근을 위해 웹 서버는 443을 전체 IP(0.0.0.0/0)에서 오픈하고, DB는 웹 서버만 접근하도록 제한해 보안을 높이는 올바른 설정입니다.",
    "SelectB": "web servers의 security group에서 포트 443에 대해 고객들의 IP 주소만 inbound traffic을 허용합니다. DB instance의 security group에서는 포트 3306을 web servers의 security group에서의 inbound traffic에 대해 허용합니다.",
    "SelectB_Commentary": "사용자들의 IP가 동적으로 변하므로 모든 IP를 일일이 허용하기 어렵습니다. 현실적으로 유지보수가 힘들어 비효율적입니다.",
    "SelectC": "web servers의 security group에서 포트 443에 대해 고객들의 IP 주소만 inbound traffic을 허용합니다. DB instance의 security group에서는 포트 3306에 대해 고객들의 IP 주소에 대한 inbound traffic을 허용합니다.",
    "SelectC_Commentary": "DB 인스턴스를 직접 외부 IP에 개방하면 보안 위험이 커집니다. 또한 고객들의 IP는 동적으로 변화하기 때문에 관리가 복잡합니다.",
    "SelectD": "web servers의 security group에서 포트 443에 대해 0.0.0.0/0에서의 inbound traffic을 허용합니다. DB instance의 security group에서 포트 3306에 대해 0.0.0.0/0에서의 inbound traffic을 허용합니다.",
    "SelectD_Commentary": "DB를 전 세계에 공개하면 보안 취약점이 매우 커집니다. DB는 웹 서버에서만 접근하도록 제한하는 것이 안전합니다.",
    "Question_Description_recommedations": [
      "Q82",
      "Q211",
      "Q385",
      "Q927",
      "Q549"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q385",
      "Q74"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q385",
      "Q74"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q385",
      "Q74"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q385",
      "Q74"
    ]
  },
  {
    "Question_Number": "Q393",
    "Question_Description": "한 결제 처리 회사에서는 고객과의 모든 음성 통화를 기록하고 해당 오디오 파일을 Amazon S3 버킷에 저장하고 있습니다. 이 회사는 오디오 파일에서 텍스트를 추출해야 하고, 고객의 개인 식별 정보(PII)를 텍스트에서 제거해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102322-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 음성 녹취 데이터에서 텍스트를 추출하고 그중에 포함된 고객 개인 식별 정보를 자동으로 제거해야 하는 보안 요구사항을 다룹니다. Amazon Transcribe의 PII Redaction 기능을 사용하면 음성 내 민감 정보를 쉽게 마스킹해 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "음성 녹취",
      "전체 텍스트 추출",
      "개인 식별 정보 제거",
      "Amazon Transcribe",
      "PII Redaction"
    ],
    "Terms": [
      "Amazon Kinesis Video Streams",
      "AWS Lambda",
      "Amazon Textract",
      "Amazon Transcribe",
      "PII Redaction",
      "Amazon Connect",
      "Amazon EventBridge"
    ],
    "SelectA": "Amazon Kinesis Video Streams를 사용하여 오디오 파일을 처리합니다. AWS Lambda 함수를 사용해 알려진 PII 패턴을 스캔합니다.",
    "SelectA_Commentary": "주로 실시간 비디오 스트리밍에 적합하며, 음성 데이터의 자동 PII 제거 기능을 제공하지 않아 요구사항을 만족하기 어렵습니다.",
    "SelectB": "오디오 파일이 S3 버킷에 업로드되면 AWS Lambda 함수를 호출해 Amazon Textract 작업을 시작합니다.",
    "SelectB_Commentary": "Amazon Textract는 이미지나 문서 내 텍스트 인식을 위한 서비스이므로 음성 파일 처리에는 부적합합니다.",
    "SelectC": "Amazon Transcribe transcription job을 PII redaction 옵션을 활성화하여 설정합니다. 오디오 파일이 S3 버킷에 업로드되면 AWS Lambda 함수를 호출해 transcription job을 시작하고, 결과를 별도의 S3 버킷에 저장합니다.",
    "SelectC_Commentary": "정답입니다. Amazon Transcribe에서 음성 데이터를 텍스트로 자동 변환하며, 내부 옵션으로 PII 제거를 지원해 보안성을 높일 수 있습니다.",
    "SelectD": "Amazon Connect contact flow를 사용해 transcription을 켠 상태로 오디오 파일을 처리합니다. AWS Lambda 함수를 사용해 알려진 PII 패턴을 스캔하고, 오디오 파일이 S3 버킷에 업로드되면 Amazon EventBridge로 contact flow를 시작합니다.",
    "SelectD_Commentary": "콜센터 흐름 설정에 특화된 Amazon Connect를 활용하는 복잡한 방식으로, Transcribe의 자동 PII 제거 옵션만큼 간소하거나 직관적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q26",
      "Q294",
      "Q89",
      "Q549",
      "Q85"
    ],
    "SelectA_recommedations": [
      "Q295",
      "Q529",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q289",
      "Q965",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q533",
      "Q289",
      "Q495"
    ],
    "SelectD_recommedations": [
      "Q495",
      "Q791",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q394",
    "Question_Description": "한 회사가 AWS Cloud에서 다중 계층 전자상거래 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon EC2 인스턴스에서 동작하며, Amazon RDS for MySQL Multi-AZ DB 인스턴스를 사용합니다. Amazon RDS는 최신 세대 DB 인스턴스로, 2,000GB 저장용량의 General Purpose SSD(gp3) Amazon EBS 볼륨을 구성했습니다. 이 데이터베이스 성능은 높은 트래픽이 발생할 때 애플리케이션에 영향을 미치고 있습니다. 데이터베이스 관리자가 Amazon CloudWatch Logs를 분석한 결과, 읽기·쓰기 IOPS가 20,000을 초과할 때마다 애플리케이션 성능이 항상 저하되는 것으로 확인되었습니다. 애플리케이션 성능을 개선하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102161-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL의 IOPS 한계에 도달했을 때 성능 저하가 발생하는 상황을 해결하는 방법을 묻습니다. gp3 볼륨 한 개로는 20,000 IOPS를 넘기기 어려우므로 볼륨을 병렬 구성하여 IOPS를 늘리는 것이 핵심입니다. 정답인 D는 2개의 gp3 볼륨을 사용해 총 IOPS를 높여 성능을 개선할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "Multi-AZ",
      "gp3",
      "IOPS",
      "고성능"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "Multi-AZ",
      "gp3 Volume",
      "IOPS",
      "Provisioned IOPS SSD (io2)",
      "Magnetic Volume"
    ],
    "SelectA": "Magnetic Volume으로 교체합니다.",
    "SelectA_Commentary": "Magnetic Volume은 최대 IOPS가 매우 낮아 고성능 요구 사항을 충족할 수 없습니다.",
    "SelectB": "gp3 볼륨의 IOPS를 높입니다.",
    "SelectB_Commentary": "gp3 볼륨당 IOPS 한도가 약 16,000이므로 20,000 이상 IOPS에는 부족합니다.",
    "SelectC": "Provisioned IOPS SSD(io2) 볼륨으로 교체합니다.",
    "SelectC_Commentary": "RDS 환경에서 io2 지원은 제한적일 수 있으며 요구 사항에 적합하지 않습니다.",
    "SelectD": "2,000 GB gp3 볼륨을 1,000 GB gp3 볼륨 두 개로 교체합니다.",
    "SelectD_Commentary": "gp3 볼륨 여러 개를 구성해 IOPS를 병렬로 확보하면 총 IOPS 증가로 성능을 높일 수 있습니다.",
    "Question_Description_recommedations": [
      "Q386",
      "Q481",
      "Q910",
      "Q999",
      "Q39"
    ],
    "SelectA_recommedations": [
      "Q888",
      "Q158",
      "Q506"
    ],
    "SelectB_recommedations": [
      "Q352",
      "Q501",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q919",
      "Q299",
      "Q127"
    ],
    "SelectD_recommedations": [
      "Q830",
      "Q1000",
      "Q1"
    ]
  },
  {
    "Question_Number": "Q395",
    "Question_Description": "지난주 프로덕션 배포 중에 한 IAM user가 회사 계정의 AWS 리소스에 대해 여러 가지 구성 변경을 수행했습니다. 그런데 일부 security group 규칙이 원하는 대로 구성되지 않았다는 사실을 확인했습니다. 솔루션스 아키텍트는 어느 IAM user가 해당 변경을 했는지 확인하고자 합니다. 어떤 서비스를 사용해야 이러한 정보를 찾을 수 있습니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102162-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "어느 IAM user가 특정 시점에 AWS 리소스 구성을 변경했는지 추적하려면 누가 언제 어떤 작업을 했는지 기록하는 로그가 필요합니다. AWS CloudTrail은 계정 내 활동을 모두 기록하므로 가장 적합한 서비스입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM user",
      "security group 규칙",
      "구성 변경",
      "AWS CloudTrail"
    ],
    "Terms": [
      "IAM",
      "security group",
      "Amazon GuardDuty",
      "Amazon Inspector",
      "AWS CloudTrail",
      "AWS Config"
    ],
    "SelectA": "Amazon GuardDuty",
    "SelectA_Commentary": "Amazon GuardDuty는 보안 위협 감지 서비스로, 특정 리소스 변경 기록을 추적하여 ‘누가’ 수정했는지까지는 제공하지 않습니다.",
    "SelectB": "Amazon Inspector",
    "SelectB_Commentary": "Amazon Inspector는 애플리케이션의 보안 취약성을 평가하고 권장 사항을 제시하지만 IAM user의 구성 변경 기록은 추적하지 않습니다.",
    "SelectC": "AWS CloudTrail",
    "SelectC_Commentary": "AWS CloudTrail은 API 호출이나 콘솔 활동 등 계정 내 모든 변경 사항을 기록하며, 어떤 IAM user가 어떤 시점에 어떤 작업을 했는지 확인할 수 있으므로 정답입니다.",
    "SelectD": "AWS Config",
    "SelectD_Commentary": "AWS Config는 리소스 구성 변경 전후 상태를 추적하지만, 어떤 사용자에 의해 수정되었는지는 세부적으로 보여주지 않아 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q222",
      "Q476",
      "Q780",
      "Q751",
      "Q233"
    ],
    "SelectA_recommedations": [
      "Q321",
      "Q313",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q321",
      "Q689",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q970",
      "Q898",
      "Q321"
    ],
    "SelectD_recommedations": [
      "Q898",
      "Q313",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q396",
    "Question_Description": "한 회사가 AWS에 셀프 관리 DNS 서비스를 구현했습니다. 이 솔루션은 여러 AWS 리전에 있는 Amazon EC2 인스턴스와 AWS Global Accelerator의 표준 엑셀러레이터 엔드포인트로 구성되어 있습니다. 회사는 이 솔루션을 DDoS 공격으로부터 보호하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102164-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 셀프 관리 DNS와 Global Accelerator로 구성된 환경을 네트워크 계층의 대규모 공격(DDoS)으로부터 보호하는 방법에 관한 것입니다. 대규모 트래픽을 효율적으로 차단하기 위해서는 네트워크 계층 보호에 특화된 AWS Shield Advanced를 사용해 Global Accelerator를 보호 리소스로 등록하는 것이 핵심입니다. AWS WAF와 같은 애플리케이션 계층 방어만으로는 대규모 DDoS 공격에 대한 충분한 보호를 제공하기 어렵습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "DNS 서비스",
      "DDoS 보호",
      "AWS Global Accelerator",
      "AWS Shield Advanced"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Global Accelerator",
      "AWS Shield Advanced",
      "AWS WAF",
      "rate-based rule"
    ],
    "SelectA": "Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.",
    "SelectA_Commentary": "AWS Shield Advanced는 Global Accelerator와 같은 네트워크 엔드포인트에 대한 높은 수준의 DDoS 보호를 제공합니다. 해당 엑셀러레이터를 직접 보호 대상으로 추가해야 효과적으로 방어할 수 있습니다.",
    "SelectB": "Subscribe to AWS Shield Advanced. Add the EC2 instances as resources to protect.",
    "SelectB_Commentary": "EC2 인스턴스 단독 보호는 Global Accelerator를 경유하는 DDoS 공격을 충분히 방어하지 못합니다. Global Accelerator 자체를 보호 대상으로 지정해야 합니다.",
    "SelectC": "Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the accelerator.",
    "SelectC_Commentary": "AWS WAF는 주로 애플리케이션 계층(레이어 7) 보호에 적합합니다. DDoS는 더 하위 계층에서 발생할 수 있어, WAF만으로는 대규모 트래픽 공격 완화가 제한적입니다.",
    "SelectD": "Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the EC2 instances.",
    "SelectD_Commentary": "EC2 인스턴스 측에 WAF를 연동해도 네트워크 및 전송 계층 대규모 DDoS 공격은 효과적으로 방어하기 어렵습니다. Global Accelerator 차원의 방어가 우선입니다.",
    "Question_Description_recommedations": [
      "Q35",
      "Q104",
      "Q927",
      "Q961",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q313",
      "Q961",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q233",
      "Q682",
      "Q453"
    ],
    "SelectC_recommedations": [
      "Q961",
      "Q165",
      "Q170"
    ],
    "SelectD_recommedations": [
      "Q165",
      "Q655",
      "Q853"
    ]
  },
  {
    "Question_Number": "Q397",
    "Question_Description": "한 이커머스 회사는 분석을 위해 매일 스케줄된 작업을 실행하여 판매 내역을 집계하고 필터링해야 합니다. 이 회사는 판매 내역을 Amazon S3 버킷에 저장하고 있으며, 각 객체는 최대 10GB 크기일 수 있습니다. 판매 이벤트의 수에 따라 작업은 최대 1시간까지 걸릴 수 있습니다. 또한 이 작업의 CPU와 메모리 사용량은 일정하며 사전에 파악되어 있습니다. 솔루션스 아키텍트는 이 작업을 실행하는 데 필요한 운영 노력을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102165-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 1시간 가까이 소요될 수 있는 일별 잡을 효과적으로 처리하면서 운영 부담을 줄이는 방안을 묻습니다. Lambda는 15분 제한이 있어 불가능하며, EC2 직접 관리보다는 Fargate가 서버리스로 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "이커머스",
      "스케줄된 일별 작업",
      "분석",
      "운영 노력 최소화",
      "Amazon S3",
      "AWS Lambda",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon EventBridge"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon EC2",
      "Amazon API Gateway",
      "Amazon EventBridge",
      "Auto Scaling group",
      "ECS task"
    ],
    "SelectA": "Amazon EventBridge 알림이 연결된 AWS Lambda 함수를 생성합니다. EventBridge 이벤트를 하루에 한 번 실행되도록 스케줄링합니다.",
    "SelectA_Commentary": "AWS Lambda는 최대 실행 시간이 15분으로 제한되어 1시간이 걸릴 수 있는 작업을 완전히 처리하기 어렵습니다.",
    "SelectB": "AWS Lambda 함수를 생성하고, Amazon API Gateway HTTP API와 연동합니다. 그 후 EventBridge 스케줄드 이벤트를 생성해 API 호출로 함수를 실행합니다.",
    "SelectB_Commentary": "마찬가지로 Lambda의 시간 제한이 문제이며, API Gateway를 추가로 관리해야 하므로 운영 노력이 늘어납니다.",
    "SelectC": "AWS Fargate 실행 유형으로 Amazon ECS 클러스터를 생성합니다. EventBridge 스케줄드 이벤트를 생성하여 클러스터에서 ECS 작업을 실행하고 잡을 수행합니다.",
    "SelectC_Commentary": "정답입니다. Fargate는 서버리스 컨테이너 환경으로 EC2를 직접 관리할 필요 없이 장시간 작업에도 적합하며 운영 부담이 최소화됩니다.",
    "SelectD": "Amazon EC2 실행 유형의 Amazon ECS 클러스터와 최소 한 대 이상의 EC2 인스턴스를 갖춘 Auto Scaling group을 생성합니다. 스케줄드 이벤트를 생성해 ECS 작업을 실행합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 운영 및 관리해야 하므로 운영 노력과 비용이 증가해 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q1",
      "Q626",
      "Q43",
      "Q501",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ],
    "SelectC_recommedations": [
      "Q695",
      "Q957",
      "Q515"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q257",
      "Q695"
    ]
  },
  {
    "Question_Number": "Q398",
    "Question_Description": "한 회사가 온프레미스 NAS(Network-Attached Storage) 시스템에 저장된 600TB 데이터를 AWS Cloud로 전송해야 합니다. 전체 전송은 2주 이내에 완료되어야 하며, 데이터는 전송 중 암호화되어야 합니다. 회사의 인터넷 연결은 100Mbps 업로드 속도를 지원합니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102166-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량 데이터(600TB)를 2주라는 짧은 시간 안에 안전하게(암호화) AWS로 전송하는 데 있어, 인터넷만으로는 속도가 부족하고 Direct Connect는 개설까지 시간이 오래 걸린다는 점이 핵심입니다. AWS Snowball Edge Storage Optimized 디바이스를 사용하면 물리 장치를 통해 빠르고 안전하며 비용 효율적으로 대량 데이터를 전송할 수 있어 요구 사항에 부합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "온프레미스 NAS",
      "600TB 데이터",
      "2주 이내",
      "암호화",
      "100Mbps",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3 Multi-part Upload",
      "HTTPS",
      "VPN",
      "AWS Snow Family",
      "AWS Snowball Edge Storage Optimized",
      "AWS Direct Connect",
      "10 Gbps",
      "Encryption in transit"
    ],
    "SelectA": "Amazon S3의 Multi-part Upload 기능을 이용해 HTTPS로 파일을 전송합니다.",
    "SelectA_Commentary": "인터넷만으로 600TB를 전송하려면 최대 속도로 전송해도 수백 일이 걸려 2주 마감에 맞출 수 없습니다.",
    "SelectB": "온프레미스 NAS 시스템과 가장 가까운 AWS 리전 간 VPN 연결을 생성해 데이터를 전송합니다.",
    "SelectB_Commentary": "VPN 또한 인터넷 대역폭(100Mbps)에 의존하므로 전송 시간이 지나치게 길어집니다.",
    "SelectC": "AWS Snow Family 콘솔에서 여러 AWS Snowball Edge Storage Optimized 디바이스를 주문하여 Amazon S3로 데이터를 전송합니다.",
    "SelectC_Commentary": "대용량 데이터를 물리 장치로 빠르게 전송할 수 있고, 전송 중 암호화도 제공하며, 직접 인터넷에 의존하지 않아 2주 이하 마감에 비용 측면에서도 가장 효율적입니다.",
    "SelectD": "회사 위치와 가장 가까운 AWS 리전 간 10Gbps AWS Direct Connect를 구축하고, 리전으로 VPN 전송하여 Amazon S3에 데이터를 저장합니다.",
    "SelectD_Commentary": "Direct Connect 구축에 걸리는 시간이 몇 주 이상 소요될 수 있어 2주 마감을 충족하기 어렵고 초기 비용도 큽니다.",
    "Question_Description_recommedations": [
      "Q215",
      "Q763",
      "Q583",
      "Q778",
      "Q617"
    ],
    "SelectA_recommedations": [
      "Q326",
      "Q285",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q284",
      "Q703",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q499",
      "Q835",
      "Q240"
    ]
  },
  {
    "Question_Number": "Q399",
    "Question_Description": "한 금융 회사가 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon API Gateway Regional API 엔드포인트를 사용하여 사용자들이 현재 주가를 조회할 수 있도록 합니다. 보안 팀은 최근 API 요청이 급증하고 있으며, HTTP flood 공격으로 인해 애플리케이션이 오프라인이 될 수 있다고 우려하고 있습니다. 솔루션스 아키텍트는 이러한 공격으로부터 애플리케이션을 보호하기 위한 방법을 설계해야 합니다. 운영 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102167-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS에서 호스팅되는 웹 애플리케이션에 대한 HTTP flood 공격을 효율적으로 차단하는 방법을 요구합니다. AWS WAF의 rate-based rule을 통해 요청 빈도를 제한하면 운영 오버헤드가 낮으면서도 효과적인 방어 전략을 구현할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "HTTP flood",
      "API Gateway",
      "AWS WAF",
      "rate-based rule",
      "Regional API",
      "web ACL"
    ],
    "Terms": [
      "Amazon API Gateway Regional API",
      "Amazon CloudFront",
      "TTL(Time to Live)",
      "Region",
      "AWS WAF web ACL",
      "rate-based rule",
      "API Gateway stage",
      "Amazon CloudWatch",
      "Lambda@Edge",
      "AWS Lambda"
    ],
    "SelectA": "Amazon CloudFront 배포를 API Gateway Regional API 엔드포인트 앞에 생성하고, 최대 TTL을 24시간으로 설정합니다.",
    "SelectA_Commentary": "CloudFront만으로는 요청 빈도를 제한하기 어렵고, TTL 설정으로 캐싱 효과를 얻을 순 있지만 HTTP flood 방어에 직접적인 도움이 되지 않습니다.",
    "SelectB": "Regional AWS WAF web ACL을 생성하고 rate-based rule을 설정합니다. 이 web ACL을 API Gateway 스테이지에 연결합니다.",
    "SelectB_Commentary": "AWS WAF의 rate-based rule로 특정 IP에서 발생하는 과도한 요청을 자동으로 차단할 수 있어 운영이 간소하고 효과적입니다.",
    "SelectC": "Amazon CloudWatch 지표에서 Count 메트릭을 모니터링하고, 사전에 정의된 임계치를 초과하면 보안 팀에게 알림을 보냅니다.",
    "SelectC_Commentary": "알림만으로는 공격을 자동으로 차단할 수 없어 즉각적인 방어가 어렵고 운영 오버헤드가 증가합니다.",
    "SelectD": "Amazon CloudFront와 Lambda@Edge를 API Gateway Regional API 엔드포인트 앞에 생성합니다. 요청 횟수가 임계치를 초과하는 IP 주소를 차단하는 AWS Lambda 함수를 만듭니다.",
    "SelectD_Commentary": "Lambda@Edge로 직접 IP 차단 로직을 구현해야 하므로 관리가 복잡하고, 구성 및 유지 보수에도 추가적인 오버헤드가 발생합니다.",
    "Question_Description_recommedations": [
      "Q1019",
      "Q34",
      "Q532",
      "Q623",
      "Q889"
    ],
    "SelectA_recommedations": [
      "Q855",
      "Q538",
      "Q172"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q399",
      "Q1019"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q893",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q159",
      "Q1019",
      "Q791"
    ]
  },
  {
    "Question_Number": "Q400",
    "Question_Description": "한 기상 스타트업 회사는 사용자들에게 온라인으로 날씨 데이터를 판매하기 위해 자체 웹 애플리케이션을 운영하고 있습니다. 이 회사는 Amazon DynamoDB를 사용하여 데이터를 저장하고 있으며, 새로운 날씨 이벤트가 기록될 때마다 사내 네 개 팀 관리자에게 알림을 전송하는 새로운 서비스를 구축하려고 합니다. 이 서비스가 기존 애플리케이션의 성능에 영향을 주지 않도록 해야 하며, 운영 오버헤드를 최소화해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102169-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 시스템에 부하를 주지 않고 새로운 이벤트 발생 시 사내 팀에 알림을 보내는 구조를 설계하는 질문입니다. 정답인 C를 이용하면 DynamoDB Streams를 통해 테이블의 변경 사항을 실시간으로 감지하고 트리거로 SNS에 전달하여 알림을 간소화하고, 운영 오버헤드 역시 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "기상 스타트업",
      "새로운 날씨 이벤트",
      "알림 전송",
      "기존 애플리케이션 성능",
      "운영 오버헤드 최소화",
      "DynamoDB Streams"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "DynamoDB Streams",
      "Amazon SNS",
      "Amazon SQS",
      "DynamoDB transactions",
      "cron job",
      "트리거"
    ],
    "SelectA": "DynamoDB transactions를 사용하여 테이블에 새로운 이벤트 데이터를 작성하고, 내부 팀에게 알리도록 설정합니다.",
    "SelectA_Commentary": "Transactions 자체는 데이터 무결성 보장에 적합하지만, 알림 시스템 구성 기능은 없으므로 이벤트 알림용으로는 복잡하며 기존 애플리케이션에 부하가 늘어날 수 있습니다.",
    "SelectB": "현재 애플리케이션에서 4개의 Amazon SNS 토픽에 메시지를 게시하고, 각 팀이 하나의 토픽을 구독하도록 합니다.",
    "SelectB_Commentary": "팀별로 별도의 SNS 토픽 생성과 게시 로직 구현이 필요해 운영 및 관리가 늘어나며, 확장성 측면에서 오버헤드가 커질 수 있습니다.",
    "SelectC": "테이블에서 Amazon DynamoDB Streams를 활성화하고 트리거를 사용하여 하나의 Amazon SNS 토픽에 쓰도록 하며, 팀들이 그 토픽을 구독하도록 합니다.",
    "SelectC_Commentary": "DynamoDB Streams로 변경 사항을 실시간 감지하고 트리거 SNS 연동을 통해 간단히 여러 팀에 동시에 알림을 보낼 수 있어 운영 오버헤드를 최소화합니다.",
    "SelectD": "각 레코드에 새 아이템임을 표시하는 커스텀 속성을 추가하고, 매분 테이블을 스캔해 새 아이템을 찾아 Amazon SQS 큐에 알리는 cron job을 작성합니다.",
    "SelectD_Commentary": "테이블을 주기적으로 스캔하는 것은 비효율적이며, 빈번한 스캔으로 인해 성능 부담과 비용이 증가할 위험이 큽니다.",
    "Question_Description_recommedations": [
      "Q1002",
      "Q114",
      "Q845",
      "Q768",
      "Q1014"
    ],
    "SelectA_recommedations": [
      "Q1002",
      "Q845",
      "Q78"
    ],
    "SelectB_recommedations": [
      "Q615",
      "Q967",
      "Q362"
    ],
    "SelectC_recommedations": [
      "Q1002",
      "Q78",
      "Q489"
    ],
    "SelectD_recommedations": [
      "Q820",
      "Q784",
      "Q110"
    ]
  },
  {
    "Question_Number": "Q401",
    "Question_Description": "한 회사가 기존 애플리케이션을 AWS Cloud로 이전하여 고가용성과 복원력을 확보하고자 합니다. 현재 애플리케이션은 회사 데이터 센터에 있으며, 최근 예상치 못한 정전으로 데이터베이스 서버가 다운되어 데이터 손실이 발생했습니다. 회사는 단일 장애 지점(SPOF)을 방지해야 하고 사용자 수요에 맞춰 확장 가능한 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102170-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 서버와 데이터베이스 모두를 여러 AZ에 분산 배치하여 단일 장애 지점을 제거하고, Auto Scaling으로 확장성을 확보하는 솔루션을 요구합니다. Amazon RDS Multi-AZ 구조는 장애 발생 시 자동으로 장애 조치(Failover)를 수행하여 데이터 손실 위험을 크게 줄이고, 애플리케이션 중단 시간을 최소화합니다. 따라서 고가용성과 확장성을 함께 제공할 수 있는 구성이 필요합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "복원력",
      "데이터 손실 방지",
      "Auto Scaling",
      "Multi-AZ"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon RDS",
      "Multi-AZ configuration",
      "read replica",
      "Amazon EBS Multi-Attach"
    ],
    "SelectA": "여러 가용 영역에 걸친 Auto Scaling 그룹으로 Amazon EC2 인스턴스에 애플리케이션 서버를 배포합니다. Amazon RDS DB 인스턴스를 Multi-AZ 구성으로 사용합니다.",
    "SelectA_Commentary": "애플리케이션 서버와 DB 모두 다중 AZ에 배포되어 단일 장애 지점을 제거하며, 장애 상황에서도 RDS Multi-AZ를 통해 데이터 손실과 다운타임을 최소화할 수 있습니다.",
    "SelectB": "단일 가용 영역에 있는 Auto Scaling 그룹으로 Amazon EC2 인스턴스에 애플리케이션 서버를 배포합니다. Amazon EC2 인스턴스에 데이터베이스를 구축하고 EC2 Auto Recovery를 활성화합니다.",
    "SelectB_Commentary": "애플리케이션 서버와 데이터베이스가 단일 AZ에 있어 여전히 단일 장애 지점 위험이 크며, 데이터베이스의 고가용성과 자동 장애 조치를 보장하기 어렵습니다.",
    "SelectC": "여러 가용 영역에 걸친 Auto Scaling 그룹으로 Amazon EC2 인스턴스에 애플리케이션 서버를 배포합니다. 단일 가용 영역에서 Amazon RDS DB 인스턴스와 read replica를 구성하고, 장애 발생 시 read replica를 승격하여 주 DB 인스턴스를 대체합니다.",
    "SelectC_Commentary": "DB 본체와 replica가 동일 AZ 내에만 존재하므로 AZ 장애 시 보호가 되지 않습니다. 복원력 확보에 한계가 있습니다.",
    "SelectD": "여러 가용 영역에 걸친 Auto Scaling 그룹으로 Amazon EC2 인스턴스에 애플리케이션 서버를 배포합니다. 여러 AZ에 위치한 EC2 인스턴스에 기본·보조 데이터베이스 서버를 배포하고 Amazon EBS Multi-Attach로 공유 스토리지를 구성합니다.",
    "SelectD_Commentary": "Amazon EBS Multi-Attach는 같은 AZ 내에서만 동시 연결을 지원하며, 단일 EBS 볼륨은 장애 시 SPOF(단일 장애 지점)가 될 수 있어 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q1014",
      "Q802",
      "Q149",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q390",
      "Q466",
      "Q768"
    ],
    "SelectB_recommedations": [
      "Q581",
      "Q210",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q276",
      "Q195",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q581",
      "Q595",
      "Q210"
    ]
  },
  {
    "Question_Number": "Q402",
    "Question_Description": "한 회사는 애플리케이션에서 대량의 스트리밍 데이터를 생성하며, 이 데이터를 Amazon EC2 인스턴스에서 Amazon Kinesis Data Streams(기본 설정)로 전송한 후 이틀에 한 번씩 데이터를 수집해 Amazon S3 버킷으로 전달하여 BI 처리를 수행하고 있습니다. 그러나 이틀마다 데이터를 S3로 옮길 때 모든 데이터가 S3에 도달하지 않는 문제가 발생하고 있습니다. 어떻게 해결해야 할까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102175-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "기본 설정으로 Kinesis Data Streams는 24시간 동안 데이터가 보관됩니다. 데이터를 이틀에 한 번씩 처리하려면 보관 기간을 늘려서 사라지지 않도록 해야 문제가 해결됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "Amazon Kinesis Data Streams",
      "Amazon S3",
      "기본 데이터 보관 기간",
      "스트리밍 데이터",
      "이틀 간격"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Kinesis Data Streams",
      "data retention period",
      "Kinesis Producer Library (KPL)",
      "shard",
      "Amazon S3",
      "S3 Versioning"
    ],
    "SelectA": "기본 Kinesis Data Streams 설정을 수정하여 data retention period를 늘립니다.",
    "SelectA_Commentary": "기본 24시간 보관 기간을 더 길게 설정하면 이틀에 한 번씩 데이터를 처리해도 데이터가 누락되지 않으므로 문제를 해결할 수 있습니다.",
    "SelectB": "애플리케이션이 데이터를 전송할 때 Kinesis Producer Library(KPL)를 사용하도록 업데이트합니다.",
    "SelectB_Commentary": "KPL은 효율적인 데이터 전송을 지원하지만, 데이터가 24시간 후에 삭제되는 문제 자체는 해결하지 못합니다.",
    "SelectC": "Kinesis shards 수를 늘려 Kinesis Data Streams에 전송되는 데이터 처리량을 처리하도록 업데이트합니다.",
    "SelectC_Commentary": "샤드 확장은 처리 용량 문제를 해결하지만, 보관 기간 문제 때문에 데이터가 유실되는 것은 막지 못합니다.",
    "SelectD": "S3 버킷에 S3 Versioning을 활성화해 버킷에 적재되는 모든 객체의 버전을 보존합니다.",
    "SelectD_Commentary": "S3 Versioning은 S3 내 버전 관리를 위한 것이며, Kinesis에서 데이터가 누락되는 문제 해결과 직접적인 연관이 없습니다.",
    "Question_Description_recommedations": [
      "Q680",
      "Q687",
      "Q155",
      "Q292",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q620",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q746",
      "Q77"
    ],
    "SelectC_recommedations": [
      "Q402",
      "Q695",
      "Q515"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q672",
      "Q292"
    ]
  },
  {
    "Question_Number": "Q403",
    "Question_Description": "한 개발자가 AWS Lambda 함수를 사용하여 Amazon S3에 파일을 업로드하는 애플리케이션을 보유하고 있습니다. 이 작업을 수행하기 위한 권한이 필요합니다. 해당 개발자는 이미 Amazon S3에 필요한 유효한 IAM 자격 증명을 보유한 IAM 사용자를 가지고 있습니다. 이 경우 어떤 조치를 취해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102178-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda 함수가 Amazon S3에 접근하기 위해 필요한 권한을 어떻게 구성해야 하는지를 묻습니다. 가장 적절한 방법은 IAM 역할을 생성하고 Lambda 함수에 연결하여 필요한 권한만 최소 권한으로 부여하는 것입니다. 이를 통해 Lambda 함수는 실행 시 필요한 자격 증명을 임시로 받게 되며, 보안 모범 사례를 준수할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Lambda 함수",
      "Amazon S3",
      "IAM 권한",
      "IAM 역할",
      "파일 업로드"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "IAM User",
      "IAM Role",
      "Resource Policy",
      "Signed Request"
    ],
    "SelectA": "Lambda 함수의 리소스 정책(resource policy)에 필요한 IAM 권한을 추가합니다.",
    "SelectA_Commentary": "Lambda 함수의 리소스 정책만으로는 Amazon S3에 대한 세분화된 IAM 권한을 안전하게 부여하기 어렵습니다.",
    "SelectB": "Lambda 함수에서 기존 IAM 자격 증명을 사용하여 서명된 요청을 생성합니다.",
    "SelectB_Commentary": "서명된 요청 방식은 별도 관리가 필요하여 유지보수 부담이 크며 모범 사례가 아닙니다.",
    "SelectC": "새로운 IAM 사용자를 생성하고, Lambda 함수에서 기존 IAM 자격 증명을 재사용합니다.",
    "SelectC_Commentary": "IAM 사용자를 추가로 만드는 것은 불필요하며, Lambda용 권한 설정 방식과 맞지 않습니다.",
    "SelectD": "필요한 권한이 있는 IAM 실행 역할을 생성하고 해당 IAM 역할을 Lambda 함수에 연결합니다.",
    "SelectD_Commentary": "Lambda 함수는 실행 역할을 통해 최소 권한만을 안전하게 위임받아 Amazon S3에 업로드 작업을 수행할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q289",
      "Q982",
      "Q477",
      "Q222",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q936",
      "Q423",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q476",
      "Q936"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ]
  },
  {
    "Question_Number": "Q404",
    "Question_Description": "한 회사가 새로운 문서가 Amazon S3 버킷에 업로드될 때 AWS Lambda 함수가 호출되는 serverless application을 배포했습니다. 애플리케이션은 Lambda 함수를 사용해 문서를 처리합니다. 최근 마케팅 캠페인 이후, 회사는 애플리케이션이 많은 문서를 제대로 처리하지 못했다는 점을 발견했습니다. 솔루션 아키텍트가 이 애플리케이션의 아키텍처를 어떻게 개선해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102180-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "문서 업로드가 급격히 증가한 상황에서 Lambda 함수가 일부 문서를 놓쳤습니다. Amazon SQS를 사용해 메시지를 큐에 저장하고 비동기로 처리하면 요청 손실을 방지하고 안정적으로 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "서버리스 애플리케이션",
      "Amazon S3 버킷",
      "AWS Lambda 함수",
      "문서 처리",
      "Amazon Simple Queue Service(Amazon SQS)",
      "이벤트 소스"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "Amazon Simple Queue Service(Amazon SQS)",
      "S3 replication policy",
      "Lambda runtime timeout"
    ],
    "SelectA": "Lambda 함수의 runtime timeout 값을 15분으로 설정합니다.",
    "SelectA_Commentary": "타임아웃만 증가하면 트래픽 급증 시 발생하는 처리 누락을 근본적으로 방지하지 못합니다.",
    "SelectB": "S3 버킷 replication policy를 구성하고, S3 버킷에 문서를 보관했다가 나중에 처리합니다.",
    "SelectB_Commentary": "Replication은 객체를 다른 버킷으로 복제하는 방식일 뿐, 처리 누락 문제를 직접 해결하지 못합니다.",
    "SelectC": "추가적인 Lambda 함수를 배포하고, 두 Lambda 함수에 문서 처리를 분산합니다.",
    "SelectC_Commentary": "Lambda는 자동 확장되므로 함수 자체를 더 늘리는 것만으로는 처리 누락을 방지하기 어렵습니다.",
    "SelectD": "Amazon Simple Queue Service(Amazon SQS) 큐를 만들고 요청을 큐로 보낸 뒤, 해당 큐를 Lambda의 이벤트 소스로 설정합니다.",
    "SelectD_Commentary": "큐를 사용해 Lambda와 S3 간의 결합을 느슨하게 하고, 급증하는 트래픽에도 문서를 안정적으로 수집·처리할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q785",
      "Q18",
      "Q45",
      "Q98",
      "Q636"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q845",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q891",
      "Q188",
      "Q784"
    ],
    "SelectC_recommedations": [
      "Q187",
      "Q785",
      "Q917"
    ],
    "SelectD_recommedations": [
      "Q98",
      "Q636",
      "Q203"
    ]
  },
  {
    "Question_Number": "Q405",
    "Question_Description": "한 솔루션스 아키텍트가 소프트웨어 데모 환경을 위한 아키텍처를 설계하고 있습니다. 이 환경은 Application Load Balancer(ALB) 뒤의 Auto Scaling group 내 Amazon EC2 인스턴스에서 실행될 예정입니다. 이 시스템은 업무 시간 동안에는 트래픽이 크게 증가하지만 주말에는 동작할 필요가 없습니다. 시스템이 수요를 충족하기 위해 확장될 수 있도록 솔루션스 아키텍트가 취해야 할 조치는 무엇입니까? (두 개를 선택하십시오.)",
    "Answer": "D,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102181-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 업무 시간에는 트래픽이 급증하고 주말에는 시스템이 필요 없는 상황을 효율적으로 확장하기 위한 아키텍처 설계를 묻습니다. Target Tracking Scaling Policy를 통해 트래픽 지표(예: CPU 활용도)에 맞춰 실시간으로 Auto Scaling group을 확장·축소할 수 있고, Scheduled Scaling을 통해 주말에는 인스턴스를 0으로 줄여 비용 절감과 운영 단순화를 동시에 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Target Tracking Scaling Policy",
      "Scheduled Scaling"
    ],
    "Terms": [
      "AWS Auto Scaling",
      "Application Load Balancer(ALB)",
      "Auto Scaling group",
      "Amazon EC2",
      "Target tracking scaling policy",
      "VPC internet gateway",
      "AWS Region",
      "Scheduled scaling"
    ],
    "SelectA": "AWS Auto Scaling으로 ALB 용량을 요청 빈도 기반으로 조정합니다.",
    "SelectA_Commentary": "ALB 자체 용량은 AWS Auto Scaling으로 직접 조정할 수 없어 적절한 솔루션이 아닙니다.",
    "SelectB": "AWS Auto Scaling으로 VPC internet gateway 용량을 확장합니다.",
    "SelectB_Commentary": "VPC internet gateway는 Auto Scaling 대상이 아니므로 관련이 없는 옵션입니다.",
    "SelectC": "여러 AWS Region에 EC2 인스턴스를 실행해 부하를 분산합니다.",
    "SelectC_Commentary": "Region 간 분산은 필수 사항이 아니며, 트래픽 패턴에 맞는 단순 확장과 무관합니다.",
    "SelectD": "인스턴스 CPU 사용량 기반 Target Tracking Scaling Policy를 사용해 Auto Scaling group을 확장합니다.",
    "SelectD_Commentary": "업무 시간 트래픽 급증을 자동으로 대응하기 위한 적합한 확장 방식이며 정답입니다.",
    "SelectE": "Scheduled Scaling을 사용해 주말에는 Auto Scaling group의 최소·최대·원하는 용량을 0으로 설정하고, 주중에는 기본값으로 복원합니다.",
    "SelectE_Commentary": "주말에는 불필요한 인스턴스를 모두 중지해 비용을 절감할 수 있는 방법으로 정답입니다.",
    "Question_Description_recommedations": [
      "Q275",
      "Q595",
      "Q174",
      "Q581",
      "Q846"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q174",
      "Q589"
    ],
    "SelectB_recommedations": [
      "Q29",
      "Q708",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q456",
      "Q194",
      "Q224"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q595",
      "Q342"
    ],
    "SelectE_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q406",
    "Question_Description": "한 솔루션스 아키텍트가 퍼블릭 서브넷과 데이터베이스 서브넷으로 구성된 2티어 아키텍처를 설계하고 있습니다. 퍼블릭 서브넷에 있는 웹 서버는 포트 443을 통해 인터넷에 개방되어야 합니다. 데이터베이스 서브넷에 있는 Amazon RDS for MySQL DB 인스턴스는 포트 3306을 통해 오직 웹 서버만 액세스할 수 있어야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트가 취해야 할 단계 조합은 무엇입니까? (두 개를 선택하십시오.)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102183-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 퍼블릭 서브넷의 웹 서버와 데이터베이스 서브넷에 위치한 Amazon RDS 리소스 간 안전한 통신 경로를 설계하는 데 대한 질문입니다. 웹 서버는 외부 인터넷에서 HTTPS(443)로 접근 가능해야 하며, MySQL 포트(3306)는 웹 서버에서만 접근 가능하도록 설정해야 합니다. Security Group에서는 명시적으로 허용 규칙만 설정할 수 있고, IP나 다른 보안 그룹을 출처로 지정하여 트래픽을 허용합니다. 따라서 웹 서버 보안 그룹에는 포트 443에 대한 인바운드 허용 규칙이 필요하고, DB 인스턴스 보안 그룹은 오직 웹 서버 보안 그룹에서 오는 포트 3306 트래픽만 허용해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "2티어 아키텍처",
      "퍼블릭 서브넷",
      "데이터베이스 서브넷",
      "포트 443",
      "Amazon RDS for MySQL DB",
      "포트 3306",
      "Security Group",
      "Network ACL"
    ],
    "Terms": [
      "Security Group",
      "Network ACL",
      "Amazon RDS",
      "MySQL",
      "CIDR block",
      "포트 443",
      "포트 3306"
    ],
    "SelectA": "Create a network ACL for the public subnet. Add a rule to deny outbound traffic to 0.0.0.0/0 on port 3306.",
    "SelectA_Commentary": "네트워크 ACL로 모든 아웃바운드를 막는 방식은 과도하고, 실질적으로 DB 접근을 제한하는 방법으로는 Security Group을 사용하는 것이 적절합니다.",
    "SelectB": "Create a security group for the DB instance. Add a rule to allow traffic from the public subnet CIDR block on port 3306.",
    "SelectB_Commentary": "퍼블릭 서브넷의 전체 CIDR에서 들어오는 3306 트래픽을 허용하면, 해당 서브넷에 있는 웹 서버 이외의 리소스도 접근 가능하게 됩니다. 보다 제한적인 방법이 필요합니다.",
    "SelectC": "Create a security group for the web servers in the public subnet. Add a rule to allow traffic from 0.0.0.0/0 on port 443.",
    "SelectC_Commentary": "퍼블릭 서브넷 내 웹 서버가 인터넷 전체(0.0.0.0/0)에서의 HTTPS(443) 요청을 허용하기 위해 필요한 설정이며, 요구사항에 부합합니다. (정답)",
    "SelectD": "Create a security group for the DB instance. Add a rule to allow traffic from the web servers’ security group on port 3306.",
    "SelectD_Commentary": "DB 인스턴스로 포트 3306 트래픽을 오직 웹 서버 보안 그룹에서만 받도록 허용하는 설정이므로 적절한 접근 제어 방식입니다. (정답)",
    "SelectE": "Create a security group for the DB instance. Add a rule to deny all traffic except traffic from the web servers’ security group on port 3306.",
    "SelectE_Commentary": "Security Group은 'Deny'를 설정할 수 없고 'Allow' 규칙만 설정할 수 있습니다. 이 방식은 SG 모델과 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q330",
      "Q732",
      "Q742",
      "Q61",
      "Q847"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q875",
      "Q385"
    ],
    "SelectB_recommedations": [
      "Q74",
      "Q385",
      "Q406"
    ],
    "SelectC_recommedations": [
      "Q385",
      "Q774",
      "Q644"
    ],
    "SelectD_recommedations": [
      "Q74",
      "Q406",
      "Q385"
    ],
    "SelectE_recommedations": [
      "Q74",
      "Q406",
      "Q385"
    ]
  },
  {
    "Question_Number": "Q407",
    "Question_Description": "한 회사가 AWS Cloud에서 호스팅되는 게임 애플리케이션을 위해 공유 스토리지 솔루션을 구현하려고 합니다. 회사는 Lustre 클라이언트를 사용하여 데이터에 액세스해야 하며, 솔루션은 완전 관리형이어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102184-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Lustre 프로토콜을 지원하는 완전 관리형 공유 스토리지 솔루션이 필요하므로 Amazon FSx for Lustre가 정답입니다. 고성능 컴퓨팅 환경에서 Lustre 클라이언트를 통한 간편한 파일 액세스를 지원합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "공유 스토리지 솔루션",
      "게임 애플리케이션",
      "Lustre 클라이언트",
      "완전 관리형",
      "AWS Cloud"
    ],
    "Terms": [
      "AWS DataSync",
      "AWS Storage Gateway",
      "Amazon EFS",
      "Amazon FSx for Lustre"
    ],
    "SelectA": "AWS DataSync 태스크를 생성하여 마운트 가능한 파일 시스템으로 데이터를 공유하고, 이를 애플리케이션 서버에 마운트합니다.",
    "SelectA_Commentary": "DataSync는 데이터 복제나 전송을 자동화해 주지만 Lustre 프로토콜 기반의 완전 관리형 파일 시스템을 제공하지 않으므로 오답입니다.",
    "SelectB": "AWS Storage Gateway 파일 게이트웨이를 생성합니다. 필요한 클라이언트 프로토콜을 사용하도록 파일 공유를 생성하고 애플리케이션 서버를 연결합니다.",
    "SelectB_Commentary": "Storage Gateway는 온프레미스 환경과 AWS 간 파일 공유가 주 목적이며 Lustre 호환을 지원하지 않아 이 요구사항을 충족할 수 없습니다.",
    "SelectC": "Amazon EFS 파일 시스템을 생성하고 Lustre를 지원하도록 구성합니다. 원본 서버에 파일 시스템을 연결하고 애플리케이션 서버를 연결합니다.",
    "SelectC_Commentary": "Amazon EFS는 NFS 기반이며 Lustre가 아닌 프로토콜을 사용하므로 문제에서 요구하는 Lustre 클라이언트 지원 요건을 충족하지 못합니다.",
    "SelectD": "Amazon FSx for Lustre 파일 시스템을 생성합니다. 원본 서버에 파일 시스템을 연결하고 애플리케이션 서버를 연결합니다.",
    "SelectD_Commentary": "Amazon FSx for Lustre는 완전 관리형 Lustre 파일 시스템을 제공하므로 요구사항(고성능, Lustre 프로토콜, 완전 관리형)에 정확히 부합하는 정답입니다.",
    "Question_Description_recommedations": [
      "Q631",
      "Q361",
      "Q443",
      "Q568",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q155",
      "Q472",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q173",
      "Q155"
    ],
    "SelectC_recommedations": [
      "Q99",
      "Q407",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q99",
      "Q407",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q408",
    "Question_Description": "한 회사가 UDP를 사용하는 전 세계 여러 지역에 분산된 수천 개의 원격 디바이스로부터 데이터를 수신하는 애플리케이션을 운영하고 있습니다. 애플리케이션은 데이터를 즉시 처리하고, 필요한 경우 디바이스로 메시지를 다시 전송합니다. 별도의 데이터 저장은 하지 않습니다. 회사는 디바이스에서 전송되는 데이터의 지연 시간을 최소화해야 하며, 다른 AWS Region으로 신속한 페일오버를 지원해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102185-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "UDP 트래픽을 지원하면서 전 세계에서 들어오는 데이터를 빠르게 처리하고, Region 간 페일오버를 위해서는 AWS Global Accelerator와 NLB 구성이 필수적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2",
      "3.4"
    ],
    "Keywords": [
      "UDP",
      "지연 시간 최소화",
      "Global Accelerator",
      "Network Load Balancer(NLB)",
      "빠른 페일오버"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Amazon Route 53",
      "Failover Routing Policy",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "UDP"
    ],
    "SelectA": "Amazon Route 53의 Failover Routing Policy를 구성하고, 두 개의 Region 각각에 Network Load Balancer(NLB)를 생성한 뒤, Lambda 함수가 데이터를 처리하도록 구성합니다.",
    "SelectA_Commentary": "Failover 자체는 가능하지만 Global Accelerator 없이 Route 53만으로는 지연 시간을 최소화하기 어렵고, Lambda가 UDP 트래픽 처리에 직접적으로 최적화된 구성은 아닙니다.",
    "SelectB": "AWS Global Accelerator를 사용합니다. 두 개의 Region 각각에 Network Load Balancer(NLB)를 엔드포인트로 생성합니다. Fargate 유형의 Amazon ECS 클러스터를 만들어 ECS 서비스에서 데이터를 처리합니다.",
    "SelectB_Commentary": "UDP를 지원하는 NLB와 전 세계 Edge를 통한 Global Accelerator를 이용해 지연 시간을 짧게 유지하며, 한 Region에 장애가 발생해도 다른 Region으로 자동 페일오버가 가능합니다.",
    "SelectC": "AWS Global Accelerator를 사용합니다. 두 개의 Region 각각에 Application Load Balancer(ALB)를 엔드포인트로 생성합니다. Fargate 유형의 Amazon ECS 클러스터를 만들어 ECS 서비스에서 데이터를 처리합니다.",
    "SelectC_Commentary": "ALB는 기본적으로 UDP를 지원하지 않아 목적에 부적합합니다. ALB 대신 NLB를 사용해야 UDP 트래픽 처리가 가능합니다.",
    "SelectD": "Amazon Route 53의 Failover Routing Policy를 구성하고, 두 개의 Region 각각에 Application Load Balancer(ALB)를 생성합니다. Fargate 유형의 Amazon ECS 클러스터를 만들어 ECS 서비스에서 데이터를 처리합니다.",
    "SelectD_Commentary": "마찬가지로 ALB는 UDP 처리에 적합하지 않으며, Global Accelerator 없이 Route 53만으로는 지연 시간 단축 효과가 제한적입니다.",
    "Question_Description_recommedations": [
      "Q700",
      "Q8",
      "Q987",
      "Q802",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q447",
      "Q836"
    ],
    "SelectB_recommedations": [
      "Q698",
      "Q303",
      "Q575"
    ],
    "SelectC_recommedations": [
      "Q698",
      "Q303",
      "Q639"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q698",
      "Q303"
    ]
  },
  {
    "Question_Number": "Q409",
    "Question_Description": "한 솔루션스 아키텍트는 Windows Internet Information Services(IIS) 웹 애플리케이션을 AWS로 마이그레이션해야 합니다. 현재 애플리케이션은 온프레미스 Network-Attached Storage(NAS)에 호스팅된 파일 공유를 사용하고 있습니다. 솔루션스 아키텍트는 다중 Availability Zone에 있는 Amazon EC2 인스턴스에 IIS 웹 서버를 이전하고, 해당 스토리지 솔루션에 연결한 다음, 이 인스턴스들에 Elastic Load Balancer를 붙이는 방안을 제안했습니다. 이때 온프레미스 파일 공유를 대체할 가장 탄력적이고 내구성이 높은 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102186-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows 환경의 파일 공유를 클라우드로 옮길 때, 가장 높은 탄력성과 내구성을 제공하는 서비스를 선택하는 것입니다. Amazon FSx for Windows File Server는 Windows 기반 파일 시스템에 최적화되어 있으므로 가장 적합한 대안입니다. RDS는 데이터베이스 서비스, Storage Gateway는 하이브리드 환경용이며, EFS는 Linux 워크로드에 적합하므로 이 요구사항을 충족하기 어렵습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Windows IIS",
      "파일 공유",
      "Amazon FSx for Windows File Server",
      "탄력성",
      "내구성"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic Load Balancer",
      "Amazon RDS",
      "AWS Storage Gateway",
      "Amazon FSx for Windows File Server",
      "Amazon Elastic File System(Amazon EFS)"
    ],
    "SelectA": "파일 공유를 Amazon RDS로 마이그레이션합니다.",
    "SelectA_Commentary": "RDS는 데이터베이스용 관리형 서비스입니다. 파일 공유 요구사항을 처리하기에는 부적합하므로 정답이 아닙니다.",
    "SelectB": "파일 공유를 AWS Storage Gateway로 마이그레이션합니다.",
    "SelectB_Commentary": "Storage Gateway는 온프레미스와 AWS 간의 하이브리드 저장소 연결에 유용하지만, 완전한 클라우드 기반 파일 공유 대체로는 다소 제한적입니다.",
    "SelectC": "파일 공유를 Amazon FSx for Windows File Server로 마이그레이션합니다.",
    "SelectC_Commentary": "Windows 파일 환경에 최적화된 완전관리형 서비스로, 필요한 확장성과 내구성을 제공하므로 가장 적합한 솔루션입니다.",
    "SelectD": "파일 공유를 Amazon Elastic File System(Amazon EFS)로 마이그레이션합니다.",
    "SelectD_Commentary": "EFS는 주로 Linux 기반 워크로드에 적합합니다. Windows 환경에 특화된 기능을 완전히 제공하지 않으므로 부적합합니다.",
    "Question_Description_recommedations": [
      "Q186",
      "Q654",
      "Q357",
      "Q5",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q108",
      "Q863",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q8",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q618",
      "Q54",
      "Q972"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q194",
      "Q102"
    ]
  },
  {
    "Question_Number": "Q410",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에 새로운 애플리케이션을 배포하고 있습니다. 애플리케이션은 Amazon Elastic Block Store (Amazon EBS) 볼륨에 데이터를 기록합니다. 회사는 EBS 볼륨에 기록되는 모든 데이터가 저장 시 암호화(encrypted at rest)되어야 함을 보장해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102187-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EBS 볼륨이 생성되는 시점부터 암호화 기능을 활성화해 저장되는 모든 데이터를 자동으로 암호화하는 것이 핵심입니다. IAM 역할이나 인스턴스 태그, KMS 키 정책만으로는 볼륨이 실제로 암호화되지 않을 수 있으므로, 볼륨 자체를 암호화된 상태로 생성하여 연결하는 방법이 가장 확실하고 간단합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon EBS",
      "Amazon EC2",
      "암호화",
      "encrypted at rest",
      "EBS 볼륨"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EBS 암호화",
      "IAM Role",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key (CMK)"
    ],
    "SelectA": "IAM 역할을 생성하여 EBS 암호화를 지정하고 이를 EC2 인스턴스에 연결합니다.",
    "SelectA_Commentary": "IAM 역할 부착만으로는 EBS 볼륨 암호화를 강제할 수 없어 요구사항을 충족하지 못합니다.",
    "SelectB": "EBS 볼륨을 암호화된 볼륨으로 생성하고 이를 EC2 인스턴스에 연결합니다.",
    "SelectB_Commentary": "저장되는 모든 데이터가 자동으로 암호화되어 요구사항을 충족하는 정답입니다.",
    "SelectC": "Encrypt라는 키와 True라는 값을 가진 EC2 인스턴스 태그를 생성하고, EBS 암호화가 필요한 인스턴스에 태그를 지정합니다.",
    "SelectC_Commentary": "인스턴스 태그만으로는 EBS 볼륨 암호화를 강제할 수 없습니다.",
    "SelectD": "AWS KMS 키 정책을 생성하여 계정 전체에서 EBS 암호화를 적용하도록 하고, 키 정책을 활성 상태로 유지합니다.",
    "SelectD_Commentary": "KMS 키 정책은 키 사용 조건을 정의하지만, 볼륨 자체를 실제로 암호화하려면 생성 단계에서 별도 설정이 필요합니다.",
    "Question_Description_recommedations": [
      "Q675",
      "Q998",
      "Q681",
      "Q977",
      "Q710"
    ],
    "SelectA_recommedations": [
      "Q689",
      "Q96",
      "Q222"
    ],
    "SelectB_recommedations": [
      "Q689",
      "Q682",
      "Q675"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q682",
      "Q410"
    ],
    "SelectD_recommedations": [
      "Q371",
      "Q681",
      "Q550"
    ]
  },
  {
    "Question_Number": "Q411",
    "Question_Description": "한 회사는 사용 패턴이 비정기적인 웹 애플리케이션을 보유하고 있습니다. 매월 초에는 사용량이 매우 많고, 매주 초에는 중간 정도의 사용량이 있으며, 주중에는 예측 불가능한 사용량을 보입니다. 애플리케이션은 웹 서버와 MySQL 데이터베이스 서버로 구성되어 있으며, 현재 온프레미스 데이터 센터에서 실행 중입니다. 회사는 해당 애플리케이션을 AWS Cloud로 이전하고자 하며, 데이터베이스 수정 없이 비용 효율적인 데이터베이스 플랫폼을 선택해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102188-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용량이 크게 변동되는 웹 애플리케이션에 적합한 비용 효율적인 MySQL 호환 데이터베이스를 찾는 문제입니다. Aurora Serverless는 사용 패턴에 따라 자동으로 확장·축소되므로 과금이 유연하고, 기존 MySQL 애플리케이션을 그대로 이전할 수 있어 최적의 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "비정기적 사용 패턴",
      "월초 집중 사용",
      "MySQL 호환",
      "비용 효율",
      "Aurora Serverless"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Amazon RDS for MySQL",
      "MySQL-compatible Amazon Aurora Serverless",
      "MySQL on Amazon EC2",
      "Auto Scaling group"
    ],
    "SelectA": "Amazon DynamoDB",
    "SelectA_Commentary": "DynamoDB는 NoSQL 서비스로 MySQL 스키마를 그대로 옮기기 어려우며 호환성이 낮습니다.",
    "SelectB": "Amazon RDS for MySQL",
    "SelectB_Commentary": "RDS 인스턴스 크기가 고정되어 있어, 사용량이 적거나 많아져도 유연한 비용 최적화가 어렵습니다.",
    "SelectC": "MySQL-compatible Amazon Aurora Serverless",
    "SelectC_Commentary": "사용량에 따라 자동으로 확장·축소되어 과금이 유연하고, MySQL 애플리케이션과 호환 가능합니다. 정답입니다.",
    "SelectD": "MySQL을 Amazon EC2에서 Auto Scaling group으로 배포",
    "SelectD_Commentary": "EC2 상에 직접 MySQL을 운영하면 관리 부하가 크고, 스케일링 및 비용 관리가 상대적으로 복잡합니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q728",
      "Q985",
      "Q525",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q79",
      "Q348",
      "Q670"
    ],
    "SelectB_recommedations": [
      "Q574",
      "Q449",
      "Q128"
    ],
    "SelectC_recommedations": [
      "Q128",
      "Q827",
      "Q449"
    ],
    "SelectD_recommedations": [
      "Q290",
      "Q937",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q412",
    "Question_Description": "한 이미지 호스팅 회사가 Amazon S3 버킷에 객체를 저장하고 있습니다. 회사는 S3 버킷의 객체가 실수로 퍼블릭하게 노출되는 것을 방지하고 싶어 합니다. AWS 계정 전체에서 모든 S3 객체가 비공개 상태를 유지해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102189-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 계정 내 모든 S3 객체를 실수로 퍼블릭하게 노출하지 않도록 제어하는 최적의 방안을 묻습니다. 가장 근본적이고 적극적인 접근은 계정 수준에서 S3 Block Public Access를 활성화하고, AWS Organizations의 SCP로 해당 설정을 변경하지 못하도록 제한해 사전에 위험을 차단하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "S3 버킷",
      "퍼블릭 노출 방지",
      "계정 전체 비공개",
      "S3 Block Public Access"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Block Public Access",
      "Amazon GuardDuty",
      "AWS Trusted Advisor",
      "AWS Resource Access Manager",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Lambda",
      "AWS Organizations",
      "Service Control Policy (SCP)"
    ],
    "SelectA": "Amazon GuardDuty로 S3 버킷 정책을 모니터링하고, 퍼블릭 설정 변경 시 자동 수정하는 AWS Lambda 기반 룰을 생성합니다.",
    "SelectA_Commentary": "GuardDuty는 위협 감지 서비스로 모니터링 관점이며, 정책 수정 발생 후 대응하는 방식이므로 사전적 차단 효과가 부족합니다.",
    "SelectB": "AWS Trusted Advisor로 퍼블릭 접근이 가능한 S3 버킷을 찾고, 변경 시 이메일 알림을 설정합니다. 퍼블릭 액세스가 허용되면 수동으로 버킷 정책을 변경합니다.",
    "SelectB_Commentary": "수동 조치가 필요하므로 실수 가능성을 완전히 제거하기 어렵고, 즉각적이고 근본적인 통제가 어렵습니다.",
    "SelectC": "AWS Resource Access Manager로 퍼블릭 접근이 가능한 S3 버킷을 찾습니다. 변경 사항이 감지되면 Amazon SNS를 통해 AWS Lambda 함수를 호출하여 자동으로 수정합니다.",
    "SelectC_Commentary": "이 방법 역시 변경 후에 수정하는 방식이며, 계정 전체 퍼블릭 액세스를 완전 차단하지 못해 선제적 제어가 부족합니다.",
    "SelectD": "계정 수준에서 S3 Block Public Access 기능을 사용합니다. AWS Organizations로 Service Control Policy(SCP)를 생성하여 IAM 사용자가 해당 설정을 변경하지 못하도록 합니다. 이 SCP를 계정에 적용합니다.",
    "SelectD_Commentary": "S3 Block Public Access를 통해 모든 퍼블릭 액세스를 사전에 차단하고, SCP로 이를 수정할 수 없게 만들어 근본적으로 노출 위험을 방지합니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q109",
      "Q202",
      "Q638",
      "Q965"
    ],
    "SelectA_recommedations": [
      "Q289",
      "Q965",
      "Q270"
    ],
    "SelectB_recommedations": [
      "Q270",
      "Q412",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q289",
      "Q862",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q3",
      "Q494",
      "Q709"
    ]
  },
  {
    "Question_Number": "Q413",
    "Question_Description": "한 전자상거래 회사에서 사용자 트래픽이 증가하고 있습니다. 회사의 스토어는 Amazon EC2 인스턴스에서 동작하는 웹 티어와 별도의 데이터베이스 티어로 구성된 2계층 웹 애플리케이션입니다. 트래픽이 증가함에 따라, 아키텍처가 마케팅 메일과 주문 확인 메일을 적시에 발송하는 데 심각한 지연을 일으키고 있다는 점을 발견했습니다. 회사는 복잡한 이메일 전달 문제를 해결하는 데 소요되는 시간을 줄이고 운영 오버헤드를 최소화하려고 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/102190-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 증가한 트래픽으로 인해 발생하는 이메일 전송 지연을 해결하면서, 복잡한 설정과 운영 부담을 줄이는 방법이 핵심입니다. Amazon SES를 사용하면 별도 인프라 운영 없이 간편하게 마케팅 및 주문 확인 메일을 신속하고 안정적으로 보낼 수 있어, 복잡한 이메일 인프라 구성이나 평판 관리를 직접 할 필요가 없습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EC2",
      "이메일 발송 지연",
      "마케팅 메일",
      "주문 확인 메일",
      "운영 오버헤드 최소화",
      "Amazon Simple Email Service (Amazon SES)"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon SES",
      "Amazon SNS",
      "Auto Scaling group",
      "이메일 발송"
    ],
    "SelectA": "이메일 처리 전용 Amazon EC2 인스턴스를 사용하는 별도의 애플리케이션 티어를 구성합니다.",
    "SelectA_Commentary": "직접 EC2 기반의 메일 전송 시스템을 구성하면 인프라 운영 부담과 메일 서버 관리가 필요해 운영 오버헤드가 오히려 증가합니다.",
    "SelectB": "웹 인스턴스가 Amazon Simple Email Service(Amazon SES)를 통해 이메일을 전송하도록 구성합니다.",
    "SelectB_Commentary": "Amazon SES는 저비용, 확장성, 높은 전송 성공률을 제공하며, 이메일 인프라 관리를 대신해주므로 메일 전송 문제 해결에 소요되는 시간을 크게 줄이고 운영 부담도 완화합니다.",
    "SelectC": "웹 인스턴스가 Amazon Simple Notification Service(Amazon SNS)를 통해 이메일을 전송하도록 구성합니다.",
    "SelectC_Commentary": "Amazon SNS는 주로 주제 기반의 메시지 게시/구독에 적합하며, 대량 이메일 전송 기능보다는 알림 서비스 용도로 사용됩니다.",
    "SelectD": "이메일 처리 전용 Amazon EC2 인스턴스를 별도의 애플리케이션 티어로 구성하고 Auto Scaling group으로 구성합니다.",
    "SelectD_Commentary": "확장은 가능하지만 여전히 자체 메일 서버 운영 및 인프라 관리를 수행해야 해 문제 해결 시간이 줄어들지 않고 운영 오버헤드가 증가할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q252",
      "Q757",
      "Q244",
      "Q584",
      "Q110"
    ],
    "SelectA_recommedations": [
      "Q584",
      "Q194",
      "Q757"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q8",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q636",
      "Q148",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q414",
    "Question_Description": "한 회사에는 매일 수백 개의 보고서를 생성하는 비즈니스 시스템이 있습니다. 이 비즈니스 시스템은 CSV 형식의 보고서를 네트워크 공유 폴더에 저장합니다. 이 회사는 해당 데이터를 거의 실시간으로 분석하기 위해 AWS Cloud에 저장해야 합니다. 관리 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/103452-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 로컬 네트워크 공유 폴더에 저장되는 보고서를 Amazon S3에 거의 실시간으로 업로드하고, 관리 오버헤드를 최소화하는 방안을 찾는 것입니다. Amazon S3 File Gateway를 사용하면 기존 네트워크 공유 방식을 그대로 유지하면서 S3로 자동 전송할 수 있어 운영 복잡도를 크게 줄이고 신속한 분석 환경을 마련할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "AWS Cloud",
      "CSV",
      "네트워크 공유",
      "거의 실시간",
      "관리 오버헤드 최소"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "Amazon S3 File Gateway",
      "AWS Transfer for SFTP",
      "DataSync API",
      "CSV"
    ],
    "SelectA": "AWS DataSync로 파일을 Amazon S3에 전송합니다. 매일 업무가 끝날 때 실행되는 스케줄 작업을 만듭니다.",
    "SelectA_Commentary": "DataSync 스케줄을 일일 단위로 잡으면 거의 실시간 처리가 어렵고, 추가적인 스케줄 관리가 필요해 오버헤드가 증가합니다.",
    "SelectB": "Amazon S3 File Gateway를 생성합니다. 비즈니스 시스템이 새로운 S3 File Gateway 네트워크 공유를 사용하도록 업데이트합니다.",
    "SelectB_Commentary": "S3 File Gateway를 통해 기존 방식대로 파일을 쓰기만 하면 S3에 자동 업로드되어 거의 실시간 처리가 가능하며 관리 오버헤드가 최소화됩니다.",
    "SelectC": "AWS DataSync로 파일을 Amazon S3에 전송합니다. 자동화 워크플로우에서 DataSync API를 사용하는 애플리케이션을 만듭니다.",
    "SelectC_Commentary": "새로운 애플리케이션 개발이 필요해 오버헤드가 높아집니다. 간단한 솔루션이 요구되는 본 문제와 맞지 않습니다.",
    "SelectD": "AWS Transfer for SFTP 엔드포인트를 배포합니다. 네트워크 공유의 신규 파일을 확인하고 SFTP로 업로드하는 스크립트를 만듭니다.",
    "SelectD_Commentary": "주기적으로 직접 스크립트를 실행해 파일을 전송해야 해 관리가 복잡하고, 추가 구성 요소가 늘어납니다.",
    "Question_Description_recommedations": [
      "Q192",
      "Q631",
      "Q2",
      "Q547",
      "Q568"
    ],
    "SelectA_recommedations": [
      "Q672",
      "Q501",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q672",
      "Q501",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q292",
      "Q672",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q528",
      "Q173",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q415",
    "Question_Description": "한 회사가 Amazon S3 Standard에 페타바이트 규모의 데이터를 저장하고 있습니다. 데이터는 여러 개의 S3 버킷에 분산되어 있으며, 접근 빈도는 다양합니다. 회사는 모든 데이터의 접근 패턴을 정확히 알 수 없으며, 각 S3 버킷별로 S3 사용 비용을 최적화할 솔루션을 구현해야 합니다. 가장 높은 운영 효율성을 제공하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/103404-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장된 대량 데이터를 접근 패턴이 불분명한 상황에서 효과적으로 비용을 최적화하는 방법을 묻습니다. 각 객체별 접근 패턴을 추적하고 자동으로 스토리지 계층을 전환해 주는 S3 Intelligent-Tiering이 최적 해법입니다. 다른 방법은 수작업 분석, 불필요한 라이프사이클 전환, 혹은 내구성 측면에서 위험이 따를 수 있으므로 운영 효율성에서 뒤처집니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "페타바이트 데이터",
      "여러 개의 S3 버킷",
      "접근 빈도 다양",
      "접근 패턴 불명",
      "비용 최적화",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "S3 Lifecycle",
      "S3 Intelligent-Tiering",
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Storage Class Analysis"
    ],
    "SelectA": "S3 버킷의 객체를 S3 Intelligent-Tiering으로 전환하는 규칙이 포함된 S3 Lifecycle 구성을 생성합니다.",
    "SelectA_Commentary": "S3 Intelligent-Tiering은 자동으로 접근 패턴을 분석해 비용을 절감하며, 수작업이 거의 없어 운영 복잡성을 최소화하는 데 가장 적합한 솔루션입니다.",
    "SelectB": "S3 Storage Class Analysis를 사용해 버킷 내 객체별 맞춤 스토리지 클래스를 식별한 뒤, 해당 클래스로 직접 이동합니다.",
    "SelectB_Commentary": "분석 도구 사용 후 객체를 일일이 이동해야 하며, 접근 패턴이 변경될 때마다 재분석이 필요해 운영 부담이 큽니다.",
    "SelectC": "S3 버킷 객체를 S3 Glacier Instant Retrieval로 전환하는 규칙을 포함한 S3 Lifecycle 구성을 생성합니다.",
    "SelectC_Commentary": "Glacier Instant Retrieval은 장기 보관에 적합하지만, 잘못 전환 시 높은 검색 비용이 들 수 있어 접근 패턴이 불분명할 때 비효율적입니다.",
    "SelectD": "S3 버킷 객체를 S3 One Zone-IA로 전환하는 규칙이 포함된 S3 Lifecycle 구성을 생성합니다.",
    "SelectD_Commentary": "한 개의 AZ만 사용하는 스토리지 클래스로, 내구성 및 접근 패턴 자동 최적화 기능이 없어 모든 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q23",
      "Q498",
      "Q829",
      "Q469",
      "Q356"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q415",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q285",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q829",
      "Q498",
      "Q415"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q23",
      "Q498"
    ]
  },
  {
    "Question_Number": "Q416",
    "Question_Description": "빠르게 성장하는 글로벌 e-commerce 회사가 AWS에서 web application을 호스팅 중입니다. 이 web application은 static content와 dynamic content를 모두 포함합니다. 이 웹사이트는 online transaction processing(OLTP) 데이터를 Amazon RDS database에 저장하고 있으며, 사용자들이 웹페이지 로드가 느리다는 문제를 겪고 있습니다. 이러한 문제를 해결하기 위해 solutions architect가 수행해야 할 작업 조합은 무엇입니까? (두 가지를 선택하십시오.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/103423-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 트래픽 급증으로 인해 발생하는 응답 지연을 해결하는 데 초점을 둡니다. Amazon CloudFront로 static content를 캐싱하면 글로벌 엣지 로케이션을 통해 콘텐츠 전송이 빨라집니다. 동시에 RDS read replica를 추가해 데이터베이스 읽기 부하를 분산함으로써 DB 성능을 높일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.4"
    ],
    "Keywords": [
      "웹페이지 로드 성능",
      "Amazon RDS",
      "CloudFront",
      "read replica",
      "static content",
      "dynamic content"
    ],
    "Terms": [
      "Amazon RDS",
      "Amazon CloudFront",
      "Amazon Redshift",
      "Amazon S3",
      "read replica",
      "Multi-AZ",
      "OLTP",
      "web application"
    ],
    "SelectA": "Amazon Redshift cluster를 구성합니다.",
    "SelectA_Commentary": "Amazon Redshift는 데이터 웨어하우징을 위한 서비스이므로 OLTP 요구사항이나 웹페이지 로드 시간 문제 해결에 직접적 도움이 되지 않습니다.",
    "SelectB": "Amazon CloudFront distribution을 설정합니다.",
    "SelectB_Commentary": "글로벌 캐싱으로 static content 전송을 가속화해 사용자에게 빠른 페이지 로드를 제공할 수 있는 핵심 솔루션입니다.",
    "SelectC": "dynamic web content를 Amazon S3에 호스팅합니다.",
    "SelectC_Commentary": "S3는 static content 호스팅에 적합하고 서버사이드 연산이 없어 dynamic content 성능 향상에는 한계가 있습니다.",
    "SelectD": "RDS DB instance에 대해 read replica를 생성합니다.",
    "SelectD_Commentary": "읽기 전용 부하를 분산해 DB 성능을 높이므로 웹페이지 로딩 지연을 줄일 수 있습니다.",
    "SelectE": "RDS DB instance를 Multi-AZ로 구성합니다.",
    "SelectE_Commentary": "Multi-AZ 구성은 고가용성을 제공하나 성능(속도) 문제를 직접적으로 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q268",
      "Q431",
      "Q861",
      "Q561",
      "Q910"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q361",
      "Q557"
    ],
    "SelectB_recommedations": [
      "Q280",
      "Q361",
      "Q620"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q166",
      "Q672"
    ],
    "SelectD_recommedations": [
      "Q247",
      "Q337",
      "Q95"
    ],
    "SelectE_recommedations": [
      "Q633",
      "Q481",
      "Q95"
    ]
  },
  {
    "Question_Number": "Q417",
    "Question_Description": "한 회사가 애플리케이션을 구동하기 위해 Amazon EC2 인스턴스와 AWS Lambda 함수를 사용하고 있습니다. 이 회사의 AWS 계정에는 public subnet 및 private subnet이 포함된 VPC가 여러 개 구성되어 있습니다. EC2 인스턴스는 한 VPC 내의 private subnet에서 동작 중입니다. Lambda 함수들은 애플리케이션이 동작하기 위해 EC2 인스턴스에 직접적으로 네트워크 액세스해야 합니다. 애플리케이션은 최소 1년 이상 동작할 예정이며, 이 기간 동안 Lambda 함수의 수는 점차 증가할 것으로 예상됩니다. 회사는 모든 애플리케이션 리소스에 대해 최대한의 비용 절감을 원하며, 동시에 서비스 간의 네트워크 지연도 낮게 유지하고 싶어합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/103598-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "애플리케이션 구성에서 Amazon EC2 인스턴스와 AWS Lambda 함수를 모두 사용하는 경우, 비용 절감과 저지연 네트워크 환경을 동시에 고려해야 합니다. Compute Savings Plan은 EC2 인스턴스뿐 아니라 Lambda 실행 비용에도 할인이 적용되므로, 시간 경과에 따라 증가할 Lambda 비용까지 효율적으로 최적화할 수 있습니다. 또한 Lambda 함수를 EC2 인스턴스가 위치한 private subnet에 연결하면 네트워크 트래픽을 내부적으로 처리하여 지연을 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "AWS Lambda 함수",
      "private subnet",
      "네트워크 지연",
      "Compute Savings Plan"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "VPC",
      "public subnet",
      "private subnet",
      "EC2 Instance Savings Plan",
      "Compute Savings Plan"
    ],
    "SelectA": "EC2 Instance Savings Plan을 구매하고 Lambda 함수의 실행 시간 및 메모리 사용량, 호출 횟수를 최적화합니다. Lambda 함수를 EC2 인스턴스가 있는 private subnet에 연결합니다.",
    "SelectA_Commentary": "EC2 Instance Savings Plan은 EC2만 할인 대상이어서 늘어날 Lambda 비용을 충분히 절감하기 어렵습니다.",
    "SelectB": "EC2 Instance Savings Plan을 구매하고 Lambda 함수의 실행 시간 및 메모리 사용량, 호출 횟수, 전송 데이터 양을 최적화합니다. Lambda 함수를 EC2 인스턴스가 동작하는 동일 VPC의 public subnet에 연결합니다.",
    "SelectB_Commentary": "public subnet 연결 시 외부 경로를 거쳐야 하므로 네트워크 지연이 증가할 수 있으며, EC2 Instance Savings Plan만으로는 Lambda 비용 절감이 제한적입니다.",
    "SelectC": "Compute Savings Plan을 구매하고 Lambda 함수의 실행 시간 및 메모리 사용량, 호출 횟수, 전송 데이터 양을 최적화합니다. Lambda 함수를 EC2 인스턴스가 있는 private subnet에 연결합니다.",
    "SelectC_Commentary": "EC2와 Lambda 모두에 할인 적용이 가능한 Compute Savings Plan을 사용하고 private subnet으로 네트워크 지연과 보안까지 충족하므로 가장 적합한 솔루션입니다.",
    "SelectD": "Compute Savings Plan을 구매하고 Lambda 함수의 실행 시간 및 메모리 사용량, 호출 횟수, 전송 데이터 양을 최적화합니다. Lambda 함수를 Lambda service VPC에 그대로 둡니다.",
    "SelectD_Commentary": "Lambda가 별도의 VPC에 있으면 EC2에 직접적인 네트워크 접근이 까다롭고, 지연 및 구성 복잡도가 높아질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q882",
      "Q860",
      "Q140",
      "Q770",
      "Q800"
    ],
    "SelectA_recommedations": [
      "Q882",
      "Q417",
      "Q800"
    ],
    "SelectB_recommedations": [
      "Q882",
      "Q417",
      "Q800"
    ],
    "SelectC_recommedations": [
      "Q882",
      "Q417",
      "Q715"
    ],
    "SelectD_recommedations": [
      "Q715",
      "Q885",
      "Q467"
    ]
  },
  {
    "Question_Number": "Q418",
    "Question_Description": "한 솔루션스 아키텍트는 두 개의 서로 다른 AWS 계정(개발 계정과 프로덕션 계정) 내 Amazon S3 버킷에 팀원들이 접근할 수 있도록 해야 합니다. 현재 팀원들은 개발 계정에서 고유한 IAM user를 갖고 있으며, 해당 user들이 IAM group에 속해 적절한 권한으로 개발 계정의 S3 버킷에 접근하고 있습니다. 솔루션스 아키텍트는 프로덕션 계정에 IAM role을 만들었고, 이 role은 프로덕션 계정 내 S3 버킷에 접근할 수 있는 policy를 가지고 있습니다. 최소 권한 원칙(Principle of Least Privilege)을 준수하면서 이러한 요건을 충족하려면 어떤 솔루션이 적합할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/103585-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 크로스 계정 간에 Amazon S3에 접근을 허용하는 방법을 찾는 상황입니다. IAM role의 trust policy에 개발 계정을 명시함으로써 개발 계정의 IAM user가 프로덕션 계정 role을 적절히 가정(assume)할 수 있게 합니다. 이는 최소 권한 원칙을 충족하는 올바른 접근 방식입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "개발 계정",
      "프로덕션 계정",
      "IAM role",
      "trust policy",
      "최소 권한 원칙"
    ],
    "Terms": [
      "Amazon S3",
      "IAM role",
      "IAM user",
      "IAM group",
      "AWS account",
      "trust policy",
      "S3 Block Public Access",
      "Administrator Access policy",
      "credentials"
    ],
    "SelectA": "개발 계정의 사용자에게 Administrator Access policy를 부착합니다.",
    "SelectA_Commentary": "관리자 권한을 부여하면 최소 권한 원칙을 위배하고 불필요하게 광범위한 권한을 허용하므로 적절하지 않습니다.",
    "SelectB": "프로덕션 계정에 있는 role의 trust policy에 개발 계정을 principal로 추가합니다.",
    "SelectB_Commentary": "크로스 계정 액세스 시 권장되는 방법으로 개발 계정의 사용자들이 필요한 권한만 획득하도록 최소 권한을 보장합니다.",
    "SelectC": "프로덕션 계정의 S3 버킷에서 S3 Block Public Access 기능을 꺼 둡니다.",
    "SelectC_Commentary": "Public Access 설정은 대중에게 공개/차단 여부이며, 크로스 계정 IAM 사용자 접근을 제어하기에는 적합한 방법이 아닙니다.",
    "SelectD": "프로덕션 계정에 팀원마다 별도의 user를 생성하고 고유 자격 증명을 부여합니다.",
    "SelectD_Commentary": "각 팀원을 개별 user로 관리하면 계정 관리와 권한 설정이 복잡해지고, 최소 권한 원칙에도 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q477",
      "Q913",
      "Q982",
      "Q387",
      "Q403"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q233",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q423",
      "Q233",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q202",
      "Q825",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q419",
    "Question_Description": "한 회사는 모든 기능이 활성화된 AWS Organizations를 사용하여 ap-southeast-2 리전에서 여러 Amazon EC2 워크로드를 운영하고 있습니다. 이 회사는 서비스 제어 정책(SCP)을 통해 다른 리전에서는 어떠한 리소스도 생성되지 못하도록 차단하고 있습니다. 보안 정책상 모든 데이터는 암호화되어 저장되어야 합니다. 하지만 감사 결과 일부 직원들이 EC2 인스턴스용 Amazon EBS 볼륨을 암호화하지 않고 생성한 사실이 발견되었습니다. 이 회사는 ap-southeast-2 리전에서 어떤 IAM 사용자나 루트 사용자가 새 EC2 인스턴스를 생성하더라도 EBS 볼륨이 자동으로 암호화되도록 만들고자 합니다. 또한 EBS 볼륨을 생성하는 직원들에게 미치는 영향을 최소화하기를 원합니다. 이러한 요구사항을 충족하기 위한 단계 조합은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109268-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 조직 내 모든 계정에서 기본적으로 EBS 볼륨을 암호화하도록 하는 정책 구성 방안을 묻습니다. SCP를 통해 암호화되지 않은 볼륨 생성 작업(ec2:CreateVolume)을 막고, Organizations 관리 계정에서 Default EBS volume encryption 설정을 활성화하면 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Organizations",
      "SCP",
      "EBS 암호화",
      "EC2 인스턴스",
      "데이터 암호화",
      "기본 EBS 볼륨 암호화"
    ],
    "Terms": [
      "Service Control Policy(SCP)",
      "AWS Organizations",
      "Amazon EBS",
      "EC2 instances",
      "IAM Policy",
      "Default EBS volume encryption setting",
      "IAM Permission Boundary"
    ],
    "SelectA": "Amazon EC2 콘솔에서 EBS encryption account attribute를 활성화하고, 기본 암호화 키를 지정합니다.",
    "SelectA_Commentary": "한 계정 내에서만 기본 암호화를 적용하는 설정이므로 Organizations 수준에서의 강제는 되지 않습니다.",
    "SelectB": "IAM permission boundary를 생성하고 루트 OU에 연결합니다. ec2:Encrypted 조건이 false일 때 ec2:CreateVolume 액션을 거부하도록 만듭니다.",
    "SelectB_Commentary": "Permission boundary는 IAM 권한을 제한할 수 있지만, 조직 전체 차원의 통제와는 다르며 필요한 범위에 완전히 적용하기 어렵습니다.",
    "SelectC": "SCP를 생성하고 루트 OU에 연결합니다. ec2:Encrypted 조건이 false일 때 ec2:CreateVolume 액션을 거부하도록 SCP를 정의합니다.",
    "SelectC_Commentary": "조직 전체 계정에 일괄 적용 가능한 정책으로, 암호화되지 않은 EBS 볼륨 생성을 원천적으로 차단하는 핵심 조치입니다.",
    "SelectD": "각 계정의 IAM 정책을 업데이트하여 ec2:Encrypted 조건이 false일 경우 ec2:CreateVolume 액션을 거부하도록 설정합니다.",
    "SelectD_Commentary": "각 계정마다 정책을 수정해야 하므로 운영이 복잡해지며, 전체 Organizations 차원에서 일관성 있게 적용하기 어렵습니다.",
    "SelectE": "Organizations 관리 계정에서 Default EBS volume encryption 설정을 지정합니다.",
    "SelectE_Commentary": "조직의 모든 계정에서 새로 생성되는 EBS 볼륨이 자동으로 암호화되어 기본 요구사항을 만족합니다.",
    "Question_Description_recommedations": [
      "Q115",
      "Q988",
      "Q675",
      "Q998",
      "Q92"
    ],
    "SelectA_recommedations": [
      "Q410",
      "Q681",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q988",
      "Q494",
      "Q92"
    ],
    "SelectC_recommedations": [
      "Q92",
      "Q91",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q453",
      "Q494",
      "Q92"
    ],
    "SelectE_recommedations": [
      "Q410",
      "Q689",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q420",
    "Question_Description": "한 회사가 프로덕션 데이터베이스 워크로드를 위해 Amazon RDS for PostgreSQL DB cluster를 사용하여 시간이 많이 소요되는 데이터베이스 관리 작업을 간소화하려고 합니다. 이 회사는 데이터베이스가 높은 가용성을 유지하고 대부분의 시나리오에서 40초 미만의 자동 장애 조치(failover)를 지원하기를 원합니다. 또한 기본 인스턴스의 읽기 부하를 오프로드하고 비용을 최대한 낮게 유지하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109269-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고가용성과 빠른 장애 조치를 위해 Amazon RDS Multi-AZ DB cluster를 어떻게 활용하는지가 핵심 포인트입니다. Multi-AZ DB cluster는 40초 미만의 장애 조치와 읽기 분산을 모두 지원하여 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ DB cluster",
      "자동 장애 조치",
      "높은 가용성",
      "읽기 부하 오프로드"
    ],
    "Terms": [
      "Amazon RDS Multi-AZ DB instance deployment",
      "Amazon RDS Multi-AZ DB cluster deployment",
      "Read replica",
      "Primary instance",
      "Reader endpoint",
      "Failover"
    ],
    "SelectA": "Amazon RDS Multi-AZ DB instance 배포를 사용합니다. 하나의 read replica를 생성하고 읽기 작업을 read replica로 보냅니다.",
    "SelectA_Commentary": "Multi-AZ DB instance 배포는 보조 인스턴스가 대기 상태이며, 장애 조치 시간이 평균 60~120초로 요구사항에 충족하지 못합니다.",
    "SelectB": "Amazon RDS Multi-AZ DB cluster 배포를 사용합니다. 두 개의 read replica를 생성하고 읽기 작업을 이들 read replica로 보냅니다.",
    "SelectB_Commentary": "클러스터 형태로 빠른 failover는 가능하지만 read replica가 2개여서 비용 상승 가능성이 높아 요구사항의 비용 절감 목표에 부합하지 않습니다.",
    "SelectC": "Amazon RDS Multi-AZ DB instance 배포를 사용합니다. Multi-AZ 쌍의 보조 인스턴스에 읽기 작업을 전달합니다.",
    "SelectC_Commentary": "일반적인 Multi-AZ 인스턴스 배포에서 보조 인스턴스는 읽기 연결을 허용하지 않아 별도의 read replica가 필요합니다.",
    "SelectD": "Amazon RDS Multi-AZ DB cluster 배포를 사용합니다. 읽기 작업을 reader endpoint로 보냅니다.",
    "SelectD_Commentary": "클러스터 환경에서 40초 미만의 빠른 장애 조치가 가능하며, reader endpoint를 통해 읽기 부하도 분산할 수 있어 비용과 가용성을 모두 만족합니다.",
    "Question_Description_recommedations": [
      "Q958",
      "Q989",
      "Q281",
      "Q464",
      "Q629"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q259",
      "Q464"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q989",
      "Q958"
    ],
    "SelectC_recommedations": [
      "Q464",
      "Q466",
      "Q958"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q466",
      "Q228"
    ]
  },
  {
    "Question_Number": "Q421",
    "Question_Description": "한 회사가 고가용성 SFTP 서비스를 운영하고 있습니다. 이 SFTP 서비스는 인터넷에서 신뢰된 IP 소스들의 트래픽을 수신하기 위해 Elastic IP 주소를 사용하는 두 Amazon EC2 Linux 인스턴스를 이용합니다. 이 SFTP 서비스는 인스턴스에 연결된 공유 스토리지를 사용합니다. 사용자는 SFTP 서버의 Linux 사용자로 생성 및 관리됩니다. 회사는 고성능(High IOPS)을 제공하고 보안 구성을 자유롭게 설정할 수 있는 서버리스(Serverless) 옵션을 원합니다. 또한 사용자 권한을 직접 제어하고 싶어 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109270-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 EC2 기반 SFTP 서비스를 서버리스로 전환하여 높은 IOPS 성능과 세밀한 보안 설정, 사용자 권한 관리를 지원해야 하는 시나리오입니다. AWS Transfer Family는 전용 서버 없이도 SFTP 기능을 제공하며, Amazon EFS를 백엔드로 연결하면 파일 시스템 방식으로 높은 IOPS를 확보할 수 있습니다. Amazon S3도 Transfer Family의 백엔드로 사용 가능하지만, 대량 랜덤 처리가 필요한 경우 EFS가 더 적합합니다. Elastic IP나 보안 그룹을 통해 특정 IP만 허용하고, 사용자 권한은 Transfer Family 내에서 세밀하게 설정할 수 있어 보안이 강화됩니다. 따라서 Amazon EFS와 결합된 AWS Transfer Family(VPC Endpoint + Elastic IP) 구성이 우수한 선택입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "SFTP 서비스",
      "서버리스 옵션",
      "High IOPS",
      "보안 구성",
      "사용자 권한 제어",
      "Encrypted EFS",
      "Elastic IP",
      "Trusted IP"
    ],
    "Terms": [
      "AWS Transfer Family",
      "SFTP",
      "Amazon EC2",
      "Elastic IP",
      "Amazon EBS",
      "Amazon EFS",
      "Amazon S3",
      "VPC endpoint",
      "Security Group",
      "Encryption"
    ],
    "SelectA": "Encrypted Amazon EBS 볼륨을 생성하고, AWS Transfer Family SFTP 서비스를 Public Endpoint로 구성하여 신뢰된 IP만 허용합니다. 해당 EBS 볼륨을 SFTP 서비스에 연결하고 사용자에게 액세스를 부여합니다.",
    "SelectA_Commentary": "AWS Transfer Family는 EBS를 직접 연결해 사용할 수 없으므로 요구사항을 충족하지 못합니다.",
    "SelectB": "Encrypted Amazon EFS 볼륨을 생성하고, AWS Transfer Family SFTP 서비스를 Elastic IP가 있는 인터넷 액세스용 VPC Endpoint로 구성합니다. 신뢰된 IP만 허용하는 Security Group을 설정하고 EFS 볼륨을 SFTP 서비스와 연결한 뒤 사용자에게 액세스를 부여합니다.",
    "SelectB_Commentary": "서버리스로 SFTP 제공이 가능하며, EFS 연결로 높은 IOPS 성능과 보안을 모두 만족하므로 정답입니다.",
    "SelectC": "기본 암호화가 활성화된 Amazon S3 버킷을 생성하고, 신뢰된 IP만 허용하는 Public Endpoint로 AWS Transfer Family SFTP 서비스를 구성합니다. 해당 S3 버킷을 SFTP 서비스에 연결하고 사용자에게 액세스를 부여합니다.",
    "SelectC_Commentary": "S3는 높은 처리량이 가능하나 파일 단위 IOPS 관점에서 EFS 대비 불리하며, 기존 요구사항인 고성능 파일 시스템 활용에는 적합하지 않습니다.",
    "SelectD": "기본 암호화가 활성화된 Amazon S3 버킷을 생성하고, 내부 전용 VPC Endpoint(Private Subnet)로 AWS Transfer Family SFTP 서비스를 구성합니다. 신뢰된 IP만 허용하는 Security Group을 연결하고 동일 S3 버킷을 SFTP 서비스에 연결한 뒤 사용자에게 액세스를 부여합니다.",
    "SelectD_Commentary": "Private Subnet 구성은 인터넷에서 직접 접근이 불가능하므로 외부 사용자를 위한 SFTP 서비스로 활용하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q369",
      "Q299",
      "Q680",
      "Q704",
      "Q283"
    ],
    "SelectA_recommedations": [
      "Q895",
      "Q421",
      "Q680"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q421",
      "Q844"
    ],
    "SelectC_recommedations": [
      "Q672",
      "Q680",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q680",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q422",
    "Question_Description": "한 회사가 AWS에서 새로운 Machine Learning (ML) 모델 솔루션을 개발하고 있습니다. 각 모델은 독립적인 microservices 형태로 개발되며, 시작 시 약 1GB의 모델 데이터를 Amazon S3에서 가져와 메모리에 적재합니다. 사용자는 asynchronous API를 통해 모델을 호출하며, 단일 요청 또는 대량의 요청(batch)을 보낼 수 있고 결과가 전달될 위치를 지정할 수 있습니다. 회사는 수백 명의 사용자에게 모델을 제공하고 있으며, 사용 패턴이 불규칙적입니다. 어떤 모델은 며칠 혹은 몇 주 동안 사용되지 않을 수도 있고, 다른 모델은 한 번에 수천 건의 요청을 받기도 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 설계를 권장해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109280-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 불규칙적이고 때로는 폭증하는 요청을 처리하기 위해, 대기열 기반의 비동기 아키텍처와 자동 확장 기능을 결합하는 방안을 묻습니다. 무거운 모델 데이터를 시작 시마다 적재해야 하므로, ECS 같은 컨테이너 기반 서비스에서 큐의 크기에 맞춰 자동 확장하는 것이 이상적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Machine Learning",
      "asynchronous API",
      "microservices",
      "Amazon S3",
      "Amazon SQS",
      "AWS Auto Scaling",
      "Amazon ECS"
    ],
    "Terms": [
      "Amazon S3",
      "Asynchronous API",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Auto Scaling",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "AWS App Mesh"
    ],
    "SelectA": "API 요청을 Network Load Balancer(NLB)를 통해 전달하고, 모델을 AWS Lambda 함수로 배포하여 NLB가 호출하도록 합니다.",
    "SelectA_Commentary": "Lambda는 1GB 이상의 Large Model 로딩 시 Cold Start 지연이 크고 환경 제약이 있어 장기적으로는 비효율적입니다.",
    "SelectB": "API 요청을 Application Load Balancer(ALB)로 전달하고, 모델을 Amazon ECS 서비스로 배포하여 Amazon SQS 큐에서 읽도록 합니다. AWS App Mesh를 사용해 SQS 큐 크기에 따라 ECS 클러스터를 스케일합니다.",
    "SelectB_Commentary": "ALB와 App Mesh를 결합한 구조는 가능하지만 설정이 복잡하며, 요구사항 대비 오버엔지니어링이 될 수 있습니다.",
    "SelectC": "API 요청을 Amazon SQS 큐로 전달하고, 모델을 AWS Lambda 함수로 배포하여 SQS 이벤트로 호출합니다. SQS 큐 크기에 따라 Lambda 함수의 vCPU 수를 AWS Auto Scaling으로 조정합니다.",
    "SelectC_Commentary": "Lambda 함수는 1GB 모델 로딩 시 메모리 한계와 반복적인 Cold Start 문제가 발생해 대용량 처리에 적합하지 않습니다.",
    "SelectD": "API 요청을 Amazon SQS 큐로 전달하고, 모델을 Amazon ECS 서비스로 배포하여 큐에서 메시지를 읽습니다. Amazon ECS의 클러스터 및 서비스 복제본을 큐 크기에 맞춰 AWS Auto Scaling으로 확장하도록 구성합니다.",
    "SelectD_Commentary": "ECS가 대량 모델을 메모리에 적재하고, SQS로 비동기 요청을 처리하며 자동 확장까지 가능해 요구사항을 모두 충족하는 최적의 구성입니다.",
    "Question_Description_recommedations": [
      "Q954",
      "Q351",
      "Q18",
      "Q52",
      "Q721"
    ],
    "SelectA_recommedations": [
      "Q70",
      "Q545",
      "Q405"
    ],
    "SelectB_recommedations": [
      "Q1012",
      "Q405",
      "Q545"
    ],
    "SelectC_recommedations": [
      "Q98",
      "Q775",
      "Q404"
    ],
    "SelectD_recommedations": [
      "Q900",
      "Q67",
      "Q203"
    ]
  },
  {
    "Question_Number": "Q423",
    "Question_Description": "한 솔루션스 아키텍트가 특정 권한을 부여하기 위해 다음과 같은 JSON 텍스트를 identity-based policy로 사용하려고 합니다. 이 policy는 어떤 IAM principals에 적용할 수 있습니까? (2개를 고르시오.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109281-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 identity-based policy가 적용 가능한 IAM 주체를 구분하는 문제입니다. policy는 IAM Role이나 Group과 같은 identity에 적용이 가능하지만, Organization이나 리소스에는 적용할 수 없습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "identity-based policy",
      "IAM",
      "Role",
      "Group",
      "Organization",
      "Amazon ECS resource",
      "Amazon EC2 resource"
    ],
    "Terms": [
      "JSON text",
      "IAM principals",
      "Role",
      "Group",
      "Organization",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon EC2"
    ],
    "SelectA": "Role",
    "SelectA_Commentary": "정답입니다. IAM Role은 identity의 하나로 이 policy를 직접 적용할 수 있습니다.",
    "SelectB": "Group",
    "SelectB_Commentary": "정답입니다. IAM Group도 identity의 하나이므로 해당 policy를 부여할 수 있습니다.",
    "SelectC": "Organization",
    "SelectC_Commentary": "Organization은 계정 관리자 단위로 identity-based policy를 직접 적용할 수 없습니다.",
    "SelectD": "Amazon Elastic Container Service (Amazon ECS) resource",
    "SelectD_Commentary": "Amazon ECS 리소스는 IAM Role이나 Group처럼 identity가 아니므로 identity-based policy를 적용할 수 없습니다.",
    "SelectE": "Amazon EC2 resource",
    "SelectE_Commentary": "Amazon EC2 역시 리소스이며, identity가 아니므로 identity-based policy 대상이 될 수 없습니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q222",
      "Q429",
      "Q253",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q682",
      "Q663"
    ],
    "SelectE_recommedations": [
      "Q682",
      "Q321",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q424",
    "Question_Description": "한 회사가 Amazon EC2 On-Demand Instances에서 커스텀 애플리케이션을 운영하고 있습니다. 이 애플리케이션에는 24시간 7일 내내 구동해야 하는 frontend 노드와, 워크로드에 따라 짧은 시간만 실행되는 backend 노드가 있습니다. 하루 중에도 backend 노드 수가 변동됩니다. 회사는 워크로드에 맞춰 인스턴스를 확장(Scale out)하거나 축소(Scale in)할 수 있어야 합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109283-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 상시로 동작해야 하는 부분과 유동적인 워크로드를 처리하는 부분을 어떻게 구성해야 가장 비용을 절감할 수 있는지를 묻습니다. 24시간 필요한 frontend 노드에는 Reserved Instances를 이용해 고정 비용을 절감하고, 짧은 기간에만 동작하는 backend 노드는 사용한 만큼 비용을 지불하는 AWS Fargate로 운용해 스케일 인·아웃 시 유연하고 불필요한 비용을 최소화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2 On-Demand Instances",
      "Reserved Instances",
      "AWS Fargate",
      "Spot Instances",
      "frontend 노드",
      "backend 노드",
      "짧은 시간 실행",
      "비용 효율",
      "확장 및 축소"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Reserved Instances",
      "AWS Fargate",
      "Spot Instances",
      "Scale out",
      "Scale in"
    ],
    "SelectA": "Use Reserved Instances for the frontend nodes. Use AWS Fargate for the backend nodes.",
    "SelectA_Commentary": "항상 필요한 frontend 노드에는 할인된 요금의 Reserved Instances가 적합하고, 짧게 동작하는 backend 노드는 AWS Fargate로 사용한 만큼만 과금되어 가장 비용 효율적입니다.",
    "SelectB": "Use Reserved Instances for the frontend nodes. Use Spot Instances for the backend nodes.",
    "SelectB_Commentary": "Spot Instances는 저렴하지만 언제든 반환될 수 있어 안정성이 보장되지 않습니다. 백엔드 기능이 중단 위험 없이 필요하다면 적합하지 않습니다.",
    "SelectC": "Use Spot Instances for the frontend nodes. Use Reserved Instances for the backend nodes.",
    "SelectC_Commentary": "항상 동작해야 하는 프론트엔드를 Spot Instances로 운영하면 중단 가능성이 높아 가용성 문제가 큽니다. 백엔드에 Reserved Instances를 쓰는 것도 워크로드 변동에 비효율적입니다.",
    "SelectD": "Use Spot Instances for the frontend nodes. Use AWS Fargate for the backend nodes.",
    "SelectD_Commentary": "프론트엔드가 24시간 필요하므로 Spot Instances로는 신뢰성이 떨어집니다. 백엔드를 Fargate로 사용하는 점은 유연하지만 프론트엔드 가용성 요구사항을 만족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q505",
      "Q1008",
      "Q1013",
      "Q146",
      "Q24"
    ],
    "SelectA_recommedations": [
      "Q926",
      "Q943",
      "Q424"
    ],
    "SelectB_recommedations": [
      "Q424",
      "Q1013",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q424",
      "Q1013",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q926",
      "Q943",
      "Q424"
    ]
  },
  {
    "Question_Number": "Q425",
    "Question_Description": "한 회사는 고 블록 스토리지 용량을 사용하여 온프레미스에서 워크로드를 운영하고 있습니다. 이 회사의 하루 최대 IOPS(초당 입력 및 출력 트랜잭션)는 15,000 IOPS를 넘지 않습니다. 회사는 이 워크로드를 Amazon EC2로 마이그레이션하고, 스토리지 용량과 무관하게 디스크 성능을 프로비저닝하고 싶어합니다. 가장 비용 효율적인 Amazon Elastic Block Store(Amazon EBS) 볼륨 타입은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109282-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 최대 15,000 IOPS까지 필요한 블록 스토리지 워크로드를 Amazon EC2로 이전할 때, 스토리지 용량과 무관한 디스크 성능 제공 및 비용 효율성을 달성할 수 있는 EBS 볼륨 타입을 선택하는 것입니다. GP3 볼륨은 낮은 GB당 비용과 높은 최대 IOPS 프로비저닝이 가능하여 가장 적합한 솔루션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon EBS",
      "IOPS",
      "스토리지 용량과 무관한 디스크 성능",
      "비용 효율성",
      "GP3"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "IOPS",
      "Gp2",
      "Gp3",
      "io1",
      "io2",
      "Volume Type"
    ],
    "SelectA": "GP2 볼륨 타입",
    "SelectA_Commentary": "GP2는 용량에 따라 IOPS가 결정되고, GB당 비용도 GP3보다 높아 가장 비용 효율적이지 않습니다.",
    "SelectB": "io2 볼륨 타입",
    "SelectB_Commentary": "io2는 매우 높은 내구성과 성능을 제공하지만, 비용이 커서 15,000 IOPS 요구사항 대비 과도한 사양입니다.",
    "SelectC": "GP3 볼륨 타입",
    "SelectC_Commentary": "GP3는 낮은 비용으로 최대 16,000 IOPS를 스토리지 용량과 무관하게 프로비저닝할 수 있어 가장 비용 효율적입니다.",
    "SelectD": "io1 볼륨 타입",
    "SelectD_Commentary": "io1은 이전 세대 프로비저닝 IOPS 볼륨으로 비용이 크고 효율성이 떨어지므로 이 문제에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q841",
      "Q353",
      "Q867",
      "Q822",
      "Q505"
    ],
    "SelectA_recommedations": [
      "Q630",
      "Q997",
      "Q49"
    ],
    "SelectB_recommedations": [
      "Q630",
      "Q997",
      "Q49"
    ],
    "SelectC_recommedations": [
      "Q630",
      "Q997",
      "Q49"
    ],
    "SelectD_recommedations": [
      "Q49",
      "Q630",
      "Q997"
    ]
  },
  {
    "Question_Number": "Q426",
    "Question_Description": "한 회사가 헬스케어 애플리케이션의 데이터를 저장해야 합니다. 해당 애플리케이션의 데이터는 자주 변경되며, 새로운 규제에 따라 저장된 모든 데이터 레벨에서의 감사(Audit) 액세스가 요구됩니다. 현재 온프레미스 인프라에서 애플리케이션을 호스팅 중이나 스토리지 용량이 부족해지고 있습니다. 솔루션스 아키텍트는 새로운 규제를 만족하면서 기존 데이터를 안전하게 AWS로 마이그레이션해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109278-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 자주 변경되는 헬스케어 데이터를 Amazon S3로 이전하면서, 모든 데이터 레벨에서의 접근 기록을 만족해야 하는 보안 관점의 시나리오입니다. 'Audit access at all levels'는 객체 수준의 접근 로그 적재를 의미하므로, AWS CloudTrail Data Events를 활성화하는 것이 중요합니다. 이 요구사항을 만족하는 가장 효율적인 마이그레이션 도구가 답이 됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "헬스케어 애플리케이션",
      "감사 액세스",
      "온프레미스 마이그레이션",
      "데이터 변경",
      "AWS CloudTrail",
      "데이터 이벤트"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "AWS CloudTrail",
      "AWS Snowcone",
      "Amazon S3 Transfer Acceleration",
      "AWS Storage Gateway",
      "Management Events",
      "Data Events"
    ],
    "SelectA": "AWS DataSync로 기존 데이터를 Amazon S3로 옮기고, AWS CloudTrail에서 Data Events를 활성화하여 로그를 수집합니다.",
    "SelectA_Commentary": "DataSync는 온프레미스 데이터를 빠르고 안전하게 S3로 마이그레이션하고, Data Events는 S3 객체 접근 기록까지 상세하게 추적할 수 있으므로 규제 요구사항을 완벽하게 충족합니다.",
    "SelectB": "AWS Snowcone을 통해 기존 데이터를 Amazon S3로 옮기고, AWS CloudTrail에서 Management Events를 활성화합니다.",
    "SelectB_Commentary": "Snowcone은 오프라인 전송 솔루션으로 대용량 사용 시 비효율적이며, Management Events는 객체 수준 작업을 추적하지 않아 새 규제 요구사항에 부합하지 않습니다.",
    "SelectC": "Amazon S3 Transfer Acceleration을 사용해 기존 데이터를 Amazon S3로 옮기고, AWS CloudTrail에서 Data Events를 활성화합니다.",
    "SelectC_Commentary": "S3 Transfer Acceleration은 전송 속도를 향상시키지만, 온프레미스 파일 서버와 직접 연동할 수 있는 안전한 마이그레이션 절차로서 DataSync만큼 편리하지 않습니다.",
    "SelectD": "AWS Storage Gateway를 사용해 기존 데이터를 Amazon S3로 옮기고, AWS CloudTrail에서 Management Events를 활성화합니다.",
    "SelectD_Commentary": "Storage Gateway는 온프레미스와 AWS 간 하이브리드 스토리지 연결 용도로 주로 사용되며, Management Events만으로 객체 수준 감사 요건을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q893",
      "Q592",
      "Q922",
      "Q548",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q862",
      "Q451"
    ],
    "SelectB_recommedations": [
      "Q942",
      "Q862",
      "Q451"
    ],
    "SelectC_recommedations": [
      "Q942",
      "Q862",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q862",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q427",
    "Question_Description": "한 솔루션스 아키텍트가 MySQL database를 사용하는 복잡한 Java application을 구현 중입니다. 이 Java application은 Apache Tomcat에 배포되어야 하며, 높은 가용성을 유지해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109279-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 MySQL database를 사용하는 Java application을 Tomcat 환경에 배포하면서도 고가용성을 확보해야 하는 상황입니다. AWS Elastic Beanstalk는 Java와 Tomcat을 쉽게 설정하고, 로드 밸런서 및 Rolling deployment 등으로 고가용성과 확장성을 자동 관리하여 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "MySQL database",
      "복잡한 Java application",
      "Apache Tomcat",
      "높은 가용성",
      "AWS Elastic Beanstalk",
      "로드 밸런싱 환경",
      "rolling deployment"
    ],
    "Terms": [
      "Java application",
      "MySQL database",
      "Apache Tomcat",
      "AWS Elastic Beanstalk",
      "로드 밸런싱 환경",
      "Rolling deployment policy"
    ],
    "SelectA": "AWS Lambda를 사용해 애플리케이션을 배포하고, Amazon API Gateway API로 Lambda 함수를 연결합니다.",
    "SelectA_Commentary": "Lambda는 서버 관리 부담이 적지만, Tomcat 기반의 전통적 Java 웹 애플리케이션 배포와는 맞지 않아 고가용성을 보장하기에 적절하지 않습니다.",
    "SelectB": "AWS Elastic Beanstalk를 사용해 애플리케이션을 배포합니다. 로드 밸런싱 환경과 rolling deployment 정책을 구성합니다.",
    "SelectB_Commentary": "Elastic Beanstalk는 Tomcat 환경을 빠르게 구성해주며, 로드 밸런싱과 Rolling deployment로 고가용성을 손쉽게 확보할 수 있는 최적의 솔루션입니다.",
    "SelectC": "데이터베이스를 Amazon ElastiCache로 마이그레이션합니다. ElastiCache 보안 그룹을 애플리케이션에서 접근 가능하도록 설정합니다.",
    "SelectC_Commentary": "ElastiCache는 캐시 서비스로서, RDBMS인 MySQL을 대체할 수 없으므로 요구사항을 충족하지 못합니다.",
    "SelectD": "Amazon EC2 인스턴스를 실행하고 MySQL server와 애플리케이션을 설치합니다. 이를 AMI로 생성 후 Launch Template과 Auto Scaling group으로 구성합니다.",
    "SelectD_Commentary": "EC2 인스턴스로 직접 설정해도 가능하나, Tomcat 환경 설정 및 고가용성 유지 관점에서 Elastic Beanstalk보다 운영 복잡도가 크게 증가합니다.",
    "Question_Description_recommedations": [
      "Q824",
      "Q182",
      "Q914",
      "Q683",
      "Q129"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q10",
      "Q739"
    ],
    "SelectB_recommedations": [
      "Q664",
      "Q194",
      "Q351"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q8",
      "Q584"
    ],
    "SelectD_recommedations": [
      "Q824",
      "Q595",
      "Q111"
    ]
  },
  {
    "Question_Number": "Q428",
    "Question_Description": "한 서버리스 애플리케이션은 Amazon API Gateway, AWS Lambda, 그리고 Amazon DynamoDB를 사용하고 있습니다. 이 Lambda 함수는 DynamoDB 테이블에 대한 읽기 및 쓰기 권한이 필요합니다. Lambda 함수가 가장 안전하게 DynamoDB 테이블에 액세스할 수 있도록 해주는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109285-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda가 DynamoDB 테이블에 안전하게 접근하도록 권한을 부여하는 방법을 묻습니다. 모범 사례는 Lambda를 trusted service로 포함한 IAM role을 생성해 필요한 policy를 연결하고, 이를 Lambda의 execution role로 사용하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "서버리스 애플리케이션",
      "Lambda 함수",
      "DynamoDB 테이블",
      "IAM role",
      "trusted service",
      "execution role"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "IAM user",
      "IAM role",
      "execution role",
      "access_key_id",
      "secret_access_key",
      "AWS Systems Manager Parameter Store",
      "trusted service",
      "policy"
    ],
    "SelectA": "프로그램 방식 액세스가 가능한 IAM user를 생성하고 DynamoDB 테이블에 대한 읽기 및 쓰기 권한이 있는 policy를 연결합니다. access_key_id와 secret_access_key를 Lambda environment variables에 저장합니다. 다른 AWS user가 Lambda 구성에 접근하지 못하도록 합니다.",
    "SelectA_Commentary": "IAM user 자격 증명을 Lambda environment variables에 직접 저장하므로 안전하지 않습니다. 이는 보안 리스크가 높아 권장되지 않습니다.",
    "SelectB": "Lambda를 trusted service로 포함하는 IAM role을 생성합니다. 이 role에 DynamoDB 테이블에 대한 읽기 및 쓰기 권한을 허용하는 policy를 연결합니다. Lambda 함수가 이 role을 execution role로 사용하도록 구성합니다.",
    "SelectB_Commentary": "Lambda를 위한 IAM role을 사용해 필요한 권한만 부여하고, 자격 증명을 코드나 환경 변수에 노출하지 않아 가장 안전하고 모범적인 방법입니다.",
    "SelectC": "프로그램 방식 액세스가 가능한 IAM user를 생성하고, DynamoDB 테이블에 대한 읽기 및 쓰기 권한이 있는 policy를 연결합니다. 자격 증명은 AWS Systems Manager Parameter Store에 보안 문자열로 저장하고, Lambda 함수 코드를 수정해 해당 정보를 가져와 DynamoDB에 연결합니다.",
    "SelectC_Commentary": "Parameter Store를 활용해 자격 증명을 보호하는 방식이지만, 여전히 IAM user 자격 증명 사용 자체가 모범 사례보다 덜 안전한 편입니다.",
    "SelectD": "DynamoDB를 trusted service로 포함하는 IAM role을 생성합니다. Lambda 함수로부터의 읽기/쓰기 권한을 허용하는 policy를 연결합니다. Lambda 함수 코드를 업데이트해 이 role을 execution role로 사용하도록 합니다.",
    "SelectD_Commentary": "DynamoDB가 Lambda를 신뢰해야 하는 방식이므로 방향 설정이 올바르지 않습니다. Lambda를 trusted service로 지정해야 하는 모범 사례와 반대됩니다.",
    "Question_Description_recommedations": [
      "Q366",
      "Q159",
      "Q176",
      "Q936",
      "Q791"
    ],
    "SelectA_recommedations": [
      "Q428",
      "Q403",
      "Q279"
    ],
    "SelectB_recommedations": [
      "Q428",
      "Q791",
      "Q403"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q428",
      "Q791",
      "Q936"
    ]
  },
  {
    "Question_Number": "Q429",
    "Question_Description": "다음 IAM 정책이 한 IAM 그룹에 연결되어 있습니다. 이 그룹에 적용된 정책은 이 정책이 유일합니다. 이때 그룹 멤버들의 유효한 IAM 권한은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109286-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM 정책을 해석하여 실제로 적용되는 권한을 파악하는 문제입니다. MFA 조건이 붙은 특정 EC2 작업(Stop/Terminate) 권한과 기본적으로 부여된 EC2 전체 액션 권한이 어떻게 조합되는지 이해해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM 그룹",
      "IAM 정책",
      "MFA",
      "EC2",
      "us-east-1",
      "StopInstances",
      "TerminateInstances"
    ],
    "Terms": [
      "IAM policy",
      "IAM group",
      "Multi-Factor Authentication (MFA)",
      "Amazon EC2",
      "ec2:StopInstances",
      "ec2:TerminateInstances",
      "Allow 스테이트먼트",
      "Deny 스테이트먼트",
      "us-east-1 리전"
    ],
    "SelectA": "그룹 멤버들은 us-east-1 리전 내에서 모든 Amazon EC2 작업을 허용받습니다. Allow 권한 뒤의 스테이트먼트들은 적용되지 않습니다.",
    "SelectA_Commentary": "첫 번째 Allow로 모든 EC2 작업을 허용한다고 해석하지만, IAM 정책은 여러 스테이트먼트가 모두 유효하므로, 뒤 스테이트먼트도 적용됩니다. 따라서 틀린 해석입니다.",
    "SelectB": "그룹 멤버들은 MFA로 로그인하지 않으면 us-east-1 리전에서 어떠한 Amazon EC2 작업도 허용되지 않습니다.",
    "SelectB_Commentary": "이 해석은 모든 EC2 권한에 MFA가 필수라는 의미인데, 실제 정책은 특정 작업(Stop/Terminate)에만 MFA가 필요한 조건이 있을 수 있으므로 잘못된 해석입니다.",
    "SelectC": "MFA로 로그인했을 때, 그룹 멤버들은 모든 리전에서 ec2:StopInstances와 ec2:TerminateInstances 권한을 허용받으며, 그 외 Amazon EC2 작업은 자유롭게 허용됩니다.",
    "SelectC_Commentary": "MFA 조건이 모든 리전에 적용된다고 가정하지만, 정책상 특정 리전(us-east-1) 제한이 있을 수 있으므로 완전히 맞지 않습니다.",
    "SelectD": "그룹 멤버들은 MFA로 로그인했을 때만 us-east-1 리전에서 ec2:StopInstances와 ec2:TerminateInstances 권한을 허용받으며, us-east-1 리전의 다른 EC2 작업은 제한 없이 허용됩니다.",
    "SelectD_Commentary": "MFA가 없으면 특정 작업(Stop/Terminate)은 허용되지 않고, 나머지 EC2 작업은 허용된다면 정책 해석과 일치합니다. 정답입니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q222",
      "Q780",
      "Q803",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q480",
      "Q100"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q480",
      "Q682"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q329",
      "Q453"
    ],
    "SelectD_recommedations": [
      "Q510",
      "Q974",
      "Q329"
    ]
  },
  {
    "Question_Number": "Q430",
    "Question_Description": "한 제조 회사는 머신 센서에서 Amazon S3 버킷으로 .csv 파일을 업로드합니다. 해당 .csv 파일들은 자동 그래프 보고서를 생성하기 위해 가능한 한 빨리 이미지로 변환되어야 합니다. 이미지는 1개월 후에는 더 이상 유의미하지 않지만, .csv 파일은 1년에 두 번 수행되는 머신 러닝(ML) 모델 학습을 위해 보관해야 합니다. ML 학습 및 감사 일정은 수 주 전에 미리 계획됩니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 단계 조합은 무엇입니까? (둘을 선택하십시오.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109288-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 자동 그래프 생성용 이미지를 빠르게 제공하면서, 장기적으로 .csv 파일을 저비용으로 보관하는 방법을 찾는 것입니다. Lambda로 이벤트 기반 이미지를 생성하고, .csv 파일은 S3 Glacier로 전환해 필요 시 미리 복원하는 방식이 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "이미지 변환",
      "S3 Lifecycle",
      "S3 Glacier",
      "머신 러닝(ML) 모델 훈련",
      "비용 효율화"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2 Spot Instance",
      "AWS Lambda",
      "S3 Lifecycle Rule",
      "S3 Glacier",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "Reduced Redundancy Storage (RRS)"
    ],
    "SelectA": "Amazon EC2 Spot Instance를 시작하여 매시간 .csv 파일을 다운로드하고 이미지를 생성한 후 S3 버킷에 업로드합니다.",
    "SelectA_Commentary": "Spot Instance를 활용해도 어느 정도 비용 절감이 가능하지만, 인프라 관리와 일정 트리거 구현이 복잡해집니다.",
    "SelectB": "AWS Lambda 함수를 설계하여 .csv 파일을 이미지로 변환하고, 이미지를 S3 버킷에 저장하도록 합니다. .csv 파일이 업로드될 때 Lambda 함수를 호출합니다.",
    "SelectB_Commentary": "서버리스 이벤트 기반 구조로 간단하며, 추가 인프라 관리를 최소화해 비용 효율이 뛰어납니다.",
    "SelectC": "S3 버킷에 .csv 파일과 이미지 파일에 대한 S3 Lifecycle 규칙을 만듭니다. 업로드된 지 1일 후 .csv 파일을 S3 Glacier로 전환하고, 이미지는 30일 후에 만료시킵니다.",
    "SelectC_Commentary": "ML 학습 시점을 미리 알 수 있으므로 Glacier를 사용하는 것이 장기 보관에 가장 저렴하며, 이미지는 1개월 후 삭제해 비용을 줄일 수 있습니다.",
    "SelectD": "S3 버킷에 .csv 파일과 이미지 파일에 대한 S3 Lifecycle 규칙을 만듭니다. 업로드된 지 1일 후 .csv 파일을 S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하고, 이미지는 30일 후 만료시킵니다.",
    "SelectD_Commentary": "One Zone-IA는 단일 AZ에만 저장되어 내구성이 떨어지므로, 중요한 파일을 장기 보관하기에는 적합하지 않습니다.",
    "SelectE": "S3 버킷에 .csv 파일과 이미지 파일에 대한 S3 Lifecycle 규칙을 만듭니다. 업로드된 지 1일 후 .csv 파일을 S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하고, 이미지는 Reduced Redundancy Storage(RRS)에 보관합니다.",
    "SelectE_Commentary": "RRS는 더 이상 잘 사용되지 않는 스토리지 클래스이며, 장기 비용 효율성과 내구성 측면에서 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q606",
      "Q285",
      "Q469",
      "Q769",
      "Q911"
    ],
    "SelectA_recommedations": [
      "Q904",
      "Q552",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q430",
      "Q807",
      "Q469"
    ],
    "SelectC_recommedations": [
      "Q430",
      "Q829",
      "Q498"
    ],
    "SelectD_recommedations": [
      "Q430",
      "Q415",
      "Q471"
    ],
    "SelectE_recommedations": [
      "Q430",
      "Q415",
      "Q356"
    ]
  },
  {
    "Question_Number": "Q431",
    "Question_Description": "한 회사가 새로운 비디오 게임을 웹 어플리케이션으로 개발했습니다. 이 어플리케이션은 VPC 내 삼계층 아키텍처로 실행되며, 데이터베이스 계층에 Amazon RDS for MySQL이 사용됩니다. 여러 플레이어가 동시에 온라인 대전을 벌입니다. 게임 개발자는 거의 실시간(near real-time)으로 Top-10 스코어보드를 표시하고, 현재 점수를 유지한 상태에서 게임을 중지하고 다시 복원할 수 있는 기능을 원합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109274-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 빠른 읽기/쓰기에 최적화된 인메모리 저장소를 활용해 Top-10과 같은 랭킹 데이터를 거의 실시간으로 처리하고, 동시에 현재 점수를 안정적으로 보존하고 복원하는 방식에 대한 것입니다. Redis는 Sorted Set 같은 자료구조와 지속성(Persistence) 설정을 통해 스코어 데이터를 실시간으로 업데이트하고, 장애 발생 시에도 데이터를 보존할 수 있어 요구사항을 모두 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "삼계층 아키텍처",
      "거의 실시간",
      "Top-10 스코어보드",
      "현재 점수 유지",
      "Amazon RDS for MySQL"
    ],
    "Terms": [
      "Amazon ElastiCache for Memcached",
      "Amazon ElastiCache for Redis",
      "Amazon CloudFront",
      "Amazon RDS for MySQL",
      "Read Replica",
      "Persistence"
    ],
    "SelectA": "Amazon ElastiCache for Memcached 클러스터를 설정하여 웹 애플리케이션에서 표시할 점수를 캐시합니다.",
    "SelectA_Commentary": "Memcached는 간단한 캐시 솔루션으로, 고급 자료구조나 영구적인 데이터 저장 기능을 제공하지 않으므로 Top-10 처리 및 점수 유지에 적합하지 않습니다.",
    "SelectB": "Amazon ElastiCache for Redis 클러스터를 구성하여 웹 애플리케이션에서 표시할 점수를 계산하고 캐시합니다.",
    "SelectB_Commentary": "Redis의 정렬, 랭킹 연산 기능과 영구적 저장(Persistence) 지원으로 거의 실시간 스코어보드 구현과 게임 데이터 보존이 가능합니다. 문제의 요구사항을 완벽하게 충족합니다.",
    "SelectC": "웹 애플리케이션 앞에 Amazon CloudFront 배포를 배치하여 애플리케이션의 특정 구역에 스코어보드를 캐시합니다.",
    "SelectC_Commentary": "CloudFront는 콘텐츠 전송 네트워크로, 동적인 점수 계산과 저장 기능을 제공하지 않습니다. 실시간으로 업데이트되는 스코어 표시와 데이터 보존 요건을 만족하기 어렵습니다.",
    "SelectD": "Amazon RDS for MySQL에 Read Replica를 만들어 스코어보드를 계산하는 쿼리를 실행하고 웹 애플리케이션에서 읽기 트래픽을 처리하도록 합니다.",
    "SelectD_Commentary": "Read Replica로 읽기 부하를 줄일 수 있지만, Top-10 계산을 자주 수행하면 DB 부담이 여전히 크고, 중지·복원 시 점수를 보존하는 별도 매커니즘이 필요해 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q268",
      "Q861",
      "Q561",
      "Q416",
      "Q819"
    ],
    "SelectA_recommedations": [
      "Q229",
      "Q746",
      "Q472"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q746",
      "Q557"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q361",
      "Q631"
    ],
    "SelectD_recommedations": [
      "Q247",
      "Q337",
      "Q376"
    ]
  },
  {
    "Question_Number": "Q432",
    "Question_Description": "한 전자상거래(ecommerce) 회사가 Machine Learning(ML) 알고리즘을 사용하여 모델을 구축하고 교육하려고 합니다. 이 모델은 복잡한 시나리오를 시각화하고 고객 데이터에서 트렌드를 탐지하는 데 사용할 예정입니다. 아키텍처 팀은 보고 플랫폼과 ML 모델을 통합하여 증강된 데이터를 분석하고, 비즈니스 인텔리전스 대시보드에서 직접 활용하고자 합니다. 이 요구사항을 충족하면서 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109291-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "ML 모델을 효율적으로 구축하고 시각화 도구로 연동하려면 기존에 통합된 관리형 서비스가 중요합니다. Amazon SageMaker와 Amazon QuickSight는 각각 모델 생성과 시각화를 지원하며, 운영 과정이 단순해집니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "Machine Learning",
      "Amazon SageMaker",
      "Amazon QuickSight",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Glue",
      "ML transform",
      "Amazon OpenSearch Service",
      "Amazon SageMaker",
      "Amazon QuickSight",
      "AWS Marketplace",
      "Amazon Machine Image(AMI)"
    ],
    "SelectA": "AWS Glue를 사용하여 ML transform으로 모델을 구축하고 학습합니다. Amazon OpenSearch Service를 사용하여 데이터를 시각화합니다.",
    "SelectA_Commentary": "AWS Glue의 ML transform은 ETL 환경에 특화되어 있어 본격적인 모델 훈련 및 배포에는 적합하지 않으며, 운영 오버헤드도 늘어납니다.",
    "SelectB": "Amazon SageMaker를 사용하여 모델을 구축하고 학습합니다. Amazon QuickSight를 사용하여 데이터를 시각화합니다.",
    "SelectB_Commentary": "SageMaker는 완전관리형 ML 서비스로 모델 구축·학습을 간소화하며 QuickSight와 연동해 시각화가 용이해 운영 오버헤드가 가장 적은 올바른 솔루션입니다.",
    "SelectC": "AWS Marketplace의 사전 구성된 ML Amazon Machine Image(AMI)를 사용하여 모델을 구축하고 학습합니다. Amazon OpenSearch Service를 사용하여 데이터를 시각화합니다.",
    "SelectC_Commentary": "AMI 활용 시 추가 설정과 유지보수가 필요해 운영 부담이 늘어납니다. OpenSearch Service는 텍스트 및 로그 분석용 시각화에 주로 사용됩니다.",
    "SelectD": "Amazon QuickSight에서 계산된 필드를 사용해 모델을 구축하고 학습합니다. Amazon QuickSight를 사용하여 데이터를 시각화합니다.",
    "SelectD_Commentary": "QuickSight의 계산된 필드는 대규모 ML 모델을 훈련하는 기능이 아니라 시각화용 데이터 계산에 적합합니다. ML 양질의 학습을 위해서는 SageMaker가 필요합니다.",
    "Question_Description_recommedations": [
      "Q493",
      "Q587",
      "Q687",
      "Q506",
      "Q915"
    ],
    "SelectA_recommedations": [
      "Q687",
      "Q515",
      "Q603"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q361",
      "Q631"
    ],
    "SelectC_recommedations": [
      "Q687",
      "Q335",
      "Q305"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q568",
      "Q443"
    ]
  },
  {
    "Question_Number": "Q433",
    "Question_Description": "한 회사가 여러 AWS 계정에서 운영 환경과 비운영 환경 워크로드를 운영하고 있습니다. 이 계정들은 AWS Organizations의 한 조직에 속해 있습니다. 회사는 cost usage tags의 수정을 방지하는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109384-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Organizations 내 여러 계정에서 cost usage tags를 임의로 수정하지 못하게 제한하는 보안 시나리오입니다. SCP를 활용하면 조직 전체에 일관된 권한 정책을 강제하여 태그 수정을 통제할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "cost usage tags",
      "태그 수정 방지",
      "서비스 컨트롤 폴리시"
    ],
    "Terms": [
      "AWS Organizations",
      "Service Control Policy(SCP)",
      "AWS Config",
      "AWS CloudTrail",
      "Amazon CloudWatch logs",
      "cost usage tags"
    ],
    "SelectA": "커스텀 AWS Config rule을 생성하여 승인된 주체 이외의 태그 수정을 방지합니다.",
    "SelectA_Commentary": "AWS Config rule로 리소스 구성을 모니터링할 수 있지만, 태그 수정을 직접적으로 차단하기에는 적합하지 않습니다.",
    "SelectB": "커스텀 AWS CloudTrail trail을 생성하여 태그 수정을 방지합니다.",
    "SelectB_Commentary": "CloudTrail은 감사를 위한 서비스이고 태그 수정 방지 자체 기능은 제공하지 않습니다.",
    "SelectC": "Service Control Policy(SCP)를 생성하여 승인된 주체 이외의 태그 수정을 방지합니다.",
    "SelectC_Commentary": "AWS Organizations의 SCP는 조직 내 계정 전체에 대한 권한 제한을 적용할 수 있어 요구사항을 충족하는 올바른 솔루션입니다.",
    "SelectD": "커스텀 Amazon CloudWatch logs를 생성하여 태그 수정을 방지합니다.",
    "SelectD_Commentary": "CloudWatch logs는 로그 모니터링 서비스로, 태그 수정 권한을 직접적으로 제한할 수는 없습니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q1018",
      "Q3",
      "Q878"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q313",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q898",
      "Q942",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q893",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q893",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q434",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 호스팅하고 있습니다. 애플리케이션은 Auto Scaling group 내의 Amazon EC2 인스턴스와 Elastic Load Balancer 뒤에서 실행되며, Amazon DynamoDB 테이블을 사용합니다. 이 회사는 애플리케이션이 최소 다운타임으로 다른 AWS Region에서 사용할 수 있도록 보장하고자 합니다. 가장 적은 다운타임으로 이러한 요구사항을 충족하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109294-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "DR(재해 복구) 시나리오에서 Auto Scaling group과 Elastic Load Balancer를 재해 복구(Disaster Recovery) 리전에 미리 구성하고, Amazon DynamoDB Global Table로 데이터를 실시간 복제하면 다운타임을 최소화할 수 있습니다. 또한 DNS Failover 기능을 통해 장애 시 트래픽을 자동으로 DR 리전으로 전환하므로 별도의 CloudWatch 알람과 Lambda를 이용한 추가 설정 없이 빠르게 대응이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Elastic Load Balancer",
      "Auto Scaling group",
      "Amazon DynamoDB",
      "DNS failover",
      "Global Table",
      "최소 다운타임"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic Load Balancer",
      "Auto Scaling",
      "Amazon DynamoDB",
      "AWS CloudFormation",
      "Global Table",
      "DNS failover",
      "Amazon CloudWatch",
      "AWS Lambda",
      "Amazon Route 53",
      "disaster recovery Region"
    ],
    "SelectA": "DR(재해 복구) 리전에 Auto Scaling group과 Load Balancer를 생성합니다. DynamoDB 테이블을 Global Table로 구성합니다. DNS failover가 DR 리전의 로드 밸런서를 가리키도록 설정합니다.",
    "SelectA_Commentary": "DNS Failover와 Global Table 실시간 동기화로 신속하고 간단한 DR 전환이 가능해 최소 다운타임이 보장됩니다.",
    "SelectB": "AWS CloudFormation 템플릿을 작성해 필요 시 EC2 인스턴스, 로드 밸런서, DynamoDB 테이블을 생성하도록 합니다. DNS failover를 DR 리전의 로드 밸런서를 가리키도록 설정합니다.",
    "SelectB_Commentary": "문제가 발생한 뒤에 리소스를 배포하므로 배포 시간 동안 다운타임이 발생할 수 있습니다.",
    "SelectC": "AWS CloudFormation 템플릿을 작성해 필요 시 EC2 인스턴스와 로드 밸런서를 생성하도록 합니다. DynamoDB 테이블을 Global Table로 구성합니다. DNS failover를 DR 리전의 로드 밸런서를 가리키도록 설정합니다.",
    "SelectC_Commentary": "재해 복구 시점에 리소스를 새로 생성해야 하므로 빠른 전환이 어려워 다운타임이 길어질 수 있습니다.",
    "SelectD": "DR 리전에 Auto Scaling group과 로드 밸런서를 생성합니다. DynamoDB 테이블을 Global Table로 구성합니다. CloudWatch 알람으로 장애를 감지하고 Lambda 함수를 통해 Route 53을 업데이트하여 DR 로드 밸런서를 가리키도록 합니다.",
    "SelectD_Commentary": "DNS Failover 기능만으로도 필요 시 자동 전환이 가능하므로 CloudWatch와 Lambda를 활용한 추가 설정은 오버엔지니어링이 될 수 있습니다.",
    "Question_Description_recommedations": [
      "Q479",
      "Q138",
      "Q874",
      "Q454",
      "Q711"
    ],
    "SelectA_recommedations": [
      "Q874",
      "Q955",
      "Q343"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q935",
      "Q768"
    ],
    "SelectC_recommedations": [
      "Q874",
      "Q768",
      "Q935"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q343",
      "Q836"
    ]
  },
  {
    "Question_Number": "Q435",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에 있는 MySQL 데이터베이스(20TB)를 2주 이내에 AWS로 마이그레이션해야 합니다. 회사는 다운타임을 최소화하면서 마이그레이션을 완료하기를 원합니다. 어떤 솔루션이 가장 비용 효율적으로 데이터베이스를 마이그레이션할 수 있습니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109377-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량(20TB) MySQL 데이터베이스를 단기간(2주 내)으로 옮기면서 다운타임과 비용을 최소화하는 전략을 묻습니다. Snowball Edge Storage Optimized와 AWS DMS의 조합이 효율성과 비용 면에서 가장 적절합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3",
      "4.4"
    ],
    "Keywords": [
      "MySQL",
      "20TB",
      "2주",
      "비용 효율적",
      "다운타임 최소화"
    ],
    "Terms": [
      "AWS Database Migration Service (AWS DMS)",
      "AWS Schema Conversion Tool (AWS SCT)",
      "AWS Snowball Edge Storage Optimized device",
      "AWS Snowmobile vehicle",
      "AWS Snowball Edge Compute Optimized with GPU device",
      "AWS Direct Connect",
      "ongoing changes"
    ],
    "SelectA": "AWS Snowball Edge Storage Optimized device를 주문합니다. AWS DMS와 AWS SCT를 사용하여 ongoing changes를 복제하면서 데이터베이스를 마이그레이션합니다. 이후 Snowball Edge를 AWS로 배송하여 마이그레이션을 완료하고 ongoing replication을 계속 진행합니다.",
    "SelectA_Commentary": "Snowball Edge Storage Optimized는 대용량 데이터를 경제적이면서 빠르게 전송할 수 있습니다. AWS DMS의 ongoing replication을 통해 다운타임도 최소화됩니다.",
    "SelectB": "AWS Snowmobile vehicle을 주문합니다. AWS DMS와 AWS SCT를 사용하여 ongoing changes를 복제하면서 데이터베이스를 마이그레이션합니다. 이후 Snowmobile을 AWS로 돌려보내 마이그레이션을 완료하고 ongoing replication을 계속 진행합니다.",
    "SelectB_Commentary": "Snowmobile은 페타바이트~엑사바이트 규모의 초대형 전송용으로, 20TB 마이그레이션에는 과도하고 비용이 더 많이 듭니다.",
    "SelectC": "AWS Snowball Edge Compute Optimized with GPU device를 주문합니다. AWS DMS와 AWS SCT를 사용하여 ongoing changes를 복제하면서 데이터베이스를 마이그레이션합니다. 이후 Snowball device를 AWS로 배송하여 마이그레이션을 완료하고 ongoing replication을 계속 진행합니다.",
    "SelectC_Commentary": "Compute Optimized with GPU 기능은 고성능 연산이 필요한 경우 유용하지만, 단순 데이터 전송 목적에는 불필요하게 비용이 높습니다.",
    "SelectD": "전용 1GB AWS Direct Connect를 주문하여 데이터 센터와 연결을 설정합니다. AWS DMS와 AWS SCT를 사용하여 ongoing changes를 복제하면서 데이터베이스를 마이그레이션합니다.",
    "SelectD_Commentary": "Direct Connect 구독 비용과 네트워크 대역폭을 고려하면, 20TB를 2주 내 전송할 때 Snowball Edge보다 비용이 더 들 수 있으며 구축 복잡성도 있습니다.",
    "Question_Description_recommedations": [
      "Q411",
      "Q485",
      "Q943",
      "Q449",
      "Q486"
    ],
    "SelectA_recommedations": [
      "Q926",
      "Q591",
      "Q822"
    ],
    "SelectB_recommedations": [
      "Q486",
      "Q380",
      "Q31"
    ],
    "SelectC_recommedations": [
      "Q926",
      "Q591",
      "Q822"
    ],
    "SelectD_recommedations": [
      "Q499",
      "Q240",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q436",
    "Question_Description": "한 회사가 온프레미스 PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스로 이전했습니다. 회사는 새 제품을 성공적으로 출시했고, 데이터베이스에 대한 워크로드가 증가했습니다. 회사는 추가 인프라를 늘리지 않고 더 큰 워크로드를 수용하고자 합니다. 가장 비용 효율적인 방식으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109277-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 증가한 DB 워크로드를 처리하면서도 추가 인프라 없이, 비용을 최소화하는 방안을 묻습니다. 수직 확장(스케일 업)과 Reserved DB Instances 활용이 장기적으로 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "추가 인프라 없이",
      "비용 효율적",
      "Reserved DB Instances",
      "스케일 업",
      "Multi-AZ"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Reserved DB Instances",
      "Multi-AZ",
      "On-Demand",
      "DB Instance"
    ],
    "SelectA": "전체 워크로드에 대해 Reserved DB Instances를 구매하고, Amazon RDS for PostgreSQL DB 인스턴스를 더 큰 사이즈로 만듭니다.",
    "SelectA_Commentary": "정답. 수직 확장으로 성능을 높이고, 예약 인스턴스를 통해 장기적인 비용 절감 효과를 얻을 수 있습니다.",
    "SelectB": "Amazon RDS for PostgreSQL DB 인스턴스를 Multi-AZ DB 인스턴스로 만듭니다.",
    "SelectB_Commentary": "Multi-AZ 구성은 고가용성을 보장하지만, 워크로드 증가 대응이 아닌 장애 대비용이라 비용 효율적이지 않습니다.",
    "SelectC": "전체 워크로드에 대해 Reserved DB Instances를 구매하고, 추가 Amazon RDS for PostgreSQL DB 인스턴스를 만듭니다.",
    "SelectC_Commentary": "추가 DB 인스턴스를 생성하는 수평 확장은 ‘추가 인프라 없음’ 조건에 어긋나고 운영 비용이 더 증가합니다.",
    "SelectD": "Amazon RDS for PostgreSQL DB 인스턴스를 온디맨드 DB 인스턴스로 만듭니다.",
    "SelectD_Commentary": "온디맨드 인스턴스는 장기 비용이 예약 인스턴스보다 높기 때문에 효과적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q579",
      "Q940",
      "Q574",
      "Q959",
      "Q851"
    ],
    "SelectA_recommedations": [
      "Q579",
      "Q436",
      "Q940"
    ],
    "SelectB_recommedations": [
      "Q436",
      "Q579",
      "Q940"
    ],
    "SelectC_recommedations": [
      "Q579",
      "Q940",
      "Q436"
    ],
    "SelectD_recommedations": [
      "Q436",
      "Q579",
      "Q940"
    ]
  },
  {
    "Question_Number": "Q437",
    "Question_Description": "한 회사가 Application Load Balancer (ALB) 뒤의 Amazon EC2 인스턴스 오토 스케일링 그룹에서 이커머스 웹사이트를 운영하고 있습니다. 외부의 변화하는 IP 주소를 사용하는 불법적인 시스템으로부터 높은 요청량이 발생해 성능 장애가 일어나고 있으며, 보안 팀은 웹사이트에 대한 잠재적인 DDoS 공격을 우려하고 있습니다. 합법적인 사용자의 영향이 최소화되는 방식으로 이러한 불법 요청을 차단해야 합니다. 솔루션스 아키텍트는 어떤 조치를 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109378-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 불법적인 트래픽을 식별해 차단하여 DDoS에 대비하고, 정상 사용자의 접근에 지장을 주지 않는 최적의 방안을 묻습니다. AWS WAF를 ALB에 연결하고 rate-limiting 규칙을 사용하면 과도한 요청을 효과적으로 제한할 수 있어 합법적 사용자의 불편을 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "성능 문제",
      "DDoS 공격",
      "불법 요청 차단",
      "합법적 사용자 영향 최소화",
      "AWS WAF",
      "rate-limiting"
    ],
    "Terms": [
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "Auto Scaling group",
      "AWS WAF",
      "Amazon Inspector",
      "network ACL",
      "Amazon GuardDuty",
      "DDoS",
      "rate-limiting"
    ],
    "SelectA": "Amazon Inspector를 배포하고 ALB에 연결합니다.",
    "SelectA_Commentary": "Amazon Inspector는 보안 취약성 평가 서비스로, DDoS 방어 또는 실시간 불법 요청 차단에 직접적으로 관여하지 못하므로 문제 요구사항을 해결하기 어렵습니다.",
    "SelectB": "AWS WAF를 배포하고 ALB에 연결한 뒤, rate-limiting 규칙을 구성합니다.",
    "SelectB_Commentary": "정답입니다. AWS WAF에 rate-limiting 규칙을 적용하면 특정 리소스에 대한 과도한 요청만 효과적으로 차단하여 정상 트래픽의 서비스 이용을 유지할 수 있습니다.",
    "SelectC": "ALB와 연결된 network ACL에 규칙을 배포하여 들어오는 트래픽을 차단합니다.",
    "SelectC_Commentary": "network ACL은 CIDR 단위로 트래픽을 제어하므로 세분화된 차단 규칙을 적용하기 어렵고, IP가 자주 바뀌는 공격을 대응하기에 부적절합니다.",
    "SelectD": "Amazon GuardDuty를 배포하고, GuardDuty 설정 시 rate-limiting 보호를 활성화합니다.",
    "SelectD_Commentary": "Amazon GuardDuty는 위협 탐지 서비스로, 직접 트래픽을 차단하기 위해 설계된 것이 아니므로 즉각적인 요청 제한이나 차단에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q701",
      "Q169",
      "Q707",
      "Q927",
      "Q744"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q426",
      "Q122"
    ],
    "SelectB_recommedations": [
      "Q169",
      "Q60",
      "Q165"
    ],
    "SelectC_recommedations": [
      "Q169",
      "Q707",
      "Q60"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ]
  },
  {
    "Question_Number": "Q438",
    "Question_Description": "회사는 외부 감사인과 회계 데이터를 공유하려고 합니다. 해당 데이터는 private subnet에 위치한 Amazon RDS DB instance에 저장되어 있습니다. 감사인은 자체 AWS 계정을 보유하고 있으며, 데이터베이스 사본을 별도로 보유해야 합니다. 가장 보안성이 높은 상태로 데이터를 감사인과 공유하려면 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109398-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 private subnet에 위치한 RDS 인스턴스의 데이터를 외부 감사인과 가장 안전하게 공유하는 방법을 묻습니다. 암호화된 스냅샷을 공유하고 KMS 키에 대한 접근 권한을 제공함으로써 데이터 무결성과 기밀성을 확보할 수 있으며, 감사인은 자신의 AWS 계정에서 안전하게 복원하여 사용할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "private subnet",
      "Amazon RDS DB instance",
      "외부 감사인",
      "데이터베이스 사본",
      "암호화 스냅샷",
      "AWS KMS 암호화 키"
    ],
    "Terms": [
      "Amazon RDS",
      "RDS Snapshot",
      "읽기 전용 복제본",
      "AWS KMS",
      "Encrypted Snapshot",
      "IAM",
      "Amazon S3",
      "KMS encryption key"
    ],
    "SelectA": "데이터베이스의 읽기 전용 복제본을 생성합니다. IAM 표준 데이터베이스 인증을 구성하여 감사인에게 액세스 권한을 부여합니다.",
    "SelectA_Commentary": "읽기 전용 복제본은 다른 계정과 직접 공유하기에 제한이 있으며, 보안적으로 외부 계정에 완전한 사본을 제공하기에는 적합하지 않습니다.",
    "SelectB": "데이터베이스 내용을 텍스트 파일로 내보냅니다. 이 파일들을 Amazon S3 버킷에 저장합니다. 감사인을 위한 새로운 IAM 사용자를 생성하고, 해당 S3 버킷에 대한 액세스 권한을 부여합니다.",
    "SelectB_Commentary": "텍스트 파일로 내보내는 방식은 관리 부담이 크고, 데이터 유출 위험도 증가합니다. 또한 직접 DB 사본을 제공하지 못하므로 안전성 측면에서 한계가 있습니다.",
    "SelectC": "데이터베이스 스냅샷을 Amazon S3 버킷으로 복사합니다. IAM 사용자를 생성하고, 이 사용자의 키를 감사인에게 공유하여 해당 S3 객체에 접근할 수 있게 합니다.",
    "SelectC_Commentary": "스냅샷을 직접 S3에 복사해 공유하는 것은 암호화를 별도로 처리해야 하고, 키 공유 문제로 보안 위험이 증가할 수 있습니다.",
    "SelectD": "데이터베이스의 암호화된 스냅샷을 생성합니다. 이 스냅샷을 감사인과 공유합니다. 그리고 AWS Key Management Service (AWS KMS) 암호화 키에 대한 액세스 권한을 허용합니다.",
    "SelectD_Commentary": "암호화된 스냅샷을 공유하고 KMS 키 접근을 허용함으로써 데이터 보안과 효율적인 접근 제어가 가능합니다. 가장 안전하고 권장되는 방법입니다.",
    "Question_Description_recommedations": [
      "Q330",
      "Q742",
      "Q810",
      "Q61",
      "Q732"
    ],
    "SelectA_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q44",
      "Q965",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q202",
      "Q965",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ]
  },
  {
    "Question_Number": "Q439",
    "Question_Description": "한 솔루션스 아키텍트가 작은 IP 주소 범위를 가진 VPC를 구성했습니다. VPC 내 Amazon EC2 인스턴스의 수가 증가하여, 향후 워크로드에 필요한 IP 주소가 부족합니다. 운영 오버헤드를 최소화하면서 이 문제를 해결할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109400-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC의 IP 주소 범위가 포화 상태에 가까워 향후 EC2 인스턴스나 워크로드를 추가하기 어려운 상황을 해결하는 방법을 묻습니다. VPC에 추가 IPv4 CIDR 블록을 할당하면 기존 리소스를 크게 변경하지 않고도 IP 주소를 쉽게 확장할 수 있어, 운영 오버헤드가 가장 낮은 방법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "VPC IP 주소 부족",
      "운영 오버헤드 최소화",
      "확장 가능한 아키텍처"
    ],
    "Terms": [
      "VPC",
      "IPv4 CIDR Block",
      "Subnet",
      "Amazon EC2",
      "VPC Peering",
      "AWS Transit Gateway",
      "Site-to-Site VPN",
      "Virtual Private Gateway"
    ],
    "SelectA": "추가 IPv4 CIDR 블록을 할당하여 IP 주소 범위를 늘린 뒤, 신규 CIDR을 사용하는 서브넷을 생성하고 새 리소스를 이 서브넷에 배치합니다.",
    "SelectA_Commentary": "기존 VPC에 간단히 CIDR 블록을 추가해 IP 주소를 확장할 수 있어 운영 오버헤드가 가장 낮은 최적의 솔루션입니다.",
    "SelectB": "두 번째 VPC를 생성하고 추가 서브넷을 구성합니다. 첫 번째 VPC와 두 번째 VPC 사이에 VPC Peering 연결을 생성하고 라우트를 업데이트한 뒤, 두 번째 VPC 서브넷에 신규 리소스를 생성합니다.",
    "SelectB_Commentary": "VPC Peering을 사용하면 VPC를 분할해 운영하지만, 라우트 테이블 및 리소스 이관이 복잡해 운영 부담이 증가합니다.",
    "SelectC": "AWS Transit Gateway를 사용하여 트랜짓 게이트웨이를 추가하고, 두 번째 VPC를 첫 번째 VPC와 연결합니다. 트랜짓 게이트웨이와 각 VPC의 라우트를 업데이트하고, 두 번째 VPC 서브넷에 신규 리소스를 생성합니다.",
    "SelectC_Commentary": "Transit Gateway는 엔터프라이즈 규모의 네트워크 연결에는 적합하지만, 단순히 IP를 확장하기에는 구성과 비용이 더 복잡합니다.",
    "SelectD": "두 번째 VPC를 생성하고, Amazon EC2 기반 VPN 호스팅 솔루션과 Virtual Private Gateway를 사용하여 첫 번째 VPC와 두 번째 VPC를 Site-to-Site VPN으로 연결합니다. VPC 간 라우트를 VPN 경로로 업데이트하고, 두 번째 VPC 서브넷에 새 리소스를 만듭니다.",
    "SelectD_Commentary": "VPN 구성이 추가되어 복잡성과 유지보수 부담이 증가하므로, IP 주소 확장만 필요한 경우에는 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q101",
      "Q504",
      "Q237",
      "Q487",
      "Q296"
    ],
    "SelectA_recommedations": [
      "Q101",
      "Q296",
      "Q567"
    ],
    "SelectB_recommedations": [
      "Q439",
      "Q504",
      "Q758"
    ],
    "SelectC_recommedations": [
      "Q504",
      "Q722",
      "Q10"
    ],
    "SelectD_recommedations": [
      "Q487",
      "Q439",
      "Q237"
    ]
  },
  {
    "Question_Number": "Q440",
    "Question_Description": "한 회사가 애플리케이션 테스트를 위해 Amazon RDS for MySQL DB 인스턴스를 사용했습니다. 테스트 사이클이 끝날 때 DB 인스턴스를 종료하기 전, 솔루션스 아키텍트는 두 가지 백업을 생성했습니다. 첫 번째 백업은 mysqldump 유틸리티를 사용하여 데이터베이스 덤프로 생성했고, 두 번째 백업은 RDS 종료 시점에 final DB snapshot 옵션을 활성화하여 생성했습니다. 회사는 새로운 테스트 사이클을 준비하며, 가장 최근 백업으로부터 새로운 DB 인스턴스를 생성하고자 합니다. 회사는 MySQL 호환 Amazon Aurora 에디션을 사용하여 DB 인스턴스를 호스팅하기로 결정했습니다. 다음 중 어떤 솔루션이 새로운 DB 인스턴스를 생성할 수 있습니까? (두 가지를 선택하세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109297-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS for MySQL에서 생성된 두 가지 백업(데이터베이스 덤프와 RDS snapshot)을 어떻게 활용하여 MySQL 호환 Amazon Aurora 인스턴스를 생성할 수 있는지 묻습니다. RDS snapshot은 이미 AWS 내부에 존재하므로 직접 Aurora로 가져올 수 있고(mysqldump로 만든 덤프는 Amazon S3 업로드 후 Aurora로 가져올 수 있습니다. AWS DMS는 별도의 마이그레이션 시나리오에 적합하므로 여기서는 불필요합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "mysqldump",
      "DB snapshot",
      "Amazon Aurora",
      "MySQL 호환",
      "백업",
      "새로운 DB 인스턴스"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "mysqldump",
      "DB snapshot",
      "MySQL-compatible Amazon Aurora",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon S3"
    ],
    "SelectA": "RDS snapshot을 Aurora로 직접 Import 합니다.",
    "SelectA_Commentary": "RDS snapshot은 이미 AWS 내부에 저장되어 있으므로 Aurora로 바로 Import가 가능합니다. 간단하고 신속하게 DB를 복원할 수 있습니다.",
    "SelectB": "RDS snapshot을 Amazon S3에 업로드한 뒤, 이를 Aurora로 Import 합니다.",
    "SelectB_Commentary": "이미 AWS에 저장된 RDS snapshot을 굳이 Amazon S3로 옮겨 Import할 필요가 없어 절차가 불필요하게 복잡해집니다.",
    "SelectC": "데이터베이스 덤프를 Amazon S3에 업로드한 다음, 그 덤프를 Aurora로 Import 합니다.",
    "SelectC_Commentary": "mysqldump 형식의 덤프는 S3 업로드 후 MySQL 호환 Aurora로 쉽게 Import할 수 있어 추가 마이그레이션 툴이 필요 없습니다.",
    "SelectD": "AWS Database Migration Service(AWS DMS)를 사용해 RDS snapshot을 Aurora로 Import 합니다.",
    "SelectD_Commentary": "AWS DMS는 실시간 마이그레이션 시나리오 등에 적합하며, RDS snapshot을 직접 Import할 수 있는 기능으로는 적절하지 않습니다.",
    "SelectE": "데이터베이스 덤프를 Amazon S3에 업로드한 뒤, AWS DMS를 사용해 Aurora로 Import 합니다.",
    "SelectE_Commentary": "DMS를 추가로 활용할 필요가 없어 절차가 복잡하며, mysqldump를 Aurora로 직접 Import가 가능하므로 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q518",
      "Q629",
      "Q601",
      "Q259",
      "Q989"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q843",
      "Q462"
    ],
    "SelectB_recommedations": [
      "Q601",
      "Q490",
      "Q843"
    ],
    "SelectC_recommedations": [
      "Q784",
      "Q194",
      "Q110"
    ],
    "SelectD_recommedations": [
      "Q601",
      "Q338",
      "Q518"
    ],
    "SelectE_recommedations": [
      "Q784",
      "Q194",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q441",
    "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Amazon Linux Amazon EC2 인스턴스로 구성된 다중 계층 웹 애플리케이션을 운영하고 있습니다. 이 인스턴스들은 여러 가용 영역(Availability Zones)에 걸쳐 Auto Scaling group으로 동작합니다. 최근 사용자들이 정적 웹 콘텐츠를 대량으로 요청할 때마다 Auto Scaling group이 On-Demand Instances를 추가로 시작하고 있으며, 회사는 비용 최적화를 원하고 있습니다. 가장 비용 효율적인 방식으로 애플리케이션을 재설계하려면 어떻게 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109423-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 정적 웹 콘텐츠 요청이 증가할 때마다 Amazon EC2 인스턴스 사용량도 함께 늘어나 비용이 상승한다는 점입니다. 이를 해결하기 위해서는 정적 콘텐츠를 Amazon S3와 Amazon CloudFront로 분리해 제공함으로써, EC2 사용량을 줄이고 비용을 절감할 수 있습니다. 추가로 Reserved Instances나 Spot Instances를 도입하는 방법도 있지만, 정적 콘텐츠 제공 방식을 근본적으로 개선하지 않으면 EC2 비용이 계속 늘어날 수밖에 없습니다. 따라서 정적 파일 제공을 직접 EC2 대신 CloudFront와 S3를 활용하는 옵션이 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.4"
    ],
    "Keywords": [
      "다중 계층 웹 애플리케이션",
      "정적 웹 콘텐츠",
      "비용 최적화",
      "Auto Scaling group",
      "Amazon EC2"
    ],
    "Terms": [
      "Application Load Balancer",
      "Amazon EC2",
      "Auto Scaling group",
      "On-Demand Instances",
      "Reserved Instances",
      "Spot Instances",
      "Amazon CloudFront",
      "Amazon S3",
      "AWS Lambda",
      "Amazon API Gateway"
    ],
    "SelectA": "Auto Scaling group에서 On-Demand Instances 대신 Reserved Instances를 사용하도록 업데이트합니다.",
    "SelectA_Commentary": "Reserved Instances는 장기 사용 시 비용을 절감할 수 있지만, 정적 콘텐츠 자체를 EC2로 서빙하는 구조를 그대로 두므로 EC2 수요가 늘어날 때 근본적인 해결책이 되지 못합니다.",
    "SelectB": "Auto Scaling group에서 On-Demand Instances 대신 Spot Instances를 사용하도록 스케일링 정책을 변경합니다.",
    "SelectB_Commentary": "Spot Instances는 저렴하지만 중단 가능성이 있으며, 여전히 정적 콘텐츠 서빙을 EC2에 의존해 비용이 크게 줄지 않을 수 있습니다.",
    "SelectC": "Amazon S3 버킷의 정적 웹 콘텐츠를 Amazon CloudFront distribution으로 제공하도록 구성합니다.",
    "SelectC_Commentary": "정적 콘텐츠를 S3와 CloudFront로 직접 서빙하면 EC2 사용량이 크게 줄어들어 가장 비용 효율적인 방안입니다. 글로벌 엣지 로케이션에서 빠르게 콘텐츠를 전달할 수 있어 사용자 경험도 향상됩니다.",
    "SelectD": "AWS Lambda 함수와 Amazon API Gateway API를 사용해 정적 웹사이트 콘텐츠를 호스팅합니다.",
    "SelectD_Commentary": "Lambda와 API Gateway는 동적 요청이나 서버리스 애플리케이션에 적합하지만, 대량의 정적 콘텐츠 제공에는 오히려 비용과 구조 복잡도가 늘어날 수 있어 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q984",
      "Q245",
      "Q146",
      "Q473",
      "Q894"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q424",
      "Q290"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q424",
      "Q505"
    ],
    "SelectC_recommedations": [
      "Q993",
      "Q943",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q220",
      "Q770",
      "Q807"
    ]
  },
  {
    "Question_Number": "Q442",
    "Question_Description": "회사는 여러 AWS 계정에 걸쳐 페타바이트(페타바이트급)의 데이터를 저장하고 있으며, AWS Lake Formation을 사용해 데이터 레이크를 관리하고 있습니다. 회사의 데이터 사이언스 팀은 엔지니어링 팀과 필요한 데이터만 선택적으로 안전하게 공유하여 분석 목적으로 사용하고자 합니다. 이 요구사항을 운영 오버헤드를 최소화하면서 충족하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109647-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 계정에 분산된 대규모 데이터를 보안 요구사항과 최소한의 운영 복잡도로 공유하는 문제입니다. Lake Formation의 태그 기반 접근 제어(tag-based access control)를 활용하면, 별도의 복제나 추가 권한 설정 없이 필요한 데이터에 대해 정확하고 세밀하게 크로스 계정 권한을 부여할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Lake Formation",
      "데이터 공유",
      "크로스 계정 액세스",
      "운영 오버헤드 최소화",
      "tag-based access control"
    ],
    "Terms": [
      "AWS Lake Formation",
      "IAM access role",
      "Lake Formation permissions Grant command",
      "AWS Data Exchange",
      "Lake Formation tag-based access control"
    ],
    "SelectA": "필요한 데이터를 공용 계정으로 복사하고, 그 계정에 IAM 액세스 롤을 생성합니다. 엔지니어링 팀 계정의 사용자들을 신뢰 주체로 지정하는 권한 정책을 구성합니다.",
    "SelectA_Commentary": "공용 계정으로 데이터 복사, 계정 간 권한 정책 설정 등 여러 단계를 거쳐야 하므로 운영 오버헤드가 큽니다.",
    "SelectB": "각 계정에서 Lake Formation permissions Grant 명령을 사용해 엔지니어링 팀 사용자가 데이터를 액세스하도록 허용합니다.",
    "SelectB_Commentary": "각 계정마다 Grant 명령을 개별적으로 수행해야 하므로, 계정 수가 많을 경우 작업이 번거롭습니다.",
    "SelectC": "AWS Data Exchange를 사용해 필요한 데이터를 엔지니어링 팀 계정으로 비공개 게시합니다.",
    "SelectC_Commentary": "AWS Data Exchange는 외부 배포나 상업적 데이터 교환에 주로 사용되며, 내부 크로스 계정 공유에는 맞지 않아 오버헤드가 증가합니다.",
    "SelectD": "Lake Formation 태그 기반 액세스 제어(tag-based access control)를 사용해 데이터에 대한 크로스 계정 권한을 엔지니어링 팀 계정에 부여합니다.",
    "SelectD_Commentary": "태그를 활용해 필요한 데이터에만 정확하게 접근 권한을 설정할 수 있어, 데이터 복사나 별도 계정 생성 없이 최소한의 운영 오버헤드로 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q495",
      "Q609",
      "Q893",
      "Q484",
      "Q592"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q665",
      "Q478"
    ],
    "SelectB_recommedations": [
      "Q478",
      "Q665",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q529",
      "Q898",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q495",
      "Q442",
      "Q609"
    ]
  },
  {
    "Question_Number": "Q443",
    "Question_Description": "회사는 AWS 상에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다. 이 애플리케이션은 전 세계 다양한 지리적 리전에서 접근할 예정이며, 사용자는 최대 기가바이트 단위의 고유 데이터를 다운로드하고 업로드할 수 있습니다. 개발 팀은 업로드 및 다운로드 지연을 최소화하고 성능을 극대화하면서 비용 효율적인 솔루션을 원합니다. 이를 달성하기 위해 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109424-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 세계 여러 지역에서 대용량 데이터를 효율적으로 업로드·다운로드하기 위해 네트워크 전송 속도와 비용 효과를 모두 고려해야 합니다. Amazon S3의 Transfer Acceleration 기능은 글로벌 Edge Location을 통해 지연을 크게 줄이고, 대용량 업로드 및 다운로드 모두에 이점을 제공합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "확장 가능한 웹 애플리케이션",
      "업로드 및 다운로드 지연 최소화",
      "성능 극대화",
      "비용 효율적",
      "Amazon S3 Transfer Acceleration"
    ],
    "Terms": [
      "Amazon S3",
      "Transfer Acceleration",
      "CacheControl headers",
      "Amazon EC2",
      "Auto Scaling",
      "Amazon CloudFront",
      "Amazon ElastiCache"
    ],
    "SelectA": "Amazon S3와 Transfer Acceleration을 사용하여 애플리케이션을 호스팅합니다.",
    "SelectA_Commentary": "Transfer Acceleration은 전 세계 Edge Location을 활용해 대규모 데이터를 빠르고 저렴하게 전송하므로, 지연을 줄이고 성능을 극대화할 수 있는 최적의 방식입니다.",
    "SelectB": "Amazon S3와 CacheControl 헤더를 사용하여 애플리케이션을 호스팅합니다.",
    "SelectB_Commentary": "CacheControl 헤더는 정적 콘텐츠 캐싱에 유용하지만, 업로드 지연 개선에 큰 도움이 되지 않아 세계 각지에서의 빠른 업로드 요구사항을 충족시키기 어렵습니다.",
    "SelectC": "Amazon EC2와 Auto Scaling, Amazon CloudFront를 사용하여 애플리케이션을 호스팅합니다.",
    "SelectC_Commentary": "CloudFront는 다운로드 성능엔 도움이 되지만 대용량 업로드를 위한 전송 가속 기능이 없으므로, 업로드 지연과 비용 효율 양 측면에서 최적의 해법은 아닙니다.",
    "SelectD": "Amazon EC2와 Auto Scaling, Amazon ElastiCache를 사용하여 애플리케이션을 호스팅합니다.",
    "SelectD_Commentary": "ElastiCache는 데이터베이스 캐싱용 서비스이며 전 지구적 업로드·다운로드 가속을 지원하지 않습니다. 지연을 직접적으로 줄이는 솔루션이 아니므로 부적합합니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q568",
      "Q631",
      "Q547",
      "Q865"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q1015",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q626",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q857",
      "Q335",
      "Q305"
    ],
    "SelectD_recommedations": [
      "Q857",
      "Q335",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q444",
    "Question_Description": "한 회사가 솔루션스 아키텍트를 고용하여 애플리케이션을 위한 신뢰할 수 있는 아키텍처를 설계하고자 합니다. 애플리케이션은 하나의 Amazon RDS DB instance와 웹 서버가 설치된 두 개의 수동 프로비저닝된 Amazon EC2 instance로 구성되어 있습니다. 현재 EC2 instance들은 단일 가용 영역(Availability Zone)에 위치해 있습니다. 최근 한 직원이 실수로 DB instance를 삭제하여 애플리케이션이 24시간 동안 중단되었습니다. 회사는 전체적인 환경의 신뢰성에 대해 우려하고 있습니다. 애플리케이션 인프라의 신뢰성을 극대화하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109426-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 가용 영역에서 운영 중이던 EC2와 삭제 보호 미설정 DB instance로 인해 장애가 발생한 사례입니다. Multi-AZ 설정 및 deletion protection을 적용하고, EC2는 여러 가용 영역에 걸쳐 Auto Scaling과 Load Balancer로 구성하여 고가용성을 확보하는 방안을 묻습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS Multi-AZ",
      "Amazon EC2",
      "Application Load Balancer",
      "EC2 Auto Scaling",
      "삭제 보호",
      "가용 영역",
      "신뢰성"
    ],
    "Terms": [
      "Amazon RDS",
      "DB instance",
      "Multi-AZ",
      "Termination Protection",
      "Deletion Protection",
      "Application Load Balancer",
      "EC2 Auto Scaling group",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon CloudWatch"
    ],
    "SelectA": "한 개의 EC2 인스턴스를 삭제하고 남은 EC2 인스턴스에 termination protection을 활성화합니다. DB 인스턴스를 Multi-AZ로 업데이트하고 deletion protection을 활성화합니다.",
    "SelectA_Commentary": "EC2 인스턴스를 하나만 남기면 여전히 장애에 취약하므로 고가용성을 확보하기 어렵습니다. DB에는 deletion protection이 필요하지만, 웹 계층도 다중 AZ 구성이 필수입니다.",
    "SelectB": "DB 인스턴스를 Multi-AZ로 업데이트하고 deletion protection을 활성화합니다. EC2 인스턴스를 Application Load Balancer 뒤에 배치하고, 여러 가용 영역에 걸쳐 EC2 Auto Scaling group으로 운영합니다.",
    "SelectB_Commentary": "DB Multi-AZ와 deletion protection으로 데이터베이스 신뢰성을 높이고, 웹 서버도 여러 가용 영역과 Auto Scaling, Load Balancer를 통해 고가용성을 달성하므로 정답입니다.",
    "SelectC": "추가 DB 인스턴스, Amazon API Gateway, AWS Lambda 함수를 생성하고, Lambda 함수를 통해 두 DB 인스턴스에 데이터를 쓰도록 애플리케이션을 구성합니다.",
    "SelectC_Commentary": "Lambda와 API Gateway로 DB를 이중화하는 방법은 단순 DB Multi-AZ보다 복잡하고 운영 부담이 커서 권장되지 않습니다.",
    "SelectD": "여러 가용 영역에 걸쳐 서브넷을 구성한 EC2 Auto Scaling group에 EC2 인스턴스를 배치하고, On-Demand 대신 Spot Instances를 사용합니다. Amazon CloudWatch 알람으로 인스턴스 상태를 모니터링하고, DB 인스턴스를 Multi-AZ로 업데이트 및 deletion protection을 활성화합니다.",
    "SelectD_Commentary": "Spot Instances는 비용 효율적이나 중단 위험이 있어 신뢰성을 크게 높이지 못합니다. Auto Scaling 자체는 좋지만 예측불가한 중단 가능성이 커서 안정성 확보에 불리합니다.",
    "Question_Description_recommedations": [
      "Q125",
      "Q195",
      "Q228",
      "Q67",
      "Q259"
    ],
    "SelectA_recommedations": [
      "Q466",
      "Q768",
      "Q224"
    ],
    "SelectB_recommedations": [
      "Q390",
      "Q874",
      "Q955"
    ],
    "SelectC_recommedations": [
      "Q354",
      "Q843",
      "Q207"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q660",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q445",
    "Question_Description": "한 회사는 사내 데이터 센터의 대형 NAS(Network-attached Storage) 시스템에 700TB의 데이터를 저장하고 있습니다. 회사는 10Gbps AWS Direct Connect 연결을 갖춘 하이브리드 환경을 사용하고 있습니다. 규제 기관 감사 결과, 회사는 90일 이내에 해당 데이터를 클라우드로 마이그레이션해야 합니다. 이 과정에서 데이터 전송 효율과 무중단 접근이 중요하며, 전송 기간 동안에도 데이터를 업데이트하고 사용해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109403-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "700TB 대규모 데이터를 90일 안에 클라우드로 이전하면서도, 전송 중 무중단 접근이 필요합니다. AWS DataSync는 증분 전송과 동시 액세스를 지원해 이 요구사항을 효과적으로 해결합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "하이브리드 환경",
      "NAS",
      "10Gbps AWS Direct Connect",
      "90일 이내 마이그레이션",
      "무중단 접근",
      "AWS DataSync agent",
      "Amazon S3"
    ],
    "Terms": [
      "AWS DataSync",
      "AWS Snowball Edge Storage Optimized",
      "Amazon S3",
      "AWS Direct Connect",
      "rsync",
      "Tape backups",
      "NAS",
      "온프레미스 파일 시스템"
    ],
    "SelectA": "회사 데이터 센터에 AWS DataSync agent를 설치한 뒤 데이터 전송 태스크를 생성해 Amazon S3 버킷으로 전송을 시작합니다.",
    "SelectA_Commentary": "AWS DataSync는 증분 동기화와 예약 전송을 지원하고, Direct Connect를 활용해 대용량 데이터를 빠르고 안정적으로 이전하며 전송 중에도 데이터 접근과 수정이 가능합니다.",
    "SelectB": "데이터를 AWS Snowball Edge Storage Optimized 디바이스에 백업 후 AWS 데이터 센터로 배송하고, 온프레미스에서 대상 S3 버킷을 마운트합니다.",
    "SelectB_Commentary": "Snowball Edge는 물리 배송이므로 700TB 전송에 여러 번 디바이스 이용이 필요하고, 전송 중 데이터 변경을 실시간 반영하기 어려워 비효율적입니다.",
    "SelectC": "rsync를 사용하여 로컬 스토리지에서 Direct Connect를 통해 Amazon S3 버킷으로 직접 데이터를 복사합니다.",
    "SelectC_Commentary": "rsync만으로 700TB를 무중단 실시간 동기화하기 어렵고, 관리 오버헤드가 커서 최적의 방법이 아닙니다.",
    "SelectD": "테이프로 데이터를 백업하고 해당 테이프를 AWS 데이터 센터로 배송한 뒤, 온프레미스에서 대상 S3 버킷을 마운트합니다.",
    "SelectD_Commentary": "테이프 백업은 배송 과정에서 시간이 많이 소요되고, 전송 중 데이터 변경 반영이 불가능해 요건을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q604",
      "Q113",
      "Q299",
      "Q747",
      "Q76"
    ],
    "SelectA_recommedations": [
      "Q155",
      "Q672",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q702",
      "Q155",
      "Q305"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q672",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q155",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q446",
    "Question_Description": "어느 회사가 Amazon S3 버킷에 PDF 형식으로 데이터를 저장하고 있습니다. 해당 회사는 새로운 데이터와 기존 데이터를 모두 7년 동안 Amazon S3에 보관해야 하는 법적 요건을 준수해야 합니다. 가장 적은 운영 오버헤드를 갖고 이 요건을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109404-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 7년 보관 법적 요건을 만족하면서 모든 데이터를 쉽게 보호해야 합니다. S3 Object Lock의 compliance 모드와 S3 Batch Operations를 통해 기존·신규 데이터를 일괄 적용하여 운영 오버헤드를 줄일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "법적 요건",
      "7년 보관",
      "Amazon S3",
      "S3 Object Lock",
      "compliance retention mode",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "S3 Versioning",
      "S3 Lifecycle",
      "MFA delete",
      "S3 Object Lock",
      "governance retention mode",
      "compliance retention mode",
      "S3 Batch Operations"
    ],
    "SelectA": "S3 버킷에서 S3 Versioning 기능을 활성화합니다. S3 Lifecycle을 구성하여 7년 후 데이터를 삭제합니다. 모든 S3 객체에 대해 MFA delete를 구성합니다.",
    "SelectA_Commentary": "S3 Versioning과 Lifecycle만으로는 보존 기간 중 삭제 방지를 절대적으로 강제하기 어렵고, MFA delete도 관리 부담이 크므로 요건 충족에 비효율적입니다.",
    "SelectB": "S3 버킷에서 governance retention mode가 활성화된 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. 기존 데이터를 준수하도록 다시 복사합니다.",
    "SelectB_Commentary": "governance 모드는 적절하지만, 관리자 권한으로 해제할 수 있으므로 완전한 삭제 방지를 보장하지 못하고, 기존 데이터를 모두 재업로드해야 해 오버헤드가 큽니다.",
    "SelectC": "S3 버킷에서 compliance retention mode가 활성화된 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. 기존 데이터를 준수하도록 다시 복사합니다.",
    "SelectC_Commentary": "compliance 모드는 삭제 방지를 엄격히 적용하지만, 기존 데이터를 모두 재복사하는 방식은 여전히 운영 오버헤드가 큽니다.",
    "SelectD": "S3 버킷에서 compliance retention mode가 활성화된 S3 Object Lock을 켭니다. 보존 기간을 7년 후 만료로 설정합니다. S3 Batch Operations를 사용하여 기존 데이터를 준수하도록 설정합니다.",
    "SelectD_Commentary": "compliance 모드는 법적 보존 요구사항을 엄격히 준수해주며, S3 Batch Operations를 이용하면 기존 객체에 대한 일괄 적용이 가능해 운영 오버헤드를 최소화합니다.",
    "Question_Description_recommedations": [
      "Q856",
      "Q44",
      "Q202",
      "Q154",
      "Q825"
    ],
    "SelectA_recommedations": [
      "Q868",
      "Q270",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q256",
      "Q740",
      "Q856"
    ],
    "SelectC_recommedations": [
      "Q740",
      "Q256",
      "Q856"
    ],
    "SelectD_recommedations": [
      "Q862",
      "Q256",
      "Q740"
    ]
  },
  {
    "Question_Number": "Q447",
    "Question_Description": "한 회사는 Amazon API Gateway로부터 호출되는 AWS Lambda 함수로 동작하는 무상태 웹 애플리케이션을 운영합니다. 이 회사는 여러 AWS Region에 애플리케이션을 배포하여 지역 단위의 장애에도 대비할 수 있는 Regional failover 기능을 원합니다. 여러 Region으로 트래픽을 라우팅하려면 솔루션스 아키텍트가 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109405-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 Region에 무상태 웹 애플리케이션을 배포하여 장애를 대비하는 방법을 묻습니다. Amazon Route 53은 헬스 체크와 Failover 라우팅을 제공하여 Region별 장애 시 빠르게 대체 Region으로 트래픽을 전환할 수 있으므로, active-active 구성을 통해 안정적인 서비스를 유지할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "무상태 웹 애플리케이션",
      "AWS Lambda",
      "Amazon API Gateway",
      "Regional failover",
      "트래픽 라우팅"
    ],
    "Terms": [
      "Amazon Route 53",
      "active-active failover configuration",
      "Amazon CloudFront distribution",
      "CloudFront health checks",
      "AWS Transit Gateway",
      "Application Load Balancer",
      "API Gateway endpoint hostnames"
    ],
    "SelectA": "각 Region에 대해 Amazon Route 53 헬스 체크를 생성하고, active-active Failover 구성을 사용합니다.",
    "SelectA_Commentary": "Route 53은 글로벌 헬스 체크와 Failover 라우팅을 지원하므로, 여러 Region에 동일 서비스를 구현하고 장애 시에도 자동으로 트래픽을 분산할 수 있는 최적의 방식입니다.",
    "SelectB": "각 Region에 대해 Amazon CloudFront 배포를 생성하고, CloudFront 헬스 체크로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "CloudFront도 글로벌 엣지 네트워크를 통해 트래픽을 분산하지만, 경로 장애 시 명확한 Failover 라우팅을 구성하기에는 Route 53보다 적합하지 않습니다.",
    "SelectC": "Transit Gateway를 생성하고 각 Region의 API Gateway 엔드포인트에 연결한 뒤, Transit Gateway로 요청을 라우팅합니다.",
    "SelectC_Commentary": "Transit Gateway는 VPC 간 트래픽 라우팅에 사용되며, 다중 Region 로드 밸런싱 및 Failover 용도와는 직접적으로 맞지 않습니다.",
    "SelectD": "주요 Region에 Application Load Balancer를 생성하고, 타겟 그룹을 각 Region의 API Gateway 엔드포인트로 설정합니다.",
    "SelectD_Commentary": "단일 Region에 존재하는 ALB가 다른 Region의 엔드포인트로 트래픽을 분산해야 하므로, 다중 Region에서 고가용성을 보장하기에는 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q178",
      "Q585",
      "Q456",
      "Q224",
      "Q544"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q224",
      "Q585"
    ],
    "SelectB_recommedations": [
      "Q68",
      "Q8",
      "Q408"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q68",
      "Q700"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q575",
      "Q700"
    ]
  },
  {
    "Question_Number": "Q448",
    "Question_Description": "한 회사가 Management와 Production이라는 두 개의 VPC를 가지고 있습니다. Management VPC는 데이터 센터에 있는 단일 디바이스와 연결하기 위해 Customer Gateway를 통해 VPN을 사용합니다. Production VPC는 Virtual Private Gateway를 사용하며, 여기에 두 개의 AWS Direct Connect 연결이 attach되어 있습니다. Management VPC와 Production VPC는 애플리케이션 간 통신을 위해 단일 VPC Peering 연결을 사용합니다. 이 아키텍처에서 단일 장애 지점을 방지하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109499-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 하나의 Customer Gateway 디바이스에만 의존하는 Management VPC의 연결 구성을 이중화하여 단일 장애 지점을 제거해야 하는 상황을 다룹니다. 올바른 답변은 두 번째 Customer Gateway 장비를 추가하여 추가 VPN 연결을 구성함으로써 고가용성을 달성하는 방식입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Management VPC",
      "Production VPC",
      "단일 장애 지점",
      "Customer Gateway",
      "Virtual Private Gateway",
      "AWS Direct Connect",
      "VPC Peering",
      "VPN"
    ],
    "Terms": [
      "VPC",
      "VPC Peering",
      "VPN",
      "Customer Gateway",
      "Virtual Private Gateway",
      "AWS Direct Connect",
      "Single Point of Failure"
    ],
    "SelectA": "Management VPC와 Production VPC 간에 VPN 세트를 추가합니다.",
    "SelectA_Commentary": "VPC 간 VPN 연결 자체만으로는 Management VPC의 Customer Gateway 의존성을 해결하지 못합니다. 이 방식은 기존 구성을 보완하지 않아 단일 장애 지점을 여전히 남깁니다.",
    "SelectB": "두 번째 Virtual Private Gateway를 생성하여 Management VPC에 attach합니다.",
    "SelectB_Commentary": "Management VPC에 Virtual Private Gateway를 추가하는 것은 Direct Connect 연결 시나리오에 가깝지만, 기존 Customer Gateway의 단일 장애 지점 문제를 직접 해결하지는 못합니다.",
    "SelectC": "두 번째 Customer Gateway 디바이스에서 Management VPC로 두 번째 VPN 세트를 추가합니다.",
    "SelectC_Commentary": "단일 Customer Gateway 디바이스에 의존하는 현 구성을 이중화하여 중단 상황에도 VPN 연결이 유지되도록 합니다. 따라서 단일 장애 지점을 제거하고 고가용성을 보장할 수 있는 최적의 솔루션입니다.",
    "SelectD": "Management VPC와 Production VPC 사이에 두 번째 VPC Peering 연결을 추가합니다.",
    "SelectD_Commentary": "VPC Peering은 두 VPC 간 트래픽 전달을 가능하게 하지만, Management VPC에서 데이터 센터로 가는 단일 Customer Gateway 문제는 그대로 남습니다.",
    "Question_Description_recommedations": [
      "Q722",
      "Q504",
      "Q487",
      "Q237",
      "Q439"
    ],
    "SelectA_recommedations": [
      "Q487",
      "Q448",
      "Q439"
    ],
    "SelectB_recommedations": [
      "Q487",
      "Q448",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q487",
      "Q448",
      "Q439"
    ],
    "SelectD_recommedations": [
      "Q448",
      "Q439",
      "Q504"
    ]
  },
  {
    "Question_Number": "Q449",
    "Question_Description": "한 회사가 Oracle database로 애플리케이션을 운영하고 있습니다. 이 회사는 데이터베이스, 백업 관리, 데이터 센터 유지보수를 위한 자원이 제한되어 AWS로 빠르게 마이그레이션하려고 합니다. 해당 애플리케이션은 권한이 필요한 서드파티 데이터베이스 기능을 사용합니다. 가장 비용 효율적인 방법으로 회사가 데이터베이스를 AWS로 마이그레이션하도록 도와줄 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109432-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서드파티 기능에 대한 관리자 권한이 필요한 Oracle DB를 신속하고 비용 효율적으로 AWS로 이전하는 시나리오를 다룹니다. RDS Custom for Oracle은 필요한 OS 수준 권한을 제공하면서 관리 부담과 비용을 줄여 가장 적합한 해법입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Oracle database",
      "서드파티 데이터베이스 기능",
      "권한이 필요한 기능",
      "비용 효율",
      "AWS 마이그레이션",
      "RDS Custom for Oracle"
    ],
    "Terms": [
      "Oracle database",
      "Amazon RDS for Oracle",
      "Amazon RDS Custom for Oracle",
      "Amazon EC2 AMI for Oracle",
      "Oracle APEX",
      "privileged access",
      "third-party database features"
    ],
    "SelectA": "Amazon RDS for Oracle로 데이터베이스를 마이그레이션하고, 서드파티 기능을 클라우드 서비스로 대체합니다.",
    "SelectA_Commentary": "RDS for Oracle은 사용자화 권한이 제한적이어서 서드파티 기능에 필요한 고급 권한 설정이 어렵습니다.",
    "SelectB": "Amazon RDS Custom for Oracle로 데이터베이스를 마이그레이션합니다. 서드파티 기능을 지원하기 위해 데이터베이스 설정을 사용자화합니다.",
    "SelectB_Commentary": "RDS Custom for Oracle은 OS 수준 권한 제공으로 서드파티 기능 설정이 용이하며, 자동화된 관리로 비용 효율이 가장 높습니다.",
    "SelectC": "Amazon EC2용 Oracle AMI로 데이터베이스를 마이그레이션합니다. 서드파티 기능을 지원하기 위해 데이터베이스 설정을 사용자화합니다.",
    "SelectC_Commentary": "EC2 환경에서는 DB 운영, 백업 등을 모두 직접 관리해야 하므로 운영 복잡도가 높고 비용도 증가합니다.",
    "SelectD": "Amazon RDS for PostgreSQL로 데이터베이스를 마이그레이션하기 위해 애플리케이션 코드를 재작성하고, Oracle APEX 의존성을 제거합니다.",
    "SelectD_Commentary": "PostgreSQL로 전환 시 애플리케이션 전체를 재작성해야 하므로 시간과 비용 부담이 크게 증가합니다.",
    "Question_Description_recommedations": [
      "Q411",
      "Q284",
      "Q238",
      "Q985",
      "Q728"
    ],
    "SelectA_recommedations": [
      "Q574",
      "Q579",
      "Q449"
    ],
    "SelectB_recommedations": [
      "Q574",
      "Q449",
      "Q579"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q238",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q436",
      "Q579",
      "Q940"
    ]
  },
  {
    "Question_Number": "Q450",
    "Question_Description": "한 회사는 단일 서버 위에 구축된 3계층 웹 애플리케이션을 보유하고 있습니다. 이 애플리케이션을 AWS Cloud로 마이그레이션하려 하고, 동시에 AWS Well-Architected Framework에 부합하며 보안, 확장성, 복원성 측면에서 AWS 권장 모범 사례를 따르길 원합니다. 이러한 요구사항을 충족하기 위해 필요한 솔루션 조합은 무엇입니까? (3개를 고르시오.)",
    "Answer": "C,E,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109406-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 단일 서버 애플리케이션을 AWS 모범 사례에 따라 3계층으로 분리하고, 확장성과 복원성을 고려한 Multi-AZ 및 Auto Scaling 구성을 통해 보안, 성능, 가용성을 향상하는 방안을 묻습니다. 정답은 C, E, F입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "3계층 웹 애플리케이션",
      "AWS Well-Architected Framework",
      "보안",
      "확장성",
      "복원성",
      "Multi-AZ",
      "Auto Scaling",
      "Elastic Load Balancer",
      "Refactor"
    ],
    "Terms": [
      "VPC",
      "Availability Zone",
      "Amazon EC2",
      "Security Group",
      "Network ACL",
      "Amazon RDS",
      "Auto Scaling Group",
      "Elastic Load Balancer",
      "Multi-AZ",
      "AWS Well-Architected Framework"
    ],
    "SelectA": "기존 아키텍처를 이용하여 두 개의 Availability Zone에 걸쳐 VPC를 생성합니다. 각 AZ의 private subnet에 EC2 Auto Scaling 그룹으로 애플리케이션을 호스팅하고, security group과 network ACL로 EC2 인스턴스를 보호합니다.",
    "SelectA_Commentary": "3계층 분리가 명확하지 않고 기존 아키텍처를 그대로 사용하는 방식으로 확장성 및 모듈성 측면에서 모범 사례에 부합하지 않습니다.",
    "SelectB": "데이터베이스 레이어 접근을 제어하기 위해 security group과 network ACL을 설정합니다. private subnet에 단일 Amazon RDS 데이터베이스를 구성합니다.",
    "SelectB_Commentary": "Amazon RDS를 단일 DB 인스턴스로만 구성하면 복원성과 확장성 면에서 부족합니다.",
    "SelectC": "두 개의 Availability Zone에 걸쳐 VPC를 생성합니다. 애플리케이션을 웹, 애플리케이션, 데이터베이스 계층으로 리팩터링합니다. 각 계층을 자체 private subnet에 배치하고, 웹 계층과 애플리케이션 계층에 Auto Scaling 그룹을 구성합니다.",
    "SelectC_Commentary": "3계층 분리를 통해 보안, 확장성, 복원성을 모두 갖추는 AWS 모범 사례 구조를 구현할 수 있어 적합합니다.",
    "SelectD": "단일 Amazon RDS 데이터베이스를 사용합니다. 데이터베이스 접근은 애플리케이션 계층 security group에서만 허용합니다.",
    "SelectD_Commentary": "단일 RDS 인스턴스 구성은 Well-Architected Framework의 고가용성 및 복원성 기준 충족이 어렵습니다.",
    "SelectE": "웹 계층 앞에 Elastic Load Balancer를 배치합니다. 계층별 security group을 참조하는 방식으로 접근을 제어합니다.",
    "SelectE_Commentary": "각 계층을 분리하고 Load Balancer로 트래픽을 관리함으로써 확장성과 가용성을 높이는 올바른 구성입니다.",
    "SelectF": "Amazon RDS Multi-AZ 클러스터를 private subnet에 배포합니다. 데이터베이스 접근은 오직 애플리케이션 계층 security group에서만 허용합니다.",
    "SelectF_Commentary": "DB를 Multi-AZ로 구성하면 장애 시에도 자동으로 복구 가능해 고가용성과 복원성을 확보합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q75",
      "Q790",
      "Q944",
      "Q1014"
    ],
    "SelectA_recommedations": [
      "Q729",
      "Q691",
      "Q639"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q259",
      "Q629"
    ],
    "SelectC_recommedations": [
      "Q729",
      "Q758",
      "Q691"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q259",
      "Q629"
    ],
    "SelectE_recommedations": [
      "Q405",
      "Q275",
      "Q1001"
    ],
    "SelectF_recommedations": [
      "Q466",
      "Q958",
      "Q989"
    ]
  },
  {
    "Question_Number": "Q451",
    "Question_Description": "한 회사가 애플리케이션과 데이터베이스를 AWS Cloud로 마이그레이션하고 있습니다. 회사는 Amazon Elastic Container Service(Amazon ECS), AWS Direct Connect, 그리고 Amazon RDS를 사용할 예정입니다. 어떤 작업들을 회사의 운영팀이 관리하게 됩니까? (3개를 고르십시오.)",
    "Answer": "B,C,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109408-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 공유 책임 모델을 확인하는 것으로, 인프라와 물리적 보안, DB 엔진 버전 패칭은 AWS가 담당합니다. 사용자 운영팀은 RDS 인스턴스 설정, ECS 소프트웨어 구성, Direct Connect 전송 데이터 암호화를 직접 관리해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "AWS Cloud 마이그레이션",
      "Amazon ECS",
      "AWS Direct Connect",
      "Amazon RDS",
      "운영팀 책임",
      "암호화",
      "모니터링"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Direct Connect",
      "Amazon RDS",
      "Patch Management",
      "Log Management",
      "Host Intrusion Detection",
      "RDS Maintenance Window",
      "Encryption"
    ],
    "SelectA": "Amazon RDS 인프라 계층, 운영 체제 및 플랫폼 관리",
    "SelectA_Commentary": "Amazon RDS 인프라 계층은 AWS 책임 영역에 해당하므로 운영팀이 직접 관리하지 않습니다.",
    "SelectB": "Amazon RDS DB 인스턴스를 생성하고 예약된 유지 관리 창을 구성",
    "SelectB_Commentary": "RDS 인스턴스 생성과 유지 관리 일정 설정은 사용자의 운영팀이 직접 담당해야 하는 작업입니다.",
    "SelectC": "Amazon ECS에서 모니터링, 패치 관리, 로그 관리, 호스트 침입 탐지 등을 위한 추가 소프트웨어 구성",
    "SelectC_Commentary": "ECS 내 애플리케이션 수준의 보안 및 모니터링 도구 구성은 운영팀이 수행해야 합니다.",
    "SelectD": "Amazon RDS의 모든 마이너 및 메이저 데이터베이스 버전에 대한 패치 설치",
    "SelectD_Commentary": "RDS 엔진 버전에 대한 패치 적용은 기본적으로 AWS가 제공하므로 운영팀 책임이 아닙니다.",
    "SelectE": "데이터 센터의 Amazon RDS 인프라 물리적 보안을 보장",
    "SelectE_Commentary": "AWS가 운영하는 데이터 센터의 물리적 보안은 AWS 책임입니다.",
    "SelectF": "Direct Connect를 통해 이동하는 데이터의 암호화",
    "SelectF_Commentary": "회사는 네트워크 구간 암호화를 직접 설정해야 하므로 이는 운영팀의 책임입니다.",
    "Question_Description_recommedations": [
      "Q663",
      "Q810",
      "Q211",
      "Q998",
      "Q61"
    ],
    "SelectA_recommedations": [
      "Q330",
      "Q742",
      "Q732"
    ],
    "SelectB_recommedations": [
      "Q330",
      "Q742",
      "Q732"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q689",
      "Q592"
    ],
    "SelectD_recommedations": [
      "Q330",
      "Q742",
      "Q732"
    ],
    "SelectE_recommedations": [
      "Q330",
      "Q742",
      "Q732"
    ],
    "SelectF_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q452",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 Java 기반 작업을 실행하고 있습니다. 이 작업은 매시간 실행되며 약 10초 소요됩니다. 스케줄에 맞춰 실행되며 1GB 메모리를 사용합니다. 작업이 실행될 때를 제외하면 CPU 사용률이 낮지만, 작업 실행 시 최대 CPU를 사용합니다. 회사는 이 작업을 실행하는 비용을 최적화하기를 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109521-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매우 짧은(약 10초) 시간 동안만 CPU와 메모리를 사용하는 작업을 어떻게 최소 비용으로 실행할지 묻습니다. 전체 인스턴스를 상시 구동하면 불필요한 비용이 발생합니다. AWS Lambda는 코드를 실행한 시간만큼만 비용을 지불하기 때문에 10초 내외의 작업에 매우 적합합니다. 따라서 Lambda 함수로 전환하고 EventBridge 스케줄링을 통해 매시간 실행하도록 설정하면 운용과 비용 측면에서 최적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 최적화",
      "짧은 실행 시간",
      "AWS Lambda",
      "Amazon EventBridge",
      "Java 기반 작업",
      "매시간 실행"
    ],
    "Terms": [
      "AWS App2Container (A2C)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "vCPU",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon Machine Image (AMI)",
      "EC2"
    ],
    "SelectA": "AWS App2Container (A2C)를 사용해 작업을 컨테이너화합니다. Amazon ECS 태스크로 AWS Fargate에서 0.5 vCPU, 1GB 메모리로 작업을 실행합니다.",
    "SelectA_Commentary": "짧게 실행되는 작업에 대해 Fargate를 사용하면 인스턴스보다 낫지만, Lambda보다 세부 관리와 비용이 더 들 수 있습니다.",
    "SelectB": "코드를 AWS Lambda 함수(1GB 메모리)로 옮깁니다. Amazon EventBridge 스케줄링 규칙을 만들어 코드를 매시간 실행합니다.",
    "SelectB_Commentary": "Lambda는 실제 사용 시간에 대해서만 과금되므로 짧은 작업을 매시간 실행하기에 적합하며, 비용과 관리 측면에서 최적의 선택입니다.",
    "SelectC": "AWS App2Container (A2C)를 사용해 작업을 컨테이너화합니다. 해당 컨테이너를 기존 AMI에 설치하고, 작업 종료 시 컨테이너를 중지하도록 스케줄을 설정합니다.",
    "SelectC_Commentary": "EC2 상에서 컨테이너를 구동하고 스케줄을 제어해도 인프라 비용이 지속 발생해 Lambda에 비해 비효율적입니다.",
    "SelectD": "현재 스케줄을 구성하여 작업이 완료되면 EC2 인스턴스를 중지하고, 다음 작업 시작 시 인스턴스를 재시작하도록 설정합니다.",
    "SelectD_Commentary": "인스턴스를 중지·시작하여 비용 절감은 가능하지만, Lambda처럼 실행 시간당 과금이 아니므로 운영 복잡도가 높고 효율이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q347",
      "Q671",
      "Q238",
      "Q221",
      "Q167"
    ],
    "SelectA_recommedations": [
      "Q926",
      "Q140",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q943",
      "Q300"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q383",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q238",
      "Q284"
    ]
  },
  {
    "Question_Number": "Q453",
    "Question_Description": "회사는 Amazon EC2 데이터와 여러 Amazon S3 버킷에 대한 백업 전략을 구현하려고 합니다. 규제 요구사항으로 인해, 특정 기간 동안 백업 파일을 보관해야 하며 해당 기간 동안 파일을 수정해서는 안 됩니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109410-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 규제 준수를 위해 백업 파일이 설정된 보존 기간 내내 변경 불가능해야 한다는 점입니다. AWS Backup의 vault lock을 compliance mode로 구성하면 지정된 기간 동안 누구도 파일을 변경하거나 삭제할 수 없어 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "백업 전략",
      "Amazon EC2 데이터",
      "Amazon S3 버킷",
      "규제 요구사항",
      "보관 기간",
      "파일 수정 불가"
    ],
    "Terms": [
      "AWS Backup",
      "Backup Vault",
      "Vault Lock",
      "Governance Mode",
      "Compliance Mode",
      "Amazon Data Lifecycle Manager",
      "Amazon S3 File Gateway",
      "S3 Lifecycle Management"
    ],
    "SelectA": "AWS Backup으로 governance mode인 backup vault를 생성하고 필요한 backup plan을 구성합니다.",
    "SelectA_Commentary": "governance mode는 권한을 가진 사용자나 루트 계정이 잠금을 해제할 수도 있어, 완전한 불변성 요구사항을 만족하지 못합니다.",
    "SelectB": "Amazon Data Lifecycle Manager를 사용하여 필요한 자동 스냅숏 정책을 생성합니다.",
    "SelectB_Commentary": "스냅숏 정책만으로는 S3 버킷에 대한 파일 수정 방지와 규제 보존을 엄격히 보장하기 어렵습니다.",
    "SelectC": "Amazon S3 File Gateway를 통해 백업을 생성하고, 적절한 S3 Lifecycle 관리를 구성합니다.",
    "SelectC_Commentary": "S3 Lifecycle은 주로 객체의 이동 및 삭제 시점을 제어하므로, 수정 불가 요구사항을 강제할 만한 설정으로는 부족합니다.",
    "SelectD": "AWS Backup으로 compliance mode인 backup vault를 생성하고 필요한 backup plan을 구성합니다.",
    "SelectD_Commentary": "compliance mode는 보관 기간 동안 누구도 데이터 변경이나 삭제를 할 수 없어, 규제 요건을 충족하는 완벽한 불변성을 제공합니다.",
    "Question_Description_recommedations": [
      "Q612",
      "Q17",
      "Q480",
      "Q682",
      "Q710"
    ],
    "SelectA_recommedations": [
      "Q15",
      "Q970",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q898",
      "Q529",
      "Q970"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q862",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q15",
      "Q970",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q454",
    "Question_Description": "한 회사가 여러 AWS Regions와 여러 계정에 걸쳐 리소스를 보유하고 있습니다. 새로 합류한 Solutions Architect는 이전 직원이 리소스 인벤토리에 대한 세부 정보를 제공하지 않았음을 알게 되었습니다. 이 Solutions Architect는 모든 계정에 분산된 다양한 워크로드의 관계 정보를 구성하고 매핑해야 합니다. 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109433-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "멀티 계정·리전 환경에서 리소스를 자동으로 시각화하고 관계를 파악하려면 Workload Discovery on AWS가 가장 효율적이며, 운영 복잡도를 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "AWS Regions",
      "여러 계정",
      "리소스 인벤토리",
      "관계 매핑",
      "운영 효율",
      "Workload Discovery on AWS"
    ],
    "Terms": [
      "AWS Systems Manager Inventory",
      "AWS Step Functions",
      "Workload Discovery on AWS",
      "AWS X-Ray"
    ],
    "SelectA": "AWS Systems Manager Inventory를 사용하여 상세 보고서에서 맵 뷰를 생성합니다.",
    "SelectA_Commentary": "인벤토리 수집은 가능하지만 아키텍처 맵을 자동으로 생성하지 못해 목적 달성에 비효율적입니다.",
    "SelectB": "AWS Step Functions로 워크로드 세부 정보를 수집하고, 수동으로 아키텍처 다이어그램을 작성합니다.",
    "SelectB_Commentary": "수집 후 사람이 직접 다이어그램을 작성해야 하므로 운영 오버헤드가 높습니다.",
    "SelectC": "Workload Discovery on AWS를 사용하여 워크로드의 아키텍처 다이어그램을 생성합니다.",
    "SelectC_Commentary": "계정·리전 전반의 아키텍처 관계를 자동으로 시각화하여 가장 운영 효율이 뛰어난 정답입니다.",
    "SelectD": "AWS X-Ray로 워크로드 세부 정보를 보고 관계를 수동으로 다이어그램화합니다.",
    "SelectD_Commentary": "X-Ray는 애플리케이션 트레이싱 기능에 초점이 맞춰져 있어 전체 아키텍처 매핑에 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q288",
      "Q138",
      "Q479",
      "Q711",
      "Q434"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q293",
      "Q869"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q293",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q198",
      "Q8",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q293",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q455",
    "Question_Description": "한 회사가 AWS Organizations를 사용하고 있습니다. 이 회사는 일부 AWS 계정에 대해 서로 다른 예산을 적용하려 합니다. 특정 기간 동안 할당된 예산 한도에 도달하면 알림을 받고, 추가 리소스 프로비저닝을 자동으로 차단하고자 합니다. 이 요구사항을 충족하기 위해 어떤 솔루션 조합을 구현해야 합니까? (3개를 선택하십시오.)",
    "Answer": "B,D,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109522-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예산 초과 시 자동으로 추가 리소스 생성을 막고 비용 초과 위험을 최소화하는 설정을 묻습니다. AWS Budgets와 SCP를 연동해 경보와 프로비저닝 차단을 동시에 수행해야 합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "예산 한도",
      "자동 차단",
      "AWS Organizations",
      "Billing 대시보드",
      "Service Control Policy"
    ],
    "Terms": [
      "AWS Budgets",
      "Cost and Usage Reports",
      "Billing dashboard",
      "IAM role",
      "IAM user",
      "Budget action",
      "Service Control Policy(SCP)",
      "AWS Organizations"
    ],
    "SelectA": "필요한 AWS 계정에서 Cost and Usage Reports 섹션 아래에 예산 금액을 설정하여 AWS Budgets를 생성합니다.",
    "SelectA_Commentary": "Cost and Usage Reports는 예산 자체를 설정하는 위치가 아니므로 요구사항에 부합하지 않습니다.",
    "SelectB": "필요한 AWS 계정에서 Billing 대시보드 아래에 예산 금액을 설정하여 AWS Budgets를 생성합니다.",
    "SelectB_Commentary": "Billing 대시보드에서 예산을 설정하는 것은 일반적인 방식이며 요구사항 충족에 필수적입니다.",
    "SelectC": "필요한 권한을 가진 AWS Budgets용 IAM 사용자를 생성합니다.",
    "SelectC_Commentary": "AWS Budgets에서 액션을 수행하려면 보통 IAM Role을 사용하므로 IAM 사용자보다는 역할이 적절합니다.",
    "SelectD": "AWS Budgets에서 필요한 권한으로 예산 액션을 실행하기 위해 IAM Role을 생성합니다.",
    "SelectD_Commentary": "AWS Budgets 액션이 리소스 제어 작업을 수행하려면 수행 권한을 위임받을 IAM Role이 필요합니다.",
    "SelectE": "계정이 예산 임계값에 도달했을 때 알림을 보냅니다. Config rule을 사용해 만들어진 IAM 주체를 선택하여 추가 리소스 프로비저닝을 방지하는 예산 액션을 추가합니다.",
    "SelectE_Commentary": "Config rule로는 리소스 프로비저닝 차단을 구조적으로 제어하기 어렵습니다.",
    "SelectF": "계정이 예산 임계값에 도달했을 때 알림을 보냅니다. Service Control Policy(SCP)를 사용해 만들어진 IAM 주체를 선택하여 추가 리소스 프로비저닝을 방지하는 예산 액션을 추가합니다.",
    "SelectF_Commentary": "SCP는 Organizations 계정 전체에 적용되어 리소스 프로비저닝을 효과적으로 차단할 수 있어 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q541",
      "Q485",
      "Q284",
      "Q641",
      "Q728"
    ],
    "SelectA_recommedations": [
      "Q641",
      "Q459",
      "Q715"
    ],
    "SelectB_recommedations": [
      "Q641",
      "Q455",
      "Q238"
    ],
    "SelectC_recommedations": [
      "Q728",
      "Q485",
      "Q284"
    ],
    "SelectD_recommedations": [
      "Q455",
      "Q284",
      "Q485"
    ],
    "SelectE_recommedations": [
      "Q728",
      "Q284",
      "Q485"
    ],
    "SelectF_recommedations": [
      "Q485",
      "Q728",
      "Q541"
    ]
  },
  {
    "Question_Number": "Q456",
    "Question_Description": "한 회사가 한 AWS Region에서 Amazon EC2 인스턴스로 애플리케이션을 운영하고 있습니다. 이 회사는 해당 EC2 인스턴스들을 두 번째 Region으로 백업하고 싶어 하며, 동시에 두 번째 Region에도 EC2 리소스를 프로비저닝하고 하나의 AWS 계정에서 중앙 집중적으로 관리하고자 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109523-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스를 다른 Region으로 백업해 재해 복구(Disaster Recovery)와 비용 최적화를 동시에 달성하는 방법을 찾는 상황입니다. 두 번째 Region에 미리 EC2 인스턴스를 상시 유지하거나 실시간 동기화 방식을 쓰면 비용이 높아집니다. AWS Backup의 교차 리전 백업 기능을 사용하면 필요한 시점 스냅샷만 저장하고, 복원이 필요할 때만 자원을 프로비저닝해 비용과 관리 부담을 모두 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "백업",
      "두 번째 Region",
      "코스트 절감",
      "EC2 리소스 관리",
      "AWS Backup",
      "스냅샷"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Region",
      "Amazon EBS",
      "Point-in-time EBS Snapshot",
      "AWS Backup",
      "Cross-Region Backup",
      "AWS DataSync",
      "DR(Disaster Recovery)"
    ],
    "SelectA": "두 번째 Region에 유사한 수의 EC2 인스턴스를 동일하게 배치한 재해 복구(DR) 계획을 생성합니다. 데이터 복제를 구성합니다.",
    "SelectA_Commentary": "상시로 유사한 규모의 인스턴스를 유지해야 해 비용이 크게 증가하는 비효율적 솔루션입니다.",
    "SelectB": "EC2 인스턴스의 point-in-time Amazon EBS 스냅샷을 생성하고, 해당 스냅샷을 정기적으로 두 번째 Region으로 복사합니다.",
    "SelectB_Commentary": "스냅샷을 수동으로 복사하는 방식은 활용 가능하지만, 자동화를 위해선 추가 구성과 관리가 필요해 운영 편의성이 떨어집니다.",
    "SelectC": "AWS Backup을 사용하여 백업 플랜을 생성하고, EC2 인스턴스에 대해 두 번째 Region으로 교차 리전 백업을 설정합니다.",
    "SelectC_Commentary": "AWS Backup으로 백업 작업을 자동화하고 교차 리전 백업을 간편하게 구성할 수 있어 가장 비용 효율적이고 운영이 간소합니다.",
    "SelectD": "두 번째 Region에 유사한 수의 EC2 인스턴스를 배포하고, AWS DataSync를 통해 소스 Region에서 데이터를 두 번째 Region으로 전송합니다.",
    "SelectD_Commentary": "항상 동일 규모의 EC2를 운영하면서 DataSync를 사용하는 방식은 유지 비용이 높고 운영 복잡도가 크게 증가합니다.",
    "Question_Description_recommedations": [
      "Q312",
      "Q47",
      "Q224",
      "Q178",
      "Q842"
    ],
    "SelectA_recommedations": [
      "Q585",
      "Q343",
      "Q224"
    ],
    "SelectB_recommedations": [
      "Q312",
      "Q456",
      "Q224"
    ],
    "SelectC_recommedations": [
      "Q456",
      "Q224",
      "Q312"
    ],
    "SelectD_recommedations": [
      "Q456",
      "Q178",
      "Q47"
    ]
  },
  {
    "Question_Number": "Q457",
    "Question_Description": "어떤 AWS 사용 회사가 제품 제조업체에 데이터를 전송하기 위한 애플리케이션을 구축하고 있습니다. 회사는 자체 Identity Provider(IdP)를 가지고 있으며, 이 애플리케이션을 통해 사용자가 데이터를 전송하는 동안 IdP를 통해 인증하기를 원합니다. 또한 회사는 Applicability Statement 2(AS2) 프로토콜을 반드시 사용해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AS2 프로토콜을 통한 안전한 데이터 전송과 외부 IdP 인증이 관건인 문제입니다. AWS Transfer Family는 AS2를 지원하고, AWS Lambda를 통해 사용자의 IdP 인증 처리도 가능하므로 보안과 요구사항을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "데이터 전송",
      "AS2 프로토콜",
      "IdP 인증",
      "AWS Transfer Family"
    ],
    "Terms": [
      "AWS Transfer Family",
      "AWS DataSync",
      "Amazon AppFlow",
      "Amazon ECS",
      "AWS Lambda",
      "AWS Storage Gateway",
      "Amazon Cognito",
      "IdP",
      "AS2 프로토콜"
    ],
    "SelectA": "AWS DataSync로 데이터를 전송하고, AWS Lambda 함수를 생성하여 IdP 인증을 수행합니다.",
    "SelectA_Commentary": "DataSync는 파일 동기화에 유용하지만 AS2 프로토콜을 직접 지원하지 않아 회사의 요구사항을 만족하기 어렵습니다.",
    "SelectB": "Amazon AppFlow를 사용하여 데이터를 전송하고, Amazon ECS 태스크를 생성하여 IdP 인증을 수행합니다.",
    "SelectB_Commentary": "AppFlow는 SaaS 애플리케이션 간 데이터 이동에 적합하지만, AS2 프로토콜을 지원하지 않으므로 부적합합니다.",
    "SelectC": "AWS Transfer Family를 사용하여 데이터를 전송하고, AWS Lambda 함수를 생성하여 IdP 인증을 수행합니다.",
    "SelectC_Commentary": "AWS Transfer Family는 AS2 프로토콜을 지원하며, Lambda로 외부 IdP 인증 흐름을 구현할 수 있어 요구사항을 충족합니다.",
    "SelectD": "AWS Storage Gateway를 사용하여 데이터를 전송하고, Amazon Cognito identity pool을 생성하여 IdP 인증을 수행합니다.",
    "SelectD_Commentary": "Storage Gateway는 온프레미스 스토리지와 클라우드 간 통합에 초점이 맞춰져 있어, AS2 프로토콜 요구사항을 만족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q750",
      "Q222",
      "Q476",
      "Q780",
      "Q295"
    ],
    "SelectA_recommedations": [
      "Q428",
      "Q893",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q222",
      "Q1017",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q222",
      "Q750",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q200",
      "Q366",
      "Q750"
    ]
  },
  {
    "Question_Number": "Q458",
    "Question_Description": "한 솔루션스 아키텍트가 cash payback 서비스용 REST API를 Amazon API Gateway로 설계하고 있습니다. 애플리케이션은 1GB 메모리와 2GB 스토리지가 필요한 컴퓨팅 리소스가 요구됩니다. 또한 데이터를 관계형 형식으로 저장해야 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하기 위한 추가 AWS 서비스 조합은 무엇입니까? (정답 2개를 고르시오.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109435-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 1GB 메모리, 2GB 스토리지로 구성된 컴퓨팅 리소스에 관계형 데이터베이스가 필요한 애플리케이션을 최소한의 운영 부담으로 구성하는 방법을 묻습니다. 서버 관리를 대신해주는 AWS Lambda 및 완전 관리형 관계형 데이터베이스 서비스인 Amazon RDS를 함께 사용하는 것이 가장 간단하고 유지보수 비용이 낮은 해법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "REST API",
      "Amazon API Gateway",
      "cash payback 서비스",
      "관계형 데이터",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "Amazon RDS",
      "Amazon DynamoDB",
      "Amazon Elastic Kubernetes Services (Amazon EKS)"
    ],
    "SelectA": "Amazon EC2",
    "SelectA_Commentary": "직접 인스턴스를 관리해야 하므로 추가적인 운영 오버헤드가 발생해 적합하지 않습니다.",
    "SelectB": "AWS Lambda",
    "SelectB_Commentary": "서버리스 컴퓨팅으로 인프라 관리 부담이 적고 확장성이 높아 최소 운영 오버헤드에 부합하는 선택입니다.",
    "SelectC": "Amazon RDS",
    "SelectC_Commentary": "관계형 데이터베이스를 완전 관리형 서비스로 제공하므로 데이터베이스 운영 부담을 크게 줄일 수 있습니다.",
    "SelectD": "Amazon DynamoDB",
    "SelectD_Commentary": "비관계형(NoSQL) 데이터베이스이므로 관계형 데이터 요구사항을 충족하지 않습니다.",
    "SelectE": "Amazon Elastic Kubernetes Services (Amazon EKS)",
    "SelectE_Commentary": "컨테이너 오케스트레이션 플랫폼으로, 설정 및 클러스터 관리를 직접 수행해야 하므로 운영 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q637",
      "Q10",
      "Q207",
      "Q52",
      "Q513"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ],
    "SelectB_recommedations": [
      "Q785",
      "Q194",
      "Q351"
    ],
    "SelectC_recommedations": [
      "Q108",
      "Q843",
      "Q845"
    ],
    "SelectD_recommedations": [
      "Q768",
      "Q845",
      "Q78"
    ],
    "SelectE_recommedations": [
      "Q563",
      "Q996",
      "Q198"
    ]
  },
  {
    "Question_Number": "Q459",
    "Question_Description": "한 회사가 AWS Organizations를 사용해 여러 AWS 계정에서 워크로드를 운영하고 있습니다. 태깅 정책으로 인해 회사가 태그를 생성할 때 AWS 리소스에 department 태그가 추가됩니다. 회계 팀은 Amazon EC2 이용 비용을 파악해야 합니다. 또한 이 회계 팀은 어떤 부서가 비용에 대한 책임이 있는지, AWS 계정과 상관없이 알아야 합니다. 이 회계 팀은 조직 내 모든 AWS 계정에 대한 AWS Cost Explorer에 접근할 수 있으며 Cost Explorer에서 제공하는 모든 보고서를 조회해야 합니다. 이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109440-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "조직 전체에서 부서별 비용 할당을 하려면, 관리 계정에서 user-defined cost allocation tag를 활성화하고 한 번의 Cost Explorer 보고서로 통합 파악하는 방안이 가장 효율적입니다. 이렇게 하면 별도 설정 없이 모든 계정의 데이터를 일괄 분석할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS Organizations",
      "department 태그",
      "EC2 비용",
      "Cost Explorer"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS Cost Explorer",
      "Cost Allocation Tag",
      "User-Defined Cost Allocation Tag",
      "Management Account",
      "Member Account",
      "Billing Console",
      "Amazon EC2"
    ],
    "SelectA": "Organizations 관리 계정의 결제 콘솔에서 department라는 user-defined cost allocation tag를 활성화합니다. 그런 다음 Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링하는 한 개의 비용 보고서를 생성합니다.",
    "SelectA_Commentary": "관리 계정에서 사용자 정의 태그를 활성화하면 모든 계정이 공통 태그를 사용해 비용을 추적 가능하며, 보고서를 한 번만 설정해도 조직 전체의 EC2 비용을 효율적으로 확인할 수 있습니다.",
    "SelectB": "Organizations 관리 계정의 결제 콘솔에서 department라는 AWS-defined cost allocation tag를 활성화합니다. 그런 다음 Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링하는 한 개의 비용 보고서를 생성합니다.",
    "SelectB_Commentary": "단일 비용 보고서라는 점은 적절하지만 department라는 태그는 AWS-defined가 아니라 user-defined여야 하므로 요구사항에 맞지 않습니다.",
    "SelectC": "Organizations 멤버 계정의 결제 콘솔에서 department라는 user-defined cost allocation tag를 활성화합니다. 그런 다음 Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링하는 한 개의 비용 보고서를 생성합니다.",
    "SelectC_Commentary": "멤버 계정에서 태그를 활성화하면 전 조직 계정 비용을 통합 추적하기 어렵습니다. 관리 계정에서 활성화해야 전체 비용을 한번에 파악할 수 있습니다.",
    "SelectD": "Organizations 멤버 계정의 결제 콘솔에서 department라는 AWS-defined cost allocation tag를 활성화합니다. 그런 다음 Cost Explorer에서 태그 이름으로 그룹화하고 EC2로 필터링하는 한 개의 비용 보고서를 생성합니다.",
    "SelectD_Commentary": "AWS-defined tag로 설정할 수 있는 department 태그가 없으며, 멤버 계정에서 활성화해도 전사 비용 분석에는 비효율적이므로 올바른 접근이 아닙니다.",
    "Question_Description_recommedations": [
      "Q641",
      "Q455",
      "Q559",
      "Q238",
      "Q671"
    ],
    "SelectA_recommedations": [
      "Q459",
      "Q641",
      "Q31"
    ],
    "SelectB_recommedations": [
      "Q459",
      "Q641",
      "Q31"
    ],
    "SelectC_recommedations": [
      "Q459",
      "Q641",
      "Q31"
    ],
    "SelectD_recommedations": [
      "Q459",
      "Q641",
      "Q31"
    ]
  },
  {
    "Question_Number": "Q460",
    "Question_Description": "한 회사가 SaaS 애플리케이션인 Salesforce 계정과 Amazon S3 간에 데이터를 안전하게 교환하고자 합니다. 이 회사는 AWS Key Management Service(AWS KMS) 고객 관리형 키(CMKs)를 사용하여 저장 시 데이터를 암호화해야 하며, 전송 중인 데이터도 암호화해야 합니다. 이 회사는 Salesforce 계정에 대해 API 접근을 활성화해두었습니다. 이러한 요구사항을 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109525-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SaaS 애플리케이션인 Salesforce와 Amazon S3 간 데이터 교환 시, 저장 및 전송 단계 모두에서 보안을 유지해야 하는 상황입니다. 특히 AWS KMS CMK를 사용한 암호화와 전송 중 SSL/TLS 암호화를 구현할 수 있는 완전관리형 통합 서비스가 핵심입니다. Amazon AppFlow를 활용하면 복잡한 커스텀 코드를 작성할 필요 없이 손쉽게 데이터를 안전하게 전송하고, AWS KMS를 통한 저장 시 암호화도 함께 설정할 수 있어 요구사항을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Salesforce",
      "Amazon S3",
      "AWS KMS CMK",
      "암호화",
      "전송 중 암호화",
      "Amazon AppFlow"
    ],
    "Terms": [
      "AWS Key Management Service(AWS KMS)",
      "고객 관리형 키(CMK)",
      "API access",
      "SSL/TLS",
      "Amazon AppFlow",
      "Salesforce",
      "Amazon S3"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.",
    "SelectA_Commentary": "Lambda를 이용하면 사용자 정의 로직으로 전송 가능하지만, 직접 연결 로직 및 암호화 설정을 모두 구현해야 하므로 관리 부담이 크고 완전관리형 서비스만큼 간단하지 않습니다.",
    "SelectB": "AWS Step Functions 워크플로우를 생성하고, Salesforce에서 Amazon S3로 데이터를 안전하게 전송하는 태스크를 정의합니다.",
    "SelectB_Commentary": "Step Functions는 워크플로우 오케스트레이션 서비스로 적합하지만, Salesforce 전송 로직을 별도로 구현해야 하며 통합 및 보안 설정 관리가 복잡할 수 있습니다.",
    "SelectC": "Amazon AppFlow 플로우를 생성하여 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.",
    "SelectC_Commentary": "Amazon AppFlow는 SaaS 애플리케이션과 AWS 간 완전관리형 데이터 통합을 제공하며, 저장 시 AWS KMS CMK 사용과 SSL/TLS 전송 암호화를 간단히 설정할 수 있어 요구사항을 모두 충족합니다.",
    "SelectD": "Salesforce용 커스텀 커넥터를 만들어 Salesforce에서 Amazon S3로 데이터를 안전하게 전송합니다.",
    "SelectD_Commentary": "커스텀 커넥터를 개발하려면 추가 개발 및 운영 노력이 들며, 완전관리형 서비스 대비 설정 및 보안 구현이 번거롭습니다.",
    "Question_Description_recommedations": [
      "Q640",
      "Q916",
      "Q793",
      "Q681",
      "Q1009"
    ],
    "SelectA_recommedations": [
      "Q289",
      "Q936",
      "Q791"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q965",
      "Q34"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q821",
      "Q862"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q965",
      "Q106"
    ]
  },
  {
    "Question_Number": "Q461",
    "Question_Description": "한 회사가 단일 AWS Region에서 모바일 게임 앱을 개발하고 있습니다. 앱은 Auto Scaling group에 있는 여러 Amazon EC2 인스턴스에서 실행됩니다. 회사는 앱 데이터를 Amazon DynamoDB에 저장합니다. 앱은 사용자와 서버 간에 TCP 트래픽과 UDP 트래픽을 사용합니다. 이 애플리케이션은 전 세계적으로 사용될 예정이며, 회사는 모든 사용자에게 가능한 한 가장 낮은 지연 시간을 보장하고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109446-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계를 대상으로 TCP와 UDP 트래픽을 빠르게 전달하기 위한 최적의 네트워크 아키텍처를 설계하는 것입니다. UDP를 지원해야 하므로 NLB가 필요하며, 글로벌 지연 시간을 낮추기 위해 AWS Global Accelerator를 활용해야 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.4"
    ],
    "Keywords": [
      "모바일 게임 앱",
      "글로벌 지연 시간 최소화",
      "TCP와 UDP",
      "AWS Global Accelerator",
      "Network Load Balancer",
      "Application Load Balancer",
      "Amazon CloudFront"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon DynamoDB",
      "Amazon CloudFront (CDN)"
    ],
    "SelectA": "AWS Global Accelerator로 accelerator를 생성합니다. Global Accelerator 통합을 사용하는 ALB를 accelerator endpoint 뒤에 두고 TCP와 UDP 포트에서 리스닝합니다. Auto Scaling group을 ALB에 등록합니다.",
    "SelectA_Commentary": "ALB는 주로 HTTP/HTTPS 트래픽 처리를 위해 사용되므로 UDP 트래픽 처리에 제약이 있어 최적 답안이 아닙니다.",
    "SelectB": "AWS Global Accelerator로 accelerator를 생성합니다. Global Accelerator 통합을 사용하는 NLB를 accelerator endpoint 뒤에 두고 TCP와 UDP 포트에서 리스닝합니다. Auto Scaling group을 NLB에 등록합니다.",
    "SelectB_Commentary": "UDP 트래픽을 지원하는 NLB와 AWS Global Accelerator의 조합으로 전 세계 사용자에게 낮은 지연 시간과 안정적인 연결을 제공하므로 정답입니다.",
    "SelectC": "Amazon CloudFront CDN endpoint를 생성합니다. TCP와 UDP 포트에서 리스닝하는 NLB를 endpoint 뒤에 두고, Auto Scaling group을 NLB에 등록합니다. CloudFront가 NLB를 오리진으로 사용하도록 업데이트합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS 콘텐츠 전달에 최적화되어 있어 UDP 트래픽 처리는 적절하지 않습니다.",
    "SelectD": "Amazon CloudFront CDN endpoint를 생성합니다. TCP와 UDP 포트에서 리스닝하는 ALB를 endpoint 뒤에 두고, Auto Scaling group을 ALB에 등록합니다. CloudFront가 ALB를 오리진으로 사용하도록 업데이트합니다.",
    "SelectD_Commentary": "ALB와 CloudFront 모두 UDP 트래픽 처리가 제한적이므로 글로벌 UDP 트래픽 최적화에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q335",
      "Q261",
      "Q674",
      "Q686",
      "Q20"
    ],
    "SelectA_recommedations": [
      "Q358",
      "Q266",
      "Q461"
    ],
    "SelectB_recommedations": [
      "Q815",
      "Q530",
      "Q461"
    ],
    "SelectC_recommedations": [
      "Q530",
      "Q815",
      "Q280"
    ],
    "SelectD_recommedations": [
      "Q358",
      "Q280",
      "Q530"
    ]
  },
  {
    "Question_Number": "Q462",
    "Question_Description": "한 회사는 고객 주문을 처리하는 애플리케이션을 운영하고 있으며, 이 애플리케이션은 Amazon EC2 instance 위에서 동작하며 주문 데이터를 Amazon Aurora database에 저장합니다. 가끔 트래픽이 높을 때 주문 처리 속도가 충분히 빠르지 않은 문제가 발생합니다. 이러한 주문을 최대한 빠르고 안정적으로 데이터베이스에 쓰려면 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109653-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주문을 안정적으로 빠르게 데이터베이스에 추가하기 위해, 높은 트래픽 상황에서도 신뢰성과 확장성을 확보할 수 있는 구조가 필요함을 묻습니다. Amazon SQS로 쓰기 작업을 먼저 큐에 적재하고, Auto Scaling으로 확장 가능한 EC2 인스턴스 그룹에서 이를 비동기식으로 처리하면 가장 효율적인 해결책이 됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고객 주문",
      "높은 트래픽",
      "Amazon EC2 instance",
      "Amazon Aurora database",
      "빠른 쓰기",
      "신뢰성",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon SQS"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Aurora",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Auto Scaling group",
      "Application Load Balancer",
      "Scheduled scaling"
    ],
    "SelectA": "트래픽이 높아질 때 EC2 instance 크기를 늘립니다. 주문을 Amazon SNS에 작성합니다. 데이터베이스 endpoint를 SNS 토픽에 구독시킵니다.",
    "SelectA_Commentary": "단순히 인스턴스 크기만 늘리고 SNS 토픽에 DB를 직접 구독시키는 구조로는 처리 병목이 완전히 해소되지 않으며, 확장성 측면에서도 한계가 있습니다.",
    "SelectB": "Amazon SQS queue에 주문을 작성합니다. Application Load Balancer 뒤의 Auto Scaling group 내 EC2 인스턴스들이 SQS 메시지를 읽어 주문을 데이터베이스에 처리합니다.",
    "SelectB_Commentary": "SQS를 활용하여 쓰기와 처리를 분리하면, 큐에 주문을 안정적으로 적재하고 Auto Scaling group의 EC2 인스턴스가 필요에 따라 확장되어 병렬로 처리할 수 있어 가장 효과적인 솔루션입니다.",
    "SelectC": "주문을 Amazon SNS에 작성합니다. 데이터베이스 endpoint를 SNS 토픽에 구독시킵니다. 뒤이어 Application Load Balancer 뒤의 Auto Scaling group 내 EC2 인스턴스가 SNS 토픽을 읽어 처리합니다.",
    "SelectC_Commentary": "SNS는 주로 푸시 알림 및 방송용 메시지에 적합하며, SNS를 통해 DB에 직접 쓰는 구조는 확장성과 비동기 처리가 불완전해 병목을 완화하기 어렵습니다.",
    "SelectD": "EC2 instance의 CPU 임계치에 도달하면 Amazon SQS queue에 주문을 작성합니다. Application Load Balancer 뒤의 Auto Scaling group 내 EC2 인스턴스를 스케줄 기반으로 확장하여 SQS 큐를 읽고 주문을 처리합니다.",
    "SelectD_Commentary": "CPU 임계치 기반으로만 SQS에 쓰면 일관된 성능 보장이 어렵고, 예약된 스케일링만으로는 예측 불가능한 급격한 트래픽 증가에 탄력적으로 대응하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q824",
      "Q879",
      "Q136",
      "Q768",
      "Q48"
    ],
    "SelectA_recommedations": [
      "Q489",
      "Q194",
      "Q48"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q1012",
      "Q275"
    ],
    "SelectC_recommedations": [
      "Q489",
      "Q405",
      "Q636"
    ],
    "SelectD_recommedations": [
      "Q1012",
      "Q405",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q463",
    "Question_Description": "한 IoT 회사가 사용자의 수면 정보를 수집하기 위해 매트리스를 출시하고 있습니다. 매트리스에 장착된 센서는 매일 밤마다 약 2MB의 데이터를 Amazon S3 버킷으로 전송합니다. 회사는 각 매트리스에 대해 이 데이터를 처리 및 요약해야 하며, 가능한 한 빨리 결과가 제공되어야 합니다. 데이터 처리에는 1GB의 메모리가 필요하고, 30초 이내에 처리가 완료되어야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109501-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 상대적으로 소량의 데이터를 신속히 처리해야 하면서도, 가능한 한 비용을 절감해야 하는 시나리오를 다룹니다. 데이터 처리는 2MB 규모이지만 매트리스마다 매일 발생하며, 1GB 메모리와 30초 이내 처리라는 제약이 있습니다. AWS Lambda는 사용한 만큼만 비용을 지불하는 구조이므로 데이터와 처리 시간이 작고 짧을수록 비용 효율적입니다. 다른 서비스인 AWS Glue나 Amazon EMR은 클러스터나 환경 구성 비용이 추가로 발생하므로 소규모·단발성 처리에 비해 상대적으로 비효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "IoT",
      "매트리스",
      "2MB 데이터",
      "Amazon S3",
      "1GB 메모리",
      "30초 이내",
      "AWS Lambda",
      "비용 효율성"
    ],
    "Terms": [
      "AWS Glue",
      "Scala",
      "Amazon EMR",
      "Apache Spark",
      "AWS Lambda",
      "Python",
      "PySpark",
      "Amazon S3"
    ],
    "SelectA": "AWS Glue에서 Scala Job을 사용합니다.",
    "SelectA_Commentary": "AWS Glue는 관리형 Spark 환경을 제공하지만, 작은 데이터 처리에는 과도한 오버헤드로 인해 비용 효율성이 떨어집니다.",
    "SelectB": "Amazon EMR에서 Apache Spark 스크립트를 사용합니다.",
    "SelectB_Commentary": "EMR 클러스터를 구성하고 관리해야 하므로 소규모 데이터 처리에는 비용이 더 많이 들 수 있습니다.",
    "SelectC": "AWS Lambda에서 Python 스크립트를 사용합니다.",
    "SelectC_Commentary": "Lambda는 요청당 과금 체계로, 2MB 수준의 데이터와 1GB 메모리, 30초 이내 처리에 매우 적합하며 비용 효율이 뛰어납니다.",
    "SelectD": "AWS Glue에서 PySpark Job을 사용합니다.",
    "SelectD_Commentary": "PySpark 역시 클러스터 기반으로 동작하며 설정 및 관리 오버헤드가 크기 때문에 소규모 데이터 처리에 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q759",
      "Q153",
      "Q890",
      "Q212",
      "Q126"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q728",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q728",
      "Q943",
      "Q300"
    ],
    "SelectC_recommedations": [
      "Q300",
      "Q485",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q464",
    "Question_Description": "한 회사가 온라인 쇼핑 애플리케이션을 운영 중이며, 모든 주문 데이터를 Amazon RDS for PostgreSQL Single-AZ DB instance에 저장하고 있습니다. 경영진은 단일 장애점을 제거하고, 애플리케이션 코드를 변경하지 않으면서 데이터베이스 다운타임을 최소화하기를 원하여, 솔루션스 아키텍트에게 대안을 제시해달라고 요청했습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109449-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 장애점을 제거하고 데이터베이스 복원력을 높이기 위해 Multi-AZ 구성으로 전환하는 방법을 묻습니다. 애플리케이션 코드를 변경하지 않고, 최소한의 다운타임으로 고가용성을 확보해야 합니다. 기존 RDS 인스턴스를 Multi-AZ로 변경하면 자동 페일오버를 제공하여 장애 시에도 서비스 중단을 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Single-AZ",
      "Multi-AZ",
      "단일 장애점",
      "다운타임 최소화",
      "애플리케이션 코드 변경 없음"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL Single-AZ DB instance",
      "Multi-AZ deployment",
      "read-only replica",
      "Amazon Route 53 weighted record sets",
      "Amazon EC2 Auto Scaling"
    ],
    "SelectA": "기존 데이터베이스 인스턴스를 수정하여 Multi-AZ 옵션을 지정하고, Multi-AZ 배포로 전환합니다.",
    "SelectA_Commentary": "가장 간단하고 직접적인 방법으로, 기존 인스턴스 설정만 변경해도 페일오버를 지원해 다운타임을 최소화하고 Code 변경이 필요 없습니다.",
    "SelectB": "새로운 RDS Multi-AZ 배포를 생성합니다. 현재 RDS 인스턴스의 스냅샷을 생성하고 이를 사용해 새로운 Multi-AZ 배포를 복원합니다.",
    "SelectB_Commentary": "새 인스턴스를 만들어 스냅샷으로 복원할 경우 마이그레이션 중 다운타임이 길어질 수 있고 운영이 복잡해집니다.",
    "SelectC": "PostgreSQL 데이터베이스의 읽기 전용 리플리카를 다른 가용 영역에 생성합니다. Amazon Route 53 가중치 레코드 세트를 사용해 데이터베이스로의 요청을 분산시킵니다.",
    "SelectC_Commentary": "읽기 전용 리플리카이므로 장애 시 쓰기 처리에 문제가 생기고, 코드나 연결 로직 변경이 필요할 수 있습니다.",
    "SelectD": "Amazon RDS for PostgreSQL 데이터베이스를 Amazon EC2 Auto Scaling 그룹(최소 그룹 크기 2개)에 배치합니다. Amazon Route 53 가중치 레코드 세트를 사용해 인스턴스 간 요청을 분산시킵니다.",
    "SelectD_Commentary": "RDS는 EC2 Auto Scaling 그룹을 통해 관리되지 않으며, RDS 인스턴스를 직접 Auto Scaling에 배치할 수 없습니다. 적절한 고가용성 구성 방식이 아닙니다.",
    "Question_Description_recommedations": [
      "Q536",
      "Q601",
      "Q958",
      "Q629",
      "Q259"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q967",
      "Q58"
    ],
    "SelectB_recommedations": [
      "Q108",
      "Q843",
      "Q863"
    ],
    "SelectC_recommedations": [
      "Q129",
      "Q198",
      "Q241"
    ],
    "SelectD_recommedations": [
      "Q935",
      "Q354",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q465",
    "Question_Description": "한 회사가 고객 수요를 지원하기 위한 애플리케이션을 개발 중입니다. 회사는 단일 가용 영역(AZ) 내에 있는 여러 Amazon EC2 Nitro 기반 인스턴스에 해당 애플리케이션을 배포하려고 합니다. 또한 애플리케이션이 여러 EC2 Nitro 기반 인스턴스에 있는 블록 스토리지 볼륨에 동시에 쓸 수 있는 기능을 갖추어 애플리케이션 가용성을 높이고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109655-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 가용성을 높이기 위해 여러 EC2 Nitro 기반 인스턴스에서 동시에 동일한 EBS 볼륨에 접근할 수 있는 방법을 묻습니다. Amazon EBS Multi-Attach 기능은 동일한 볼륨을 여러 인스턴스에 동시에 연결해 데이터를 읽고 쓸 수 있게 해 주지만, Provisioned IOPS SSD(io1, io2) 타입에서만 지원됩니다. 따라서 io2 볼륨을 사용하는 Multi-Attach 구성이 정답이며, 이를 통해 애플리케이션이 공유 스토리지를 활용하여 높아진 가용성을 실현할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "EBS Multi-Attach",
      "Provisioned IOPS SSD",
      "io2",
      "EC2 Nitro 기반 인스턴스",
      "고가용성",
      "블록 스토리지"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Nitro 기반 인스턴스",
      "Amazon EBS",
      "Provisioned IOPS SSD (io2)",
      "General Purpose SSD (gp3)",
      "General Purpose SSD (gp2)",
      "Throughput Optimized HDD (st1)",
      "Multi-Attach"
    ],
    "SelectA": "General Purpose SSD(gp3) EBS 볼륨을 Amazon EBS Multi-Attach로 사용합니다.",
    "SelectA_Commentary": "gp3는 Multi-Attach를 지원하지 않으므로 요구 사항을 충족하지 못합니다.",
    "SelectB": "Throughput Optimized HDD(st1) EBS 볼륨을 Amazon EBS Multi-Attach로 사용합니다.",
    "SelectB_Commentary": "st1 볼륨은 Multi-Attach 대상이 아니므로 동시에 여러 인스턴스에서 쓰기가 불가능합니다.",
    "SelectC": "Provisioned IOPS SSD(io2) EBS 볼륨을 Amazon EBS Multi-Attach로 사용합니다.",
    "SelectC_Commentary": "io2 볼륨은 Multi-Attach를 지원하므로 여러 인스턴스에서 동시 연결과 쓰기 작업을 통해 가용성을 높일 수 있는 올바른 선택입니다.",
    "SelectD": "General Purpose SSD(gp2) EBS 볼륨을 Amazon EBS Multi-Attach로 사용합니다.",
    "SelectD_Commentary": "gp2 역시 Multi-Attach가 허용되지 않아 요구 사항을 만족할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q757",
      "Q584",
      "Q244",
      "Q413",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q986",
      "Q194",
      "Q602"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q602",
      "Q944"
    ],
    "SelectC_recommedations": [
      "Q602",
      "Q660",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q986",
      "Q602",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q466",
    "Question_Description": "한 회사가 단일 Availability Zone에서 Amazon EC2와 Amazon RDS Multi-AZ DB 인스턴스를 사용하는 stateless 2티어 애플리케이션을 설계했습니다. 새 경영진은 애플리케이션이 고가용성을 보장하도록 하고자 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109450-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 AZ에서 동작 중인 애플리케이션을 어떻게 Multi-AZ 환경으로 확장해 고가용성을 달성할지 묻습니다. EC2 Auto Scaling과 ALB를 활용해 장애 발생 시 자동 대체와 트래픽 분산이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "2티어 애플리케이션",
      "Amazon EC2",
      "Amazon RDS Multi-AZ",
      "Application Load Balancer",
      "Auto Scaling",
      "Route 53"
    ],
    "Terms": [
      "stateless application",
      "Multi-AZ EC2 Auto Scaling",
      "Application Load Balancer(ALB)",
      "Amazon Route 53",
      "snapshots",
      "AWS Region",
      "Availability Zone",
      "Amazon RDS Multi-AZ"
    ],
    "SelectA": "애플리케이션을 Multi-AZ EC2 Auto Scaling으로 구성하고, Application Load Balancer를 생성합니다.",
    "SelectA_Commentary": "Multi-AZ EC2 Auto Scaling을 통해 인스턴스 장애 시 다른 AZ에서 자동으로 대체 인스턴스를 가동하고, ALB로 트래픽을 분산하여 안정적으로 고가용성을 달성합니다.",
    "SelectB": "EC2 인스턴스의 스냅샷을 생성하여 다른 AWS Region으로 전송하도록 애플리케이션을 구성합니다.",
    "SelectB_Commentary": "스냅샷을 다른 Region으로 옮기는 것은 재해 복구에 유용하지만, 실시간 고가용성을 보장하지 못하므로 즉각적인 장애 대처가 어렵습니다.",
    "SelectC": "Amazon Route 53 지연 기반 라우팅을 사용해 애플리케이션에 대한 요청을 전달하도록 구성합니다.",
    "SelectC_Commentary": "지연 시간에 따라 트래픽을 분산할 수 있지만, 단일 AZ에서 EC2를 운영한다면 근본적인 고가용성 확보가 어렵습니다.",
    "SelectD": "Amazon Route 53 규칙으로 요청을 처리하고, Multi-AZ Application Load Balancer를 생성합니다.",
    "SelectD_Commentary": "Route 53을 통한 라우팅 및 ALB만으로는 EC2 인스턴스를 다중 AZ에서 자동으로 확장·배치하는 구성이 없어, 완전한 HA를 달성하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q444",
      "Q298",
      "Q125",
      "Q958",
      "Q259"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q174",
      "Q275"
    ],
    "SelectB_recommedations": [
      "Q456",
      "Q224",
      "Q47"
    ],
    "SelectC_recommedations": [
      "Q264",
      "Q545",
      "Q869"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q537",
      "Q935"
    ]
  },
  {
    "Question_Number": "Q467",
    "Question_Description": "한 회사가 AWS Organizations를 사용하고 있습니다. 한 멤버 계정이 Compute Savings Plan을 구매했는데, 이 계정 내 워크로드가 변경되어 더 이상 Compute Savings Plan 약정을 충분히 활용하지 못하고 있습니다. 회사는 구매한 컴퓨팅 파워의 절반 미만만 사용 중입니다. 이 상황에서 회사가 Compute Savings Plan 혜택을 최대한 활용하려면 어떤 솔루션이 적절합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109485-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Compute Savings Plan 약정을 조직 전체에 적용하기 위해 Discount Sharing을 활성화해야 함을 묻습니다. 관리 계정에서 이를 켜면 멤버 계정의 남는 할인이 다른 계정에도 적용됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS Organizations",
      "Compute Savings Plan",
      "멤버 계정",
      "Management Account",
      "Discount Sharing",
      "Reserved Instance Marketplace"
    ],
    "Terms": [
      "AWS Organizations",
      "Compute Savings Plan",
      "Billing Preferences",
      "Organizations management account",
      "Reserved Instance Marketplace",
      "Discount Sharing"
    ],
    "SelectA": "Compute Savings Plan을 구매한 멤버 계정 콘솔의 Billing Preferences 섹션에서 Discount Sharing을 활성화합니다.",
    "SelectA_Commentary": "멤버 계정이 아닌, Organizations 관리 계정을 통해 Discount Sharing을 설정해야 하므로 부적절합니다.",
    "SelectB": "회사 Organizations 관리 계정 콘솔의 Billing Preferences 섹션에서 Discount Sharing을 활성화합니다.",
    "SelectB_Commentary": "정답입니다. 관리 계정에서 Discount Sharing을 활성화해야만 조직 내 다른 계정들도 Compute Savings Plan 약정을 공유할 수 있습니다.",
    "SelectC": "Compute Savings Plan을 가진 계정으로 다른 AWS 계정의 추가 컴퓨팅 워크로드를 마이그레이션합니다.",
    "SelectC_Commentary": "물리적·논리적 마이그레이션 부담이 크며, Discount Sharing이 가능하다면 굳이 워크로드를 옮길 필요가 없습니다.",
    "SelectD": "Reserved Instance Marketplace에서 남는 Savings Plan 약정을 판매합니다.",
    "SelectD_Commentary": "Savings Plan은 Reserved Instance Marketplace에 재판매할 수 없습니다. 따라서 적절한 방안이 아닙니다.",
    "Question_Description_recommedations": [
      "Q715",
      "Q543",
      "Q885",
      "Q641",
      "Q455"
    ],
    "SelectA_recommedations": [
      "Q885",
      "Q467",
      "Q543"
    ],
    "SelectB_recommedations": [
      "Q455",
      "Q467",
      "Q641"
    ],
    "SelectC_recommedations": [
      "Q715",
      "Q467",
      "Q885"
    ],
    "SelectD_recommedations": [
      "Q885",
      "Q943",
      "Q300"
    ]
  },
  {
    "Question_Number": "Q468",
    "Question_Description": "회사는 고객들에게 검색 카탈로그를 제공하는 마이크로서비스 애플리케이션을 개발 중입니다. REST API를 사용하여 애플리케이션의 프론트엔드를 사용자에게 제공해야 합니다. 또한, REST API에서는 회사가 Private VPC Subnet에서 컨테이너로 호스팅하는 백엔드 서비스에 접근해야 합니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109451-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon API Gateway로 REST API를 제공하고, Private Subnet에 있는 ECS 컨테이너를 Private VPC Link를 통해 안전하게 연결하는 구성을 묻습니다. WebSocket 대신 REST API를 선택하고 VPC Link로 내부 통신을 보호해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "마이크로서비스",
      "REST API",
      "Amazon API Gateway",
      "Amazon ECS",
      "Private VPC Subnet",
      "Private VPC Link"
    ],
    "Terms": [
      "REST API",
      "Amazon API Gateway",
      "Amazon ECS",
      "Private Subnet",
      "VPC Link",
      "WebSocket API",
      "Security Group"
    ],
    "SelectA": "Amazon API Gateway로 WebSocket API를 설계합니다. 애플리케이션을 Private Subnet의 Amazon ECS에 호스팅합니다. API Gateway에서 Amazon ECS로 접근하기 위해 Private VPC Link를 생성합니다.",
    "SelectA_Commentary": "WebSocket API는 실시간 양방향 통신에 적합하지만, 여기서는 REST API 요구사항을 충족하지 못해 부적절합니다.",
    "SelectB": "Amazon API Gateway로 REST API를 설계합니다. 애플리케이션을 Private Subnet의 Amazon ECS에 호스팅합니다. API Gateway에서 Amazon ECS로 접근하기 위해 Private VPC Link를 생성합니다.",
    "SelectB_Commentary": "REST API와 Private VPC Link를 활용해 ECS 컨테이너를 외부에 노출하지 않고 안전하게 연결할 수 있으므로 요구사항을 만족하는 정답입니다.",
    "SelectC": "Amazon API Gateway로 WebSocket API를 설계합니다. 애플리케이션을 Private Subnet의 Amazon ECS에 호스팅합니다. API Gateway가 Amazon ECS에 접근할 수 있도록 Security Group을 생성합니다.",
    "SelectC_Commentary": "WebSocket API가 아닌 REST API를 사용해야 하므로 요구사항에 부합하지 않습니다.",
    "SelectD": "Amazon API Gateway로 REST API를 설계합니다. 애플리케이션을 Private Subnet의 Amazon ECS에 호스팅합니다. API Gateway가 Amazon ECS에 접근할 수 있도록 Security Group을 생성합니다.",
    "SelectD_Commentary": "VPC Link 없이 단순히 Security Group만 연결하는 것은 Private Subnet 리소스에 대한 안전하고 직접적인 연결을 제공하지 못합니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q792",
      "Q135",
      "Q15",
      "Q34"
    ],
    "SelectA_recommedations": [
      "Q451",
      "Q1019",
      "Q468"
    ],
    "SelectB_recommedations": [
      "Q468",
      "Q451",
      "Q1019"
    ],
    "SelectC_recommedations": [
      "Q1019",
      "Q451",
      "Q875"
    ],
    "SelectD_recommedations": [
      "Q1019",
      "Q468",
      "Q532"
    ]
  },
  {
    "Question_Number": "Q469",
    "Question_Description": "한 회사가 수집된 원시 데이터를 Amazon S3 버킷에 보관하고 있습니다. 이 데이터는 회사 고객들을 위해 여러 종류의 분석을 수행하는 데 사용됩니다. 요청되는 분석 유형에 따라 S3 오브젝트에 대한 액세스 패턴이 결정됩니다. 이 회사는 액세스 패턴을 예측하거나 제어할 수 없습니다. 회사는 S3 비용을 절감하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109452-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능한 액세스 패턴에 대해 S3 비용 최적화를 달성해야 하는 시나리오입니다. S3 Intelligent-Tiering은 액세스 빈도를 자동으로 모니터링하여 최적의 스토리지 요금으로 전환하므로, 액세스 패턴을 예측할 수 없을 때 가장 효과적인 솔루션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon S3",
      "S3 Intelligent-Tiering",
      "S3 Standard-IA",
      "액세스 패턴 예측 불가",
      "비용 절감"
    ],
    "Terms": [
      "S3 Lifecycle",
      "S3 Intelligent-Tiering",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Replication",
      "S3 Inventory"
    ],
    "SelectA": "S3 Replication을 사용하여 자주 액세스되지 않는 오브젝트를 S3 Standard-IA로 전환합니다.",
    "SelectA_Commentary": "Replication은 버킷 간 복제에 적용되며, 단순 비용 절감 목적과는 맞지 않습니다.",
    "SelectB": "S3 Lifecycle 규칙을 사용하여 S3 Standard에서 S3 Standard-IA로 오브젝트를 전환합니다.",
    "SelectB_Commentary": "일정 시점 이후 액세스가 적을 때는 유용하지만, 액세스 패턴을 전혀 예측할 수 없을 땐 적절치 않습니다.",
    "SelectC": "S3 Lifecycle 규칙을 사용하여 S3 Standard에서 S3 Intelligent-Tiering으로 오브젝트를 전환합니다.",
    "SelectC_Commentary": "액세스 패턴 예측이 어려울 때, Intelligent-Tiering을 통해 자동으로 가장 비용 효율적인 스토리지 클래스를 제공하므로 최적의 솔루션입니다.",
    "SelectD": "S3 Inventory를 사용하여 액세스되지 않은 오브젝트를 식별하고 S3 Standard에서 S3 Intelligent-Tiering으로 전환합니다.",
    "SelectD_Commentary": "S3 Inventory는 단지 객체 목록을 제공할 뿐 자동으로 다른 스토리지 클래스로 이전할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q829",
      "Q498",
      "Q769",
      "Q1003",
      "Q911"
    ],
    "SelectA_recommedations": [
      "Q415",
      "Q23",
      "Q356"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q470",
    "Question_Description": "한 회사가 IPv6 주소를 사용하는 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션들은 인터넷을 통해 외부 애플리케이션과 통신을 시작해야 합니다. 그러나 회사의 보안 정책상, 외부 서비스가 EC2 인스턴스에 대한 연결을 시작하는 것은 허용되지 않습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 어떤 방법을 제안해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109334-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IPv6 환경에서 인스턴스가 외부로는 연결을 시작해야 하나, 외부에서의 직접적인 접근은 차단해야 하는 보안 요구사항을 다룹니다. IPv4의 NAT gateway 역할을 IPv6에서 수행하는 솔루션은 egress-only internet gateway이며, 이를 통해 아웃바운드 트래픽은 허용하고 인바운드는 차단할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "IPv6 주소",
      "외부 애플리케이션",
      "인터넷 통신",
      "보안 정책"
    ],
    "Terms": [
      "NAT gateway",
      "Internet gateway",
      "Virtual private gateway",
      "Egress-only internet gateway",
      "IPv4",
      "IPv6",
      "서브넷 라우트 테이블"
    ],
    "SelectA": "NAT gateway를 생성하여 서브넷의 라우트 테이블 대상지로 설정합니다.",
    "SelectA_Commentary": "NAT gateway는 IPv4 트래픽 전용이므로 IPv6 통신을 위한 요구사항을 충족하지 못합니다.",
    "SelectB": "Internet gateway를 생성하여 서브넷의 라우트 테이블 대상지로 설정합니다.",
    "SelectB_Commentary": "Internet gateway는 양방향 트래픽을 허용하므로 외부에서의 인바운드 연결 규제를 만족시키지 못합니다.",
    "SelectC": "Virtual private gateway를 생성하여 서브넷의 라우트 테이블 대상지로 설정합니다.",
    "SelectC_Commentary": "Virtual private gateway는 온프레미스 VPN 연결 용도로 사용되어, 이 문제의 요건을 해결할 수 없습니다.",
    "SelectD": "Egress-only internet gateway를 생성하여 서브넷의 라우트 테이블 대상지로 설정합니다.",
    "SelectD_Commentary": "IPv6 트래픽에 대해 아웃바운드는 허용하고 인바운드는 차단할 수 있어 보안 정책을 충족하는 올바른 선택입니다.",
    "Question_Description_recommedations": [
      "Q329",
      "Q327",
      "Q453",
      "Q682",
      "Q866"
    ],
    "SelectA_recommedations": [
      "Q803",
      "Q893",
      "Q538"
    ],
    "SelectB_recommedations": [
      "Q803",
      "Q850",
      "Q265"
    ],
    "SelectC_recommedations": [
      "Q265",
      "Q803",
      "Q538"
    ],
    "SelectD_recommedations": [
      "Q265",
      "Q803",
      "Q564"
    ]
  },
  {
    "Question_Number": "Q471",
    "Question_Description": "한 회사가 VPC 내 컨테이너에서 동작하는 애플리케이션을 생성하고 있습니다. 이 애플리케이션은 Amazon S3 버킷에 데이터를 저장하고 접근합니다. 개발 단계 동안 애플리케이션이 매일 1TB의 데이터를 Amazon S3에 저장하고 액세스할 예정입니다. 회사는 비용을 최소화하고, 가능한 한 인터넷을 경유하지 않도록 트래픽을 제어하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109453-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부에서 Amazon S3와 통신할 때 인터넷 경유를 피하고 비용을 최소화하는 방안을 묻습니다. Gateway VPC endpoint를 사용하면 추가 비용 없이 S3에 직접 연결하여 트래픽이 인터넷을 거치지 않고 AWS 네트워크 내부에서 처리됩니다. 반면에 Interface endpoint는 비용이 추가되며, S3 Transfer Acceleration 등 다른 옵션들은 목적인 비용 최소화와 내부 트래픽 사용에 적합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "VPC",
      "Amazon S3",
      "컨테이너 애플리케이션",
      "1TB 데이터",
      "비용 최소화",
      "인터넷 경유 방지"
    ],
    "Terms": [
      "S3 Intelligent-Tiering",
      "S3 Transfer Acceleration",
      "Gateway VPC endpoint",
      "Interface endpoint",
      "Internet Gateway",
      "NAT device"
    ],
    "SelectA": "S3 버킷에 S3 Intelligent-Tiering을 활성화합니다.",
    "SelectA_Commentary": "S3 Intelligent-Tiering은 접근 패턴에 따라 스토리지 비용을 최적화하지만, VPC 내부 트래픽을 유지하거나 인터넷 경유를 차단해주는 기능은 제공하지 않습니다.",
    "SelectB": "S3 버킷에 S3 Transfer Acceleration을 활성화합니다.",
    "SelectB_Commentary": "S3 Transfer Acceleration은 업로드/다운로드 속도를 향상시키지만, 전 세계 Edge Location을 경유하며 추가 비용이 발생하고 인터넷 경유를 완전히 차단하지 못하므로 요구사항에 부합하지 않습니다.",
    "SelectC": "Amazon S3에 대한 Gateway VPC endpoint를 생성하고, 이 엔드포인트를 VPC의 모든 라우트 테이블에 연결합니다.",
    "SelectC_Commentary": "Gateway VPC endpoint를 사용하면 인터넷 게이트웨이나 NAT 디바이스 없이 VPC 내부에서 직접 S3에 접근할 수 있으므로, 비용을 줄이고 트래픽을 인터넷으로 내보내지 않아 요구사항에 부합하는 최적의 선택입니다.",
    "SelectD": "VPC 내에 Amazon S3에 대한 Interface endpoint를 생성하고, 이 엔드포인트를 VPC의 모든 라우트 테이블에 연결합니다.",
    "SelectD_Commentary": "Interface endpoint 역시 VPC 내 트래픽을 유지할 수 있지만, 추가 비용이 발생하며 Gateway endpoint에 비해 비용 효율성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q860",
      "Q993",
      "Q88",
      "Q911",
      "Q469"
    ],
    "SelectA_recommedations": [
      "Q486",
      "Q943",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q497",
      "Q471",
      "Q860"
    ],
    "SelectD_recommedations": [
      "Q471",
      "Q860",
      "Q497"
    ]
  },
  {
    "Question_Number": "Q472",
    "Question_Description": "한 회사가 모바일 채팅 애플리케이션을 운영하고 있으며, Amazon DynamoDB에 기반한 데이터 스토어를 사용하고 있습니다. 사용자는 새로운 메시지를 가능한 한 지연 없이 받아보고 싶어 합니다. 솔루션즈 아키텍트는 애플리케이션 변경을 최소화하면서 최적의 지연 성능을 달성해야 합니다. 어떤 방법을 선택해야 할까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109454-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB의 읽기 지연을 최소화하기 위해 인메모리 캐시 서비스를 활용하거나 테이블 속성을 조정하는 방안을 묻습니다. 적은 코드 변경으로 높은 성능 이점을 얻으려면 DAX가 최적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "모바일 채팅",
      "DynamoDB",
      "지연 최소화",
      "최소한의 애플리케이션 변경"
    ],
    "Terms": [
      "Amazon DynamoDB Accelerator (DAX)",
      "DynamoDB 읽기 용량",
      "Amazon ElastiCache for Redis"
    ],
    "SelectA": "Amazon DynamoDB Accelerator (DAX)를 새로운 메시지 테이블에 구성하고, 코드를 업데이트하여 DAX 엔드포인트를 사용하도록 합니다.",
    "SelectA_Commentary": "DAX는 DynamoDB에 최적화된 인메모리 캐시이므로 코드에서 엔드포인트만 바꿔도 지연을 크게 줄일 수 있으며, 애플리케이션 변경이 가장 적게 듭니다.",
    "SelectB": "증가한 읽기 부하를 처리하기 위해 DynamoDB 읽기 레플리카를 추가하고, 애플리케이션에서 읽기 레플리카 엔드포인트를 사용하도록 업데이트합니다.",
    "SelectB_Commentary": "DynamoDB에는 전통적인 의미의 읽기 레플리카가 없어 글로벌 테이블 등의 복잡한 구성이 필요합니다. 지연 완화보다는 확장에 초점이 맞춰져 있어 적합하지 않습니다.",
    "SelectC": "새로운 메시지 테이블의 읽기 용량 단위를 2배로 늘리고, 기존 DynamoDB 엔드포인트를 계속 사용합니다.",
    "SelectC_Commentary": "읽기 용량을 늘리면 쓰로틀링을 방지할 수 있지만, 지연을 즉각 줄이는 데에는 한계가 있어 사용자 요구를 제대로 충족하기 어렵습니다.",
    "SelectD": "애플리케이션 스택에 Amazon ElastiCache for Redis를 추가하고, 애플리케이션에서 Redis 캐시 엔드포인트로 연결하도록 변경합니다.",
    "SelectD_Commentary": "Redis 캐시를 활용하려면 DynamoDB와의 동기화 로직과 애플리케이션 수정이 많이 필요해 지연 단축 효과 대비 구현이 복잡합니다.",
    "Question_Description_recommedations": [
      "Q578",
      "Q177",
      "Q731",
      "Q523",
      "Q962"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q578",
      "Q731"
    ],
    "SelectB_recommedations": [
      "Q523",
      "Q177",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q523",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q481",
      "Q557"
    ]
  },
  {
    "Question_Number": "Q473",
    "Question_Description": "한 회사가 Application Load Balancer(ALB) 뒤의 Amazon EC2 인스턴스에서 웹사이트를 호스팅하고 있습니다. 해당 웹사이트는 정적 콘텐츠를 제공합니다. 웹사이트 트래픽이 증가하고 있어, 회사는 비용 증가에 대해 우려하고 있습니다. 어떤 솔루션이 이러한 문제를 해결하고 비용을 절감할 수 있을까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109455-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 정적 콘텐츠를 제공하는 웹사이트 트래픽 증가와 이로 인한 비용 증가에 어떻게 대응할지 묻습니다. 정적 파일을 캐싱하여 EC2 인스턴스의 부하와 데이터 전송 비용을 줄이는 방법이 핵심입니다. CloudFront는 전 세계 Edge Location에서 콘텐츠를 캐싱하므로, 사용자가 가까운 위치에서 정적 파일을 받아볼 수 있어 지연이 줄고, 원본 서버(EC2)의 부하 역시 크게 완화되어 비용 절감 효과가 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.4"
    ],
    "Keywords": [
      "비용 절감",
      "정적 콘텐츠",
      "콘텐츠 캐싱",
      "데이터 전송 비용",
      "트래픽 증가"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront",
      "Edge Location",
      "Amazon ElastiCache",
      "AWS WAF",
      "web ACL",
      "AWS Region"
    ],
    "SelectA": "Amazon CloudFront 배포를 생성하여 Edge Location에서 정적 파일을 캐싱합니다.",
    "SelectA_Commentary": "CloudFront를 사용하면 정적 콘텐츠를 글로벌 엣지 위치에 캐싱해 EC2 인스턴스 트래픽과 데이터 전송 비용을 줄일 수 있으므로 비용 절감과 성능 향상에 효과적입니다.",
    "SelectB": "Amazon ElastiCache 클러스터를 생성하고 ALB를 ElastiCache에 연결해 캐시된 파일을 제공합니다.",
    "SelectB_Commentary": "ElastiCache는 애플리케이션 내부 데이터 캐싱에 적합하지만, 전 세계 엣지에서 콘텐츠를 전달하지 않아, 글로벌 트래픽 분산 및 전송 비용 절감에는 CloudFront만큼 효율적이지 않습니다.",
    "SelectC": "AWS WAF web ACL을 ALB에 연결하고 정적 파일을 캐싱하도록 규칙을 추가합니다.",
    "SelectC_Commentary": "AWS WAF는 주로 웹 트래픽 필터링과 보안 제어를 담당합니다. 정적 파일 캐싱 기능은 별도로 제공되지 않아 비용 절감 효과도 미미합니다.",
    "SelectD": "대체 AWS Region에 두 번째 ALB를 만들고, 사용자 트래픽을 가장 가까운 Region으로 라우팅합니다.",
    "SelectD_Commentary": "Region 간 라우팅은 트래픽 분산에는 도움이 되지만, 정적 콘텐츠 캐싱이 없어 EC2 부하와 데이터 전송 비용을 크게 줄이지 못합니다.",
    "Question_Description_recommedations": [
      "Q894",
      "Q245",
      "Q146",
      "Q984",
      "Q441"
    ],
    "SelectA_recommedations": [
      "Q205",
      "Q943",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q262",
      "Q473"
    ],
    "SelectC_recommedations": [
      "Q473",
      "Q485",
      "Q31"
    ],
    "SelectD_recommedations": [
      "Q72",
      "Q984",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q474",
    "Question_Description": "한 회사는 여러 AWS Region에 걸쳐 VPC들을 운영하고 있습니다. 각 Region의 워크로드는 다른 Region의 워크로드와 격리되어 있습니다. 그러나 최근 애플리케이션 론칭 요구사항으로 인해, 이 회사의 모든 VPC들은 모든 Region의 다른 VPC들과 통신해야 합니다. 어떤 솔루션이 가장 적은 관리 오버헤드로 이러한 요구사항을 충족할 수 있을까요?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109659-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS Region에서 운영 중인 다수의 VPC들을 쉽게 상호 연결하면서, 관리 오버헤드를 최소화하는 방법을 묻습니다. AWS Transit Gateway는 네트워크 허브로서 VPC 연결을 중앙에서 관리하게 해주며, Transit Gateway Peering을 통해 Region 간 트래픽 연결을 효율적으로 처리할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "VPC",
      "AWS Region",
      "Transit Gateway",
      "통신",
      "관리 오버헤드 최소화"
    ],
    "Terms": [
      "VPC Peering",
      "AWS Direct Connect Gateway",
      "AWS Transit Gateway",
      "Transit Gateway Peering",
      "AWS PrivateLink"
    ],
    "SelectA": "단일 Region에서 VPC Peering을 설정하고, 다른 Region까지 확장하여 VPC 간 통신을 관리합니다.",
    "SelectA_Commentary": "VPC Peering은 다대다 연결 시 각 VPC 마다 Peering을 구성해야 하므로 관리 오버헤드가 높습니다.",
    "SelectB": "모든 Region에서 AWS Direct Connect Gateway를 사용하여 VPC를 연결하고 VPC 통신을 관리합니다.",
    "SelectB_Commentary": "Direct Connect Gateway는 주로 온프레미스 연결 시 사용되며, 모든 Region과 VPC를 연결하는 데 관리 복잡도가 큽니다.",
    "SelectC": "AWS Transit Gateway를 이용해 단일 Region VPC 통신을 관리하고, Region 간 통신은 Transit Gateway Peering으로 관리합니다.",
    "SelectC_Commentary": "Transit Gateway는 중앙집중화된 네트워크 허브 역할을 제공하며, Transit Gateway Peering을 통해 쉽게 여러 Region을 연결할 수 있는 가장 적은 관리 오버헤드를 제공하는 솔루션입니다.",
    "SelectD": "모든 Region에 걸쳐 AWS PrivateLink를 사용하여 VPC를 연결하고 VPC 통신을 관리합니다.",
    "SelectD_Commentary": "PrivateLink는 서비스 엔드포인트 노출에 적합하며, 대규모 VPC 간 연결 시 설정과 관리 방식이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q686",
      "Q938",
      "Q20",
      "Q976",
      "Q566"
    ],
    "SelectA_recommedations": [
      "Q474",
      "Q686",
      "Q938"
    ],
    "SelectB_recommedations": [
      "Q474",
      "Q734",
      "Q686"
    ],
    "SelectC_recommedations": [
      "Q957",
      "Q474",
      "Q686"
    ],
    "SelectD_recommedations": [
      "Q474",
      "Q686",
      "Q734"
    ]
  },
  {
    "Question_Number": "Q475",
    "Question_Description": "한 회사가 Amazon Elastic Container Service(Amazon ECS)를 사용하여 컨테이너 기반 애플리케이션을 설계하고 있습니다. 애플리케이션은 고내구성과 함께 다른 AWS 리전으로 8시간 RPO(Recovery Point Objective)를 충족할 수 있어야 합니다. 또한 각 리전 내의 모든 가용 영역(Availability Zone)에 대해 마운트 대상이 필요한 공유 파일 시스템에 접근해야 합니다. 솔루션스 아키텍트는 AWS Backup을 사용해 다른 리전으로의 백업을 관리하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109456-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컨테이너 환경에서 각 AZ별 마운트 대상이 필요하며, RPO 8시간을 충족하기 위한 공유 파일 시스템을 결정하는 문제입니다. Amazon EFS는 멀티 AZ 마운트 지점을 기본 제공하며, AWS Backup이나 EFS Replication을 결합하여 다른 리전으로 간편하게 백업 및 복구가 가능합니다. 질문에서 요구하는 고내구성, 복구 시간, 멀티 AZ 마운트 기능, 그리고 AWS Backup 연동을 모두 충족하므로 EFS가 적합한 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "공유 파일 시스템",
      "번영구조(High Durability)",
      "RPO 8시간",
      "AWS Backup"
    ],
    "Terms": [
      "Amazon ECS",
      "Amazon EFS",
      "AWS Backup",
      "RPO",
      "Multi-AZ",
      "Amazon FSx for Windows File Server",
      "Amazon FSx for NetApp ONTAP",
      "Amazon FSx for OpenZFS",
      "Mount Target",
      "Replication"
    ],
    "SelectA": "Amazon FSx for Windows File Server with a Multi-AZ deployment",
    "SelectA_Commentary": "Windows 파일 서버 환경에 적합하지만, ECS 기반 애플리케이션의 확장성과 네이티브 AZ별 마운트 제공 측면에서 제한적입니다. 다른 리전으로의 백업도 추가 작업이 필요합니다.",
    "SelectB": "Amazon FSx for NetApp ONTAP with a Multi-AZ deployment",
    "SelectB_Commentary": "ONTAP 환경에서는 Snapshot 및 Cross-Region 기능을 사용할 수 있지만, 컨테이너 워크로드와 일반적인 공유 파일 시스템 사용성 측면에서 EFS만큼 단순하지 않을 수 있습니다.",
    "SelectC": "Amazon Elastic File System (Amazon EFS) with the Standard storage class",
    "SelectC_Commentary": "멀티 AZ 마운트 대상과 높은 내구성, 그리고 AWS Backup 또는 EFS Replication을 통한 다른 리전 백업 기능을 제공하여 요구사항을 완벽히 충족합니다. 정답입니다.",
    "SelectD": "Amazon FSx for OpenZFS",
    "SelectD_Commentary": "주로 단일 AZ 배포에 적합하며, 컨테이너 환경에서의 직접적 통합과 다른 리전으로의 백업 측면에서 더 복잡한 구성이 필요합니다.",
    "Question_Description_recommedations": [
      "Q274",
      "Q900",
      "Q599",
      "Q639",
      "Q874"
    ],
    "SelectA_recommedations": [
      "Q618",
      "Q972",
      "Q186"
    ],
    "SelectB_recommedations": [
      "Q635",
      "Q584",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q602"
    ],
    "SelectD_recommedations": [
      "Q584",
      "Q244",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q476",
    "Question_Description": "한 회사는 가까운 미래에 빠른 성장이 예상됩니다. 솔루션스 아키텍트는 기존 사용자들을 구성하고, 새로운 사용자들에게 AWS 상의 권한을 부여해야 합니다. 솔루션스 아키텍트는 IAM 그룹을 생성하기로 결정했으며, 부서에 따라 새로운 사용자들을 IAM 그룹에 추가하려고 합니다. 이때, 새로운 사용자들에게 권한을 부여하는 가장 안전한 방법은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109458-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새롭게 늘어나는 사용자들에게 안전하게 권한을 부여하기 위한 구조를 설계하는 것입니다. IAM 그룹에 최소 권한의 IAM Policy를 연결하여 부서별로 일관되게 관리하면 유연하고 안전한 구성이 가능합니다. IAM Role을 직접 IAM 그룹에 부착하는 방식은 일반적이지 않으며, SCP는 AWS Organizations 계정 단위 제한이므로 문제 요구사항에 직접 부합하지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "기존 사용자 구성",
      "새로운 사용자 권한",
      "AWS",
      "IAM 그룹",
      "부서 기반",
      "IAM 정책",
      "최소 권한"
    ],
    "Terms": [
      "IAM Groups",
      "IAM Policy",
      "IAM Role",
      "Service Control Policies (SCPs)",
      "Permissions Boundary",
      "Least Privilege"
    ],
    "SelectA": "Service Control Policies(SCPs)를 적용하여 액세스 권한을 관리합니다.",
    "SelectA_Commentary": "SCP는 AWS Organizations 내 계정 전체 권한을 제한하기 위한 정책으로, 부서별 사용자 권한 부여에 직접 사용하기에는 적절하지 않습니다.",
    "SelectB": "최소 권한을 가진 IAM Role을 생성하고, 해당 Role을 IAM 그룹에 연결합니다.",
    "SelectB_Commentary": "IAM Role은 자격을 ‘가정(assume)’하는 주체를 위한 것이므로, IAM 그룹에 직접 Role을 부착하는 것은 일반적이지 않으며 AWS Directory Service에게는 가능해도 IAM 그룹에는 적용이 어렵습니다.",
    "SelectC": "최소 권한을 부여하는 IAM Policy를 생성하고, 해당 Policy를 IAM 그룹에 연결합니다.",
    "SelectC_Commentary": "IAM 그룹 규칙에 직접 Policy를 연결하면 부서별로 그룹을 구분해 일괄적으로 권한을 관리할 수 있습니다. 최소 권한 원칙에 가장 적합한 안전한 방법입니다.",
    "SelectD": "IAM Role을 생성하고, Role에 최대 권한을 정의하는 Permissions Boundary를 연결합니다.",
    "SelectD_Commentary": "Permissions Boundary는 사용할 수 있는 권한의 최대 범위를 제한하지만, 신규 사용자에게 단순히 Role을 적용하기 위해서는 추가 설정이 필요하고 일반적인 IAM 그룹 활용 방안도 아닙니다.",
    "Question_Description_recommedations": [
      "Q222",
      "Q780",
      "Q548",
      "Q922",
      "Q313"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q426",
      "Q774"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q423",
      "Q476"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ]
  },
  {
    "Question_Number": "Q477",
    "Question_Description": "한 그룹이 Amazon S3 버킷 목록 조회 권한과 해당 버킷에서 객체를 삭제할 수 있는 권한을 필요로 합니다. 관리자는 이를 위해 버킷에 대한 접근 권한을 부여하는 IAM 정책을 생성하고 이 정책을 그룹에 적용했습니다. 그러나 그룹이 버킷 내 객체를 삭제하지 못하고 있습니다. 회사는 최소 권한(least-privilege) 접근 규칙을 따릅니다. 버킷 접근을 올바르게 수정하기 위해 솔루션스 아키텍트가 IAM 정책에 추가해야 할 문장은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷 정책에서 리스트와 삭제 권한을 정확히 구성해야 하는 상황입니다. s3:ListBucket 권한은 버킷 수준 리소스에 설정하고, s3:DeleteObject 권한은 객체 수준 리소스(arn:aws:s3:::BucketName/*)에 부여해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "S3 버킷 목록 조회",
      "객체 삭제",
      "least-privilege",
      "IAM 정책"
    ],
    "Terms": [
      "Amazon S3",
      "IAM Policy",
      "s3:ListBucket",
      "s3:DeleteObject",
      "Resource",
      "Effect",
      "Allow"
    ],
    "SelectA": "정책에 s3:DeleteObject 액션을 추가하고, Resource를 arn:aws:s3:::ExampleBucket 만으로 설정",
    "SelectA_Commentary": "버킷 자체에 대한 권한만 있으므로 객체 삭제에 필요한 객체 수준 리소스를 지정하지 않아 삭제가 불가능합니다.",
    "SelectB": "정책에 s3:DeleteObject 액션을 추가하고, Resource를 arn:aws:s3:::ExampleBucket/* 로 구성",
    "SelectB_Commentary": "객체 수준(버킷/*) 리소스에 대해 s3:DeleteObject 권한을 허용하여 실제로 객체를 삭제할 수 있게 하는 올바른 접근 설정입니다.",
    "SelectC": "정책에 s3:ListBucketVersions 액션을 추가하고, Resource를 arn:aws:s3:::ExampleBucket/* 로 설정",
    "SelectC_Commentary": "ListBucketVersions는 객체의 버전 목록 조회 권한이며, 객체 삭제와 직접적인 연관이 없습니다.",
    "SelectD": "정책에 s3:PutObject 액션을 추가하고, Resource를 arn:aws:s3:::ExampleBucket/*/ 으로 잘못 지정",
    "SelectD_Commentary": "PutObject 권한은 객체 업로드를 허용할 뿐이며, 객체 삭제 권한 부재와 Resource 경로 오류가 있어 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q418",
      "Q476",
      "Q403",
      "Q982",
      "Q222"
    ],
    "SelectA_recommedations": [
      "Q270",
      "Q256",
      "Q216"
    ],
    "SelectB_recommedations": [
      "Q270",
      "Q256",
      "Q216"
    ],
    "SelectC_recommedations": [
      "Q868",
      "Q216",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q256",
      "Q216",
      "Q270"
    ]
  },
  {
    "Question_Number": "Q478",
    "Question_Description": "한 로펌이 대중과 정보를 공유해야 합니다. 정보는 수백 개의 파일로 구성되어 있으며, 지정된 미래 날짜 전까지는 아무도 파일을 수정하거나 삭제해서는 안 됩니다. 또한 파일들은 모두 공용으로 읽을 수 있어야 합니다. 보안을 가장 우선적으로 고려하여 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109725-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 지정된 날짜 전까지 파일을 삭제하거나 수정하지 못하도록 보안 설정을 적용하면서도, 공용(read-only)으로 파일을 제공해야 하는 시나리오입니다. 가장 중요한 포인트는 '변경 불가능(Immutable)' 설정과 버저닝, 그리고 잠금(retention) 기간을 활용해 보안을 유지하는 것입니다. 이를 위해 S3 Versioning과 Object Lock을 함께 사용하는 방안이 가장 효과적이며, 이렇게 구성된 S3 버킷을 static website hosting으로 공개하면 요구 사항을 모두 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "공개 접근",
      "수정 삭제 금지",
      "S3 Versioning",
      "S3 Object Lock",
      "retention period",
      "static website hosting",
      "bucket policy"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Versioning",
      "S3 Object Lock",
      "Retention Period",
      "Static Website Hosting",
      "S3 Bucket Policy",
      "IAM Permissions",
      "AWS Lambda Function"
    ],
    "SelectA": "Amazon S3 버킷을 static website hosting으로 구성하고, 접근하는 모든 AWS 주체에게 read-only IAM 권한을 부여합니다.",
    "SelectA_Commentary": "버킷에 Object Lock과 Versioning이 설정되어 있지 않아, 지정된 날짜 전까지 파일 수정·삭제 방지를 완벽히 보장하지 못합니다.",
    "SelectB": "S3 Versioning이 활성화된 새로운 Amazon S3 버킷을 생성하고, 지정된 날짜에 맞춰 S3 Object Lock의 retention period를 설정합니다. 버킷을 static website hosting으로 구성하고, S3 버킷 정책으로 객체에 대한 읽기 전용 접근을 허용합니다.",
    "SelectB_Commentary": "가장 안전한 방법입니다. Versioning과 Object Lock이 결합되어 수정·삭제가 불가능하며, 꾸준히 public read 권한을 유지하면서도 변경할 수 없게 설정 가능합니다.",
    "SelectC": "S3 Versioning이 활성화된 버킷을 만들고, 객체 수정·삭제 시 AWS Lambda 함수를 트리거해 사설 S3 버킷에서 원본으로 교체하도록 구성합니다.",
    "SelectC_Commentary": "Lambda 함수로 파일을 복구하는 방식은 운영 복잡도가 높고, 잠금(Retention)을 통한 불가역적 보장과는 다릅니다.",
    "SelectD": "static website hosting이 설정된 Amazon S3 버킷에 모든 파일을 업로드하고, 해당 폴더에 S3 Object Lock과 retention period를 설정합니다. 그리고 읽기 전용 IAM 권한을 부여합니다.",
    "SelectD_Commentary": "Object Lock을 사용하려면 S3 Versioning 활성화가 필수이지만, 이 옵션에는 Versioning 설정이 명시되어 있지 않아 보안적으로 완전하지 않습니다.",
    "Question_Description_recommedations": [
      "Q665",
      "Q57",
      "Q122",
      "Q189",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q862",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q868",
      "Q270",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q289",
      "Q868",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q862",
      "Q740"
    ]
  },
  {
    "Question_Number": "Q479",
    "Question_Description": "한 회사가 신규 웹사이트를 위해 필요한 인프라를 수동으로 프로비저닝하여 프로토타입 인프라를 제작하고 있습니다. 이 인프라에는 Auto Scaling group, Application Load Balancer, Amazon RDS database가 포함됩니다. 구성이 충분히 검증된 후, 회사는 개발 및 프로덕션 용도로 2개의 Availability Zone에 인프라를 즉시 자동화 방식으로 배포할 수 있길 원합니다. 이 요구사항을 충족하기 위해 Solutions Architect는 무엇을 추천해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109461-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 코드 기반으로 인프라를 정의하여 다중 AZ 환경으로 신속하고 일관되게 배포하는 방법을 묻습니다. AWS CloudFormation으로 템플릿을 만들어 배포하면 운영 복잡성을 줄이고 확장성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "프로토타입 인프라",
      "개발 및 프로덕션",
      "자동화 배포",
      "2개의 Availability Zone",
      "AWS CloudFormation"
    ],
    "Terms": [
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon RDS database",
      "AWS Systems Manager",
      "AWS CloudFormation",
      "AWS Config",
      "AWS Elastic Beanstalk"
    ],
    "SelectA": "AWS Systems Manager를 사용하여 프로토타입 인프라를 두 Availability Zone에 복제 및 프로비저닝합니다.",
    "SelectA_Commentary": "Systems Manager는 주로 패치 관리와 파라미터 저장 등에 최적화되어 있어 전체 인프라를 자동 배포하는 데는 적합하지 않습니다.",
    "SelectB": "프로토타입 인프라를 가이드로 삼아 템플릿을 정의하고, AWS CloudFormation을 사용해 인프라를 배포합니다.",
    "SelectB_Commentary": "AWS CloudFormation으로 인프라를 코드로 정의하면 재사용 및 확장이 용이하고, 다중 AZ 배포도 간편합니다.",
    "SelectC": "AWS Config를 사용하여 프로토타입 인프라에 사용된 리소스를 기록한 뒤, 해당 프로토타입 인프라를 두 Availability Zone에 배포합니다.",
    "SelectC_Commentary": "AWS Config는 리소스 구성을 추적하고 감사하는 데 초점이 맞춰져 있으며, 인프라 자동 배포 기능은 제한적입니다.",
    "SelectD": "AWS Elastic Beanstalk을 사용하고 프로토타입 인프라를 자동 참조하도록 설정하여 두 Availability Zone에 새로운 환경을 자동으로 배포합니다.",
    "SelectD_Commentary": "Elastic Beanstalk은 애플리케이션 배포에 최적화된 서비스로, 인프라 전체 제어에는 CloudFormation 대비 제약이 많습니다.",
    "Question_Description_recommedations": [
      "Q434",
      "Q138",
      "Q711",
      "Q288",
      "Q454"
    ],
    "SelectA_recommedations": [
      "Q758",
      "Q691",
      "Q47"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q8",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q758",
      "Q987",
      "Q570"
    ],
    "SelectD_recommedations": [
      "Q691",
      "Q47",
      "Q639"
    ]
  },
  {
    "Question_Number": "Q480",
    "Question_Description": "한 비즈니스 애플리케이션이 Amazon EC2에서 호스팅되고, Amazon S3를 사용하여 암호화된 객체를 저장하고 있습니다. 최고 정보 보안 책임자는 이 두 서비스 간의 애플리케이션 트래픽이 절대로 퍼블릭 인터넷을 통과하지 않도록 지시했습니다. 이러한 규정 준수 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 기능을 사용해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109663-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2와 Amazon S3 간 트래픽이 퍼블릭 인터넷을 거치지 않도록 설계하는 방법을 묻습니다. VPC endpoint를 사용하면 VPC 내부에서 Amazon S3와 직접 통신하여 규정 준수를 충족할 수 있습니다. 다른 선택지는 트래픽을 내부망에만 머무르게 하지 못하거나 목적에 맞지 않아 부적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon S3",
      "암호화된 객체",
      "퍼블릭 인터넷",
      "VPC endpoint",
      "규정 준수"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "AWS Key Management Service (AWS KMS)",
      "VPC endpoint",
      "Private subnet",
      "Virtual private gateway"
    ],
    "SelectA": "AWS Key Management Service (AWS KMS)",
    "SelectA_Commentary": "KMS는 암호화 키를 관리하는 서비스이므로, 퍼블릭 인터넷을 차단하는 네트워크 경로 문제를 해결하지 못합니다.",
    "SelectB": "VPC endpoint",
    "SelectB_Commentary": "VPC endpoint를 사용하면 EC2와 Amazon S3 간의 트래픽이 AWS 내부망을 통해서만 이동해 퍼블릭 인터넷을 통과하지 않도록 보장합니다.",
    "SelectC": "Private subnet",
    "SelectC_Commentary": "Private subnet을 사용하더라도 Amazon S3에 접근할 때 퍼블릭 엔드포인트를 거치면 인터넷 경로가 생길 수 있어 요구사항을 충족하지 못합니다.",
    "SelectD": "Virtual private gateway",
    "SelectD_Commentary": "Virtual private gateway는 온프레미스 네트워크와의 VPN 연결용이므로, EC2와 S3 간 내부 통신을 위한 직접적인 해결책이 아닙니다.",
    "Question_Description_recommedations": [
      "Q453",
      "Q17",
      "Q315",
      "Q100",
      "Q682"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q640"
    ],
    "SelectB_recommedations": [
      "Q898",
      "Q682",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q803",
      "Q122",
      "Q665"
    ],
    "SelectD_recommedations": [
      "Q321",
      "Q898",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q481",
    "Question_Description": "한 회사가 AWS Cloud에서 3계층 웹 애플리케이션을 운영하고 있습니다. Multi-AZ Amazon RDS for MySQL 서버가 데이터베이스 계층을 구성하고, Amazon ElastiCache가 캐시 계층을 구성합니다. 회사는 고객이 데이터베이스에 아이템을 추가할 때 캐시에 데이터를 추가하거나 업데이트하는 캐싱 전략을 원합니다. 캐시의 데이터는 항상 데이터베이스의 데이터와 일치해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109462-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새로운 데이터가 데이터베이스에 저장되자마자 캐시에도 동일하게 반영되어야 하는 상황을 묻고 있습니다. Lazy Loading이나 TTL만으로는 데이터베이스와 캐시 간의 즉각적·지속적 동기화를 보장하지 못합니다. AWS AppConfig는 애플리케이션 설정 관리를 위한 서비스로, 데이터 캐싱과는 직접적인 관련이 없습니다. 반면 Write-Through 캐싱은 트랜잭션 발생 시점에 캐시에도 즉각 업데이트가 이루어져, 항상 DB와 캐시 간 데이터 일치를 보장합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "3계층 웹 애플리케이션",
      "Multi-AZ Amazon RDS",
      "Amazon ElastiCache",
      "쓰기 반영(Write-Through) 캐싱",
      "데이터 일치"
    ],
    "Terms": [
      "Multi-AZ Amazon RDS for MySQL",
      "Amazon ElastiCache",
      "Lazy Loading",
      "Write-Through Caching",
      "Time-to-Live (TTL)",
      "AWS AppConfig"
    ],
    "SelectA": "Lazy Loading 캐싱 전략을 구현합니다.",
    "SelectA_Commentary": "요청 시에만 데이터를 캐시에 로드하므로 데이터베이스와 즉시 일치하지 않을 수 있습니다. 항상 일치를 보장하지 못합니다.",
    "SelectB": "Write-Through 캐싱 전략을 구현합니다.",
    "SelectB_Commentary": "DB에 쓰기가 발생할 때 동시에 캐시를 업데이트하므로 DB와 캐시 간의 즉각적 동기화가 가능하며 항상 일치를 보장합니다.",
    "SelectC": "TTL(Time-to-Live) 기반 캐싱 전략을 구현합니다.",
    "SelectC_Commentary": "캐시에 만료 시간을 두는 방식으로, 데이터가 만료 전에는 변경사항을 즉시 반영하기 어렵고 항상 일치를 보장하기 어렵습니다.",
    "SelectD": "AWS AppConfig 캐싱 전략을 구현합니다.",
    "SelectD_Commentary": "AWS AppConfig는 주로 애플리케이션 설정 관리 용도로 사용되며, DB-캐시 동기화 솔루션과는 무관합니다.",
    "Question_Description_recommedations": [
      "Q394",
      "Q386",
      "Q910",
      "Q999",
      "Q834"
    ],
    "SelectA_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectB_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectC_recommedations": [
      "Q352",
      "Q77",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q746",
      "Q443"
    ]
  },
  {
    "Question_Number": "Q482",
    "Question_Description": "한 회사가 온프레미스 위치에 저장된 100GB의 이력 데이터를 Amazon S3 버킷으로 마이그레이션하려고 합니다. 이 회사는 온프레미스에 100Mbps 인터넷 연결을 보유하고 있으며, S3 버킷으로 데이터를 전송할 때 반드시 암호화를 적용해야 합니다. 또한 앞으로 생성되는 새로운 데이터는 바로 Amazon S3에 저장될 예정입니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109490-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 Amazon S3로 데이터를 전송할 때 암호화를 통해 보안을 유지하고 동시에 운영 부담을 최소화하는 방법을 묻습니다. 정답으로 제시되는 AWS DataSync는 전송 암호화 기능이 이미 내장되어 있어 추가 설정 없이도 안전한 전송이 가능하며, 간단한 구성으로 대규모 데이터도 효율적으로 이관할 수 있습니다. 다른 옵션들은 암호화 설정 및 운영 절차가 더 복잡하거나 물리적 장비 사용 등이 포함되어 오버헤드가 증가합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "온프레미스",
      "암호화",
      "운영 오버헤드 최소화",
      "AWS DataSync",
      "100GB 데이터"
    ],
    "Terms": [
      "AWS CLI",
      "s3 sync",
      "s3 cp",
      "Amazon S3",
      "AWS DataSync",
      "AWS Snowball",
      "IPsec VPN"
    ],
    "SelectA": "AWS CLI에서 's3 sync' 명령어를 사용하여 데이터를 S3 버킷으로 직접 이동합니다.",
    "SelectA_Commentary": "HTTPS를 통해 암호화 전송은 가능하지만, 별도 모니터링과 에러 처리 구성 등이 필요해 운영 오버헤드가 상대적으로 큽니다.",
    "SelectB": "AWS DataSync를 사용하여 온프레미스 위치의 데이터를 S3 버킷으로 마이그레이션합니다.",
    "SelectB_Commentary": "데이터 암호화와 전송 자동화가 내장되어 있어 안전하고 간단하게 대용량 데이터를 옮길 수 있으며, 운영 부담이 가장 낮은 솔루션입니다.",
    "SelectC": "AWS Snowball을 사용하여 데이터를 S3 버킷으로 이동합니다.",
    "SelectC_Commentary": "배송 및 물리 디바이스 준비 과정이 필요해, 100GB 전송에는 과도하고 운영 절차가 복잡해집니다.",
    "SelectD": "온프레미스에서 AWS로 IPsec VPN을 설정한 후, AWS CLI의 's3 cp' 명령어로 데이터를 직접 이동합니다.",
    "SelectD_Commentary": "VPN 설정 및 유지, 대역폭 고려 등 추가 작업이 많고 운영 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q412",
      "Q109",
      "Q270",
      "Q202",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q270",
      "Q202",
      "Q412"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q202",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q678",
      "Q825"
    ],
    "SelectD_recommedations": [
      "Q92",
      "Q91",
      "Q712"
    ]
  },
  {
    "Question_Number": "Q483",
    "Question_Description": "한 회사가 Windows Container에서 .NET 6 Framework로 동작하는 Windows 작업을 컨테이너화했습니다. 이 작업은 AWS Cloud에서 실행하길 원하며, 10분마다 실행됩니다. 작업 실행 시간은 1분에서 3분 사이로 달라집니다. 비용 효율성을 가장 높이면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109463-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows 컨테이너 환경에서 일정 주기로 단기 작업을 수행할 때, 가장 비용 효율적인 방안을 찾는 것이 핵심입니다. Linux 기반만 지원되는 Lambda 대신, Amazon ECS에 스케줄된 Fargate 작업을 사용하는 것이 정답입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Windows Container",
      ".NET 6 Framework",
      "10분 주기 작업",
      "비용 효율"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS Batch",
      "AWS Fargate",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Windows Task Scheduler"
    ],
    "SelectA": "AWS Lambda 함수를 작업 컨테이너 이미지를 기반으로 생성하고, Amazon EventBridge로 10분마다 함수를 호출합니다.",
    "SelectA_Commentary": "Lambda는 Linux 기반 컨테이너만 지원하므로 Windows용 이미지를 사용할 수 없어 오답입니다.",
    "SelectB": "AWS Batch에서 AWS Fargate 리소스를 사용하는 작업을 생성하고, 10분 주기로 작업 스케줄링을 구성합니다.",
    "SelectB_Commentary": "AWS Batch는 대규모 배치 처리에 적합하며, 간단한 반복 작업에는 오버엔지니어링이 되어 비용 효율성이 떨어집니다.",
    "SelectC": "AWS Fargate 기반 Amazon ECS에서 작업을 실행하고, 작업 컨테이너 이미지를 이용해 10분마다 스케줄된 태스크를 생성합니다.",
    "SelectC_Commentary": "Windows 컨테이너도 지원하며, 사용 시간만큼만 과금되어 가장 비용 효율적입니다.",
    "SelectD": "AWS Fargate 기반 Amazon ECS에서 독립 실행형 태스크를 생성하고, Windows Task Scheduler로 10분마다 작업을 수행합니다.",
    "SelectD_Commentary": "상시 실행 컨테이너가 필요하므로 불필요한 리소스가 소모되어 비용 효율성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q300",
      "Q485",
      "Q719",
      "Q486",
      "Q943"
    ],
    "SelectA_recommedations": [
      "Q485",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q926",
      "Q485",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q926",
      "Q140",
      "Q715"
    ],
    "SelectD_recommedations": [
      "Q926",
      "Q140",
      "Q715"
    ]
  },
  {
    "Question_Number": "Q484",
    "Question_Description": "한 회사가 여러 독립형 AWS 계정에서 통합된 멀티 계정 아키텍처로 전환하고자 합니다. 이 회사는 여러 사업 부서를 위해 새 AWS 계정을 많이 생성할 계획입니다. 이 회사는 중앙 관리형 기업 디렉터리 서비스를 사용하여 이러한 AWS 계정에 대한 액세스를 인증해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 조합의 작업을 권장해야 합니까? (2개를 선택하십시오.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109467-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 AWS 계정을 통합하여 손쉽게 관리하려면 AWS Organizations를 통해 계정을 생성하고, 중앙 관리형 기업 디렉터리와 연결하기 위해 AWS IAM Identity Center를 통합 구동하는 방안이 핵심입니다. 이 방식으로 멀티 계정을 일관되게 관리하고, 사용자 액세스를 간소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "멀티 계정 아키텍처",
      "중앙 관리형 인증",
      "기업 디렉터리 서비스",
      "AWS Organizations",
      "AWS IAM Identity Center"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS IAM Identity Center (AWS Single Sign-On)",
      "AWS Directory Service",
      "Service Control Policy (SCP)",
      "Amazon Cognito identity pool"
    ],
    "SelectA": "AWS Organizations에서 모든 기능이 활성화된 새 organization을 생성합니다. 이 organization 안에서 새 AWS 계정들을 생성합니다.",
    "SelectA_Commentary": "조직 단위 관리가 가능하며 멀티 계정을 형상화하는 토대를 마련합니다. 중앙 집중식 정책 적용 기능도 제공합니다.",
    "SelectB": "Amazon Cognito identity pool을 설정합니다. AWS IAM Identity Center (AWS Single Sign-On)가 Amazon Cognito 인증을 수락하도록 구성합니다.",
    "SelectB_Commentary": "직접적인 기업 디렉터리 연동이 아닌 Cognito 인증 방식을 사용하므로 요구 사항에 부합하지 않습니다.",
    "SelectC": "Service Control Policy(SCP)를 구성하여 AWS 계정을 관리합니다. AWS IAM Identity Center(AWS Single Sign-On)를 AWS Directory Service에 추가합니다.",
    "SelectC_Commentary": "SCP로 리소스 제한은 가능하지만, 중앙 기업 디렉터리 통합을 위한 직접적인 구성이 부족합니다.",
    "SelectD": "AWS Organizations에서 새 organization을 생성합니다. 이 organization의 인증 메커니즘이 AWS Directory Service를 직접 사용하도록 구성합니다.",
    "SelectD_Commentary": "AWS Organizations 자체적으로 AWS Directory Service와 직접 통합하는 방식은 지원되지 않아 이 요구 사항을 충족하기 어렵습니다.",
    "SelectE": "organization 내에 AWS IAM Identity Center(AWS Single Sign-On)을 설정합니다. IAM Identity Center를 구성하고, 회사의 기업 디렉터리 서비스와 통합합니다.",
    "SelectE_Commentary": "기업 디렉터리와의 중앙 집중식 인증 연동을 실현하기 위한 핵심 구성으로, 회사의 인증을 일원화할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q831",
      "Q548",
      "Q922",
      "Q313",
      "Q592"
    ],
    "SelectA_recommedations": [
      "Q945",
      "Q168",
      "Q3"
    ],
    "SelectB_recommedations": [
      "Q688",
      "Q200",
      "Q668"
    ],
    "SelectC_recommedations": [
      "Q688",
      "Q28",
      "Q668"
    ],
    "SelectD_recommedations": [
      "Q945",
      "Q168",
      "Q3"
    ],
    "SelectE_recommedations": [
      "Q668",
      "Q688",
      "Q28"
    ]
  },
  {
    "Question_Number": "Q485",
    "Question_Description": "한 회사가 오래된 뉴스 영상의 비디오 아카이브를 AWS에 저장하기 위한 솔루션을 찾고 있습니다. 회사는 비용을 최소화해야 하며, 자주 복구할 일이 거의 없습니다. 그러나 필요할 때는 최대 5분 이내에 액세스가 가능해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109470-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 오랜 기간 동안 거의 접근하지 않는 대용량 데이터를 저렴하게 보관하면서, 필요 시 5분 이내에 데이터를 가져와야 하는 시나리오입니다. Amazon S3 Glacier의 Expedited retrievals를 사용하면 짧은 대기 시간으로 파일을 복구할 수 있으면서도, 저장 비용을 크게 낮출 수 있어 가장 적합한 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "오래된 뉴스 영상",
      "비디오 아카이브",
      "비용 최소화",
      "드문 복구",
      "5분 이내 가용",
      "Amazon S3 Glacier",
      "Expedited retrievals",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3 Glacier",
      "Expedited retrievals",
      "Standard retrievals",
      "Amazon S3 Standard-Infrequent Access (S3 Standard-IA)",
      "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)"
    ],
    "SelectA": "비디오 아카이브를 Amazon S3 Glacier에 저장하고 Expedited retrievals를 사용합니다.",
    "SelectA_Commentary": "Expedited retrievals를 통해 5분 이내에 데이터를 복구할 수 있으며, 드문 복구 시 높은 비용 효율을 달성할 수 있는 최적의 솔루션입니다.",
    "SelectB": "비디오 아카이브를 Amazon S3 Glacier에 저장하고 Standard retrievals를 사용합니다.",
    "SelectB_Commentary": "Standard retrieval은 3~5시간까지 소요될 수 있어 5분 이내 액세스 요구사항을 충족하지 못합니다.",
    "SelectC": "비디오 아카이브를 Amazon S3 Standard-Infrequent Access (S3 Standard-IA)에 저장합니다.",
    "SelectC_Commentary": "S3 Standard-IA는 즉각적 액세스가 가능하지만, S3 Glacier보다 저장 비용이 더 높아 장기 보관 요구 시 비용 효율이 떨어집니다.",
    "SelectD": "비디오 아카이브를 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)에 저장합니다.",
    "SelectD_Commentary": "S3 One Zone-IA는 한 개의 가용 영역에만 보관하므로 내구성이 낮고, Glacier보다 비용도 더 높아 장기 보관 및 복구 요구에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q728",
      "Q541",
      "Q486",
      "Q985",
      "Q943"
    ],
    "SelectA_recommedations": [
      "Q1003",
      "Q285",
      "Q606"
    ],
    "SelectB_recommedations": [
      "Q126",
      "Q285",
      "Q1003"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q23",
      "Q126"
    ],
    "SelectD_recommedations": [
      "Q23",
      "Q285",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q486",
    "Question_Description": "한 회사가 AWS에서 3티어 애플리케이션을 구축하고 있습니다. 프레젠테이션 티어는 정적 웹사이트를 제공하고, 로직 티어는 컨테이너화된 애플리케이션으로 구성됩니다. 이 애플리케이션은 관계형 데이터베이스에 데이터를 저장합니다. 회사는 배포를 간소화하고 운영 비용을 줄이길 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109664-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 정적 콘텐츠, 컨테이너 기반 로직, 그리고 관계형 데이터베이스의 3티어 애플리케이션을 최소한의 운영 부담으로 구축하는 방법을 묻습니다. 정적 콘텐츠는 Amazon S3에 호스팅하여 비용을 절감할 수 있고, Amazon ECS를 AWS Fargate와 함께 사용하면 서버 관리가 필요 없으므로 운영이 간소화됩니다. 또한 Managed Amazon RDS로 데이터베이스를 운영하면 인프라 관리를 최소화할 수 있으며, 참고로 ECS가 EKS보다 비용 면에서 더 유리하기도 합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "3티어 애플리케이션",
      "정적 웹사이트",
      "컨테이너",
      "관계형 데이터베이스",
      "배포 간소화",
      "운영 비용 절감"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon RDS",
      "Amazon CloudFront",
      "Amazon EKS",
      "Amazon EC2",
      "Reserved Instance"
    ],
    "SelectA": "Amazon S3를 사용해 정적 콘텐츠를 호스팅하고, Amazon Elastic Container Service(Amazon ECS)와 AWS Fargate를 사용해 컴퓨팅 리소스를 제공합니다. 데이터베이스는 Managed Amazon RDS 클러스터를 사용합니다.",
    "SelectA_Commentary": "정적 웹은 Amazon S3로 호스팅해 쉽고 저렴하며, ECS Fargate로 서버 관리 없이 컨테이너를 운영해 간소화와 비용 절감을 모두 달성합니다.",
    "SelectB": "Amazon CloudFront를 사용해 정적 콘텐츠를 호스팅하고, Amazon ECS와 Amazon EC2를 사용해 컴퓨팅 리소스를 제공합니다. 데이터베이스는 Managed Amazon RDS 클러스터를 사용합니다.",
    "SelectB_Commentary": "CloudFront 단독으로 정적 호스팅 비용이 늘어날 수 있고 EC2 인스턴스 관리 필요성이 있어 운영 부담이 커집니다.",
    "SelectC": "Amazon S3를 사용해 정적 콘텐츠를 호스팅하고, Amazon Elastic Kubernetes Service(Amazon EKS)와 AWS Fargate를 사용해 컴퓨팅 리소스를 제공합니다. 데이터베이스는 Managed Amazon RDS 클러스터를 사용합니다.",
    "SelectC_Commentary": "EKS는 ECS 대비 설정이 복잡해 운영 비용과 노력이 더 들 수 있어 단순화 요구사항에 부합하지 않습니다.",
    "SelectD": "Amazon EC2 Reserved Instances로 정적 콘텐츠를 호스팅하고, Amazon Elastic Kubernetes Service(Amazon EKS)와 Amazon EC2로 컴퓨팅 리소스를 제공합니다. 데이터베이스는 Managed Amazon RDS 클러스터를 사용합니다.",
    "SelectD_Commentary": "EC2 인스턴스로 정적 호스팅은 불필요하게 복잡하며, EKS와 EC2 조합은 운영 비용과 관리 부담도 증가시킵니다.",
    "Question_Description_recommedations": [
      "Q943",
      "Q541",
      "Q728",
      "Q485",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q822",
      "Q31",
      "Q380"
    ],
    "SelectB_recommedations": [
      "Q822",
      "Q31",
      "Q300"
    ],
    "SelectC_recommedations": [
      "Q822",
      "Q591",
      "Q31"
    ],
    "SelectD_recommedations": [
      "Q380",
      "Q591",
      "Q822"
    ]
  },
  {
    "Question_Number": "Q487",
    "Question_Description": "한 회사가 애플리케이션용 스토리지 솔루션을 찾고 있습니다. 이 솔루션은 고가용성이어야 하며 확장 가능해야 합니다. 또한 파일시스템처럼 동작해야 하고, 여러 Linux 인스턴스(온프레미스와 AWS 모두)에서 기본 프로토콜을 통해 마운트할 수 있어야 하며 최소 크기 제한이 없어야 합니다. 이 회사는 온프레미스 네트워크와 VPC 간 Site-to-Site VPN을 구성해두었습니다. 이러한 요구 사항을 만족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109665-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스와 AWS 환경 모두에서 하나의 공유 파일시스템을 고가용성과 확장성을 갖추어 사용해야 하는 시나리오입니다. Amazon EFS는 NFS를 통해 여러 인스턴스에서 동시에 마운트할 수 있고, 미니멈 사이즈 제한이 없어 요구 사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "확장성",
      "파일시스템",
      "Site-to-Site VPN",
      "Amazon EFS",
      "Multiple Mount Targets"
    ],
    "Terms": [
      "Amazon FSx",
      "Multi-AZ",
      "Amazon EBS Multi-Attach volumes",
      "Amazon EFS",
      "Mount Target",
      "Access Point",
      "NFS"
    ],
    "SelectA": "Amazon FSx Multi-AZ deployments",
    "SelectA_Commentary": "Amazon FSx는 필요한 경우 Windows 파일 서버나 특정 파일시스템(Lustre, NetApp 등)을 제공하지만, 문제에서 요구하는 기본 NFS 프로토콜과의 호환성이 제한되어 적합하지 않습니다.",
    "SelectB": "Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes",
    "SelectB_Commentary": "Amazon EBS Multi-Attach 볼륨은 여러 EC2 인스턴스에 동시 연결은 가능하지만 블록 스토리지로서 NFS 같은 파일 프로토콜을 직접 지원하지 않습니다.",
    "SelectC": "Amazon Elastic File System (Amazon EFS) with multiple mount targets",
    "SelectC_Commentary": "Amazon EFS는 NFS를 통한 공유 파일시스템을 제공하며, 여러 마운트 타겟을 활용해 다중 리전/서브넷 및 온프레미스 접근까지 지원하여 가장 적절한 해법입니다.",
    "SelectD": "Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points",
    "SelectD_Commentary": "단일 마운트 타겟이나 Access Point만으로는 여러 서브넷이나 온프레미스 환경을 효율적으로 지원하기 어려워, 문제의 고가용성과 확장성 요구를 완벽히 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q194",
      "Q720",
      "Q68",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q584",
      "Q466",
      "Q869"
    ],
    "SelectB_recommedations": [
      "Q602",
      "Q244",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q244",
      "Q584"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q102",
      "Q244"
    ]
  },
  {
    "Question_Number": "Q488",
    "Question_Description": "한 미디어 회사는 4년 동안 AWS Organizations의 All features 모드로 여러 AWS 계정을 조직해 왔습니다. 회사의 재무 팀에 따르면, 멤버 계정의 Billing 정보는 멤버 계정의 root user를 포함하여 그 누구도 액세스할 수 없어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109509-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 멤버 계정의 Billing 정보에 대한 접근을 조직 단위에서 일괄 차단해야 하는 상황을 다룹니다. SCP를 통해 root user를 포함한 모든 사용자 권한을 제한해 안전하게 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Organizations",
      "All features",
      "root user",
      "Billing 정보",
      "Service Control Policy",
      "Organizational Unit",
      "접근 권한 제한"
    ],
    "Terms": [
      "AWS Organizations",
      "All features",
      "Billing",
      "Member account",
      "Root user",
      "Service Control Policy (SCP)",
      "Organizational unit (OU)",
      "Identity-based policy",
      "Consolidated billing",
      "IAM Group"
    ],
    "SelectA": "모든 재무 팀 사용자를 IAM 그룹에 추가하고, AWS에서 제공하는 Billing이라는 Managed Policy를 그룹에 연결합니다.",
    "SelectA_Commentary": "이는 재무 팀에 권한을 부여하는 설정일 뿐, 멤버 계정 root user의 Billing 접근을 막지 못해 요구사항을 만족시키지 못합니다.",
    "SelectB": "아이덴티티 기반 정책을 연결하여 모든 사용자(루트 사용자 포함)의 Billing 정보 액세스를 거부합니다.",
    "SelectB_Commentary": "아이덴티티 기반 정책만으로는 root user 권한을 완전히 차단하기 어렵기 때문에 이 요구 사항을 충족할 수 없습니다.",
    "SelectC": "서비스 컨트롤 정책(SCP)을 생성해 Billing 정보 액세스를 거부합니다. 이 SCP를 루트 OU에 연결합니다.",
    "SelectC_Commentary": "SCP는 조직 전체의 권한 상한선을 설정하므로 root user를 포함해 멤버 계정 모두에서 Billing 정보를 차단할 수 있어 요구사항에 최적화된 솔루션입니다.",
    "SelectD": "Organizations All features 모드에서 Organizations Consolidated billing 모드로 전환합니다.",
    "SelectD_Commentary": "Consolidated billing 모드로 전환해도 root user의 Billing 정보 접근 자체를 막을 수 없으므로 문제를 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q878",
      "Q137",
      "Q745",
      "Q168",
      "Q945"
    ],
    "SelectA_recommedations": [
      "Q476",
      "Q222",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q665",
      "Q478",
      "Q189"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q803",
      "Q106"
    ],
    "SelectD_recommedations": [
      "Q488",
      "Q168",
      "Q945"
    ]
  },
  {
    "Question_Number": "Q489",
    "Question_Description": "한 전자상거래 회사가 AWS Cloud에서 구동되는 애플리케이션을 운영 중이며, 이는 온프레미스 창고 솔루션과 연동되어 있습니다. 이 회사는 Amazon SNS를 사용하여 주문 메시지를 온프레미스 HTTPS endpoint로 전송하여 창고 애플리케이션이 주문을 처리하도록 합니다. 그런데 온프레미스 데이터 센터 팀은 일부 주문 메시지가 수신되지 않았음을 발견했습니다. 솔루션스 아키텍트는 미전달된 메시지들을 14일 동안 보관하고 분석해야 합니다. 가장 적은 개발 노력으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109637-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon SNS와 온프레미스 HTTPS endpoint 간 메시지 전달 실패 시, 미전달 메시지를 14일 보관하고 검토하는 방안을 묻습니다. SNS Dead Letter Queue(DLQ)로 Amazon SQS를 사용하는 옵션은 추가 개발을 최소화하면서 간단히 메시지를 안전하게 수집·분석할 수 있는 최적의 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "메시지 보관",
      "미전달 메시지 분석",
      "14일 보관",
      "개발 노력 최소화"
    ],
    "Terms": [
      "Amazon SNS",
      "Amazon SQS",
      "Dead Letter Queue(DLQ)",
      "HTTPS endpoint",
      "Amazon Kinesis Data Stream",
      "Amazon DynamoDB",
      "TTL"
    ],
    "SelectA": "Amazon SNS dead letter queue로 Amazon Kinesis Data Stream을 사용하고 보관 기간을 14일로 설정합니다.",
    "SelectA_Commentary": "Kinesis Data Stream을 추가로 구성해야 하며, DLQ로서 SQS보다 설정이 복잡합니다. 최소 개발 노력이 요구된다는 조건에 적합하지 않습니다.",
    "SelectB": "애플리케이션과 Amazon SNS 사이에 보관 기간 14일로 설정된 Amazon SQS 큐를 추가합니다.",
    "SelectB_Commentary": "SNS로 직접 전송 로직을 변경해야 하며, 실패 메시지를 보관하는 DLQ 용도와 달라서 조건을 만족하지 못합니다.",
    "SelectC": "Amazon SNS dead letter queue로 보관 기간 14일의 Amazon SQS 큐를 구성합니다.",
    "SelectC_Commentary": "DLQ로 SQS를 사용하면 미전달 메시지를 자동으로 수집하고 14일간 안전하게 보관·분석할 수 있어 개발 노력과 설정이 간단합니다.",
    "SelectD": "Amazon SNS dead letter queue로 Amazon DynamoDB를 사용하고 TTL을 14일로 설정합니다.",
    "SelectD_Commentary": "DynamoDB에 TTL을 적용하려면 추가 개발 고려사항이 많고, SQS를 사용하는 방법에 비해 설정이 더 복잡합니다.",
    "Question_Description_recommedations": [
      "Q94",
      "Q775",
      "Q148",
      "Q10",
      "Q513"
    ],
    "SelectA_recommedations": [
      "Q845",
      "Q489",
      "Q351"
    ],
    "SelectB_recommedations": [
      "Q615",
      "Q8",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q845",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q845",
      "Q78",
      "Q768"
    ]
  },
  {
    "Question_Number": "Q490",
    "Question_Description": "한 게임 회사가 Amazon DynamoDB를 사용하여 지리적 위치, 플레이어 데이터, 리더보드와 같은 사용자 정보를 저장하고 있습니다. 이 회사는 최소한의 코딩으로 Amazon S3 버킷에 연속 백업을 구성해야 합니다. 백업은 애플리케이션 가용성에 영향을 주어서는 안 되며, 테이블에 정의된 읽기 용량 단위(RCU)에도 영향을 주어서는 안 됩니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109577-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "DynamoDB의 연속 백업 기능은 운영 테이블의 가용성과 RCU에 영향을 주지 않으며, 복원 시점을 자유롭게 지정할 수 있습니다. 별도 구축이나 복잡한 코딩 없이 네이티브 기능을 사용하면 신뢰도 높은 백업을 손쉽게 유지할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "연속 백업",
      "Amazon DynamoDB",
      "Amazon S3",
      "Point-in-time recovery",
      "읽기 용량 단위(RCU)",
      "가용성"
    ],
    "Terms": [
      "DynamoDB Streams",
      "AWS Lambda",
      "EMR",
      "Apache Hive",
      "Continuous Backups",
      "Point-in-time recovery"
    ],
    "SelectA": "Amazon EMR 클러스터를 사용합니다. Apache Hive 작업을 생성해 데이터를 Amazon S3로 백업합니다.",
    "SelectA_Commentary": "EMR 및 Hive를 구축하고 관리해야 하므로 코딩 및 운영 복잡성이 증가하며, DynamoDB의 연속 백업 요구사항과는 맞지 않습니다.",
    "SelectB": "DynamoDB에서 데이터를 연속 백업으로 직접 Amazon S3로 내보냅니다. 테이블에 대해 point-in-time recovery를 활성화합니다.",
    "SelectB_Commentary": "DynamoDB의 네이티브 연속 백업 기능을 사용하여 S3로 빠르고 간단하게 백업이 가능하며, 테이블 가용성이나 RCU에 영향을 주지 않는 최적의 솔루션입니다.",
    "SelectC": "Amazon DynamoDB Streams를 구성합니다. 스트림을 소비하는 AWS Lambda 함수를 만들어 데이터를 Amazon S3 버킷으로 내보냅니다.",
    "SelectC_Commentary": "DynamoDB Streams 활용 시 트랜잭션 데이터를 처리하는 별도 Lambda 코딩이 필요하며, 연속 백업 요구사항을 단순히 충족하기엔 비효율적일 수 있습니다.",
    "SelectD": "정기적으로 데이터베이스 테이블 데이터를 Amazon S3로 내보내는 AWS Lambda 함수를 생성합니다. 테이블에 대해 point-in-time recovery를 활성화합니다.",
    "SelectD_Commentary": "정기적 Lambda 실행에 대한 스케줄링과 유지보수가 필요해 코딩 및 운영 부담이 높습니다. DynamoDB의 네이티브 연속 백업보다 간편성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q1002",
      "Q400",
      "Q228",
      "Q114",
      "Q768"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q944",
      "Q198"
    ],
    "SelectB_recommedations": [
      "Q1002",
      "Q490",
      "Q78"
    ],
    "SelectC_recommedations": [
      "Q768",
      "Q1002",
      "Q845"
    ],
    "SelectD_recommedations": [
      "Q764",
      "Q18",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q491",
    "Question_Description": "한 솔루션스 아키텍트가 은행의 신용 카드 데이터 검증 요청을 처리하기 위한 비동기 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 보안이 보장되어야 하며 각 요청을 적어도 한 번 이상 처리할 수 있어야 합니다. 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109513-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 은행의 신용 카드 검증 요청을 비동기로 처리하면서 보안을 유지하고, 각 요청을 최소 한 번 이상 처리해야 하는 아키텍처를 요구합니다. Amazon SQS Standard Queue는 'at least once' 처리 모델을 제공하며, FIFO 큐보다 비용이 저렴합니다. AWS KMS(SSE-KMS)를 통한 암호화로 보안 요건도 충족하며 Lambda Event Source Mapping을 통해 처리 과정을 자동화하고 운영 복잡성을 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "비동기 애플리케이션",
      "신용 카드 데이터 검증",
      "보안",
      "최소 한 번 이상 처리",
      "비용 효율"
    ],
    "Terms": [
      "AWS Lambda Event Source Mapping",
      "Amazon Simple Queue Service (Amazon SQS) Standard Queue",
      "Amazon Simple Queue Service (Amazon SQS) FIFO Queue",
      "SSE-KMS",
      "SSE-SQS",
      "kms:Decrypt",
      "encryption key invocation permission"
    ],
    "SelectA": "AWS Lambda Event Source Mapping을 사용합니다. Amazon SQS Standard Queue를 이벤트 소스로 설정합니다. AWS KMS(SSE-KMS)를 사용하여 암호화하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가합니다.",
    "SelectA_Commentary": "Amazon SQS Standard Queue는 최소 한 번 이상 전달 보장을 제공하며, FIFO보다 비용이 저렴합니다. AWS KMS(SSE-KMS)를 사용해 보안을 강화하고 Lambda Event Source Mapping으로 운영이 간소해집니다.",
    "SelectB": "AWS Lambda Event Source Mapping을 사용합니다. Amazon SQS FIFO Queue를 이벤트 소스로 설정합니다. SQS-managed encryption keys(SSE-SQS)를 사용하여 암호화하고, Lambda 함수에 encryption key invocation 권한을 추가합니다.",
    "SelectB_Commentary": "FIFO 큐는 정확히 한 번(Exactly-Once) 처리를 보장하지만 비용이 더 들고, 문제 요구 사항은 ‘최소 한 번 이상 처리’이며 비용 효율이 중요하므로 적절하지 않습니다.",
    "SelectC": "AWS Lambda Event Source Mapping을 사용합니다. Amazon SQS FIFO Queue를 이벤트 소스로 설정합니다. AWS KMS 키(SSE-KMS)를 사용하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가합니다.",
    "SelectC_Commentary": "FIFO 큐와 KMS 조합은 정확성과 보안을 강화하지만, 표준 큐보다 비용이 높습니다. 문제에서 요구하는 ‘적어도 한 번’ 처리와 비용 효율 측면에서 비효율적입니다.",
    "SelectD": "AWS Lambda Event Source Mapping을 사용합니다. Amazon SQS Standard Queue를 이벤트 소스로 설정합니다. AWS KMS 키(SSE-KMS)를 사용하여 암호화하고, Lambda 함수에 encryption key invocation 권한을 추가합니다.",
    "SelectD_Commentary": "표준 큐 사용은 적절하지만, encryption key invocation 권한 설정으로 인해 kms:Decrypt만 필요한 방식보다 설정이 복잡합니다. 비용 효율성과 단순성 면에서 A만큼 최적은 아닙니다.",
    "Question_Description_recommedations": [
      "Q58",
      "Q917",
      "Q255",
      "Q735",
      "Q187"
    ],
    "SelectA_recommedations": [
      "Q775",
      "Q354",
      "Q98"
    ],
    "SelectB_recommedations": [
      "Q98",
      "Q636",
      "Q775"
    ],
    "SelectC_recommedations": [
      "Q775",
      "Q354",
      "Q351"
    ],
    "SelectD_recommedations": [
      "Q775",
      "Q354",
      "Q98"
    ]
  },
  {
    "Question_Number": "Q492",
    "Question_Description": "한 회사가 개발 작업을 위해 여러 AWS 계정을 사용하고 있습니다. 일부 스태프가 과도하게 큰 Amazon EC2 인스턴스를 지속적으로 사용하여, 개발 계정의 연간 예산을 초과하게 되었습니다. 회사는 이러한 계정에서 AWS 리소스 생성을 중앙에서 제한하고 싶어 합니다. 가장 적은 개발 노력이 필요한 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109638-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 AWS 계정에서 과도한 리소스 사용을 방지하고자 할 때 가장 간단하고 효과적인 방법은 AWS Organizations의 SCP를 통해 리소스 생성 자체를 제한하는 것입니다. 이는 추가 개발 작업 없이 즉시 적용 가능하며 중앙 집중적으로 관리할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "중앙에서 제한",
      "AWS 계정 관리",
      "예산 초과",
      "개발 노력 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Organizations",
      "Service Control Policy (SCP)",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS Service Catalog",
      "AWS Systems Manager"
    ],
    "SelectA": "AWS Systems Manager 템플릿을 개발하여 승인된 EC2 생성 프로세스를 사용합니다. 승인된 Systems Manager 템플릿으로만 EC2 인스턴스를 프로비저닝합니다.",
    "SelectA_Commentary": "직접 템플릿을 개발하고 유지보수해야 하므로 개발 노력이 많이 들며, 계정 전체를 쉽게 관리하기에는 한계가 있습니다.",
    "SelectB": "AWS Organizations를 사용하여 계정을 조직 단위(OU)로 구성합니다. 그리고 EC2 인스턴스 타입 사용을 제어하는 service control policy (SCP)를 정의하고 연결합니다.",
    "SelectB_Commentary": "조직 전체에 단일 정책을 적용해 리소스 생성을 제한할 수 있어 개발 노력이 가장 적고 중앙 집중 관리가 가능한 최적의 솔루션입니다.",
    "SelectC": "Amazon EventBridge 규칙을 구성하여 EC2 인스턴스가 생성될 때 AWS Lambda 함수를 호출합니다. 허용되지 않은 EC2 인스턴스 타입을 중지시킵니다.",
    "SelectC_Commentary": "사후에 인스턴스를 중지하는 방식이므로 완전한 제어가 어렵고, Lambda 코드를 작성·유지해야 하므로 추가 개발 노력이 필요합니다.",
    "SelectD": "스태프가 허용된 EC2 인스턴스 타입만 생성할 수 있도록 AWS Service Catalog 제품을 설정합니다. 스태프가 오직 Service Catalog 제품만으로 EC2 인스턴스를 배포할 수 있게 합니다.",
    "SelectD_Commentary": "Service Catalog 구성이 필요하며, 각 제품을 주기적으로 업데이트해야 하므로 운영 부담과 개발 노력이 더 큽니다.",
    "Question_Description_recommedations": [
      "Q315",
      "Q329",
      "Q682",
      "Q480",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q723",
      "Q329",
      "Q492"
    ],
    "SelectB_recommedations": [
      "Q709",
      "Q988",
      "Q560"
    ],
    "SelectC_recommedations": [
      "Q329",
      "Q682",
      "Q453"
    ],
    "SelectD_recommedations": [
      "Q329",
      "Q492",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q493",
    "Question_Description": "한 회사가 고객 서비스 전화의 품질을 측정하기 위해 AI를 활용하고자 합니다. 현재 영어를 포함하여 4개 언어로 전화를 관리하고 있으며, 추후 새로운 언어가 추가될 예정입니다. 회사는 ML 모델을 정기적으로 유지관리할 인력이 부족합니다. 이 회사는 고객 서비스 전화 녹음으로부터 텍스트 기반의 감정 분석 보고서를 작성해야 하며, 녹음된 텍스트는 영어로 번역되어야 합니다. 이 요구사항을 충족하기 위해 어떤 단계를 결합해야 할까요? (3개를 선택하십시오.)",
    "Answer": "D,E,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109639-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 언어로 제공되는 고객 서비스 전화 녹음을 텍스트로 변환하고, 영어로 번역한 뒤 감정 분석 레포트를 작성해야 하는 상황입니다. 사내에서 ML 모델을 직접 관리하기 어려우므로, 관리형 AWS AI 서비스를 효율적으로 조합하는 것이 핵심입니다. 먼저 Amazon Transcribe를 이용해 음성을 텍스트로 전사하고, Amazon Translate를 이용해 생성된 텍스트를 영어로 번역합니다. 마지막으로 Amazon Comprehend로 번역된 텍스트에 감정 분석을 수행하면 별도의 모델 관리 없이 필요한 보고서를 손쉽게 생성할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "고객 서비스 전화",
      "다국어 음성 녹음",
      "텍스트 변환",
      "영어 번역",
      "감정 분석"
    ],
    "Terms": [
      "Amazon Transcribe",
      "Amazon Translate",
      "Amazon Comprehend",
      "Amazon Polly",
      "Amazon Lex",
      "AI",
      "ML 모델",
      "Sentiment Analysis"
    ],
    "SelectA": "Use Amazon Comprehend to translate the audio recordings into English.",
    "SelectA_Commentary": "Amazon Comprehend는 번역 서비스가 아니므로 음성을 영어로 바로 번역할 수 없습니다.",
    "SelectB": "Use Amazon Lex to create the written sentiment analysis reports.",
    "SelectB_Commentary": "Amazon Lex는 대화형 봇을 구축하는 서비스로, 감정 분석 보고서를 작성하는 데 적합하지 않습니다.",
    "SelectC": "Use Amazon Polly to convert the audio recordings into text.",
    "SelectC_Commentary": "Amazon Polly는 텍스트를 음성으로 변환하는 서비스로, 음성을 텍스트로 변환하는 역할이 아닙니다.",
    "SelectD": "Use Amazon Transcribe to convert the audio recordings in any language into text.",
    "SelectD_Commentary": "Amazon Transcribe는 음성을 텍스트로 전사하는 서비스로, 다양한 언어 지원이 가능해 녹음을 텍스트로 변환하기에 적합합니다.",
    "SelectE": "Use Amazon Translate to translate text in any language to English.",
    "SelectE_Commentary": "Amazon Translate는 전사된 텍스트를 영어로 번역할 수 있어 다국어 녹음 처리에 필수적입니다.",
    "SelectF": "Use Amazon Comprehend to create the sentiment analysis reports.",
    "SelectF_Commentary": "Amazon Comprehend를 통해 번역된 텍스트에 대한 감정 분석을 수행하고, 보고서를 생성할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q622",
      "Q506",
      "Q915",
      "Q132",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q817",
      "Q158",
      "Q888"
    ],
    "SelectB_recommedations": [
      "Q199",
      "Q361",
      "Q33"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q199",
      "Q166"
    ],
    "SelectD_recommedations": [
      "Q817",
      "Q199",
      "Q501"
    ],
    "SelectE_recommedations": [
      "Q158",
      "Q888",
      "Q132"
    ],
    "SelectF_recommedations": [
      "Q414",
      "Q361",
      "Q199"
    ]
  },
  {
    "Question_Number": "Q494",
    "Question_Description": "한 회사가 내부 시스템을 호스팅하기 위해 Amazon EC2 인스턴스를 사용하고 있습니다. 배포 작업의 일환으로 한 관리자가 AWS CLI를 사용하여 EC2 인스턴스를 종료하려고 시도했지만 403(Access Denied) 오류 메시지를 받았습니다. 해당 관리자는 특정 IAM 역할을 사용 중이며, 그 IAM 역할에는 다음과 같은 IAM policy가 연결되어 있습니다. 이러한 요청이 실패한 원인은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109727-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM 정책에 정의된 Source IP 조건에 따라 EC2 인스턴스 종료 요청이 거부되는 상황을 파악하는 것입니다. 요청이 허용된 CIDR 범위가 아닌 곳에서 이루어지면 Access Denied가 발생합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "EC2 인스턴스 종료",
      "Access Denied",
      "IAM 역할",
      "CIDR 블록",
      "IP 제한"
    ],
    "Terms": [
      "Amazon EC2",
      "IAM",
      "IAM Role",
      "IAM Policy",
      "Deny statement",
      "Action field",
      "CIDR block",
      "Access Denied (403)"
    ],
    "SelectA": "EC2 인스턴스에 Deny 구문이 포함된 리소스 기반 정책이 있습니다.",
    "SelectA_Commentary": "인스턴스 자체 리소스 기반 정책 문제로 오해할 수 있지만, IAM 정책에서의 IP 주소 제한이 핵심이므로 틀렸습니다.",
    "SelectB": "정책 문에 Principal이 지정되지 않았습니다.",
    "SelectB_Commentary": "정책 문에 Principal 명시가 없어 발생하는 오류는 아닙니다. 액세스가 완전히 차단될 수 있지만, 여기서는 IP 범위에 따라 Deny가 발생한 것입니다.",
    "SelectC": "\"Action\" 필드가 EC2 인스턴스를 종료하기 위한 작업 권한을 부여하지 않았습니다.",
    "SelectC_Commentary": "EC2를 종료하는 데 필요한 ec2:TerminateInstances가 없어서 생기는 문제로 보일 수 있으나, 정책에 대한 언급보다 IP 제한이 원인입니다.",
    "SelectD": "EC2 인스턴스를 종료하는 요청이 192.0.2.0/24 또는 203.0.113.0/24 CIDR 블록에서 유입된 것이 아닙니다.",
    "SelectD_Commentary": "IAM 정책에서 Source IP 제약을 두었고, 요청 IP가 허용된 CIDR 범위 밖이므로 403 오류가 발생했습니다. 정답입니다.",
    "Question_Description_recommedations": [
      "Q96",
      "Q780",
      "Q524",
      "Q218",
      "Q222"
    ],
    "SelectA_recommedations": [
      "Q682",
      "Q100",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q100",
      "Q315"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q100",
      "Q315"
    ]
  },
  {
    "Question_Number": "Q495",
    "Question_Description": "한 회사가 내부 감사를 진행하고 있습니다. 이 회사는 AWS Lake Formation 데이터 레이크와 연결된 Amazon S3 버킷에 민감한 고객 또는 직원 데이터가 포함되어 있지 않은지 확인하려고 합니다. 회사는 여권 번호와 신용카드 번호를 포함하여 개인 식별 정보(PII)나 금융 정보를 발견하고 싶어 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109666-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷에 저장된 민감 정보(PII, 금융 정보 등)의 식별 여부를 확인하기 위한 방법을 묻습니다. Amazon Macie는 PII 관련 스캔에 특화된 관리 식별자를 통해 여권 번호, 신용카드 번호 등 규정된 유형의 데이터를 탐지할 수 있어 가장 간단하고 적합한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "내부 감사",
      "민감 데이터",
      "개인 식별 정보(PII)",
      "금융 정보",
      "AWS Lake Formation"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lake Formation",
      "PII",
      "AWS Audit Manager",
      "Payment Card Industry Data Security Standards (PCI DSS)",
      "Amazon S3 Inventory",
      "Amazon Athena",
      "Amazon Macie",
      "S3 Select"
    ],
    "SelectA": "계정에 AWS Audit Manager를 구성하고, Payment Card Industry Data Security Standards (PCI DSS)를 선택합니다.",
    "SelectA_Commentary": "AWS Audit Manager는 규정 준수 평가 도구로, 직접 데이터 스캔이나 PII 탐지에는 적합하지 않습니다.",
    "SelectB": "S3 버킷에서 Amazon S3 Inventory를 구성하고, Amazon Athena로 인벤토리를 쿼리합니다.",
    "SelectB_Commentary": "Inventory는 객체 목록만 제공하며, 실제 데이터 내용의 민감 정보를 탐지하기 어렵습니다.",
    "SelectC": "Amazon Macie를 구성하여 필요한 데이터 유형에 대해 관리 식별자를 사용하는 데이터 디스커버리 작업을 실행합니다.",
    "SelectC_Commentary": "Macie는 PII, 금융 정보 등 민감 데이터 스캔에 특화된 서비스이므로 요구 사항에 가장 부합하며 정답입니다.",
    "SelectD": "Amazon S3 Select를 사용하여 S3 버킷 전체에 대한 리포트를 실행합니다.",
    "SelectD_Commentary": "S3 Select는 객체 내 일부 데이터만 쿼리 가능하지만, 체계적인 민감 데이터 식별 솔루션으로는 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q442",
      "Q609",
      "Q533",
      "Q756",
      "Q965"
    ],
    "SelectA_recommedations": [
      "Q426",
      "Q828",
      "Q787"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q862",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q106",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q496",
    "Question_Description": "한 회사가 온프레미스 서버에서 애플리케이션을 호스팅하고 있습니다. 현재 스토리지 용량이 부족해지고 있으며, 애플리케이션은 block storage와 NFS storage를 모두 사용합니다. 회사는 기존 애플리케이션을 재설계하지 않고도 로컬 캐싱을 지원하는 고성능 솔루션이 필요합니다. 이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 두 가지 조합의 작업을 수행해야 합니까? (두 가지를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109552-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 block storage와 NFS storage를 동시에 다루면서, 로컬 캐시를 통해 높은 성능을 제공해야 하는 시나리오를 다루고 있습니다. AWS Storage Gateway의 file gateway와 volume gateway를 함께 도입하면, NFS 스토리지와 block 스토리지를 각각 대체하고 로컬 캐싱을 통해 성능을 향상시킬 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "온프레미스",
      "고성능",
      "로컬 캐싱",
      "기존 애플리케이션 재설계 없음",
      "block storage",
      "NFS storage",
      "AWS Storage Gateway"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "file gateway",
      "volume gateway",
      "NFS",
      "Amazon S3",
      "AWS Snowball Edge",
      "Amazon EFS",
      "block storage",
      "local caching"
    ],
    "SelectA": "Amazon S3를 파일 시스템처럼 온프레미스 서버에 마운트합니다.",
    "SelectA_Commentary": "기존 block storage와 NFS에 대한 직접적 대체가 어렵고, 로컬 캐싱 방식도 적절하지 않아 요구사항을 만족시키기 어렵습니다.",
    "SelectB": "AWS Storage Gateway file gateway를 배포하여 NFS storage를 대체합니다.",
    "SelectB_Commentary": "NFS 프로토콜을 지원하면서 로컬 캐싱을 제공해, 운영 중인 NFS 스토리지를 대체할 수 있습니다.",
    "SelectC": "AWS Snowball Edge를 배포하여 온프레미스 서버에 NFS 마운트를 제공합니다.",
    "SelectC_Commentary": "AWS Snowball Edge는 대규모 데이터 이전에 적합하지만, 상시적인 로컬 캐싱 및 스토리지 확장 시나리오에는 부적합합니다.",
    "SelectD": "AWS Storage Gateway volume gateway를 배포하여 block storage를 대체합니다.",
    "SelectD_Commentary": "block storage를 클라우드로 확장하면서 로컬 캐싱을 통해 높은 성능을 유지할 수 있습니다.",
    "SelectE": "Amazon EFS 볼륨을 배포하고 이를 온프레미스 서버에 마운트합니다.",
    "SelectE_Commentary": "Amazon EFS는 NFS 기반의 완전관리형 서비스이지만, 온프레미스 환경과의 직접적 로컬 캐싱 통합이 복잡하여 요구사항과 다소 어긋납니다.",
    "Question_Description_recommedations": [
      "Q283",
      "Q990",
      "Q626",
      "Q1015",
      "Q397"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q626"
    ],
    "SelectB_recommedations": [
      "Q6",
      "Q990",
      "Q283"
    ],
    "SelectC_recommedations": [
      "Q990",
      "Q283",
      "Q496"
    ],
    "SelectD_recommedations": [
      "Q305",
      "Q620",
      "Q597"
    ],
    "SelectE_recommedations": [
      "Q361",
      "Q501",
      "Q626"
    ]
  },
  {
    "Question_Number": "Q497",
    "Question_Description": "한 회사가 동일한 AWS 리전의 Amazon S3 버킷에서 대량의 데이터를 읽고 쓰는 서비스를 운영하고 있습니다. 이 서비스는 VPC의 프라이빗 서브넷 내 Amazon EC2 인스턴스에 배포되어 있으며, 현재 퍼블릭 서브넷의 NAT Gateway를 통해 Amazon S3와 통신하고 있습니다. 하지만 회사는 데이터 전송 비용을 절감하기를 원합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109667-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "VPC 내부에서 S3로 전송하는 대량 데이터의 비용 절감을 위해서는 NAT Gateway 대신 VPC Gateway Endpoint를 사용해 직접 통신하는 것이 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "프라이빗 서브넷",
      "데이터 전송 비용",
      "NAT Gateway",
      "VPC Gateway Endpoint",
      "Amazon EC2",
      "Amazon S3"
    ],
    "Terms": [
      "VPC Gateway Endpoint",
      "NAT Gateway",
      "NAT Instance",
      "VPC Route Table",
      "Amazon S3",
      "Amazon EC2"
    ],
    "SelectA": "퍼블릭 서브넷에 전용 EC2 NAT Instance를 배포하고, 프라이빗 서브넷의 라우트 테이블을 이 NAT Instance의 ENI로 설정합니다.",
    "SelectA_Commentary": "NAT Instance를 사용해도 NAT Gateway와 비슷한 Data Transfer Out 요금이 발생하므로 비용 절감 효과가 크지 않습니다.",
    "SelectB": "프라이빗 서브넷에 전용 EC2 NAT Instance를 배포하고, 퍼블릭 서브넷의 라우트 테이블을 이 Instance의 ENI로 설정합니다.",
    "SelectB_Commentary": "퍼블릭 서브넷으로의 트래픽 라우팅이 비효율적이며 NAT Instance 자체도 유지·관리 부담과 추가 비용이 발생합니다.",
    "SelectC": "VPC Gateway Endpoint를 구성하고, 프라이빗 서브넷의 라우트 테이블을 해당 Gateway Endpoint로 설정하여 S3 트래픽을 직접 연결합니다.",
    "SelectC_Commentary": "NAT를 거치지 않고 S3에 직접 연결함으로써 데이터 전송 비용을 크게 낮추는 최적의 방법입니다.",
    "SelectD": "두 번째 NAT Gateway를 배포하고, 프라이빗 서브넷의 라우트 테이블을 이 NAT Gateway로 설정합니다.",
    "SelectD_Commentary": "NAT Gateway를 하나 더 늘려도 Data Transfer Out 비용은 여전히 발생하므로 비용 절감 효과가 미미합니다.",
    "Question_Description_recommedations": [
      "Q42",
      "Q860",
      "Q960",
      "Q471",
      "Q72"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q42",
      "Q1013"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q42",
      "Q1013"
    ],
    "SelectC_recommedations": [
      "Q471",
      "Q497",
      "Q860"
    ],
    "SelectD_recommedations": [
      "Q728",
      "Q485",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q498",
    "Question_Description": "한 회사는 Amazon S3 버킷에 고해상도 이미지를 저장하고 있습니다. 애플리케이션 변경을 최소화하기 위해 이미지를 S3 객체의 최신 버전으로 저장하고 있습니다. 회사는 이 이미지들의 최신 두 개 버전만 유지해야 하며, 비용 절감을 원하고 있습니다. 이미 S3 버킷이 큰 비용 요인이라는 사실을 파악했고, 운영 오버헤드를 최소화하면서 S3 비용을 줄일 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109668-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 버저닝이 활성화된 Amazon S3 버킷 내에서 최신 두 개 버전만 유지하고 나머지 버전을 제거해 비용을 절감하려고 합니다. 운영 오버헤드를 최소화하기 위해서는 자동화된 방법이 중요합니다. S3 Lifecycle을 사용하면 규칙에 따라 만료된 객체 버전을 자동으로 제거해 필요한 버전만 유지해 주므로, 가장 효율적인 방법이 됩니다. 수동 삭제가 필요한 AWS Lambda 또는 S3 Batch Operations, 그리고 버저닝 비활성화 방식은 더 많은 관리 작업이 요구되거나 요구사항을 완전히 충족하기 어렵습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon S3",
      "S3 버킷",
      "버저닝",
      "S3 Lifecycle",
      "최신 두 개 버전",
      "비용 절감"
    ],
    "Terms": [
      "S3 Lifecycle",
      "AWS Lambda",
      "S3 Batch Operations",
      "Deactivate versioning",
      "Versioning",
      "Expired object versions",
      "Noncurrent object versions"
    ],
    "SelectA": "S3 Lifecycle을 사용해 만료된 객체 버전을 삭제하고 최신 두 개 버전만 유지하도록 설정합니다.",
    "SelectA_Commentary": "자동화된 정책으로 원하는 개수의 버전만 남겨두어야 할 때 가장 간단한 방식으로, 최소한의 운영 오버헤드로 S3 비용을 절감할 수 있습니다.",
    "SelectB": "AWS Lambda 함수를 사용해 오래된 버전을 확인하고 최신 두 개 버전을 제외한 모든 버전을 삭제합니다.",
    "SelectB_Commentary": "Lambda 함수를 직접 설계, 배포, 모니터링해야 하므로 추가적인 관리와 운영 오버헤드가 발생하여 비효율적입니다.",
    "SelectC": "S3 Batch Operations를 사용해 이전 버전 객체를 삭제하고 최신 두 개 버전만 유지합니다.",
    "SelectC_Commentary": "Batch Operations를 주기적으로 실행하고 모니터링해야 하므로 자동화 수준이 낮고, 추가 설정이 필요해 운영 오버헤드가 적지 않습니다.",
    "SelectD": "S3 버킷의 버저닝을 비활성화하고 최신 두 개 버전만 유지합니다.",
    "SelectD_Commentary": "버저닝을 꺼 버리면 이후 새 버전이 생성되지 않아 전체 워크플로우를 다시 설계해야 할 수 있으며, 이전 버전 관리 역시 자동화되지 않아 운영 복잡도가 높을 수 있습니다.",
    "Question_Description_recommedations": [
      "Q829",
      "Q469",
      "Q415",
      "Q769",
      "Q88"
    ],
    "SelectA_recommedations": [
      "Q829",
      "Q498",
      "Q469"
    ],
    "SelectB_recommedations": [
      "Q807",
      "Q284",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q829",
      "Q993",
      "Q469"
    ],
    "SelectD_recommedations": [
      "Q630",
      "Q997",
      "Q656"
    ]
  },
  {
    "Question_Number": "Q499",
    "Question_Description": "한 회사는 1 Gbps AWS Direct Connect 연결 비용을 최소화해야 합니다. 회사의 평균 연결 사용률은 10% 미만입니다. 솔루션스 아키텍트는 보안을 저해하지 않으면서 비용을 절감할 수 있는 솔루션을 추천해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109515-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "회사에서 사용하는 1 Gbps Direct Connect의 평균 트래픽이 10% 미만이므로, 더 낮은 대역폭의 Hosted Connection을 통해 비용을 줄이는 것이 적합합니다. 이는 보안을 유지하면서도 과도한 네트워크 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "AWS Direct Connect",
      "1 Gbps",
      "200 Mbps hosted connection",
      "보안",
      "비용 절감"
    ],
    "Terms": [
      "AWS Direct Connect",
      "Hosted Connection",
      "Dedicated Connection",
      "AWS Direct Connect Partner",
      "AWS Management Console"
    ],
    "SelectA": "새로운 1 Gbps Direct Connect 연결을 설정하고, 다른 AWS 계정과 공유합니다.",
    "SelectA_Commentary": "1 Gbps 연결을 새로 만들어도 기존과 동일한 고정 비용이 발생하며, 계정 공유는 트래픽 분산이나 비용 절감 측면에서 확실치 않습니다.",
    "SelectB": "AWS Management Console에서 새 200 Mbps Direct Connect 연결을 설정합니다.",
    "SelectB_Commentary": "직접 구성 가능한 Dedicated Connection은 최소 1 Gbps이므로, Console에서 200 Mbps 전용 연결을 설정할 수 없습니다.",
    "SelectC": "AWS Direct Connect Partner에 연락하여 1 Gbps 연결을 주문합니다. 다른 AWS 계정과 공유합니다.",
    "SelectC_Commentary": "1 Gbps 연결을 Partner를 통해 주문해도 초과 대역폭 비용이 그대로 유지되므로 비용 절감 효과가 크지 않습니다.",
    "SelectD": "AWS Direct Connect Partner에 연락하여 기존 AWS 계정에 200 Mbps Hosted Connection을 주문합니다.",
    "SelectD_Commentary": "사용률이 10% 미만이므로 200 Mbps Hosted Connection이 적절합니다. 이는 더 낮은 배포 비용과 유지 비용으로 보안에도 영향을 주지 않으며 요구 사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q240",
      "Q583",
      "Q763",
      "Q284",
      "Q525"
    ],
    "SelectA_recommedations": [
      "Q499",
      "Q300",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q499",
      "Q763",
      "Q240"
    ],
    "SelectC_recommedations": [
      "Q499",
      "Q300",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q499",
      "Q300",
      "Q763"
    ]
  },
  {
    "Question_Number": "Q500",
    "Question_Description": "한 회사는 온프레미스에 여러 Windows file servers를 운영하고 있습니다. 이 회사는 파일들을 Amazon FSx for Windows File Server 파일 시스템으로 마이그레이션하여 통합하려고 합니다. 파일 권한이 유지되어 액세스 권한이 변경되지 않도록 해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (2개를 선택하십시오)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109689-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Windows 파일 서버의 데이터를 Amazon FSx for Windows File Server로 옮기면서 기존 파일 권한(ACL)을 그대로 보존하는 방법을 찾는 것입니다. AWS DataSync는 NTFS 권한을 유지하며 직접 FSx로 전송할 수 있고, Snowcone에 DataSync를 설치해도 ACL이 보존되어 빠르고 안전하게 마이그레이션할 수 있습니다. 반면 S3 등을 경유하는 다른 방식은 권한 손실 위험이 있으므로 부적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "마이그레이션",
      "파일 권한 유지",
      "Amazon FSx for Windows File Server",
      "Windows file server",
      "AWS DataSync",
      "AWS Snowcone"
    ],
    "Terms": [
      "Amazon FSx for Windows File Server",
      "Windows file server",
      "AWS DataSync",
      "AWS CLI",
      "Amazon S3",
      "AWS Snowcone",
      "AWS Snowball Edge"
    ],
    "SelectA": "온프레미스에 AWS DataSync agents를 배포합니다. DataSync 작업을 스케줄링하여 FSx for Windows File Server 파일 시스템으로 데이터를 전송합니다.",
    "SelectA_Commentary": "AWS DataSync를 통해 직접 FSx에 데이터를 업로드하면 Windows 파일 권한이 유지됩니다. 단일 작업으로 마이그레이션과 권한 이전을 간단히 수행 가능합니다.",
    "SelectB": "각 file server의 공유 데이터를 AWS CLI를 사용해 Amazon S3 버킷으로 복사합니다. DataSync 작업을 스케줄링하여 FSx for Windows File Server 파일 시스템으로 데이터를 전송합니다.",
    "SelectB_Commentary": "S3로 먼저 전송하는 방식은 NTFS 권한이 손실될 수 있어 파일 권한 보장 요구사항을 충족하지 못합니다.",
    "SelectC": "각 file server에서 드라이브를 제거합니다. 드라이브를 AWS로 배송하여 Amazon S3로 가져옵니다. DataSync 작업을 스케줄링하여 FSx for Windows File Server 파일 시스템으로 데이터를 전송합니다.",
    "SelectC_Commentary": "드라이브 발송 후 S3로 복사 시 NTFS 권한이 그대로 유지되기 어렵고, 절차가 복잡하여 요구사항과 맞지 않습니다.",
    "SelectD": "AWS Snowcone device를 주문합니다. 디바이스를 온프레미스 네트워크에 연결합니다. AWS DataSync agents를 디바이스에서 실행합니다. DataSync 작업을 스케줄링하여 FSx for Windows File Server 파일 시스템으로 데이터를 전송합니다.",
    "SelectD_Commentary": "Snowcone에 DataSync를 설치해 직접 FSx로 전송하면 파일 시스템 권한이 유지됩니다. 소규모 데이터 마이그레이션에 적합한 간단하고 안전한 방법입니다.",
    "SelectE": "AWS Snowball Edge Storage Optimized device를 주문합니다. 디바이스를 온프레미스 네트워크에 연결합니다. AWS CLI를 사용해 데이터를 디바이스로 복사합니다. 디바이스를 다시 AWS로 배송하여 Amazon S3로 데이터를 가져옵니다. DataSync 작업을 스케줄링하여 FSx for Windows File Server 파일 시스템으로 데이터를 전송합니다.",
    "SelectE_Commentary": "일단 S3로 가져온 뒤 다시 FSx로 옮겨야 하므로 파일 권한이 제대로 유지되지 않을 수 있고, 절차도 복잡합니다.",
    "Question_Description_recommedations": [
      "Q260",
      "Q901",
      "Q970",
      "Q529",
      "Q965"
    ],
    "SelectA_recommedations": [
      "Q500",
      "Q260",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q500",
      "Q260",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q500",
      "Q260",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q500",
      "Q260",
      "Q965"
    ],
    "SelectE_recommedations": [
      "Q500",
      "Q965",
      "Q260"
    ]
  },
  {
    "Question_Number": "Q501",
    "Question_Description": "한 회사가 고객 결제 데이터를 Amazon S3의 데이터 레이크에 수집하려고 합니다. 평균적으로 매 분마다 결제 데이터를 수신하고 있으며, 이를 실시간으로 분석한 뒤 데이터 레이크에 적재하고자 합니다. 가장 운영 효율성이 높은 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109421-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 결제 데이터를 실시간으로 분석하고 쉽게 데이터 레이크에 적재하는 방법을 묻습니다. Kinesis Data Firehose는 설정에 따라 최소 60초의 버퍼를 갖지만, 자동으로 S3에 적재하며 관리 부담이 적습니다. Kinesis Data Analytics와 연동하면 가동 중단 없이 실시간 처리 가능하므로 운영 효율성이 높습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "결제 데이터",
      "실시간 분석",
      "데이터 레이크",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "AWS Lambda",
      "AWS Glue",
      "Amazon Kinesis Data Analytics",
      "Amazon Kinesis Data Firehose",
      "Amazon API Gateway"
    ],
    "SelectA": "Amazon Kinesis Data Streams를 사용해 데이터를 수집하고, AWS Lambda로 실시간 분석을 수행합니다.",
    "SelectA_Commentary": "실시간 수집이 가능하지만 Kinesis Data Streams의 샤드 관리가 필요해 운영 부담이 상대적으로 큽니다.",
    "SelectB": "AWS Glue를 사용해 데이터를 수집하고, Amazon Kinesis Data Analytics로 실시간 분석을 수행합니다.",
    "SelectB_Commentary": "AWS Glue는 배치 중심의 ETL 서비스이므로 매분 단위의 실시간 처리 요구에 적합하지 않습니다.",
    "SelectC": "Amazon Kinesis Data Firehose를 사용해 데이터를 수집하고, Amazon Kinesis Data Analytics로 실시간 분석을 수행합니다.",
    "SelectC_Commentary": "Kinesis Data Firehose는 자동 확장과 S3 적재를 제공하며, Kinesis Data Analytics로 실시간 분석까지 함께 구현해 운영이 가장 간단합니다.",
    "SelectD": "Amazon API Gateway로 데이터를 수집하고, AWS Lambda로 실시간 분석을 수행합니다.",
    "SelectD_Commentary": "API Gateway는 이벤트 기반 처리용으로 적합하지만 스트리밍 처리를 위한 가장 효율적인 방식은 아닙니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q43",
      "Q672",
      "Q173",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q361",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q603",
      "Q33"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q402",
      "Q557"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q502",
    "Question_Description": "한 회사가 Amazon EC2 위에서 동작하는 콘텐츠 관리 시스템(CMS)을 사용하여 웹사이트를 운영하고 있습니다. 이 CMS는 데이터 계층으로 Amazon Aurora MySQL Multi-AZ DB instance를 사용하고 있습니다. 웹사이트 이미지는 단일 EC2 인스턴스 내부에 마운트된 Amazon EBS 볼륨에 저장되어 있습니다. 웹사이트의 성능과 복원력을 개선하기 위해 솔루션스 아키텍트가 취해야 할 조치 조합은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109420-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 EC2 인스턴스와 EBS에 의존하던 웹사이트 환경을 좀 더 탄력적이고 고성능으로 전환하기 위해 공유 스토리지와 확장 가능한 아키텍처 도입을 묻는 것입니다. Amazon EFS를 사용하면 여러 인스턴스에서 동시에 접근 가능한 스토리지를 구성할 수 있고, Auto Scaling group 뒤에 Application Load Balancer를 구성하면 트래픽 증가 시 인스턴스가 자동으로 확장되어 복원력과 성능 모두가 향상됩니다. 추가로 Amazon CloudFront를 통해 전 세계적으로 빠른 콘텐츠 전송이 가능해집니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "CMS",
      "Amazon Aurora MySQL Multi-AZ DB instance",
      "Amazon EBS 볼륨",
      "성능 개선",
      "복원력",
      "Amazon EFS",
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Aurora MySQL Multi-AZ",
      "Amazon EBS",
      "Amazon S3",
      "NFS",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon Machine Image (AMI)",
      "Application Load Balancer",
      "Auto Scaling group",
      "AWS Global Accelerator",
      "Amazon CloudFront"
    ],
    "SelectA": "웹사이트 이미지를 모든 EC2 인스턴스에 마운트된 Amazon S3 버킷으로 이동합니다.",
    "SelectA_Commentary": "S3 버킷을 직접 마운트하는 것은 일반적으로 권장되지 않으며, 실시간 파일 시스템처럼 쓰기/읽기하는 데 한계가 있어 적합하지 않습니다.",
    "SelectB": "주요 EC2 인스턴스에서 NFS 공유를 설정하여 웹사이트 이미지를 공유하고, 다른 EC2 인스턴스에서 이를 마운트합니다.",
    "SelectB_Commentary": "기존 인스턴스에 의존하는 NFS 구성은 단일 장애 지점(SPOF)이 되며, 복원력이 떨어지는 해결책입니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS)에 웹사이트 이미지를 저장하고, 모든 EC2 인스턴스에서 이를 마운트합니다.",
    "SelectC_Commentary": "EFS는 다중 인스턴스가 동시에 접근 가능한 공유 스토리지를 제공해 확장성과 가용성을 높입니다.",
    "SelectD": "기존 EC2 인스턴스로부터 AMI를 생성하고, 해당 AMI를 사용해 Auto Scaling group 내 Application Load Balancer 뒤에서 새로운 인스턴스를 프로비저닝합니다. 최소 2개의 인스턴스를 유지하도록 Auto Scaling group을 설정합니다. 웹사이트를 위해 AWS Global Accelerator에서 Accelerator를 구성합니다.",
    "SelectD_Commentary": "Global Accelerator는 전역적으로 트래픽을 최적화하지만, 이미지 스토리지 문제(단일 EBS 의존)를 근본적으로 해소하지 못하므로 완전한 해결책이 되지 않습니다.",
    "SelectE": "기존 EC2 인스턴스로부터 AMI를 생성하고, 해당 AMI를 사용해 Auto Scaling group 내 Application Load Balancer 뒤에서 새로운 인스턴스를 프로비저닝합니다. 최소 2개의 인스턴스를 유지하도록 Auto Scaling group을 설정합니다. 웹사이트를 위해 Amazon CloudFront 배포를 구성합니다.",
    "SelectE_Commentary": "CloudFront는 전 세계적으로 콘텐츠 전송 속도를 높이고, Auto Scaling group과 함께 복원력 및 성능을 동시에 강화하는 핵심 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q879",
      "Q462",
      "Q824",
      "Q125",
      "Q935"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q110",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q244",
      "Q584",
      "Q757"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q602"
    ],
    "SelectD_recommedations": [
      "Q405",
      "Q275",
      "Q69"
    ],
    "SelectE_recommedations": [
      "Q405",
      "Q275",
      "Q69"
    ]
  },
  {
    "Question_Number": "Q503",
    "Question_Description": "한 회사가 Infrastructure Monitoring 서비스를 운영하고 있습니다. 이 회사는 새 기능을 개발 중이며, 이 기능은 고객의 AWS 계정에서 데이터를 모니터링할 수 있도록 해줍니다. 새 기능은 고객 계정에서 AWS APIs를 호출하여 Amazon EC2 인스턴스 정보를 확인하고 Amazon CloudWatch 지표를 조회하려고 합니다. 가장 안전한(MOST secure) 방식으로 고객 계정에 대한 액세스를 제공하려면 어떻게 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109595-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고객 계정에 안전하게 접근하기 위한 방법을 묻고 있습니다. Cross-account Access 구조에서 고객이 직접 IAM role을 생성하고, 필요한 권한과 신뢰 정책을 설정해두면, 모니터링 업체는 임시로 해당 role을 Assume하여 제한된 권한만 행사할 수 있습니다. 이는 원본 계정의 장기 액세스 키를 저장할 필요가 없고, 꼭 필요한 권한만 부여하므로 보안과 편의성을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "가장 안전한 방식",
      "Infrastructure Monitoring",
      "고객 AWS 계정 접근",
      "Amazon EC2",
      "Amazon CloudWatch",
      "cross-account access",
      "IAM role",
      "read-only"
    ],
    "Terms": [
      "IAM role",
      "AWS APIs",
      "Amazon EC2",
      "Amazon CloudWatch",
      "read-only EC2 and CloudWatch permissions",
      "trust policy",
      "Token Vending Machine",
      "IAM user",
      "access key",
      "secret key",
      "Amazon Cognito",
      "secrets management system"
    ],
    "SelectA": "고객이 IAM role을 생성하고, EC2 및 CloudWatch에 대해 read-only 권한과 회사 계정을 신뢰(Trust)하도록 구성합니다.",
    "SelectA_Commentary": "Cross-account 역할을 통해 임시 권한만 사용하므로 가장 안전하고 권장되는 접근 방식입니다. 고객 키를 저장하지 않아도 되고 필요 권한 이상을 부여하지 않습니다.",
    "SelectB": "Serverless API로 Token Vending Machine을 구현해 read-only 권한을 지닌 역할의 임시 AWS 자격 증명을 발급합니다.",
    "SelectB_Commentary": "Token Vending Machine 구성은 복잡하며 고객 계정에 대한 직접적인 역할 신뢰 설정보다 안전성이 떨어질 수 있습니다.",
    "SelectC": "고객이 EC2와 CloudWatch에 대해 read-only 권한을 가진 IAM user를 생성하고, 해당 액세스 키와 시크릿 키를 암호화하여 보관합니다.",
    "SelectC_Commentary": "고객의 장기 자격 증명을 저장하는 방식이라서 키 노출 위험이 크며 필요 이상으로 권한이 유지될 수 있습니다.",
    "SelectD": "고객이 Amazon Cognito user를 생성하여 read-only 권한을 갖는 IAM role을 사용하도록 하고, Cognito 자격과 비밀번호를 암호화하여 보관합니다.",
    "SelectD_Commentary": "Cognito 사용자는 주로 애플리케이션 사용자 관리에 적합하며, 모니터링용으로 이 방식을 쓰면 절차와 관리가 더 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q27",
      "Q34",
      "Q949",
      "Q37",
      "Q748"
    ],
    "SelectA_recommedations": [
      "Q476",
      "Q494",
      "Q780"
    ],
    "SelectB_recommedations": [
      "Q159",
      "Q871",
      "Q34"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q233",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q200",
      "Q745"
    ]
  },
  {
    "Question_Number": "Q504",
    "Question_Description": "한 회사는 us-east-1 리전에 있는 여러 VPC를 수백 개의 AWS 계정에 걸쳐 연결해야 합니다. 회사의 네트워킹 팀은 클라우드 네트워크를 관리하기 위해 자체 AWS 계정을 보유하고 있습니다. 이 VPC들을 연결하기 위한 가장 운영 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109690-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 VPC와 계정을 가장 단순하고 효율적으로 연결하는 방안을 묻습니다. AWS Transit Gateway는 허브 앤 스포크 방식으로 VPC 연결을 중앙화해 운영 복잡성을 낮추며 확장성도 뛰어납니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "여러 VPC",
      "us-east-1 리전",
      "수백 개의 AWS 계정",
      "AWS Transit Gateway",
      "운영 효율",
      "허브 앤 스포크"
    ],
    "Terms": [
      "VPC peering",
      "AWS Transit Gateway",
      "NAT Gateway",
      "Internet Gateway",
      "VPN Gateway",
      "Transit VPC",
      "Hub-and-spoke model",
      "Peer-to-peer model"
    ],
    "SelectA": "각 VPC 간에 VPC peering 연결을 설정합니다. 각 연관된 서브넷의 라우트 테이블을 업데이트합니다.",
    "SelectA_Commentary": "VPC 간 일대일 피어링을 모두 설정해야 하므로, 수많은 계정에 대해 유지보수가 매우 복잡합니다.",
    "SelectB": "각 VPC에 NAT Gateway와 Internet Gateway를 구성하여 인터넷을 통해 각 VPC를 연결합니다.",
    "SelectB_Commentary": "인터넷 경유는 보안 및 비용 측면에서 비효율적이며 운영 복잡성과 연계 비용이 증가합니다.",
    "SelectC": "네트워킹 팀의 AWS 계정에 AWS Transit Gateway를 생성합니다. 각 VPC에서 정적 라우트를 구성합니다.",
    "SelectC_Commentary": "AWS Transit Gateway는 허브 앤 스포크 방식으로 여러 VPC를 중앙에서 효율적으로 연결해 가장 운영 효율이 높습니다.",
    "SelectD": "각 VPC에 VPN Gateway를 배포합니다. 네트워킹 팀의 AWS 계정에 transit VPC를 만들어 각 VPC에 연결합니다.",
    "SelectD_Commentary": "VPN Gateway와 transit VPC는 추가 인프라 구성과 관리가 필요하여 복잡도와 운영 부담이 증가합니다.",
    "Question_Description_recommedations": [
      "Q439",
      "Q237",
      "Q570",
      "Q621",
      "Q899"
    ],
    "SelectA_recommedations": [
      "Q439",
      "Q487",
      "Q504"
    ],
    "SelectB_recommedations": [
      "Q708",
      "Q230",
      "Q487"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q504",
      "Q487"
    ],
    "SelectD_recommedations": [
      "Q487",
      "Q504",
      "Q722"
    ]
  },
  {
    "Question_Number": "Q505",
    "Question_Description": "한 회사가 야간에 데이터 처리 배치 작업을 실행하는 Amazon EC2 인스턴스를 보유하고 있습니다. EC2 인스턴스는 On-Demand 요금을 사용하는 Auto Scaling 그룹에서 실행됩니다. 어떤 인스턴스에서 작업이 실패하면 다른 인스턴스가 해당 작업을 재처리합니다. 이 배치 작업은 매일 자정부터 오전 6시(현지 시간)까지 실행됩니다. 이 요구사항을 가장 비용 효율적으로 충족시키는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109691-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 정해진 시간에만 구동되는 배치 작업 환경에서 EC2 인스턴스 비용을 최소화하고자 하는 시나리오입니다. On-Demand 요금을 계속 이용하기에는 사용 시간이 한정되어 있어 비용 효율이 떨어집니다. Savings Plan 혹은 Reserved Instance는 장기 사용에 적합하지만, 일정 시간에만 운영되는 배치 작업에는 불필요한 고정비용이 생길 수 있습니다. Spot Instances는 저렴한 요금으로 인스턴스를 활용할 수 있고, 작업 실패 시 재시도 구조로 위험을 완화하며, 일정 시간만 구동되는 배치 처리를 매우 비용 효율적으로 수행하는 해결책이 됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Auto Scaling 그룹",
      "On-Demand",
      "Spot Instances",
      "야간 배치 작업",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "On-Demand billing",
      "Savings Plan",
      "Reserved Instance",
      "Spot Instances",
      "CPU usage"
    ],
    "SelectA": "배치 작업에 사용하는 Auto Scaling 그룹의 인스턴스 패밀리를 대상으로 1년짜리 Amazon EC2 Savings Plan을 구매합니다.",
    "SelectA_Commentary": "Savings Plan은 장기적으로 인스턴스를 꾸준히 사용해야 절감 효과가 큽니다. 배치 작업처럼 특정 시간대에만 사용하는 경우에는 효율이 떨어질 수 있습니다.",
    "SelectB": "배치 작업에 사용하는 Auto Scaling 그룹의 특정 인스턴스 유형과 운영 체제를 대상으로 1년짜리 Reserved Instance를 구매합니다.",
    "SelectB_Commentary": "Reserved Instance 역시 상시 운영 환경에 적합합니다. 배치 작업은 제한된 시간대를 활용하므로, 사용량 변동이 큰 환경에는 불필요한 고정 지출이 생깁니다.",
    "SelectC": "Auto Scaling 그룹을 위한 새로운 시작 템플릿을 생성하고 인스턴스를 Spot Instances로 설정합니다. CPU 사용률에 기반한 정책을 설정하여 스케일 아웃하도록 합니다.",
    "SelectC_Commentary": "Spot Instances는 유연성 있는 사용 패턴에 매우 저렴한 비용으로 인스턴스를 확보할 수 있는 옵션입니다. 배치 작업이 실패해도 재처리가 가능해, 비용 대비 효율이 높습니다.",
    "SelectD": "Auto Scaling 그룹을 위한 새로운 시작 템플릿을 생성하고 인스턴스 크기를 늘립니다. CPU 사용률에 기반한 정책을 설정하여 스케일 아웃하도록 합니다.",
    "SelectD_Commentary": "인스턴스 크기를 키우면 처리량은 늘어날 수 있지만 On-Demand 비용이 전체적으로 상승합니다. 이는 비용 효율적이지 않으며, 오히려 Spot Instances가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q552",
      "Q24",
      "Q347",
      "Q671",
      "Q1008"
    ],
    "SelectA_recommedations": [
      "Q505",
      "Q552",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q943",
      "Q505"
    ],
    "SelectC_recommedations": [
      "Q505",
      "Q1013",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q505",
      "Q728",
      "Q284"
    ]
  },
  {
    "Question_Number": "Q506",
    "Question_Description": "한 소셜 미디어 회사에서 웹사이트에 새 기능을 개발 중입니다. 이 기능은 사용자가 사진을 업로드할 수 있도록 해줍니다. 회사는 대형 이벤트 기간 동안 수요가 크게 증가할 것으로 예상하며, 웹사이트가 사용자들의 업로드 트래픽을 처리할 수 있도록 해야 합니다. 가장 확장성이 뛰어난 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109692-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 갑작스러운 업로드 트래픽 급증에 대비하여 가장 확장성이 우수하고 애플리케이션 서버 부하를 최소화하는 방법을 묻습니다. 정답인 Amazon S3 presigned URL을 사용하면 사용자가 애플리케이션 서버를 거치지 않고 직접 S3에 업로드하여 대규모 트래픽도 효율적으로 처리할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "소셜 미디어",
      "사진 업로드",
      "확장성",
      "사용자 직접 업로드",
      "Amazon S3 Presigned URL"
    ],
    "Terms": [
      "Amazon S3",
      "Presigned URL",
      "AWS Storage Gateway",
      "Amazon Elastic File System(Amazon EFS)"
    ],
    "SelectA": "사용자의 브라우저에서 애플리케이션 서버로 파일을 업로드한 후 해당 파일을 Amazon S3 버킷으로 전송합니다.",
    "SelectA_Commentary": "애플리케이션 서버가 트래픽을 모두 처리해야 하므로 서버 부하가 매우 커져 확장성이 떨어집니다.",
    "SelectB": "AWS Storage Gateway(file gateway)를 프로비저닝하고, 사용자의 브라우저에서 이 게이트웨이로 직접 파일을 업로드합니다.",
    "SelectB_Commentary": "Storage Gateway는 온프레미스와 연동하거나 파일 서버 환경에 적합하며, 고도로 확장된 대규모 웹 업로드에는 적합하지 않습니다.",
    "SelectC": "애플리케이션에서 Amazon S3 presigned URL을 생성하고, 사용자의 브라우저가 해당 URL을 통해 S3 버킷에 직접 파일을 업로드하게 합니다.",
    "SelectC_Commentary": "사용자가 직접 S3에 업로드하므로 애플리케이션 서버 부하가 크게 감소하고, 확장성 향상에 가장 유리한 솔루션입니다.",
    "SelectD": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 프로비저닝하고, 사용자의 브라우저에서 파일 시스템으로 직접 파일을 업로드합니다.",
    "SelectD_Commentary": "EFS는 파일 스토리지 서비스로서 서버를 거쳐야 하고 웹 브라우저에서 직접 업로드하기에는 구조가 복잡해 확장성 측면에서 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q132",
      "Q915",
      "Q888",
      "Q158",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q626",
      "Q43"
    ],
    "SelectB_recommedations": [
      "Q620",
      "Q361",
      "Q305"
    ],
    "SelectC_recommedations": [
      "Q672",
      "Q501",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q695",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q507",
    "Question_Description": "한 회사는 여행 티케팅을 위한 웹 애플리케이션을 보유하고 있습니다. 이 애플리케이션은 North America의 단일 데이터 센터에서 실행되는 데이터베이스를 기반으로 합니다. 회사는 글로벌 사용자 기반을 지원하기 위해 여러 AWS Region에 애플리케이션을 배포해야 하며, 예약(Reservation) 데이터베이스 업데이트 지연 시간을 1초 미만으로 유지해야 합니다. 또한 각 Region마다 별도의 웹 플랫폼을 배포하면서도 전 세계적으로 일관된 단일 Primary Reservation Database를 유지해야 합니다. 이 요구사항을 충족하기 위해 Solutions Architect가 권장해야 할 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109608-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 글로벌 규모로 웹 애플리케이션을 확장하면서 예약 데이터베이스 업데이트 시 1초 미만의 지연 및 전 세계적 일관성을 유지해야 하는 상황을 다룹니다. 여러 Region에 배포된 웹 플랫폼에서도 단일 Primary Database를 유지하려면 빠르고 자동화된 글로벌 복제 기능이 필수적입니다. Amazon DynamoDB의 Global Table은 멀티 리전에 걸쳐 동기화된 데이터를 제공하고, 고성능 쓰기·읽기를 지원하여 전 세계 사용자를 위한 지연 시간 단축과 일관된 업데이트를 보장하므로 최적의 해법이 됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "글로벌 사용자",
      "여러 AWS Region",
      "1초 미만 지연",
      "단일 Primary Reservation Database",
      "글로벌 일관성",
      "Amazon DynamoDB Global Table"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Global Table",
      "Amazon Aurora MySQL",
      "Aurora Read Replica",
      "Amazon RDS for MySQL",
      "MySQL Read Replica",
      "Amazon Aurora Serverless",
      "AWS Lambda"
    ],
    "SelectA": "애플리케이션을 Amazon DynamoDB로 전환하고, 중앙 Reservation Table에 대해 Global Table을 사용합니다. 각 Region 배포에서 해당 Region Endpoint를 사용합니다.",
    "SelectA_Commentary": "DynamoDB Global Table은 다중 Region 간 실시간 글로벌 동기화가 가능하고 1초 미만의 지연을 달성하기 쉬워 단일 Primary Reservation Database 요건에 가장 부합합니다.",
    "SelectB": "데이터베이스를 Amazon Aurora MySQL로 마이그레이션합니다. 각 Region에 Aurora Read Replica를 배포합니다. 각 Region 배포에서 올바른 Regional Endpoint를 사용하여 데이터베이스에 액세스합니다.",
    "SelectB_Commentary": "Aurora Read Replica는 쓰기 연산이 한 리전에 집중되어 글로벌 쓰기 지연이 발생할 수 있습니다. 한 번에 하나의 마스터만 존재하므로 실시간 글로벌 업데이트에는 적합하지 않습니다.",
    "SelectC": "데이터베이스를 Amazon RDS for MySQL로 마이그레이션하고, 각 Region에 MySQL Read Replica를 배포합니다. 각 Region 배포에서 올바른 Regional Endpoint를 사용하여 데이터베이스에 액세스합니다.",
    "SelectC_Commentary": "RDS MySQL Read Replica 역시 Aurora Read Replica와 유사하게 글로벌 쓰기 지연을 피하기 어렵고, 지연 복제로 일관성 보장이 어려워 1초 미만 지연 요건에 부합하기 어렵습니다.",
    "SelectD": "애플리케이션을 Amazon Aurora Serverless로 마이그레이션합니다. 각 Region에 데이터베이스 인스턴스를 배포합니다. AWS Lambda 함수를 사용해 각 Region의 이벤트 스트림을 처리하여 데이터베이스를 동기화합니다.",
    "SelectD_Commentary": "Lambda 이벤트 스트림을 통한 수동 동기화는 설계가 복잡하고 지연을 초래하기 쉬워 글로벌 일관성을 보장하기 어렵습니다. 자동화된 글로벌 테이블만큼 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q431",
      "Q738",
      "Q268",
      "Q686",
      "Q976"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q578",
      "Q461"
    ],
    "SelectB_recommedations": [
      "Q946",
      "Q337",
      "Q247"
    ],
    "SelectC_recommedations": [
      "Q247",
      "Q337",
      "Q389"
    ],
    "SelectD_recommedations": [
      "Q175",
      "Q603",
      "Q686"
    ]
  },
  {
    "Question_Number": "Q508",
    "Question_Description": "한 회사가 여러 Microsoft Windows Server 워크로드를 us-west-1 리전에서 실행 중인 Amazon EC2 인스턴스로 마이그레이션했습니다. 이 회사는 필요할 때마다 워크로드를 백업하여 Amazon Machine Image(AMI)를 수동으로 생성해 왔습니다. 만약 us-west-1 리전에서 자연재해가 발생할 경우, 회사는 us-west-2 리전에서 워크로드를 신속하게 복구하고자 합니다. 또한 EC2 인스턴스에서 24시간 이상의 데이터 손실이 발생하지 않기를 원합니다. 그리고 회사는 EC2 인스턴스 백업 자동화도 원하고 있습니다. 최소한의 관리 작업으로 위 요구 사항을 충족하려면 어떤 솔루션을 사용해야 합니까? (두 개를 고르십시오.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109530-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 재해 복구 시나리오에서 RPO(복구 시점 목표)를 24시간 내로 유지하고, EC2 인스턴스 백업을 자동화하여 신속한 복구 과정을 구현하는 방법을 묻습니다. AMI lifecycle policy나 AWS Backup을 활용해 주기적인 백업 생성과 리전 간 복사를 설정하면 최소한의 관리 부담으로 높은 가용성을 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Windows Server 워크로드",
      "us-west-1 리전",
      "us-west-2 리전",
      "데이터 손실 24시간 제한",
      "백업 자동화",
      "Amazon EC2",
      "AMI lifecycle policy",
      "AWS Backup"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Machine Image(AMI)",
      "lifecycle policy",
      "AWS Backup",
      "backup vault",
      "us-west-1 Region",
      "us-west-2 Region"
    ],
    "SelectA": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand.",
    "SelectA_Commentary": "수동으로 리전 간 복사를 해야 하므로 자동화 수준이 낮고, 재해 발생 시 신속 대응이 어려울 수 있어 비효율적입니다.",
    "SelectB": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region.",
    "SelectB_Commentary": "백업 자동화와 리전 간 복사를 동시 구성해 운영 부담을 줄이고 재해 발생 시 RPO를 만족할 수 있어 정답 중 하나입니다.",
    "SelectC": "Create backup vaults in us-west-1 and in us-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2.",
    "SelectC_Commentary": "Lambda 함수를 추가 작성하여 백업을 복제하는 방식은 설정이 복잡하고 관리가 번거로워 최소한의 관리 작업 요구사항을 충족하기 어렵습니다.",
    "SelectD": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily.",
    "SelectD_Commentary": "AWS Backup의 중앙집중식 정책으로 간편하게 백업 주기와 리전 간 복사를 자동화할 수 있어 또 다른 정답입니다.",
    "SelectE": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2.",
    "SelectE_Commentary": "온디맨드 복사는 재해 상황에서 자동화 대비 빠른 대응이 어렵고, 관리 부담이 더 큽니다.",
    "Question_Description_recommedations": [
      "Q186",
      "Q570",
      "Q892",
      "Q762",
      "Q224"
    ],
    "SelectA_recommedations": [
      "Q762",
      "Q963",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q508",
      "Q224",
      "Q762"
    ],
    "SelectC_recommedations": [
      "Q570",
      "Q621",
      "Q874"
    ],
    "SelectD_recommedations": [
      "Q224",
      "Q48",
      "Q570"
    ],
    "SelectE_recommedations": [
      "Q48",
      "Q224",
      "Q570"
    ]
  },
  {
    "Question_Number": "Q509",
    "Question_Description": "한 회사가 이미지 처리를 위한 2티어 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 두 개의 Availability Zone을 사용하며, 각 AZ에는 하나의 public subnet과 하나의 private subnet이 있습니다. 웹 티어를 위한 Application Load Balancer (ALB)는 public subnet을 사용하고, 애플리케이션 티어를 위한 Amazon EC2 인스턴스는 private subnet을 사용합니다. 사용자는 애플리케이션이 예상보다 느려졌다고 보고합니다. 웹 서버 로그 파일 보안 감사 결과, 소수의 IP 주소로부터 수백만 건의 불법 요청이 들어오고 있는 것으로 확인되었습니다. 회사가 보다 영구적인 솔루션을 조사하는 동안, 솔루션스 아키텍트는 즉각적인 성능 문제를 해결해야 합니다. 이러한 요구사항을 충족하기 위해 어떤 조치를 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109531-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 티어에서 발생하는 대규모 불법 요청을 효율적으로 차단하여 즉각적인 성능 문제를 해결하는 것이 핵심입니다. Security Group은 명시적 deny 설정이 불가능하므로, inbound deny rule을 적용할 수 있는 network ACL을 사용해야 합니다. 또한, 웹 티어에 위치한 public subnet에서 직접 트래픽을 거부함으로써 애플리케이션 티어 자원 사용을 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "2티어 애플리케이션",
      "이미지 처리",
      "성능 문제",
      "불법 요청",
      "IP 주소 차단",
      "network ACL"
    ],
    "Terms": [
      "Availability Zone",
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "public subnet",
      "private subnet",
      "security group",
      "network ACL"
    ],
    "SelectA": "웹 티어의 inbound security group을 수정하고, 리소스를 소모하는 IP 주소에 대해 deny rule을 추가합니다.",
    "SelectA_Commentary": "Security Group은 트래픽을 명시적으로 거부(deny)하기 위한 규칙을 설정할 수 없습니다. 오직 allow 규칙만 가능하므로 적절하지 않습니다.",
    "SelectB": "웹 티어 서브넷에 대한 network ACL을 수정하고, 리소스를 소모하는 IP 주소에 대한 inbound deny rule을 추가합니다.",
    "SelectB_Commentary": "network ACL은 트래픽을 명시적으로 거부할 수 있는 stateless 제어 기능을 제공합니다. 웹 티어의 public subnet에 deny rule을 걸어 불법 요청을 즉각 차단하는 최적의 방법입니다.",
    "SelectC": "애플리케이션 티어의 inbound security group을 수정하고, 리소스를 소모하는 IP 주소에 대해 deny rule을 추가합니다.",
    "SelectC_Commentary": "Security Group에는 거부 규칙을 설정할 수 없으며, 애플리케이션 티어가 아닌 웹 티어에서 트래픽을 미리 차단해야 가장 효과적입니다.",
    "SelectD": "애플리케이션 티어 서브넷에 대한 network ACL을 수정하고, 리소스를 소모하는 IP 주소에 대한 inbound deny rule을 추가합니다.",
    "SelectD_Commentary": "트래픽을 애플리케이션 티어까지 전달한 뒤 차단하는 것은 효율성이 떨어집니다. 불법 트래픽은 웹 티어에서 조기에 차단하는 것이 바람직합니다.",
    "Question_Description_recommedations": [
      "Q282",
      "Q608",
      "Q884",
      "Q382",
      "Q437"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q395",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q169",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q774",
      "Q395",
      "Q233"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q169",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q510",
    "Question_Description": "글로벌 마케팅 회사는 ap-southeast-2 리전과 eu-west-1 리전에서 애플리케이션을 운영하고 있습니다. eu-west-1 리전의 VPC에서 구동되는 애플리케이션이 ap-southeast-2 리전의 VPC에서 구동되는 데이터베이스와 안전하게 통신해야 합니다. 이 요건을 만족하는 네트워크 설계는 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109708-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 리전에 위치한 VPC 간에 안전한 통신을 설정하는 방법을 묻습니다. 다른 Region의 Security Group ID는 직접 참조할 수 없으므로 CIDR block 또는 IP 주소를 사용해 Inbound Rule을 구성해야 합니다. 따라서 직접 IP 주소 범위를 허용하는 VPC Peering 연결 설정이 필요하며, 그 점 때문에 C가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "글로벌 마케팅 회사",
      "ap-southeast-2 리전",
      "eu-west-1 리전",
      "VPC Peering 연결",
      "서브넷 라우트 테이블",
      "인바운드 규칙"
    ],
    "Terms": [
      "VPC Peering",
      "Security Group",
      "Inbound Rule",
      "Transit Gateway",
      "CIDR block",
      "Subnet Route Tables"
    ],
    "SelectA": "eu-west-1 VPC와 ap-southeast-2 VPC 간에 VPC peering 연결을 생성합니다. eu-west-1 애플리케이션 Security Group에 ap-southeast-2 보안 그룹 IP 주소를 허용하는 인바운드 규칙을 만듭니다.",
    "SelectA_Commentary": "상대 리전 Security Group을 직접 참조하려고 시도하므로 불가능합니다. 또한 인바운드 규칙 위치가 잘못 설정되어 효과적인 통신 구성이 어렵습니다.",
    "SelectB": "ap-southeast-2 VPC와 eu-west-1 VPC 간에 VPC peering 연결을 설정하고 서브넷 라우트 테이블을 업데이트합니다. ap-southeast-2 데이터베이스 보안 그룹에 eu-west-1 애플리케이션 서버 Security Group ID를 참조하는 인바운드 규칙을 추가합니다.",
    "SelectB_Commentary": "跨리전(크로스리전) 보안 그룹 참조는 지원되지 않습니다. 다른 리전의 Security Group ID를 직접 참조할 수 없으므로 이 설정은 올바르지 않습니다.",
    "SelectC": "ap-southeast-2 VPC와 eu-west-1 VPC 간에 VPC peering 연결을 구성하고 서브넷 라우트 테이블을 업데이트합니다. ap-southeast-2 데이터베이스 보안 그룹에 eu-west-1 애플리케이션 서버 IP 주소를 허용하는 인바운드 규칙을 만듭니다.",
    "SelectC_Commentary": "보안 그룹 ID 대신 IP 주소(CIDR block)로 접근을 허용해 올바른 크로스리전 연결을 구성한 정답입니다. 네트워크 라우팅과 보안 설정 모두 충족합니다.",
    "SelectD": "eu-west-1 VPC와 ap-southeast-2 VPC 간에 Transit Gateway를 생성하고 Peering Attachment를 구성합니다. 라우팅을 마친 후 eu-west-1 애플리케이션 서버 Security Group ID를 데이터베이스 보안 그룹 인바운드 규칙에 참조합니다.",
    "SelectD_Commentary": "Transit Gateway를 사용하는 것은 구현이 복잡하고, 여전히 다른 리전 Security Group ID를 직접 참조할 수 없다는 제약이 해결되지 않아 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q151",
      "Q950",
      "Q893",
      "Q370",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q510",
      "Q151",
      "Q231"
    ],
    "SelectB_recommedations": [
      "Q510",
      "Q151",
      "Q419"
    ],
    "SelectC_recommedations": [
      "Q510",
      "Q151",
      "Q231"
    ],
    "SelectD_recommedations": [
      "Q510",
      "Q151",
      "Q74"
    ]
  },
  {
    "Question_Number": "Q511",
    "Question_Description": "한 회사가 PostgreSQL 데이터베이스 스키마를 사용하는 소프트웨어를 개발 중입니다. 이 회사는 여러 개발 환경과 개발자용 데이터베이스를 구성해야 합니다. 평균적으로 각 개발 환경은 8시간 근무시간의 절반 정도인 4시간 동안 사용됩니다. 이 요구사항을 만족하면서 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109532-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 주로 부분적인 사용 시간(하루 평균 4시간) 동안만 활성화되는 개발 환경의 데이터베이스 비용을 최소화하는 방법을 묻고 있습니다. Amazon Aurora On-Demand PostgreSQL-Compatible은 사용 시간에 따른 종량제 모델로, 장시간 프로비저닝이 필요 없는 개발 환경에 가장 적합합니다. 따라서 사용량에 맞춰 과금되어, 비활성 시간 비용을 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "개발 환경",
      "PostgreSQL",
      "비용 효율적",
      "Amazon Aurora On-Demand",
      "Amazon RDS for PostgreSQL"
    ],
    "Terms": [
      "PostgreSQL database schema",
      "Amazon Aurora PostgreSQL",
      "Amazon RDS for PostgreSQL Single-AZ",
      "Amazon Aurora On-Demand PostgreSQL-Compatible",
      "Amazon S3 Object Select"
    ],
    "SelectA": "각 개발 환경마다 별도의 Amazon Aurora PostgreSQL 데이터베이스를 구성합니다.",
    "SelectA_Commentary": "Aurora 프로비저닝 모드는 항상 인프라가 실행 상태로 있기 때문에, 실제 사용 시간이 짧은 개발 환경에는 상대적으로 비용이 높아집니다.",
    "SelectB": "각 개발 환경마다 별도의 Amazon RDS for PostgreSQL Single-AZ DB 인스턴스를 구성합니다.",
    "SelectB_Commentary": "RDS 단일 AZ 구성이며 표준 프로비저닝 방식으로, 실제 사용 시간 외에도 인스턴스 비용이 계속 청구되어 비용 효율성이 떨어질 수 있습니다.",
    "SelectC": "각 개발 환경마다 별도의 Amazon Aurora On-Demand PostgreSQL-Compatible 데이터베이스를 구성합니다.",
    "SelectC_Commentary": "실제 사용 시간에 대해서만 종량제를 적용하므로, 사용량이 적은 개발 환경에서 매우 비용 효율적인 해법입니다.",
    "SelectD": "각 개발 환경마다 Amazon S3 버킷을 사용하고 Amazon S3 Object Select를 구성합니다.",
    "SelectD_Commentary": "S3는 객체 스토리지 서비스이므로 관계형 쿼리에 적합하지 않으며, PostgreSQL 스키마를 대체하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q851",
      "Q411",
      "Q436",
      "Q79",
      "Q670"
    ],
    "SelectA_recommedations": [
      "Q827",
      "Q436",
      "Q449"
    ],
    "SelectB_recommedations": [
      "Q579",
      "Q436",
      "Q940"
    ],
    "SelectC_recommedations": [
      "Q827",
      "Q436",
      "Q449"
    ],
    "SelectD_recommedations": [
      "Q469",
      "Q829",
      "Q769"
    ]
  },
  {
    "Question_Number": "Q512",
    "Question_Description": "한 회사가 AWS Organizations를 사용하여 계정별로 태깅된 리소스를 운영 중이며, AWS Backup을 사용해 AWS 인프라 리소스를 백업하고 있습니다. 회사는 모든 AWS 리소스를 백업해야 하며, 이 과정을 최소한의 운영 오버헤드로 달성하려고 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109709-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "모든 AWS 리소스를 백업하기 위해선 중복 작업 없이 손쉽게 백업 범위를 자동화할 수 있어야 합니다. AWS Config를 사용해 태그가 누락된 리소스를 확인하고, 필요한 백업 태그를 추가해 백업 플랜에서 태그 기준으로 백업 대상을 지정하면 운영 오버헤드를 최소화하면서 원하는 리소스를 확실히 백업할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "AWS Organizations",
      "AWS Backup",
      "AWS Config",
      "백업 태그",
      "백업 플랜",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS Backup",
      "AWS Config",
      "Amazon Inspector",
      "backup vault",
      "tag",
      "backup plan"
    ],
    "SelectA": "AWS Config를 사용하여 태그가 누락된 리소스를 식별하고, 식별된 리소스에 태그를 프로그래밍 방식으로 할당합니다. 그리고 이 태그를 백업 플랜에서 사용합니다.",
    "SelectA_Commentary": "AWS Config와 태그를 활용해 필요한 리소스만 정확히 백업 대상으로 포함함으로써 운영 오버헤드를 최소화합니다. 자동화된 태그 부여로 백업 누락 가능성을 줄입니다.",
    "SelectB": "AWS Config를 사용하여 동작하지 않고 있는 리소스를 식별합니다. 해당 리소스를 backup vault에 추가합니다.",
    "SelectB_Commentary": "실행 중이 아닌 리소스를 찾는 방식은 모든 리소스를 백업하는 목적에 부합하지 않고, 동작 여부가 백업 대상 선정 기준으로 적절하지 않아 제한적입니다.",
    "SelectC": "모든 AWS 계정 소유자가 각 리소스를 직접 검토하여 백업 대상이 될 리소스를 식별하도록 요구합니다.",
    "SelectC_Commentary": "수동 검토 방식이므로 운영 오버헤드가 크게 증가하고, 백업 누락이나 실수가 발생할 수 있어 대규모 환경에서는 비효율적입니다.",
    "SelectD": "Amazon Inspector를 사용하여 규정을 준수하지 않는 리소스를 식별합니다.",
    "SelectD_Commentary": "Amazon Inspector는 주로 보안 취약성과 컴플라이언스 점검을 위한 서비스로, 백업을 위한 리소스 식별에는 적절하지 않아 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q944",
      "Q843",
      "Q892",
      "Q513"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q293",
      "Q869"
    ],
    "SelectB_recommedations": [
      "Q293",
      "Q8",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q869",
      "Q8",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q615",
      "Q363",
      "Q58"
    ]
  },
  {
    "Question_Number": "Q513",
    "Question_Description": "한 소셜 미디어 회사가 AWS Cloud에 호스팅된 애플리케이션에서 사용자가 이미지를 업로드할 수 있도록 하려 합니다. 회사는 자동으로 이미지를 리사이즈하여 여러 기기 유형에 이미지를 표시할 수 있는 솔루션이 필요합니다. 이 애플리케이션은 하루 중 예측하기 어려운 트래픽 패턴을 보입니다. 회사는 고가용성을 유지하면서 확장성을 극대화할 수 있는 솔루션을 원합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109713-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 불규칙한 트래픽에도 자동 이미지 리사이즈가 가능하며 고가용성과 확장성을 모두 만족하는 구조를 설계하는 것이 핵심입니다. Amazon S3에 이미지를 업로드하면 AWS Lambda가 이벤트를 받아 이미지를 리사이즈하고 다시 S3에 저장하는 서버리스 방식을 사용하면 인프라 관리 부담을 최소화하면서도 필요에 따라 빠르게 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "이미지 리사이즈",
      "고가용성",
      "확장성",
      "AWS Lambda",
      "Amazon S3"
    ],
    "Terms": [
      "AWS Cloud",
      "Amazon S3",
      "AWS Lambda",
      "Amazon CloudFront",
      "AWS Step Functions",
      "Amazon RDS",
      "Amazon EC2",
      "Amazon ECS",
      "Amazon Simple Queue Service (Amazon SQS)"
    ],
    "SelectA": "Amazon S3에 정적 웹사이트를 호스팅하고, 이미지를 리사이즈하기 위해 AWS Lambda 함수를 호출하여 결과 이미지를 Amazon S3 버킷에 저장합니다.",
    "SelectA_Commentary": "이 방식은 서버 없이 Lambda로 이미지 처리를 자동 확장할 수 있어 운영 복잡성을 줄이고 고가용성과 확장성을 동시에 만족하는 최적의 솔루션입니다.",
    "SelectB": "Amazon CloudFront에 정적 웹사이트를 호스팅하고, 이미지를 리사이즈하기 위해 AWS Step Functions를 호출하여 결과 이미지를 Amazon RDS에 저장합니다.",
    "SelectB_Commentary": "Step Functions와 RDS를 활용하면 처리 구조가 복잡해지고, RDS는 이미지 저장에 적합하지 않아 비용과 운영 부담이 커집니다.",
    "SelectC": "Amazon EC2 인스턴스에서 웹 서버를 호스팅하고, 이미지 리사이즈 프로세스를 EC2 인스턴스에서 실행하여 결과 이미지를 Amazon S3 버킷에 저장합니다.",
    "SelectC_Commentary": "EC2 인스턴스 기반은 수동 확장이나 모니터링이 필요해 트래픽 급증 시 안정적인 고가용성과 자동 확장성을 확보하기 어렵습니다.",
    "SelectD": "자동으로 스케일링하는 Amazon ECS 클러스터에서 동적 웹사이트를 호스팅하고, Amazon SQS에 이미지 리사이즈 작업을 생성합니다. Amazon EC2 인스턴스에서 리사이즈 프로그램이 작업을 처리하도록 구성합니다.",
    "SelectD_Commentary": "ECS와 SQS를 활용한 구조는 분산 처리 가능성이 있지만, Lambda 기반 서버리스 솔루션에 비해 설정이 복잡하고 EC2 인스턴스 관리를 요구합니다.",
    "Question_Description_recommedations": [
      "Q1014",
      "Q112",
      "Q802",
      "Q519",
      "Q786"
    ],
    "SelectA_recommedations": [
      "Q636",
      "Q18",
      "Q404"
    ],
    "SelectB_recommedations": [
      "Q354",
      "Q944",
      "Q67"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q194",
      "Q244"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q67",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q514",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 마이크로서비스 애플리케이션을 운영하고 있습니다. 이 회사는 확장성을 위해 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터로 애플리케이션을 마이그레이션하려고 합니다. 회사는 보안 규정 준수를 위해 Amazon EKS 컨트롤 플레인을 endpoint private access를 true로, endpoint public access를 false로 설정해야 합니다. 또한 데이터 플레인은 프라이빗 서브넷에 위치해야 합니다. 그러나 현재 노드가 클러스터에 합류하지 못해 오류 알림을 받고 있습니다. 어떤 해결책이 노드가 클러스터에 합류하도록 허용할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109534-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 보안 요구사항에 따라 컨트롤 플레인을 내부 전용으로 구성했을 때, 노드가 EKS 클러스터에 연결할 수 있도록 네트워크 출구 및 보안 설정을 어떻게 구성해야 하는지 묻습니다. 정답은 노드가 내부 망에서 컨트롤 플레인과 통신할 수 있는 충분한 아웃바운드 규칙을 열어주는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "프라이빗 서브넷",
      "컨트롤 플레인",
      "endpoint private access",
      "노드 합류",
      "보안 규정 준수"
    ],
    "Terms": [
      "Amazon EKS",
      "Amazon EC2",
      "IAM",
      "AmazonEKSNodeRole",
      "VPC endpoints",
      "Security Group"
    ],
    "SelectA": "AWS Identity and Access Management(IAM)에서 AmazonEKSNodeRole IAM 롤에 필요한 권한을 부여합니다.",
    "SelectA_Commentary": "IAM 권한은 필수적이지만, 현재 노드가 클러스터에 접근 가능한 네트워크 경로 자체가 없으면 여전히 연결할 수 없습니다.",
    "SelectB": "인터페이스 VPC endpoints를 생성해 노드가 컨트롤 플레인에 접근할 수 있도록 합니다.",
    "SelectB_Commentary": "PrivateLink를 활용하는 방법이지만 Amazon EKS 환경에서 꼭 필요한 설정은 아니며, 오버엔지니어링일 수 있습니다.",
    "SelectC": "노드를 퍼블릭 서브넷에서 다시 생성하고, EC2 노드의 보안 그룹을 제한합니다.",
    "SelectC_Commentary": "데이터 플레인을 프라이빗 서브넷에 두어야 한다는 요구사항을 위반하므로 적절한 해결책이 아닙니다.",
    "SelectD": "노드의 보안 그룹에서 아웃바운드 트래픽을 허용합니다.",
    "SelectD_Commentary": "Private endpoint만 활성화된 환경에서는 노드가 인터넷 또는 NAT Gateway 등을 통해 EKS API에 연결해야 하므로, 아웃바운드 규칙 허용이 필수입니다. 정답입니다.",
    "Question_Description_recommedations": [
      "Q613",
      "Q115",
      "Q535",
      "Q371",
      "Q681"
    ],
    "SelectA_recommedations": [
      "Q1017",
      "Q941",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q135",
      "Q950",
      "Q151"
    ],
    "SelectC_recommedations": [
      "Q315",
      "Q682",
      "Q100"
    ],
    "SelectD_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q515",
    "Question_Description": "한 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션하고자 합니다. 이 회사는 Amazon Redshift를 솔루션으로 사용하려고 합니다. 이 시나리오에서 Amazon Redshift에 적합한 사용 사례는 무엇입니까? (3개를 고르시오)",
    "Answer": "B,C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109535-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon Redshift가 어떤 시나리오에 적합한지 묻습니다. Amazon Redshift는 대규모 데이터웨어하우싱 및 분석 워크로드에 최적화된 솔루션으로, 저장 데이터에 대한 암호화를 지원하며, 페타바이트 이상의 데이터를 다루는 글로벌 확장에 유리합니다. 따라서 오프피크 시간대에 대규모 분석을 수행하거나 대규모 데이터를 처리해야 할 때 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon Redshift",
      "온프레미스 마이그레이션",
      "사용 사례",
      "데이터웨어하우스",
      "분석 워크로드",
      "암호화",
      "글로벌 확장"
    ],
    "Terms": [
      "Amazon Redshift",
      "on-premises",
      "client-side encryption",
      "server-side encryption",
      "analytics",
      "petabytes scale",
      "AWS Management Console"
    ],
    "SelectA": "전통적인, 컨테이너 기반 및 이벤트 기반 애플리케이션에서 데이터를 액세스하기 위한 Data APIs 지원",
    "SelectA_Commentary": "Amazon Redshift는 주로 SQL 기반 분석 워크로드에 집중하며 Data APIs 지원이 핵심 기능은 아니므로 부적합합니다.",
    "SelectB": "Client-side와 Server-side 암호화를 지원",
    "SelectB_Commentary": "Amazon Redshift는 저장 및 전송 중 데이터를 보호하기 위해 다양한 암호화 방식을 지원하므로 적합한 사용 사례입니다.",
    "SelectC": "애플리케이션이 활성화되지 않은 시간대 또는 특정 시간에 분석 워크로드를 구축",
    "SelectC_Commentary": "오프피크 시간대에 대규모 분석 작업을 수행하는 전형적인 데이터웨어하우스 시나리오로 적합합니다.",
    "SelectD": "백엔드 데이터베이스의 부하를 줄이기 위해 데이터를 캐싱",
    "SelectD_Commentary": "Redshift는 캐싱 솔루션보다는 대규모 분석 데이터웨어하우스로 설계되었기 때문에 적절하지 않습니다.",
    "SelectE": "페타바이트 규모의 데이터와 분당 수천만 건의 요청을 지원하기 위한 글로벌 확장",
    "SelectE_Commentary": "Redshift는 페타바이트 이상의 데이터를 처리할 수 있고, 대규모 확장 및 높은 처리량을 지원하므로 적합합니다.",
    "SelectF": "AWS Management Console을 사용하여 클러스터의 보조 복제본 생성",
    "SelectF_Commentary": "Redshift 클러스터는 간단한 ‘보조 복제본 생성’ 기능이 별도로 제공되지 않으며, 스냅샷 복구 등을 통해 다른 리전으로 복제할 수 있으나 본 옵션은 실제 기능 설명과 다르므로 부적절합니다.",
    "Question_Description_recommedations": [
      "Q557",
      "Q361",
      "Q155",
      "Q687",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q516",
      "Q107"
    ],
    "SelectB_recommedations": [
      "Q77",
      "Q888",
      "Q158"
    ],
    "SelectC_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectD_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectE_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectF_recommedations": [
      "Q361",
      "Q443",
      "Q631"
    ]
  },
  {
    "Question_Number": "Q516",
    "Question_Description": "한 회사는 고객들이 자신의 금융 정보를 조회할 수 있도록 API 인터페이스를 제공합니다. 이 회사는 연중 특정 시기에 사용량이 급증하여 더 많은 요청을 예상하고 있습니다. 회사는 고객 만족을 위해 API가 항상 매우 낮은 지연 시간과 일관된 응답 속도를 유지하기를 원합니다. 또한 API를 호스팅할 컴퓨팅 환경을 운영 오버헤드를 최소화하여 구성해야 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109719-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 피크 트래픽 시에도 API가 낮은 지연 시간과 일관된 성능을 제공해야 하는 상황에서, 운영 오버헤드를 최소화하는 아키텍처 선택을 요구합니다. AWS Lambda에 provisioned concurrency를 설정하면 함수가 사전에 준비되어 콜드 스타트 지연을 없앨 수 있어, 꾸준한 저지연 응답이 가능해집니다. 또한 서버 구성·관리 부담이 적어 운영 오버헤드가 줄어들므로 정답은 B입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "Amazon API Gateway",
      "AWS Lambda",
      "provisioned concurrency",
      "낮은 지연 시간",
      "일관된 응답",
      "금융 정보",
      "운영 오버헤드"
    ],
    "Terms": [
      "Application Load Balancer",
      "Amazon Elastic Container Service(Amazon ECS)",
      "Amazon API Gateway",
      "AWS Lambda",
      "provisioned concurrency",
      "Amazon Elastic Kubernetes Service(Amazon EKS)",
      "reserved concurrency"
    ],
    "SelectA": "Use an Application Load Balancer and Amazon Elastic Container Service (Amazon ECS).",
    "SelectA_Commentary": "ECS를 사용하려면 컨테이너 오케스트레이션과 클러스터 운영이 필요해 운영 부담이 증가합니다. 간단한 API 호스팅 요구사항엔 적합하지 않습니다.",
    "SelectB": "Use Amazon API Gateway and AWS Lambda functions with provisioned concurrency.",
    "SelectB_Commentary": "Provisioned concurrency로 Lambda 콜드 스타트를 줄이고, API Gateway와 연동 시 서버 관리가 최소화됩니다. 피크 트래픽 시에도 일관된 저지연을 유지하는 최적의 선택입니다.",
    "SelectC": "Use an Application Load Balancer and an Amazon Elastic Kubernetes Service (Amazon EKS) cluster.",
    "SelectC_Commentary": "EKS는 Kubernetes 클러스터 구성 및 관리가 필요하며 운영이 복잡해집니다. 서버리스 옵션 대비 오버헤드가 높습니다.",
    "SelectD": "Use Amazon API Gateway and AWS Lambda functions with reserved concurrency.",
    "SelectD_Commentary": "Reserved concurrency는 호출 한도를 보장하지만 콜드 스타트가 여전히 발생할 수 있습니다. Provisioned concurrency와 달리 즉각적인 응답을 위해 인스턴스를 미리 준비하지 않습니다.",
    "Question_Description_recommedations": [
      "Q77",
      "Q107",
      "Q915",
      "Q158",
      "Q506"
    ],
    "SelectA_recommedations": [
      "Q261",
      "Q704",
      "Q695"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q576",
      "Q704"
    ],
    "SelectC_recommedations": [
      "Q261",
      "Q695",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q517",
    "Question_Description": "한 회사가 AWS Systems Manager Session Manager 로그를 아카이빙 목적으로 Amazon S3 버킷에 전송하려고 합니다. 가장 높은 운영 효율성으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109536-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Session Manager 인터랙션 로그를 S3 버킷에 보관해 두어야 하는 상황에서, 별도의 구성이나 설치를 최소화해 운영 부담을 줄이는 방법을 묻습니다. 가장 직접적이며 간단한 방법은 Systems Manager 콘솔에서 S3 logging 기능을 활성화하여 로그를 S3로 전송하는 방식이므로, SelectA가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Session Manager 로그",
      "Amazon S3 버킷",
      "아카이빙",
      "운영 효율성"
    ],
    "Terms": [
      "AWS Systems Manager Session Manager",
      "Amazon S3",
      "S3 logging",
      "Amazon CloudWatch",
      "Amazon Kinesis Data Firehose",
      "IAM Role",
      "EventBridge",
      "Systems Manager Document"
    ],
    "SelectA": "Systems Manager 콘솔에서 S3 logging을 활성화하고, Session 데이터를 보낼 Amazon S3 버킷을 선택합니다.",
    "SelectA_Commentary": "Session Manager 설정 자체에 S3로 로그 전송 기능이 포함되어 있어 별도 에이전트 설치나 프로세스가 필요 없으므로 운영 복잡도를 최소화하는 가장 효율적인 옵션입니다.",
    "SelectB": "Amazon CloudWatch 에이전트를 설치하고, 모든 로그를 CloudWatch log group으로 보냅니다. 이를 다시 S3 버킷으로 내보내 아카이빙합니다.",
    "SelectB_Commentary": "CloudWatch 에이전트 설치와 로그 그룹 → 내보내기 단계를 거쳐야 해 추가 작업이 필요하므로 운영 오버헤드가 더 큽니다.",
    "SelectC": "서버 로그를 중앙 S3 버킷으로 업로드하는 Systems Manager document를 생성합니다. Amazon EventBridge를 통해 계정 내 모든 서버에서 매일 해당 document를 실행합니다.",
    "SelectC_Commentary": "Session Manager 전용 설정 대신 문서를 만들어 매일 작업을 실행해야 하므로 유지보수와 스케줄링이 복잡해집니다.",
    "SelectD": "Amazon CloudWatch 에이전트를 설치하고, 로그를 CloudWatch log group에 저장합니다. 이후 CloudWatch logs subscription을 이용해 Kinesis Data Firehose로 전송하고, 최종 목적지로 Amazon S3 버킷을 설정합니다.",
    "SelectD_Commentary": "CloudWatch subscription과 Kinesis Data Firehose 설정 과정이 복잡하여 운영 오버헤드가 크게 늘어납니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q412",
      "Q109",
      "Q889",
      "Q202"
    ],
    "SelectA_recommedations": [
      "Q517",
      "Q965",
      "Q679"
    ],
    "SelectB_recommedations": [
      "Q27",
      "Q965",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q517",
      "Q270",
      "Q202"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q748",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q518",
    "Question_Description": "한 애플리케이션이 Amazon RDS MySQL DB 인스턴스를 사용하고 있습니다. 이 RDS 데이터베이스의 디스크 용량이 부족해지고 있습니다. 솔루션스 아키텍트는 다운타임 없이 디스크 용량을 늘리고자 합니다. 가장 적은 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109721-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS MySQL DB의 디스크 용량이 부족해질 때, 다운타임 없이 간편하게 확장하는 방법을 묻습니다. storage autoscaling 기능을 사용하면 수작업 없이 자동으로 용량이 늘어나며, 운영 부담이 최소화됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS MySQL DB",
      "디스크 용량 부족",
      "다운타임 없이 확장",
      "storage autoscaling"
    ],
    "Terms": [
      "Amazon RDS MySQL DB instance",
      "storage autoscaling",
      "RDS database instance size",
      "Provisioned IOPS",
      "Backup and restore",
      "Storage capacity"
    ],
    "SelectA": "RDS에서 storage autoscaling을 활성화합니다.",
    "SelectA_Commentary": "storage autoscaling은 설정된 임계값을 초과하면 자동으로 스토리지를 확장하여, 다운타임 없이 손쉽게 용량 문제를 해결할 수 있는 최적의 방법입니다.",
    "SelectB": "RDS 데이터베이스 인스턴스 크기를 증가시킵니다.",
    "SelectB_Commentary": "인스턴스 크기를 키우면 CPU나 메모리는 늘릴 수 있지만 디스크 확장과는 직접적 연관이 없고, 재부팅에 따른 잠시의 다운타임이 발생할 수 있습니다.",
    "SelectC": "RDS 데이터베이스 인스턴지 스토리지 유형을 Provisioned IOPS로 변경합니다.",
    "SelectC_Commentary": "Provisioned IOPS는 I/O 성능 보장을 위한 옵션이지만 디스크 공간 자체가 충분히 늘어나는 것은 아니며, 문제의 핵심인 디스크 용량 부족을 해결하기 어렵습니다.",
    "SelectD": "RDS 데이터베이스를 백업하고 스토리지 용량을 늘려 복원한 뒤, 이전 인스턴스를 중지합니다.",
    "SelectD_Commentary": "백업 후 복원 절차는 시간이 걸리고 다운타임이 발생합니다. 운영상 복잡성이 크고, ‘가장 적은 노력’이라는 조건에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q629",
      "Q259",
      "Q108",
      "Q228",
      "Q195"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q518",
      "Q259"
    ],
    "SelectB_recommedations": [
      "Q863",
      "Q108",
      "Q187"
    ],
    "SelectC_recommedations": [
      "Q518",
      "Q629",
      "Q259"
    ],
    "SelectD_recommedations": [
      "Q108",
      "Q863",
      "Q58"
    ]
  },
  {
    "Question_Number": "Q519",
    "Question_Description": "한 컨설팅 회사가 전 세계 고객들에게 전문 서비스를 제공합니다. 이 회사는 고객이 AWS에서 데이터 수집과 분석을 더 빠르게 수행할 수 있도록 솔루션과 도구를 제공합니다. 회사는 이러한 공통 솔루션과 도구를 고객이 셀프 서비스로 사용할 수 있도록 중앙에서 관리하고 배포해야 합니다. 이를 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109722-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 고객에게 공통된 솔루션과 도구를 표준화하여 셀프 서비스 형태로 제공하고, 간편하게 관리하고 배포할 수 있는 방법을 찾는 것입니다. 정답은 AWS Service Catalog로, 관리자가 승인한 제품들을 중앙에서 일괄적으로 제공하고 고객이 필요 시 원하는 솔루션을 자동으로 배포할 수 있게 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "글로벌 고객",
      "데이터 분석 가속화",
      "공통 솔루션 배포",
      "중앙 집중 관리",
      "셀프 서비스"
    ],
    "Terms": [
      "AWS CloudFormation",
      "AWS Service Catalog",
      "AWS Systems Manager",
      "AWS Config"
    ],
    "SelectA": "고객을 위해 AWS CloudFormation 템플릿을 생성합니다.",
    "SelectA_Commentary": "CloudFormation은 인프라를 코드로 프로비저닝하는 서비스이지만, 셀프 서비스 제공과 중앙 집중 카탈로그 관리를 위한 전문 기능은 부족합니다.",
    "SelectB": "고객을 위해 AWS Service Catalog 제품을 생성합니다.",
    "SelectB_Commentary": "Service Catalog는 승인된 솔루션과 도구를 중앙에서 표준화해 고객이 셀프 서비스로 배포할 수 있도록 하며, 요구사항을 정확히 충족합니다.",
    "SelectC": "고객을 위해 AWS Systems Manager 템플릿을 생성합니다.",
    "SelectC_Commentary": "Systems Manager는 구성이나 운영 자동화에 유용하지만, 기업 차원의 표준 제품 카탈로그 제공 기능을 대체하기에는 적합하지 않습니다.",
    "SelectD": "고객을 위해 AWS Config 항목을 생성합니다.",
    "SelectD_Commentary": "AWS Config는 리소스 구성을 추적하고 평가하는 서비스로, 솔루션을 배포하거나 셀프 서비스를 위한 중앙 관리 기능을 제공하지 않습니다.",
    "Question_Description_recommedations": [
      "Q786",
      "Q802",
      "Q869",
      "Q112",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q8",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q194",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q520",
    "Question_Description": "한 회사가 Amazon EC2 Instances에서 실행될 새로운 웹 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 백엔드 데이터 스토리지로 Amazon DynamoDB를 사용합니다. 애플리케이션 트래픽은 예측하기 어렵고, 데이터베이스에 대한 읽기 및 쓰기 처리량이 중간에서 높을 것으로 예상됩니다. 회사는 애플리케이션 트래픽에 따라 확장해야 하며, 비용 효율적인 구성을 원합니다. 어떤 DynamoDB 테이블 설정이 이러한 요구 사항을 가장 비용 효율적으로 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109539-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능한 애플리케이션 트래픽에 대응하여 DynamoDB를 효율적으로 확장 가능하도록 구성해야 합니다. Provisioned 모드는 트래픽 변동에 대응하기 위해 과다 설정을 유발할 수 있어 비용 증가 위험이 큽니다. On-demand 모드는 사용한 만큼만 과금하며 자동으로 처리량을 확장하므로 예측하기 어려우면서 중간에서 높은 트래픽이 예상되는 시나리오에서 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon EC2 Instances",
      "Amazon DynamoDB",
      "예측 불가능한 트래픽",
      "중간에서 높은 처리량",
      "스케일링",
      "비용 효율성",
      "DynamoDB on-demand mode",
      "DynamoDB Standard"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon DynamoDB",
      "Provisioned capacity",
      "DynamoDB auto scaling",
      "DynamoDB Standard",
      "DynamoDB Standard-IA (Infrequent Access)",
      "On-demand mode",
      "Maximum defined capacity"
    ],
    "SelectA": "DynamoDB Standard 테이블 클래스를 사용해 provisioned 용량을 설정하고, DynamoDB auto scaling을 최대 정의 용량으로 구성합니다.",
    "SelectA_Commentary": "Provisioned 모드는 용량을 예측해 설정해야 하므로 트래픽 변동이 큰 경우 비용 과잉 지출 위험이 높고, 유연성도 제한적입니다.",
    "SelectB": "DynamoDB Standard 테이블 클래스를 사용해 on-demand 모드로 구성합니다.",
    "SelectB_Commentary": "트래픽 변화에 따라 자동으로 처리량을 조정하고, 사용량에 따라 과금되어 예측 불가능한 트래픽과 중간~높은 처리량 환경에 가장 비용 효율적인 선택입니다.",
    "SelectC": "DynamoDB Standard-IA 테이블 클래스를 사용해 provisioned 용량을 설정하고, DynamoDB auto scaling을 최대 정의 용량으로 구성합니다.",
    "SelectC_Commentary": "Standard-IA는 액세스 빈도가 낮은 데이터를 위해 설계되어 중간 이상 트래픽 환경에서는 성능과 비용 측면에서 적합하지 않습니다.",
    "SelectD": "DynamoDB Standard-IA 테이블 클래스를 사용해 on-demand 모드로 구성합니다.",
    "SelectD_Commentary": "Standard-IA는 드물게 액세스되는 환경을 가정하므로 중간~높은 처리량이 필요한 예측 불가능한 트래픽에는 추가 비용과 성능 부담이 발생할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q196",
      "Q348",
      "Q79",
      "Q670",
      "Q799"
    ],
    "SelectA_recommedations": [
      "Q348",
      "Q196",
      "Q670"
    ],
    "SelectB_recommedations": [
      "Q79",
      "Q348",
      "Q670"
    ],
    "SelectC_recommedations": [
      "Q196",
      "Q520",
      "Q348"
    ],
    "SelectD_recommedations": [
      "Q79",
      "Q670",
      "Q348"
    ]
  },
  {
    "Question_Number": "Q521",
    "Question_Description": "한 소매 회사에 여러 비즈니스 부서가 있습니다. 각 비즈니스의 IT 팀은 자체 AWS 계정을 관리하고 있으며, 모든 계정은 AWS Organizations 내 조직의 일부입니다. 각 팀은 자체 AWS 계정의 Amazon DynamoDB 테이블에서 제품 재고 레벨을 모니터링하고 있습니다. 이 회사는 중앙 인벤토리 보고 애플리케이션을 공유 AWS 계정에 배포하려고 합니다. 이 애플리케이션은 모든 팀의 DynamoDB 테이블에서 아이템을 읽을 수 있어야 합니다. 이 요구사항을 가장 안전하게 충족하는 인증 옵션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109703-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에 있는 Amazon DynamoDB 테이블을 중앙화된 애플리케이션에서 읽어야 할 때, 가장 안전한 인증 방법을 묻습니다. Cross-account IAM role을 사용해 신뢰 정책과 함께 STS AssumeRole을 통해 필요한 권한만 부여하는 방법이 권장됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "중앙 인벤토리 보고 애플리케이션",
      "재고 레벨",
      "Cross-Account Role",
      "IAM Role",
      "STS AssumeRole",
      "AWS Organizations",
      "DynamoDB"
    ],
    "Terms": [
      "AWS Organizations",
      "Amazon DynamoDB",
      "IAM Role",
      "IAM User",
      "STS AssumeRole",
      "AWS Secrets Manager",
      "AWS Certificate Manager (ACM)",
      "Access Key",
      "Trust Policy"
    ],
    "SelectA": "AWS Secrets Manager를 inventory 애플리케이션 계정과 DynamoDB에 통합하고, 애플리케이션에서 Secrets Manager의 올바른 시크릿을 사용하여 테이블에 접근하도록 설정합니다. 30일 간격으로 시크릿을 교체하도록 스케줄링합니다.",
    "SelectA_Commentary": "Secrets Manager만으로는 각 비즈니스 계정의 DynamoDB 접근 권한을 효과적으로 제어하기 어렵고, Cross-Account 접근 제어와 롤 기반 권한 부여를 대체하기에는 적합하지 않습니다.",
    "SelectB": "각 비즈니스 계정마다 프로그래밍 방식 액세스 권한이 있는 IAM User를 생성하고, 애플리케이션에서 해당 IAM User의 Access Key와 Secret Key로 인증해 DynamoDB 테이블을 읽도록 설정합니다. IAM 액세스 키는 30일마다 수동으로 교체합니다.",
    "SelectB_Commentary": "IAM User의 액세스 키를 공유하면 보안 위험이 크고, 여러 계정 간 키 관리가 복잡해지므로 가장 안전한 방법이 아닙니다.",
    "SelectC": "각 비즈니스 계정에 BU_ROLE이라는 IAM Role을 생성하여 DynamoDB 테이블에 대한 액세스 권한을 부여하고, inventory 애플리케이션 계정의 특정 Role을 신뢰하도록 Trust Policy를 설정합니다. 그리고 inventory 계정에는 STS AssumeRole API 작업에 대한 권한이 있는 APP_ROLE을 만들어 두 계정 간 Cross-Account Role을 사용해 DynamoDB 테이블에 접근하도록 설정합니다.",
    "SelectC_Commentary": "Cross-Account Role과 STS AssumeRole을 사용하는 방식은 필요한 권한만 부여하면서 계정 간 액세스를 안전하게 설정하는 베스트 프랙티스입니다. 보안과 권한 관리를 가장 효율적으로 수행할 수 있습니다.",
    "SelectD": "DynamoDB를 AWS Certificate Manager(ACM)과 통합하고, 인증용 인증서를 생성하여 DynamoDB에 접근합니다. 애플리케이션에서 이 인증서를 사용해 DynamoDB 테이블을 읽습니다.",
    "SelectD_Commentary": "DynamoDB 직접 인증에 ACM을 활용하는 방식은 일반적으로 지원되지 않는 패턴이며, 계정 간 접근 제어와는 관련성이 낮아 안전성과 실용성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q727",
      "Q945",
      "Q1018",
      "Q168",
      "Q176"
    ],
    "SelectA_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ],
    "SelectB_recommedations": [
      "Q279",
      "Q476",
      "Q780"
    ],
    "SelectC_recommedations": [
      "Q423",
      "Q279",
      "Q878"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ]
  },
  {
    "Question_Number": "Q522",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용해 컨테이너 애플리케이션을 실행하고 있습니다. 회사의 워크로드는 하루 종일 일정하지 않으며, Amazon EKS가 워크로드에 따라 자동으로 In/Out 확장되어야 합니다. 운영 업무 부담이 가장 적은 방법으로 이 요구 사항을 충족하기 위해 필요한 단계 조합은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109702-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS 클러스터를 자동으로 확장 및 축소해 운영 부담을 최소화하는 방법을 묻습니다. Kubernetes Metrics Server와 Kubernetes Cluster Autoscaler를 함께 활용하면 애플리케이션과 노드 레벨에서 모두 동적으로 확장할 수 있어 가장 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EKS",
      "컨테이너 애플리케이션",
      "자동 확장",
      "Horizontal Pod Autoscaling",
      "Kubernetes Cluster Autoscaler"
    ],
    "Terms": [
      "AWS Lambda",
      "Kubernetes Metrics Server",
      "Horizontal Pod Autoscaling(HPA)",
      "Kubernetes Cluster Autoscaler",
      "Amazon API Gateway",
      "AWS App Mesh"
    ],
    "SelectA": "AWS Lambda 함수를 사용해 EKS 클러스터 크기를 조정합니다.",
    "SelectA_Commentary": "수동 제어가 필요하고 자동 확장 기능이 제한돼 운영 부담이 큽니다.",
    "SelectB": "Kubernetes Metrics Server를 사용해 Horizontal Pod Autoscaling을 활성화합니다.",
    "SelectB_Commentary": "Pod 레벨에서 CPU/메모리 사용량을 기준으로 워크로드에 맞춰 동적으로 확장이 가능해 유연성을 높입니다. (정답)",
    "SelectC": "Kubernetes Cluster Autoscaler를 사용해 클러스터 노드 수를 관리합니다.",
    "SelectC_Commentary": "노드 레벨에서 자동으로 확장/축소해 인프라 자원을 효율적으로 활용합니다. (정답)",
    "SelectD": "Amazon API Gateway를 사용해 Amazon EKS에 연결합니다.",
    "SelectD_Commentary": "API 관리와 엔드포인트 제공을 위한 서비스이므로 EKS 자원 확장과 직접 관련이 없습니다.",
    "SelectE": "AWS App Mesh를 사용해 네트워크 활동을 관찰합니다.",
    "SelectE_Commentary": "서비스 메시 형태로 트래픽을 모니터링하지만, 자동 확장에는 직접적인 도움이 되지 않습니다.",
    "Question_Description_recommedations": [
      "Q563",
      "Q724",
      "Q996",
      "Q775",
      "Q698"
    ],
    "SelectA_recommedations": [
      "Q775",
      "Q563",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q724",
      "Q660",
      "Q29"
    ],
    "SelectC_recommedations": [
      "Q724",
      "Q660",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q775",
      "Q563"
    ],
    "SelectE_recommedations": [
      "Q8",
      "Q293",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q523",
    "Question_Description": "한 회사가 마이크로서비스 기반 서버리스 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 여러 Amazon DynamoDB 테이블에서 데이터를 조회할 수 있어야 합니다. 솔루션스 아키텍트는 애플리케이션의 기본 성능에 영향을 주지 않고 데이터를 조회할 수 있는 기능을 제공해야 합니다. 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/109701-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버리스 웹 애플리케이션이 여러 DynamoDB 테이블에서 데이터를 빠르고 간편하게 조회하는 방법을 묻습니다. AWS AppSync pipeline resolvers를 사용하면 GraphQL API 단에서 여러 데이터 소스를 한 번에 조합하여 호출할 수 있고, 확장성과 성능을 효율적으로 유지할 수 있습니다. Lambda 함수를 이용하거나, Athena Federated Query 등의 방법은 추가 구성과 관리가 필요하여 운영 복잡도가 높아집니다. 따라서 가장 운영 효율이 높은 솔루션은 AWS AppSync pipeline resolvers입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "서버리스 웹 애플리케이션",
      "마이크로서비스",
      "Amazon DynamoDB",
      "성능 유지",
      "운영 효율"
    ],
    "Terms": [
      "AWS AppSync pipeline resolvers",
      "Amazon CloudFront",
      "Lambda@Edge",
      "Edge-optimized Amazon API Gateway",
      "AWS Lambda",
      "Amazon Athena Federated Query",
      "DynamoDB connector"
    ],
    "SelectA": "AWS AppSync pipeline resolvers",
    "SelectA_Commentary": "단일 GraphQL API로 여러 DynamoDB 테이블을 파이프라인 리졸버로 연동해 간단히 데이터에 접근할 수 있어, 성능 저하 없이 운영 효율도 높습니다.",
    "SelectB": "Amazon CloudFront와 Lambda@Edge 함수",
    "SelectB_Commentary": "CloudFront는 주로 정적 콘텐츠 배포와 엣지에서의 요청 처리에 적합합니다. DynamoDB 데이터를 조회하는 용도로는 추가 설정이 필요하여 운영 효율이 떨어집니다.",
    "SelectC": "Edge-optimized Amazon API Gateway와 AWS Lambda 함수",
    "SelectC_Commentary": "API Gateway와 Lambda를 통해 데이터를 조회할 수 있지만, 다수의 테이블을 관리하려면 별도의 코드 및 구성이 추가로 필요해 운영 복잡도가 증가합니다.",
    "SelectD": "Amazon Athena Federated Query와 DynamoDB connector",
    "SelectD_Commentary": "Athena를 이용한 Federated Query는 주로 분석이나 일회성 쿼리에 적합하며, 실시간 트랜잭션 처리보다는 데이터 분석용으로 운영 효율성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q472",
      "Q731",
      "Q578",
      "Q177",
      "Q962"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q515",
      "Q443"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q361",
      "Q280"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q576",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q472",
      "Q578",
      "Q177"
    ]
  },
  {
    "Question_Number": "Q524",
    "Question_Description": "한 회사가 IAM permissions와 관련된 Access Denied errors 및 Unauthorized errors를 분석하고 문제를 해결하고자 합니다. 회사는 이미 AWS CloudTrail을 활성화해 두었습니다. 가장 적은 노력으로 이러한 요구 사항을 충족하는 방법은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111425-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM 권한 문제로 발생하는 Access Denied, Unauthorized 에러 로그를 효율적으로 분석하는 방법을 묻습니다. Amazon Athena는 CloudTrail 로그를 직접 쿼리할 수 있어 추가 리소스나 복잡한 설정 없이 문제 해결에 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Access Denied errors",
      "Unauthorized errors",
      "IAM permissions",
      "AWS CloudTrail",
      "Amazon Athena"
    ],
    "Terms": [
      "IAM permissions",
      "AWS CloudTrail",
      "AWS Glue",
      "AWS Batch",
      "Amazon Athena",
      "Amazon QuickSight",
      "Access Denied errors",
      "Unauthorized errors"
    ],
    "SelectA": "AWS Glue와 custom scripts를 사용하여 CloudTrail 로그에서 에러를 쿼리합니다.",
    "SelectA_Commentary": "AWS Glue를 이용하면 데이터 처리를 자동화할 수 있지만, custom scripts 작성 및 Glue 작업 구성이 필요해 상대적으로 복잡합니다.",
    "SelectB": "AWS Batch와 custom scripts를 사용하여 CloudTrail 로그에서 에러를 쿼리합니다.",
    "SelectB_Commentary": "Batch 작업 설정과 스크립트 운영이 필요해 관리 오버헤드가 높고, 문제 해결에 즉각적으로 접근하기에는 불편합니다.",
    "SelectC": "Amazon Athena 쿼리를 통해 CloudTrail 로그에서 에러를 식별합니다.",
    "SelectC_Commentary": "S3에 저장된 CloudTrail 로그를 Athena로 직접 조회 가능하므로 설정이 간단하고, 최소한의 노력으로 필요한 에러 정보를 신속히 찾을 수 있는 최적의 선택입니다.",
    "SelectD": "Amazon QuickSight로 CloudTrail 로그를 검색하고 대시보드를 만들어 에러를 식별합니다.",
    "SelectD_Commentary": "QuickSight는 시각화와 대시보드에 유용하지만, 임시 쿼리 기반의 빠른 트러블슈팅에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q476",
      "Q222",
      "Q780",
      "Q233",
      "Q494"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q524",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q942",
      "Q524",
      "Q970"
    ],
    "SelectC_recommedations": [
      "Q898",
      "Q970",
      "Q529"
    ],
    "SelectD_recommedations": [
      "Q898",
      "Q942",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q525",
    "Question_Description": "한 회사가 이미 발생한 AWS 사용 비용을 운영 비용 대시보드에 추가하려고 합니다. 솔루션스 아키텍트는 회사가 사용 비용을 프로그래매틱하게 조회할 수 있는 방법을 추천해야 합니다. 이 회사는 올해 발생한 비용 데이터뿐 아니라, 향후 12개월 동안의 비용 예측 데이터도 조회할 수 있어야 합니다. 최소한의 운영 오버헤드를 제공하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111278-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 사용 비용을 간편하고 자동화된 방식으로 조회하고 미래 비용까지 예측하기 위한 방법을 묻습니다. AWS Cost Explorer API를 사용하면 최소한의 수작업과 자동화된 예측 기능으로 연간 및 향후 12개월 비용 데이터를 안전하고 신속하게 확보할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [],
    "Keywords": [
      "AWS 사용 비용",
      "운영 비용 대시보드",
      "프로그램적 접근",
      "최소 운영 오버헤드",
      "비용 예측"
    ],
    "Terms": [
      "AWS Cost Explorer",
      "AWS Budgets",
      "API",
      "CSV",
      "FTP",
      "SMTP",
      "Cost Forecast"
    ],
    "SelectA": "AWS Cost Explorer API를 pagination과 함께 사용하여 사용 비용 관련 데이터를 조회합니다.",
    "SelectA_Commentary": "프로그램적으로 연간 데이터 및 12개월 예측 값을 자동으로 조회할 수 있고, 운영 오버헤드가 매우 적습니다.",
    "SelectB": "다운로드 가능한 AWS Cost Explorer 보고서 .csv 파일을 이용해 사용 비용 관련 데이터를 조회합니다.",
    "SelectB_Commentary": "CSV 파일을 다운로드해 수동으로 처리해야 하므로 자동화가 어렵고 오버헤드가 큽니다.",
    "SelectC": "AWS Budgets 액션을 구성하여 FTP로 회사에 사용 비용 데이터를 전송합니다.",
    "SelectC_Commentary": "FTP 연동 설정 등 추가 구성이 필요하고 예측 데이터 활용이 직관적이지 않아 오버헤드가 큽니다.",
    "SelectD": "AWS Budgets 보고서를 생성하여 SMTP를 통해 회사에 사용 비용 데이터를 전송합니다.",
    "SelectD_Commentary": "이메일 방식으로 전송하므로 실시간 조회가 어렵고 추가 자동화가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q985",
      "Q284",
      "Q728",
      "Q541",
      "Q485"
    ],
    "SelectA_recommedations": [
      "Q485",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q641",
      "Q238",
      "Q284"
    ],
    "SelectC_recommedations": [
      "Q205",
      "Q485",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q485",
      "Q728",
      "Q284"
    ]
  },
  {
    "Question_Number": "Q526",
    "Question_Description": "한 솔루션스 아키텍트가 애플리케이션의 복원성을 검토하고 있습니다. 최근 데이터베이스 관리자가 스케일링 테스트의 일환으로 애플리케이션의 Amazon Aurora PostgreSQL database writer 인스턴스를 페일오버했으며, 이로 인해 애플리케이션에 약 3분간의 다운타임이 발생했습니다. 가장 적은 운영 작업으로 스케일링 중 발생하는 다운타임을 줄일 수 있는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111245-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon Aurora PostgreSQL 환경에서 스케일링이나 페일오버 시 발생하는 다운타임을 최소화하는 방법을 묻습니다. Amazon RDS proxy를 사용하면 애플리케이션이 단일 엔드포인트를 통해 자동으로 정상 writer 인스턴스에 연결되어 운영 부담과 다운타임이 크게 줄어듭니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon Aurora PostgreSQL",
      "failover",
      "다운타임",
      "스케일링",
      "operational overhead",
      "Amazon RDS proxy"
    ],
    "Terms": [
      "Amazon Aurora PostgreSQL",
      "database writer instance",
      "failover",
      "downtime",
      "scaling exercise",
      "Aurora PostgreSQL read replicas",
      "Amazon ElastiCache for Memcached",
      "Amazon RDS proxy"
    ],
    "SelectA": "클러스터에 Aurora PostgreSQL read replicas를 더 많이 생성하여 페일오버 시 부하를 처리하도록 합니다.",
    "SelectA_Commentary": "read replicas는 읽기 전용 부하 분산에는 유용하지만, writer 인스턴스가 바뀔 때 발생하는 다운타임을 근본적으로 줄이는 데는 한계가 있습니다.",
    "SelectB": "동일 AWS Region에 보조 Aurora PostgreSQL cluster를 구성합니다. 페일오버 시 애플리케이션을 보조 cluster의 writer endpoint로 업데이트합니다.",
    "SelectB_Commentary": "별도 클러스터를 구축해도 failover 후 애플리케이션 단에서 설정 변경이 필요해 운영 작업이 늘고, 전체적인 구성이 복잡해질 수 있습니다.",
    "SelectC": "페일오버 시 부하를 처리하기 위해 Amazon ElastiCache for Memcached cluster를 생성합니다.",
    "SelectC_Commentary": "콘텐츠 캐싱은 읽기 전용 트래픽에 도움을 줄 수 있지만, 실제 DB write 작업에 대한 다운타임 감소 방안으로는 적합하지 않습니다.",
    "SelectD": "데이터베이스에 대해 Amazon RDS proxy를 설정합니다. 애플리케이션을 proxy endpoint를 사용하도록 업데이트합니다.",
    "SelectD_Commentary": "단일 프록시 엔드포인트로 자동으로 헬시 writer 인스턴스에 라우팅되어 다운타임이 크게 감소하므로 스케일링이나 페일오버에 가장 효과적입니다.",
    "Question_Description_recommedations": [
      "Q136",
      "Q879",
      "Q25",
      "Q400",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q136",
      "Q755",
      "Q601"
    ],
    "SelectB_recommedations": [
      "Q526",
      "Q136",
      "Q241"
    ],
    "SelectC_recommedations": [
      "Q824",
      "Q194",
      "Q584"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q228",
      "Q629"
    ]
  },
  {
    "Question_Number": "Q527",
    "Question_Description": "한 회사가 단일 AWS Region에서 구독 기반 스트리밍 서비스를 운영하고 있습니다. 아키텍처는 Amazon EC2 인스턴스 위에서 동작하는 웹 서버와 애플리케이션 서버로 구성되며, 이 인스턴스들은 Elastic Load Balancer 뒤에서 Auto Scaling group을 통해 관리됩니다. 또한 여러 Availability Zone에 걸쳐 구성된 Amazon Aurora global database 클러스터를 사용하고 있습니다. 회사는 글로벌로 확장하고 애플리케이션의 다운타임을 최소화하고자 합니다. 어떤 솔루션이 가장 높은 Fault Tolerance를 제공할 수 있습니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111428-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 현재 단일 Region에서 운영되는 스트리밍 서비스를 글로벌 확장 시 높은 가용성과 내결함성(고가용성)을 유지하도록 아키텍처를 설계하는 방법을 묻습니다. Multi-Region 배포와 Amazon Aurora global database를 활용해 데이터베이스를 동기화하고, Amazon Route 53의 Health Check와 Failover Routing을 통해 자동 장애 조치(failover)를 가능하게 해야 다운타임을 최소화할 수 있습니다. 정답은 중복 Region으로 웹/애플리케이션 계층을 확장하고 Aurora global database를 활용해 자동 Failover 구조를 갖추는 것입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "글로벌 확장",
      "최소 다운타임",
      "Fault Tolerance",
      "Amazon Aurora global database",
      "Route 53",
      "Failover Routing"
    ],
    "Terms": [
      "Amazon EC2",
      "Elastic Load Balancer",
      "Auto Scaling group",
      "Amazon Aurora global database cluster",
      "Aurora PostgreSQL",
      "Cross-Region Aurora Replica",
      "AWS Database Migration Service(AWS DMS)",
      "Availability Zone",
      "Amazon Route 53",
      "Failover routing policy",
      "Health checks"
    ],
    "SelectA": "웹 및 애플리케이션 계층 Auto Scaling group을 확장하여 두 번째 Region의 Availability Zone에도 인스턴스를 배포하고, 기본 Region과 두 번째 Region에 Amazon Aurora global database를 구성합니다. Amazon Route 53 헬스 체크와 Failover 라우팅 정책을 통해 두 번째 Region으로 트래픽을 전환합니다.",
    "SelectA_Commentary": "Auto Scaling group은 여러 Availability Zone 간 확장은 가능하지만, 다른 Region으로 직접 확장할 수는 없습니다. 또한 Aurora global database 구성을 제안하고 있으나, Auto Scaling group 자체만으로는 새로운 Region에 인스턴스를 배포하기 어렵습니다.",
    "SelectB": "두 번째 Region에 웹 및 애플리케이션 계층을 배포하고, 두 번째 Region에 Aurora PostgreSQL Cross-Region Aurora Replica를 추가합니다. Amazon Route 53 헬스 체크와 Failover 라우팅 정책을 사용하여 필요한 경우 보조 노드를 승격(Promote)합니다.",
    "SelectB_Commentary": "Cross-Region Replica로 구성하면 Failover 시 수동 승격이 필요하지만, 글로벌 데이터베이스 구조에 비해 글로벌 동기화 시 성능 이점이 적습니다.",
    "SelectC": "두 번째 Region에 웹 및 애플리케이션 계층을 배포하고, 두 번째 Region에 Aurora PostgreSQL DB를 생성합니다. AWS Database Migration Service(AWS DMS)를 사용하여 기본 데이터베이스를 두 번째 Region으로 복제합니다. Amazon Route 53 헬스 체크와 Failover 라우팅 정책을 통해 트래픽을 두 번째 Region으로 전환합니다.",
    "SelectC_Commentary": "AWS DMS를 통한 DB 복제 방식은 변경 사항 동기화가 실시간이 아닐 수 있고, Aurora global database에 비해 Failover 구성이 까다롭습니다.",
    "SelectD": "두 번째 Region에 웹 및 애플리케이션 계층을 배포합니다. 기본 Region과 두 번째 Region에 Amazon Aurora global database를 구성합니다. Amazon Route 53 헬스 체크와 Failover 라우팅 정책을 통해 두 번째 Region으로 트래픽을 전환하며, 필요한 경우 보조 노드를 승격(Promote)합니다.",
    "SelectD_Commentary": "글로벌 Aurora 구성으로 각 Region에 읽기/쓰기 노드를 배치할 수 있고, 장애 발생 시 보조 노드를 손쉽게 Primary로 승격하여 다운타임을 최소화할 수 있어 가장 Fault Tolerant한 구조입니다.",
    "Question_Description_recommedations": [
      "Q224",
      "Q69",
      "Q691",
      "Q47",
      "Q874"
    ],
    "SelectA_recommedations": [
      "Q527",
      "Q69",
      "Q836"
    ],
    "SelectB_recommedations": [
      "Q585",
      "Q136",
      "Q527"
    ],
    "SelectC_recommedations": [
      "Q178",
      "Q585",
      "Q338"
    ],
    "SelectD_recommedations": [
      "Q527",
      "Q585",
      "Q178"
    ]
  },
  {
    "Question_Number": "Q528",
    "Question_Description": "한 데이터 분석 회사가 기존 배치 처리 시스템을 AWS로 마이그레이션하려고 합니다. 회사는 하루 동안 주기적으로 FTP를 통해 다수의 소형 데이터 파일을 수신합니다. 온프레미스 배치 작업은 이 데이터를 야간에 처리하지만 처리 완료까지 몇 시간이 걸립니다. 회사는 AWS 솔루션이 도착한 데이터 파일을 가능한 한 빠르게 처리하고, FTP 클라이언트 변경을 최소화하길 원합니다. 또한 처리 완료 후에는 해당 데이터 파일을 삭제해야 합니다. 각 파일을 처리하는 데는 3~8분이 필요합니다. 이 요구사항을 가장 운영 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111317-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 FTP 기반 데이터 전송을 AWS로 옮기면서 파일 처리 시간을 단축하고 자동으로 파일을 삭제해야 하는 시나리오입니다. AWS Transfer Family를 사용하면 기존 FTP 클라이언트 변경 없이 S3에 안전하게 파일을 업로드할 수 있으며, S3 event notification을 통한 AWS Lambda 트리거로 3~8분 내의 처리 시간을 수용하면서 파일을 실시간에 가깝게 처리하고 운영 복잡성을 최소화할 수 있습니다. Lambda는 기본 최대 실행 시간이 15분이므로 각 파일당 처리 시간이 충분하며, 처리 후 자동으로 파일을 삭제할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "데이터 마이그레이션",
      "FTP",
      "배치 처리",
      "운영 효율",
      "AWS Transfer Family",
      "3~8분 처리",
      "파일 자동 삭제"
    ],
    "Terms": [
      "AWS Transfer Family",
      "Amazon EC2",
      "Amazon EBS",
      "Amazon S3 Glacier Flexible Retrieval",
      "AWS Batch",
      "Amazon EventBridge",
      "S3 event notification",
      "AWS Lambda",
      "Amazon S3 Standard"
    ],
    "SelectA": "Amazon EC2 인스턴스에서 FTP 서버를 구동하여 들어오는 파일을 Amazon S3 Glacier Flexible Retrieval로 저장합니다. AWS Batch의 job queue를 구성하고 Amazon EventBridge 규칙을 사용해 매일 밤에 S3 Glacier Flexible Retrieval에서 객체를 처리하도록 작업을 호출한 뒤, 처리가 완료된 후 객체를 삭제합니다.",
    "SelectA_Commentary": "파일이 S3 Glacier Flexible Retrieval에 저장되면 복원 과정이 필요해 처리 시작이 지연됩니다. 즉시 처리가 어려워 목적에 부합하지 않습니다.",
    "SelectB": "Amazon EC2 인스턴스에서 FTP 서버를 구동하여 들어오는 파일을 Amazon EBS 볼륨에 저장합니다. AWS Batch의 job queue를 구성하고 Amazon EventBridge 규칙을 사용해 매일 밤 EBS 볼륨에서 파일 처리 작업을 호출한 뒤, 처리가 완료된 후 파일을 삭제합니다.",
    "SelectB_Commentary": "야간 일괄 방식이므로 즉시 처리 요구사항을 충족하지 못하고, EC2와 EBS 관리 부담이 큽니다.",
    "SelectC": "AWS Transfer Family로 FTP 서버를 생성하고, 들어오는 파일을 Amazon EBS 볼륨에 저장합니다. AWS Batch의 job queue를 구성합니다. 각 파일이 도착할 때마다 Amazon S3 event notification을 통해 AWS Batch 작업을 호출하도록 설정한 뒤, 처리가 완료된 후 파일을 삭제합니다.",
    "SelectC_Commentary": "EBS에 파일을 저장하면 Batch를 통해 즉각적 처리는 가능하지만, FTP 업로드 후 S3 event notification과의 연동이 불명확하며 EBS 관리가 필요합니다.",
    "SelectD": "AWS Transfer Family를 사용해 FTP 서버를 생성하고, 들어오는 파일을 Amazon S3 Standard에 저장합니다. AWS Lambda 함수를 만들어 파일을 처리한 뒤 처리가 완료되면 파일을 삭제합니다. 파일이 S3에 도착할 때마다 S3 event notification으로 Lambda 함수를 호출합니다.",
    "SelectD_Commentary": "즉시 처리가 가능하고 Lambda 최대 실행 시간(15분) 내에서 3~8분 처리가 가능해 운영 효율성이 높으며, 추가 서버 관리가 필요 없어 요구사항을 완벽히 충족합니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q547",
      "Q155",
      "Q568",
      "Q626"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q155",
      "Q910"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q910",
      "Q680"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q844",
      "Q38"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q155",
      "Q38"
    ]
  },
  {
    "Question_Number": "Q529",
    "Question_Description": "한 회사가 AWS로 워크로드를 마이그레이션하고자 합니다. 이 회사는 트랜잭션 데이터와 민감한 데이터를 포함한 데이터베이스를 보유하고 있습니다. 회사는 AWS Cloud 솔루션을 활용해 데이터베이스 보안을 강화하고 운영 오버헤드를 줄이기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111246-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트랜잭션 처리와 민감한 데이터를 모두 안전하게 유지하면서 운영 관리를 간소화하는 방법을 묻습니다. Amazon RDS에 마이그레이션하고 암호화를 설정하면 서버 관리 부담이 줄고, 기본적으로 제공되는 암호화와 자동 백업, 패치 기능으로 민감한 데이터를 보호할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "트랜잭션 데이터",
      "민감한 데이터",
      "AWS Cloud",
      "Amazon RDS",
      "Encryption at rest",
      "운영 오버헤드 감소"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Key Management Service (AWS KMS)",
      "Amazon RDS",
      "Encryption at rest",
      "Amazon S3",
      "Amazon Macie",
      "Amazon CloudWatch Logs"
    ],
    "SelectA": "데이터베이스를 Amazon EC2로 마이그레이션하고, AWS KMS에서 제공하는 AWS Managed Key로 암호화를 사용합니다.",
    "SelectA_Commentary": "EC2에서 직접 데이터베이스를 운영하면 보안 설정과 운영 관리가 모두 사용자 책임이므로 오버헤드가 큽니다.",
    "SelectB": "데이터베이스를 Amazon RDS로 마이그레이션하고, 암호화(Encryption at rest)를 구성합니다.",
    "SelectB_Commentary": "Amazon RDS는 자동 백업, 보안 패치 등의 관리 기능을 제공하며, 암호화 설정으로 민감한 데이터를 안심하고 관리할 수 있는 가장 적절한 솔루션입니다.",
    "SelectC": "데이터를 Amazon S3로 마이그레이션하고, Amazon Macie를 사용하여 데이터 보안 및 보호를 수행합니다.",
    "SelectC_Commentary": "Amazon Macie는 S3 데이터 보안에 특화되어 있지만, 트랜잭션 처리용 데이터베이스 환경에는 적합하지 않아 요구사항을 만족하기 어렵습니다.",
    "SelectD": "데이터베이스를 Amazon RDS로 마이그레이션하고, Amazon CloudWatch Logs를 통해 데이터 보안 및 보호를 수행합니다.",
    "SelectD_Commentary": "CloudWatch Logs는 모니터링 및 로깅에 주로 활용되며, 암호화 같은 직접적인 데이터 보호 기능을 제공하지 않으므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q970",
      "Q898",
      "Q548",
      "Q922",
      "Q592"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ],
    "SelectB_recommedations": [
      "Q847",
      "Q977",
      "Q330"
    ],
    "SelectC_recommedations": [
      "Q106",
      "Q678",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q330",
      "Q847",
      "Q742"
    ]
  },
  {
    "Question_Number": "Q530",
    "Question_Description": "한 회사가 TCP와 UDP 멀티플레이어 게임 기능을 가진 온라인 게임 애플리케이션을 운영하고 있습니다. 회사는 Amazon Route 53을 사용해 여러 AWS Region에 걸쳐 배포된 여러 Network Load Balancer(NLB)로 트래픽을 라우팅하고 있습니다. 이 회사는 사용자 수 증가에 대비하여 애플리케이션 성능을 개선하고 지연 시간을 줄이길 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111271-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 TCP와 UDP를 모두 사용하는 멀티플레이어 게임 환경에서 글로벌 트래픽을 낮은 지연 시간으로 처리해야 하는 상황을 다룹니다. Network Load Balancer는 TCP와 UDP를 지원하며, AWS Global Accelerator를 추가로 사용하면 전 세계적으로 트래픽을 빠르고 안정적으로 라우팅해 지연 시간을 크게 단축할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "온라인 게임 애플리케이션",
      "TCP",
      "UDP",
      "멀티플레이어",
      "Network Load Balancer",
      "지연 시간 감소",
      "AWS Global Accelerator",
      "성능 향상",
      "여러 AWS Region",
      "Amazon Route 53"
    ],
    "Terms": [
      "Amazon Route 53",
      "Network Load Balancer(NLB)",
      "TCP",
      "UDP",
      "AWS Global Accelerator",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront",
      "Amazon API Gateway",
      "API Caching",
      "Latency-based Routing",
      "Listener Ports",
      "Cache-Control"
    ],
    "SelectA": "NLB들 앞에 Amazon CloudFront 배포를 추가하고 Cache-Control max-age 파라미터를 증가시킵니다.",
    "SelectA_Commentary": "CloudFront는 주로 HTTP/HTTPS 기반 콘텐츠 캐싱에 특화되어 있어 TCP 및 UDP 멀티플레이어 게임 트래픽 개선에는 제한적입니다.",
    "SelectB": "NLB를 Application Load Balancer(ALB)로 교체하고 Amazon Route 53에 대기 시간 기반 라우팅을 구성합니다.",
    "SelectB_Commentary": "ALB는 주로 HTTP/HTTPS 트래픽에 최적화되어 있어 TCP/UDP 기반 게임 트래픽 처리에 적합하지 않습니다.",
    "SelectC": "NLB들 앞에 AWS Global Accelerator를 추가합니다. 올바른 리스너 포트를 사용하도록 Global Accelerator 엔드포인트를 구성합니다.",
    "SelectC_Commentary": "Global Accelerator는 TCP/UDP 트래픽을 효율적으로 라우팅하고 전 세계적으로 일관된 엔드포인트(IP 주소)를 제공하므로 지연 시간을 크게 줄이고 성능을 개선합니다.",
    "SelectD": "NLB 뒤에 Amazon API Gateway 엔드포인트를 추가하고 API 캐싱을 활성화합니다. 서로 다른 스테이지마다 메서드 캐싱을 재정의합니다.",
    "SelectD_Commentary": "API Gateway는 RESTful API 트래픽 중 HTTP/HTTPS에 최적화되어 있으며, TCP/UDP 멀티플레이어 게임 트래픽에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q12",
      "Q367",
      "Q692",
      "Q815",
      "Q582"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q280",
      "Q38"
    ],
    "SelectB_recommedations": [
      "Q530",
      "Q12",
      "Q815"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q865",
      "Q33"
    ],
    "SelectD_recommedations": [
      "Q576",
      "Q597",
      "Q77"
    ]
  },
  {
    "Question_Number": "Q531",
    "Question_Description": "한 회사는 서드파티 데이터 피드와 통합이 필요합니다. 이 데이터 피드는 새로운 데이터가 사용 가능해질 때 외부 서비스에 알리기 위해 webhook을 전송합니다. 한 개발자가 AWS Lambda 함수를 작성하여 webhook 콜백을 수신하면 데이터를 가져오도록 구성했습니다. 개발자는 서드파티가 호출할 수 있도록 이 Lambda 함수를 외부에 공개해야 합니다. 가장 적은 운영 상의 복잡성으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111430-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새 데이터가 준비되었을 때 웹훅(webhook)으로 알림을 받는 서드파티 환경에서, AWS Lambda 함수를 외부에서 직접 호출하도록 구성하는 방법을 묻습니다. Lambda function URL을 사용하면 별도의 인프라 설정 없이 고유한 HTTPS 엔드포인트가 자동으로 생성되므로 운영 복잡성이 가장 낮습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "서드파티 데이터 피드",
      "AWS Lambda",
      "webhook",
      "function URL",
      "운영 효율성"
    ],
    "Terms": [
      "AWS Lambda",
      "Webhook",
      "Lambda function URL",
      "Application Load Balancer (ALB)",
      "Amazon Simple Notification Service (SNS)",
      "Amazon Simple Queue Service (SQS)"
    ],
    "SelectA": "Lambda 함수에 function URL을 생성합니다. 이 Lambda function URL을 서드파티에 제공하여 webhook으로 호출하게 합니다.",
    "SelectA_Commentary": "Lambda function URL을 사용하면 운영 복잡성이 최소화되고, 간단히 HTTPS 엔드포인트를 제공할 수 있어 가장 효율적인 솔루션입니다.",
    "SelectB": "Lambda 함수 앞에 Application Load Balancer(ALB)를 배포합니다. ALB URL을 서드파티에 제공하여 webhook으로 호출하게 합니다.",
    "SelectB_Commentary": "ALB를 구성하고 유지관리해야 하므로 운영 부담이 커지며, 단순히 Lambda를 호출하기에는 과도한 설정입니다.",
    "SelectC": "Amazon SNS 토픽을 생성합니다. 해당 토픽에 Lambda 함수를 연결합니다. Amazon SNS의 퍼블릭 호스트네임을 서드파티에 제공하여 webhook으로 호출하게 합니다.",
    "SelectC_Commentary": "SNS를 통해 메시지를 전달하는 과정을 거쳐야 하므로 직접 호출보다 복잡하며, webhook 패턴과는 맞지 않습니다.",
    "SelectD": "Amazon SQS 대기열을 생성합니다. 해당 대기열에 Lambda 함수를 연결합니다. Amazon SQS의 퍼블릭 호스트네임을 서드파티에 제공하여 webhook으로 호출하게 합니다.",
    "SelectD_Commentary": "SQS에 메시지를 쌓고 Lambda가 폴링해야 하므로 단순 webhook 호출 대비 운영 구조가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q785",
      "Q45",
      "Q148",
      "Q513",
      "Q112"
    ],
    "SelectA_recommedations": [
      "Q531",
      "Q785",
      "Q404"
    ],
    "SelectB_recommedations": [
      "Q531",
      "Q545",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q636",
      "Q148",
      "Q45"
    ],
    "SelectD_recommedations": [
      "Q531",
      "Q98",
      "Q785"
    ]
  },
  {
    "Question_Number": "Q532",
    "Question_Description": "한 회사가 특정 AWS 리전에 워크로드를 운영 중이며, 고객들은 Amazon API Gateway REST API를 통해 해당 워크로드에 접속합니다. 회사는 DNS 제공자로 Amazon Route 53을 사용하고 있으며, 각 고객별로 개별적이고 보안이 강화된 URL을 제공하고자 합니다. 운영 효율성을 극대화하면서 이 요구사항을 충족하려면 어떤 단계를 수행해야 합니까? (3가지를 고르세요.)",
    "Answer": "A,D,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111382-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "개별 서브도메인으로 고객별 안전한 접속을 제공하려면 Route 53에서 와일드카드 도메인을 설정하고, 동일 리전의 ACM에서 와일드카드 인증서를 발급받아 API Gateway 커스텀 도메인에 연결해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "워크로드",
      "Amazon API Gateway",
      "Route 53",
      "보안 URL",
      "와일드카드 인증서",
      "ACM",
      "커스텀 도메인"
    ],
    "Terms": [
      "Amazon API Gateway",
      "Amazon Route 53",
      "REST API",
      "AWS Certificate Manager (ACM)",
      "Wildcard Certificate",
      "Hosted Zone",
      "DNS",
      "Domain Registrar",
      "Custom Domain Name"
    ],
    "SelectA": "필요한 도메인을 등록한 뒤, Route 53 호스티드 존에서 와일드카드 커스텀 도메인을 만들고 해당 존 레코드를 API Gateway 엔드포인트로 지정합니다.",
    "SelectA_Commentary": "도메인 등록 및 와일드카드 커스텀 도메인 생성으로 각 고객에게 개별 URL을 쉽게 할당하고 운영 부담을 줄일 수 있습니다.",
    "SelectB": "다른 리전의 AWS Certificate Manager (ACM)에서 도메인과 일치하는 와일드카드 인증서를 요청합니다.",
    "SelectB_Commentary": "API Gateway가 위치한 동일 리전이 아닌 곳에서 발급받으면 인증서 연결 과정이 복잡해집니다.",
    "SelectC": "Route 53에서 고객별로 호스티드 존을 생성하고, API Gateway 엔드포인트를 가리키는 존 레코드를 만듭니다.",
    "SelectC_Commentary": "각 고객마다 별도 호스티드 존을 만들면 관리가 복잡해지고 운영 효율성이 떨어집니다.",
    "SelectD": "동일 리전의 AWS Certificate Manager (ACM)에서 와일드카드 인증서를 요청하여 커스텀 도메인 이름과 일치하도록 합니다.",
    "SelectD_Commentary": "API Gateway가 있는 리전에서 발급받아야 인증서 연동이 원활하며 HTTPS를 보장할 수 있습니다.",
    "SelectE": "API Gateway에서 고객별로 여러 API 엔드포인트를 만듭니다.",
    "SelectE_Commentary": "마이크로서비스가 아니라면 엔드포인트를 분산 관리하게 되어 비효율적이고 관리 부담이 커집니다.",
    "SelectF": "API Gateway에서 REST API에 대한 커스텀 도메인 이름을 생성하고, AWS Certificate Manager (ACM)의 인증서를 가져와 연결합니다.",
    "SelectF_Commentary": "커스텀 도메인에 인증서를 연결해 HTTPS 통신을 제공하고, 손쉽게 서브도메인 방식 접근을 설정할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q1019",
      "Q712",
      "Q56",
      "Q34",
      "Q291"
    ],
    "SelectA_recommedations": [
      "Q532",
      "Q56",
      "Q1019"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q222",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q532",
      "Q56",
      "Q34"
    ],
    "SelectD_recommedations": [
      "Q222",
      "Q893",
      "Q898"
    ],
    "SelectE_recommedations": [
      "Q571",
      "Q34",
      "Q159"
    ],
    "SelectF_recommedations": [
      "Q1019",
      "Q159",
      "Q532"
    ]
  },
  {
    "Question_Number": "Q533",
    "Question_Description": "한 회사는 Amazon S3에 데이터를 저장하고 있습니다. 규정에 따르면 데이터에는 개인 식별 정보(PII)가 포함되어서는 안 됩니다. 그러나 최근 회사는 일부 S3 버킷에서 PII가 포함된 객체들을 발견했습니다. 회사는 S3 버킷에서 PII를 자동으로 감지하고, 이를 보안 팀에 알릴 수 있는 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111432-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 저장된 데이터에서 PII 여부를 자동으로 식별하고, 해당 사실을 보안 팀에 빠르게 알리는 방법을 묻습니다. Amazon Macie는 S3 내 PII 탐지 기능을 제공하며, 탐지 이벤트를 Amazon EventBridge와 연동하여 보안 팀에게 SNS 알림을 전송하는 구성이 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "PII",
      "보안 팀",
      "자동 감지",
      "Amazon Macie",
      "SensitiveData 이벤트",
      "Amazon SNS",
      "EventBridge"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Macie",
      "Amazon GuardDuty",
      "Amazon EventBridge",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "SensitiveData",
      "CRITICAL event type",
      "S3Object/Personal",
      "개인 식별 정보(PII)"
    ],
    "SelectA": "Amazon Macie를 사용합니다. Macie 검색 결과에서 SensitiveData 이벤트 유형을 필터링하도록 Amazon EventBridge 규칙을 생성하고, Amazon SNS 알림을 보안 팀에 전송하도록 설정합니다.",
    "SelectA_Commentary": "Macie는 S3 버킷 내 PII를 탐지하기에 최적이며, SNS는 보안 팀에 직접 알림을 주기 쉬운 서비스입니다. 요구 사항에 가장 부합하는 솔루션입니다.",
    "SelectB": "Amazon GuardDuty를 사용합니다. GuardDuty 검색 결과에서 CRITICAL 이벤트 유형을 필터링하도록 Amazon EventBridge 규칙을 생성하고, Amazon SNS 알림을 보안 팀에 전송하도록 설정합니다.",
    "SelectB_Commentary": "GuardDuty는 악의적 활동을 탐지하는 보안 서비스지만, PII 자동 감지 기능은 제공하지 않습니다. 필요한 기능과 맞지 않아 오답입니다.",
    "SelectC": "Amazon Macie를 사용합니다. Macie 검색 결과에서 SensitiveData:S3Object/Personal 이벤트 유형을 필터링하도록 Amazon EventBridge 규칙을 생성하고, Amazon SQS 알림을 보안 팀에 전송하도록 설정합니다.",
    "SelectC_Commentary": "Macie 사용은 적절하지만, 보안 팀에 실시간으로 전달하려면 SNS가 더 효율적입니다. SQS는 메일박스 형태로 큐에 쌓이므로 즉시성 측면에서 덜 적합합니다.",
    "SelectD": "Amazon GuardDuty를 사용합니다. GuardDuty 검색 결과에서 CRITICAL 이벤트 유형을 필터링하도록 Amazon EventBridge 규칙을 생성하고, Amazon SQS 알림을 보안 팀에 전송하도록 설정합니다.",
    "SelectD_Commentary": "GuardDuty 자체가 PII를 식별해주지 않으므로 요구 사항을 충족하지 못합니다. 또한 SQS만으로 보안 팀이 실시간 알림을 받기는 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q756",
      "Q295",
      "Q359",
      "Q553",
      "Q678"
    ],
    "SelectA_recommedations": [
      "Q359",
      "Q678",
      "Q106"
    ],
    "SelectB_recommedations": [
      "Q364",
      "Q893",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q533",
      "Q359",
      "Q740"
    ],
    "SelectD_recommedations": [
      "Q364",
      "Q765",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q534",
    "Question_Description": "한 회사는 여러 AWS 계정에서 생성되는 로그를 중앙화된 계정의 Amazon S3 버킷에 저장하고자 합니다. 이 회사는 VPC flow logs와 AWS CloudTrail logs를 30일 동안은 자주 조회해야 하므로 높은 가용성이 필요하며, 이후 60일간 추가 백업으로 보관하다가, 생성 후 90일이 지난 로그는 삭제하기로 결정했습니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111434-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "로그를 30일간 자주 조회 후 백업 상태로 전환하는 데에는 비용이 적게 드는 Glacier Flexible Retrieval 사용이 가장 효율적입니다. 90일 후 자동 삭제로 전체 요구 사항을 만족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "로그",
      "중앙화",
      "가용성",
      "백업",
      "삭제",
      "비용 효율",
      "라이프사이클"
    ],
    "Terms": [
      "Amazon S3",
      "VPC flow logs",
      "AWS CloudTrail",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Glacier Flexible Retrieval",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "Lifecycle policy"
    ],
    "SelectA": "생성 후 30일 뒤 S3 Standard 스토리지 클래스로 전환하고, 90일 뒤 만료 작업으로 삭제를 설정합니다.",
    "SelectA_Commentary": "30일 후에도 Standard를 사용하면 비용 절감 폭이 작아, 백업 위주의 요구 사항에 비효율적입니다.",
    "SelectB": "생성 후 30일 뒤 S3 Standard-IA로 전환합니다. 90일 뒤 S3 Glacier Flexible Retrieval로 옮깁니다. 이후 90일 뒤 만료 작업으로 삭제를 설정합니다.",
    "SelectB_Commentary": "90일에야 Glacier로 전환하면 90일 보관 뒤 삭제 일정과 맞지 않아, 불필요한 과정을 거칩니다.",
    "SelectC": "생성 후 30일 뒤 S3 Glacier Flexible Retrieval로 전환합니다. 이후 90일 뒤 만료 작업으로 삭제를 설정합니다.",
    "SelectC_Commentary": "30일 이후로는 자주 조회하지 않으므로 Glacier Flexible Retrieval로 바로 전환해 비용을 절감하고, 90일에 삭제해 요구 사항을 충족합니다.",
    "SelectD": "생성 후 30일 뒤 S3 One Zone-IA로 전환합니다. 90일 뒤 S3 Glacier Flexible Retrieval로 옮깁니다. 이후 90일 뒤 만료 작업으로 삭제를 설정합니다.",
    "SelectD_Commentary": "One Zone-IA는 가용 영역 하나에만 저장되어 가용성 요구 사항에 부적합하며, 90일에야 Glacier로 전환하는 방식도 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q250",
      "Q471",
      "Q606",
      "Q498",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q126",
      "Q630",
      "Q997"
    ],
    "SelectB_recommedations": [
      "Q356",
      "Q126",
      "Q890"
    ],
    "SelectC_recommedations": [
      "Q606",
      "Q285",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q778",
      "Q486",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q535",
    "Question_Description": "한 회사가 업무를 위해 Amazon EKS 클러스터를 구축하고 있습니다. Amazon EKS에 저장되는 모든 secrets는 Kubernetes etcd key-value store에서 반드시 암호화되어야 합니다. 이러한 요구사항을 만족시키려면 어떤 솔루션이 필요합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111385-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS 클러스터의 Kubernetes etcd key-value store에 저장되는 secrets를 암호화해야 하는 시나리오입니다. KMS key를 이용하여 EKS KMS secrets encryption을 활성화하면 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon EKS",
      "Kubernetes etcd",
      "Secrets 암호화",
      "AWS KMS key",
      "EKS KMS secrets encryption"
    ],
    "Terms": [
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Kubernetes",
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager",
      "Amazon Elastic Block Store (Amazon EBS) Container Storage Interface (CSI) driver",
      "etcd",
      "EBS encryption",
      "EKS KMS secrets encryption"
    ],
    "SelectA": "새로운 AWS KMS key를 생성하고, AWS Secrets Manager를 사용해 Amazon EKS의 모든 secrets를 관리, 로테이션, 저장합니다.",
    "SelectA_Commentary": "Secrets Manager는 개별 secret을 관리하지만 etcd 자체의 암호화를 보장하지 않아 요구사항을 충족하지 못합니다.",
    "SelectB": "새로운 AWS KMS key를 생성합니다. Amazon EKS 클러스터에서 Amazon EKS KMS secrets encryption을 활성화합니다.",
    "SelectB_Commentary": "KMS key를 사용해 Kubernetes etcd에 저장된 secrets를 직접 암호화하여 요구사항을 완벽히 충족하는 정답입니다.",
    "SelectC": "기본 옵션으로 Amazon EKS 클러스터를 생성합니다. Amazon EBS Container Storage Interface(CSI) 드라이버를 애드온으로 사용합니다.",
    "SelectC_Commentary": "EBS CSI 드라이버는 영구 스토리지 용도로 사용되며, etcd에 저장된 secrets 암호화와는 무관합니다.",
    "SelectD": "alias/aws/ebs 별칭으로 새로운 AWS KMS key를 생성해 계정의 기본 Amazon EBS 볼륨 암호화를 활성화합니다.",
    "SelectD_Commentary": "EBS 볼륨 암호화는 etcd key-value store에 저장된 secrets 암호화와 별개이므로 요구사항을 해결할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q613",
      "Q371",
      "Q805",
      "Q681",
      "Q514"
    ],
    "SelectA_recommedations": [
      "Q535",
      "Q681",
      "Q371"
    ],
    "SelectB_recommedations": [
      "Q535",
      "Q371",
      "Q681"
    ],
    "SelectC_recommedations": [
      "Q451",
      "Q371",
      "Q535"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q371",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q536",
    "Question_Description": "한 회사가 프로덕션 Amazon RDS for PostgreSQL 데이터베이스에 대해 데이터 과학자들에게 거의 실시간(near real-time)의 읽기 전용 접근 권한을 제공하고자 합니다. 현재 데이터베이스는 Single-AZ 구성으로 되어 있습니다. 데이터 과학자들은 복잡한 쿼리를 사용하지만, 이는 프로덕션 데이터베이스에 영향을 주지 않습니다. 회사는 고가용성을 필요로 하며, 가장 비용 효율적인 솔루션이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111435-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프로덕션 RDS PostgreSQL 환경에서 데이터 과학자들이 거의 실시간으로 읽기 전용 쿼리를 수행할 수 있도록 하면서 고가용성을 충족해야 하는 요구 사항을 다룹니다. 근본적으로 Multi-AZ 구성이 필요하며, 일반적인 Multi-AZ 대기 인스턴스(standby)는 읽기 기능을 제공하지 않으므로, 읽기 가능한 standby가 있는 Multi-AZ Cluster 배포가 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "읽기 전용 접근",
      "가까운 실시간",
      "데이터 과학자",
      "고가용성",
      "비용 효율성"
    ],
    "Terms": [
      "Single-AZ",
      "Multi-AZ instance deployment",
      "Multi-AZ cluster deployment",
      "Read replica",
      "Readable standby",
      "Synchronous replication",
      "Asynchronous replication"
    ],
    "SelectA": "기존 프로덕션 데이터베이스를 점검 창구(maintenance window)에 확장하여 데이터 과학자들에게 충분한 처리 능력을 제공합니다.",
    "SelectA_Commentary": "단일 인스턴스 확대만으로 고가용성을 확보할 수 없고 데이터 과학자 쿼리가 생산 계정에 직접 영향 줄 수 있어 적절하지 않습니다.",
    "SelectB": "Single-AZ에서 Multi-AZ 인스턴스 배포로 변경하고, 대형 보조(standby) 인스턴스를 구성합니다. 데이터 과학자에게 그 보조 인스턴스에 대한 접근 권한을 제공합니다.",
    "SelectB_Commentary": "일반적인 Multi-AZ 인스턴스 배포의 standby는 읽기용으로 제공되지 않아 근본적으로 거의 실시간 읽기가 불가능합니다.",
    "SelectC": "Single-AZ에서 Multi-AZ 인스턴스 배포로 변경하고, 데이터 과학자들을 위해 두 개의 추가 Read Replica를 만듭니다.",
    "SelectC_Commentary": "Read Replica는 비동기 복제로 인해 지연이 발생할 수 있고, standby까지 운영 시 오버프로비저닝으로 비용이 높아집니다.",
    "SelectD": "Single-AZ에서 Multi-AZ 클러스터 배포로 변경하고, 읽기 가능한 스탠바이 인스턴스 두 개를 구성합니다. 데이터 과학자에게 해당 읽기 엔드포인트를 제공합니다.",
    "SelectD_Commentary": "동기식 복제로 거의 실시간 읽기가 가능하며, Multi-AZ Cluster로 고가용성을 충족합니다. 비용 대비 요구사항 충족에 가장 적합한 해법입니다.",
    "Question_Description_recommedations": [
      "Q464",
      "Q958",
      "Q989",
      "Q420",
      "Q601"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q967",
      "Q917"
    ],
    "SelectB_recommedations": [
      "Q311",
      "Q8",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q133",
      "Q194",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q363",
      "Q163"
    ]
  },
  {
    "Question_Number": "Q537",
    "Question_Description": "한 회사가 AWS Cloud를 사용하여 세 개의 가용 영역에서 동작하는 3계층 웹 애플리케이션을 운영하고 있습니다. 현재 애플리케이션 아키텍처는 Application Load Balancer, 사용자 세션 상태를 호스팅하는 Amazon EC2 웹 서버, EC2 인스턴스에서 실행되는 MySQL 데이터베이스로 구성됩니다. 회사는 갑작스러운 애플리케이션 트래픽 증가를 예상하고 있으며, 향후 애플리케이션 용량 수요에 맞춰 확장 가능하고 세 개 가용 영역 전반에서 고가용성을 보장하고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111386-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자 세션을 안정적으로 유지하면서 데이터베이스와 웹 서버가 갑작스러운 트래픽 증가에 대응하도록 확장성과 고가용성을 모두 충족하는 아키텍처를 설계하는 것입니다. 세션 상태를 EC2 내부가 아닌 ElastiCache(특히 Redis)에 저장하면 영구성과 빠른 접근을 모두 확보할 수 있고, 데이터베이스는 Multi-AZ 배포로 가용성을 높입니다. 마지막으로 웹 서버는 Auto Scaling 그룹으로 탄력적인 스케일 아웃이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "세 개 가용 영역",
      "확장성",
      "가 sudden한 트래픽 증가",
      "Amazon RDS for MySQL",
      "ElastiCache for Redis",
      "세션 데이터",
      "Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "MySQL",
      "Amazon RDS for MySQL",
      "Multi-AZ DB cluster",
      "Amazon ElastiCache",
      "Redis",
      "Memcached",
      "Auto Scaling group",
      "DynamoDB",
      "DAX"
    ],
    "SelectA": "MySQL 데이터베이스를 Amazon RDS for MySQL Multi-AZ DB 클러스터로 마이그레이션합니다. 세션 데이터 저장과 읽기 캐시를 위해 고가용성 Amazon ElastiCache for Redis를 사용합니다. 웹 서버를 세 개 가용 영역의 Auto Scaling 그룹으로 이전합니다.",
    "SelectA_Commentary": "Redis는 세션 등 영구적 데이터 보존에 더 적합하며 Multi-AZ 구성 RDS로 DB 가용성까지 높일 수 있어 요구사항을 모두 충족합니다.",
    "SelectB": "MySQL 데이터베이스를 Amazon RDS for MySQL Multi-AZ DB 클러스터로 마이그레이션합니다. 세션 데이터 저장과 읽기 캐시를 위해 고가용성 Amazon ElastiCache for Memcached를 사용합니다. 웹 서버를 세 개 가용 영역의 Auto Scaling 그룹으로 이전합니다.",
    "SelectB_Commentary": "Memcached도 캐시 용도로 훌륭하나, 세션 상태 관리에는 영구성이 높은 Redis가 더 적합합니다.",
    "SelectC": "MySQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다. DynamoDB Accelerator(DAX)를 사용하여 읽기 캐시를 수행하고, 세션 데이터도 DynamoDB에 저장합니다. 웹 서버를 세 개 가용 영역의 Auto Scaling 그룹으로 이전합니다.",
    "SelectC_Commentary": "데이터를 완전히 DynamoDB로 이전하는 것은 큰 구조 변경이며, 기존 MySQL 워크로드 요구사항과 어긋날 수 있습니다.",
    "SelectD": "MySQL 데이터베이스를 단일 가용 영역의 Amazon RDS for MySQL로 마이그레이션합니다. 세션 데이터 저장과 읽기 캐시를 위해 고가용성 Amazon ElastiCache for Redis를 사용합니다. 웹 서버를 세 개 가용 영역의 Auto Scaling 그룹으로 이전합니다.",
    "SelectD_Commentary": "DB가 단일 AZ 구성이라 고가용성을 충족하지 못해 장애 시 서비스 중단 가능성이 있습니다.",
    "Question_Description_recommedations": [
      "Q1012",
      "Q357",
      "Q944",
      "Q654",
      "Q236"
    ],
    "SelectA_recommedations": [
      "Q390",
      "Q958",
      "Q944"
    ],
    "SelectB_recommedations": [
      "Q390",
      "Q354",
      "Q935"
    ],
    "SelectC_recommedations": [
      "Q1002",
      "Q768",
      "Q78"
    ],
    "SelectD_recommedations": [
      "Q935",
      "Q944",
      "Q354"
    ]
  },
  {
    "Question_Number": "Q538",
    "Question_Description": "한 글로벌 비디오 스트리밍 회사가 Amazon CloudFront를 CDN으로 사용하고 있습니다. 이 회사는 여러 국가에 걸쳐 단계적으로 콘텐츠를 출시하고 싶어 합니다. 회사는 콘텐츠를 출시한 국가가 아닌 지역의 시청자들이 해당 콘텐츠를 볼 수 없도록 해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111387-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 특정 국가에서만 콘텐츠를 시청하도록 제한하는 방법을 묻는 질문입니다. Amazon CloudFront의 지리적 제한(Geo Restriction)을 사용하여 허가된 국가를 Allow List로 설정하면 원하는 국가에서만 콘텐츠를 볼 수 있게 합니다. 다른 옵션들은 국가 제어가 아닌 인증 방식이나 시간 제한, 암호화에 초점을 맞추어 요구 사항을 만족하지 못합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon CloudFront",
      "단계적 콘텐츠 배포",
      "지리적 접근 제한",
      "사용 국가 제한",
      "커스텀 에러 메시지"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Geo Restriction",
      "Allow List",
      "Signed URL",
      "Cookies",
      "Encryption",
      "Time-restricted Access Policy",
      "Custom Error Message"
    ],
    "SelectA": "CloudFront에서 Allow List를 사용하여 콘텐츠에 대한 Geographic Restrictions을 추가합니다. 커스텀 에러 메시지를 설정합니다.",
    "SelectA_Commentary": "지리적 접근 제한을 통해 특정 국가만 접근을 허용하는 정답입니다. Allow List 방식으로 국가 단위 제어가 가능하며, 요구 사항을 충족합니다.",
    "SelectB": "제한된 콘텐츠를 위한 새 URL을 설정합니다. Signed URL과 Cookies를 사용하여 접근을 인증합니다. 커스텀 에러 메시지를 설정합니다.",
    "SelectB_Commentary": "Signed URL과 Cookies는 사용자 자격 증명을 확인하는 방식으로, 국가별 제한 대신 인증 기반 접근 제어만 가능하므로 요구 사항에 부합하지 않습니다.",
    "SelectC": "회사에서 배포하는 콘텐츠 데이터를 암호화합니다. 커스텀 에러 메시지를 설정합니다.",
    "SelectC_Commentary": "암호화 자체는 데이터 보안을 위한 기능일 뿐, 특정 국가에서만 콘텐츠를 볼 수 있도록 제한하지 못하므로 문제 해결과 직접적인 관련이 없습니다.",
    "SelectD": "제한된 콘텐츠를 위한 새 URL을 생성합니다. Signed URL에 대한 시간 제한 접근 정책을 설정합니다.",
    "SelectD_Commentary": "시간 제한 방식은 콘텐츠 접근 기간만 제어할 뿐, 국가별 제한이 불가능해 요구 사항을 만족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q172",
      "Q592",
      "Q831",
      "Q898",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q172",
      "Q538",
      "Q855"
    ],
    "SelectB_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q265",
      "Q106",
      "Q678"
    ]
  },
  {
    "Question_Number": "Q539",
    "Question_Description": "회사는 AWS Cloud를 사용하여 온프레미스 재해 복구(DR) 구성을 개선하고자 합니다. 회사의 핵심 프로덕션 비즈니스 애플리케이션은 Microsoft SQL Server Standard를 사용하며, 가상 머신(VM)에서 구동 중입니다. 이 애플리케이션은 30초 이하의 복구 지점 목표(RPO)와 60분의 복구 시간 목표(RTO)가 필요합니다. DR 솔루션은 비용을 가능한 한 최소화해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111301-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 실행되는 Microsoft SQL Server Standard 기반 애플리케이션에 대해 30초 이하의 RPO와 60분 이내의 RTO를 충족하면서 비용도 최소화해야 하는 DR 전략을 묻는 것입니다. Warm Standby 방식은 RPO를 초 단위로, RTO를 분 단위로 맞출 수 있으면서 Active-Active 방식보다 비용을 효율적으로 절감할 수 있습니다. 따라서 Warm Standby 구성을 Amazon RDS for SQL Server로 구축하고, AWS DMS로 실시간에 가까운 데이터를 동기화(CDC)하는 SelectB가 요구사항을 가장 잘 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DR 구성 개선",
      "RPO 30초 이하",
      "RTO 60분",
      "비용 최소화",
      "Warm Standby",
      "Microsoft SQL Server Standard"
    ],
    "Terms": [
      "AWS Cloud",
      "Microsoft SQL Server",
      "Always On availability groups",
      "Amazon RDS for SQL Server",
      "AWS Database Migration Service(AWS DMS)",
      "change data capture(CDC)",
      "AWS Elastic Disaster Recovery",
      "Pilot Light",
      "Amazon S3"
    ],
    "SelectA": "Microsoft SQL Server Enterprise의 Always On availability groups를 사용하여 온프레미스 서버와 AWS 간에 다중 사이트 active/active 구성을 설정합니다.",
    "SelectA_Commentary": "Active-Active 구조는 거의 무중단 RPO/RTO를 달성하지만, Microsoft SQL Server Enterprise 라이선스 비용이 매우 높고, 운영 유지 비용도 크게 증가합니다.",
    "SelectB": "AWS에서 warm standby Amazon RDS for SQL Server 데이터베이스를 구성합니다. AWS Database Migration Service(AWS DMS)가 change data capture(CDC)를 사용하도록 설정합니다.",
    "SelectB_Commentary": "Warm Standby는 요구사항인 RPO 30초 이하와 RTO 60분 이내를 만족하면서도 Active-Active 대비 비용이 훨씬 적게 들어 최적의 해법입니다.",
    "SelectC": "AWS Elastic Disaster Recovery를 사용하여 디스크 변경 사항을 AWS로 복제하도록 pilot light 구성을 설정합니다.",
    "SelectC_Commentary": "Pilot Light는 최소 리소스만 실행하며 RPO가 분 단위, RTO가 시간 단위로 비용은 절약되지만, 30초 RPO와 60분 RTO를 준수하기에는 쉽지 않습니다.",
    "SelectD": "서드파티 백업 소프트웨어를 사용하여 매일 백업을 수행합니다. 그리고 백업의 보조본을 Amazon S3에 저장합니다.",
    "SelectD_Commentary": "Backup & Restore 방식의 RPO는 보통 시간 단위이며, RTO도 하루 이내로 맞출 수는 있지만, 본 문제의 엄격한 30초 RPO와 60분 RTO에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q273",
      "Q274",
      "Q588",
      "Q896",
      "Q343"
    ],
    "SelectA_recommedations": [
      "Q843",
      "Q69",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q843",
      "Q944"
    ],
    "SelectC_recommedations": [
      "Q224",
      "Q874",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q784",
      "Q110",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q540",
    "Question_Description": "한 회사에서 온프레미스 서버에 Oracle 데이터베이스를 사용해 고객 정보를 처리하고 저장하고 있습니다. 이 회사는 더 높은 가용성과 애플리케이션 성능 개선을 위해 AWS 데이터베이스 서비스를 사용하고자 합니다. 또한 기본 데이터베이스 시스템의 부하를 줄이기 위해 보고(Reporting) 기능을 별도로 처리하기를 원합니다. 이러한 요구사항을 가장 운영 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111439-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 Oracle DB를 확장성 있고 가용성이 높은 AWS 서비스로 마이그레이션하면서, 읽기 부하(보고 기능)를 기본 DB에서 분리하는 방법을 묻고 있습니다. Oracle RDS에 Multi-AZ Cluster 구성이 불가능하고, Single-AZ로는 가용성이 떨어지며, 여러 리전을 직접 운영하는 것은 복잡도를 높입니다. Amazon Aurora를 Multi-AZ로 구성하면 고가용성과 자동화된 리더 인스턴스를 통해 보고를 별도로 처리하여 성능을 높일 수 있어 운영 효율이 뛰어납니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2",
      "3.3"
    ],
    "Keywords": [
      "가용성",
      "애플리케이션 성능 개선",
      "보고 기능 오프로딩",
      "Multi-AZ",
      "AWS Database 서비스"
    ],
    "Terms": [
      "Oracle Database",
      "Amazon RDS",
      "Multi-AZ Instance Deployment",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon Aurora",
      "Read Replica"
    ],
    "SelectA": "AWS Database Migration Service(AWS DMS)를 사용해 여러 AWS 리전에 Amazon RDS DB 인스턴스를 생성합니다. 보고 기능은 기본 DB 인스턴스와 다른 별도 DB 인스턴스로 지정합니다.",
    "SelectA_Commentary": "멀티 리전을 직접 구성하고 운영해야 하므로 복잡도가 높고, 보고 인스턴스와 기본 인스턴스를 분리하려면 추가 설정이 필요합니다.",
    "SelectB": "Amazon RDS에서 Single-AZ 배포로 Oracle 데이터베이스를 생성합니다. 동일한 가용 영역에 Read Replica를 만들어 보고 기능을 담당하게 합니다.",
    "SelectB_Commentary": "Single-AZ 구성은 고가용성을 보장하지 못하며, 재해 발생 시 가용성 관점에서 취약점이 존재합니다.",
    "SelectC": "Amazon RDS를 Multi-AZ Cluster 배포로 구성하여 Oracle 데이터베이스를 생성합니다. 클러스터 배포의 리더 인스턴스를 통해 보고 기능을 처리합니다.",
    "SelectC_Commentary": "RDS for Oracle은 Multi-AZ Cluster 배포를 지원하지 않아 불가능한 구성입니다.",
    "SelectD": "Amazon RDS를 Multi-AZ Instance 배포로 구성하여 Amazon Aurora 데이터베이스를 생성합니다. 보고 기능은 리더 인스턴스로 오프로딩합니다.",
    "SelectD_Commentary": "Aurora는 Multi-AZ 환경과 자동화된 Read Replica로 높은 가용성과 성능을 제공하며, 보고를 분리해 기본 DB 부하를 줄일 수 있는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q133",
      "Q513",
      "Q1014",
      "Q112",
      "Q363"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q365",
      "Q259"
    ],
    "SelectB_recommedations": [
      "Q978",
      "Q464",
      "Q259"
    ],
    "SelectC_recommedations": [
      "Q978",
      "Q958",
      "Q989"
    ],
    "SelectD_recommedations": [
      "Q601",
      "Q958",
      "Q464"
    ]
  },
  {
    "Question_Number": "Q541",
    "Question_Description": "한 회사가 AWS에서 웹 애플리케이션을 구축하려고 합니다. 웹사이트에 대한 클라이언트 액세스 요청은 예측이 어려우며 오랜 시간 동안 유휴 상태일 수 있습니다. 오직 구독료를 지불한 고객만 웹 애플리케이션에 로그인하여 사용할 수 있어야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하려면 어떤 조합의 단계를 수행해야 합니까? (3개 선택)",
    "Answer": "A,C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111440-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능하고 사용량이 적은 웹 애플리케이션의 로그인을 처리하면서 비용을 최소화하는 아키텍처를 설계하는 것입니다. 서버리스 서비스인 AWS Lambda와 Amazon DynamoDB, Amazon Cognito를 활용하면 사용량이 없을 때 비용이 거의 발생하지 않아 효율적입니다. 또한 AWS Amplify는 프런트엔드 호스팅과 배포를 간소화하며 CloudFront 통합을 통해 전 세계적으로 저렴하고 빠른 콘텐츠 전송이 가능합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "비용 효율적",
      "비정기적 요청",
      "유휴 상태",
      "구독료 지불 고객",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon Cognito",
      "AWS Amplify",
      "Amazon CloudFront"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon API Gateway",
      "Amazon Cognito",
      "AWS Amplify",
      "Amazon CloudFront",
      "Amazon S3"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 Amazon DynamoDB에서 사용자 정보를 가져옵니다. Amazon API Gateway 엔드포인트를 생성하여 RESTful API를 받고, API 호출을 Lambda 함수로 전달합니다.",
    "SelectA_Commentary": "서버리스와 NoSQL DB를 활용한 비용 효율적 조합입니다. 사용이 적을 때 과금이 거의 없으므로 웹 애플리케이션을 유지 비용이 적게 듭니다.",
    "SelectB": "Application Load Balancer 뒤의 Amazon Elastic Container Service(Amazon ECS) 서비스에서 Amazon RDS로부터 사용자 정보를 가져옵니다. Amazon API Gateway 엔드포인트를 생성하여 RESTful API를 받고, API 호출을 Lambda 함수로 전달합니다.",
    "SelectB_Commentary": "ECS와 RDS 구성은 기본 인프라 비용이 들고, 예측 불가능한 트래픽에 대해 Serverless보다 덜 비용 효율적입니다.",
    "SelectC": "사용자 인증을 위해 Amazon Cognito user pool을 생성합니다.",
    "SelectC_Commentary": "user pool은 웹 애플리케이션 사용자를 직접 인증하기 위한 최적의 방법입니다. 구독료를 지불한 사용자만 접근 권한을 부여할 수 있어 보안성과 편의성이 높습니다.",
    "SelectD": "사용자 인증을 위해 Amazon Cognito identity pool을 생성합니다.",
    "SelectD_Commentary": "identity pool은 주로 AWS 자원에 대한 임시 자격 증명을 제공하기 위한 용도로, 사용자를 직접 인증하려는 상황과는 맞지 않습니다.",
    "SelectE": "AWS Amplify를 사용하여 HTML, CSS, JS로 구성된 프런트엔드 웹 콘텐츠를 제공하고, 이를 Amazon CloudFront 통합 구성과 함께 사용합니다.",
    "SelectE_Commentary": "Amplify는 웹 호스팅과 앱 배포를 간소화하고 CloudFront를 통한 글로벌 전송으로 성능과 비용 효율을 높이는 최적의 프런트엔드 솔루션입니다.",
    "SelectF": "Amazon S3 정적 웹 호스팅을 사용하여 PHP, CSS, JS 파일을 제공하고, Amazon CloudFront로 프런트엔드 웹 콘텐츠를 서비스합니다.",
    "SelectF_Commentary": "S3 정적 웹 호스팅은 서버사이드 스크립트(PHP)를 지원하지 않으므로 원하는 기능을 구현하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q985",
      "Q728",
      "Q284",
      "Q943",
      "Q486"
    ],
    "SelectA_recommedations": [
      "Q140",
      "Q770",
      "Q196"
    ],
    "SelectB_recommedations": [
      "Q473",
      "Q146",
      "Q140"
    ],
    "SelectC_recommedations": [
      "Q728",
      "Q284",
      "Q485"
    ],
    "SelectD_recommedations": [
      "Q284",
      "Q728",
      "Q943"
    ],
    "SelectE_recommedations": [
      "Q300",
      "Q485",
      "Q486"
    ],
    "SelectF_recommedations": [
      "Q993",
      "Q300",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q542",
    "Question_Description": "한 미디어 회사가 인터넷을 통해 콘텐츠를 제공하기 위해 Amazon CloudFront distribution을 사용하고 있습니다. 이 회사는 오직 프리미엄 고객만 미디어 스트리밍 및 파일 콘텐츠에 접근할 수 있도록 하길 원합니다. 회사는 모든 콘텐츠를 Amazon S3 bucket에 저장하고 있으며, 영화 대여나 음악 다운로드와 같은 특정 용도로 고객에게 주문형(on-demand) 방식으로 콘텐츠를 제공합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111441-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon CloudFront를 사용해 프리미엄 고객에게만 스트리밍 및 파일 콘텐츠를 제공하기 위한 보안 액세스 제어 방안을 묻습니다. CloudFront signed URLs 또는 signed cookies를 사용하면 콘텐츠에 대한 접근을 특정 사용자나 그룹(프리미엄 고객)으로 제한할 수 있습니다. 이를 통해 링크마다 만료 시간을 설정하거나 접근 권한을 안전하게 부여할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "미디어 스트리밍",
      "프리미엄 고객",
      "Amazon CloudFront distribution",
      "Amazon S3 bucket",
      "영화 대여",
      "음악 다운로드",
      "주문형 콘텐츠"
    ],
    "Terms": [
      "Amazon CloudFront",
      "CloudFront signed URLs",
      "CloudFront signed cookies",
      "Origin Access Control (OAC)",
      "Field-level encryption",
      "Amazon S3"
    ],
    "SelectA": "프리미엄 고객에게 S3 signed cookies를 생성 및 제공한다.",
    "SelectA_Commentary": "S3에는 signed URL 기능이 있지만 'signed cookies'는 CloudFront에서 주로 사용하는 방식이므로, 이 방법은 CloudFront distribution의 접근 제어 요구사항에 적절하지 않습니다.",
    "SelectB": "프리미엄 고객에게 CloudFront signed URLs를 생성하여 제공한다.",
    "SelectB_Commentary": "CloudFront signed URLs는 특정 사용자의 콘텐츠 접근 권한을 시간이나 IP 범위 등으로 제한하는 데 적합하며, 프리미엄 고객에게만 접근 권한을 부여함으로써 요구사항을 충족합니다.",
    "SelectC": "Origin Access Control(OAC)을 사용하여 프리미엄이 아닌 고객의 접근을 제한한다.",
    "SelectC_Commentary": "OAC는 CloudFront가 S3 버킷에 안전하게 액세스하도록 도와주는 기능이지만, 개별 고객(프리미엄 vs 일반)에 대한 세분화된 접근 제어에는 직접적으로 활용하기 어렵습니다.",
    "SelectD": "Field-level encryption을 활성화하여 프리미엄 고객이 아닌 사용자를 차단한다.",
    "SelectD_Commentary": "Field-level encryption은 전송 중 민감 정보를 보호하기 위한 기능으로, 프리미엄 고객 전용 접근 통제를 구현하는 핵심 방법이 아닙니다.",
    "Question_Description_recommedations": [
      "Q131",
      "Q291",
      "Q172",
      "Q216",
      "Q256"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q855",
      "Q172",
      "Q538"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q106",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q265",
      "Q898",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q543",
    "Question_Description": "한 회사가 개별 과금되는 여러 AWS 계정에서 Amazon EC2 인스턴스를 운영하고 있습니다. 이 회사는 최근 Savings Plan을 구매했으나, 비즈니스 요구사항 변화로 다수의 EC2 인스턴스를 더 이상 사용하지 않게 되었습니다. 회사는 이제 남은 Savings Plan 할인을 다른 AWS 계정들에서도 활용하고자 합니다. 이러한 요구사항을 충족하기 위해 어떤 조합의 단계를 수행해야 합니까? (두 가지를 선택하십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111442-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Savings Plan의 할인 혜택을 여러 계정에 공유하려면, Savings Plan을 구매한 계정이 AWS Organizations의 관리 계정이 되어야 하며, 해당 계정에서 discount sharing을 활성화하여야 한다는 점이 핵심입니다. 이를 통해 사용하지 않는 리소스가 많더라도 남은 Savings Plan 할인을 모든 계정에서 효율적으로 활용할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Savings Plan",
      "할인 공유",
      "AWS Organizations",
      "관리 계정"
    ],
    "Terms": [
      "Amazon EC2",
      "Savings Plan",
      "AWS Account Management Console",
      "discount sharing",
      "AWS Organizations",
      "AWS Resource Access Manager (AWS RAM)",
      "management account",
      "billing preferences"
    ],
    "SelectA": "AWS Account Management Console에서 관리 계정을 열고, billing preferences 섹션에서 discount sharing을 켭니다.",
    "SelectA_Commentary": "관리 계정이 이미 Savings Plan을 구매한 계정이어야 적용됩니다. 만약 이 계정이 Savings Plan 구매 계정이 아니라면 단독으로는 요구사항을 충족하기 어렵습니다.",
    "SelectB": "기존 Savings Plan을 구매한 계정의 AWS Account Management Console에서 discount sharing을 활성화하고 모든 계정을 포함하도록 설정합니다.",
    "SelectB_Commentary": "Savings Plan을 구매한 계정이 실제로는 관리 계정일 경우, discount sharing 활성화로 다른 계정들이 해당 할인 혜택을 공유받을 수 있습니다.",
    "SelectC": "AWS Organizations 관리 계정에서 AWS Resource Access Manager(AWS RAM)를 사용해 Savings Plan을 다른 계정에 공유합니다.",
    "SelectC_Commentary": "Savings Plan 할인은 일반적으로 Organizations 내에서 billing preferences를 통해 공유됩니다. AWS RAM은 Savings Plan 자체를 공유하기 위한 수단으로는 사용되지 않습니다.",
    "SelectD": "새로운 결제( payer ) 계정에 AWS Organizations를 생성한 뒤, 관리 계정에서 다른 AWS 계정들을 조직에 초대합니다.",
    "SelectD_Commentary": "새 계정을 별도로 만들면 기존 Savings Plan 계정과 분리됨으로써 설정이 복잡해집니다. 또한 기존 Savings Plan을 바로 활용하기도 어려워 비효율적입니다.",
    "SelectE": "기존 EC2 인스턴스와 Savings Plan이 있는 AWS 계정에서 AWS Organizations를 생성하고, 관리 계정에서 다른 계정들을 초대합니다.",
    "SelectE_Commentary": "Savings Plan을 구매한 계정이 조직 관리 계정이 되면 discount sharing 기능을 켜서 남은 할인을 모든 계정으로 손쉽게 적용할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q885",
      "Q715",
      "Q238",
      "Q671",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q455",
      "Q715",
      "Q300"
    ],
    "SelectB_recommedations": [
      "Q467",
      "Q543",
      "Q885"
    ],
    "SelectC_recommedations": [
      "Q467",
      "Q885",
      "Q715"
    ],
    "SelectD_recommedations": [
      "Q455",
      "Q485",
      "Q541"
    ],
    "SelectE_recommedations": [
      "Q543",
      "Q467",
      "Q885"
    ]
  },
  {
    "Question_Number": "Q544",
    "Question_Description": "한 소매 회사는 퍼블릭 REST API를 위해 regional Amazon API Gateway API를 사용하고 있습니다. API Gateway 엔드포인트에는 Amazon Route 53 alias record로 연결된 커스텀 도메인 이름이 설정되어 있습니다. 솔루션스 아키텍트는 새 API 버전을 출시할 때 고객에게 미치는 영향과 데이터 손실을 최소화해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/111450-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 API Gateway의 새 버전을 고객 영향과 데이터 손실을 최소화하면서 배포하는 최적 해법을 묻습니다. Canary Release 방식을 사용하면 트래픽의 일부만 새 API 버전으로 유도하여 기능을 검증한 뒤, 문제가 없으면 프로덕션에 안전하게 전환할 수 있어 운영 리스크가 매우 낮습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "API Gateway",
      "Route 53 alias record",
      "custom domain name",
      "canary release",
      "minimal data loss",
      "production stage",
      "OpenAPI",
      "import-to-update"
    ],
    "Terms": [
      "Amazon API Gateway",
      "Amazon Route 53",
      "Custom Domain Name",
      "Canary Release Deployment Stage",
      "OpenAPI YAML",
      "OpenAPI JSON",
      "Import-to-Update",
      "Merge Mode",
      "Overwrite Mode",
      "Production Stage"
    ],
    "SelectA": "API Gateway에 canary release deployment stage를 생성합니다. 최신 API 버전을 배포하고, 적절한 비율의 트래픽을 canary stage로 라우팅합니다. 이후 API를 검증한 뒤 canary stage를 프로덕션 stage로 승격시킵니다.",
    "SelectA_Commentary": "이 방식은 검증된 소수 트래픽으로 새 버전을 테스트한 후 프로덕션으로 전환하여 고객 영향과 잠재적 데이터 손실을 최소화할 수 있어 가장 적합합니다.",
    "SelectB": "OpenAPI YAML 파일 형식의 새 버전 API로 새 API Gateway 엔드포인트를 생성합니다. API Gateway에 있는 기존 API에 merge 모드로 import-to-update 작업을 적용한 뒤, 새 API 버전을 프로덕션 stage에 배포합니다.",
    "SelectB_Commentary": "merge 모드는 기존 리소스에 새 리소스를 덧붙이는 방식이지만, 트래픽 전환 과정이 명시되지 않아 안정적인 단계적 전환을 보장하기 어렵습니다.",
    "SelectC": "OpenAPI JSON 파일 형식의 새 버전 API로 새 API Gateway 엔드포인트를 생성합니다. API Gateway에 있는 기존 API에 overwrite 모드로 import-to-update 작업을 적용한 뒤, 새 API 버전을 프로덕션 stage에 배포합니다.",
    "SelectC_Commentary": "overwrite 모드는 기존 설정을 덮어쓰므로 실수 시 즉시 전체가 영향을 받으며, 고객 영향과 데이터 손실 위험이 큽니다.",
    "SelectD": "새 API 정의로 새 API Gateway 엔드포인트를 생성합니다. 새 API Gateway API를 위한 커스텀 도메인 이름을 만든 뒤, Route 53 alias record를 새 API Gateway 커스텀 도메인으로 가리키도록 설정합니다.",
    "SelectD_Commentary": "완전히 별도의 엔드포인트로 전환하기 때문에 도메인 스위칭 시점에서 단절이 발생할 수 있고, 고객에게 즉각적인 영향이 갈 수 있습니다.",
    "Question_Description_recommedations": [
      "Q10",
      "Q545",
      "Q264",
      "Q207",
      "Q228"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q75",
      "Q351"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q207",
      "Q354"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q51",
      "Q207"
    ],
    "SelectD_recommedations": [
      "Q544",
      "Q10",
      "Q545"
    ]
  },
  {
    "Question_Number": "Q545",
    "Question_Description": "한 회사는 주요 웹사이트가 사용할 수 없을 경우, 백업 정적 에러 페이지로 사용자를 안내하고자 합니다. 주요 웹사이트의 DNS 레코드는 Amazon Route 53에서 호스팅 중이며, 도메인은 Application Load Balancer(ALB)를 가리키고 있습니다. 이 회사는 변경 사항과 인프라 오버헤드를 최소화할 수 있는 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116974-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹사이트 장애 시 사용자를 정적 페이지로 안전하게 유도하는 방법을 묻습니다. Route 53 Health Check와 함께 Active-Passive 구조를 구성하면 간단하게 장애 감지 후 S3에 호스팅된 정적 페이지로 트래픽을 전환할 수 있습니다. 최소한의 인프라 변경으로 고가용성과 신속한 장애 대응이 가능하므로 B가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "백업 정적 에러 페이지",
      "Amazon Route 53",
      "Application Load Balancer(ALB)",
      "인프라 오버헤드 최소화",
      "Failover"
    ],
    "Terms": [
      "Amazon Route 53",
      "DNS",
      "Application Load Balancer(ALB)",
      "Amazon S3",
      "Amazon EC2",
      "Multivalue answer routing policy",
      "Latency routing policy",
      "Route 53 active-passive failover",
      "Route 53 active-active configuration",
      "Route 53 health check"
    ],
    "SelectA": "Route 53 레코드를 Latency Routing Policy로 업데이트하고, Amazon S3 버킷에 호스팅된 정적 에러 페이지를 추가해 가장 반응이 빠른 엔드포인트로 트래픽을 전송합니다.",
    "SelectA_Commentary": "Latency 기반 정책은 지연 시간을 기준으로 라우팅하며, 실제 웹사이트 장애 시 즉각적인 대체 페이지 제공을 명확히 보장하지 못합니다.",
    "SelectB": "Route 53 Active-Passive Failover 구성을 설정합니다. ALB가 비정상이면 Route 53 Health Check 결과에 따라 Amazon S3 버킷에 호스팅된 정적 에러 페이지로 트래픽을 전환합니다.",
    "SelectB_Commentary": "정적 페이지가 연결되지 않은 상태로 대기하고, 헬스 체크를 통해 ALB가 다운되면 자동으로 S3 페이지로 전환해 운영 부담이 적고 간단합니다.",
    "SelectC": "ALB와 정적 에러 페이지를 호스팅하는 Amazon EC2 인스턴스를 엔드포인트로 둔 Route 53 Active-Active 구성을 만듭니다. ALB의 헬스 체크가 실패하면 EC2 인스턴스로 요청을 보냅니다.",
    "SelectC_Commentary": "두 엔드포인트를 동시에 활성화하는 방식으로, EC2 인스턴스 운영 및 관리 오버헤드가 커서 최소화 요구사항에 부합하지 않습니다.",
    "SelectD": "Route 53 레코드를 Multivalue Answer Routing Policy로 업데이트하고 헬스 체크를 생성합니다. 헬스 체크가 통과되면 웹사이트로, 실패 시 Amazon S3에 호스팅된 정적 에러 페이지로 트래픽을 전송합니다.",
    "SelectD_Commentary": "Multivalue Answer는 여러 IP 응답을 통해 간단한 가용성 향상을 도모하지만, Active-Passive Failover 대비 구성 복잡도가 높고 제어가 제한적입니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q627",
      "Q1012",
      "Q537",
      "Q293"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q264",
      "Q188"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q836",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q813",
      "Q405"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q544",
      "Q264"
    ]
  },
  {
    "Question_Number": "Q546",
    "Question_Description": "최근 회사의 IT 비용 분석 결과, 백업 비용 절감이 필요함이 강조되었습니다. 최고 정보 책임자는 물리적 백업 테이프 사용을 중단하여 온프레미스 백업 인프라를 단순화하고 비용을 절감하고자 합니다. 단, 기존 온프레미스 백업 애플리케이션과 워크플로에 대한 투자는 그대로 유지해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 어떤 방안을 제안해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116975-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 기존의 테이프 기반 백업 워크플로를 그대로 사용하면서 물리적 테이프를 제거하고 비용을 절감하는 방법을 찾는 것입니다. Amazon EFS는 테이프 기반 애플리케이션과 직접 연동하기 어렵고, NFS 인터페이스 또한 테이프 장치를 에뮬레이션하지 못합니다. 반면 AWS Storage Gateway의 iSCSI-VTL 인터페이스는 기존 백업 소프트웨어가 인식하는 가상 테이프 라이브러리를 제공해 물리적 테이프 없이도 동일한 프로세스를 유지하도록 돕습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "백업 비용 절감",
      "물리적 백업 테이프 제거",
      "온프레미스 백업 애플리케이션",
      "AWS Storage Gateway",
      "iSCSI-virtual tape library(VTL)",
      "기존 투자 보존"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Amazon EFS",
      "NFS",
      "iSCSI",
      "VTL",
      "온프레미스 백업 인프라"
    ],
    "SelectA": "AWS Storage Gateway를 NFS 인터페이스로 백업 애플리케이션에 연결합니다.",
    "SelectA_Commentary": "NFS 인터페이스를 사용하면 일반 파일 공유 기능만 제공되므로 테이프 워크플로 그대로 사용하기에는 제한이 큽니다.",
    "SelectB": "Amazon EFS 파일 시스템을 NFS 인터페이스로 백업 애플리케이션에 연결합니다.",
    "SelectB_Commentary": "Amazon EFS는 네트워크 파일 시스템 기능만 제공하므로, 기존 테이프 기반 워크플로를 유지하기 위한 가상 테이프 기능을 제공하지 못합니다.",
    "SelectC": "Amazon EFS 파일 시스템을 iSCSI 인터페이스로 백업 애플리케이션에 연결합니다.",
    "SelectC_Commentary": "Amazon EFS는 iSCSI 인터페이스를 제공하지 않으므로, 테이프 가상화 방식의 요구사항을 충족할 수 없습니다.",
    "SelectD": "AWS Storage Gateway를 iSCSI-virtual tape library(VTL) 인터페이스로 백업 애플리케이션에 연결합니다.",
    "SelectD_Commentary": "기존 테이프 기반 백업 시스템에서 사용하는 워크플로를 그대로 유지하면서 물리적 테이프 대신 가상 테이프를 활용해 비용을 절감할 수 있는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q643",
      "Q872",
      "Q124",
      "Q63",
      "Q309"
    ],
    "SelectA_recommedations": [
      "Q703",
      "Q617",
      "Q806"
    ],
    "SelectB_recommedations": [
      "Q703",
      "Q617",
      "Q806"
    ],
    "SelectC_recommedations": [
      "Q307",
      "Q277",
      "Q719"
    ],
    "SelectD_recommedations": [
      "Q307",
      "Q300",
      "Q471"
    ]
  },
  {
    "Question_Number": "Q547",
    "Question_Description": "한 회사는 서로 다른 위치에 데이터 수집 센서들을 두고 있습니다. 이 센서들은 대량의 데이터를 실시간에 가깝게 스트림 형태로 전송합니다. 회사는 AWS 상에서 이러한 대용량 스트리밍 데이터를 수집 및 처리할 수 있는 플랫폼을 설계하고자 합니다. 솔루션은 확장 가능해야 하며, 거의 실시간으로 데이터 수집을 지원해야 합니다. 또한 추후 보고를 위해 Amazon S3에 데이터를 저장해야 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116976-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 센서에서 발생하는 대량의 스트리밍 데이터를 빠르고 간단하게 수집·처리하고, 확장성을 유지하면서 Amazon S3에 저장하는 방법을 묻습니다. 가장 운영 오버헤드가 적으면서 거의 실시간 데이터를 반복적으로 전송·처리하기 위해서는 완전관리형 스트리밍 서비스인 Amazon Kinesis Data Firehose가 최적의 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "대용량 스트리밍 데이터",
      "확장 가능",
      "실시간 데이터 수집",
      "Amazon S3 저장",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "AWS Glue",
      "AWS Lambda",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon S3"
    ],
    "SelectA": "Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 Amazon S3로 전송합니다.",
    "SelectA_Commentary": "Kinesis Data Firehose는 설정만으로 자동 확장, 배치, 압축 등을 제공하므로 운영 오버헤드가 최소화되고 실시간에 가까운 데이터 수집이 가능합니다. 따라서 가장 적합한 솔루션입니다.",
    "SelectB": "AWS Glue를 사용하여 스트리밍 데이터를 Amazon S3로 전송합니다.",
    "SelectB_Commentary": "AWS Glue는 주로 ETL 작업 및 데이터 카탈로그에 초점을 맞춘 서비스로, 직접 실시간 스트리밍 수집을 수행하기에는 적합하지 않습니다.",
    "SelectC": "AWS Lambda를 사용하여 스트리밍 데이터를 전송하고 Amazon S3에 저장합니다.",
    "SelectC_Commentary": "Lambda 함수를 직접 트리거하고 관리를 수행해야 하므로 운영 및 확장에 대한 오버헤드가 큽니다. 처리량이 많은 스트리밍 환경에서는 관리 부담과 비용이 늘어날 수 있습니다.",
    "SelectD": "AWS Database Migration Service (AWS DMS)를 사용하여 스트리밍 데이터를 Amazon S3로 전송합니다.",
    "SelectD_Commentary": "AWS DMS는 주로 데이터베이스 간 마이그레이션 및 동기화에 특화된 서비스이므로 센서 스트리밍 데이터를 처리하기에는 비효율적이고 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q155",
      "Q626",
      "Q501",
      "Q43"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q501",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q155",
      "Q501",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q672",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q292",
      "Q155",
      "Q834"
    ]
  },
  {
    "Question_Number": "Q548",
    "Question_Description": "회사는 재무, 데이터 분석, 개발 부서를 위해 각각 별도의 AWS 계정을 가지고 있습니다. 비용 및 보안 문제로 인해, 회사는 각 AWS 계정에서 어떤 서비스들을 사용할 수 있는지 제어하기를 원합니다. 이 요구사항을 최소한의 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116977-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 부서별로 분리된 AWS 계정에서 사용 가능한 서비스를 중앙에서 효율적으로 제어하는 방법을 묻고 있습니다. 비용 및 보안 측면에서 부담을 줄이려면 한 곳에서 각 계정에 대한 정책을 손쉽게 적용해야 합니다. AWS Organizations의 OU와 SCP를 통해 계정 수준에서 허용/제한할 수 있는 서비스 목록을 중앙에서 관리할 수 있습니다. 이는 운영 오버헤드를 최소화하면서도 보안 요구사항과 비용 관리 모두에 효과적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "부서별 AWS 계정",
      "비용 및 보안 문제",
      "사용 서비스 제어",
      "최소한의 운영 오버헤드"
    ],
    "Terms": [
      "AWS account",
      "AWS Organizations",
      "Organization Unit (OU)",
      "Service Control Policies (SCP)",
      "AWS Systems Manager templates",
      "AWS CloudFormation",
      "AWS Service Catalog"
    ],
    "SelectA": "AWS Systems Manager templates를 사용하여 각 부서가 사용할 수 있는 AWS 서비스를 제어합니다.",
    "SelectA_Commentary": "Systems Manager templates는 계정마다 템플릿을 따로 관리해야 하므로 운영이 복잡해지고, 자동화 범위가 제한적입니다.",
    "SelectB": "AWS Organizations에서 각 부서를 위한 Organization Unit (OU)을 생성하고, 해당 OU에 Service Control Policies (SCP)를 연결합니다.",
    "SelectB_Commentary": "AWS Organizations를 통한 OU와 SCP 사용은 중앙에서 각 부서의 계정에 허용할 서비스 목록을 간단히 제한할 수 있어 운영 오버헤드가 최소화되는 정답입니다.",
    "SelectC": "AWS CloudFormation을 사용하여 각 부서가 사용할 수 있는 AWS 서비스만 자동으로 프로비저닝합니다.",
    "SelectC_Commentary": "CloudFormation 템플릿으로 필요한 리소스만 생성은 가능하나, 애초부터 비허용 서비스를 막기엔 한계가 있으며 변경 및 유지보수도 어렵습니다.",
    "SelectD": "각 AWS 계정에 AWS Service Catalog의 제품 목록을 설정하여 특정 AWS 서비스 사용을 관리 및 제어합니다.",
    "SelectD_Commentary": "Service Catalog는 제품 포트폴리오 관리를 위한 도구로, 기반 서비스 전체를 세밀히 제한하기에는 적합하지 않아 운영 부담이 증가합니다.",
    "Question_Description_recommedations": [
      "Q922",
      "Q313",
      "Q831",
      "Q592",
      "Q529"
    ],
    "SelectA_recommedations": [
      "Q970",
      "Q529",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q560",
      "Q709",
      "Q988"
    ],
    "SelectC_recommedations": [
      "Q970",
      "Q529",
      "Q387"
    ],
    "SelectD_recommedations": [
      "Q970",
      "Q34",
      "Q529"
    ]
  },
  {
    "Question_Number": "Q549",
    "Question_Description": "한 회사가 자사의 전자상거래 웹사이트를 위해 다중 계층 애플리케이션을 만들었습니다. 해당 웹사이트는 퍼블릭 서브넷에 위치한 Application Load Balancer, 퍼블릭 서브넷에 있는 웹 계층, 그리고 프라이빗 서브넷에 위치한 Amazon EC2 인스턴스에서 호스팅되는 MySQL 클러스터를 사용하고 있습니다. 이 MySQL 데이터베이스는 서드파티 공급자에 의해 인터넷에서 호스팅되는 상품 카탈로그와 가격 정보를 조회해야 합니다. Solutions Architect는 운영 오버헤드를 증가시키지 않으면서 보안을 최대화할 수 있는 전략을 고안해야 합니다. 이러한 요구사항을 만족하는 방법은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116978-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 퍼블릭 서브넷에 있는 웹 계층과 프라이빗 서브넷에 있는 MySQL 클러스터가 외부 인터넷에서 호스팅되는 데이터를 안전하게 가져오도록 구성해야 하는 시나리오입니다. 가장 안전하고 관리가 간편한 방법은 NAT gateway를 퍼블릭 서브넷에 두고, 프라이빗 서브넷의 라우트 테이블을 NAT gateway로 향하게 하여 아웃바운드만 허용하는 구조로 만드는 것입니다. 이는 보안이 강화되고, 추가 관리 부담 없이 인터넷 접근이 가능해집니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "전자상거래 웹사이트",
      "다중 계층 애플리케이션",
      "Application Load Balancer",
      "MySQL",
      "프라이빗 서브넷",
      "NAT gateway"
    ],
    "Terms": [
      "Application Load Balancer",
      "Public Subnets",
      "MySQL",
      "Amazon EC2",
      "Private Subnets",
      "NAT instance",
      "NAT gateway",
      "Internet gateway",
      "Virtual private gateway",
      "Route table"
    ],
    "SelectA": "NAT instance를 VPC에 배포하고, 모든 인터넷 기반 트래픽을 NAT instance를 통해 라우팅합니다.",
    "SelectA_Commentary": "NAT instance는 관리 부담이 크고 고가용성 구성이 번거롭습니다. 또한 스케일링 이슈 등 운영 오버헤드가 NAT gateway 대비 높습니다.",
    "SelectB": "퍼블릭 서브넷에 NAT gateway를 배포합니다. private 서브넷의 라우트 테이블을 수정하여 인터넷으로 나가는 트래픽을 NAT gateway로 전송하도록 설정합니다.",
    "SelectB_Commentary": "NAT gateway는 관리가 간편하고, 고가용성과 확장성을 기본 제공하므로 운영 오버헤드가 낮고 보안도 극대화됩니다. 정답입니다.",
    "SelectC": "인터넷 게이트웨이를 구성하고 VPC에 연결한 뒤, private 서브넷의 라우트 테이블을 인터넷 게이트웨이로 직접 수정합니다.",
    "SelectC_Commentary": "프라이빗 서브넷이 인터넷 게이트웨이에 직접 연결되면 외부에서 인바운드 접근이 가능해져 보안 취약성이 높아집니다. 원하는 보안 요구사항과 맞지 않습니다.",
    "SelectD": "Virtual private gateway를 구성하고 VPC에 연결한 다음, private 서브넷의 라우트 테이블을 가상 프라이빗 게이트웨이로 지정합니다.",
    "SelectD_Commentary": "Virtual private gateway는 온프레미스 VPN 연결 등 전용 통신용으로 사용됩니다. 인터넷 핸들링 용도로는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q82",
      "Q85",
      "Q393",
      "Q26",
      "Q11"
    ],
    "SelectA_recommedations": [
      "Q468",
      "Q151",
      "Q950"
    ],
    "SelectB_recommedations": [
      "Q803",
      "Q774",
      "Q468"
    ],
    "SelectC_recommedations": [
      "Q950",
      "Q893",
      "Q468"
    ],
    "SelectD_recommedations": [
      "Q950",
      "Q468",
      "Q555"
    ]
  },
  {
    "Question_Number": "Q550",
    "Question_Description": "한 회사가 AWS KMS 키를 사용해 AWS Lambda 환경 변수를 암호화하고 있습니다. 솔루션스 아키텍트는 환경 변수를 복호화하고 사용하는 데 필요한 권한이 적절히 구성되어 있는지 확인해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트가 수행해야 하는 단계는 무엇입니까? (2개를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116979-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 암호화된 Lambda 환경 변수를 사용하기 위해 AWS KMS 키와 Lambda 실행 역할 간의 적절한 권한 관계를 설정하는 방법을 묻습니다. 필요한 권한은 Lambda 실행 역할의 정책과 KMS 키 정책 모두에 설정되어야 합니다. 즉, Lambda 실행 역할에는 kms:Decrypt, kms:GenerateDataKey 권한이 있어야 하며, 해당 KMS 키 정책 또한 Lambda 실행 역할을 허용 주체로 지정해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS KMS",
      "Lambda 환경 변수",
      "권한 구성",
      "kms:Decrypt",
      "kms:GenerateDataKey",
      "KMS 키 정책",
      "Lambda 실행 역할"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "AWS Lambda",
      "Lambda execution role",
      "KMS key policy",
      "kms:Decrypt",
      "kms:GenerateDataKey"
    ],
    "SelectA": "Lambda 리소스 정책에 AWS KMS 권한을 추가한다.",
    "SelectA_Commentary": "Lambda 리소스 정책은 주로 함수 자체에 대한 접근 권한을 제어합니다. KMS 액세스 권한을 설정하는 데에는 적절하지 않습니다.",
    "SelectB": "Lambda 실행 역할에 AWS KMS 권한을 추가한다.",
    "SelectB_Commentary": "Lambda 함수가 kms:Decrypt 및 kms:GenerateDataKey를 호출하기 위해서는 Lambda 실행 역할에 명시적으로 이러한 권한들이 필요합니다. (정답)",
    "SelectC": "Lambda 함수 정책에 AWS KMS 권한을 추가한다.",
    "SelectC_Commentary": "Lambda 함수 자체는 별도의 함수 정책으로 KMS 권한을 설정하지 않습니다. 실행 역할을 통해 권한이 부여되어야 합니다.",
    "SelectD": "AWS KMS 키 정책에서 Lambda 실행 역할을 허용한다.",
    "SelectD_Commentary": "KMS 키 정책 역시 Lambda의 실행 역할을 주체로 허용해야 합니다. 그렇지 않으면 해당 키를 사용해 환경 변수를 복호화할 수 없습니다. (정답)",
    "SelectE": "AWS KMS 키 정책에서 Lambda 리소스 정책을 허용한다.",
    "SelectE_Commentary": "Lambda 리소스 정책이 아니라 Lambda 실행 역할에 대해 KMS 키 정책을 허용해야 합니다. 리소스 정책을 허용해도 KMS 기능 사용이 보장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q640",
      "Q916",
      "Q936",
      "Q1009",
      "Q371"
    ],
    "SelectA_recommedations": [
      "Q550",
      "Q640",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q550",
      "Q640",
      "Q936"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q640",
      "Q936"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q640",
      "Q916"
    ],
    "SelectE_recommedations": [
      "Q550",
      "Q640",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q551",
    "Question_Description": "한 회사가 재무 애플리케이션을 통해 보고서를 생성하고 있습니다. 보고서의 평균 크기는 50KB이며 Amazon S3에 저장됩니다. 보고서는 생성 후 첫 일주일 동안 자주 조회되며, 몇 년간 보관해야 합니다. 또한 보고서는 6시간 이내에 복원이 가능해야 합니다. 어떤 솔루션이 가장 비용 효율적으로 이러한 요구사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116896-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 짧은 기간(첫 7일) 동안은 잦은 조회가 필요하고 이후에는 몇 년간 장기 보관이 필요한 보고서를 어떻게 비용 효율적으로 저장할지 묻습니다. S3 Glacier는 표준 복원 시 3~5시간으로 6시간 이내 복원을 충족하며, 장기 보관 비용도 낮아 정답이 됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "재무 애플리케이션",
      "보고서",
      "Amazon S3",
      "6시간 이내 복원",
      "7일 후 전환",
      "S3 Glacier"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Standard",
      "S3 Glacier",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Intelligent-Tiering",
      "S3 Glacier Deep Archive",
      "S3 Lifecycle rule"
    ],
    "SelectA": "S3 Standard를 사용합니다. 7일 후 S3 Lifecycle rule을 통해 보고서를 S3 Glacier로 전환합니다.",
    "SelectA_Commentary": "S3 Glacier의 표준 복원 시간(3~5시간)은 6시간 이내 요구사항을 충족하며, 장기 보관 비용도 낮아 가장 적합합니다.",
    "SelectB": "S3 Standard를 사용합니다. 7일 후 S3 Lifecycle rule을 통해 보고서를 S3 Standard-IA로 전환합니다.",
    "SelectB_Commentary": "S3 Standard-IA도 비용 절감에 도움이 되지만, 장기 보관에는 Glacier보다 비용 효율이 떨어집니다.",
    "SelectC": "S3 Intelligent-Tiering을 사용합니다. 보고서를 S3 Standard-IA와 S3 Glacier로 전환하도록 구성합니다.",
    "SelectC_Commentary": "Intelligent-Tiering은 자동 분류가 장점이지만 작은 파일에 대한 관리 수수료가 있고, 지정한 주기가 확실하다면 일반 Lifecycle 전환이 더 경제적입니다.",
    "SelectD": "S3 Standard를 사용합니다. 7일 후 S3 Lifecycle rule을 통해 보고서를 S3 Glacier Deep Archive로 전환합니다.",
    "SelectD_Commentary": "S3 Glacier Deep Archive는 최소 12시간 소요되어 6시간 이내 복원 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q66",
      "Q153",
      "Q1003",
      "Q759",
      "Q890"
    ],
    "SelectA_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q486",
      "Q943",
      "Q126"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ]
  },
  {
    "Question_Number": "Q552",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스의 비용을 최적화해야 합니다. 또한 2~3개월마다 EC2 인스턴스 유형과 패밀리를 변경해야 합니다. 이 요구사항을 충족하기 위해서는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116897-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스 비용을 절감하면서도 인스턴스 유형과 패밀리를 자주 변경해야 하는 유연성이 핵심입니다. Reserved Instances는 특정 유형 또는 패밀리에 묶여 있어 변경이 어렵고, EC2 Instance Savings Plan 역시 인스턴스 패밀리에 제약이 있습니다. 반면 Compute Savings Plan은 인스턴스 유형과 패밀리를 자유롭게 변경할 수 있으므로 요구사항을 충족합니다. No Upfront 옵션은 초기 비용 부담 없이 월 사용량에 따라 비용이 청구되어 유연성과 비용 최적화를 모두 달성할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "비용 최적화",
      "유연성",
      "인스턴스 유형 변경",
      "Compute Savings Plan",
      "No Upfront"
    ],
    "Terms": [
      "Amazon EC2",
      "Reserved Instances",
      "Compute Savings Plan",
      "No Upfront",
      "All Upfront",
      "Partial Upfront",
      "Instance Family"
    ],
    "SelectA": "3년 기간의 Partial Upfront Reserved Instances를 구매합니다.",
    "SelectA_Commentary": "Reserved Instances는 특정 인스턴스 유형과 패밀리에 묶이므로 2~3개월마다 변경하는 유연성을 제공하지 못합니다.",
    "SelectB": "1년 기간의 No Upfront Compute Savings Plan을 구매합니다.",
    "SelectB_Commentary": "Compute Savings Plan은 다양한 인스턴스 유형과 패밀리로 자유롭게 전환 가능하며, No Upfront 옵션으로 초기 비용 없이 월 단위로 지불하므로 요구되는 유연성과 비용 절감을 모두 충족합니다.",
    "SelectC": "1년 기간의 All Upfront Reserved Instances를 구매합니다.",
    "SelectC_Commentary": "Reserved Instances는 인스턴스 유형과 패밀리 변경에 제약이 크며 선불 결제로 재정 부담이 커집니다.",
    "SelectD": "1년 기간의 All Upfront EC2 Instance Savings Plan을 구매합니다.",
    "SelectD_Commentary": "EC2 Instance Savings Plan은 Compute Savings Plan에 비해 인스턴스 패밀리 변경에 제약이 있어 문제의 요구사항을 완전히 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q347",
      "Q238",
      "Q671",
      "Q993",
      "Q167"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q486",
      "Q767"
    ],
    "SelectB_recommedations": [
      "Q49",
      "Q630",
      "Q147"
    ],
    "SelectC_recommedations": [
      "Q486",
      "Q943",
      "Q49"
    ],
    "SelectD_recommedations": [
      "Q885",
      "Q543",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q553",
    "Question_Description": "한 솔루션스 아키텍트는 회사의 Amazon S3 버킷을 검토하여 개인식별정보(PII)를 찾아야 합니다. 회사는 us-east-1 리전과 us-west-2 리전에 PII 데이터를 저장하고 있습니다. 이 요구사항을 만족하면서 가장 적은 운영 오버헤드로 해결할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117206-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 리전에 저장된 PII 데이터를 효과적으로 식별하고 운영 오버헤드를 최소화하는 방법을 묻습니다. Amazon Macie는 PII 탐지 기능을 제공하며, 필요한 리전에만 설정해 자동화된 방식으로 S3 데이터를 검사할 수 있어 가장 적합한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "개인식별정보(PII)",
      "us-east-1 리전",
      "us-west-2 리전",
      "Amazon Macie",
      "운영 오버헤드"
    ],
    "Terms": [
      "Amazon S3",
      "PII",
      "Amazon Macie",
      "AWS Security Hub",
      "AWS Config",
      "Amazon Inspector",
      "Amazon GuardDuty"
    ],
    "SelectA": "각 리전에서 Amazon Macie를 구성합니다. Amazon S3의 데이터를 분석하는 Job을 생성합니다.",
    "SelectA_Commentary": "Amazon Macie는 S3 내 PII 데이터를 자동 검색하고 분류하는 데 특화된 전용 서비스로, 최소한의 운영 부담으로 목적을 달성할 수 있는 최적의 선택입니다.",
    "SelectB": "모든 리전에 AWS Security Hub를 구성합니다. Amazon S3에 있는 데이터를 분석할 AWS Config rule을 생성합니다.",
    "SelectB_Commentary": "Security Hub는 전 계정 보안 모니터링 중심 서비스로, PII 식별만을 위해서는 과도한 설정이 필요해 운영 오버헤드가 높습니다.",
    "SelectC": "Amazon S3에 있는 데이터를 분석하도록 Amazon Inspector를 구성합니다.",
    "SelectC_Commentary": "Amazon Inspector는 주로 OS 및 애플리케이션 취약점 스캔에 주력하는 서비스로, S3 내 PII 식별에는 적합하지 않습니다.",
    "SelectD": "Amazon S3에 있는 데이터를 분석하도록 Amazon GuardDuty를 구성합니다.",
    "SelectD_Commentary": "GuardDuty는 악성 활동 및 비정상 동작 탐지에 초점을 맞춘 보안 서비스이므로, PII 식별 기능을 제공하지 않습니다.",
    "Question_Description_recommedations": [
      "Q533",
      "Q756",
      "Q295",
      "Q838",
      "Q974"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q889",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q825",
      "Q678"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q554",
    "Question_Description": "한 회사가 사내 환경에서 SAP 애플리케이션의 백엔드로 SQL Server 데이터베이스를 운영 중입니다. 회사는 이 온프레미스 애플리케이션과 데이터베이스 서버를 AWS로 마이그레이션하려고 합니다. SAP 데이터베이스의 높은 요구사항을 충족할 인스턴스 타입이 필요합니다. 온프레미스 성능 자료에 따르면 SAP 애플리케이션과 데이터베이스 모두 메모리 사용률이 높습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117442-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 메모리 집중형 워크로드인 SAP 애플리케이션과 SQL Server 데이터베이스를 모두 만족시키는 인스턴스 패밀리 선택에 대한 것입니다. Memory optimized 인스턴스는 고메모리 요구사항을 충족하고 운영 복잡성을 줄이므로 적합한 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.3"
    ],
    "Keywords": [
      "SAP 애플리케이션",
      "SQL Server 데이터베이스",
      "메모리 사용률",
      "인스턴스 타입",
      "마이그레이션"
    ],
    "Terms": [
      "Memory optimized instance",
      "Compute optimized instance",
      "Storage optimized instance",
      "High performance computing (HPC) optimized instance",
      "SAP",
      "SQL Server"
    ],
    "SelectA": "애플리케이션에는 compute optimized 인스턴스 패밀리를, 데이터베이스에는 memory optimized 인스턴스 패밀리를 사용합니다.",
    "SelectA_Commentary": "애플리케이션 또한 메모리 사용량이 높으므로 compute optimized보다 memory optimized가 더 적합합니다. 이 방식은 애플리케이션에 충분한 메모리를 보장하지 못합니다.",
    "SelectB": "애플리케이션과 데이터베이스 모두에 storage optimized 인스턴스 패밀리를 사용합니다.",
    "SelectB_Commentary": "storage optimized는 디스크 I/O 위주의 워크로드에 최적화되어 있어, 메모리 중심의 SAP 워크로드에는 부적합합니다.",
    "SelectC": "애플리케이션과 데이터베이스 모두에 memory optimized 인스턴스 패밀리를 사용합니다.",
    "SelectC_Commentary": "두 워크로드 모두 높은 메모리를 요구하므로 하나의 패밀리를 쓰면 운영이 단순해지고 성능도 극대화됩니다. 정답입니다.",
    "SelectD": "애플리케이션에는 high performance computing(HPC) optimized 인스턴스를, 데이터베이스에는 memory optimized 인스턴스를 사용합니다.",
    "SelectD_Commentary": "HPC 인스턴스는 과도하게 높은 컴퓨팅 리소스를 제공하여 비용이 증가하며, 메모리 위주인 SAP 애플리케이션에는 불필요합니다.",
    "Question_Description_recommedations": [
      "Q192",
      "Q565",
      "Q650",
      "Q568",
      "Q292"
    ],
    "SelectA_recommedations": [
      "Q143",
      "Q496",
      "Q746"
    ],
    "SelectB_recommedations": [
      "Q496",
      "Q622",
      "Q1000"
    ],
    "SelectC_recommedations": [
      "Q77",
      "Q888",
      "Q622"
    ],
    "SelectD_recommedations": [
      "Q857",
      "Q795",
      "Q646"
    ]
  },
  {
    "Question_Number": "Q555",
    "Question_Description": "한 회사가 public 및 private 서브넷을 갖춘 VPC에서 애플리케이션을 운영하고 있습니다. 이 VPC는 여러 가용 영역에 걸쳐 있습니다. 애플리케이션은 private 서브넷의 Amazon EC2 인스턴스에서 실행되며, Amazon Simple Queue Service(Amazon SQS) 큐를 사용합니다. 솔루션스 아키텍트는 EC2 인스턴스와 SQS 큐 간에 보안 연결을 설정하기 위한 솔루션을 설계해야 합니다. 어떤 솔루션이 이 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116983-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스가 Amazon SQS 큐에 인터넷을 거치지 않고 안전하게 접근해야 하는 상황입니다. Interface VPC Endpoint를 private 서브넷에 구성하고 보안 그룹을 통해 트래픽을 제한하면 보안성을 높일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "보안 연결",
      "Amazon SQS 큐",
      "EC2 인스턴스",
      "private 서브넷",
      "Interface VPC Endpoint"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon SQS",
      "Interface VPC Endpoint",
      "Gateway Endpoint",
      "Security Group",
      "IAM role",
      "VPC Endpoint Policy",
      "Amazon SQS Access Policy",
      "NAT Gateway",
      "Inbound Access Rule"
    ],
    "SelectA": "Interface VPC Endpoint for Amazon SQS를 구현합니다. 이 Endpoint를 private 서브넷에서 사용하도록 설정하고, inbound 트래픽을 private 서브넷의 EC2 인스턴스만 허용하는 Security Group을 추가합니다.",
    "SelectA_Commentary": "Interface VPC Endpoint를 사용하면 VPC 내부 트래픽만으로 SQS에 접속 가능하여 인터넷 노출이 없으므로 가장 안전하고 권장되는 솔루션입니다.",
    "SelectB": "Interface VPC Endpoint for Amazon SQS를 구현합니다. 이 Endpoint를 public 서브넷에서 사용하도록 설정하고, private 서브넷의 EC2 인스턴스만 접근을 허용하도록 VPC Endpoint Policy를 연결합니다.",
    "SelectB_Commentary": "public 서브넷에 Endpoint를 두면 외부에 노출될 가능성이 있고, 트래픽의 안전성도 상대적으로 낮아 보안 요구사항을 충분히 만족하기 어렵습니다.",
    "SelectC": "Interface VPC Endpoint for Amazon SQS를 구현합니다. 이 Endpoint를 public 서브넷에 사용하도록 설정하고, 특정 VPC Endpoint만 요청을 허용하도록 하는 Amazon SQS Access Policy를 붙입니다.",
    "SelectC_Commentary": "마찬가지로 public 서브넷을 거치므로 보안 관점에서 권장되지 않습니다. Access Policy만으로는 VPC 내부 트래픽 보호가 완벽하지 않습니다.",
    "SelectD": "Gateway Endpoint for Amazon SQS를 구현합니다. private 서브넷에 NAT Gateway를 추가하고 EC2 인스턴스에 SQS 큐 접근을 허용하는 IAM role을 부착합니다.",
    "SelectD_Commentary": "SQS는 Gateway Endpoint 대상이 아니므로 사용 불가능하며, NAT Gateway를 거치는 방식은 불필요한 비용과 설정 복잡성을 높입니다.",
    "Question_Description_recommedations": [
      "Q610",
      "Q998",
      "Q55",
      "Q251",
      "Q866"
    ],
    "SelectA_recommedations": [
      "Q555",
      "Q91",
      "Q251"
    ],
    "SelectB_recommedations": [
      "Q555",
      "Q91",
      "Q610"
    ],
    "SelectC_recommedations": [
      "Q555",
      "Q91",
      "Q792"
    ],
    "SelectD_recommedations": [
      "Q364",
      "Q1016",
      "Q1019"
    ]
  },
  {
    "Question_Number": "Q556",
    "Question_Description": "한 솔루션스 아키텍트가 AWS CloudFormation 템플릿을 사용해 3티어 웹 애플리케이션을 배포하고 있습니다. 이 웹 애플리케이션은 웹 티어와 애플리케이션 티어로 구성되며, Amazon DynamoDB 테이블에 사용자 데이터를 저장하고 조회합니다. 웹과 애플리케이션 티어는 Amazon EC2 인스턴스에서 호스팅되고, 데이터베이스 티어는 공개적으로 접근할 수 없습니다. 애플리케이션 EC2 인스턴스는 DynamoDB 테이블에 접근해야 하지만, 템플릿에 API 자격 증명을 노출해서는 안 됩니다. 이 요구사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117434-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudFormation 템플릿에서 DynamoDB 권한을 안전하게 관리하는 방법을 묻습니다. IAM role과 EC2 instance profile을 활용하면 민감한 자격 증명 없이 EC2에서 DynamoDB를 사용할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM role",
      "EC2 instance profile",
      "DynamoDB 접근",
      "API 자격 증명 노출 방지"
    ],
    "Terms": [
      "AWS CloudFormation",
      "Amazon EC2",
      "Amazon DynamoDB",
      "IAM role",
      "Instance Profile",
      "API credentials"
    ],
    "SelectA": "IAM role을 생성해 DynamoDB 테이블에 대한 읽기 권한을 부여하고, 애플리케이션 인스턴스에 instance profile로 연결합니다.",
    "SelectA_Commentary": "읽기 권한만 포함되어 쓰기가 필요한 경우 부족하며, 요구사항을 전부 충족하지 못합니다.",
    "SelectB": "DynamoDB 테이블에 읽기/쓰기를 할 수 있는 권한을 가진 IAM role을 생성합니다. 해당 role을 EC2 instance profile에 추가하고 애플리케이션 인스턴스에 연동합니다.",
    "SelectB_Commentary": "정답입니다. EC2 인스턴스에서 자격 증명을 노출하지 않고 DynamoDB 접근 권한을 안전하게 제공할 수 있습니다.",
    "SelectC": "AWS CloudFormation 템플릿의 Parameter 섹션에서 기존 IAM 사용자의 access key와 secret key를 입력받아 사용합니다.",
    "SelectC_Commentary": "사용자의 자격 증명을 직접 템플릿에 입력받으면 보안 리스크가 커지며, 요구사항에 어긋납니다.",
    "SelectD": "AWS CloudFormation 템플릿에서 DynamoDB에 대한 읽기/쓰기 권한이 있는 IAM 사용자를 생성하고, GetAtt 함수를 통해 키를 가져와 EC2 user data로 전달합니다.",
    "SelectD_Commentary": "IAM 사용자 키를 직접 전달하는 방식은 자격 증명을 노출하므로, 보안 관점에서 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q907",
      "Q176",
      "Q854",
      "Q17",
      "Q208"
    ],
    "SelectA_recommedations": [
      "Q279",
      "Q727",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q387",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q556",
      "Q176",
      "Q562"
    ]
  },
  {
    "Question_Number": "Q557",
    "Question_Description": "한 솔루션스 아키텍트가 분석 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 대량의 반정형 데이터를 Amazon S3 버킷에 저장합니다. 솔루션스 아키텍트는 데이터를 더 빠르게 처리하기 위해 병렬 데이터 처리를 활용하고 싶습니다. 또한 Amazon Redshift 데이터베이스에 저장된 정보를 사용해 데이터를 보강하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117344-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 반정형 데이터를 효율적으로 처리하고 Redshift 데이터로 추가 정보까지 결합해야 하는 상황입니다. 병렬 처리를 통한 빠른 작업이 중요하며, EMR은 Hadoop 기반 클러스터로 확장 가능하고 S3와 직접 연동하여 대량 데이터를 병렬로 처리할 수 있습니다. 또한 EMR-Redshift 통합을 통해 Redshift 정보를 활용하여 S3의 데이터를 쉽게 보강할 수 있으므로 가장 적합한 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "대량의 반정형 데이터",
      "Amazon S3",
      "병렬 데이터 처리",
      "Amazon Redshift",
      "데이터 보강",
      "분석 애플리케이션"
    ],
    "Terms": [
      "Amazon EMR",
      "Amazon S3",
      "AWS Glue",
      "Amazon Redshift",
      "Amazon Kinesis Data Streams",
      "Amazon Lake Formation",
      "Amazon Athena"
    ],
    "SelectA": "Amazon Athena로 S3 데이터를 처리하고, AWS Glue를 통해 Redshift 데이터를 사용해 S3 데이터를 보강합니다.",
    "SelectA_Commentary": "Athena와 AWS Glue를 결합해 처리 및 보강을 수행할 수 있지만, Athena는 서버리스 쿼리 서비스 중심이며, 대량 데이터를 병렬로 빠르게 처리하기에는 EMR 대비 제약이 있습니다.",
    "SelectB": "Amazon EMR로 S3 데이터를 처리하고, Amazon EMR을 통해 Redshift 데이터를 활용하여 S3 데이터를 보강합니다.",
    "SelectB_Commentary": "EMR은 병렬 처리가 뛰어난 분산 처리 플랫폼으로, Redshift와 직접 연동이 가능해 데이터를 쉽게 보강할 수 있습니다. 요구사항을 모두 만족하는 가장 적합한 옵션입니다.",
    "SelectC": "Amazon EMR로 S3 데이터를 처리하고, Amazon Kinesis Data Streams를 사용해 S3 데이터를 Redshift로 전송하여 보강합니다.",
    "SelectC_Commentary": "Kinesis Data Streams는 스트리밍 데이터 처리용으로 적합하지만, 이미 S3에 저장된 대용량 정적 데이터를 보강하기엔 작업이 복잡해집니다.",
    "SelectD": "AWS Glue로 S3 데이터를 처리하고, Amazon Lake Formation을 통해 Redshift 데이터를 활용하여 S3 데이터를 보강합니다.",
    "SelectD_Commentary": "AWS Glue와 Lake Formation 역시 데이터 카탈로그 관리와 ETL 작업에 유용하지만, 병렬 데이터 처리에 최적화된 분산 환경을 제공하는 EMR만큼의 확장성과 성능을 제공하진 않습니다.",
    "Question_Description_recommedations": [
      "Q547",
      "Q173",
      "Q155",
      "Q626",
      "Q43"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q687"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q557",
      "Q402"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q557",
      "Q687"
    ]
  },
  {
    "Question_Number": "Q558",
    "Question_Description": "한 회사가 같은 AWS 계정 내 us-west-2 Region에 위치한 두 개의 VPC를 보유하고 있습니다. 이 회사는 두 VPC 간 네트워크 트래픽을 허용해야 하며, 월 약 500GB의 데이터 전송이 발생할 예정입니다. 이 상황에서 가장 비용 효율적인 방식으로 두 VPC를 연결하기 위한 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117053-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 같은 Region 내에서 두 VPC를 연결할 때 가장 저렴하고 간단한 방안을 묻습니다. VPC Peering은 동일 Region 내 트래픽에 대해 추가 데이터 전송 비용이 거의 들지 않으며, 장비나 별도 터널 구성 없이도 안정적 연결을 제공합니다. 그에 비해 Transit Gateway나 Site-to-Site VPN, Direct Connect는 추가 요금 및 복잡도가 높아 비용 효율이 떨어집니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "비용 효율",
      "VPC 간 연결",
      "동일 Region",
      "데이터 전송",
      "500GB/월"
    ],
    "Terms": [
      "AWS Transit Gateway",
      "AWS Site-to-Site VPN",
      "VPC Peering",
      "AWS Direct Connect",
      "Data Transfer"
    ],
    "SelectA": "두 VPC를 연결하기 위해 AWS Transit Gateway를 구현합니다. 각 VPC의 route table을 업데이트하여 VPC 간 통신 시 Transit Gateway를 사용하도록 설정합니다.",
    "SelectA_Commentary": "Transit Gateway는 기능이 풍부하지만 시간당 사용 비용과 데이터 전송 요금이 추가로 들어가며, Peering보다 비용 효율이 떨어집니다.",
    "SelectB": "두 VPC 간 AWS Site-to-Site VPN 터널을 구성합니다. 각 VPC의 route table을 업데이트하여 VPC 간 트래픽 시 VPN 터널을 사용하도록 설정합니다.",
    "SelectB_Commentary": "VPN은 설정이 간단하지만 시간당 과금과 전송 요금이 부과되어, 동일 Region VPC Peering에 비해 비용이 더 듭니다.",
    "SelectC": "두 VPC 간 VPC Peering 연결을 설정합니다. 각 VPC의 route table을 업데이트하여 VPC 간 트래픽 시 VPC Peering 연결을 사용하도록 설정합니다.",
    "SelectC_Commentary": "동일 Region 간 Peering은 추가 요금이 적고 간단해 월 500GB 수준 트래픽에 가장 비용 효율적이며 적합한 솔루션입니다.",
    "SelectD": "두 VPC 간 1GB AWS Direct Connect를 설정합니다. 각 VPC의 route table을 업데이트하여 VPC 간 트래픽 시 Direct Connect를 사용하도록 설정합니다.",
    "SelectD_Commentary": "Direct Connect는 안정성이 높지만 구축 및 시간당 비용이 매우 높아, 이 문제의 용도(월 500GB)에 비해 과도하게 비쌉니다.",
    "Question_Description_recommedations": [
      "Q471",
      "Q374",
      "Q860",
      "Q736",
      "Q72"
    ],
    "SelectA_recommedations": [
      "Q497",
      "Q860",
      "Q471"
    ],
    "SelectB_recommedations": [
      "Q860",
      "Q497",
      "Q471"
    ],
    "SelectC_recommedations": [
      "Q374",
      "Q860",
      "Q471"
    ],
    "SelectD_recommedations": [
      "Q499",
      "Q471",
      "Q240"
    ]
  },
  {
    "Question_Number": "Q559",
    "Question_Description": "한 회사가 서로 다른 제품 라인별로 여러 애플리케이션을 AWS에서 호스팅하고 있습니다. 이 애플리케이션들은 Amazon EC2 인스턴스와 Application Load Balancer를 포함한 다양한 컴퓨팅 리소스를 사용합니다. 이러한 애플리케이션은 같은 AWS Organizations 내 여러 AWS 계정과 여러 AWS Region에서 동작합니다. 각 제품 라인 팀은 각 계정 내 리소스에 태그를 붙여 관리하고 있습니다. 회사는 AWS Organizations의 통합 청구 기능을 사용하여, 각 제품 라인별로 더 상세한 비용 정보를 확인하고자 합니다. 이 요구사항을 만족하기 위해 어떤 단계를 조합해야 합니까? (두 가지를 선택하세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117403-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 계정과 Region에 걸쳐 운영되는 애플리케이션의 비용을 효과적으로 추적하기 위해 태그 기반 비용 할당 기능을 어떻게 활성화하느냐에 대한 것입니다. 각 제품 라인별로 부착한 user-defined tag를 AWS Billing console에서 사용함으로써 제품 라인 단위로 비용을 세분화할 수 있습니다. 또한 이 태그를 Organizations의 관리 계정에서 활성화해야 모든 하위 계정에 대해 통합 청구 시 동일하게 반영되어 정확한 비용 집계가 가능합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "통합 청구",
      "제품 라인별 비용 분석",
      "user-defined tag",
      "관리 계정",
      "AWS Billing console"
    ],
    "Terms": [
      "AWS Organizations",
      "Consolidated Billing",
      "AWS Billing console",
      "AWS generated tag",
      "User-defined tag",
      "AWS Resource Groups console",
      "Amazon EC2",
      "Application Load Balancer",
      "Organization Management Account"
    ],
    "SelectA": "AWS Billing console에서 특정 AWS generated tag를 선택합니다.",
    "SelectA_Commentary": "AWS에서 생성한 기본 태그는 사용자가 정의한 제품 라인별 식별과 정확히 일치하지 않아 제품 라인 단위 비용 분석에 적합하지 않습니다.",
    "SelectB": "AWS Billing console에서 특정 user-defined tag를 선택합니다.",
    "SelectB_Commentary": "각 제품 라인 팀이 스스로 정의한 태그는 원하는 수준으로 리소스를 구분하고 비용할당을 할 수 있어, 제품 라인별 비용 데이터를 얻는 핵심 단계입니다. (정답)",
    "SelectC": "AWS Resource Groups console에서 특정 user-defined tag를 선택합니다.",
    "SelectC_Commentary": "Resource Groups는 리소스 관리 목적으로 유용하지만, 통합 청구와 직접 연동되지 않아 비용 집계 정보에는 영향을 주지 못합니다.",
    "SelectD": "각 AWS 계정에서 선택된 태그를 활성화합니다.",
    "SelectD_Commentary": "각 하위 계정에서 별도로 태그를 활성화할 필요 없이, Organizations 관리 계정에서 한 번에 태그를 활성화하면 전체 비용 집계에 적용됩니다.",
    "SelectE": "Organizations 관리 계정에서 선택된 태그를 활성화합니다.",
    "SelectE_Commentary": "통합 청구 환경에서 태그 기반 비용 할당을 하려면 관리 계정에서 태그를 활성화해야 전체 계정에 태그가 적용되어 일관된 비용 분석이 가능합니다. (정답)",
    "Question_Description_recommedations": [
      "Q984",
      "Q455",
      "Q459",
      "Q238",
      "Q773"
    ],
    "SelectA_recommedations": [
      "Q31",
      "Q943",
      "Q455"
    ],
    "SelectB_recommedations": [
      "Q31",
      "Q455",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q31",
      "Q455",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q728",
      "Q486",
      "Q943"
    ],
    "SelectE_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ]
  },
  {
    "Question_Number": "Q560",
    "Question_Description": "한 회사의 솔루션스 아키텍트가 AWS Organizations를 사용하여 멀티 계정 환경을 설계하고 있습니다. 솔루션스 아키텍트는 회사의 계정들을 Organizational Unit(OU)로 구성해 두었습니다. 이제 OU 계층 구조에 어떤 변경 사항이 발생할 경우 이를 식별하고, 회사 운영팀에게 해당 변경 사항을 알리는 솔루션이 필요합니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117021-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Organizations 환경에서 OU 계층 구조의 변경을 간단하고 효율적으로 파악하고, 운영팀에 알리는 방안을 찾는 내용입니다. 여러 계정 관리 솔루션 중에서 AWS Control Tower는 멀티 계정 환경 설정을 쉽고 자동화된 방식으로 처리하며, 계정 드리프트(OU 변경 사항) 알림을 기본적으로 제공하므로 운영 오버헤드를 최소화할 수 있는 가장 적합한 선택입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "OU 계층 구조",
      "AWS Organizations",
      "멀티 계정 환경",
      "운영팀 알림",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Control Tower",
      "Account drift notifications",
      "AWS Config",
      "Aggregated rules",
      "AWS Service Catalog",
      "AWS CloudTrail",
      "CloudTrail organization trail",
      "AWS CloudFormation",
      "Drift detection"
    ],
    "SelectA": "AWS Control Tower를 사용하여 AWS 계정을 프로비저닝합니다. OU 계층 구조 변경사항을 식별하기 위해 Account drift notifications를 활용합니다.",
    "SelectA_Commentary": "AWS Control Tower의 기본 기능인 Account drift notifications를 사용하면 OU 구조 변경을 자동으로 감지 및 알림할 수 있어 운영 부담이 가장 적습니다.",
    "SelectB": "AWS Control Tower를 사용하여 AWS 계정을 프로비저닝합니다. AWS Config의 집계 규칙을 사용하여 OU 계층 구조 변경사항을 식별합니다.",
    "SelectB_Commentary": "AWS Config 규칙을 구성해야 하고 규칙 업데이트, 집계 설정 등 추가 작업이 필요하여 운영 오버헤드가 더 커집니다.",
    "SelectC": "AWS Service Catalog를 사용하여 Organizations 내에 계정을 생성합니다. AWS CloudTrail 조직 트레일을 사용하여 OU 계층 구조 변경사항을 식별합니다.",
    "SelectC_Commentary": "Service Catalog와 CloudTrail을 연동해 변경 로그를 분석하는 것은 가능하지만, 계정 생성부터 변경 식별까지 단계가 많아 운영이 복잡합니다.",
    "SelectD": "AWS CloudFormation 템플릿을 사용하여 Organizations 내에 계정을 생성합니다. 스택 드리프트 감지 기능을 활용해 OU 계층 구조 변경사항을 식별합니다.",
    "SelectD_Commentary": "CloudFormation 스택과 OU 계층 구조가 직접적으로 1:1 대응하기 어렵고, 스택 드리프트 감지 설정 및 관리가 필요해 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q586",
      "Q988",
      "Q1018"
    ],
    "SelectA_recommedations": [
      "Q688",
      "Q27",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q688",
      "Q945",
      "Q970"
    ],
    "SelectC_recommedations": [
      "Q560",
      "Q945",
      "Q748"
    ],
    "SelectD_recommedations": [
      "Q560",
      "Q945",
      "Q168"
    ]
  },
  {
    "Question_Number": "Q561",
    "Question_Description": "어느 회사의 웹사이트가 매일 수백만 건의 요청을 처리하고 있으며, 요청 건수가 계속 증가하고 있습니다. Solutions Architect는 웹 애플리케이션의 응답 시간을 개선해야 합니다. Solutions Architect는 Amazon DynamoDB 테이블에서 제품 상세 정보를 조회하는 지연 시간을 줄여야 한다고 판단했습니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117022-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 지속적으로 증가하는 웹 트래픽 상황에서 DynamoDB 데이터 조회 지연 시간을 단축하기 위한 방안을 묻습니다. DynamoDB Accelerator(DAX)는 DynamoDB 전용 인메모리 캐싱 서비스로, 간단한 구성과 최소한의 코드 수정만으로 읽기 요청 지연을 크게 낮출 수 있어 운영 오버헤드를 최소화합니다. 반면에 ElastiCache를 사용하는 방법은 추가적인 구성 및 코드 변경이 더 많이 필요하여 운영이 복잡해질 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "수백만 요청",
      "DynamoDB",
      "지연 시간 감소",
      "운영 오버헤드 최소화",
      "DAX"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon ElastiCache for Redis",
      "Amazon ElastiCache for Memcached",
      "Amazon DynamoDB Streams",
      "AWS Lambda",
      "Amazon ElastiCache"
    ],
    "SelectA": "DynamoDB Accelerator(DAX) 클러스터를 설정하고, 모든 읽기 요청을 DAX를 통해 라우팅합니다.",
    "SelectA_Commentary": "DAX는 DynamoDB용으로 최적화된 캐싱 서비스이므로 쉽게 연동 가능하며, 지연 시간을 단축하는 가장 효율적인 솔루션입니다.",
    "SelectB": "DynamoDB 테이블과 웹 애플리케이션 사이에 Amazon ElastiCache for Redis를 설정하고, 모든 읽기 요청을 Redis를 통해 라우팅합니다.",
    "SelectB_Commentary": "Redis를 사용하려면 코드 수정 범위가 넓어지고, DynamoDB 전용 캐싱보다 운영 오버헤드가 큽니다.",
    "SelectC": "DynamoDB 테이블과 웹 애플리케이션 사이에 Amazon ElastiCache for Memcached를 설정하고, 모든 읽기 요청을 Memcached를 통해 라우팅합니다.",
    "SelectC_Commentary": "Memcached 역시 동일하게 추가 개발 및 관리가 필요하여 운영 오버헤드가 증가합니다.",
    "SelectD": "테이블에 Amazon DynamoDB Streams를 설정하고, AWS Lambda로 테이블을 읽어 Amazon ElastiCache에 데이터를 저장합니다. 모든 읽기 요청을 ElastiCache로 라우팅합니다.",
    "SelectD_Commentary": "Streams와 Lambda, ElastiCache를 결합하면 처리 과정이 복잡해져서 운영 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q819",
      "Q861",
      "Q268",
      "Q472",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q578",
      "Q177"
    ],
    "SelectB_recommedations": [
      "Q472",
      "Q177",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectD_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ]
  },
  {
    "Question_Number": "Q562",
    "Question_Description": "한 솔루션스 아키텍트가 Amazon EC2 인스턴스에서 Amazon DynamoDB로의 API 호출이 인터넷을 통과하지 않도록 VPC 내에서 트래픽을 유지해야 합니다. 이 요구사항을 충족하기 위해 어떤 단계를 결합해야 합니까? (2개를 선택하세요.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117251-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부에서 DynamoDB에 액세스하도록 설정해 인터넷 경유를 차단하는 방법을 묻습니다. DynamoDB는 Gateway Endpoint를 지원하므로, 이를 생성한 뒤 라우트 테이블에 해당 엔드포인트로 가는 경로를 추가해야 합니다. 이렇게 하면 EC2 인스턴스가 DynamoDB에 직접 연결할 수 있어 인터넷으로 트래픽이 나가지 않고 안전하게 통신할 수 있습니다. 보안을 위해서는 인터넷 경로가 필요 없으며, 가장 효율적인 방식은 Gateway Endpoint와 라우트 테이블 구성을 통해 사설 네트워크 내에서 트래픽을 처리하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC 엔드포인트",
      "Gateway Endpoint",
      "DynamoDB",
      "EC2"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Amazon EC2",
      "VPC",
      "Gateway Endpoint",
      "Route Table"
    ],
    "SelectA": "Create a route table entry for the endpoint.",
    "SelectA_Commentary": "Gateway Endpoint 사용 시 라우트 테이블에 해당 엔드포인트로 가는 경로를 등록해야 트래픽이 인터넷으로 나가지 않고 내부 라우팅을 통해 DynamoDB로 전달됩니다.",
    "SelectB": "Create a gateway endpoint for DynamoD",
    "SelectB_Commentary": "DynamoDB는 Gateway Endpoint를 통해 사설 통신이 가능합니다. 이를 생성하면 EC2에서 인터넷 경유 없이 안전하게 DynamoDB에 액세스할 수 있습니다.",
    "SelectC": "Create an interface endpoint for Amazon EC2.",
    "SelectC_Commentary": "DynamoDB용 Interface Endpoint가 아니라 Gateway Endpoint가 필요합니다. 따라서 이 선택지는 요구사항에 부합하지 않습니다.",
    "SelectD": "Create an elastic network interface for the endpoint in each of the subnets of the VPC.",
    "SelectD_Commentary": "Gateway Endpoint는 서브넷별 ENI를 생성하는 구조가 아니므로, 이 단계는 불필요합니다.",
    "SelectE": "Create a security group entry in the endpoint's security group to provide access.",
    "SelectE_Commentary": "Gateway Endpoint에는 특정 Security Group 구성이 필요하지 않습니다. Interface Endpoint 방식일 때 보안 그룹 설정이 중요하지만, 이 경우는 해당되지 않습니다.",
    "Question_Description_recommedations": [
      "Q91",
      "Q176",
      "Q866",
      "Q92",
      "Q327"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q791",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q428",
      "Q727",
      "Q279"
    ],
    "SelectC_recommedations": [
      "Q208",
      "Q562",
      "Q91"
    ],
    "SelectD_recommedations": [
      "Q231",
      "Q251",
      "Q866"
    ],
    "SelectE_recommedations": [
      "Q774",
      "Q233",
      "Q395"
    ]
  },
  {
    "Question_Number": "Q563",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service (Amazon EKS) 클러스터와 온프레미스 Kubernetes 클러스터 모두에서 애플리케이션을 운영하고 있습니다. 회사는 모든 클러스터와 워크로드를 중앙 위치에서 확인하고자 합니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117023-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 환경(Amazon EKS와 온프레미스 Kubernetes)을 하나로 모아 운영 상태와 워크로드를 모니터링하려는 요구사항에 관한 것입니다. 최적의 솔루션은 최소한의 작업으로 여러 Kubernetes 클러스터를 하나의 콘솔에서 확인할 수 있어야 합니다. Amazon EKS Connector를 사용하면 온프레미스 또는 다른 클라우드의 Kubernetes 클러스터를 EKS 콘솔에 연결해 중앙에서 상태와 워크로드를 확인할 수 있으므로 운영 오버헤드를 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EKS",
      "온프레미스 Kubernetes",
      "중앙 위치",
      "최소한의 운영 오버헤드",
      "Amazon EKS Connector"
    ],
    "Terms": [
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Amazon CloudWatch Container Insights",
      "AWS Systems Manager",
      "Amazon EKS Connector",
      "Amazon EKS Anywhere"
    ],
    "SelectA": "Amazon CloudWatch Container Insights를 사용하여 클러스터 정보를 수집하고 그룹화합니다.",
    "SelectA_Commentary": "Container Insights는 모니터링 및 로그 수집에 유용하나, 여러 온프레미스 및 EKS 클러스터를 통합해 보여주는 기능보다는 개별 지표 수집에 초점이 있어 중앙 관리용으로는 제한이 있습니다.",
    "SelectB": "Amazon EKS Connector를 사용하여 모든 Kubernetes 클러스터를 등록하고 연결합니다.",
    "SelectB_Commentary": "정답입니다. EKS Connector를 통해 온프레미스 Kubernetes 클러스터와 Amazon EKS 클러스터를 EKS 콘솔에서 일관되게 모니터링 및 시각화할 수 있어 운영 복잡도를 크게 줄일 수 있습니다.",
    "SelectC": "AWS Systems Manager를 사용하여 클러스터 정보를 수집하고 확인합니다.",
    "SelectC_Commentary": "AWS Systems Manager는 서버 관리와 일부 지표 확인에 유리하지만, Kubernetes 클러스터 단위로 전체적인 워크로드와 상태를 통합 관제하는 기능은 제한적입니다.",
    "SelectD": "Amazon EKS Anywhere를 기본 클러스터로 사용하여 다른 클러스터를 native Kubernetes 명령으로 확인합니다.",
    "SelectD_Commentary": "EKS Anywhere는 온프레미스 서버에 EKS 호환 환경을 구축해 주지만, 이미 존재하는 여러 Kubernetes 클러스터를 중앙에서 일괄적으로 모니터링하기 위해서는 추가 설정과 운영이 더 필요해 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q996",
      "Q724",
      "Q522",
      "Q775",
      "Q698"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q869",
      "Q293"
    ],
    "SelectB_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q293",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q564",
    "Question_Description": "회사는 전자상거래(ecommerce) 애플리케이션을 구축 중이며 민감한 고객 정보를 저장해야 합니다. 고객이 웹사이트에서 구매 트랜잭션을 완료할 수 있도록 해야 하며, 데이터베이스 관리자조차 민감 고객 데이터에 접근할 수 없도록 보호해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117024-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "민감한 데이터를 다루는 전자상거래 환경에서 데이터베이스 관리자조차 평문 정보에 접근하지 못하도록 하는 것이 핵심입니다. AWS KMS client-side encryption을 활용하면 애플리케이션 계층에서 먼저 데이터를 암호화하여 DB에 전달하므로, DB 관리자나 클라우드 운영자가 데이터에 직접 접근하더라도 평문을 볼 수 없습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 고객 정보",
      "RDS for MySQL",
      "AWS KMS client-side encryption",
      "구매 트랜잭션",
      "데이터베이스 관리자 접근 제한"
    ],
    "Terms": [
      "Amazon Elastic Block Store (Amazon EBS)",
      "EBS encryption",
      "IAM instance role",
      "Amazon RDS for MySQL",
      "AWS Key Management Service (AWS KMS) client-side encryption",
      "Amazon S3",
      "AWS KMS server-side encryption",
      "S3 bucket policies",
      "Amazon FSx for Windows Server",
      "Windows file permissions"
    ],
    "SelectA": "Amazon EBS 볼륨에 민감 데이터를 저장하고 EBS encryption을 사용합니다. IAM instance role을 이용해 접근을 제한합니다.",
    "SelectA_Commentary": "EBS 암호화는 저장 시점에만 적용되며, 인스턴스 내부에서 평문 접근이 가능합니다. IAM role만으로는 데이터베이스 관리자 접근을 완전히 차단하기 어렵습니다.",
    "SelectB": "Amazon RDS for MySQL을 사용하고, AWS KMS client-side encryption으로 데이터를 직접 암호화해 저장합니다.",
    "SelectB_Commentary": "클라이언트 측에서 데이터를 암호화해 전달하므로, RDS를 포함해 DB 내부나 관리자도 평문을 볼 수 없습니다. 민감 데이터 보호에 가장 적합합니다.",
    "SelectC": "Amazon S3에 민감 데이터를 저장하고 AWS KMS server-side encryption을 사용합니다. S3 bucket policies로 접근을 제한합니다.",
    "SelectC_Commentary": "서버 측 암호화만 사용하면 S3 자체나 관리자 권한으로 평문 접근이 가능할 수 있습니다. 또한 DB 활용성을 고려하면 적합하지 않습니다.",
    "SelectD": "Amazon FSx for Windows Server에 데이터를 저장하고 파일 공유를 애플리케이션 서버에 마운트합니다. Windows 파일 권한으로 접근을 제한합니다.",
    "SelectD_Commentary": "Windows 파일 권한은 기본 운영체제 권한으로, 관리자 권한이 있으면 평문 데이터를 볼 수 있어 민감 정보 보호 측면에서 취약합니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q665",
      "Q57",
      "Q122",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q689",
      "Q410"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q743",
      "Q847"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q681",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q500",
      "Q260",
      "Q901"
    ]
  },
  {
    "Question_Number": "Q565",
    "Question_Description": "한 회사가 온프레미스 MySQL 데이터베이스로 트랜잭션 데이터를 처리하고 있습니다. 이 회사는 해당 데이터베이스를 AWS Cloud로 마이그레이션하려고 합니다. 마이그레이션된 데이터베이스는 이 데이터베이스를 사용하는 회사의 애플리케이션과의 호환성을 유지해야 하며, 수요가 증가하는 시기에 자동으로 확장되어야 합니다. 이러한 요구사항을 충족하는 마이그레이션 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117025-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 MySQL 호환성과 자동 확장 요구사항을 동시에 충족할 수 있는 AWS 데이터베이스 서비스 선택이 핵심입니다. Amazon Aurora는 MySQL 호환 모델을 제공하면서 Aurora Auto Scaling을 통해 증가하는 트래픽을 자동으로 처리할 수 있습니다. 또한 AWS DMS를 이용하면 최소한의 다운타임으로 간편하게 MySQL에서 Aurora로 데이터 이관이 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "MySQL 호환성",
      "자동 확장",
      "AWS DMS",
      "Amazon Aurora",
      "Aurora Auto Scaling"
    ],
    "Terms": [
      "MySQL",
      "Amazon RDS for MySQL",
      "Amazon Aurora",
      "AWS DMS",
      "Amazon Redshift",
      "Amazon DynamoDB",
      "Aurora Auto Scaling",
      "Auto Scaling"
    ],
    "SelectA": "네이티브 MySQL 툴을 사용하여 Amazon RDS for MySQL로 데이터베이스를 마이그레이션합니다. 탄력적 스토리지 스케일링을 구성합니다.",
    "SelectA_Commentary": "RDS for MySQL은 MySQL 호환성은 충족하지만 Aurora 대비 자동 확장 기능에서 제한적이며, 고증가 트래픽 대응력이 상대적으로 떨어집니다.",
    "SelectB": "mysqldump 유틸리티를 사용하여 Amazon Redshift로 데이터베이스를 마이그레이션합니다. Amazon Redshift 클러스터에 Auto Scaling을 활성화합니다.",
    "SelectB_Commentary": "Amazon Redshift는 데이터 웨어하우스 및 분석 워크로드에 특화되어 있으며, 트랜잭션 처리 요구사항 및 MySQL 호환성과는 맞지 않습니다.",
    "SelectC": "AWS Database Migration Service(AWS DMS)를 사용하여 Amazon Aurora로 데이터베이스를 마이그레이션합니다. Aurora Auto Scaling을 활성화합니다.",
    "SelectC_Commentary": "Aurora는 MySQL과 호환되는 관계형 데이터베이스로, 트랜잭션 처리에 적합하며 Auto Scaling 기능으로 수요 증가 시 자동으로 확장 가능합니다.",
    "SelectD": "AWS Database Migration Service(AWS DMS)로 Amazon DynamoDB로 데이터베이스를 마이그레이션합니다. Auto Scaling 정책을 구성합니다.",
    "SelectD_Commentary": "Amazon DynamoDB는 NoSQL 서비스로, 기존 MySQL 애플리케이션 호환성 유지가 어렵고 스키마 구조도 달라 마이그레이션 용도로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q229",
      "Q834",
      "Q192",
      "Q314",
      "Q631"
    ],
    "SelectA_recommedations": [
      "Q376",
      "Q590",
      "Q386"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q674"
    ],
    "SelectC_recommedations": [
      "Q305",
      "Q481",
      "Q386"
    ],
    "SelectD_recommedations": [
      "Q305",
      "Q33",
      "Q834"
    ]
  },
  {
    "Question_Number": "Q566",
    "Question_Description": "한 회사가 두 개의 Availability Zone에 걸쳐 다수의 Amazon EC2 Linux 인스턴스를 VPC 내에서 운영하고 있습니다. 인스턴스들은 계층적 디렉터리 구조를 사용하는 애플리케이션을 호스팅하며, 빠른 속도로 동시에 공유 스토리지에 읽고 쓰기를 수행해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116902-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 EC2 인스턴스에서 동시에 파일 기반 I/O를 처리해야 하는 시나리오로, 계층적 디렉터리 구조를 지원하는 공유 파일 스토리지 솔루션이 핵심입니다. Amazon EFS는 사용자가 별도 코드를 수정할 필요 없이 NFSv4 프로토콜 기반으로 확장 가능한 네트워크 파일 시스템을 제공하므로, 고성능 및 동시 접근이 필요한 경우에 적합한 선택입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "공유 스토리지",
      "계층적 디렉터리 구조",
      "빠른 동시 읽기/쓰기",
      "Amazon EFS"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC",
      "Availability Zone",
      "Amazon EFS",
      "Amazon S3",
      "Amazon EBS",
      "Provisioned IOPS SSD(io2)"
    ],
    "SelectA": "Amazon S3 버킷을 생성합니다. VPC 내 모든 EC2 인스턴스에서 이 버킷에 접근할 수 있도록 허용합니다.",
    "SelectA_Commentary": "Amazon S3는 오브젝트 스토리지여서 계층적 파일 시스템 접근이나 동시 파일 I/O에 적합하지 않습니다.",
    "SelectB": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다. 각 EC2 인스턴스에서 EFS 파일 시스템을 마운트합니다.",
    "SelectB_Commentary": "EFS는 계층적 디렉터리 구조와 파일 기반 I/O를 지원하며, 여러 인스턴스가 동시에 공유 스토리지에 접근할 수 있는 최적의 해법입니다.",
    "SelectC": "Provisioned IOPS SSD(io2) Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하여 파일 시스템을 생성합니다. 이 EBS 볼륨을 모든 EC2 인스턴스에 연결합니다.",
    "SelectC_Commentary": "EBS 볼륨은 단일 인스턴스에 연결되는 특성이 있어 여러 인스턴스에서 동시에 마운트하기 어렵고 관리가 복잡합니다.",
    "SelectD": "각 EC2 인스턴스에 연결된 Amazon EBS 볼륨에 파일 시스템을 생성합니다. 서로 다른 EC2 인스턴스 간에 EBS 볼륨을 동기화합니다.",
    "SelectD_Commentary": "인스턴스마다 별도 EBS 볼륨을 동기화하는 방식은 복잡도가 높고 실시간 동시 접근이 불가능하여 요구사항에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q938",
      "Q632",
      "Q818",
      "Q976",
      "Q686"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q173",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q695",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q919",
      "Q299",
      "Q394"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q193",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q567",
    "Question_Description": "한 솔루션스 아키텍트가 빌딩 내 테넌트들의 시간당 에너지 사용량을 저장할 워크로드를 설계하고 있습니다. 센서들은 HTTP 요청을 통해 각 테넌트별 사용량을 합산해주는 데이터베이스로 데이터를 전송합니다. 솔루션스 아키텍트는 가능한 경우에는 매니지드 서비스를 사용해야 합니다. 또한 앞으로 독립적인 컴포넌트를 추가하면서 기능이 확장될 예정입니다. 이 요구 사항을 만족하면서 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117026-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 별도의 서버 관리 없이 시간당 에너지 사용 정보를 수집하고 확장성을 보장할 수 있는 구조를 설계하는 것이 핵심입니다. Amazon API Gateway와 AWS Lambda, Amazon DynamoDB를 사용하면 완전한 서버리스 아키텍처를 구축할 수 있어 운영 및 관리 부담이 크게 줄어듭니다. EC2 기반 솔루션의 경우 인스턴스 관리나 라이선스 문제가 발생해 운영 오버헤드가 증가하고, SQL Server나 EFS 역시 별도 관리와 용량 계획이 필요하므로 적합하지 않습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "시간당 에너지 사용량",
      "HTTP 요청",
      "매니지드 서비스",
      "운영 오버헤드 최소화",
      "독립적인 컴포넌트 확장"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Elastic Load Balancer",
      "Auto Scaling",
      "Amazon EC2",
      "Amazon S3",
      "Microsoft SQL Server Express",
      "Amazon Elastic File System (Amazon EFS)"
    ],
    "SelectA": "Amazon API Gateway와 AWS Lambda를 사용하여 센서로부터 데이터를 수신하고 처리한 뒤 Amazon DynamoDB 테이블에 저장합니다.",
    "SelectA_Commentary": "서버리스 환경으로 서버 관리 부담이 없고 DynamoDB는 완전 관리형 스토리지이므로 확장성과 유연성이 뛰어납니다. 독립 컴포넌트 추가에도 용이하여 미래 확장에 유리합니다.",
    "SelectB": "Auto Scaling 그룹 내 Amazon EC2 인스턴스를 지원하는 Elastic Load Balancer로 센서 데이터를 수신・처리하고, 결과를 Amazon S3 버킷에 저장합니다.",
    "SelectB_Commentary": "EC2 인스턴스 운영과 Auto Scaling 환경 구성이 필요해 서버 관리 오버헤드가 늘어납니다. 더 나은 서버리스 대안이 존재합니다.",
    "SelectC": "Amazon API Gateway와 AWS Lambda를 사용하여 센서 데이터를 수신하고 처리한 뒤, Amazon EC2 인스턴스의 Microsoft SQL Server Express 데이터베이스에 저장합니다.",
    "SelectC_Commentary": "서버리스 기반이지만 최종 저장소로 EC2에서 동작하는 SQL Server를 운영해야 하므로, DB 관리 및 라이선스 비용 측면에서 운영 오버헤드가 높아집니다.",
    "SelectD": "Auto Scaling 그룹 내 Amazon EC2 인스턴스를 지원하는 Elastic Load Balancer로 센서 데이터를 수신・처리하고, 결과를 Amazon EFS에 저장합니다.",
    "SelectD_Commentary": "EC2와 EFS는 모두 별도 관리와 용량 계획이 필요합니다. 운영 복잡성이 증가하여 최소한의 오버헤드를 요구하는 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q798",
      "Q735",
      "Q255",
      "Q917",
      "Q58"
    ],
    "SelectA_recommedations": [
      "Q207",
      "Q25",
      "Q10"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q405",
      "Q581"
    ],
    "SelectC_recommedations": [
      "Q354",
      "Q944",
      "Q10"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q568",
    "Question_Description": "한 솔루션스 아키텍트가 엔지니어링 도면을 저장하고 조회하기 위한 새로운 웹 애플리케이션을 위해 스토리지 아키텍처를 설계하고 있습니다. 모든 애플리케이션 구성 요소는 AWS 인프라에 배포될 예정입니다. 이 애플리케이션 디자인은 사용자가 엔지니어링 도면을 로드하는 데 걸리는 시간을 최소화하기 위해 캐싱을 지원해야 합니다. 또한 애플리케이션은 페타바이트급 데이터를 저장할 수 있어야 합니다. 솔루션스 아키텍트가 사용할 스토리지와 캐싱 조합으로 적절한 것은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117027-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모(페타바이트급) 데이터를 효율적으로 저장하고 동시에 빠른 응답 속도를 위해 캐싱을 적용해야 하는 시나리오입니다. Amazon S3는 뛰어난 내구성과 확장성을 갖춰 대량의 데이터를 저장하기에 적합합니다. 여기에 Amazon CloudFront를 함께 사용하면 글로벌 엣지 로케이션에서 컨텐츠를 캐싱해 사용자 지연을 낮출 수 있습니다. 따라서 S3와 CloudFront의 조합이 가장 적절합니다. 나머지 옵션은 저장 규모나 캐싱 방식이 문제 요구사항을 만족하기 어렵거나, 접근 속도와 확장성 면에서 효율적이지 못해 부적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "웹 애플리케이션",
      "엔지니어링 도면",
      "캐싱",
      "페타바이트급 데이터",
      "Amazon S3",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon S3 Glacier",
      "Amazon ElastiCache",
      "Amazon Elastic Block Store (Amazon EBS)",
      "AWS Storage Gateway"
    ],
    "SelectA": "Amazon S3와 Amazon CloudFront를 사용합니다.",
    "SelectA_Commentary": "대규모 데이터를 효과적으로 저장할 수 있고, CloudFront를 통한 글로벌 캐싱으로 지연을 줄일 수 있어 문제 요구사항을 가장 잘 충족합니다.",
    "SelectB": "Amazon S3 Glacier와 Amazon ElastiCache를 사용합니다.",
    "SelectB_Commentary": "S3 Glacier는 주로 장기 보관용이므로 조회 속도가 느리고, 자주 액세스되는 엔지니어링 도면을 빠르게 제공하기엔 적합하지 않습니다.",
    "SelectC": "Amazon Elastic Block Store (Amazon EBS) 볼륨과 Amazon CloudFront를 사용합니다.",
    "SelectC_Commentary": "Amazon EBS는 서버 블록 스토리지이며 페타바이트급 확장에 불리하고, CloudFront와 함께 사용해도 대규모 객체 스토리지 요구를 효율적으로 해결하기 어렵습니다.",
    "SelectD": "AWS Storage Gateway와 Amazon ElastiCache를 사용합니다.",
    "SelectD_Commentary": "Storage Gateway는 온프레미스와의 통합용으로 주로 활용되며, ElastiCache는 인메모리 캐시로 글로벌 엣지 캐싱에 적합하지 않아 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q443",
      "Q361",
      "Q631",
      "Q547",
      "Q738"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q620",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q695",
      "Q620",
      "Q280"
    ],
    "SelectD_recommedations": [
      "Q620",
      "Q597",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q569",
    "Question_Description": "Amazon EventBridge 규칙이 서드파티 API를 대상으로 하고 있습니다. 서드파티 API는 전혀 트래픽을 받지 않고 있습니다. 솔루션스 아키텍트는 규칙 조건이 충족되는지와 규칙의 타겟이 실제로 호출되는지를 확인해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117377-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EventBridge 규칙이 정상적으로 트리거되어 타겟을 호출하고 있는지 모니터링하는 방법을 묻습니다. AWS/Events 네임스페이스에서 Invocations 같은 지표를 사용하면 규칙이 실제로 어느 정도 호출되었는지 알 수 있으므로, 규칙 조건 충족 여부와 타겟 호출 여부를 즉시 확인할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EventBridge",
      "규칙 조건",
      "타겟 호출",
      "third-party API",
      "CloudWatch Metrics"
    ],
    "Terms": [
      "Amazon EventBridge",
      "third-party API",
      "AWS/Events",
      "Amazon SQS",
      "Dead-letter queue",
      "Amazon CloudWatch Logs",
      "AWS CloudTrail"
    ],
    "SelectA": "Amazon CloudWatch에서 AWS/Events 네임스페이스의 지표를 확인합니다.",
    "SelectA_Commentary": "AWS/Events 지표(Invocations, FailedInvocations 등)을 통해 EventBridge가 규칙을 트리거하고 타겟을 호출했는지 한눈에 파악할 수 있으므로 요구사항을 가장 효과적으로 충족합니다.",
    "SelectB": "Amazon Simple Queue Service(Amazon SQS) dead-letter queue에 있는 이벤트를 검토합니다.",
    "SelectB_Commentary": "Dead-letter queue에는 실패한 이벤트가 누적되지만, 해당 큐를 구성하지 않았거나 이벤트가 실패 없이 전송되지 않은 경우에는 확인이 어렵고, 규칙 자체가 성공적으로 호출되었는지 직접적으로 알 수 없습니다.",
    "SelectC": "Amazon CloudWatch Logs에 있는 이벤트를 확인합니다.",
    "SelectC_Commentary": "CloudWatch Logs에 이벤트가 기록되려면 추가 설정이 필요합니다. 규칙 트리거 여부 확인만으로는 AWS/Events 지표가 더 간단하고 명확한 방법입니다.",
    "SelectD": "AWS CloudTrail에서 EventBridge 이벤트를 확인합니다.",
    "SelectD_Commentary": "CloudTrail은 AWS API 호출 기록이지만, 서드파티 API 호출이나 규칙의 상세 동작을 직접 확인하기에는 적합하지 않아 규칙이 실제로 타겟을 호출했는지 명확하게 파악하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q10",
      "Q207",
      "Q351",
      "Q228",
      "Q798"
    ],
    "SelectA_recommedations": [
      "Q351",
      "Q8",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q203",
      "Q67",
      "Q98"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q293",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q569",
      "Q351",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q570",
    "Question_Description": "한 회사는 매주 금요일 저녁에 실행되는 대규모 워크로드가 있습니다. 이 워크로드는 us-east-1 Region 내 두 개의 Availability Zone에 있는 Amazon EC2 인스턴스에서 실행됩니다. 평소에는 인스턴스가 항상 2개를 넘지 않아야 하지만, 회사는 매주 금요일마다 정기적으로 반복되는 증가한 워크로드를 처리하기 위해 인스턴스를 6개까지 확장하기를 원합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116903-exam-aws-certified-sol",
    "AnswerDescription": "매주 일정 시점에 증가하는 워크로드를 처리하려면 정해진 시간에 자동으로 인스턴스 수를 조정하는 기능이 필요합니다. Scheduled Action을 사용하는 Auto Scaling group은 사용자가 별도의 작업을 하지 않아도 매주 금요일에 인스턴스 수를 높이고, 필요 없을 때 자동으로 정해진 최소 개수로 줄여 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "매주 금요일 증가하는 워크로드",
      "Amazon EC2",
      "Auto Scaling group",
      "Scheduled action",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "us-east-1 Region",
      "Amazon EventBridge",
      "Auto Scaling group",
      "Scheduled Action",
      "Manual Scaling",
      "Automatic Scaling"
    ],
    "SelectA": "Amazon EventBridge에서 리마인더를 생성하여 인스턴스를 스케일링합니다.",
    "SelectA_Commentary": "EventBridge 리마인더는 단순히 작업을 알리는 역할로, 실제로 인스턴스를 자동 확장/축소하는 기능이 없어 운영자의 수동 개입이 필요합니다.",
    "SelectB": "Scheduled action을 갖춘 Auto Scaling group을 생성합니다.",
    "SelectB_Commentary": "예정된 시간에 맞춰 인스턴스 수를 자동으로 확장/축소할 수 있어, 추가 관리 작업 없이 요구 사항을 가장 간단히 충족하는 방법입니다.",
    "SelectC": "Manual scaling을 사용하는 Auto Scaling group을 생성합니다.",
    "SelectC_Commentary": "Manual scaling은 인스턴스 조정을 사람이 직접 해야 하므로 매주 금요일마다 작업을 수행해야 하고, 운영 오버헤드가 더 높습니다.",
    "SelectD": "Automatic scaling을 사용하는 Auto Scaling group을 생성합니다.",
    "SelectD_Commentary": "Automatic scaling은 CloudWatch 지표 등에 따라 동적으로 스케일조정이 가능하나, 고정된 주기적 패턴을 정확히 처리하기에는 Scheduled Action보다 설정이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q757",
      "Q244",
      "Q987",
      "Q584",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q569",
      "Q8",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ],
    "SelectC_recommedations": [
      "Q1001",
      "Q595",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q571",
    "Question_Description": "한 회사에서 REST API를 생성 중입니다. 이 회사는 TLS 사용에 대해 엄격한 요구 사항을 가지고 있습니다. API 엔드포인트에서 TLSv1.3을 사용해야 하며, 특정 공용 서드파티 Certificate Authority(CA)가 TLS 인증서를 서명해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116904-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 특정 서드파티 CA로 서명된 인증서를 사용해 API 엔드포인트에서 TLSv1.3을 구현하는 방법을 묻습니다. ACM을 통해 쉘이나 내부 환경에서 생성/서명받은 인증서를 가져와 곧바로 API Gateway 커스텀 도메인에 연결함으로써 요구 사항을 충족할 수 있습니다. TLSv1.3 지원과 특정 CA 사용을 위해서는 스스로 만든 인증서를 import하는 방식이 필요하므로, 직접 만들고 서명받아 ACM에 가져오는 절차가 필수적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "TLSv1.3",
      "REST API",
      "AWS Certificate Manager",
      "API Gateway",
      "third-party CA",
      "커스텀 도메인"
    ],
    "Terms": [
      "TLSv1.3",
      "AWS Certificate Manager (ACM)",
      "API Gateway",
      "HTTP API",
      "Lambda function URL",
      "Import certificate",
      "third-party CA"
    ],
    "SelectA": "로컬 머신에서 서드파티 CA로 서명된 인증서를 생성합니다. 해당 인증서를 AWS Certificate Manager (ACM)에 import합니다. Amazon API Gateway에서 HTTP API를 생성하고 커스텀 도메인을 설정하여 이 인증서를 사용하도록 구성합니다.",
    "SelectA_Commentary": "서드파티 CA로 서명받은 인증서를 직접 import해 HTTPS 연결을 구성하고 TLSv1.3을 손쉽게 적용할 수 있는 올바른 방법입니다.",
    "SelectB": "AWS Certificate Manager (ACM)에서 서드파티 CA가 서명한 인증서를 생성합니다. Amazon API Gateway에서 HTTP API를 생성하고 커스텀 도메인을 설정하여 이 인증서를 사용하도록 구성합니다.",
    "SelectB_Commentary": "ACM 자체에서 직접 서드파티 CA를 통해 인증서를 발급받는 옵션은 제공되지 않으므로 불가능합니다.",
    "SelectC": "AWS Certificate Manager (ACM)에서 서드파티 CA로 서명된 인증서를 생성 후 import합니다. AWS Lambda 함수와 Lambda function URL을 생성하고 이 인증서를 사용하도록 구성합니다.",
    "SelectC_Commentary": "Lambda function URL 자체는 ACM에서 제공받은 커스텀 인증서를 사용하는 구성이 지원되지 않아, 요구사항을 만족하지 못합니다.",
    "SelectD": "AWS Certificate Manager (ACM)에서 서드파티 CA로 서명된 인증서를 생성합니다. AWS Lambda 함수와 Lambda function URL을 생성하고 이 인증서를 사용하도록 구성합니다.",
    "SelectD_Commentary": "ACM과 Lambda function URL의 조합으로 TLSv1.3 및 커스텀 도메인을 구성할 수 없으며, 서드파티 CA를 직접 '생성'하는 옵션도 없기에 부적합한 방식입니다.",
    "Question_Description_recommedations": [
      "Q265",
      "Q468",
      "Q855",
      "Q34",
      "Q172"
    ],
    "SelectA_recommedations": [
      "Q1019",
      "Q577",
      "Q532"
    ],
    "SelectB_recommedations": [
      "Q1019",
      "Q34",
      "Q532"
    ],
    "SelectC_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ],
    "SelectD_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q572",
    "Question_Description": "한 회사가 AWS에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 사용량이 불규칙합니다. 애플리케이션은 AWS Direct Connect를 사용하여 온프레미스 MySQL-compatible 데이터베이스와 연결하고 있으며, 해당 온프레미스 데이터베이스는 항상 최소 2GiB의 메모리를 사용합니다. 회사는 이 온프레미스 데이터베이스를 AWS에서 제공하는 managed 서비스로 마이그레이션하고자 합니다. 또한 예기치 못한 워크로드 증가를 처리하기 위해 auto scaling 기능을 원하고 있습니다. 가장 적은 관리 오버헤드로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117029-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 온프레미스 MySQL-compatible 데이터베이스를 AWS로 이전하면서, 예측하기 어려운 사용량 스파이크를 자동으로 처리하고 관리 오버헤드를 최소화하는 방법을 묻습니다. Amazon Aurora Serverless v2는 자동 확장 기능을 제공하므로, 증가하는 워크로드에 대비해 별도의 관리 작업 없이도 탄력적으로 대응할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "불규칙한 사용량",
      "AWS Direct Connect",
      "MySQL 호환",
      "최소 2GiB 메모리",
      "auto scaling",
      "managed AWS service 마이그레이션"
    ],
    "Terms": [
      "AWS Direct Connect",
      "MySQL-compatible",
      "auto scaling",
      "Amazon DynamoDB",
      "Amazon Aurora",
      "Aurora capacity unit (ACU)",
      "Amazon Aurora Serverless v2",
      "Amazon RDS for MySQL",
      "administrative overhead"
    ],
    "SelectA": "기본 읽기 및 쓰기 용량 설정으로 Amazon DynamoDB 데이터베이스를 프로비저닝합니다.",
    "SelectA_Commentary": "DynamoDB는 MySQL 호환성이 없기 때문에 기존 애플리케이션에서 마이그레이션 시 스키마 변경이 필요하며, 예상치 못한 사용량 처리에도 별도 배포 설정이 요구되어 관리가 복잡해질 수 있습니다.",
    "SelectB": "Amazon Aurora 데이터베이스를 최소 1 Aurora capacity unit (ACU) 용량으로 프로비저닝합니다.",
    "SelectB_Commentary": "Aurora 자체는 MySQL-compatible이지만, Provisioned 모드는 용량이 고정되어 있어 워크로드가 증가할 때 즉각적으로 확장하기 위해서는 수동으로 조정이 필요해 관리 부담이 늘어납니다.",
    "SelectC": "Amazon Aurora Serverless v2 데이터베이스를 최소 1 Aurora capacity unit (ACU)로 프로비저닝합니다.",
    "SelectC_Commentary": "Serverless v2를 사용하면 관리자가 개입하지 않아도 자동으로 확장·축소가 가능하며 MySQL 호환성을 제공하므로, 본 요구사항을 가장 적은 오버헤드로 충족합니다.",
    "SelectD": "Amazon RDS for MySQL 데이터베이스를 2GiB 메모리로 프로비저닝합니다.",
    "SelectD_Commentary": "MySQL 호환성은 있지만 인스턴스 크기가 고정되어 있어, 워크로드가 예기치 않게 증가할 경우 추가적인 수동 크기 조정과 재부팅 등 관리 작업이 필요합니다.",
    "Question_Description_recommedations": [
      "Q182",
      "Q683",
      "Q935",
      "Q843",
      "Q52"
    ],
    "SelectA_recommedations": [
      "Q1002",
      "Q845",
      "Q400"
    ],
    "SelectB_recommedations": [
      "Q879",
      "Q52",
      "Q217"
    ],
    "SelectC_recommedations": [
      "Q879",
      "Q660",
      "Q217"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q259",
      "Q629"
    ]
  },
  {
    "Question_Number": "Q573",
    "Question_Description": "한 회사가 이벤트 기반 프로그래밍 모델을 AWS Lambda에서 사용하려고 합니다. 회사는 Java 11로 실행되는 Lambda function의 시작 지연 시간(startup latency)을 단축하고 싶어 합니다. 회사는 애플리케이션에 대한 엄격한 지연 시간 요구사항이 없으며, Lambda function이 확장될 때 발생하는 콜드 스타트 및 예외적인 지연 시간을 줄이고자 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116925-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 Java 11로 실행되는 Lambda function의 콜드 스타트를 줄이면서도 비용 효율성을 극대화하는 방법을 묻습니다. Lambda SnapStart는 함수를 사전에 초기화해 콜드 스타트를 제거하고 추가 요금 없이 사용 가능해, Provisioned Concurrency보다 저렴하고 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS Lambda",
      "이벤트 기반 프로그래밍 모델",
      "콜드 스타트",
      "Java 11",
      "Lambda SnapStart",
      "비용 효율"
    ],
    "Terms": [
      "Lambda function",
      "Lambda provisioned concurrency",
      "Lambda SnapStart",
      "timeout",
      "메모리 증가",
      "콜드 스타트",
      "Java 11"
    ],
    "SelectA": "Lambda provisioned concurrency를 구성합니다.",
    "SelectA_Commentary": "항상 일정 동시성을 유지하지만 예약된 용량에 대한 비용이 계속 발생해 SnapStart 대비 더 비용이 높아 비효율적입니다.",
    "SelectB": "Lambda function의 timeout을 늘립니다.",
    "SelectB_Commentary": "timeout 증가는 함수의 실행 제한 시간만 변경할 뿐, 콜드 스타트나 스케일 시 발생하는 지연 자체를 개선하지 못합니다.",
    "SelectC": "Lambda function의 메모리를 늘립니다.",
    "SelectC_Commentary": "메모리 증가는 함수의 실행 속도엔 영향을 줄 수 있으나, 콜드 스타트 자체를 줄이는 직접적인 방법은 아니며 비용 이점도 크지 않습니다.",
    "SelectD": "Lambda SnapStart를 구성합니다.",
    "SelectD_Commentary": "Lambda SnapStart는 Java 11 함수를 사전에 초기화해 콜드 스타트와 스케일 시의 예외적 지연을 크게 완화하면서도 추가 비용 없이 비용 효율성을 달성할 수 있는 최적의 해법입니다.",
    "Question_Description_recommedations": [
      "Q807",
      "Q770",
      "Q882",
      "Q800",
      "Q417"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q128",
      "Q300"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q728",
      "Q807"
    ],
    "SelectC_recommedations": [
      "Q807",
      "Q767",
      "Q997"
    ],
    "SelectD_recommedations": [
      "Q630",
      "Q997",
      "Q551"
    ]
  },
  {
    "Question_Number": "Q574",
    "Question_Description": "금융 서비스 회사가 주식 시장 동향을 추적하기 위한 새로운 애플리케이션을 Amazon RDS for MySQL 데이터베이스와 함께 출시했습니다. 이 애플리케이션은 매주 말에 단 2시간만 운영되며, 데이터베이스 운영 비용을 최적화해야 합니다. 다음 중 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117272-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 주 단위로 짧은 시간만 동작하는 애플리케이션의 DB 비용을 최소화하려는 상황에서, 사용량에 따라 유연하게 확장·축소가 가능한 Aurora Serverless v2를 선택하는 것이 핵심입니다. Aurora Serverless v2는 미사용 시 비용을 크게 줄일 수 있고 관리 부담도 덜어줍니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "비용 최적화",
      "주간 2시간 운영",
      "Amazon RDS for MySQL",
      "Aurora Serverless v2",
      "MySQL"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Aurora Serverless v2",
      "Aurora MySQL",
      "Amazon EC2",
      "Amazon Elastic Container Service (Amazon ECS)"
    ],
    "SelectA": "기존 RDS for MySQL 데이터베이스를 Aurora Serverless v2 MySQL 데이터베이스 클러스터로 마이그레이션합니다.",
    "SelectA_Commentary": "Aurora Serverless v2는 사용하지 않는 시간 동안 자동으로 확장/축소되어 비용을 절감하며, 간헐적인 워크로드에 최적화된 솔루션입니다.",
    "SelectB": "기존 RDS for MySQL 데이터베이스를 Aurora MySQL 데이터베이스 클러스터로 마이그레이션합니다.",
    "SelectB_Commentary": "표준 Aurora MySQL은 최소 인스턴스 크기를 유지해야 하므로, 2시간 외 나머지 시간에도 비용이 발생해 비효율적입니다.",
    "SelectC": "Amazon EC2 인스턴스에 MySQL을 설치하고 인스턴스 예약 구매를 통해 마이그레이션합니다.",
    "SelectC_Commentary": "EC2 예약 인스턴스는 미사용 시에도 비용이 계속 청구되므로, 주 2시간만 사용하기에는 과도한 지출이 발생합니다.",
    "SelectD": "Amazon Elastic Container Service(Amazon ECS) 클러스터에 MySQL 컨테이너 이미지를 사용해 작업을 실행하도록 마이그레이션합니다.",
    "SelectD_Commentary": "ECS 기반 컨테이너도 사용하지 않는 시간대에 클러스터 유지 비용이 발생할 수 있어 서버리스 대비 효율이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q959",
      "Q152",
      "Q579",
      "Q436",
      "Q940"
    ],
    "SelectA_recommedations": [
      "Q574",
      "Q827",
      "Q152"
    ],
    "SelectB_recommedations": [
      "Q574",
      "Q152",
      "Q579"
    ],
    "SelectC_recommedations": [
      "Q552",
      "Q435",
      "Q411"
    ],
    "SelectD_recommedations": [
      "Q591",
      "Q552",
      "Q926"
    ]
  },
  {
    "Question_Number": "Q575",
    "Question_Description": "한 회사가 AWS Region에서 Application Load Balancer 뒤에 위치한 Amazon EKS에 애플리케이션을 배포했습니다. 애플리케이션은 PostgreSQL 데이터베이스 엔진에 데이터를 저장해야 합니다. 회사는 데이터베이스의 높은 가용성을 원하며, 읽기 워크로드를 처리할 추가 용량도 필요로 합니다. 이러한 요구 사항을 가장 운영 효율적으로 충족시키는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116969-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 고가용성과 확장된 읽기 성능을 모두 충족해야 하는 PostgreSQL 데이터베이스 설계를 묻습니다. RDS Multi-AZ DB cluster 배포는 기본적으로 복제와 페일오버를 자동으로 처리하여 운영 효율성을 높이고, 읽기 전용 노드를 통해 읽기 성능을 확장할 수 있어 요구 사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2",
      "3.3"
    ],
    "Keywords": [
      "높은 가용성",
      "읽기 처리량",
      "Amazon RDS Multi-AZ DB Cluster"
    ],
    "Terms": [
      "Amazon EKS",
      "Application Load Balancer",
      "Amazon RDS",
      "Multi-AZ",
      "DB cluster",
      "cross-Region read replicas",
      "Amazon DynamoDB",
      "global tables",
      "PostgreSQL"
    ],
    "SelectA": "Amazon DynamoDB 테이블을 생성하고 global tables로 구성합니다.",
    "SelectA_Commentary": "DynamoDB로 전환하려면 기존 PostgreSQL 애플리케이션을 재설계해야 하고, global tables 구성은 추가 설정이 복잡합니다. PostgreSQL 요구 사항과는 맞지 않아 효율적이지 않습니다.",
    "SelectB": "Amazon RDS 데이터베이스를 Multi-AZ 배포로 구성합니다.",
    "SelectB_Commentary": "일반적인 Multi-AZ 배포로 가용성은 확보할 수 있지만, 읽기 작업 확장을 위해서는 별도의 Read Replica 설정이 필요하여 완전한 운영 효율이 떨어집니다.",
    "SelectC": "Amazon RDS 데이터베이스를 Multi-AZ DB cluster 배포로 구성합니다.",
    "SelectC_Commentary": "Multi-AZ DB cluster 배포는 고가용성과 자동 페일오버, 그리고 읽기 전용 노드를 통한 읽기 성능 확장을 모두 기본 제공하여 가장 운영 효율적입니다.",
    "SelectD": "Amazon RDS 데이터베이스를 생성하고 cross-Region read replica로 구성합니다.",
    "SelectD_Commentary": "cross-Region read replica 구성이 필요한 경우 지연 시간이 증가하고, 여러 리전을 관리해야 하므로 운영이 복잡합니다. 이 요구 사항에는 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q241",
      "Q69",
      "Q996",
      "Q275",
      "Q5"
    ],
    "SelectA_recommedations": [
      "Q1002",
      "Q845",
      "Q78"
    ],
    "SelectB_recommedations": [
      "Q843",
      "Q8",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q466",
      "Q958",
      "Q518"
    ],
    "SelectD_recommedations": [
      "Q108",
      "Q863",
      "Q978"
    ]
  },
  {
    "Question_Number": "Q576",
    "Question_Description": "회사는 Amazon API Gateway와 AWS Lambda를 사용하여 RESTful 무서버 웹 애플리케이션을 구축하고 있습니다. 이 웹 애플리케이션의 사용자는 전 세계적으로 분산되어 있으며, 회사는 이러한 사용자들에게 API 요청의 지연 시간을 줄이기를 원합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트가 사용해야 하는 엔드포인트 유형은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116906-exam-aws-certified-sol",
    "AnswerDescription": "지연 시간을 최소화해야 하므로 CloudFront 엣지 로케이션을 통해 배포하는 Edge-optimized endpoint가 적합합니다. 글로벌 범위의 사용자에게 API를 제공할 때 가장 낮은 지연 시간을 제공하기 때문입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "RESTful 무서버",
      "API Gateway",
      "AWS Lambda",
      "글로벌 사용자",
      "지연 시간 감소"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "RESTful serverless",
      "Edge-optimized endpoint",
      "Regional endpoint",
      "Private endpoint",
      "Interface VPC endpoint"
    ],
    "SelectA": "Private endpoint",
    "SelectA_Commentary": "Private endpoint는 VPC 내부에서만 접근 가능하도록 설정된 엔드포인트로, 전 세계 사용자용 공용 API에는 적합하지 않습니다.",
    "SelectB": "Regional endpoint",
    "SelectB_Commentary": "Regional endpoint는 같은 리전에 위치한 사용자에게는 유리하지만, 글로벌 사용자에게는 추가적인 확장이나 CloudFront 설정이 필요해 지연 시간 단축 효과가 제한적입니다.",
    "SelectC": "Interface VPC endpoint",
    "SelectC_Commentary": "Interface VPC endpoint는 특정 VPC 내에서 API Gateway를 연결할 때 사용하는 방식으로, 인터넷을 통한 전 세계 사용자에게는 적합하지 않습니다.",
    "SelectD": "Edge-optimized endpoint",
    "SelectD_Commentary": "CloudFront 엣지 로케이션을 통해 전 세계 사용자에게 가까운 엔드포인트로 트래픽을 라우팅하여 지연 시간을 크게 줄일 수 있으므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q379",
      "Q597",
      "Q175",
      "Q603",
      "Q141"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q158",
      "Q888"
    ],
    "SelectB_recommedations": [
      "Q888",
      "Q132",
      "Q158"
    ],
    "SelectC_recommedations": [
      "Q704",
      "Q77",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q704",
      "Q77",
      "Q352"
    ]
  },
  {
    "Question_Number": "Q577",
    "Question_Description": "한 회사는 웹사이트의 콘텐츠 페이지를 제공하기 위해 Amazon CloudFront distribution을 사용하고 있습니다. 이 회사는 클라이언트가 웹사이트에 접근할 때 TLS certificate를 사용하도록 해야 합니다. 또한 TLS certificate의 생성과 갱신을 자동화하기를 원합니다. 운영 효율성을 가장 높이면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117037-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 CloudFront를 통해 제공되는 웹사이트에 대해 TLS certificate를 적용하고, 그 생성과 갱신을 자동화하는 최적의 방안을 찾는 것입니다. DNS validation 방식을 사용하는 AWS Certificate Manager(ACM)은 만료 시 자동 갱신이 가능해 운영 효율성이 가장 높습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon CloudFront distribution",
      "TLS certificate",
      "자동화",
      "AWS Certificate Manager",
      "DNS validation"
    ],
    "Terms": [
      "CloudFront security policy",
      "CloudFront origin access control (OAC)",
      "AWS Certificate Manager (ACM)",
      "DNS validation",
      "Email validation",
      "TLS certificate"
    ],
    "SelectA": "CloudFront security policy를 사용하여 certificate를 생성합니다.",
    "SelectA_Commentary": "CloudFront security policy는 certificate 생성이나 자동 갱신을 직접 제공하지 않습니다.",
    "SelectB": "CloudFront origin access control (OAC)를 사용하여 certificate를 생성합니다.",
    "SelectB_Commentary": "OAC는 Origin 접근을 제어하는 기능으로, TLS certificate 생성 및 자동 갱신 기능과는 무관합니다.",
    "SelectC": "AWS Certificate Manager(ACM)로 certificate를 생성하고, domain에 대해 DNS validation을 사용합니다.",
    "SelectC_Commentary": "DNS validation은 certificate 만료 시 자동 갱신이 가능해 운영을 크게 단순화하므로 가장 효율적인 해결책입니다.",
    "SelectD": "AWS Certificate Manager(ACM)로 certificate를 생성하고, domain에 대해 email validation을 사용합니다.",
    "SelectD_Commentary": "email validation은 수동 승인 절차가 필요해 업데이트 시 자동성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q855",
      "Q172",
      "Q538",
      "Q542",
      "Q131"
    ],
    "SelectA_recommedations": [
      "Q855",
      "Q577",
      "Q172"
    ],
    "SelectB_recommedations": [
      "Q577",
      "Q855",
      "Q172"
    ],
    "SelectC_recommedations": [
      "Q577",
      "Q396",
      "Q855"
    ],
    "SelectD_recommedations": [
      "Q577",
      "Q855",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q578",
    "Question_Description": "어느 회사에서 Amazon DynamoDB를 데이터베이스 계층으로 사용하는 서버리스 애플리케이션을 배포했습니다. 해당 애플리케이션은 사용자 수가 급격히 증가했습니다. 회사는 데이터베이스의 응답 시간을 밀리초에서 마이크로초 수준으로 단축하고, 데이터베이스에 대한 요청을 캐시하고자 합니다. 이러한 요구사항을 만족하면서 운영 오버헤드를 최소화하려면 어떤 솔루션을 도입해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117038-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 빠른 응답 시간을 위해 데이터베이스 성능을 밀리초에서 마이크로초 수준으로 개선하고, 추가적인 캐싱 레이어를 적용하려는 상황입니다. Amazon DynamoDB Accelerator(DAX)는 DynamoDB 전용으로 제공되는 완전관리형 인메모리 캐시 서비스로, 별도의 관리 부담 없이도 큰 폭의 성능 향상을 제공해 운영 오버헤드를 최소화합니다. 다른 데이터베이스로 마이그레이션하거나 별도의 캐시 시스템을 도입하는 것보다 DAX가 가장 적절하고 간단한 해결책입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "서버리스 애플리케이션",
      "Amazon DynamoDB",
      "응답 시간",
      "밀리초",
      "마이크로초",
      "캐시",
      "운영 오버헤드"
    ],
    "Terms": [
      "Amazon DynamoDB Accelerator (DAX)",
      "Amazon Redshift",
      "Amazon RDS",
      "Amazon ElastiCache for Redis"
    ],
    "SelectA": "Amazon DynamoDB Accelerator(DAX)를 사용합니다.",
    "SelectA_Commentary": "DAX는 DynamoDB와 밀접하게 통합된 인메모리 캐시로 완전관리형 서비스입니다. 운영 부담이 거의 없으면서 밀리초 응답 시간을 마이크로초로 줄일 수 있는 최적의 솔루션입니다.",
    "SelectB": "데이터베이스를 Amazon Redshift로 마이그레이션합니다.",
    "SelectB_Commentary": "Redshift는 주로 페타바이트 단위의 데이터 웨어하우싱 용도로 사용되며, 트랜잭션 처리와 저지연 캐싱 요구 사항에는 적합하지 않아 성능과 운영 효율성이 떨어집니다.",
    "SelectC": "데이터베이스를 Amazon RDS로 마이그레이션합니다.",
    "SelectC_Commentary": "관계형 데이터베이스 서비스 RDS로 옮겨도 캐시 도입은 별도의 운영 부담이 따릅니다. 요구사항인 마이크로초 단위 응답을 보장하기에는 추가 구성이 필요해 간단하지 않습니다.",
    "SelectD": "Amazon ElastiCache for Redis를 사용합니다.",
    "SelectD_Commentary": "ElastiCache for Redis 역시 강력한 캐시 솔루션이나, DynamoDB와 직접 통합되지 않아 추가 개발 및 오케스트레이션이 필요합니다. 따라서 운영 오버헤드가 더 커집니다.",
    "Question_Description_recommedations": [
      "Q731",
      "Q177",
      "Q472",
      "Q962",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q578",
      "Q177"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q361",
      "Q557"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q706",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q704",
      "Q620"
    ]
  },
  {
    "Question_Number": "Q579",
    "Question_Description": "한 회사가 Amazon RDS for PostgreSQL을 사용하는 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 주중 업무 시간에만 트래픽이 발생합니다. 회사는 이 사용 패턴에 맞춰 비용을 최적화하고 운영 오버헤드를 줄이고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116924-exam-aws-certified-sol",
    "AnswerDescription": "이 문제는 남는 시간대에 Amazon RDS 인스턴스를 중지하여 비용을 낮추고, 사용 시간이 되면 자동으로 다시 시작하여 운영 오버헤드를 줄이는 방안을 묻습니다. Instance Scheduler on AWS를 이용하면 주중 업무 시간에만 RDS가 구동되도록 스케줄링하여, 필요하지 않은 시간대의 비용을 아낄 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "주중 업무 시간",
      "비용 최적화",
      "운영 오버헤드 감소",
      "Instance Scheduler on AWS"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "AWS Instance Scheduler",
      "자동 백업(Automatic backups)",
      "수동 스냅샷(Manual snapshots)",
      "AWS Lambda",
      "예약(DB Reserved Instances)",
      "CPU 활용도(CPU utilization)"
    ],
    "SelectA": "AWS Instance Scheduler를 사용하여 시작 및 정지 스케줄을 구성합니다.",
    "SelectA_Commentary": "주중 업무 시간 이외에는 RDS를 중지하여 비용 절감 효과가 크고, 운영 오버헤드도 크게 줄어드는 가장 적합한 솔루션입니다.",
    "SelectB": "자동 백업을 끄고, 주 단위로 수동 스냅샷을 생성합니다.",
    "SelectB_Commentary": "백업만 줄여서는 인스턴스의 사용 시간을 통제하지 못해 불필요 비용이 계속 발생하므로 요구사항을 충족하지 못합니다.",
    "SelectC": "최소 CPU 활용도를 기반으로 데이터베이스를 시작 및 정지하는 커스텀 Lambda 함수를 만듭니다.",
    "SelectC_Commentary": "직접 함수를 작성·관리해야 하므로 운영 오버헤드가 높고, 단순 업무 시간 기반 스케줄링보다 효율적이지 않습니다.",
    "SelectD": "All Upfront 예약 DB 인스턴스를 구매합니다.",
    "SelectD_Commentary": "오랜 기간 고정 사용량이 예상되지 않는다면 선결제 예약 구매는 유연성이 부족하고, 실제 사용 패턴에 맞춘 비용 최적화가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q436",
      "Q940",
      "Q574",
      "Q959",
      "Q152"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q300",
      "Q380"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectC_recommedations": [
      "Q807",
      "Q284",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q630",
      "Q997",
      "Q49"
    ]
  },
  {
    "Question_Number": "Q580",
    "Question_Description": "한 회사가 로컬로 연결된 스토리지를 사용하여 지연 시간에 민감한 애플리케이션을 온프레미스에서 실행하고 있습니다. 이 회사는 lift and shift 방식을 사용하여 애플리케이션을 AWS Cloud로 이전하려고 합니다. 또한 애플리케이션 아키텍처는 변경하고 싶지 않습니다. 이러한 요구 사항을 가장 비용 효율적으로 충족시키는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117663-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 애플리케이션 아키텍처를 변경하지 않고 클라우드로 이전하기 위해, 로컬 스토리지와 유사한 지연 시간을 제공하면서도 가장 비용 효율적인 저장 장치를 선택하는 것입니다. Amazon EBS gp3 볼륨은 gp2보다 저비용이면서도 IOPS 성능을 유연하게 조정할 수 있어, ‘lift and shift’ 시나리오에 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "로컬로 연결된 스토리지",
      "지연 시간에 민감한 애플리케이션",
      "lift and shift",
      "비용 효율적",
      "Amazon EBS GP3"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon FSx for Lustre",
      "Amazon FSx for OpenZFS",
      "Amazon Elastic Block Store (Amazon EBS)",
      "gp2",
      "gp3"
    ],
    "SelectA": "Auto Scaling group에 Amazon EC2 인스턴스를 구성하고 Amazon FSx for Lustre 파일 시스템을 사용하여 애플리케이션을 실행합니다.",
    "SelectA_Commentary": "FSx for Lustre는 고성능 파일 시스템이지만 파일 스토리지 형태이므로 로컬 스토리지 대체로는 아키텍처 조정이 필요하며 비용 효율성도 떨어집니다.",
    "SelectB": "애플리케이션을 Amazon EC2 인스턴스에서 호스팅하고 Amazon EBS GP2 볼륨을 사용하여 애플리케이션을 실행합니다.",
    "SelectB_Commentary": "Amazon EBS gp2 볼륨은 충분히 사용 가능하지만 gp3에 비해 비용 효율성이 낮고 성능 조정 유연성이 제한적입니다.",
    "SelectC": "Auto Scaling group에 Amazon EC2 인스턴스를 구성하고 Amazon FSx for OpenZFS 파일 시스템을 사용하여 애플리케이션을 실행합니다.",
    "SelectC_Commentary": "FSx for OpenZFS 역시 공유 파일 시스템을 전제로 하므로, 로컬 스토리지 대체로 설계 변경이 필요하고 비용 면에서도 가장 유리하지 않습니다.",
    "SelectD": "애플리케이션을 Amazon EC2 인스턴스에서 호스팅하고 Amazon EBS GP3 볼륨을 사용하여 애플리케이션을 실행합니다.",
    "SelectD_Commentary": "gp3 볼륨은 gp2 대비 비용이 저렴하면서도 확장성과 성능 조정이 유연하여 지연 시간 요구 사항을 충족하고 가장 비용 효율적인 대안입니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q728",
      "Q985",
      "Q541",
      "Q525"
    ],
    "SelectA_recommedations": [
      "Q290",
      "Q937",
      "Q441"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q867",
      "Q238"
    ],
    "SelectC_recommedations": [
      "Q290",
      "Q937",
      "Q822"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q993",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q581",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 상태 저장 프로덕션 애플리케이션을 운영하고 있습니다. 해당 애플리케이션은 항상 최소 두 개의 EC2 인스턴스가 실행 중이어야 합니다. 솔루션스 아키텍트는 애플리케이션을 위한 고가용성 및 내결함성을 갖춘 아키텍처를 설계해야 합니다. 솔루션스 아키텍트가 EC2 인스턴스에 대한 Auto Scaling group을 생성했습니다. 요구 사항을 충족하기 위해 추가로 수행해야 하는 단계는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/116968-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 상태 저장 프로덕션 애플리케이션이 항상 2개 이상의 인스턴스를 유지하면서 하나의 Availability Zone이 장애가 나더라도 서비스를 지속적으로 제공하도록 설계하는 방법을 묻습니다. 최소 용량을 4대로 설정하고 두 개의 Availability Zone에 각각 두 대씩 On-Demand Instances를 배치하면, 어느 한쪽 AZ에 장애가 발생해도 나머지 AZ에서 2개의 인스턴스가 계속 동작하여 요구 사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "상태 저장 프로덕션 애플리케이션",
      "Amazon EC2",
      "Auto Scaling group",
      "On-Demand Instances",
      "고가용성",
      "내결함성",
      "Availability Zone"
    ],
    "Terms": [
      "Auto Scaling group",
      "Availability Zone",
      "On-Demand Instances",
      "Spot Instances",
      "stateful",
      "minimum capacity",
      "fault-tolerant"
    ],
    "SelectA": "Auto Scaling group의 최소 용량을 2로 설정합니다. 첫 번째 Availability Zone에 On-Demand Instance 1대를, 두 번째 Availability Zone에 On-Demand Instance 1대를 배포합니다.",
    "SelectA_Commentary": "각 AZ별로 인스턴스가 1대씩이므로 한 AZ에 장애가 발생하면 1대만 남아 요구 사항을 충족하지 못합니다.",
    "SelectB": "Auto Scaling group의 최소 용량을 4로 설정합니다. 첫 번째 Availability Zone에 On-Demand Instance 2대를, 두 번째 Availability Zone에 On-Demand Instance 2대를 배포합니다.",
    "SelectB_Commentary": "각 AZ에 2대씩 배치해 한쪽이 장애가 나도 최소 2대가 남아 고가용성과 내결함성을 확보할 수 있는 정답입니다.",
    "SelectC": "Auto Scaling group의 최소 용량을 2로 설정합니다. 한 Availability Zone에 Spot Instances 4대를 배포합니다.",
    "SelectC_Commentary": "단일 AZ에만 배포하면 AZ 장애 시 모든 인스턴스가 중단될 수 있고, Spot 특성상 인스턴스가 예고 없이 종료될 수 있어 안정적이지 않습니다.",
    "SelectD": "Auto Scaling group의 최소 용량을 4로 설정합니다. 첫 번째 Availability Zone에 On-Demand Instance 2대를, 두 번째 Availability Zone에 Spot Instances 2대를 배포합니다.",
    "SelectD_Commentary": "Spot Instances는 코어 애플리케이션에 예기치 못한 종료 위험이 있어 상시 2대를 보장하기 어렵습니다. 프로덕션 환경의 상태 저장 워크로드에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q595",
      "Q271",
      "Q1001",
      "Q691",
      "Q342"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q691",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q660",
      "Q729",
      "Q691"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q729",
      "Q691"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q729",
      "Q691"
    ]
  },
  {
    "Question_Number": "Q582",
    "Question_Description": "한 전자상거래 회사는 Amazon Route 53을 DNS 공급자로 사용하고 있습니다. 회사는 웹사이트를 온프레미스와 AWS Cloud에 호스팅하고 있습니다. 온프레미스 데이터 센터는 us-west-1 리전에 가깝고, 회사는 eu-central-1 리전을 사용해 웹사이트를 호스팅합니다. 회사는 웹사이트의 로드 시간을 가능한 한 최소화하고자 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/118597-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 전세계 사용자에게 가능한 한 낮은 지연 시간으로 웹사이트를 제공하기 위해, 가까운 위치의 리소스(온프레미스 또는 eu-central-1)로 트래픽을 보내는 올바른 Route 53 라우팅 정책을 고르는 것입니다. 단순 라우팅(Simple)으로는 구체적인 지리적 분기를 구현하기 어렵고, 레이턴시 라우팅(Latency)은 AWS 리전에만 적합하게 설정하기 쉽지만 온프레미스 데이터 센터와의 연동이 까다롭습니다. 가중치 라우팅(Weighted)은 트래픽 비율만 분산하기 때문에 지연 시간을 최소화하는 데에 직접적이지 않습니다. 따라서 지리적 위치를 기반으로 트래픽을 구분하는 Geolocation Routing을 사용하면 us-west-1 인근 사용자는 온프레미스 데이터 센터로, eu-central-1 인근 사용자는 eu-central-1로 즉시 연결하여 로드 시간을 최소화할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "웹사이트 로드 시간 최소화",
      "Amazon Route 53",
      "DNS",
      "온프레미스 데이터 센터",
      "us-west-1",
      "eu-central-1",
      "지리적 라우팅(Geolocation)",
      "단순 라우팅(Simple)",
      "레이턴시 라우팅(Latency)",
      "가중치 라우팅(Weighted)"
    ],
    "Terms": [
      "Route 53",
      "Geolocation Routing Policy",
      "Simple Routing Policy",
      "Latency Routing Policy",
      "Weighted Routing Policy",
      "On-Premises Data Center",
      "us-west-1",
      "eu-central-1"
    ],
    "SelectA": "지리적 라우팅 정책을 설정합니다. us-west-1에 가까운 트래픽은 온프레미스 데이터 센터로, eu-central-1에 가까운 트래픽은 eu-central-1로 보냅니다.",
    "SelectA_Commentary": "지리적 라우팅(Geolocation)은 사용자의 위치를 기준으로 트래픽을 분기하기 때문에, us-west-1 인근 사용자는 가까운 온프레미스로, eu-central-1 인근은 해당 리전으로 연결하여 지연 시간을 최소화할 수 있습니다.",
    "SelectB": "단순 라우팅 정책(Simple)을 설정하여 eu-central-1에 가까운 트래픽은 eu-central-1로, 온프레미스 데이터 센터에 가까운 트래픽은 온프레미스 데이터 센터로 라우팅합니다.",
    "SelectB_Commentary": "단순 라우팅은 지리적 혹은 지연 시간 기반 설정을 직접 지원하지 않아, 사용자 위치별로 다른 엔드포인트로 자동 라우팅하기 어렵습니다.",
    "SelectC": "레이턴시 라우팅 정책(Latency.routing)을 설정합니다. us-west-1과 연결하여 정책을 구성합니다.",
    "SelectC_Commentary": "AWS 리전을 단일 대상으로 하는 레이턴시 라우팅은 온프레미스 환경을 직접 연동하기 복잡하며, 참조 자료에도 나온 대로 us-west-1을 직접 연결하기에는 계정 설정 제약이 있어 적합하지 않습니다.",
    "SelectD": "가중치 라우팅 정책(Weighted)을 설정합니다. eu-central-1과 온프레미스 데이터 센터 사이에 트래픽을 균등하게 분산시킵니다.",
    "SelectD_Commentary": "가중치 라우팅은 단순히 설정된 비율대로만 트래픽을 분산하므로, 사용자의 위치에 따른 지연 시간 최적화 효과가 떨어집니다.",
    "Question_Description_recommedations": [
      "Q367",
      "Q530",
      "Q38",
      "Q684",
      "Q692"
    ],
    "SelectA_recommedations": [
      "Q684",
      "Q737",
      "Q738"
    ],
    "SelectB_recommedations": [
      "Q684",
      "Q77",
      "Q622"
    ],
    "SelectC_recommedations": [
      "Q737",
      "Q684",
      "Q352"
    ],
    "SelectD_recommedations": [
      "Q684",
      "Q622",
      "Q888"
    ]
  },
  {
    "Question_Number": "Q583",
    "Question_Description": "한 회사가 물리적 테이프에 5PB 규모의 아카이브 데이터를 보관하고 있습니다. 규정 준수를 위해 향후 10년 동안 이 데이터를 보관해야 합니다. 회사는 향후 6개월 내에 AWS로 마이그레이션하려고 합니다. 테이프가 저장된 데이터 센터는 1Gbps 업링크 인터넷 연결을 보유하고 있습니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/117215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량 물리 테이프 데이터를 AWS로 이전하면서, 시간 제약(6개월)과 비용 최적화를 모두 충족하는 시나리오입니다. Tape Gateway를 결합한 AWS Snowball 솔루션은 오프라인 전송으로 대역폭 제약을 극복하고, 장기 보관비를 최소화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "5PB 아카이브",
      "테이프 마이그레이션",
      "10년 보관",
      "AWS Snowball",
      "Tape Gateway",
      "비용 효율성",
      "S3 Glacier Deep Archive"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3 Glacier Flexible Retrieval",
      "Amazon S3 Glacier Deep Archive",
      "AWS Snowball",
      "Tape Gateway",
      "Lifecycle Policy",
      "NFS Storage",
      "Backup Software",
      "Virtual Tape"
    ],
    "SelectA": "온프레미스에서 테이프의 데이터를 읽어 로컬 NFS 스토리지에 임시 저장한 뒤, AWS DataSync를 사용해 Amazon S3 Glacier Flexible Retrieval로 마이그레이션합니다.",
    "SelectA_Commentary": "1Gbps 네트워크를 통해 5PB를 전송하기에는 기간이 길고, DataSync 비용 또한 상당하여 장기적으로 비효율적입니다.",
    "SelectB": "온프레미스 백업 애플리케이션을 사용해 테이프 데이터를 읽고, 직접 Amazon S3 Glacier Deep Archive로 씁니다.",
    "SelectB_Commentary": "직접 업로드 방식 역시 대량 데이터를 1Gbps로 옮기는 데 시간이 오래 걸리며, 비용 효율이 떨어질 수 있습니다.",
    "SelectC": "Tape Gateway가 탑재된 여러 AWS Snowball 디바이스를 주문합니다. 물리적 테이프를 Snowball 내 가상 테이프로 복사 후 디바이스를 AWS로 배송합니다. 그리고 Lifecycle Policy를 설정해 테이프를 Amazon S3 Glacier Deep Archive로 이동시킵니다.",
    "SelectC_Commentary": "5PB 대규모 데이터를 오프라인으로 빠르게 이전할 수 있으며, S3 Glacier Deep Archive로 장기 보관 비용을 절감할 수 있는 가장 효율적인 방법입니다.",
    "SelectD": "온프레미스에서 Tape Gateway를 구성하고, AWS 클라우드에 가상 테이프를 생성합니다. 백업 소프트웨어로 물리적 테이프를 가상 테이프로 복사합니다.",
    "SelectD_Commentary": "1Gbps 링크를 통해 실시간 전송하는 방식으로, 5PB를 단기에 모두 업로드하기에는 네트워크 대역폭에 제약이 큽니다.",
    "Question_Description_recommedations": [
      "Q778",
      "Q485",
      "Q486",
      "Q728",
      "Q943"
    ],
    "SelectA_recommedations": [
      "Q703",
      "Q719",
      "Q617"
    ],
    "SelectB_recommedations": [
      "Q1003",
      "Q606",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q912",
      "Q205",
      "Q126"
    ],
    "SelectD_recommedations": [
      "Q485",
      "Q943",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q584",
    "Question_Description": "한 회사가 대규모 병렬 데이터 처리를 위해 Amazon EC2 인스턴스를 배포하려고 합니다. 네트워크 아키텍처는 특정 노드 그룹이 동일한 물리적 하드웨어를 공유하지 않도록 구성 가능해야 합니다. 이 요구사항을 충족하는 네트워킹 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119485-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Spread Placement Group은 EC2 인스턴스를 서로 다른 물리 호스트에 배치해 하드웨어 결함 발생 시 여러 인스턴스가 동시에 영향을 받지 않도록 돕는 가장 적합한 방식입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "병렬 데이터 처리",
      "동일 하드웨어 공유 방지",
      "Amazon EC2",
      "Spread Placement Group"
    ],
    "Terms": [
      "Amazon EC2",
      "Dedicated Tenancy",
      "Shared Tenancy",
      "Spread Placement Group",
      "Placement Group"
    ],
    "SelectA": "Amazon EC2 인스턴스를 Spread Placement Group으로 실행합니다.",
    "SelectA_Commentary": "Spread Placement Group은 각 인스턴스를 서로 다른 물리 호스트에 배치해 결함 도메인을 분산하며, 노드 그룹 간 하드웨어 공유를 효과적으로 방지합니다.",
    "SelectB": "Amazon EC2 인스턴스를 별도 AWS 계정에 그룹화합니다.",
    "SelectB_Commentary": "계정이 다르더라도 물리 호스트가 겹칠 수 있으므로, 동일 하드웨어 공유를 확실히 막는 방법이 아닙니다.",
    "SelectC": "Amazon EC2 인스턴스를 Dedicated Tenancy로 구성합니다.",
    "SelectC_Commentary": "전용 호스트가 확보되지만 모든 인스턴스가 동일 하드웨어를 공유할 수 있으므로 노드 그룹 간 물리 분리가 보장되지 않습니다.",
    "SelectD": "Amazon EC2 인스턴스를 Shared Tenancy로 구성합니다.",
    "SelectD_Commentary": "기본 테넌시로, 물리 호스트를 공유하므로 노드 간 완전한 하드웨어 분산을 달성할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q757",
      "Q244",
      "Q252",
      "Q413",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q1001",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q757"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q584",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q244"
    ]
  },
  {
    "Question_Number": "Q585",
    "Question_Description": "한 솔루션스 아키텍트가 재해 복구(DR) 전략을 설계하여 failover AWS Region에 Amazon EC2 용량을 제공하려고 합니다. 비즈니스 요구사항에 따르면 이 DR 전략은 failover Region에서 필요한 용량을 반드시 충족해야 합니다. 다음 중 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119642-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DR 상황에서 failover Region에 필요한 Amazon EC2 용량을 보장해야 하는 요구사항을 다룹니다. Capacity Reservation은 특정 리전에 대한 EC2 인스턴스 용량을 미리 확보해 두어, 필요 시 장애 조치(failover) 시나리오에서도 즉시 인스턴스를 실행할 수 있도록 해줍니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DR 전략",
      "failover Region",
      "Amazon EC2",
      "용량 보장"
    ],
    "Terms": [
      "Disaster Recovery(DR) strategy",
      "Failover AWS Region",
      "Amazon EC2",
      "On-Demand Instances",
      "EC2 Savings Plan",
      "Regional Reserved Instances",
      "Capacity Reservation"
    ],
    "SelectA": "failover Region에서 On-Demand Instances를 구매합니다.",
    "SelectA_Commentary": "On-Demand Instances는 필요할 때마다 구매가 가능하지만 즉각적인 용량 보장이 되지 않아 DR 요구사항을 확실히 충족하지 못할 수 있습니다.",
    "SelectB": "failover Region에서 EC2 Savings Plan을 구매합니다.",
    "SelectB_Commentary": "EC2 Savings Plan은 비용 절감에 유리하지만, 특정 용량을 미리 확보해 주지는 않아 DR 시점에 즉시 가용한 용량이 보장되는 것은 아닙니다.",
    "SelectC": "failover Region에서 regional Reserved Instances를 구매합니다.",
    "SelectC_Commentary": "regional Reserved Instances는 미리 정해진 인스턴스 유형 및 크기에 대해 예약하는 방식이며, 다른 유형이 필요하거나 수요 변화가 발생하면 유연성이 떨어질 수 있습니다.",
    "SelectD": "failover Region에서 Capacity Reservation을 구매합니다.",
    "SelectD_Commentary": "Capacity Reservation은 지정된 리전 내에서 특정 용량을 미리 확보해 두어, DR 상황에서도 즉시 인스턴스를 실행할 수 있게 해 주므로 요구사항을 확실히 충족합니다.",
    "Question_Description_recommedations": [
      "Q343",
      "Q224",
      "Q456",
      "Q178",
      "Q304"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q585",
      "Q570"
    ],
    "SelectB_recommedations": [
      "Q585",
      "Q224",
      "Q570"
    ],
    "SelectC_recommedations": [
      "Q585",
      "Q224",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q585",
      "Q758",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q586",
    "Question_Description": "한 회사가 AWS Organizations를 사용하여 조직을 구성하고 있으며, 5개의 Organizational Units(OU)을 두고 있습니다. 각 OU는 회사가 소유한 5개의 사업체와 일대일로 대응됩니다. R&D(연구개발) 부서는 회사에서 분리되어 별도의 organization이 필요해졌고, 이를 위해 솔루션스 아키텍트가 새로운 management account를 생성했습니다. 새로운 management account에서 다음으로 어떤 조치를 취해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119645-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다계정 환경에서 특정 부서(R&D)가 회사에서 분리될 때 계정을 옮기는 방법을 묻습니다. AWS account는 동시에 두 organization에 속할 수 없으므로, 기존 organization에서 먼저 탈퇴한 후 새 organization으로 초대하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "5개의 OU",
      "별도의 organization",
      "R&D 분리",
      "management account",
      "AWS Organizations"
    ],
    "Terms": [
      "AWS Organizations",
      "Organizational Units(OU)",
      "R&D AWS account",
      "management account",
      "organization"
    ],
    "SelectA": "전환 기간 동안 R&D AWS account가 두 개의 organization에 모두 소속되도록 합니다.",
    "SelectA_Commentary": "AWS account는 동시에 두 organization에 소속될 수 없기 때문에 불가능한 접근입니다.",
    "SelectB": "기존 organization에서 R&D AWS account를 탈퇴시킨 후, 새 organization에 초대하여 합류시킵니다.",
    "SelectB_Commentary": "정답입니다. 계정은 하나의 organization에만 속할 수 있으므로, 기존 organization을 탈퇴한 후 초대해야 합니다.",
    "SelectC": "새 organization에서 R&D AWS account를 새로 생성하고, 기존 계정의 리소스를 새 계정으로 마이그레이션합니다.",
    "SelectC_Commentary": "기존 계정을 활용하지 않고 불필요한 마이그레이션이 발생하여 비효율적입니다.",
    "SelectD": "R&D AWS account가 새 organization에 가입하도록 하고, 새 management account를 기존 organization의 멤버로 만듭니다.",
    "SelectD_Commentary": "분리 의도와 달리 새 management account가 기존 조직에 속하게 되어, 목적과 어긋납니다.",
    "Question_Description_recommedations": [
      "Q560",
      "Q878",
      "Q777",
      "Q988",
      "Q709"
    ],
    "SelectA_recommedations": [
      "Q945",
      "Q168",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q945",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q233",
      "Q592"
    ],
    "SelectD_recommedations": [
      "Q586",
      "Q945",
      "Q168"
    ]
  },
  {
    "Question_Number": "Q587",
    "Question_Description": "한 회사가 여러 웹 애플리케이션에서 고객 활동 데이터를 수집하여 분석(analytics) 및 예측(predictions)을 수행하려고 합니다. 이 웹 애플리케이션들은 고객 활동이 예측 불가능하고 갑자기 증가할 수 있습니다. 또한 다른 웹 애플리케이션과 쉽게 연동되어야 하며, 보안을 위해 권한 부여(authorization) 단계가 반드시 포함되어야 합니다. 이러한 요구사항을 모두 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119576-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능하게 증가하는 고객 활동 데이터를 안정적으로 수집하고, 타 웹 애플리케이션과 손쉽게 연동되며, 권한 부여 단계를 갖춘 파이프라인을 구축하려는 시나리오입니다. 확장성과 보안을 모두 충족해야 하므로 Amazon API Gateway + Amazon Kinesis Data Firehose + API Gateway Lambda authorizer 조합이 가장 적합한 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "웹 애플리케이션",
      "고객 활동",
      "분석",
      "예측",
      "불규칙한 트래픽",
      "권한 부여",
      "Amazon API Gateway",
      "Amazon Kinesis Data Firehose",
      "Amazon S3"
    ],
    "Terms": [
      "Gateway Load Balancer (GWLB)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon API Gateway",
      "Amazon Kinesis Data Stream",
      "Amazon Kinesis Data Firehose",
      "Amazon S3",
      "AWS Lambda",
      "API Gateway Lambda authorizer"
    ],
    "SelectA": "Gateway Load Balancer (GWLB)를 Amazon ECS 컨테이너 인스턴스 앞에 구성하고, 수집된 정보를 Amazon EFS 파일 시스템에 저장합니다. 권한 부여는 GWLB에서 처리됩니다.",
    "SelectA_Commentary": "GWLB는 네트워크 트래픽 처리나 서드파티 어플라이언스 통합 목적에 적합합니다. 데이터 수집 파이프라인에 직접 연동하기엔 부적절하며, 확장성과 권한 부여 측면에서 복잡성이 증가합니다.",
    "SelectB": "Amazon API Gateway 엔드포인트를 Amazon Kinesis data stream 앞에 두고 데이터를 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 사용해 권한 부여를 처리합니다.",
    "SelectB_Commentary": "API Gateway와 Kinesis data stream 연동은 가능하지만, 권한 부여를 Lambda 함수에서 직접 처리하는 것보다는 API Gateway Lambda authorizer가 더 적합합니다. Firehose 대신 Stream 사용 시 추가 구성도 필요합니다.",
    "SelectC": "Amazon API Gateway 엔드포인트를 Amazon Kinesis Data Firehose 앞에 두고, 수집된 데이터를 Amazon S3 버킷에 저장합니다. 권한 부여는 API Gateway Lambda authorizer를 사용해서 처리합니다.",
    "SelectC_Commentary": "확장 가능한 실시간 데이터 수집 파이프라인을 구축할 수 있으며, API Gateway에서 제공하는 Lambda authorizer로 안전한 권한 부여를 구현할 수 있습니다. 요구사항을 모두 충족하므로 정답입니다.",
    "SelectD": "Gateway Load Balancer (GWLB)를 Amazon ECS 컨테이너 인스턴스 앞에 구성하고, 수집된 정보를 Amazon EFS 파일 시스템에 저장합니다. AWS Lambda 함수를 사용해 권한 부여를 처리합니다.",
    "SelectD_Commentary": "GWLB와 ECS 기반 솔루션은 네트워킹 구성 및 운영이 복잡하며, 불규칙한 트래픽 스케일링에서 효율적이지 않습니다. 단순 수집 파이프라인으로는 과도한 설정입니다.",
    "Question_Description_recommedations": [
      "Q493",
      "Q77",
      "Q631",
      "Q432",
      "Q516"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q358",
      "Q12"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q576",
      "Q402"
    ],
    "SelectC_recommedations": [
      "Q597",
      "Q576",
      "Q402"
    ],
    "SelectD_recommedations": [
      "Q358",
      "Q815",
      "Q141"
    ]
  },
  {
    "Question_Number": "Q588",
    "Question_Description": "한 전자상거래 회사는 Microsoft SQL Server Enterprise Edition으로 실행되는 Amazon RDS DB 인스턴스에 대한 재해 복구(Disaster Recovery) 솔루션을 원합니다. 현재 RPO(Recovery Point Objective)와 RTO(Recovery Time Objective)는 24시간입니다. 비용 효율적으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119718-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Microsoft SQL Server Enterprise Edition을 사용하는 RDS 환경에서 24시간 RPO와 RTO 목표를 달성하기 위한 재해 복구 전략을 찾는 것입니다. 가장 단순하고 비용 효율적인 방법은 자동 스냅샷을 다른 리전으로 정기적으로 복사하여, 재해 상황 시 복원할 수 있도록 대비하는 것입니다. 이는 별도의 복제나 고가의 서비스 운영 없이도 단순히 스냅샷을 이용해 RPO와 RTO를 충족시킬 수 있어 DR 비용을 최소화해 줍니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "재해 복구",
      "RDS DB 인스턴스",
      "Microsoft SQL Server Enterprise Edition",
      "RPO 24시간",
      "RTO 24시간",
      "비용 효율",
      "자동 스냅샷"
    ],
    "Terms": [
      "cross-Region read replica",
      "AWS Database Migration Service (AWS DMS)",
      "RDS cross-Region replication",
      "native backups",
      "Amazon S3",
      "automatic snapshots",
      "Microsoft SQL Server Enterprise Edition"
    ],
    "SelectA": "교차 리전 cross-Region read replica를 생성하고, 이를 프로모션하여 기본 인스턴스로 승격합니다.",
    "SelectA_Commentary": "Microsoft SQL Server 용 RDS는 cross-Region read replica 지원이 제한적이며, 이 접근은 비용적으로도 비효율적입니다.",
    "SelectB": "AWS DMS(AWS Database Migration Service)를 사용하여 RDS 교차 리전 복제를 설정합니다.",
    "SelectB_Commentary": "지속적인 데이터 동기화를 위한 DMS 구성은 상대적으로 운영 복잡도가 높고, 스냅샷 복사 대비 비용 효율이 떨어질 수 있습니다.",
    "SelectC": "매 24시간마다 교차 리전 복제를 실행하여 원본의 native 백업을 Amazon S3 버킷으로 복사합니다.",
    "SelectC_Commentary": "native 백업 파일을 관리하고 별도 복제 작업을 스케줄링해야 하므로 운영상 부담이 있으며 자동 스냅샷 복사보다 간단하지 않습니다.",
    "SelectD": "자동 스냅샷을 매 24시간마다 다른 리전으로 복사합니다.",
    "SelectD_Commentary": "자동 스냅샷 복사는 설정 및 운영이 간단하면서도 RPO와 RTO를 24시간으로 충족하여 비용 효율적인 DR 솔루션을 제공합니다.",
    "Question_Description_recommedations": [
      "Q539",
      "Q274",
      "Q281",
      "Q71",
      "Q273"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q615",
      "Q967"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q629",
      "Q259"
    ],
    "SelectC_recommedations": [
      "Q784",
      "Q8",
      "Q149"
    ],
    "SelectD_recommedations": [
      "Q967",
      "Q362",
      "Q187"
    ]
  },
  {
    "Question_Number": "Q589",
    "Question_Description": "한 회사가 Application Load Balancer 뒤에서 Auto Scaling 그룹의 Amazon EC2 인스턴스를 이용해 웹 애플리케이션을 운영하고 있으며, 응답 일관성을 위해 ALB에서 sticky session을 활성화한 상태입니다. 현재 웹 서버 자체가 사용자 세션 상태를 호스팅하고 있습니다. 회사는 웹 서버 장애 발생 시 사용자 세션 상태 손실 없이 고가용성을 보장하고 싶어 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119487-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "본 문제는 웹 애플리케이션에서 세션 상태를 웹 서버에 직접 유지하고 있을 때, 서버 장애가 발생해도 사용자 세션을 안전하게 유지하는 방법을 묻고 있습니다. ElastiCache for Redis는 멀티 AZ 구성과 복제를 통해 고가용성을 보장하면서 세션 데이터를 인메모리에서 빠르게 처리할 수 있어, 웹 서버 장애 시에도 세션이 손실되지 않도록 지원합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "세션 상태",
      "sticky session",
      "애플리케이션 로드 밸런서",
      "Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "sticky sessions",
      "Session state",
      "Amazon ElastiCache",
      "Memcached",
      "Redis",
      "AWS Storage Gateway",
      "Amazon RDS"
    ],
    "SelectA": "Amazon ElastiCache for Memcached 인스턴스를 사용해 세션 데이터를 저장하고, 애플리케이션을 수정하여 Memcached를 세션 상태 저장소로 활용합니다.",
    "SelectA_Commentary": "Memcached는 인메모리 캐시 기능은 제공하지만, Redis만큼 고급 복제 및 멀티 AZ 구성을 활용하기 어렵습니다. 고가용성 확보에 제약이 있습니다.",
    "SelectB": "Amazon ElastiCache for Redis를 사용해 세션 상태를 저장하고, 애플리케이션을 수정하여 Redis를 세션 상태 저장소로 활용합니다.",
    "SelectB_Commentary": "Redis는 복제와 멀티 AZ 구성을 지원해 서버 장애 시에도 사용자 세션을 안전하게 유지해 고가용성을 실현할 수 있는 최적의 솔루션입니다.",
    "SelectC": "AWS Storage Gateway cached volume을 사용해 세션 데이터를 저장하고, 애플리케이션을 수정하여 AWS Storage Gateway cached volume을 세션 상태 저장소로 활용합니다.",
    "SelectC_Commentary": "Storage Gateway는 온프레미스와 AWS 간의 스토리지 연동을 위해 주로 쓰이며, 세션 상태 저장 용도로는 과도하게 복잡하고 실시간성 요구를 만족하기 어렵습니다.",
    "SelectD": "Amazon RDS에 세션 상태를 저장하고, 애플리케이션을 수정하여 RDS를 세션 상태 저장소로 활용합니다.",
    "SelectD_Commentary": "RDS는 관계형 데이터베이스로 내구성은 뛰어나나 인메모리 캐싱보다 세션 접근 속도가 떨어지고, 단순 세션 데이터 저장에는 과도한 비용과 복잡성이 따를 수 있습니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q174",
      "Q333",
      "Q693",
      "Q275"
    ],
    "SelectA_recommedations": [
      "Q824",
      "Q768",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q593",
      "Q48",
      "Q768"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q293",
      "Q869"
    ],
    "SelectD_recommedations": [
      "Q108",
      "Q863",
      "Q259"
    ]
  },
  {
    "Question_Number": "Q590",
    "Question_Description": "한 회사가 온프레미스 데이터 센터의 MySQL 데이터베이스를 Amazon RDS for MySQL DB 인스턴스로 마이그레이션했습니다. 회사는 RDS DB 인스턴스를 일상적인 평균 워크로드에 맞게 크기 조정했습니다. 매달 한 번씩 보고서 작성을 위해 쿼리를 실행할 때 데이터베이스 성능이 저하됩니다. 회사는 보고서를 실행하면서도 일상적인 워크로드의 성능을 유지하고 싶어 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119719-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 월간 보고서용 쿼리가 본 DB 인스턴스의 성능을 저해하지 않도록 하는 방법을 묻습니다. Read Replica를 사용하면 복제된 데이터베이스에서 읽기 작업을 수행하므로 본 데이터베이스의 부하를 줄이고 일상 업무 성능을 유지할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "월간 보고서",
      "읽기 성능",
      "Read Replica",
      "성능 저하 방지"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Read Replica",
      "Backup & Restore",
      "Amazon S3",
      "Amazon Athena",
      "DB Instance Resize"
    ],
    "SelectA": "데이터베이스의 Read Replica를 생성하고, 보고서 쿼리를 Read Replica에 직접 수행하도록 설정합니다.",
    "SelectA_Commentary": "Read Replica를 활용하면 원본 DB와 동기화된 데이터를 조회할 수 있고, 본 DB 성능 저하 없이 월간 보고서를 생성할 수 있습니다.",
    "SelectB": "데이터베이스의 백업을 생성한 뒤, 다른 DB 인스턴스로 복원하고 보고서 쿼리를 새 데이터베이스로 전송합니다.",
    "SelectB_Commentary": "별도의 DB 인스턴스를 항상 유지해야 하므로 운영 복잡도와 비용이 증가하며, 실시간 동기화가 이루어지지 않아 최신 데이터 조회가 제한될 수 있습니다.",
    "SelectC": "데이터를 Amazon S3로 Export한 후, Amazon Athena를 사용하여 S3 버킷을 쿼리합니다.",
    "SelectC_Commentary": "보고서용 데이터를 정기적으로 Export해야 하고, ETL 과정이 필요할 수 있어 운영 복잡도와 지연이 발생합니다.",
    "SelectD": "DB 인스턴스를 더 큰 크기로 리사이징하여 추가 워크로드를 수용합니다.",
    "SelectD_Commentary": "월간 보고서 작업에만 필요한 부담을 위해 상시로 DB 인스턴스 크기를 키우는 것은 비용 비효율적이며, 운영 전략으로도 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q376",
      "Q95",
      "Q269",
      "Q661",
      "Q726"
    ],
    "SelectA_recommedations": [
      "Q888",
      "Q506",
      "Q132"
    ],
    "SelectB_recommedations": [
      "Q888",
      "Q506",
      "Q132"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ]
  },
  {
    "Question_Number": "Q591",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 애플리케이션을 운영하고 있습니다. 애플리케이션은 고객 관리와 주문 처리를 담당하는 마이크로서비스를 포함합니다. 회사는 들어오는 요청을 적절한 마이크로서비스로 라우팅해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119574-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "마이크로서비스별로 적절하게 트래픽을 라우팅하려면 7계층 기반의 세분화된 라우팅이 필요한데, AWS Load Balancer Controller와 Application Load Balancer 조합이 가장 경제적이고 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "Amazon EKS",
      "마이크로서비스",
      "요청 라우팅",
      "비용 효율성",
      "Application Load Balancer"
    ],
    "Terms": [
      "Amazon EKS",
      "Microservices",
      "AWS Load Balancer Controller",
      "Application Load Balancer",
      "Network Load Balancer",
      "AWS Lambda",
      "Amazon API Gateway"
    ],
    "SelectA": "AWS Load Balancer Controller를 사용하여 Network Load Balancer를 프로비저닝합니다.",
    "SelectA_Commentary": "Network Load Balancer는 L4 기반으로 HTTP 경로 라우팅이 제한적이어서 마이크로서비스 라우팅에 적합하지 않습니다.",
    "SelectB": "AWS Load Balancer Controller를 사용하여 Application Load Balancer를 프로비저닝합니다.",
    "SelectB_Commentary": "Application Load Balancer는 L7 기반 라우팅 제공으로 마이크로서비스별 트래픽 분기가 가능하며, 비용 역시 효율적이어서 정답입니다.",
    "SelectC": "AWS Lambda 함수를 사용하여 요청을 Amazon EKS로 연결합니다.",
    "SelectC_Commentary": "Lambda를 중간 계층으로 사용하는 것은 추가 비용과 운영 복잡도가 높아져, 가장 비용효율적인 방법이 아닙니다.",
    "SelectD": "Amazon API Gateway를 사용하여 요청을 Amazon EKS로 연결합니다.",
    "SelectD_Commentary": "API Gateway는 유연하지만 높은 비용이 발생할 수 있으며, 단순 라우팅 조건에서는 과도합니다.",
    "Question_Description_recommedations": [
      "Q677",
      "Q238",
      "Q867",
      "Q552",
      "Q671"
    ],
    "SelectA_recommedations": [
      "Q473",
      "Q146",
      "Q894"
    ],
    "SelectB_recommedations": [
      "Q473",
      "Q146",
      "Q894"
    ],
    "SelectC_recommedations": [
      "Q591",
      "Q238",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q591",
      "Q300",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q592",
    "Question_Description": "한 회사는 AWS를 사용하여 저작권이 있는 이미지를 판매합니다. 전 세계 고객들이 이 이미지를 빠르게 액세스할 수 있어야 하며, 특정 국가의 사용자는 접근을 제한해야 합니다. 또한 회사는 비용을 가능한 한 최소화하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119573-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS에서 저작권이 있는 이미지를 전 세계적으로 빠른 속도로 배포하면서 특정 국가를 차단해야 하는 아키텍처 설계 방안을 묻습니다. S3에 이미지를 저장한 후 CloudFront를 통해 지리적 제한을 적용하고, 액세스 제어를 위해 Signed URL을 사용하는 것이 핵심입니다. 이는 접근을 효율적으로 통제하면서 글로벌 캐싱으로 성능을 높이고, 운영 및 비용을 최소화할 수 있는 최적의 방안입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "전 세계 고객",
      "빠른 이미지 액세스",
      "특정 국가 접근 제한",
      "비용 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "MFA",
      "IAM",
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "Amazon CloudFront",
      "지리적 제한(Geo restriction)",
      "Signed URL"
    ],
    "SelectA": "Amazon S3에 이미지를 저장합니다. MFA를 활성화하고 퍼블릭 버킷 액세스를 설정한 뒤, 고객에게 S3 버킷 링크를 제공합니다.",
    "SelectA_Commentary": "MFA와 퍼블릭 접근으로는 특정 국가 차단이 불가능하며, 직접 S3 버킷 링크를 노출하는 것은 보안상 위험합니다.",
    "SelectB": "Amazon S3에 이미지를 저장합니다. 각 고객별로 IAM 사용자를 생성하고, S3 버킷에 접근 권한이 있는 그룹에 사용자를 추가합니다.",
    "SelectB_Commentary": "고객마다 IAM 사용자를 만드는 것은 관리가 복잡하고 특정 국가를 제한하는 설정이 별도로 필요해 운영 부담이 큽니다.",
    "SelectC": "Application Load Balancer(ALB) 뒤에 있는 Amazon EC2 인스턴스에 이미지를 저장합니다. 회사가 서비스를 제공하는 국가에만 인스턴스를 배포하고, ALB 링크를 고객에게 제공합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 국가별로 배포해 차단은 가능하지만 비용이 많이 들고, 단순한 콘텐츠 배포에는 과도하게 복잡한 구조입니다.",
    "SelectD": "Amazon S3에 이미지를 저장합니다. Amazon CloudFront를 사용해 지리적 제한을 적용해 이미지를 배포하고, 고객마다 Signed URL을 제공하여 CloudFront에서 데이터를 액세스하도록 합니다.",
    "SelectD_Commentary": "CloudFront의 지리적 제한과 Signed URL을 사용하면 특정 국가를 차단할 수 있고, 전 세계 엣지 로케이션으로 빠르게 이미지를 제공하므로 비용과 성능 모두 최적화됩니다.",
    "Question_Description_recommedations": [
      "Q313",
      "Q922",
      "Q831",
      "Q893",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q202",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q884",
      "Q707",
      "Q437"
    ],
    "SelectD_recommedations": [
      "Q131",
      "Q291",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q593",
    "Question_Description": "한 솔루션스 아키텍트가 고가용성을 갖춘 Amazon ElastiCache for Redis 기반 솔루션을 설계하고 있습니다. 이 솔루션스 아키텍트는 로컬 및 AWS Region 내부에서 장애가 발생하더라도 성능 저하나 데이터 손실이 없도록 보장해야 합니다. 솔루션은 노드 레벨과 Region 레벨에서 모두 고가용성을 제공해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119572-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon ElastiCache for Redis 아키텍처에서 노드 및 Region 단에서 장애 발생 시에도 성능이 저하되지 않고 데이터 손실 없이 안정적으로 운영하기 위한 구성 방안을 묻습니다. Multi-AZ 설정으로 가용영역(AZ) 장애 시 자동으로 장애 조치가 가능하며, 충분한 수의 read replica를 보유해 한 노드가 장애를 일으켜도 다른 노드가 즉시 승계해 성능 저하를 방지하는 구성이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "Amazon ElastiCache for Redis",
      "멀티AZ",
      "노드 레벨",
      "Region 레벨",
      "성능 저하 방지"
    ],
    "Terms": [
      "Amazon ElastiCache for Redis",
      "Multi-AZ",
      "Redis replication group",
      "shard",
      "append only files (AOF)",
      "Auto Scaling",
      "read replica"
    ],
    "SelectA": "Multi-AZ Redis replication groups를 사용하고, 각 shard에 여러 노드를 포함시킵니다.",
    "SelectA_Commentary": "기본적으로 Multi-AZ 설정으로 고가용성을 보장하지만, 단일 read replica만 구성하면 장애 시 일시적인 성능 저하 가능성이 존재해 요구사항을 완전히 충족하기 어렵습니다.",
    "SelectB": "Redis shard에 여러 노드를 포함하고, Redis append only files(AOF)를 활성화합니다.",
    "SelectB_Commentary": "AOF는 영구 스토리지 기능을 제공하지만, Multi-AZ 구성이 필수적으로 언급되지 않아 장애 상황에서의 가용성과 성능 저하 방지 측면에서 충분치 않습니다.",
    "SelectC": "Multi-AZ Redis 클러스터를 사용하고, replication group 내에 2개 이상의 read replica를 구성합니다.",
    "SelectC_Commentary": "Multi-AZ 설정으로 영역(AZ) 장애를 대비하고, 여러 read replica를 두어 한 노드 장애 시에도 즉각 프로모션할Replica가 남아있어 성능 저하 없이 고가용성을 확보할 수 있으므로 요구사항을 가장 잘 충족합니다.",
    "SelectD": "Redis shard에 여러 노드를 포함하고, Auto Scaling을 활성화합니다.",
    "SelectD_Commentary": "Auto Scaling은 트래픽 변동에 따른 자동 확장은 가능하나, 실패 시 데이터 무손실과 성능 저하 방지에 핵심인 Multi-AZ 및 복제본 관리가 보장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q178",
      "Q456",
      "Q224",
      "Q312",
      "Q47"
    ],
    "SelectA_recommedations": [
      "Q958",
      "Q989",
      "Q466"
    ],
    "SelectB_recommedations": [
      "Q753",
      "Q401",
      "Q188"
    ],
    "SelectC_recommedations": [
      "Q958",
      "Q466",
      "Q390"
    ],
    "SelectD_recommedations": [
      "Q1001",
      "Q660",
      "Q198"
    ]
  },
  {
    "Question_Number": "Q594",
    "Question_Description": "한 회사가 AWS로 마이그레이션을 계획하고 Amazon EC2 On-Demand Instances를 애플리케이션에 사용하려고 합니다. 마이그레이션 테스트 단계에서 기술 팀은 애플리케이션이 완전히 동작 가능해지기 위해 구동과 메모리 로드에 긴 시간이 걸린다는 사실을 관찰했습니다. 다음 테스트 단계에서 애플리케이션의 구동 시간을 단축하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119570-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "애플리케이션이 시작될 때 메모리 로드 과정이 오래 걸릴 경우, EC2 hibernation과 Auto Scaling warm pools를 활용하면 이미 로드된 상태를 빠르게 재개할 수 있어 구동 시간을 단축할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "마이그레이션",
      "EC2 On-Demand Instances",
      "어플리케이션 구동 시간",
      "메모리 로드",
      "EC2 hibernation",
      "Auto Scaling warm pools"
    ],
    "Terms": [
      "Amazon EC2",
      "On-Demand Instances",
      "Spot Instances",
      "EC2 Auto Scaling warm pools",
      "EC2 hibernation",
      "Capacity Reservations"
    ],
    "SelectA": "두 개 이상의 EC2 On-Demand Instances를 실행합니다. Auto Scaling 기능을 켜고, 다음 테스트 단계에서 EC2 On-Demand Instances를 사용 가능하도록 합니다.",
    "SelectA_Commentary": "인스턴스를 여러 대 띄우고 Auto Scaling을 활용하더라도, 애플리케이션 구동 시간을 근본적으로 줄이지 못하며 이미 로드된 상태에서 재시작하는 기능은 제공되지 않습니다.",
    "SelectB": "애플리케이션을 지원하기 위해 EC2 Spot Instances를 실행하고 애플리케이션을 스케일하여 다음 테스트 단계에서 사용 가능하도록 합니다.",
    "SelectB_Commentary": "Spot Instances는 비용 절감에는 유리하지만, 강제 중단 가능성이 있어 안정적인 구동 시간 단축에는 직접적인 도움이 되지 않습니다.",
    "SelectC": "EC2 On-Demand Instances를 hibernation이 켜진 상태로 실행합니다. 다음 테스트 단계에서 EC2 Auto Scaling warm pools를 구성합니다.",
    "SelectC_Commentary": "hibernation으로 메모리 상태를 그대로 보존하고, warm pools로 미리 초기화된 인스턴스를 대기시키면 구동 및 메모리 로드 시간을 크게 단축할 수 있는 최적의 방법입니다.",
    "SelectD": "Capacity Reservations를 사용하여 EC2 On-Demand Instances를 실행합니다. 다음 테스트 단계에서 추가 EC2 인스턴스를 시작합니다.",
    "SelectD_Commentary": "Capacity Reservations는 인스턴스 용량을 예약해 주지만, 메모리 로드를 단축하거나 빠르게 재시작하는 기능을 제공하지 않으므로 구동 시간 단축에는 직접적으로 기여하지 않습니다.",
    "Question_Description_recommedations": [
      "Q746",
      "Q690",
      "Q219",
      "Q193",
      "Q910"
    ],
    "SelectA_recommedations": [
      "Q594",
      "Q335",
      "Q746"
    ],
    "SelectB_recommedations": [
      "Q690",
      "Q594",
      "Q746"
    ],
    "SelectC_recommedations": [
      "Q594",
      "Q857",
      "Q690"
    ],
    "SelectD_recommedations": [
      "Q594",
      "Q690",
      "Q976"
    ]
  },
  {
    "Question_Number": "Q595",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 Auto Scaling group을 통해 애플리케이션을 운영하고 있습니다. 이 회사는 주중 임의의 요일에 갑작스럽게 트래픽이 증가한다는 점을 발견했습니다. 회사는 이러한 예기치 못한 트래픽 급증 시에도 애플리케이션 성능을 유지하고 싶어 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119569-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능한 트래픽 급증에 대비해 애플리케이션 성능을 유지하고 비용까지 절감해야 하는 상황을 묻습니다. Dynamic Scaling은 지표 기반 자동 확장으로 갑작스러운 트래픽에도 유연하고 효율적인 대응이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "갑작스러운 트래픽 증가",
      "비용 효율성",
      "애플리케이션 성능",
      "Amazon EC2",
      "Auto Scaling group",
      "Dynamic Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Manual Scaling",
      "Predictive Scaling",
      "Dynamic Scaling",
      "Schedule Scaling"
    ],
    "SelectA": "수동 스케일링(Manual Scaling)을 사용하여 Auto Scaling group의 크기를 변경합니다.",
    "SelectA_Commentary": "수동 스케일링은 운영자가 직접 조정해야 하므로 신속한 대응이 어려워 비효율적입니다.",
    "SelectB": "Predictive Scaling을 사용하여 Auto Scaling group의 크기를 변경합니다.",
    "SelectB_Commentary": "Predictive Scaling은 트래픽 패턴이 비교적 예측 가능한 경우에 효과적이며, 갑작스러운 급증에는 부적합합니다.",
    "SelectC": "Dynamic Scaling을 사용하여 Auto Scaling group의 크기를 변경합니다.",
    "SelectC_Commentary": "동적으로 지표를 모니터링해 필요한 경우 즉시 확장하므로 예측 불가능한 트래픽 급증에 가장 비용 효율적입니다.",
    "SelectD": "Schedule Scaling을 사용하여 Auto Scaling group의 크기를 변경합니다.",
    "SelectD_Commentary": "정해진 시간표를 기반으로 확장하므로 트래픽 패턴이 일정하지 않은 상황에서는 효과가 떨어집니다.",
    "Question_Description_recommedations": [
      "Q581",
      "Q271",
      "Q1001",
      "Q660",
      "Q342"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q1001",
      "Q595",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q596",
    "Question_Description": "한 전자상거래 애플리케이션이 Amazon EC2 인스턴스에서 실행되는 PostgreSQL 데이터베이스를 사용하고 있습니다. 월간 세일 이벤트 기간에 데이터베이스 사용량이 증가하여 애플리케이션에 데이터베이스 연결 문제가 발생합니다. 이후 이벤트에서도 예측 불가능한 트래픽이 계속 발생하여 세일 예측에 영향을 주고 있습니다. 회사는 예측 불가능한 트래픽 급증 상황에서도 성능을 유지해야 합니다. 가장 비용 효율적인 방법으로 이 문제를 해결하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119590-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 월간 이벤트마다 트래픽이 예측 불가능하게 급증하는 상황에서 데이터베이스 성능과 비용 효율성을 모두 만족하는 방안을 찾는 것입니다. Amazon Aurora Serverless v2를 사용하면 자동으로 확장되고 사용한 만큼만 비용을 지불하여, 예측 어려운 급증 트래픽에 유연하게 대처할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "전자상거래 애플리케이션",
      "월간 세일 이벤트",
      "Amazon EC2",
      "PostgreSQL",
      "예측 불가능한 트래픽",
      "비용 효율적",
      "Amazon Aurora Serverless v2"
    ],
    "Terms": [
      "Amazon Aurora Serverless v2",
      "Amazon EC2",
      "auto scaling",
      "Amazon RDS for PostgreSQL",
      "Amazon Redshift",
      "PostgreSQL"
    ],
    "SelectA": "PostgreSQL 데이터베이스를 Amazon Aurora Serverless v2로 이전합니다.",
    "SelectA_Commentary": "Aurora Serverless v2는 필요에 따라 자동으로 확장하며 비용도 사용량 기반으로 청구되어 예측 불가능한 트래픽 급증에 가장 유연하고 경제적인 선택입니다.",
    "SelectB": "EC2 인스턴스에서 PostgreSQL 데이터베이스에 대해 auto scaling을 활성화합니다.",
    "SelectB_Commentary": "EC2 일반 인스턴스에서의 auto scaling은 제한적이며, 확장 작업이 복잡할 수 있어 트래픽 급증 시 신속하고 효율적인 대응이 어렵습니다.",
    "SelectC": "PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL로 마이그레이션하고 더 큰 인스턴스 유형을 사용합니다.",
    "SelectC_Commentary": "더 큰 인스턴스만으로는 갑작스러운 급증을 완벽히 처리하기 어려우며, 항상 높은 사양을 유지하는 것은 비용 효율성이 낮아질 수 있습니다.",
    "SelectD": "PostgreSQL 데이터베이스를 Amazon Redshift로 마이그레이션합니다.",
    "SelectD_Commentary": "Amazon Redshift는 주로 데이터 웨어하우징 및 분석 워크로드에 최적화되어 있어, 트랜잭션성 애플리케이션 DB 용도로는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q229",
      "Q746",
      "Q381",
      "Q192",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q235",
      "Q596",
      "Q886"
    ],
    "SelectB_recommedations": [
      "Q674",
      "Q596",
      "Q335"
    ],
    "SelectC_recommedations": [
      "Q726",
      "Q909",
      "Q386"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q235",
      "Q596"
    ]
  },
  {
    "Question_Number": "Q597",
    "Question_Description": "한 회사가 Amazon API Gateway와 AWS Lambda를 사용하여 내부 서버리스 애플리케이션을 호스팅하고 있습니다. 회사의 직원들은 매일 애플리케이션을 사용하기 시작할 때 높은 지연(latency) 문제를 보고합니다. 회사는 지연을 줄이기를 원합니다. 어떤 해결책이 이러한 요구사항을 충족할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119465-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "매일 아침 사용자 유입 시점에 발생하는 Lambda Cold Start가 지연의 주원인입니다. Provisioned Concurrency를 미리 확보해 두면 Lambda가 사전에 준비되어 지연을 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "서버리스 애플리케이션",
      "Amazon API Gateway",
      "AWS Lambda",
      "지연(latency)",
      "Provisioned Concurrency",
      "스케줄 기반 확장"
    ],
    "Terms": [
      "Amazon API Gateway",
      "AWS Lambda",
      "Provisioned Concurrency",
      "스케줄 기반 확장",
      "Amazon CloudWatch Alarm",
      "Lambda function memory"
    ],
    "SelectA": "API Gateway throttling limit을 높입니다.",
    "SelectA_Commentary": "API Gateway 제한을 늘려도 Lambda Cold Start 문제는 해결되지 않으므로 지연 완화 효과가 적습니다.",
    "SelectB": "사용자가 애플리케이션을 사용하기 전 Lambda에 Provisioned Concurrency를 스케줄링으로 미리 설정합니다.",
    "SelectB_Commentary": "사전에 Lambda 환경을 준비시켜 Cold Start를 줄이는 직접적인 해결책으로 지연을 크게 감소시킵니다.",
    "SelectC": "하루 시작 시점에 Amazon CloudWatch alarm을 트리거하여 Lambda 함수를 실행합니다.",
    "SelectC_Commentary": "알람으로 함수 호출은 가능하지만 늘 준비 상태를 확보하기에 충분하지 않아 지연 개선이 제한적입니다.",
    "SelectD": "Lambda function의 메모리를 늘립니다.",
    "SelectD_Commentary": "메모리를 늘리면 일부 성능은 향상될 수 있지만, Cold Start 자체를 근본적으로 줄이지 못합니다.",
    "Question_Description_recommedations": [
      "Q576",
      "Q379",
      "Q175",
      "Q704",
      "Q38"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q352",
      "Q597"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q746",
      "Q443"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q361",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q77",
      "Q888",
      "Q158"
    ]
  },
  {
    "Question_Number": "Q598",
    "Question_Description": "한 연구 회사가 on-premises 장치를 사용해 데이터를 생성합니다. 이 장치는 .csv 파일을 SMB file share로 저장할 수 있습니다. 회사는 이 데이터를 AWS Cloud에서 분석하고자 하며, 분석 담당자들은 SQL 명령어로 주기적으로 쿼리를 실행해야 합니다. 가장 비용 효율적으로 이 요구사항을 충족하려면 어떤 단계를 결합해야 할까요? (3개를 선택하십시오.)",
    "Answer": "A,C,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119563-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 on-premises에서生成된 CSV 파일을 SMB file share로 저장하고, AWS 클라우드에서 간단하고 저렴하게 SQL 분석을 수행해야 하는 상황입니다. S3 File Gateway로 데이터를 S3에 저장한 뒤, AWS Glue와 Amazon Athena를 사용하면 최소 비용으로 요구사항을 충족할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.3"
    ],
    "Keywords": [
      "on-premises 데이터",
      "SMB file share",
      "AWS Cloud",
      "SQL 쿼리",
      "비용 효율",
      "Amazon S3 File Gateway",
      "AWS Glue Crawler",
      "Amazon Athena"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Amazon S3 File Gateway",
      "AWS Glue",
      "AWS Glue crawler",
      "Amazon EMR",
      "EMRFS",
      "Amazon Redshift",
      "Amazon Athena",
      "SMB file share"
    ],
    "SelectA": "on-premises 환경에 AWS Storage Gateway를 Amazon S3 File Gateway 모드로 배포합니다.",
    "SelectA_Commentary": "SMB file share를 바로 S3와 연결해 자동 동기화가 가능하므로, CSV 데이터를 손쉽게 S3에 적재할 수 있어 운영 복잡도를 줄이고 비용 효율을 높일 수 있습니다.",
    "SelectB": "on-premises 환경에 AWS Storage Gateway를 Amazon FSx File Gateway 모드로 배포합니다.",
    "SelectB_Commentary": "이 옵션은 FSx for Windows File Server를 대상으로 하며, 문제에서 요구하는 Athena 기반 SQL 분석과 직접 연계가 어려워서 적합하지 않습니다.",
    "SelectC": "Amazon S3에 있는 데이터를 기반으로 AWS Glue crawler를 설정해 테이블을 생성합니다.",
    "SelectC_Commentary": "Glue crawler가 S3에 업로드된 CSV 파일 구조를 자동으로 분석하여 Glue Data Catalog에 테이블 스키마를 생성하므로, Athena에서 쉽게 쿼리할 수 있습니다.",
    "SelectD": "Amazon EMR 클러스터를 설정하고 EMRFS를 사용해 Amazon S3의 데이터를 쿼리합니다. 분석 담당자에게 접근 권한을 제공합니다.",
    "SelectD_Commentary": "EMR 클러스터는 비용이 더 많이 들고 상시 클러스터 관리가 필요해, 주기적 쿼리를 위한 가장 비용 효율적인 방식이 아닙니다.",
    "SelectE": "Amazon Redshift 클러스터를 설정해 Amazon S3의 데이터를 쿼리합니다. 분석 담당자에게 접근 권한을 제공합니다.",
    "SelectE_Commentary": "Redshift는 대규모 데이터 웨어하우스용으로 적합하지만, 주기적이며 간단한 쿼리에 대해서는 관리 오버헤드와 비용이 더 들 수 있어 다른 선택지보다 비효율적입니다.",
    "SelectF": "Amazon Athena를 설정해 Amazon S3의 데이터를 쿼리합니다. 분석 담당자에게 접근 권한을 제공합니다.",
    "SelectF_Commentary": "Athena는 서버리스 SQL 쿼리 서비스로, 사용한 양에 대해서만 비용을 지불하므로 주기적 쿼리에 가장 적합하고 운영 부담도 적습니다.",
    "Question_Description_recommedations": [
      "Q806",
      "Q979",
      "Q411",
      "Q993",
      "Q449"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q806",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q806",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q993",
      "Q469",
      "Q829"
    ],
    "SelectD_recommedations": [
      "Q652",
      "Q993",
      "Q703"
    ],
    "SelectE_recommedations": [
      "Q943",
      "Q728",
      "Q486"
    ],
    "SelectF_recommedations": [
      "Q285",
      "Q1003",
      "Q769"
    ]
  },
  {
    "Question_Number": "Q599",
    "Question_Description": "한 회사가 결제 처리 애플리케이션을 구축 및 실행하기 위해 Amazon Elastic Container Service(Amazon ECS) 클러스터와 Amazon RDS DB 인스턴스를 사용하려고 합니다. 해당 회사는 컴플라이언스 목적으로 온프레미스 데이터 센터에서 애플리케이션을 실행할 예정입니다. 솔루션스 아키텍트는 이를 위해 AWS Outposts를 사용하고자 하며, 회사의 운영 팀과 함께 애플리케이션을 구축 중입니다. 다음 중 회사의 운영 팀이 책임져야 하는 활동은 무엇입니까? (세 개를 선택하십시오.)",
    "Answer": "A,C,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/119530-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Outposts를 활용해 온프레미스 환경에서 애플리케이션을 운영할 때, 어떤 사항을 고객(운영 팀)이 책임져야 하는지 파악하는 문제입니다. Outposts 하드웨어 자체는 AWS가 운영하지만, 전력 및 네트워크 연결, 물리적 보안, 추가 용량 계획 등은 고객사의 책임입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "AWS Outposts",
      "Amazon ECS",
      "Amazon RDS",
      "온프레미스 데이터 센터",
      "결제 처리 애플리케이션",
      "물리적 보안",
      "전원 및 네트워크",
      "추가 용량 제공"
    ],
    "Terms": [
      "Amazon Elastic Container Service(Amazon ECS)",
      "Amazon RDS",
      "AWS Outposts",
      "온프레미스 데이터 센터",
      "물리적 보안",
      "데이터 센터 접근 제어",
      "전원 공급",
      "네트워크 연결",
      "Outposts 랙",
      "용량 계획"
    ],
    "SelectA": "Outposts 랙에 대한 안정적인 전원과 네트워크 연결을 제공하는 것",
    "SelectA_Commentary": "AWS Outposts를 사용하려면 고객 측 데이터 센터에서 안정적 전원 및 연결 환경을 마련해야 하므로 운영 팀의 책임입니다.",
    "SelectB": "가상화 하이퍼바이저, 스토리지 시스템, Outposts에서 실행되는 모든 AWS 서비스를 관리하는 것",
    "SelectB_Commentary": "Outposts의 기본 인프라와 AWS 서비스 운영은 AWS가 책임집니다. 고객 측 운영 범위가 아닙니다.",
    "SelectC": "데이터 센터 환경의 물리적 보안 및 접근 제어를 적용하는 것",
    "SelectC_Commentary": "고객의 온프레미스 환경에 대한 물리적 보안 및 접근은 고객(운영 팀)의 책임입니다.",
    "SelectD": "Outposts 랙 내부의 전원 장치, 서버, 네트워킹 장비를 포함한 Outposts 인프라 가용성 보장",
    "SelectD_Commentary": "Outposts 인프라 자체의 서버 가용성은 AWS가 책임지며, 고객은 전원 공급∙물리 환경만 담당합니다. 장비 자체의 가용성 보장은 AWS 측 책임입니다.",
    "SelectE": "Outposts 구성 요소에 대한 물리적 유지보수를 수행하는 것",
    "SelectE_Commentary": "Outposts 하드웨어 유지보수는 AWS가 처리합니다. 고객이 직접 해당 구성 요소를 유지보수하지 않습니다.",
    "SelectF": "Amazon ECS 클러스터 장애 및 유지보수 이벤트를 완화하기 위한 추가 용량을 제공하는 것",
    "SelectF_Commentary": "Outposts 용량은 제한적이므로 향후 확장 및 장애 대비를 위해 필요한 용량을 계획하고 확보하는 것은 고객 측 책임입니다.",
    "Question_Description_recommedations": [
      "Q944",
      "Q67",
      "Q900",
      "Q125",
      "Q195"
    ],
    "SelectA_recommedations": [
      "Q58",
      "Q917",
      "Q491"
    ],
    "SelectB_recommedations": [
      "Q363",
      "Q8",
      "Q293"
    ],
    "SelectC_recommedations": [
      "Q491",
      "Q58",
      "Q917"
    ],
    "SelectD_recommedations": [
      "Q917",
      "Q58",
      "Q491"
    ],
    "SelectE_recommedations": [
      "Q58",
      "Q917",
      "Q491"
    ],
    "SelectF_recommedations": [
      "Q584",
      "Q244",
      "Q615"
    ]
  },
  {
    "Question_Number": "Q600",
    "Question_Description": "한 회사가 TCP 기반 애플리케이션을 회사의 VPC로 마이그레이션하려고 합니다. 이 애플리케이션은 회사 데이터 센터의 하드웨어 어플라이언스를 통해 비표준 TCP 포트로 공용 액세스가 가능합니다. 이 공용 엔드포인트는 최대 초당 300만 건의 요청을 처리하며 지연 시간이 매우 낮습니다. 해당 회사는 AWS 상에서도 동일한 성능 수준의 새로운 공용 엔드포인트를 요구합니다. 이 요구사항을 충족하려면 어떤 구성을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121205-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매우 높은 트래픽과 낮은 지연 시간 요구사항을 만족하기 위한 로드 밸런서 선택의 핵심을 묻습니다. Network Load Balancer는 OSI 4계층에서 동작하며 초당 수백만 건의 요청을 처리하는 데 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "TCP 기반 애플리케이션",
      "비표준 TCP 포트",
      "초당 300만 건의 요청",
      "지연 시간",
      "공용 엔드포인트",
      "Network Load Balancer"
    ],
    "Terms": [
      "VPC",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Amazon CloudFront",
      "Amazon API Gateway",
      "AWS Lambda",
      "Provisioned Concurrency",
      "OSI Layer 4",
      "TCP Port"
    ],
    "SelectA": "Network Load Balancer(NLB)를 배포하고, 애플리케이션에서 필요한 TCP 포트로 공용 액세스를 설정합니다.",
    "SelectA_Commentary": "NLB는 4계층에서 동작하며 매우 높은 트래픽량을 처리할 수 있으므로 요구사항에 부합합니다.",
    "SelectB": "Application Load Balancer(ALB)를 배포하고, 애플리케이션에서 필요한 TCP 포트로 공용 액세스를 설정합니다.",
    "SelectB_Commentary": "ALB는 7계층 프로토콜 기반이며 매우 높은 트래픽 처리를 위한 4계층 수준의 성능을 제공하기에는 적합하지 않습니다.",
    "SelectC": "TCP 포트로 동작하는 Amazon CloudFront 배포를 구성하고, 오리진으로 Application Load Balancer를 사용합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS를 가속화하기 위해 설계되었고, 비표준 TCP 포트에 대한 고성능 직접 처리는 제한적입니다.",
    "SelectD": "Amazon API Gateway를 비표준 TCP 포트로 구성하고, AWS Lambda 함수를 프로비저닝된 동시성으로 설정해 요청을 처리합니다.",
    "SelectD_Commentary": "API Gateway 기반 방식은 대규모 TCP 트래픽을 직접 처리하기 어렵고 Lambda 호출 구조상 지연 시간이 늘어날 수 있습니다.",
    "Question_Description_recommedations": [
      "Q686",
      "Q352",
      "Q528",
      "Q443",
      "Q895"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q530",
      "Q141"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q141",
      "Q815"
    ],
    "SelectC_recommedations": [
      "Q530",
      "Q704",
      "Q352"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ]
  },
  {
    "Question_Number": "Q601",
    "Question_Description": "한 회사가 중요한 데이터베이스를 Amazon RDS for PostgreSQL DB 인스턴스에서 운영하고 있습니다. 회사는 최소한의 다운타임과 데이터 손실로 Amazon Aurora PostgreSQL로 마이그레이션하기를 원합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121210-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS for PostgreSQL을 사용 중인 중요 데이터베이스를 Aurora PostgreSQL로 전환할 때, 최소한의 다운타임과 운영 복잡도를 유지하는 방법을 묻습니다. Aurora read replica를 생성 후 승격하는 방식은 AWS 관리형 복제를 통해 실시간으로 동기화되므로 데이터 손실이 적고 다운타임을 최소화하여 운영 오버헤드를 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Amazon Aurora PostgreSQL",
      "최소 다운타임",
      "데이터 손실 최소화",
      "운영 오버헤드 감소"
    ],
    "Terms": [
      "Aurora read replica",
      "DB snapshot",
      "pg_dump",
      "Amazon S3",
      "RDS for PostgreSQL",
      "Aurora PostgreSQL DB cluster"
    ],
    "SelectA": "RDS for PostgreSQL DB 인스턴스의 DB 스냅샷을 생성하여 새로운 Aurora PostgreSQL DB 클러스터를 구성합니다.",
    "SelectA_Commentary": "DB 스냅샷 복원은 전체 데이터를 복제한 후 새 클러스터를 띄워야 하므로, 복구 시점까지 다운타임이 길어지고 수작업도 필요해 운영 오버헤드가 큽니다.",
    "SelectB": "RDS for PostgreSQL DB 인스턴스의 Aurora 읽기 전용 복제본을 생성합니다. 이 Aurora 읽기 전용 복제본을 승격하여 새로운 Aurora PostgreSQL DB 클러스터로 만듭니다.",
    "SelectB_Commentary": "읽기 전용 복제본은 RDS와 실시간으로 동기화되므로 데이터 손실이 적고, 승격 과정에서 발생하는 다운타임도 매우 짧아 가장 효과적입니다.",
    "SelectC": "Amazon S3에서 데이터 가져오기를 사용하여 DB를 Aurora PostgreSQL DB 클러스터로 마이그레이션합니다.",
    "SelectC_Commentary": "S3로 내보내고 다시 가져오는 다단계 작업이 필요해 수작업이 많고 시간이 걸려, 다운타임과 운영 오버헤드 모두 커집니다.",
    "SelectD": "pg_dump 유틸리티를 사용해 RDS for PostgreSQL 데이터베이스를 백업합니다. 이 백업을 새로운 Aurora PostgreSQL DB 클러스터로 복원합니다.",
    "SelectD_Commentary": "수동으로 백업 및 복원을 진행해야 하므로 다운타임이 길고, 데이터 손실 위험도 있으며 운영적 복잡도가 커집니다.",
    "Question_Description_recommedations": [
      "Q136",
      "Q464",
      "Q518",
      "Q629",
      "Q259"
    ],
    "SelectA_recommedations": [
      "Q601",
      "Q518",
      "Q464"
    ],
    "SelectB_recommedations": [
      "Q601",
      "Q136",
      "Q464"
    ],
    "SelectC_recommedations": [
      "Q843",
      "Q768",
      "Q236"
    ],
    "SelectD_recommedations": [
      "Q601",
      "Q136",
      "Q440"
    ]
  },
  {
    "Question_Number": "Q602",
    "Question_Description": "회사의 인프라는 Amazon EBS 스토리지를 사용하는 수백 개의 Amazon EC2 인스턴스로 구성되어 있습니다. 솔루션스 아키텍트는 모든 EC2 인스턴스가 재해 발생 시 복구될 수 있도록 보장해야 합니다. 가장 적은 노력을 들여 이 요구사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 재해 상황에서도 EC2 인스턴스를 빠르고 간편하게 복구할 수 있는지에 주안점을 둡니다. AWS Backup을 활용하면 백업 정책을 일괄적으로 적용하고 여러 인스턴스를 자동화된 방식으로 복구할 수 있어 가장 적은 노력이 들며 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon EBS",
      "백업",
      "AWS Backup",
      "재해 복구"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "스냅샷",
      "AWS CloudFormation",
      "AWS Elastic Beanstalk",
      "AWS Backup",
      "AWS CLI",
      "AWS Lambda",
      "Amazon Machine Images(AMIs)"
    ],
    "SelectA": "각 EC2 인스턴스에 연결된 EBS 스토리지를 스냅샷으로 생성합니다. 이 EBS 스토리지로 새로운 EC2 인스턴스를 시작하기 위한 AWS CloudFormation 템플릿을 만듭니다.",
    "SelectA_Commentary": "CloudFormation으로 템플릿을 만들어도 모든 인스턴스별로 스냅샷을 수동 관리해야 하는 부담이 큽니다.",
    "SelectB": "각 EC2 인스턴스에 연결된 EBS 스토리지를 스냅샷으로 생성합니다. AWS Elastic Beanstalk을 사용하여 EC2 템플릿 기반 환경을 설정하고 해당 EBS 스토리지를 연결합니다.",
    "SelectB_Commentary": "Elastic Beanstalk은 애플리케이션 배포 환경에 주로 사용되며, EBS 볼륨 백업 및 복구 과정을 자동화하기에는 부적합합니다.",
    "SelectC": "전체 EC2 인스턴스 그룹에 대한 백업 플랜을 AWS Backup으로 설정합니다. 여러 EC2 인스턴스에 대해 복구를 가속하기 위해 AWS Backup API나 AWS CLI를 사용합니다.",
    "SelectC_Commentary": "AWS Backup을 통해 여러 리소스의 백업과 복구를 자동화하고 정책적으로 관리할 수 있어 재해 복구 시 가장 빠르고 간편한 솔루션입니다.",
    "SelectD": "각 EC2 인스턴스에 연결된 EBS 스토리지 스냅샷과 Amazon Machine Images(AMIs)를 복사하는 AWS Lambda 함수를 생성합니다. 다른 Lambda 함수를 통해 복사된 AMI로 복구를 수행하고 EBS 스토리지를 연결합니다.",
    "SelectD_Commentary": "Lambda를 이용해 스냅샷과 AMI를 복사/연결하는 방식을 직접 구현해야 하므로, 자동화 구성이 복잡하고 관리 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q312",
      "Q837",
      "Q5",
      "Q906",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q602",
      "Q312",
      "Q892"
    ],
    "SelectB_recommedations": [
      "Q602",
      "Q312",
      "Q892"
    ],
    "SelectC_recommedations": [
      "Q892",
      "Q602",
      "Q790"
    ],
    "SelectD_recommedations": [
      "Q762",
      "Q602",
      "Q775"
    ]
  },
  {
    "Question_Number": "Q603",
    "Question_Description": "한 회사가 최근 AWS Cloud로 마이그레이션을 완료했습니다. 이 회사는 대규모 병렬 온디맨드 처리를 위한 Serverless 솔루션을 원합니다. 처리해야 하는 데이터 세트는 로그, 미디어 파일, 판매 트랜잭션, IoT 센서 데이터 등 반정형 데이터이며, Amazon S3에 저장되어 있습니다. 회사는 이 데이터 세트에 포함된 수천 건의 항목을 병렬로 처리하고자 합니다. 이러한 요구 사항을 가장 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121211-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 있는 대규모 데이터를 병렬 처리하는 Serverless 방안을 묻습니다. AWS Step Functions의 Map state를 Distributed mode로 설정하면 자동으로 확장되고, 수많은 항목을 빠르게 병렬 처리할 수 있어 가장 운영 효율성이 좋습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "Serverless",
      "병렬 처리",
      "반정형 데이터",
      "Amazon S3",
      "AWS Step Functions",
      "Distributed mode",
      "운영 효율성"
    ],
    "Terms": [
      "AWS Cloud",
      "Serverless",
      "Amazon S3",
      "AWS Step Functions",
      "Map state",
      "Inline mode",
      "Distributed mode",
      "AWS Glue",
      "AWS Lambda",
      "IoT",
      "반정형 데이터",
      "온디맨드 처리"
    ],
    "SelectA": "AWS Step Functions의 Map state를 Inline mode로 사용하여 데이터를 병렬로 처리합니다.",
    "SelectA_Commentary": "Inline mode는 병렬 처리를 지원하지만 확장성이 제한적이고, 대규모 처리 시 운영 부담이 높아집니다.",
    "SelectB": "AWS Step Functions의 Map state를 Distributed mode로 사용하여 데이터를 병렬로 처리합니다.",
    "SelectB_Commentary": "Distributed mode는 Map state가 자동으로 병렬 워커를 확장하여 대규모 데이터를 효율적으로 처리하기 때문에, 운영 효율성이 가장 뛰어난 올바른 해법입니다.",
    "SelectC": "AWS Glue를 사용하여 데이터를 병렬로 처리합니다.",
    "SelectC_Commentary": "AWS Glue는 ETL 작업에 특화되어 있지만, 특정 시점 대규모 병렬 처리에 Step Functions만큼 유연하거나 쉽지는 않습니다.",
    "SelectD": "여러 AWS Lambda 함수들을 사용하여 데이터를 병렬로 처리합니다.",
    "SelectD_Commentary": "Lambda 함수를 직접 여러 개 관리해야 하므로 오케스트레이션 부담이 높아지며, Step Functions Distributed mode가 제공하는 자동 확장과 간소함에 비해 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q631",
      "Q192",
      "Q173",
      "Q547",
      "Q249"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q443",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q905",
      "Q143"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q865",
      "Q443"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q746",
      "Q631"
    ]
  },
  {
    "Question_Number": "Q604",
    "Question_Description": "한 회사가 6주 안에 10PB의 데이터를 Amazon S3로 마이그레이션하려고 합니다. 현재 데이터 센터에는 다른 온프레미스 애플리케이션들도 공유하는 500 Mbps 인터넷 업링크가 있으며, 회사는 이번 마이그레이션 작업에 인터넷 대역폭의 80%를 사용할 수 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121186-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "회사 요구사항인 6주 내에 10PB를 전송하기에는 인터넷 대역폭(약 400Mbps)으로는 불가능하므로, 오프라인 전송이 가능한 AWS Snowball이 가장 적합한 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "10PB",
      "6주",
      "Amazon S3",
      "500 Mbps",
      "AWS Snowball"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "rsync",
      "AWS CLI",
      "AWS Snowball"
    ],
    "SelectA": "AWS DataSync를 구성하여 데이터를 Amazon S3로 마이그레이션하고 자동으로 데이터를 검증하도록 설정합니다.",
    "SelectA_Commentary": "DataSync 자체는 대규모 전송에 유용하지만, 10PB를 400Mbps로 옮기기에는 시간 부족으로 적합하지 않습니다.",
    "SelectB": "rsync를 사용하여 데이터를 직접 Amazon S3로 전송합니다.",
    "SelectB_Commentary": "온라인 전송으로만 진행하면 6주 안에 10PB를 옮기는 것은 대역폭 문제로 매우 어렵습니다.",
    "SelectC": "AWS CLI와 여러 복사 프로세스를 활용하여 데이터를 직접 Amazon S3로 전송합니다.",
    "SelectC_Commentary": "병렬 전송으로 효율을 높일 수 있지만, 여전히 6주 내 10PB 이전에 필요한 속도를 달성하기 어렵습니다.",
    "SelectD": "여러 대의 AWS Snowball 디바이스를 주문하여 데이터를 복사한 후, 디바이스를 AWS로 보내 Amazon S3로 데이터를 복사합니다.",
    "SelectD_Commentary": "오프라인 전송 방식을 사용하여 인터넷 대역폭 제약 없이 대용량 데이터를 신속히 마이그레이션할 수 있는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q331",
      "Q747",
      "Q113",
      "Q127",
      "Q299"
    ],
    "SelectA_recommedations": [
      "Q672",
      "Q155",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectC_recommedations": [
      "Q672",
      "Q155",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q672",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q605",
    "Question_Description": "한 회사는 온프레미스 환경에 여러 대의 Internet Small Computer Systems Interface (iSCSI) 네트워크 스토리지 서버를 보유하고 있습니다. 이 회사는 AWS 클라우드로 이전하여 이러한 서버의 수를 줄이려고 합니다. 솔루션스 아키텍트는 자주 사용되는 데이터에 대해 저지연 액세스를 제공하고, 최소한의 인프라 변경으로 온프레미스 서버에 대한 의존도를 줄여야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121170-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 iSCSI 기반 온프레미스 스토리지를 AWS로 옮기면서, 자주 사용되는 데이터에 대한 저지연 액세스와 적은 인프라 변경을 동시에 달성할 수 있는 방법을 묻습니다. AWS Storage Gateway의 cached volumes 방식을 사용하면, 자주 사용하는 데이터만 온프레미스에 캐싱하고 나머지는 Amazon S3로 이전함으로써 온프레미스 서버 수를 줄이면서도 낮은 지연 시간을 유지할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "iSCSI",
      "저지연",
      "온프레미스 서버",
      "AWS Storage Gateway",
      "cached volumes"
    ],
    "Terms": [
      "iSCSI",
      "Amazon S3 File Gateway",
      "Amazon EBS",
      "AWS Storage Gateway",
      "stored volumes",
      "cached volumes"
    ],
    "SelectA": "Amazon S3 File Gateway를 배포합니다.",
    "SelectA_Commentary": "File Gateway는 파일 기반 프로토콜을 제공하므로 블록 스토리지(iSCSI) 대체로는 적합하지 않습니다.",
    "SelectB": "Amazon Elastic Block Store(Amazon EBS)를 배포하고 Amazon S3로 백업합니다.",
    "SelectB_Commentary": "Amazon EBS는 iSCSI를 지원하지 않아 기존 온프레미스 iSCSI 서버를 직접 대체하기 어렵습니다.",
    "SelectC": "AWS Storage Gateway volume gateway(Stored volumes 구성)를 배포합니다.",
    "SelectC_Commentary": "Stored volumes는 모든 데이터를 온프레미스에 유지하므로 서버 수를 줄이기 어렵고 S3 활용이 제한적입니다.",
    "SelectD": "AWS Storage Gateway volume gateway(Cached volumes 구성)를 배포합니다.",
    "SelectD_Commentary": "자주 사용되는 데이터만 로컬에 보관하고 나머지를 S3에 저장해 저지연 성능과 온프레미스 서버 감소를 동시에 달성할 수 있어 올바른 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q155",
      "Q443",
      "Q547",
      "Q173",
      "Q631"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q501",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q305",
      "Q620",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q620",
      "Q361",
      "Q684"
    ]
  },
  {
    "Question_Number": "Q606",
    "Question_Description": "한 솔루션스 아키텍트가 기업 사용자가 Amazon S3에 객체를 업로드할 수 있는 애플리케이션을 설계하고 있습니다. 이 솔루션은 객체의 내구성을 최대화해야 하며, 언제든지 그리고 어떤 기간이라도 즉시 액세스 가능해야 합니다. 사용자들은 업로드 후 첫 30일 동안은 해당 객체를 자주 액세스하지만, 30일이 지난 뒤에는 액세스 빈도가 크게 줄어듭니다. 이 요구사항을 가장 비용 효율적으로 충족시키는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121214-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 업로드 후 초기에 빈번히 액세스되는 객체를 높은 내구성과 즉시 액세스 요구 사항에 맞게 S3 Standard에 저장하고, 액세스 빈도가 크게 떨어지는 30일 후에 더 저렴한 스토리지로 전환해 비용을 절감하는 방안을 묻습니다. 정답은 S3 Standard-IA로 전환하는 방법이 가장 적절하며, 객체 내구성(멀티 AZ)을 보장하면서도 필요한 시점에 바로 조회할 수 있어 비용 대비 효율이 높습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "내구성 최대화",
      "즉시 조회 가능",
      "30일 후 액세스 감소",
      "비용 효율성",
      "S3 Standard",
      "S3 Standard-IA"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Standard",
      "S3 Standard-IA",
      "S3 One Zone-IA",
      "S3 Glacier",
      "S3 Intelligent-Tiering",
      "S3 Lifecycle"
    ],
    "SelectA": "모든 객체를 S3 Standard에 저장하고, S3 Lifecycle 규칙을 사용하여 30일 후 객체를 S3 Glacier로 전환하도록 설정합니다.",
    "SelectA_Commentary": "S3 Glacier는 장기 보관에 적합하지만 즉시 액세스가 어렵고 복구 시간이 길어, ‘언제든지 조회 가능’ 요건에 적합하지 않습니다.",
    "SelectB": "모든 객체를 S3 Standard에 저장하고, S3 Lifecycle 규칙을 사용하여 30일 후 객체를 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환하도록 설정합니다.",
    "SelectB_Commentary": "S3 Standard와 동일한 내구성을 제공하며, 필요 시 즉시 액세스가 가능하고 저장 비용까지 절감할 수 있는 최적의 방법입니다.",
    "SelectC": "모든 객체를 S3 Standard에 저장하고, S3 Lifecycle 규칙을 사용하여 30일 후 객체를 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 전환하도록 설정합니다.",
    "SelectC_Commentary": "저렴하지만 단일 AZ에만 저장되므로 재해 복구 측면에서 취약해 내구성 요구 사항을 충분히 만족시키지 못합니다.",
    "SelectD": "모든 객체를 S3 Intelligent-Tiering에 저장하고, S3 Lifecycle 규칙을 사용하여 30일 후 객체를 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환하도록 설정합니다.",
    "SelectD_Commentary": "S3 Intelligent-Tiering을 쓰면 자동으로 적절한 티어를 선택해주지만, 별도의 모니터링 요금이 발생하고 여기서 다시 S3 Standard-IA로 전환하는 것은 중복되어 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q285",
      "Q769",
      "Q1003",
      "Q911",
      "Q126"
    ],
    "SelectA_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectB_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q415",
      "Q725"
    ]
  },
  {
    "Question_Number": "Q607",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에서 AWS Cloud로 2티어(two-tier) 애플리케이션을 마이그레이션했습니다. 데이터 계층은 Multi-AZ 구성의 Amazon RDS for Oracle이며, 12TB 용량의 General Purpose SSD Amazon Elastic Block Store(Amazon EBS)를 사용하고 있습니다. 이 애플리케이션은 평균 크기가 6MB인 문서를 BLOB(binary large object) 형태로 데이터베이스에 저장하도록 설계되었습니다. 시간이 지남에 따라 데이터베이스 크기가 커져 성능이 저하되고 스토리지 비용이 증가했습니다. 회사는 데이터베이스 성능을 개선해야 하며, 고가용성과 탄력성을 갖춘 솔루션이 필요합니다. 다음 중 가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량 BLOB 데이터를 RDS에 직접 저장하면서 발생하는 성능 저하와 높은 스토리지 비용을 해결하는 방법을 묻습니다. 일반적으로 대규모 파일은 Amazon S3에 저장하고 메타데이터만 RDS에 두면 성능과 비용 면에서 효율적입니다. 또한 Multi-AZ 구성을 통해 고가용성이 보장되고, S3의 탄력성을 활용하면 데이터 보호 수준도 높아집니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.3"
    ],
    "Keywords": [
      "비용 효율성",
      "Amazon RDS for Oracle",
      "BLOB",
      "Amazon S3",
      "고가용성",
      "성능 개선",
      "문서 스토리지"
    ],
    "Terms": [
      "Multi-AZ",
      "Amazon RDS for Oracle",
      "General Purpose SSD",
      "Amazon EBS",
      "BLOB",
      "Amazon S3",
      "Amazon DynamoDB",
      "AWS Database Migration Service (AWS DMS)",
      "Provisioned IOPS",
      "Magnetic",
      "DB instance"
    ],
    "SelectA": "RDS DB 인스턴스 크기를 축소하고 스토리지를 24TiB로 늘린 후, 스토리지 타입을 Magnetic으로 변경합니다.",
    "SelectA_Commentary": "Magnetic 스토리지는 이전 세대 타입으로 성능이 낮고, 단순히 스토리지 확장만으로는 BLOB 저장 문제를 해결하지 못하므로 적절한 방안이 아닙니다.",
    "SelectB": "RDS DB 인스턴스 크기를 확장하고 스토리지를 24TiB로 늘린 다음, 스토리지 타입을 Provisioned IOPS로 변경합니다.",
    "SelectB_Commentary": "Provisioned IOPS로 성능을 높일 수 있으나 더 높은 비용이 발생하고 큰 데이터 파일 자체 문제를 해결하지 못하여 최적의 방법이 아닙니다.",
    "SelectC": "Amazon S3 버킷을 생성하고, 애플리케이션을 업데이트하여 문서를 S3에 저장합니다. 객체 메타데이터만 기존 데이터베이스에 보관합니다.",
    "SelectC_Commentary": "대용량 BLOB을 S3로 분리하면 RDS의 성능과 비용을 크게 개선할 수 있고, S3의 고가용성 및 내구성도 확보되어 가장 비용 효율적인 방법입니다.",
    "SelectD": "Amazon DynamoDB 테이블을 만들고 애플리케이션을 DynamoDB로 마이그레이션하도록 업데이트합니다. AWS DMS를 사용하여 Oracle 데이터베이스에서 DynamoDB로 데이터를 마이그레이션합니다.",
    "SelectD_Commentary": "DynamoDB로 전환 시 구조 변경이 크고 마이그레이션 부담이 큽니다. 목적은 문서 스토리지 비용 절감이므로 S3가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q425",
      "Q353",
      "Q822",
      "Q841",
      "Q380"
    ],
    "SelectA_recommedations": [
      "Q574",
      "Q152",
      "Q436"
    ],
    "SelectB_recommedations": [
      "Q959",
      "Q579",
      "Q574"
    ],
    "SelectC_recommedations": [
      "Q911",
      "Q285",
      "Q1003"
    ],
    "SelectD_recommedations": [
      "Q670",
      "Q79",
      "Q348"
    ]
  },
  {
    "Question_Number": "Q608",
    "Question_Description": "한 회사가 전 세계 20,000개 이상의 소매점에 배포된 클라이언트를 지원하는 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 HTTPS(443 포트)로 노출되는 백엔드 웹 서비스를 포함하며, Amazon EC2 인스턴스 위에서 Application Load Balancer(ALB) 뒤에 배포되어 있습니다. 소매점들은 공용 인터넷을 통해 웹 애플리케이션과 통신하며, 각 소매점은 지역 ISP로부터 할당받은 IP 주소를 등록할 수 있습니다. 보안 팀은 등록된 소매점 IP 주소들로만 애플리케이션 엔드포인트에 접근하도록 제한해서 보안을 강화하라고 권고했습니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121216-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 등록된 IP만이 ALB에 접근하도록 하는 방법을 묻습니다. 20,000개 이상의 소매점 IP 주소를 관리해야 하므로, 확장가능하고 쉽게 관리할 수 있는 방식을 검토해야 합니다. AWS WAF의 IP set을 사용하면 다수의 IP를 간단히 관리하고, ALB 앞단에서 트래픽을 필터링하여 보안을 강화할 수 있습니다. NACL, Firewall Manager 등도 고려할 수 있지만, AWS WAF를 ALB에 적용하는 것이 운영과 관리 측면에서 가장 효율적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Application Load Balancer",
      "HTTPS",
      "IP 주소 제한",
      "소매점",
      "AWS WAF"
    ],
    "Terms": [
      "AWS WAF",
      "Web ACL",
      "IP rule sets",
      "AWS Firewall Manager",
      "Amazon DynamoDB",
      "AWS Lambda",
      "Network ACL(NACL)"
    ],
    "SelectA": "ALB에 AWS WAF Web ACL을 연결합니다. ALB에서 IP rule sets를 사용해 트래픽을 필터링하고, 등록된 IP 주소들을 규칙에 포함시킵니다.",
    "SelectA_Commentary": "AWS WAF를 이용해 대규모 IP 리스트를 손쉽게 설정하고 ALB 레벨에서 보안 정책을 제어할 수 있어 요구사항에 적합한 솔루션입니다.",
    "SelectB": "AWS Firewall Manager를 배포해 ALB를 관리합니다. Firewall Manager 규칙을 설정해 ALB로의 트래픽을 제한하고, 등록된 IP 주소를 규칙에 포함시킵니다.",
    "SelectB_Commentary": "Firewall Manager는 여러 계정 및 리소스를 중앙 관리할 때 유용하지만, 단순 IP 제한만 필요하다면 WAF를 사용하는 편이 더 적합하고 관리도 간단합니다.",
    "SelectC": "Amazon DynamoDB 테이블에 IP 주소를 저장합니다. ALB의 AWS Lambda 권한 부여 함수를 구성하여 들어오는 요청이 등록된 IP 주소에서 온 것인지 검증합니다.",
    "SelectC_Commentary": "Lambda 함수를 통한 IP 검증은 구현 복잡도가 높고, 대량의 소매점 IP 주소를 매번 Lambda로 확인해야 하므로 오버헤드가 큽니다.",
    "SelectD": "ALB의 퍼블릭 인터페이스가 있는 서브넷의 Network ACL을 구성합니다. 등록된 IP 주소들에 대한 인바운드 규칙을 네트워크 ACL에 추가합니다.",
    "SelectD_Commentary": "NACL은 허용 가능한 규칙 수가 제한적이며, 여러 IP 주소를 자주 업데이트해야 하는 경우 관리가 복잡하므로 대규모 IP 제한에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q60",
      "Q218",
      "Q927",
      "Q509",
      "Q104"
    ],
    "SelectA_recommedations": [
      "Q60",
      "Q749",
      "Q169"
    ],
    "SelectB_recommedations": [
      "Q60",
      "Q749",
      "Q707"
    ],
    "SelectC_recommedations": [
      "Q428",
      "Q279",
      "Q176"
    ],
    "SelectD_recommedations": [
      "Q707",
      "Q169",
      "Q60"
    ]
  },
  {
    "Question_Number": "Q609",
    "Question_Description": "한 회사가 AWS Lake Formation을 사용하여 AWS 상에서 데이터 분석 플랫폼을 구축하고 있습니다. 이 플랫폼은 Amazon S3, Amazon RDS 등 다양한 소스에서 데이터를 가져올 예정입니다. 이 회사는 민감한 정보를 포함하는 데이터 일부에 대한 접근을 차단하기 위한 안전한 솔루션이 필요합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121162-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터를 부분적으로 보호하기 위해 AWS Lake Formation의 세분화된 접근 제어 방식을 이해해야 합니다. 정답은 row-level 및 cell-level을 제어하는 Data filters를 통해 민감 정보를 숨기는 방법이며, 이는 추가 Lambda 개발이나 복잡한 IAM 설정 없이 운영 오버헤드를 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "AWS Lake Formation",
      "Amazon S3",
      "Amazon RDS",
      "민감한 정보",
      "row-level security",
      "cell-level security"
    ],
    "Terms": [
      "IAM role",
      "AWS Lake Formation",
      "Amazon S3",
      "Amazon RDS",
      "Data filters",
      "Row-level security",
      "Cell-level security",
      "AWS Lambda function"
    ],
    "SelectA": "Create an IAM role that includes permissions to access Lake Formation tables.",
    "SelectA_Commentary": "IAM role은 유저 단위 권한 관리를 제공하지만, 데이터 내 민감 정보만 부분적으로 차단하기엔 너무 범용적이고 세밀한 보안 제어가 어렵습니다.",
    "SelectB": "Create data filters to implement row-level security and cell-level security.",
    "SelectB_Commentary": "AWS Lake Formation의 Data filters를 사용하면 민감 정보가 있는 행이나 셀만 제한할 수 있어 운영 부담이 적고 보안 수준을 높이는 최적의 솔루션입니다.",
    "SelectC": "Create an AWS Lambda function that removes sensitive information before Lake Formation ingests the data.",
    "SelectC_Commentary": "수집 전에 Lambda를 통해 민감 정보를 제거하는 방식은 데이터 전처리에 대한 추가 개발, 테스트, 유지보수가 필요해 오버헤드가 증가합니다.",
    "SelectD": "Create an AWS Lambda function that periodically queries and removes sensitive information from Lake Formation tables.",
    "SelectD_Commentary": "정기적으로 테이블에서 민감 정보를 제거하려면 Lambda 스케줄링과 쿼리 로직이 필요해 오버헤드가 크며, 데이터 손실 우려도 존재합니다.",
    "Question_Description_recommedations": [
      "Q442",
      "Q495",
      "Q16",
      "Q638",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q341",
      "Q495",
      "Q609"
    ],
    "SelectB_recommedations": [
      "Q732",
      "Q901",
      "Q330"
    ],
    "SelectC_recommedations": [
      "Q495",
      "Q791",
      "Q913"
    ],
    "SelectD_recommedations": [
      "Q495",
      "Q791",
      "Q913"
    ]
  },
  {
    "Question_Number": "Q610",
    "Question_Description": "회사는 Amazon EC2 인스턴스를 VPC에서 구동하고 있습니다. EC2 인스턴스는 소스 데이터를 Amazon S3 버킷에 로드하여 향후 처리할 수 있도록 합니다. 컴플라이언스 법규에 따라, 이 데이터는 Public Internet을 통해 전송되면 안 됩니다. 회사의 온프레미스 데이터 센터에 있는 서버들은 EC2 인스턴스에서 실행되는 애플리케이션의 결과물을 소비할 예정입니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121217-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 업로드되는 데이터를 Public Internet을 거치지 않고 안전하게 전송하고, 온프레미스에서 VPC로 안전하게 연결하는 방법을 설계하는 상황입니다. Gateway VPC Endpoint를 사용하면 S3에 직접 사설 링크로 액세스할 수 있으며, AWS Direct Connect는 온프레미스와 VPC를 전용 회선으로 연결해 인터넷을 우회합니다. 이러한 방식을 통해 데이터가 인터넷으로 노출되지 않고, 컴플라이언스 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Amazon S3 버킷",
      "Public Internet 차단",
      "온프레미스 데이터 센터 연결",
      "컴플라이언스"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC",
      "Amazon S3",
      "Public Internet",
      "AWS Site-to-Site VPN",
      "AWS Direct Connect",
      "Gateway VPC Endpoint",
      "Interface VPC Endpoint",
      "AWS Transit Gateway",
      "NAT Gateway"
    ],
    "SelectA": "Amazon EC2에 대해 Interface VPC Endpoint를 배포하고, 회사와 VPC 간에 AWS Site-to-Site VPN 연결을 생성합니다.",
    "SelectA_Commentary": "Interface VPC Endpoint는 주로 특정 서비스에 대한 엔드포인트를 제공하지만, S3와 같은 Gateway VPC Endpoint가 필요한 서비스에는 적합하지 않습니다. 또한 S3 전송이 Public Internet을 통하지 않는다는 보장이 약합니다.",
    "SelectB": "Amazon S3에 대해 Gateway VPC Endpoint를 배포합니다. 온프레미스 네트워크와 VPC 간에는 AWS Direct Connect 연결을 설정합니다.",
    "SelectB_Commentary": "Gateway VPC Endpoint를 통해 S3로의 트래픽이 인터넷을 사용하지 않고 VPC 내부 경로로 전송됩니다. AWS Direct Connect는 온프레미스와 VPC를 안전하게 연결해 데이터가 Public Internet을 거치지 않도록 합니다. 정답입니다.",
    "SelectC": "VPC에서 S3 버킷으로 AWS Transit Gateway 연결을 설정합니다. 회사와 VPC 간에 AWS Site-to-Site VPN 연결을 생성합니다.",
    "SelectC_Commentary": "Transit Gateway는 VPC 간 연결에는 유용하지만, S3 액세스에는 Gateway VPC Endpoint가 필요합니다. 또한 Transit Gateway만으로는 S3에 사설 접근이 보장되지 않습니다.",
    "SelectD": "NAT Gateway로 라우팅되는 Proxy EC2 인스턴스를 설정합니다. Proxy EC2 인스턴스를 통해 S3 데이터를 가져와 애플리케이션 인스턴스에 전달합니다.",
    "SelectD_Commentary": "NAT Gateway를 통한 접근은 Internet 경유 경로가 발생할 수 있습니다. 데이터를 안전하고 단순하게 전송하기에는 Proxy 인스턴스 사용이 복잡하며 Public Internet 우회를 완전히 차단하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q980",
      "Q866",
      "Q4",
      "Q92",
      "Q115"
    ],
    "SelectA_recommedations": [
      "Q782",
      "Q251",
      "Q610"
    ],
    "SelectB_recommedations": [
      "Q91",
      "Q92",
      "Q866"
    ],
    "SelectC_recommedations": [
      "Q782",
      "Q92",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q1016",
      "Q612",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q611",
    "Question_Description": "한 회사가 REST 기반 인터페이스를 지닌 애플리케이션을 운영하고 있으며, 이 애플리케이션은 서드파티 벤더로부터 거의 실시간으로 데이터를 수신할 수 있습니다. 애플리케이션은 수신된 데이터를 처리하고 추가 분석을 위해 저장합니다. 이 애플리케이션은 Amazon EC2 인스턴스에서 동작합니다. 서드파티 벤더 측에서 데이터를 전송할 때 503 Service Unavailable Error가 빈번히 발생하고 있습니다. 데이터 볼륨이 급증하면 컴퓨트 용량이 최대치에 도달하여 모든 요청을 처리하지 못하고 있습니다. 더 확장 가능한 솔루션을 제공하기 위해 솔루션스 아키텍트는 어떤 설계를 권장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121218-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트래픽 급증 시 발생하는 503 오류를 해결하기 위해 확장 가능한 데이터 수신 및 처리 방식을 고민하는 상황입니다. Amazon Kinesis Data Streams를 사용하면 대량의 스트리밍 데이터를 안정적으로 수집할 수 있고, AWS Lambda는 서버리스 환경에서 자동으로 확장되어 데이터를 처리할 수 있어 거의 무제한에 가까운 처리가 가능합니다. 이를 통해 EC2의 리소스 부족 상황을 피할 수 있고, 더욱 유연하고 확장 가능한 아키텍처를 구성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "REST 기반 인터페이스",
      "거의 실시간 처리",
      "503 Service Unavailable Error",
      "스케일링",
      "Amazon Kinesis Data Streams",
      "AWS Lambda"
    ],
    "Terms": [
      "REST-based interface",
      "Amazon EC2",
      "503 Service Unavailable",
      "Amazon Kinesis Data Streams",
      "AWS Lambda",
      "Amazon API Gateway",
      "Usage plan with quota limit",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon Elastic Container Service (Amazon ECS)",
      "EC2 launch type"
    ],
    "SelectA": "Amazon Kinesis Data Streams를 사용하여 데이터를 수집하고, AWS Lambda 함수를 사용하여 데이터를 처리하십시오.",
    "SelectA_Commentary": "Kinesis Data Streams로 대량 데이터를 안정적으로 수집하고 Lambda가 자동으로 확장되어 처리하기 때문에, EC2 리소스 한계를 극복할 수 있는 가장 확장성 높은 해법입니다.",
    "SelectB": "기존 애플리케이션 위에 Amazon API Gateway를 사용하십시오. 서드파티 벤더를 위한 usage plan과 quota 제한을 생성하십시오.",
    "SelectB_Commentary": "API Gateway는 API 관리는 가능하지만 내부 EC2 한계를 해결해 주지 못합니다. 트래픽 자체를 제한하는 것은 근본적 확장성 문제 해결책이 아닙니다.",
    "SelectC": "Amazon Simple Notification Service(Amazon SNS)를 사용하여 데이터를 수집하십시오. EC2 인스턴스를 Application Load Balancer 뒤의 Auto Scaling group에 배치하십시오.",
    "SelectC_Commentary": "SNS는 팬아웃 등 이벤트 기반 처리에 적합하지만, 대규모 스트리밍 데이터 수집에는 적절하지 않습니다. EC2 오토 스케일링만으로는 급격한 트래픽을 처리하기에 한계가 있습니다.",
    "SelectD": "애플리케이션을 컨테이너로 재패키징하십시오. Auto Scaling group과 함께 EC2 launch type을 사용하는 Amazon ECS로 애플리케이션을 배포하십시오.",
    "SelectD_Commentary": "컨테이너화는 유연성은 높이나, 여전히 EC2에 의존하므로 처리량 급증 시 EC2 용량 한계가 재발생할 수 있습니다. 근본적인 확장 방식 개선이 필요합니다.",
    "Question_Description_recommedations": [
      "Q757",
      "Q252",
      "Q584",
      "Q110",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q198",
      "Q351",
      "Q354"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q637",
      "Q52"
    ],
    "SelectC_recommedations": [
      "Q405",
      "Q636",
      "Q275"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q612",
    "Question_Description": "한 회사에서 프라이빗 서브넷의 Amazon EC2 인스턴스에서 애플리케이션을 구동 중입니다. 해당 애플리케이션은 Amazon S3 버킷의 민감한 정보를 처리해야 하며, 인터넷을 통해 S3 버킷에 연결해서는 안 됩니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121159-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프라이빗 서브넷의 애플리케이션이 인터넷을 거치지 않고 S3 버킷에 접근해야 하는 시나리오를 묻고 있습니다. NAT Gateway나 Internet Gateway를 사용하면 결국 공용 경로를 거치게 되고, VPN 연결은 별도의 터널 구성과 관리 부담이 생깁니다. VPC Endpoint(S3 Gateway Endpoint)를 통해 AWS 내부 네트워크로 직접 연결함으로써 보안 요건을 충족하고, 버킷 정책에서도 해당 Endpoint만 허용하면 안전하게 S3와 통신할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "프라이빗 서브넷",
      "민감한 정보",
      "인터넷 미사용",
      "VPC 엔드포인트",
      "S3 버킷"
    ],
    "Terms": [
      "Amazon EC2",
      "Private Subnet",
      "Amazon S3",
      "Internet Gateway",
      "NAT Gateway",
      "VPC Endpoint",
      "VPN Connection",
      "Bucket Policy"
    ],
    "SelectA": "인터넷 게이트웨이를 구성합니다. S3 버킷 정책을 업데이트하여 인터넷 게이트웨이에서의 액세스를 허용합니다. 애플리케이션을 업데이트하여 새로운 인터넷 게이트웨이를 사용하도록 합니다.",
    "SelectA_Commentary": "인터넷 게이트웨이를 통한 접근은 공용 인터넷 경로를 거치므로 민감한 데이터 보호 요구사항에 부합하지 않습니다.",
    "SelectB": "VPN 연결을 구성합니다. S3 버킷 정책을 업데이트하여 VPN 연결에서의 액세스를 허용합니다. 애플리케이션을 업데이트하여 새로운 VPN 연결을 사용하도록 합니다.",
    "SelectB_Commentary": "VPN은 사설 연결을 제공하지만 추가적인 네트워크 구성과 관리 오버헤드가 크며, 간단한 내부 통신만을 요구하는 상황에는 과도합니다.",
    "SelectC": "NAT 게이트웨이를 구성합니다. S3 버킷 정책을 업데이트하여 NAT 게이트웨이에서의 액세스를 허용합니다. 애플리케이션을 업데이트하여 새로운 NAT 게이트웨이를 사용하도록 합니다.",
    "SelectC_Commentary": "NAT 게이트웨이는 외부로의 트래픽을 담당하지만 결국 인터넷 통신 경로를 이용하게 되므로 문제의 요건(인터넷을 사용하지 않음)에 어긋납니다.",
    "SelectD": "VPC 엔드포인트를 구성합니다. S3 버킷 정책을 업데이트하여 VPC 엔드포인트에서의 액세스를 허용합니다. 애플리케이션을 업데이트하여 새로운 VPC 엔드포인트를 사용하도록 합니다.",
    "SelectD_Commentary": "VPC 내부 트래픽만으로 S3에 접근할 수 있는 구조를 제공하여 민감한 데이터 처리와 보안 요건을 모두 충족하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q453",
      "Q17",
      "Q710",
      "Q480",
      "Q329"
    ],
    "SelectA_recommedations": [
      "Q665",
      "Q478",
      "Q122"
    ],
    "SelectB_recommedations": [
      "Q825",
      "Q44",
      "Q202"
    ],
    "SelectC_recommedations": [
      "Q825",
      "Q925",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q92",
      "Q866",
      "Q950"
    ]
  },
  {
    "Question_Number": "Q613",
    "Question_Description": "회사는 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용하여 컨테이너 애플리케이션을 실행하고 있습니다. EKS 클러스터는 민감한 정보를 Kubernetes secrets object에 저장합니다. 회사는 해당 정보가 암호화되도록 보장하고 싶어 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하려면 어떤 솔루션을 구현해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121158-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Kubernetes secrets에 저장된 민감한 정보를 안전하게 보호하기 위한 방안을 묻습니다. 가장 적은 운영 오버헤드를 가지려면 EKS 클러스터의 기본 기능을 활용해 secrets 암호화를 활성화하는 것이 유리합니다. AWS KMS를 통해 EKS에서 기본적으로 제공하는 secrets 암호화를 사용하는 것이 가장 간단하고 코드 수정이나 별도 구성 부담이 적기에 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "EKS",
      "Kubernetes secrets",
      "암호화"
    ],
    "Terms": [
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Kubernetes secrets",
      "AWS Key Management Service (AWS KMS)",
      "AWS Lambda",
      "AWS Systems Manager Parameter Store",
      "Container application"
    ],
    "SelectA": "컨테이너 애플리케이션에서 AWS Key Management Service(AWS KMS)를 직접 호출하여 정보를 암호화합니다.",
    "SelectA_Commentary": "애플리케이션 코드를 수정하거나 추가 로직을 구현해야 하므로 운영 오버헤드가 상대적으로 큽니다.",
    "SelectB": "AWS Key Management Service(AWS KMS)를 사용하여 EKS 클러스터에서 secrets 암호화를 활성화합니다.",
    "SelectB_Commentary": "EKS가 제공하는 기본 암호화 기능이므로 코드 수정을 최소화하면서 Kubernetes secrets를 안전하게 보호할 수 있어 가장 적합한 솔루션입니다.",
    "SelectC": "AWS Lambda 함수를 사용하여 AWS Key Management Service(AWS KMS)로 정보를 암호화하도록 구현합니다.",
    "SelectC_Commentary": "별도의 Lambda 함수 작성 및 호출 과정을 구성해야 하므로 운영 오버헤드가 증가합니다.",
    "SelectD": "AWS Systems Manager Parameter Store를 사용하여 AWS Key Management Service(AWS KMS)로 정보를 암호화합니다.",
    "SelectD_Commentary": "Parameter Store를 사용하면 Kubernetes secrets와는 별도의 보관 방식이 되어 직접적 연동이 부족하고 추가 구성이 필요합니다.",
    "Question_Description_recommedations": [
      "Q535",
      "Q514",
      "Q371",
      "Q805",
      "Q932"
    ],
    "SelectA_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectB_recommedations": [
      "Q535",
      "Q613",
      "Q371"
    ],
    "SelectC_recommedations": [
      "Q640",
      "Q550",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q916",
      "Q793"
    ]
  },
  {
    "Question_Number": "Q614",
    "Question_Description": "한 회사가 다음과 같은 구성 요소로 이루어진 새로운 멀티 티어 웹 애플리케이션을 설계하고 있습니다. • Auto Scaling group에 속한 Amazon EC2 인스턴스에서 실행되는 웹 및 애플리케이션 서버 • 데이터 스토리지를 위한 Amazon RDS DB 인스턴스 솔루션스 아키텍트는 애플리케이션 서버에 대한 접근을 제한하여 오직 웹 서버만 애플리케이션 서버에 접근하도록 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121157-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 서버와 애플리케이션 서버 간의 안전한 트래픽 흐름을 설계하는 방법을 묻습니다. 보안 그룹 수준에서 접근 제어를 제공할 수 있는 Application Load Balancer가 핵심이며, 이를 통해 인스턴스 레벨 방화벽이 동작해 오직 웹 서버만 애플리케이션 서버에 접근하도록 제한할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "멀티 티어 웹 애플리케이션",
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon RDS",
      "애플리케이션 서버 접근 제한",
      "Application Load Balancer",
      "Security group"
    ],
    "Terms": [
      "AWS PrivateLink",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon RDS",
      "VPC endpoint",
      "Network Load Balancer",
      "Application Load Balancer",
      "Security group",
      "Network ACL"
    ],
    "SelectA": "애플리케이션 서버 앞에 AWS PrivateLink를 배포하고, network ACL을 구성해 웹 서버만 접근하도록 설정합니다.",
    "SelectA_Commentary": "AWS PrivateLink는 외부 VPC 또는 서비스 간 사설 연결을 위해 사용되므로, 단일 VPC 내부 서버 간 접근 제어에는 적합하지 않습니다.",
    "SelectB": "애플리케이션 서버 앞에 VPC endpoint를 배포하고, security group을 구성해 웹 서버만 접근하도록 설정합니다.",
    "SelectB_Commentary": "VPC endpoint는 Amazon S3나 DynamoDB 같은 AWS 서비스에 사설로 연결할 때 사용하며, EC2 인스턴스 간 접근 제어 용도로는 사용하지 않습니다.",
    "SelectC": "Network Load Balancer를 배포하고, 대상 그룹에 애플리케이션 서버의 Auto Scaling group을 포함시킨 후, network ACL로 웹 서버만 접근하도록 허용합니다.",
    "SelectC_Commentary": "Network Load Balancer는 주로 TCP/UDP 수준의 로드 밸런싱을 제공합니다. 인스턴스 레벨 방화벽 역할을 하기에는 network ACL만으로 세밀한 제어가 어렵습니다.",
    "SelectD": "Application Load Balancer를 배포하고, 대상 그룹에 애플리케이션 서버의 Auto Scaling group을 포함시킨 후, security group을 통해 오직 웹 서버만 애플리케이션 서버에 접근하도록 설정합니다.",
    "SelectD_Commentary": "HTTP/HTTPS 기반 로드 밸런싱이 가능하고, security group으로 인스턴스 단위 접근 제어가 가능하므로 요구 사항에 가장 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q732",
      "Q61",
      "Q176",
      "Q492",
      "Q330"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q875",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q135",
      "Q468",
      "Q151"
    ],
    "SelectC_recommedations": [
      "Q676",
      "Q169",
      "Q625"
    ],
    "SelectD_recommedations": [
      "Q170",
      "Q625",
      "Q884"
    ]
  },
  {
    "Question_Number": "Q615",
    "Question_Description": "한 회사가 Amazon EKS에서 중요한 고객 대상 애플리케이션을 운영하고 있습니다. 애플리케이션은 마이크로서비스 아키텍처를 사용합니다. 이 회사는 애플리케이션에서 발생하는 메트릭과 로그를 중앙화된 위치에서 수집, 집계, 요약할 수 있는 솔루션을 구현해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121154-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컨테이너 기반 마이크로서비스 애플리케이션에서 발생하는 로그와 메트릭을 간편하고 효율적으로 중앙화하여 모니터링하는 방법을 묻습니다. Amazon CloudWatch Container Insights를 사용하면 EKS 클러스터 전체에서 메트릭과 로그를 자동으로 수집, 집계, 요약할 수 있어 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EKS",
      "마이크로서비스",
      "로그 수집",
      "메트릭",
      "중앙화된 위치",
      "Amazon CloudWatch Container Insights"
    ],
    "Terms": [
      "Amazon EKS",
      "AWS App Mesh",
      "AWS CloudTrail",
      "Amazon OpenSearch Service",
      "Amazon CloudWatch Container Insights",
      "Amazon CloudWatch agent"
    ],
    "SelectA": "기존 EKS 클러스터에서 Amazon CloudWatch agent를 실행하고, CloudWatch 콘솔에서 메트릭과 로그를 확인합니다.",
    "SelectA_Commentary": "CloudWatch agent만 설치하면 일정 수준의 로그와 지표 모니터링은 가능하지만, 컨테이너 환경에 특화된 통합 모니터링은 제공하지 못해 요구사항 대비 부족합니다.",
    "SelectB": "기존 EKS 클러스터에서 AWS App Mesh를 실행하고, App Mesh 콘솔에서 메트릭과 로그를 확인합니다.",
    "SelectB_Commentary": "AWS App Mesh는 서비스 간 트래픽 관리와 가시화에 초점이 맞춰져 있어, 애플리케이션의 종합적인 로그 및 메트릭 중앙화 요구사항을 직접 충족하기에는 적합하지 않습니다.",
    "SelectC": "AWS CloudTrail에서 data events를 캡처하도록 구성하고, Amazon OpenSearch Service를 사용하여 CloudTrail을 쿼리합니다.",
    "SelectC_Commentary": "CloudTrail은 주로 AWS API 호출과 계정 활동 추적에 사용됩니다. 애플리케이션의 세부 로그와 메트릭 수집을 중심으로 한 요구사항에는 부적합합니다.",
    "SelectD": "기존 EKS 클러스터에서 Amazon CloudWatch Container Insights를 구성하고, CloudWatch 콘솔에서 메트릭과 로그를 확인합니다.",
    "SelectD_Commentary": "Amazon CloudWatch Container Insights는 EKS 환경에서 컨테이너 단위의 메트릭 및 로그를 손쉽게 수집, 요약, 중앙화할 수 있어 요구사항을 완벽하게 충족합니다.",
    "Question_Description_recommedations": [
      "Q363",
      "Q149",
      "Q786",
      "Q917",
      "Q967"
    ],
    "SelectA_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ],
    "SelectB_recommedations": [
      "Q996",
      "Q563",
      "Q575"
    ],
    "SelectC_recommedations": [
      "Q351",
      "Q944",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q616",
    "Question_Description": "한 회사가 AWS에서 최신 제품을 배포했습니다. 이 제품은 Network Load Balancer 뒤의 Auto Scaling group에서 실행됩니다. 회사는 이 제품과 관련된 객체를 Amazon S3 bucket에 저장합니다. 최근 악의적인 공격이 발생하여, AWS account와 워크로드, 그리고 S3 bucket 접근 패턴에서 일어날 수 있는 악의적인 활동을 지속적으로 모니터링해야 합니다. 또한 의심스러운 활동을 보고하고, 이 정보를 대시보드에서 확인할 수 있는 솔루션이 필요합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121177-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 계정 및 워크로드 전반에서 발생할 수 있는 악의적인 활동을 실시간으로 탐지하고 그 결과를 한눈에 확인할 수 있는 대시보드 기능을 요구합니다. Amazon GuardDuty는 AWS 내 로그를 분석하여 의심스러운 활동을 신속히 탐지하고, AWS Security Hub와 통합해 단일 창에서 모든 보안 이벤트를 모니터링할 수 있게 해줍니다. 다른 서비스들은 주로 데이터 분류, 취약점 검사, 리소스 구성 변경 추적에 중점을 두므로 요구사항과는 거리가 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "악의적인 활동 모니터링",
      "Amazon GuardDuty",
      "AWS Security Hub",
      "Network Load Balancer",
      "Auto Scaling group",
      "Amazon S3 bucket",
      "대시보드"
    ],
    "Terms": [
      "Auto Scaling group",
      "Network Load Balancer",
      "Amazon S3",
      "Amazon Macie",
      "Amazon Inspector",
      "Amazon GuardDuty",
      "AWS Security Hub",
      "AWS Config",
      "AWS CloudTrail",
      "Amazon EventBridge"
    ],
    "SelectA": "Configure Amazon Macie to monitor and report findings to AWS Config.",
    "SelectA_Commentary": "Amazon Macie는 S3 데이터 분류와 민감 정보 식별에 주로 사용되어 계정 전체 모니터링에는 제한적입니다.",
    "SelectB": "Configure Amazon Inspector to monitor and report findings to AWS CloudTrail.",
    "SelectB_Commentary": "Amazon Inspector는 주로 EC2 인스턴스 취약점 평가에 집중하여, S3 접근 패턴 등 전체 보안 모니터링과는 맞지 않습니다.",
    "SelectC": "Configure Amazon GuardDuty to monitor and report findings to AWS Security Hub.",
    "SelectC_Commentary": "Amazon GuardDuty는 AWS 계정, 워크로드, S3 접근 패턴을 폭넓게 모니터링하여 이상 징후를 탐지하고, AWS Security Hub로 통합 관리를 지원합니다.",
    "SelectD": "Configure AWS Config to monitor and report findings to Amazon EventBridge.",
    "SelectD_Commentary": "AWS Config는 리소스 구성 변경 추적 서비스로, 악의적인 활동을 실시간으로 모니터링하는 데에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q965",
      "Q862",
      "Q638",
      "Q270",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q27",
      "Q682",
      "Q426"
    ],
    "SelectB_recommedations": [
      "Q524",
      "Q942",
      "Q27"
    ],
    "SelectC_recommedations": [
      "Q27",
      "Q233",
      "Q787"
    ],
    "SelectD_recommedations": [
      "Q27",
      "Q233",
      "Q313"
    ]
  },
  {
    "Question_Number": "Q617",
    "Question_Description": "한 회사가 온프레미스 데이터 센터를 AWS로 마이그레이션하려고 합니다. 이 데이터 센터에는 NFS 기반 파일 시스템을 사용하는 스토리지 서버가 있으며, 200GB의 데이터를 보유하고 있습니다. 회사는 기존 서비스에 중단 없이 데이터를 마이그레이션해야 하며, AWS 내 여러 리소스가 NFS 프로토콜을 통해 해당 데이터를 액세스할 수 있어야 합니다. 가장 비용 효율적인 방식으로 이러한 요구 사항을 충족하는 조합은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121176-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스의 NFS 데이터(200GB)를 중단 없이 AWS로 옮기고, AWS 내 여러 리소스가 NFS로 액세스 가능하도록 하는 비용 효율적 접근을 묻습니다. Amazon EFS는 NFS 프로토콜을 통한 공유 파일 시스템을 제공하며, AWS DataSync를 사용하면 자동화된 데이터 전송과 증분 동기화로 다운타임 없이 간편하게 마이그레이션할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "온프레미스 데이터 센터",
      "NFS 파일 시스템",
      "200GB",
      "무중단 마이그레이션",
      "Amazon EFS",
      "AWS DataSync",
      "비용 효율"
    ],
    "Terms": [
      "NFS-based file system",
      "Amazon FSx for Lustre",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon S3",
      "AWS DataSync",
      "on-premises data center",
      "operating system copy command"
    ],
    "SelectA": "Amazon FSx for Lustre 파일 시스템을 생성합니다.",
    "SelectA_Commentary": "FSx for Lustre는 고성능 HPC 워크로드에 적합하지만 이 시나리오에서는 과도한 성능과 비용이 들 수 있어 최적 방안이 아닙니다.",
    "SelectB": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성합니다.",
    "SelectB_Commentary": "NFS 프로토콜을 제공하고, 여러 리소스에서 동시에 액세스 가능하며, 종량제 방식으로 비용이 청구되어 적합한 선택입니다. (정답)",
    "SelectC": "Amazon S3 버킷을 만들어 데이터를 수용합니다.",
    "SelectC_Commentary": "S3는 객체 스토리지로 NFS 지원이 없어, NFS 액세스가 필요한 환경에 바로 적용하기 어렵습니다.",
    "SelectD": "운영 체제 복사 명령어로 직접 데이터를 AWS 대상으로 푸시합니다.",
    "SelectD_Commentary": "수작업은 오류와 다운타임 위험이 크며, 200GB를 전송하기엔 관리 부담도 커서 권장되지 않습니다.",
    "SelectE": "온프레미스 데이터 센터에 AWS DataSync 에이전트를 설치하고, 온프레미스와 AWS 간 DataSync 작업을 수행합니다.",
    "SelectE_Commentary": "DataSync를 통해 증분 복제와 무중단 마이그레이션이 가능하며, 자동화로 운영 부담도 줄어듭니다. (정답)",
    "Question_Description_recommedations": [
      "Q806",
      "Q703",
      "Q719",
      "Q541",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q728",
      "Q485",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q800",
      "Q277",
      "Q591"
    ],
    "SelectC_recommedations": [
      "Q1003",
      "Q911",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q728",
      "Q284",
      "Q985"
    ],
    "SelectE_recommedations": [
      "Q918",
      "Q348",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q618",
    "Question_Description": "한 회사가 us-east-1 리전의 Amazon EC2 인스턴스에 SMB 파일 공유를 볼륨으로 탑재하여 Amazon FSx for Windows File Server를 사용하려고 합니다. 이 회사는 계획된 시스템 유지관리나 예기치 못한 서비스 중단 상황에서 복구 시점 목표(RPO)를 5분으로 설정했습니다. 또한 파일 시스템을 us-west-2 리전으로 복제해야 하며, 복제된 데이터는 어떤 사용자도 5년 동안 삭제할 수 없어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121219-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 FSx for Windows File Server를 다중 리전에 걸쳐 보존 및 복제하며, 5분 RPO와 5년 동안 데이터 삭제를 방지해야 하는 요구사항을 해결하는 방법을 묻습니다. Compliance mode 설정은 어떤 사용자도 데이터 삭제를 할 수 없도록 보장하며, RPO가 5분이므로 Multi-AZ를 통한 고가용성을 갖춘 옵션이 필요합니다. 따라서 Multi-AZ 배포와 Compliance mode를 함께 사용하는 선택지가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "FSx for Windows File Server",
      "SMB 파일 공유",
      "RPO 5분",
      "us-east-1",
      "us-west-2",
      "AWS Backup Vault Lock",
      "Compliance Mode",
      "Multi-AZ",
      "5년 보존"
    ],
    "Terms": [
      "Amazon FSx for Windows File Server",
      "Amazon EC2",
      "SMB",
      "Single-AZ 2",
      "Multi-AZ",
      "AWS Backup",
      "AWS Backup Vault Lock",
      "Compliance mode",
      "Governance mode"
    ],
    "SelectA": "us-east-1 리전에 Single-AZ 2 유형의 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup으로 일일 백업 계획을 만들고, 해당 백업을 us-west-2 리전으로 복제합니다. us-west-2에 있는 대상 Vault에는 AWS Backup Vault Lock을 Compliance mode로 설정하고, 최소 5년 보존 기간을 구성합니다.",
    "SelectA_Commentary": "Single-AZ 2로는 RPO 5분을 만족하기 어렵거나 가용성 측면에서 제한적입니다. Compliance mode 자체는 올바르지만 Multi-AZ 요구사항과 맞지 않아 정답이 아닙니다.",
    "SelectB": "us-east-1 리전에 Multi-AZ 유형의 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup으로 일일 백업 계획을 만들고, 해당 백업을 us-west-2 리전으로 복제합니다. us-west-2에 있는 대상 Vault에는 AWS Backup Vault Lock을 Governance mode로 설정하고, 최소 5년 보존 기간을 구성합니다.",
    "SelectB_Commentary": "Multi-AZ로 RPO 5분을 충족할 수 있지만, Governance mode로는 완전한 삭제 방지를 보장하지 못하므로 요구사항에 부합하지 않습니다.",
    "SelectC": "us-east-1 리전에 Multi-AZ 유형의 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup으로 일일 백업 계획을 만들고, 해당 백업을 us-west-2 리전으로 복제합니다. us-west-2에 있는 대상 Vault에는 AWS Backup Vault Lock을 Compliance mode로 설정하고, 최소 5년 보존 기간을 구성합니다.",
    "SelectC_Commentary": "Multi-AZ 구성으로 RPO 5분 유지가 가능하고, Compliance mode로 사용자에 의한 삭제를 방지할 수 있어 모든 요구사항을 충족하는 정답입니다.",
    "SelectD": "us-east-1 리전에 Single-AZ 2 유형의 FSx for Windows File Server 파일 시스템을 생성합니다. AWS Backup으로 일일 백업 계획을 만들고, 해당 백업을 us-west-2 리전으로 복제합니다. us-west-2에 있는 대상 Vault에는 AWS Backup Vault Lock을 Governance mode로 설정하고, 최소 5년 보존 기간을 구성합니다.",
    "SelectD_Commentary": "Single-AZ 2이므로 고가용성 측면에서 RPO 목표 충족이 어렵고, Governance mode가 완전한 삭제 방지를 제공하지 못해 조건을 만족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q570",
      "Q54",
      "Q621",
      "Q508",
      "Q102"
    ],
    "SelectA_recommedations": [
      "Q618",
      "Q621",
      "Q570"
    ],
    "SelectB_recommedations": [
      "Q618",
      "Q54",
      "Q621"
    ],
    "SelectC_recommedations": [
      "Q618",
      "Q621",
      "Q54"
    ],
    "SelectD_recommedations": [
      "Q618",
      "Q621",
      "Q54"
    ]
  },
  {
    "Question_Number": "Q619",
    "Question_Description": "한 회사가 AWS Organizations를 통해 각 개발자에게 개별 AWS 계정을 부여하면서도 표준 보안 통제를 유지하려고 합니다. 각 개발자는 자기 계정에 대해 root user-level access를 갖게 되므로, 새로운 개발자 계정에 적용되는 mandatory AWS CloudTrail 구성이 변경되지 않도록 보장해야 합니다. 이를 충족하는 방법은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121220-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 개발자가 자신의 계정에서 root 사용자 권한을 갖더라도, 필수 CloudTrail 설정이 수정되지 않도록 제한해야 하는 상황을 다룹니다. Account 단위 권한보다 상위 권한으로 동작하는 SCP를 사용하면 각 개발자 계정에서도 CloudTrail 변경 권한을 차단할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "개별 개발자 계정",
      "AWS Organizations",
      "root user-level access",
      "mandatory AWS CloudTrail",
      "변경 방지",
      "표준 보안 통제"
    ],
    "Terms": [
      "AWS Organizations",
      "IAM policy",
      "CloudTrail",
      "Service Control Policy (SCP)",
      "service-linked role",
      "Amazon Resource Name (ARN)"
    ],
    "SelectA": "IAM policy를 생성하여 CloudTrail 변경을 금지하고, 이를 root user에 연결합니다.",
    "SelectA_Commentary": "root user는 계정 내 최상위 권한이므로 IAM policy만으로 이를 제한하기 쉽지 않습니다. root user는 IAM policy를 제거하거나 변경할 수 있습니다.",
    "SelectB": "developer 계정 내에서 organization trails 옵션을 활성화하여 신규 CloudTrail을 생성합니다.",
    "SelectB_Commentary": "organization trails를 사용해도 개발자가 해당 계정 내에서 Trail을 비활성화할 수 있습니다. root user라면 완전한 변경 차단이 불가능합니다.",
    "SelectC": "CloudTrail 변경을 금지하는 Service Control Policy(SCP)를 생성하고 이를 developer 계정에 연결합니다.",
    "SelectC_Commentary": "SCP는 Organizations에서 계정보다 상위에서 동작하므로, root user도 CloudTrail 설정을 수정할 수 없게 만듭니다. 문제의 요구사항을 충족하는 최적의 방법입니다.",
    "SelectD": "CloudTrail에 대한 service-linked role을 생성하고 관리 계정의 ARN에서만 변경을 허용하는 policy 조건을 설정합니다.",
    "SelectD_Commentary": "service-linked role과 정책 조건만으로 root user 권한을 완전히 제한하기 어렵습니다. root user가 role이나 정책 자체를 수정할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q137",
      "Q878",
      "Q168",
      "Q945",
      "Q1018"
    ],
    "SelectA_recommedations": [
      "Q524",
      "Q423",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q619",
      "Q524",
      "Q898"
    ],
    "SelectC_recommedations": [
      "Q942",
      "Q524",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q619",
      "Q423",
      "Q942"
    ]
  },
  {
    "Question_Number": "Q620",
    "Question_Description": "한 회사가 AWS Cloud에 비즈니스 크리티컬 애플리케이션을 배포하려고 합니다. 이 애플리케이션에는 내구성(durable)이 보장된 스토리지와 일관적인 저지연 성능이 필요합니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 어떤 유형의 스토리지를 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121221-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 내구성과 일관적인 저지연 성능을 동시에 요구하는 애플리케이션에 알맞은 스토리지를 결정하는 것입니다. Instance store volume와 ElastiCache는 둘 다 애플리케이션 재부팅 시 데이터가 손실될 수 있으므로 영구적 보관이 보장되지 않습니다. Throughput Optimized HDD는 대규모 순차 처리에 적합하지만 저지연의 일관적 성능을 제공하지 못합니다. Provisioned IOPS SSD Amazon EBS volume은 높은 IOPS와 낮은 지연 시간을 제공해 비즈니스 크리티컬 애플리케이션에 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "비즈니스 크리티컬 애플리케이션",
      "내구성",
      "일관된 저지연 성능",
      "Provisioned IOPS SSD"
    ],
    "Terms": [
      "Instance store volume",
      "Amazon ElastiCache for Memcached cluster",
      "Provisioned IOPS SSD Amazon EBS volume",
      "Throughput Optimized HDD Amazon EBS volume"
    ],
    "SelectA": "Instance store volume",
    "SelectA_Commentary": "Instance store volume은 영구 저장이 보장되지 않아 내구성이 필요한 워크로드에는 적합하지 않습니다.",
    "SelectB": "Amazon ElastiCache for Memcached cluster",
    "SelectB_Commentary": "인메모리 캐시 솔루션으로, 재부팅 시 데이터 유실 위험이 있어 주 스토리지로 사용하는 것은 부적합합니다.",
    "SelectC": "Provisioned IOPS SSD Amazon Elastic Block Store (Amazon EBS) volume",
    "SelectC_Commentary": "높은 IOPS와 일관적 저지연을 갖춘 내구성 스토리지로, 비즈니스 크리티컬 워크로드에 가장 적합합니다.",
    "SelectD": "Throughput Optimized HDD Amazon Elastic Block Store (Amazon EBS) volume",
    "SelectD_Commentary": "주로 대규모 순차 작업에 최적화되어 있어 저지연이 필요한 애플리케이션에는 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q631",
      "Q361",
      "Q865",
      "Q443",
      "Q143"
    ],
    "SelectA_recommedations": [
      "Q830",
      "Q1000",
      "Q496"
    ],
    "SelectB_recommedations": [
      "Q704",
      "Q857",
      "Q229"
    ],
    "SelectC_recommedations": [
      "Q919",
      "Q299",
      "Q305"
    ],
    "SelectD_recommedations": [
      "Q299",
      "Q857",
      "Q305"
    ]
  },
  {
    "Question_Number": "Q621",
    "Question_Description": "한 온라인 사진 공유 회사가 us-west-1 리전에 위치한 Amazon S3 버킷에 사진을 저장하고 있습니다. 이 회사는 신규로 업로드되는 모든 사진의 사본을 us-east-1 리전에 보관해야 합니다. 가장 적은 운영 노력을 통해 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121222-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 S3 버킷의 신규 객체를 다른 리전으로 자동 복제해 운영 오버헤드를 줄이는 방법을 묻습니다. S3 Cross-Region Replication을 사용하면 새 객체를 자동으로 복제하므로 구현과 관리가 간단합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "자동 복제",
      "운영 부담 최소화",
      "Amazon S3",
      "us-west-1",
      "us-east-1",
      "S3 Cross-Region Replication"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Cross-Region Replication",
      "CORS (Cross-Origin Resource Sharing)",
      "AWS Lambda",
      "S3 event notifications",
      "S3 Lifecycle rule"
    ],
    "SelectA": "us-east-1 리전에 두 번째 S3 버킷을 생성한 뒤, S3 Cross-Region Replication을 사용하여 기존 S3 버킷에서 사진을 복제합니다.",
    "SelectA_Commentary": "S3 Cross-Region Replication은 새 객체를 자동으로 복제해 유지보수가 최소화됩니다. 운영 노력이 가장 적은 정답입니다.",
    "SelectB": "기존 S3 버킷의 cross-origin resource sharing(CORS) 구성을 생성하고 AllowedOrigin 요소에 us-east-1을 명시합니다.",
    "SelectB_Commentary": "CORS는 다른 도메인에서 리소스를 요청할 수 있도록 설정하는 것으로 복제 기능과는 무관합니다.",
    "SelectC": "us-east-1 리전에 두 번째 S3 버킷을 여러 가용 영역에 걸쳐 생성한 후, S3 Lifecycle 룰을 사용해 사진을 저장하도록 합니다.",
    "SelectC_Commentary": "Lifecycle 룰은 객체 보관 정책과 스토리지 클래스를 변경하기 위한 기능으로, 리전에 대한 자동 복제는 지원하지 않습니다.",
    "SelectD": "us-east-1 리전에 두 번째 S3 버킷을 생성합니다. 객체 생성, 업데이트 이벤트에 대한 S3 event notifications를 구성하여 AWS Lambda 함수를 호출하고 기존 S3 버킷에서 새 버킷으로 사진을 복제합니다.",
    "SelectD_Commentary": "Lambda 함수를 사용해 복제하면 사용자 정의 코드 및 이벤트 설정이 필요해 운영 복잡도가 높아집니다.",
    "Question_Description_recommedations": [
      "Q570",
      "Q784",
      "Q94",
      "Q110",
      "Q584"
    ],
    "SelectA_recommedations": [
      "Q621",
      "Q891",
      "Q570"
    ],
    "SelectB_recommedations": [
      "Q621",
      "Q570",
      "Q408"
    ],
    "SelectC_recommedations": [
      "Q621",
      "Q570",
      "Q891"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q621",
      "Q98"
    ]
  },
  {
    "Question_Number": "Q622",
    "Question_Description": "한 회사가 구독자를 위해 새로운 웹 애플리케이션을 개발하려고 합니다. 이 애플리케이션은 스태틱 단일 페이지와 지속성 있는 데이터베이스 계층으로 구성됩니다. 매일 아침 4시간 동안은 수백만 명의 사용자가 접속하지만, 나머지 시간에는 수천 명 수준으로 트래픽이 감소합니다. 또한 데이터 아키텍트들은 스키마를 빠르게 변경할 수 있는 능력을 요구하고 있습니다. 이 요구사항을 충족하면서 가장 확장성이 뛰어난 솔루션 두 가지를 고르세요.",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121223-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 많은 사용자가 특정 시간대에 몰리고, 그 외 시간에는 부하가 감소하는 패턴을 어떻게 효율적으로 처리할지 묻습니다. 스태틱 콘텐츠 제공에는 Amazon S3와 Amazon CloudFront가 뛰어난 확장성과 저비용을 제공합니다. 데이터베이스 계층에서 스키마 변경이 자유롭고 사용량에 따라 유연하게 확장할 수 있는 Amazon DynamoDB의 On-Demand Capacity 옵션이 특히 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3",
      "3.4"
    ],
    "Keywords": [
      "스태틱 단일 페이지",
      "수백만 명의 사용",
      "스키마 빠른 변경",
      "확장성",
      "Amazon DynamoDB On-Demand",
      "Amazon S3",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "On-Demand Capacity",
      "DynamoDB Auto Scaling",
      "Amazon Aurora",
      "Serverless DB Engine Mode",
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon EC2",
      "Auto Scaling Group",
      "Amazon Elastic File System (Amazon EFS)"
    ],
    "SelectA": "Amazon DynamoDB를 데이터베이스 솔루션으로 배포하고, On-Demand Capacity를 프로비저닝합니다.",
    "SelectA_Commentary": "On-Demand Capacity는 트래픽 급증에 자동으로 대응하며 스키마 변경에도 유연합니다. 짧은 고부하 시간대에도 추가 설정 없이 빠르게 확장이 가능합니다.",
    "SelectB": "Amazon Aurora를 데이터베이스 솔루션으로 배포하고, Serverless DB Engine Mode를 선택합니다.",
    "SelectB_Commentary": "Aurora Serverless는 확장성은 좋지만, DynamoDB만큼 무제한 확장은 아니며 스키마 변경 유연성에서 NoSQL 방식과는 차이가 큽니다.",
    "SelectC": "Amazon DynamoDB를 데이터베이스 솔루션으로 배포하고, DynamoDB Auto Scaling을 활성화합니다.",
    "SelectC_Commentary": "Auto Scaling도 유용하지만 On-Demand Capacity만큼 즉각적이고 큰 폭의 확장에는 다소 제한이 있을 수 있습니다.",
    "SelectD": "스태틱 콘텐츠를 Amazon S3 버킷에 배포하고, 이를 Origin으로 하는 Amazon CloudFront 배포를 구성합니다.",
    "SelectD_Commentary": "S3와 CloudFront 조합은 전 세계적으로 빠른 콘텐트 배포와 높은 확장성, 낮은 운영 복잡성을 모두 만족하는 최적의 방식입니다.",
    "SelectE": "스태틱 콘텐츠를 EC2 인스턴스 플릿(ASG)에 배포하고, Amazon Elastic File System(Amazon EFS)에서 주기적으로 콘텐츠를 새로 고칩니다.",
    "SelectE_Commentary": "EC2, EFS 구성이 추가적으로 복잡하며 S3/CloudFront에 비해 글로벌 확장성 면에서 더 많은 관리와 비용이 필요합니다.",
    "Question_Description_recommedations": [
      "Q915",
      "Q506",
      "Q132",
      "Q158",
      "Q888"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q177",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q886",
      "Q235",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q43",
      "Q626"
    ],
    "SelectE_recommedations": [
      "Q680",
      "Q695",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q623",
    "Question_Description": "한 회사는 서드 파티 서비스 제공업체가 액세스하는 REST API들을 관리하기 위해 Amazon API Gateway를 사용하고 있습니다. 회사는 REST API들을 SQL injection과 cross-site scripting 공격으로부터 보호해야 합니다. 이러한 요구사항을 충족하면서 가장 운영 효율성이 높은 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/121172-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon API Gateway로 제공되는 REST API를 애플리케이션 레벨 공격(SQL injection, cross-site scripting)으로부터 보호해야 하는 상황입니다. AWS WAF를 직접 API Gateway와 연동하면, 추가적인 CloudFront 구성 없이도 주로 웹 공격에 대한 룰 세팅으로 빠르고 간편하게 보호를 적용할 수 있어 운영상 효율이 높습니다. AWS Shield는 주로 DDoS 방어용이며, CloudFront까지 구성하면 복잡성이 증가합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "Amazon API Gateway",
      "SQL injection",
      "cross-site scripting",
      "운영 효율성"
    ],
    "Terms": [
      "AWS WAF",
      "AWS Shield",
      "Amazon CloudFront",
      "REST API",
      "API Gateway"
    ],
    "SelectA": "AWS Shield를 구성합니다.",
    "SelectA_Commentary": "AWS Shield는 DDoS 완화에 중점을 둔 서비스로, SQL injection이나 cross-site scripting 같은 웹 애플리케이션 계층 공격을 충분히 방어하지 못하므로 요구사항에 적합하지 않습니다.",
    "SelectB": "AWS WAF를 구성합니다.",
    "SelectB_Commentary": "API Gateway와 직접 AWS WAF를 연동하면, SQL injection과 cross-site scripting에 대한 보안 룰 설정이 간단하고 운영 효율성이 높습니다. 정답입니다.",
    "SelectC": "Amazon CloudFront 배포와 함께 API Gateway를 설정하고, CloudFront에서 AWS Shield를 구성합니다.",
    "SelectC_Commentary": "CloudFront를 사용하려면 별도의 배포 설정이 필요하고, Shield는 주로 DDoS 공격 방어에 특화되어 있어 웹 애플리케이션 취약점 공격 대응에 부족합니다. 운영 복잡성이 증가합니다.",
    "SelectD": "Amazon CloudFront 배포와 함께 API Gateway를 설정하고, CloudFront에서 AWS WAF를 구성합니다.",
    "SelectD_Commentary": "이 방식도 SQL injection과 cross-site scripting 보호가 가능하지만, CloudFront를 추가로 설정해야 하므로 운영 단순성과 효율성 면에서 직접 WAF를 사용하는 것보다 덜 적합합니다.",
    "Question_Description_recommedations": [
      "Q180",
      "Q119",
      "Q1019",
      "Q399",
      "Q34"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q1019",
      "Q855",
      "Q159"
    ],
    "SelectD_recommedations": [
      "Q165",
      "Q1019",
      "Q855"
    ]
  },
  {
    "Question_Number": "Q624",
    "Question_Description": "회사는 AWS 리소스에 대한 사용자 액세스를 제공하고자 합니다. 회사에는 1,500명의 사용자가 있으며, 온프레미스 리소스 접근은 기업 네트워크 내 Active Directory user group으로 관리됩니다. 하지만 회사는 AWS 리소스에 접근하기 위해 사용자가 또 다른 자격 증명을 유지해야 하는 상황을 원치 않습니다. 솔루션스 아키텍트는 온프레미스 리소스 접근을 보존하면서 동시에 AWS 리소스에 대한 사용자 액세스를 어떻게 관리해야 할까요? 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125336-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존의 Active Directory 사용자 그룹을 사용하여 AWS 리소스에도 단일 계정을 통해 액세스할 수 있도록 하는 방법을 묻고 있습니다. SAML 2.0 Federation을 사용하면 사용자가 자신의 온프레미스 AD 자격 증명을 그대로 활용해 AWS에 로그인할 수 있어, 별도의 IAM user 생성이나 추가 계정 관리가 필요 없습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Active Directory",
      "사용자 그룹",
      "AWS 리소스",
      "별도 자격 증명 불필요",
      "액세스 관리"
    ],
    "Terms": [
      "IAM user",
      "Active Directory",
      "Amazon Cognito",
      "SAML 2.0 Federation",
      "Cross-account role",
      "Policy"
    ],
    "SelectA": "각 사용자를 위한 IAM user를 생성하고, 각 사용자에 적절한 정책을 연결합니다.",
    "SelectA_Commentary": "사용자마다 IAM user를 직접 생성하면 관리가 복잡해지고, 기존 AD 자격 증명을 재활용할 수 없어 요구사항과 맞지 않습니다.",
    "SelectB": "Amazon Cognito와 Active Directory user pool을 사용합니다. 적절한 정책이 연결된 역할을 생성합니다.",
    "SelectB_Commentary": "Amazon Cognito는 주로 애플리케이션 인증용으로 쓰이며, AWS 리소스 자체에 대한 권한 부여 시에는 적절하지 않습니다.",
    "SelectC": "적절한 정책이 연결된 Cross-account role을 정의합니다. 이 역할들을 Active Directory 그룹과 매핑합니다.",
    "SelectC_Commentary": "Cross-account role은 여러 AWS 계정 간에 권한을 부여할 때 사용하는 방식으로, 온프레미스 AD와 직접 연동하는 데에는 적절하지 않습니다.",
    "SelectD": "Security Assertion Markup Language(SAML) 2.0 기반 페더레이션을 구성합니다. 적절한 정책이 연결된 역할을 생성하고, 이 역할들을 Active Directory 그룹과 매핑합니다.",
    "SelectD_Commentary": "SAML 2.0 Federation으로 AD와 AWS를 연동하면 온프레미스 AD 자격 증명을 그대로 사용하면서 AWS 리소스에 안전하고 쉽게 접속할 수 있어 요구사항을 만족합니다.",
    "Question_Description_recommedations": [
      "Q1018",
      "Q168",
      "Q826",
      "Q945",
      "Q28"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectB_recommedations": [
      "Q1011",
      "Q233",
      "Q366"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q745",
      "Q1018"
    ],
    "SelectD_recommedations": [
      "Q761",
      "Q28",
      "Q571"
    ]
  },
  {
    "Question_Number": "Q625",
    "Question_Description": "한 회사가 여러 개의 Application Load Balancer 뒤에서 웹사이트를 호스팅하고 있습니다. 이 회사는 전 세계적으로 콘텐츠에 대해 지역별로 상이한 배포 권리를 보유하고 있습니다. 솔루션스 아키텍트는 사용자들이 배포 권리를 위반하지 않도록, 해당 지역에 맞는 올바른 콘텐츠를 제공받도록 해야 합니다. 이러한 요구사항을 충족하기 위해 어떤 구성을 선택해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125337-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 지역별로 다른 배포 권리를 준수해야 하므로, 사용자의 위치에 따라 맞춤형 콘텐츠를 제공해 위반을 방지해야 한다는 점이 핵심입니다. Amazon Route 53의 Geolocation Routing Policy를 사용하면 사용자 위치 기반으로 트래픽을 분산하여 각 지역의 권리에 맞는 콘텐츠만 전달할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "다른 지역별 배포 권리",
      "올바른 콘텐츠 제공",
      "Amazon Route 53",
      "지리 기반 라우팅"
    ],
    "Terms": [
      "Application Load Balancer",
      "AWS WAF",
      "Amazon CloudFront",
      "Amazon Route 53",
      "Geolocation Routing Policy",
      "Geoproximity Routing Policy"
    ],
    "SelectA": "Amazon CloudFront를 AWS WAF와 함께 구성합니다.",
    "SelectA_Commentary": "CloudFront와 WAF를 사용하면 보안 필터링은 가능하지만, 지역별 트래픽 분산까지는 보장되지 않아 배포 권리 충족이 어렵습니다.",
    "SelectB": "Application Load Balancer에 AWS WAF를 구성합니다.",
    "SelectB_Commentary": "WAF로 특정 요청을 차단하거나 허용할 순 있지만 지리적 라우팅 기능은 부족하여 지역별 배포 권리 관리가 어렵습니다.",
    "SelectC": "Amazon Route 53에서 geolocation policy를 구성합니다.",
    "SelectC_Commentary": "사용자의 위치에 따라 적절한 Application Load Balancer로 트래픽을 라우팅해 지역별 배포 권리를 준수할 수 있는 최적의 해법입니다.",
    "SelectD": "Amazon Route 53에서 geoproximity routing policy를 구성합니다.",
    "SelectD_Commentary": "지리적 거리 기반의 라우팅으로, 리소스 간 트래픽 전환이 주 목적입니다. 지역별 배포 권리 관리에는 geolocation policy가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q170",
      "Q707",
      "Q169",
      "Q644",
      "Q922"
    ],
    "SelectA_recommedations": [
      "Q165",
      "Q538",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q170",
      "Q169",
      "Q625"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q592",
      "Q106"
    ],
    "SelectD_recommedations": [
      "Q532",
      "Q855",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q626",
    "Question_Description": "한 회사가 사내에 데이터를 저장하고 있으며, 데이터 양이 회사가 확보할 수 있는 용량을 넘어서 계속 증가하고 있습니다. 이 회사는 온프레미스 위치의 데이터를 Amazon S3 버킷으로 마이그레이션하려고 합니다. 중요한 점은 전송이 끝난 후 데이터 무결성을 자동으로 검증해 줄 수 있는 솔루션이 필요합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125338-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사내 저장소의 용량 한계를 넘은 데이터를 AWS로 이전하면서, 전송 과정에서 자동으로 데이터 무결성을 검증해야 하는 상황을 다룹니다. AWS DataSync는 온라인 전송 중에 데이터 무결성을 자동 확인해 주므로 요구사항을 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.5"
    ],
    "Keywords": [
      "온프레미스",
      "Amazon S3 버킷",
      "데이터 무결성",
      "자동 검증",
      "데이터 마이그레이션"
    ],
    "Terms": [
      "AWS Snowball Edge",
      "AWS DataSync",
      "Amazon S3 File Gateway",
      "Amazon S3 Transfer Acceleration",
      "Data Integrity",
      "On premises",
      "Amazon S3"
    ],
    "SelectA": "AWS Snowball Edge 디바이스를 주문하고, 온라인 전송을 수행하도록 구성합니다.",
    "SelectA_Commentary": "Snowball Edge는 대규모 데이터 이전에 주로 오프라인 방식(디바이스 운송)을 사용하며, 자동 무결성 검증 기능이 DataSync처럼 온라인 전송 중에 실시간으로 제공되지는 않습니다.",
    "SelectB": "온프레미스에 AWS DataSync 에이전트를 배포하고, 에이전트를 통해 Amazon S3 버킷으로 온라인 전송을 수행합니다.",
    "SelectB_Commentary": "정답입니다. DataSync는 전송 과정에서 자동으로 데이터 무결성을 검증하고 간편하게 대규모 데이터를 S3로 옮길 수 있습니다.",
    "SelectC": "온프레미스에 Amazon S3 File Gateway를 생성하고, 이를 사용해 Amazon S3 버킷으로 온라인 전송을 수행합니다.",
    "SelectC_Commentary": "S3 File Gateway는 온프레미스 어플리케이션이 S3를 네트워크 파일 공유처럼 사용하게 해주지만, DataSync처럼 세분화된 전송 무결성 검증이 자동 수행되지는 않습니다.",
    "SelectD": "온프레미스에서 Amazon S3 Transfer Acceleration 가속기를 구성하고, 이를 통해 Amazon S3 버킷으로 온라인 전송을 수행합니다.",
    "SelectD_Commentary": "S3 Transfer Acceleration은 전송 속도를 높이는 기능이지만 자동 무결성 확인 기능을 제공하지 않아 요구사항을 만족시키지 못합니다.",
    "Question_Description_recommedations": [
      "Q501",
      "Q43",
      "Q547",
      "Q173",
      "Q302"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q865",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q155",
      "Q292",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q672",
      "Q680",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q672",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q627",
    "Question_Description": "회사는 두 대의 DNS 서버를 AWS로 마이그레이션하려고 합니다. 이 서버들은 총 200개의 존을 호스팅하며, 평균적으로 일일 100만 건의 요청을 받습니다. 회사는 두 서버의 운영 관리를 위한 오버헤드를 최소화하면서, 가용성을 최대화하고자 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 것을 권장해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125541-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 DNS 서버를 AWS로 이전하여 최대한 높은 가용성을 확보하고, 서버 관리 부담을 최소화하는 것이 핵심입니다. Amazon Route 53은 완전관리형 DNS 서비스로 200개 존을 쉽게 호스팅하며, 대규모 트래픽을 안정적으로 처리합니다. EC2 인스턴스나 AWS SMS를 활용하면 직접 서버와 OS를 운영해야 하므로 운영 부하가 크고, Auto Scaling 구성 역시 DNS 서버 관리를 단순화하기는 어렵습니다. 따라서 Amazon Route 53에 새 hosted zone을 생성하고 zone 파일을 가져오는 방법이 최적의 해법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DNS 서버 마이그레이션",
      "200개 존",
      "100만 요청",
      "가용성 극대화",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Route 53",
      "Hosted Zones",
      "Zone Files",
      "Amazon EC2",
      "AWS Server Migration Service (AWS SMS)",
      "Amazon CloudWatch",
      "Auto Scaling group",
      "Availability Zones",
      "CPU utilization"
    ],
    "SelectA": "Amazon Route 53 콘솔에서 200개의 새로운 hosted zone을 생성하고, zone 파일을 가져옵니다.",
    "SelectA_Commentary": "Route 53은 완전관리형 DNS로 운영 부담이 적고, 가용성을 높게 유지하므로 요구사항을 만족합니다.",
    "SelectB": "하나의 대형 Amazon EC2 인스턴스를 실행하고 zone 파일을 가져옵니다. Amazon CloudWatch 알람을 구성합니다.",
    "SelectB_Commentary": "EC2 인스턴스 하나에 의존하면 단일 장애 지점이 생기고 관리 오버헤드가 큽니다.",
    "SelectC": "AWS Server Migration Service(AWS SMS)를 활용해 서버들을 AWS로 마이그레이션하고 CloudWatch 알람을 구성합니다.",
    "SelectC_Commentary": "온프레미스 DNS 서버 자체를 이전하므로 운영 체제 및 DNS 소프트웨어 관리는 여전히 남습니다.",
    "SelectD": "두 개의 Availability Zone에 걸친 Auto Scaling group에서 EC2 인스턴스를 실행하고 zone 파일을 가져옵니다.",
    "SelectD_Commentary": "Auto Scaling으로 EC2가 확장 가능하나, DNS 서버 관리 작업이 여전히 남아있어 간단하지 않습니다.",
    "Question_Description_recommedations": [
      "Q741",
      "Q293",
      "Q8",
      "Q163",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q627",
      "Q264",
      "Q545"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q790"
    ],
    "SelectC_recommedations": [
      "Q843",
      "Q351",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q691",
      "Q729",
      "Q595"
    ]
  },
  {
    "Question_Number": "Q628",
    "Question_Description": "글로벌 회사가 AWS Organizations의 여러 AWS 계정에서 애플리케이션을 운영하고 있습니다. 이 회사의 애플리케이션은 여러 AWS Region에 있는 여러 Amazon S3 버킷에 데이터를 업로드하기 위해 multipart upload를 사용합니다. 회사는 비용 준수(Cost compliance) 목적으로 불완전 multipart upload에 대한 보고서를 원합니다. 운영 오버헤드를 최소화하면서 이 요구 사항을 충족시키는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정과 리전에서 발생하는 불완전 multipart upload를 한 곳에서 모니터링하여 비용을 절감하고자 하는 상황입니다. 단순히 규칙을 생성하거나 정책을 설정하는 것보다, 중앙 집중식으로 S3 사용 현황을 분석하고 지표를 제공해주는 S3 Storage Lens가 가장 쉽게 운영 오버헤드를 낮출 수 있는 방법입니다. 이를 통해 불완전 multipart upload를 신속히 파악하고 대처하여 비용 효율을 높일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "글로벌 회사",
      "비용 준수",
      "불완전 multipart upload",
      "멀티플 AWS 계정",
      "S3 Storage Lens",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Config",
      "service control policy (SCP)",
      "S3 Storage Lens",
      "S3 Multi-Region Access Point",
      "multipart upload",
      "Amazon S3"
    ],
    "SelectA": "AWS Config에 규칙을 구성하여 불완전 multipart upload 오브젝트 수를 보고합니다.",
    "SelectA_Commentary": "AWS Config는 리소스 구성을 추적하는 서비스이며, 기본적으로 불완전 multipart upload 데이터 집계에 최적화되어 있지 않아 작업이 복잡해질 수 있습니다.",
    "SelectB": "불완전 multipart upload 오브젝트 개수를 보고하기 위해 service control policy (SCP)를 생성합니다.",
    "SelectB_Commentary": "SCP는 계정 운영 범위와 권한 제어에 활용되며, 구체적인 S3 버킷 내부 상태 모니터링을 위한 도구로는 적합하지 않습니다.",
    "SelectC": "S3 Storage Lens를 구성하여 불완전 multipart upload 오브젝트 수를 보고합니다.",
    "SelectC_Commentary": "S3 Storage Lens는 여러 계정, 버킷의 스토리지 상태를 모니터링해 불완전 multipart upload를 손쉽게 파악하므로 운영 오버헤드를 최소화하는 정답입니다.",
    "SelectD": "불완전 multipart upload 오브젝트 수를 보고하기 위해 S3 Multi-Region Access Point를 생성합니다.",
    "SelectD_Commentary": "Multi-Region Access Point는 S3 접근 경로를 단순화하기 위한 기능으로, 보고 기능 자체를 제공하지 않아 요구 사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q455",
      "Q72",
      "Q326",
      "Q960",
      "Q559"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q728",
      "Q541"
    ],
    "SelectB_recommedations": [
      "Q326",
      "Q628",
      "Q205"
    ],
    "SelectC_recommedations": [
      "Q326",
      "Q725",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q628",
      "Q326",
      "Q72"
    ]
  },
  {
    "Question_Number": "Q629",
    "Question_Description": "한 회사가 Amazon RDS for MySQL을 사용하여 프로덕션 데이터베이스를 운영 중입니다. 회사는 보안 규정 준수를 위해 데이터베이스 버전을 업그레이드하기를 원합니다. 데이터베이스에는 중요한 데이터가 포함되어 있으므로, 데이터를 잃지 않고 빠르게 업그레이드를 진행하고 기능을 테스트할 수 있는 솔루션이 필요합니다. 가장 낮은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125460-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL 데이터베이스를 보안 규정에 맞게 빠르게 업그레이드하고, 동시에 데이터 손실 없이 기능 테스트를 수행할 수 있는 방법을 묻습니다. Amazon RDS Blue/Green Deployments를 사용하면 별도의 스테이징 환경에서 새 버전으로 업그레이드와 테스트를 진행한 뒤, 거의 중단 시간 없이 프로덕션으로 전환할 수 있어 운영 오버헤드가 매우 낮습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "보안 규정 준수",
      "데이터 손실 없이",
      "빠른 업그레이드",
      "운영 오버헤드 최소화",
      "Amazon RDS for MySQL",
      "Blue/Green Deployments"
    ],
    "Terms": [
      "RDS manual snapshot",
      "Native backup and restore",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon RDS Blue/Green Deployments",
      "Amazon RDS for MySQL"
    ],
    "SelectA": "RDS manual snapshot을 생성한 후 Amazon RDS for MySQL의 새 버전으로 업그레이드합니다.",
    "SelectA_Commentary": "수동 스냅샷 생성 후 인플레이스 업그레이드는 다운타임이 길어질 수 있으며 업그레이드 실패 시 복구에도 시간이 걸립니다.",
    "SelectB": "Native backup과 restore를 사용하여 데이터를 업그레이드된 새 버전의 Amazon RDS for MySQL에 복원합니다.",
    "SelectB_Commentary": "백업과 복원 과정을 수동으로 진행해야 하므로 과정이 복잡하고 다운타임 또한 길어질 수 있어 운영 오버헤드가 높습니다.",
    "SelectC": "AWS DMS를 사용하여 데이터를 업그레이드된 새 버전의 Amazon RDS for MySQL로 복제합니다.",
    "SelectC_Commentary": "AWS DMS를 통한 복제 구성은 유연하지만, 데이터 마이그레이션 작업 설정과 모니터링에 대한 추가 오버헤드가 발생합니다.",
    "SelectD": "Amazon RDS Blue/Green Deployments를 사용하여 프로덕션 변경 사항을 배포하고 테스트합니다.",
    "SelectD_Commentary": "별도의 스테이징 환경에서 새로운 버전을 테스트하고, 준비가 되면 거의 즉시 프로덕션으로 전환할 수 있어 운영 오버헤드가 매우 낮고 다운타임도 최소화됩니다.",
    "Question_Description_recommedations": [
      "Q518",
      "Q259",
      "Q108",
      "Q978",
      "Q195"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q629",
      "Q601"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q629",
      "Q182"
    ],
    "SelectC_recommedations": [
      "Q518",
      "Q629",
      "Q843"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q67",
      "Q108"
    ]
  },
  {
    "Question_Number": "Q630",
    "Question_Description": "솔루션스 아키텍트가 하루에 한 번 실행되며 최대 2시간까지 걸릴 수 있는 데이터 처리 작업을 생성하고 있습니다. 만약 작업이 중단될 경우, 작업은 처음부터 다시 시작해야 합니다. 이 문제를 가장 비용 효율적으로 해결하려면 어떻게 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125542-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 비용을 절감하면서 최대 2시간 동안 실행되는 일일 배치 작업을 안정적으로 처리하는 방법을 묻습니다. Lambda의 경우 최대 실행 시간이 15분으로 제한되어 있고, EC2를 직접 사용하는 방법은 인스턴스 비용이 더 높아질 수 있습니다. Amazon ECS에서 Fargate를 사용하면, 실제로 작업이 수행되는 동안에만 비용이 발생하므로 가장 경제적이며 작업 내 장애가 발생해도 재처리를 자동 수행할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "데이터 처리 작업",
      "하루 한 번 실행",
      "2시간 소요",
      "중단 시 재시작",
      "비용 효율"
    ],
    "Terms": [
      "Amazon EC2 Reserved Instance",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon ECS",
      "Fargate",
      "Cron job"
    ],
    "SelectA": "Amazon EC2 예약 인스턴스에 로컬로 스크립트를 작성하고 cron job으로 트리거합니다.",
    "SelectA_Commentary": "예약 인스턴스를 활용해도 장기간 인스턴스가 실행되어 있어야 하므로, 2시간씩 매일 작업하는 데 추가 고정 비용이 발생할 수 있습니다.",
    "SelectB": "Amazon EventBridge 예약 이벤트로 트리거되는 AWS Lambda 함수를 생성합니다.",
    "SelectB_Commentary": "Lambda 함수는 최대 실행 시간이 15분이므로, 2시간이 필요한 작업을 전부 처리할 수 없습니다.",
    "SelectC": "Amazon EventBridge 예약 이벤트로 트리거되는 Amazon ECS Fargate 태스크를 사용합니다.",
    "SelectC_Commentary": "Fargate는 실제로 태스크가 동작하는 시간만큼만 과금되므로 2시간 작업에 적합하고 비용 효율적입니다. 중단 시 재시작을 유연하게 관리할 수 있습니다.",
    "SelectD": "Amazon EventBridge 예약 이벤트로 트리거되는 Amazon ECS 태스크를 Amazon EC2에서 실행합니다.",
    "SelectD_Commentary": "EC2에서 태스크를 실행하면 인스턴스가 상시 실행 비용을 부담하게 되어 Fargate에 비해 더 큰 비용이 들어갈 수 있습니다.",
    "Question_Description_recommedations": [
      "Q997",
      "Q656",
      "Q49",
      "Q794",
      "Q930"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q238",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q238",
      "Q300",
      "Q128"
    ],
    "SelectC_recommedations": [
      "Q926",
      "Q552",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q591",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q631",
    "Question_Description": "한 소셜 미디어 회사가 사용자 프로필, 관계, 상호 작용으로 구성된 데이터베이스를 AWS Cloud에 저장하려고 합니다. 이 회사는 데이터베이스에서 발생하는 모든 변경 사항을 모니터링할 애플리케이션이 필요합니다. 이 애플리케이션은 데이터 엔티티 간의 관계를 분석하고 사용자에게 추천을 제공해야 합니다. 이 요구사항을 가장 적은 운영 오버헤드로 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125113-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 엔티티 사이의 풍부한 관계를 저장하고, 변경 사항 모니터링과 추천 기능을 수행해야 하는 요구사항을 다루고 있습니다. Graph Database인 Amazon Neptune은 복잡한 관계를 효율적으로 저장하고 질의하기에 적합하며, Neptune Streams를 활용하여 변경 사항을 자동으로 처리하므로 운영 작업이 최소화됩니다. Amazon QLDB는 감사 로깅과 원장 기능이 중요한 경우에 적합하지만, 그래프 관계 분석 측면에서는 Neptune이 훨씬 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "소셜 미디어 데이터",
      "관계 분석",
      "추천 시스템",
      "Amazon Neptune",
      "Neptune Streams",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "Amazon Neptune",
      "Amazon Kinesis Data Streams",
      "Neptune Streams",
      "Amazon Quantum Ledger Database(Amazon QLDB)"
    ],
    "SelectA": "Amazon Neptune을 사용하여 정보를 저장합니다. Amazon Kinesis Data Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
    "SelectA_Commentary": "Neptune에 저장하는 것은 적절하지만, 변경 사항 처리를 위해 별도의 Amazon Kinesis Data Streams 구성을 유지해야 하므로 운영이 더 복잡해집니다.",
    "SelectB": "Amazon Neptune을 사용하여 정보를 저장합니다. Neptune Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
    "SelectB_Commentary": "그래프 관계를 저장하기에 Neptune이 가장 적합하며, Neptune Streams를 통해 변경 사항을 자동 모니터링하여 운영 오버헤드를 최소화하므로 정답입니다.",
    "SelectC": "Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. Amazon Kinesis Data Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
    "SelectC_Commentary": "QLDB는 금융 거래 등 투명성과 변조 방지 기능이 필요한 환경에 적합하며, 그래프 전문 기능이 없으므로 이 요구사항에 적절하지 않습니다.",
    "SelectD": "Amazon Quantum Ledger Database(Amazon QLDB)를 사용하여 정보를 저장합니다. Neptune Streams를 사용하여 데이터베이스의 변경 사항을 처리합니다.",
    "SelectD_Commentary": "QLDB와 Neptune Streams를 조합하는 것은 기술적으로나 사용 사례 관점에서 부적절하며, 관계형(그래프형) 데이터에 대한 최적의 접근이 아닙니다.",
    "Question_Description_recommedations": [
      "Q568",
      "Q443",
      "Q361",
      "Q192",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q626",
      "Q622"
    ],
    "SelectC_recommedations": [
      "Q33",
      "Q472",
      "Q177"
    ],
    "SelectD_recommedations": [
      "Q33",
      "Q472",
      "Q177"
    ]
  },
  {
    "Question_Number": "Q632",
    "Question_Description": "회사는 새 애플리케이션을 만들고 있으며, 이 애플리케이션은 대규모 데이터를 저장할 것입니다. 이 데이터는 매시간 분석되며 여러 가용 영역(Availability Zones)에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 수정됩니다. 필요한 스토리지 용량은 앞으로 6개월 동안 계속 증가할 예정입니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 스토리지 솔루션을 추천해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125114-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 인스턴스가 동시에 파일을 읽고 쓰며, 스토리지 용량이 동적으로 늘어나는 상황에서 적절한 스토리지 유형을 찾는 문제입니다. Amazon EFS는 다중 AZ에서 확장 가능한 파일 스토리지를 제공해 요구사항에 최적화되어 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "대규모 데이터",
      "매시간 분석",
      "여러 가용 영역",
      "EC2 Linux 인스턴스",
      "스토리지 확장",
      "Amazon EFS"
    ],
    "Terms": [
      "Amazon S3 Glacier",
      "Amazon Elastic Block Store (Amazon EBS)",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon EC2",
      "Availability Zones",
      "Provisioned IOPS volume"
    ],
    "SelectA": "Amazon S3 Glacier에 데이터를 저장합니다. S3 Glacier vault policy를 업데이트하여 애플리케이션 인스턴스에 대한 액세스를 허용합니다.",
    "SelectA_Commentary": "S3 Glacier는 장기 보관에 최적화되어 자주 수정되는 데이터의 즉시 접근에는 적합하지 않습니다.",
    "SelectB": "Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 해당 EBS 볼륨을 애플리케이션 인스턴스에 마운트합니다.",
    "SelectB_Commentary": "Amazon EBS는 기본적으로 한 인스턴스에만 연결 가능하므로, 다수의 인스턴스가 동시에 읽고 쓸 수 없습니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS) 파일 시스템에 데이터를 저장합니다. 파일 시스템을 애플리케이션 인스턴스에 마운트합니다.",
    "SelectC_Commentary": "Amazon EFS는 다중 AZ에 걸쳐 확장 가능하며 여러 인스턴스가 동시에 액세스할 수 있어 요구사항을 충족합니다.",
    "SelectD": "하나의 Amazon EBS Provisioned IOPS 볼륨을 여러 애플리케이션 인스턴스가 공유합니다.",
    "SelectD_Commentary": "하나의 EBS 볼륨을 여러 인스턴스가 직접 공유하는 것은 일반적인 시나리오가 아니며, 확장성과 동시 액세스에 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q369",
      "Q566",
      "Q976",
      "Q818",
      "Q746"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q173"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q746",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q695",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q919",
      "Q127",
      "Q20"
    ]
  },
  {
    "Question_Number": "Q633",
    "Question_Description": "한 회사가 Amazon RDS for PostgreSQL Multi-AZ DB instance에 데이터를 저장하는 애플리케이션을 운영하고 있습니다. 트래픽 증가로 인해 성능 문제가 발생하고 있으며, 회사는 데이터베이스 쿼리가 성능 저하의 주된 원인이라고 판단했습니다. 애플리케이션의 성능을 개선하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125513-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 RDS for PostgreSQL의 쓰기·읽기 트래픽 증가로 인한 성능 저하를 해결하는 방법을 묻습니다. Multi-AZ는 고가용성 구성을 제공하지만, 대기 인스턴스는 읽기 연결을 지원하지 않습니다. 따라서 읽기 전용 부하를 분산하기 위해 read replica를 생성하고, 읽기 트래픽을 그쪽으로 오프로드하는 것이 최적의 해결책입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ DB instance",
      "데이터베이스 성능 향상",
      "read replica",
      "트래픽 증가"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ DB instance",
      "Transfer Acceleration",
      "read replica",
      "Amazon Kinesis Data Firehose"
    ],
    "SelectA": "Multi-AZ 보조 복제본에서 읽기 트래픽을 처리합니다.",
    "SelectA_Commentary": "Multi-AZ 대기 인스턴스는 장애 조치용으로 읽기 연결을 지원하지 않아 트래픽 분산에 이용할 수 없습니다.",
    "SelectB": "DB instance에 Transfer Acceleration을 활성화합니다.",
    "SelectB_Commentary": "Transfer Acceleration은 S3 업로드 가속을 위한 기능으로, DB 쿼리 병목을 해결하지 못합니다.",
    "SelectC": "소스 DB instance에서 read replica를 생성하고, 해당 복제본에서 읽기 트래픽을 처리합니다.",
    "SelectC_Commentary": "read replica는 읽기 전용 트래픽을 분산하여 DB 부하를 감소시키는 가장 효율적인 방법입니다.",
    "SelectD": "애플리케이션과 Amazon RDS 사이에 Amazon Kinesis Data Firehose를 사용해 DB 요청 동시성을 높입니다.",
    "SelectD_Commentary": "Kinesis Data Firehose는 주로 스트리밍 데이터 전송에 사용되며, 직접적인 DB 쿼리 성능 개선과는 관련이 적습니다.",
    "Question_Description_recommedations": [
      "Q726",
      "Q376",
      "Q389",
      "Q590",
      "Q269"
    ],
    "SelectA_recommedations": [
      "Q622",
      "Q888",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q496",
      "Q704",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q247",
      "Q337",
      "Q95"
    ],
    "SelectD_recommedations": [
      "Q386",
      "Q269",
      "Q776"
    ]
  },
  {
    "Question_Number": "Q634",
    "Question_Description": "한 회사는 다양한 기계로부터 매일 10GB의 원격 측정 데이터를 수집합니다. 이 데이터는 source data account의 Amazon S3 버킷에 저장됩니다. 회사는 여러 컨설팅 업체를 고용하여 이 데이터를 분석하는 데 활용하려고 합니다. 각 업체의 분석가들은 해당 데이터에 대한 읽기 권한이 필요합니다. 회사는 보안성과 운영 효율성을 극대화할 수 있는 방식으로 source data account에서 데이터를 공유해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125544-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 컨설팅 업체가 소유한 계정으로 안전하고 간편하게 S3 데이터를 제공하는 방법을 묻습니다. 교차 계정 접근 권한을 설정해 각 컨설팅 업체가 자체 계정을 통해 접근하도록 하는 것이 운영 부담을 최소화하고 보안도 강화할 수 있는 최적의 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "원격 측정 데이터",
      "S3 버킷",
      "데이터 공유",
      "교차 계정 액세스",
      "분석가",
      "보안성과 운영 효율성"
    ],
    "Terms": [
      "Amazon S3",
      "교차 계정 액세스",
      "IAM 사용자",
      "S3 버킷 정책",
      "S3 Global Tables",
      "Cross-Account Access"
    ],
    "SelectA": "각 업체별로 S3 Global Tables를 구성하여 데이터를 복제합니다.",
    "SelectA_Commentary": "S3에는 Global Tables 개념이 없으며, 이는 DynamoDB 기능과 혼동된 잘못된 방식입니다.",
    "SelectB": "S3 버킷을 일정 기간 퍼블릭으로 설정하고 컨설팅 업체들에게만 공지합니다.",
    "SelectB_Commentary": "버킷을 일시적으로라도 퍼블릭으로 설정하는 것은 보안 위험이 크고 권장되지 않습니다.",
    "SelectC": "컨설팅 업체 계정에 대해 S3 버킷의 교차 계정 액세스를 구성합니다.",
    "SelectC_Commentary": "각자가 소유한 AWS 계정에서 필요한 권한만 부여받도록 설정해, 보안을 강화하면서도 운영을 단순화할 수 있는 최적의 방법입니다.",
    "SelectD": "source data account에 각 분석가별로 IAM 사용자를 생성하고 해당 사용자에게 S3 버킷 접근 권한을 줍니다.",
    "SelectD_Commentary": "분석가 인원수만큼 계정을 생성하고 관리해야 해 운영이 매우 복잡해지며 권장 방식이 아닙니다.",
    "Question_Description_recommedations": [
      "Q154",
      "Q1007",
      "Q740",
      "Q696",
      "Q44"
    ],
    "SelectA_recommedations": [
      "Q825",
      "Q44",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q634",
      "Q965",
      "Q740"
    ]
  },
  {
    "Question_Number": "Q635",
    "Question_Description": "한 회사가 기본 AWS 리전에서 CIFS와 NFS 파일 공유를 제공하기 위해 Amazon FSx for NetApp ONTAP을 사용하고 있습니다. Amazon EC2 인스턴스에서 실행되는 애플리케이션은 이러한 파일 공유에 액세스합니다. 이 회사는 보조 리전에 스토리지 재해 복구(DR) 솔루션이 필요합니다. 보조 리전에 복제된 데이터는 기본 리전과 동일한 프로토콜(CIFS, NFS)로 액세스할 수 있어야 합니다. 다음 중 운영 오버헤드를 가장 적게 들이면서 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125545-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DR 시나리오에서 CIFS/NFS 파일 공유를 동일하게 운영해야 하므로 FSx for ONTAP 간의 지속적이고 자동화된 복제 기능이 핵심입니다. NetApp SnapMirror는 운영 오버헤드를 최소화하면서 동일 프로토콜 지원과 실시간 복제를 제공하므로 가장 적합한 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon FSx for NetApp ONTAP",
      "CIFS",
      "NFS",
      "보조 리전 DR",
      "SnapMirror"
    ],
    "Terms": [
      "Amazon FSx for NetApp ONTAP",
      "CIFS",
      "NFS",
      "AWS Lambda",
      "Amazon S3",
      "AWS Backup",
      "NetApp SnapMirror",
      "Amazon EFS"
    ],
    "SelectA": "AWS Lambda 함수를 생성하여 데이터를 Amazon S3 버킷으로 복사하고, S3 버킷을 보조 리전에 복제합니다.",
    "SelectA_Commentary": "S3로 복제하면 CIFS/NFS를 직접 지원하지 않으므로 추가 마이그레이션이 필요하고 운영 부담이 늘어납니다.",
    "SelectB": "AWS Backup을 사용하여 FSx for ONTAP 볼륨의 백업을 생성하고, 그 백업을 보조 리전으로 복사한 뒤 새 FSx for ONTAP 인스턴스를 생성합니다.",
    "SelectB_Commentary": "백업/복원 방식은 일정 주기로만 동기화되므로 연속 복제에는 적합하지 않아 운영 부담이 커집니다.",
    "SelectC": "보조 리전에 FSx for ONTAP 인스턴스를 생성하고, NetApp SnapMirror를 사용하여 기본 리전의 데이터를 보조 리전으로 복제합니다.",
    "SelectC_Commentary": "SnapMirror를 통해 연속적이고 자동화된 데이터 복제가 가능하며 CIFS/NFS 프로토콜을 동일하게 활용할 수 있어 가장 적합합니다.",
    "SelectD": "Amazon EFS 볼륨을 생성하고 현재 데이터를 마이그레이션한 후, 해당 볼륨을 보조 리전에 복제합니다.",
    "SelectD_Commentary": "EFS로 전환 시 CIFS/NFS 프로토콜 호환성이 달라지고 추가 구성이 필요해 운영 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q102",
      "Q934",
      "Q842",
      "Q304",
      "Q224"
    ],
    "SelectA_recommedations": [
      "Q404",
      "Q636",
      "Q785"
    ],
    "SelectB_recommedations": [
      "Q635",
      "Q512",
      "Q753"
    ],
    "SelectC_recommedations": [
      "Q635",
      "Q753",
      "Q934"
    ],
    "SelectD_recommedations": [
      "Q615",
      "Q363",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q636",
    "Question_Description": "한 개발 팀이 이벤트 기반 애플리케이션을 개발 중이며, AWS Lambda 함수를 사용하고 있습니다. Amazon S3 버킷에 파일이 업로드될 때마다 이벤트가 생성됩니다. 현재 Amazon S3에서 Amazon Simple Notification Service(Amazon SNS)를 이벤트 대상으로 구성해 두었습니다. 솔루션스 아키텍트는 Amazon S3의 이벤트를 확장 가능한 방식으로 처리하기 위해 어떤 조치를 취해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125546-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷에 업로드되는 파일 이벤트를 안정적으로 처리하기 위한 확장성 있는 아키텍처를 묻습니다. SNS와 SQS를 연동해 큐로 이벤트를 수신하면 병렬 처리 및 자동 확장이 용이하며 Lambda가 부하에 따라 자동으로 스케일할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이벤트 기반 애플리케이션",
      "AWS Lambda",
      "Amazon S3",
      "Amazon SNS",
      "확장 가능한 이벤트 처리",
      "Amazon SQS"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "Amazon Simple Notification Service(Amazon SNS)",
      "Amazon Simple Queue Service(Amazon SQS)",
      "Amazon Elastic Container Service(Amazon ECS)",
      "Amazon Elastic Kubernetes Service(Amazon EKS)",
      "AWS Server Migration Service(AWS SMS)"
    ],
    "SelectA": "Amazon SNS 구독을 만들어 이벤트가 AWS Lambda로 전달되기 전에 Amazon ECS에서 이벤트를 처리하도록 구성합니다.",
    "SelectA_Commentary": "ECS를 중간 처리로 둔다면 설정이 복잡해지고 Lambda로 보내기 전까지 지연이 생길 수 있어 확장 및 간소화 측면에서 적합하지 않습니다.",
    "SelectB": "Amazon SNS 구독을 만들어 이벤트가 AWS Lambda로 전달되기 전에 Amazon EKS에서 이벤트를 처리하도록 구성합니다.",
    "SelectB_Commentary": "EKS 역시 Kubernetes 클러스터 유지 보수가 필요해 운영 복잡도가 증가하며, 단순한 이벤트 처리를 위해 과도한 인프라가 필요합니다.",
    "SelectC": "Amazon SNS 구독을 만들어 이벤트를 Amazon SQS로 전송하도록 합니다. 이후 SQS 큐가 AWS Lambda 함수를 트리거하도록 구성합니다.",
    "SelectC_Commentary": "SQS를 통해 이벤트를 버퍼링하고 메시지 부하에 따라 확장할 수 있어 가장 확장성 높고 안정적인 구성이며, Lambda가 자동으로 스케일할 수 있습니다.",
    "SelectD": "Amazon SNS 구독을 만들어 이벤트를 AWS Server Migration Service(AWS SMS)로 전송하도록 합니다. AWS SMS 이벤트를 폴링하여 Lambda 함수를 실행하도록 구성합니다.",
    "SelectD_Commentary": "AWS SMS는 마이그레이션 서비스로, 일반적인 이벤트 처리 흐름에는 적절하지 않으며 메시지 처리용으로 사용하기에는 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q98",
      "Q45",
      "Q148",
      "Q404",
      "Q18"
    ],
    "SelectA_recommedations": [
      "Q636",
      "Q489",
      "Q775"
    ],
    "SelectB_recommedations": [
      "Q775",
      "Q636",
      "Q563"
    ],
    "SelectC_recommedations": [
      "Q636",
      "Q489",
      "Q45"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q45",
      "Q489"
    ]
  },
  {
    "Question_Number": "Q637",
    "Question_Description": "한 솔루션스 아키텍트가 Amazon API Gateway 뒤에서 동작할 새로운 서비스를 설계하고 있습니다. 요청 패턴은 예측하기 어려우며, 0건에서 초당 500건 이상으로 갑작스럽게 변할 수 있습니다. 백엔드 데이터베이스에 영구적으로 저장해야 하는 데이터의 총 용량은 현재 1GB 미만이지만, 향후 얼마나 증가할지 예측하기 어렵습니다. 데이터는 단순한 키-값 요청으로 조회할 수 있습니다. 이러한 요구사항을 충족하기 위해 어떤 AWS 서비스 조합을 선택해야 합니까? (2개를 고르십시오.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125547-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 갑작스러운 트래픽 급증을 처리하고, 키-값 형태의 데이터를 확장성 있게 보관할 솔루션을 묻습니다. 서버리스로 자동 확장되는 AWS Lambda와 Key-Value 저장에 특화된 Amazon DynamoDB를 함께 사용해 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "새로운 서비스",
      "API Gateway",
      "예측 불가능한 요청 패턴",
      "키-값 데이터",
      "백엔드 데이터베이스"
    ],
    "Terms": [
      "AWS Fargate",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon EC2 Auto Scaling",
      "MySQL-compatible Amazon Aurora"
    ],
    "SelectA": "AWS Fargate",
    "SelectA_Commentary": "컨테이너 기반 소프트웨어 구동에 적합하나, 서버리스만큼 빠른 스케일 아웃이 아니며 키-값 데이터 저장에도 추가 구성이 필요합니다.",
    "SelectB": "AWS Lambda",
    "SelectB_Commentary": "서버리스로 요청 수에 따라 자동으로 확장되며, 0건에서 초당 수백 건까지 처리를 유연하게 대응할 수 있습니다.",
    "SelectC": "Amazon DynamoDB",
    "SelectC_Commentary": "조정 가능한 용량 모드, 키-값 쿼리에 최적화된 NoSQL 데이터베이스로, 현재 1GB 미만 데이터와 예측 불가능한 증가량을 처리하기에 적합합니다.",
    "SelectD": "Amazon EC2 Auto Scaling",
    "SelectD_Commentary": "EC2 인스턴스 확장은 가능하나 관리 부담이 크고, 0건에서 급격한 증가에 대한 대응력이 Lambda 대비 제한적입니다.",
    "SelectE": "MySQL-compatible Amazon Aurora",
    "SelectE_Commentary": "관계형 데이터베이스이며 키-값 요청 처리에 대해 DynamoDB만큼 단순하고 확장성 높은 해결책은 아닙니다.",
    "Question_Description_recommedations": [
      "Q10",
      "Q207",
      "Q25",
      "Q354",
      "Q344"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q869",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q785",
      "Q194",
      "Q351"
    ],
    "SelectC_recommedations": [
      "Q768",
      "Q845",
      "Q78"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q584",
      "Q244"
    ],
    "SelectE_recommedations": [
      "Q824",
      "Q843",
      "Q601"
    ]
  },
  {
    "Question_Number": "Q638",
    "Question_Description": "한 회사가 전 세계에 있는 직원들과 연구 데이터를 수집하고 공유하려고 합니다. 이 회사는 Amazon S3 버킷에 데이터를 수집하고 AWS Cloud에서 처리할 계획입니다. 그리고 회사 직원들에게 해당 데이터를 공유해야 합니다. 이때 보안을 보장하면서 운영 오버헤드를 최소화할 수 있는 AWS 기반 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125574-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 직원들에게 보안이 적용된 방식으로 간편하게 Amazon S3 데이터를 제공하고자 할 때, 어떤 방식이 가장 운영 오버헤드가 적으면서도 안전한지 묻는 것입니다. 접근 제어와 인증 관리를 쉽게 할 수 있으면서 외부와의 안전한 데이터 전송이 가능한지 여부가 핵심 포인트입니다. 최종적으로 AWS Transfer Family를 이용한 SFTP 접근 방식이 독립적인 사용자 관리와 보안 통신을 지원하고 운영 부담을 줄일 수 있는 적합한 해법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "보안 솔루션",
      "운영 오버헤드 최소화",
      "데이터 공유",
      "직원 접근"
    ],
    "Terms": [
      "AWS Lambda",
      "S3 presigned URL",
      "IAM user",
      "IAM policy",
      "S3 File Gateway",
      "AWS Transfer Family",
      "SFTP",
      "AWS Secrets Manager",
      "Custom Identity Provider"
    ],
    "SelectA": "AWS Lambda 함수를 사용하여 S3 presigned URL을 생성하고, 직원들에게 해당 URL을 사용하도록 안내합니다.",
    "SelectA_Commentary": "단일 URL 생성 프로세스는 간단하지만, 많은 사용자가 있을 경우 URL 관리가 번거롭습니다. 대규모 조직에서 일일이 링크를 생성·배포하는 것은 운영 오버헤드가 커집니다.",
    "SelectB": "각 직원별로 IAM user를 생성하고, 각 사용자에게 S3 액세스를 허용하는 IAM policy를 생성합니다. 그리고 직원들에게 AWS Management Console을 사용하도록 안내합니다.",
    "SelectB_Commentary": "사용자별 IAM user와 policy 관리는 유연하지만 직원 규모가 커지면 계정 및 정책 관리는 복잡해집니다. 또한 IAM 자격 증명 관리를 책임져야 하므로 운영 부담이 높아집니다.",
    "SelectC": "S3 File Gateway를 생성하고, 업로드용 공유와 다운로드용 공유를 생성합니다. 직원들이 로컬 컴퓨터에서 S3 File Gateway에 공유를 마운트하여 사용하도록 허용합니다.",
    "SelectC_Commentary": "S3 File Gateway는 온프레미스와 S3를 연동하기에 유용하지만, 게이트웨이 어플라이언스 설정과 유지가 필요해 추가 구성 요소가 늘어나고 운영 복잡도가 커질 수 있습니다.",
    "SelectD": "AWS Transfer Family SFTP 엔드포인트를 구성하고, Custom Identity Provider 옵션을 선택합니다. AWS Secrets Manager로 사용자 자격 증명을 관리하고, 직원들에게 Transfer Family를 사용하도록 안내합니다.",
    "SelectD_Commentary": "AWS Transfer Family를 통해 SFTP를 간편하게 구성하고, 자격 증명을 안전하게 통합 관리할 수 있습니다. 운영 오버헤드를 줄이면서도 데이터 전송이 보안적으로 안전하고 효율적입니다.",
    "Question_Description_recommedations": [
      "Q862",
      "Q412",
      "Q109",
      "Q270",
      "Q696"
    ],
    "SelectA_recommedations": [
      "Q289",
      "Q403",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q982",
      "Q403",
      "Q780"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q965",
      "Q106"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q740",
      "Q832"
    ]
  },
  {
    "Question_Number": "Q639",
    "Question_Description": "한 회사에서 새로운 가구 재고 애플리케이션을 구축 중입니다. 해당 애플리케이션은 여러 가용 영역(Availability Zones)에 걸쳐 배포된 Amazon EC2 인스턴스 집합에서 실행되며, 이 인스턴스를 VPC 내 Application Load Balancer(ALB)가 앞단에서 트래픽을 분산 처리하고 있습니다. 솔루션스 아키텍트가 관찰한 바에 따르면, 들어오는 트래픽이 특정 EC2 인스턴스에 집중되어 일부 요청이 지연되는 상황이 발생하고 있습니다. 이 문제를 해결하기 위해 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125575-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB 뒤에 있는 다수의 EC2 인스턴스들 중 특정 인스턴스에 트래픽이 쏠려 지연이 발생하는 상황입니다. 가장 흔한 원인은 session affinity(sticky sessions)가 활성화되어 기존 사용자 요청이 동일 인스턴스에 고정되는 것입니다. Sticky sessions를 비활성화하면 ALB가 들어오는 요청을 각 인스턴스에 균등하게 분산할 수 있어 지연을 해소할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "가구 재고 애플리케이션",
      "트래픽 집중",
      "지연 발생",
      "Application Load Balancer(ALB)",
      "sticky sessions"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Network Load Balancer(NLB)",
      "Availability Zone",
      "session affinity(sticky sessions)",
      "health check",
      "target group"
    ],
    "SelectA": "ALB에서 session affinity(sticky sessions)를 비활성화합니다.",
    "SelectA_Commentary": "sticky sessions를 끄면 각 요청이 균등하게 분산되어 특정 인스턴스에 과부하가 걸리는 상황을 완화할 수 있습니다.",
    "SelectB": "ALB를 Network Load Balancer로 교체합니다.",
    "SelectB_Commentary": "NLB는 TCP/Layer4 기반의 로드 밸런싱을 제공하지만, HTTP/Layer7 로드 밸런싱이 필요한 애플리케이션에는 적합하지 않을 수 있으며 트래픽 집중 문제 해결과 직결되지 않습니다.",
    "SelectC": "가용 영역별로 EC2 인스턴스 수를 늘립니다.",
    "SelectC_Commentary": "인스턴스를 늘리는 것 자체가 트래픽 분산 문제의 근본적 해결책이 되지 않습니다. 트래픽이 특정 인스턴스에만 묶이는 현상이 계속된다면 지연은 여전합니다.",
    "SelectD": "ALB 타깃 그룹의 health check 빈도를 조정합니다.",
    "SelectD_Commentary": "Health check 빈도를 변경해도 근본적으로 트래픽 분산이 해소되지 않을 수 있습니다. 인스턴스가 정상 판정을 받더라도 session affinity가 활성화되어 있으면 여전히 한 인스턴스에 집중될 가능성이 큽니다.",
    "Question_Description_recommedations": [
      "Q246",
      "Q174",
      "Q5",
      "Q729",
      "Q275"
    ],
    "SelectA_recommedations": [
      "Q589",
      "Q8",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q405",
      "Q174"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectD_recommedations": [
      "Q7",
      "Q967",
      "Q187"
    ]
  },
  {
    "Question_Number": "Q640",
    "Question_Description": "한 회사는 AWS Lambda 함수를 사용하여 Amazon S3에서 파일을 다운로드하고 AWS Key Management Service(AWS KMS) 키로 암호화된 파일을 복호화하는 애플리케이션 워크플로를 운영하고 있습니다. 솔루션스 아키텍트는 필수 권한이 제대로 설정되도록 하는 솔루션을 설계해야 합니다. 다음 중 어떤 조합을 통해 이를 달성할 수 있습니까? (2개를 선택하세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125579-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda 함수가 S3에 있는 암호화된 파일을 정상적으로 복호화하도록 올바른 AWS KMS 권한 설정을 이해하는지 묻습니다. Lambda의 IAM 역할이 KMS key policy에 의해 복호화 권한을 부여받아야 하며, 리소스 정책이 아닌 Lambda 실행 역할이 주체(Principal)로 지정되어야 합니다. 이로써 Lambda 함수를 사용한 보안 구성을 올바르게 설정할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Lambda 함수",
      "AWS KMS",
      "권한 설정",
      "KMS 키 정책",
      "S3 파일 복호화"
    ],
    "Terms": [
      "AWS Lambda",
      "AWS Key Management Service(AWS KMS)",
      "KMS key policy",
      "IAM role",
      "Lambda resource policy"
    ],
    "SelectA": "Lambda 함수의 리소스 정책에 kms:decrypt 권한을 부여합니다.",
    "SelectA_Commentary": "Lambda 함수의 리소스 정책 자체에 kms:decrypt를 직접 부여하는 것은 일반적으로 지원되지 않습니다. 주체로 IAM 역할이 필요해서 적절하지 않습니다.",
    "SelectB": "KMS 키의 정책에서 Lambda IAM 역할에 대해 decrypt 권한을 부여합니다.",
    "SelectB_Commentary": "Lambda가 KMS 키로 암호화된 파일을 복호화하려면, KMS 키 정책에서 Lambda 실행 역할을 주체로 지정해 decrypt 권한을 부여해야 합니다. 정답 중 하나입니다.",
    "SelectC": "KMS 키의 정책에서 Lambda 리소스 정책에 대해 decrypt 권한을 부여합니다.",
    "SelectC_Commentary": "Lambda 실행 역할이 아닌 리소스 정책을 주체로 설정하는 것은 불가능합니다. 다른 리소스 정책을 주체로 지정할 수 없으므로 오답입니다.",
    "SelectD": "kms:decrypt 권한을 포함하는 새 IAM 정책을 생성하여 Lambda 함수에 연결합니다.",
    "SelectD_Commentary": "암호화 키 이용 권한은 키 정책에서 직접 허용되어야 하며, Lambda의 IAM 역할에 단순 부착만으로는 충분치 않을 수 있으므로 오답입니다.",
    "SelectE": "kms:decrypt 권한을 가진 새 IAM 역할을 생성하고 이를 Lambda 함수의 실행 역할로 연결합니다.",
    "SelectE_Commentary": "Lambda 실행 역할을 새로 구성해 kms:decrypt를 부여하고, KMS 키 정책에도 동일 역할을 주체로 지정하면 정상 동작합니다. 정답 중 하나입니다.",
    "Question_Description_recommedations": [
      "Q550",
      "Q916",
      "Q1009",
      "Q681",
      "Q793"
    ],
    "SelectA_recommedations": [
      "Q550",
      "Q936",
      "Q640"
    ],
    "SelectB_recommedations": [
      "Q550",
      "Q916",
      "Q640"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q916",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q640",
      "Q916"
    ],
    "SelectE_recommedations": [
      "Q550",
      "Q640",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q641",
    "Question_Description": "한 회사는 비용 검토를 위해 AWS 비용을 모니터링하려고 합니다. 클라우드 운영 팀은 AWS Organizations 관리 계정에서 모든 멤버 계정의 AWS Cost and Usage Reports를 조회하기 위한 아키텍처를 설계하고 있습니다. 팀은 한 달에 한 번 이 쿼리를 실행하고 자세한 비용 분석을 제공해야 합니다. 이 요구사항을 가장 확장 가능하고 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125580-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Organizations 환경에서 월별 Cost and Usage Reports를 효율적으로 분석하는 방법을 묻습니다. Amazon S3와 Amazon Athena를 활용하면 서버리스로 간편하고, 사용한 만큼만 비용 지불하여 규모 확장에도 유리합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "AWS 비용 모니터링",
      "Cost and Usage Reports",
      "분석",
      "확장 가능",
      "비용 효율"
    ],
    "Terms": [
      "AWS Organizations Management Account",
      "AWS Cost and Usage Reports",
      "Amazon S3",
      "Amazon Athena",
      "Amazon Kinesis",
      "Amazon EMR",
      "Amazon Redshift",
      "Amazon QuickSight"
    ],
    "SelectA": "관리 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon Kinesis로 전송합니다. 분석에는 Amazon EMR을 사용합니다.",
    "SelectA_Commentary": "Kinesis와 EMR은 스트리밍 및 대규모 데이터 처리에 적합하지만, 월간 보고서 분석에는 구성이 복잡하고 비용 부담이 큽니다.",
    "SelectB": "관리 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon S3로 전송합니다. 분석에는 Amazon Athena를 사용합니다.",
    "SelectB_Commentary": "S3와 Athena는 사용한 만큼만 비용을 지불하는 서버리스 구조로 필요할 때만 쿼리하며, 관리 오버헤드가 낮고 비용 효율적입니다.",
    "SelectC": "멤버 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon S3로 전송합니다. 분석에는 Amazon Redshift를 사용합니다.",
    "SelectC_Commentary": "Redshift는 대규모 데이터 웨어하우스에 적합하지만, 월 1회 분석용으로는 과도한 오버헤드와 추가 비용이 발생합니다.",
    "SelectD": "멤버 계정에서 Cost and Usage Reports를 활성화합니다. 보고서를 Amazon Kinesis로 전송합니다. 분석에는 Amazon QuickSight를 사용합니다.",
    "SelectD_Commentary": "실시간 시각화 흐름에는 유용할 수 있지만, 멤버 계정마다 설정해야 하고 운영 구성이 복잡해지는 단점이 있습니다.",
    "Question_Description_recommedations": [
      "Q459",
      "Q455",
      "Q880",
      "Q559",
      "Q284"
    ],
    "SelectA_recommedations": [
      "Q641",
      "Q591",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q285",
      "Q993"
    ],
    "SelectC_recommedations": [
      "Q31",
      "Q943",
      "Q641"
    ],
    "SelectD_recommedations": [
      "Q641",
      "Q485",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q642",
    "Question_Description": "한 회사가 AWS 클라우드의 Auto Scaling 그룹에 속해 있는 Amazon EC2 인스턴스에서 게이밍 애플리케이션을 실행하려고 합니다. 애플리케이션은 UDP 패킷을 사용하여 데이터를 전송합니다. 회사는 트래픽 증가 및 감소에 따라 애플리케이션이 자동으로 확장 및 축소되도록 보장하고 싶어합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "UDP 트래픽을 효율적으로 분산하고 확장하기 위해서는 Network Load Balancer 활용이 필수적입니다. ALB는 HTTP/HTTPS(레이어 7) 트래픽에 적합하고, NAT 인스턴스나 Route 53 가중 라우팅만으로는 Auto Scaling과 연동된 UDP 트래픽 처리가 제한적입니다. 따라서 NLB를 Auto Scaling 그룹과 연결해 트래픽 증가 시 자동 확장을 지원하도록 설계해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "게이밍 애플리케이션",
      "UDP 패킷",
      "Auto Scaling",
      "Network Load Balancer",
      "확장성"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Network Load Balancer",
      "Application Load Balancer",
      "Amazon Route 53",
      "NAT instance",
      "포트 포워딩"
    ],
    "SelectA": "Auto Scaling 그룹에 Network Load Balancer를 연결합니다.",
    "SelectA_Commentary": "UDP 트래픽을 처리하는 데 적합하며 Auto Scaling과 연동해 트래픽 증가에 따라 자동 확장과 축소를 지원하므로 올바른 솔루션입니다.",
    "SelectB": "Auto Scaling 그룹에 Application Load Balancer를 연결합니다.",
    "SelectB_Commentary": "Application Load Balancer는 HTTP/HTTPS(레이어 7) 전용으로, UDP 트래픽을 효율적으로 처리할 수 없으므로 적합하지 않습니다.",
    "SelectC": "가중 라우팅 정책을 사용하는 Amazon Route 53 레코드 세트를 배포합니다.",
    "SelectC_Commentary": "DNS 라우팅만으로는 UDP 트래픽 부하 분산 및 Auto Scaling 그룹 연동이 어려워 적합한 해결책이 되지 못합니다.",
    "SelectD": "포트 포워딩이 구성된 NAT 인스턴스를 배포해 Auto Scaling 그룹의 EC2 인스턴스로 트래픽을 전달합니다.",
    "SelectD_Commentary": "NAT 인스턴스는 내부 인스턴스의 인터넷 액세스를 위한 것으로, 외부 UDP 트래픽 수신 및 Auto Scaling과의 연동에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q378",
      "Q595",
      "Q581",
      "Q210",
      "Q29"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q660",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q174",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q545",
      "Q869"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q230",
      "Q708"
    ]
  },
  {
    "Question_Number": "Q643",
    "Question_Description": "한 회사가 여러 브랜드를 위해 AWS에서 여러 웹사이트를 운영합니다. 각 웹사이트는 매일 수십 기가바이트의 웹 트래픽 로그를 생성합니다. 한 Solutions Architect는 회사의 모든 웹사이트에서 발생하는 트래픽 패턴을 개발자가 분석할 수 있도록 확장 가능한 솔루션을 설계해야 합니다. 이 분석은 최소 몇 달 동안 주 1회 온디맨드로 이루어집니다. 솔루션은 표준 SQL 쿼리를 지원해야 하며, 비용 효율적이어야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125581-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon S3에 로그를 저장하고 Amazon Athena로 분석하면 필요한 시점에만 서버리스 방식으로 표준 SQL 질의를 수행하므로 대규모 로그에도 비용 효율적이며 확장성이 뛰어납니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "웹 트래픽 로그",
      "비용 효율",
      "확장성",
      "SQL 쿼리",
      "분석 솔루션"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Athena",
      "Amazon RDS",
      "Amazon OpenSearch Service",
      "Amazon EMR"
    ],
    "SelectA": "로그를 Amazon S3에 저장하고 Amazon Athena를 사용하여 분석합니다.",
    "SelectA_Commentary": "서버리스 환경에서 표준 SQL 쿼리를 활용해 손쉽게 분석할 수 있고, 사용한 만큼만 비용을 지불해 가장 경제적입니다.",
    "SelectB": "로그를 Amazon RDS에 저장하고 DB 클라이언트를 사용하여 분석합니다.",
    "SelectB_Commentary": "매일 증가하는 대용량 로그를 위해 RDS를 확장하려면 운영 비용과 관리 부담이 크게 증가합니다.",
    "SelectC": "로그를 Amazon OpenSearch Service에 저장하고 OpenSearch Service로 분석합니다.",
    "SelectC_Commentary": "OpenSearch는 검색과 분석에 특화되어 있지만 표준 SQL 쿼리를 직접 지원하지 않아 요구사항에 부합하지 않습니다.",
    "SelectD": "로그를 Amazon EMR 클러스터에 저장하고 SQL 기반 분석을 지원하는 오픈소스 프레임워크를 사용합니다.",
    "SelectD_Commentary": "EMR은 일시적인 컴퓨팅 작업에 강점이 있지만, 로그 저장과 인프라 운영에 추가 비용과 관리 리소스가 요구됩니다.",
    "Question_Description_recommedations": [
      "Q872",
      "Q124",
      "Q63",
      "Q22",
      "Q546"
    ],
    "SelectA_recommedations": [
      "Q1003",
      "Q285",
      "Q911"
    ],
    "SelectB_recommedations": [
      "Q959",
      "Q152",
      "Q574"
    ],
    "SelectC_recommedations": [
      "Q486",
      "Q300",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q652",
      "Q167",
      "Q449"
    ]
  },
  {
    "Question_Number": "Q644",
    "Question_Description": "한 국제 기업은 회사가 운영 중인 각 국가에 대해 서브도메인을 운영하고 있습니다. 서브도메인의 형태는 example.com, country1.example.com, country2.example.com과 같습니다. 이 회사의 워크로드는 Application Load Balancer 뒤에서 동작합니다. 회사는 전송 중인 웹사이트 데이터를 암호화(HTTPS)하고자 합니다. 이를 만족하기 위해 어떤 단계 조합을 수행해야 합니까? (2개를 선택하세요.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125582-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다수의 국가별 서브도메인을 포함하는 웹사이트 트래픽을 HTTPS로 암호화하기 위해, ACM을 이용해 apex 도메인과 와일드카드 도메인을 모두 커버하는 퍼블릭 인증서를 요청하고, DNS 레코드를 통해 도메인 검증을 수행하는 과정이 핵심입니다. 퍼블릭 인증서를 사용해야 외부 사용자를 대상으로 하는 HTTPS 통신을 보장하며, DNS 검증은 안정적이고 편리한 도메인 소유권 확인 방식입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "암호화",
      "HTTPS",
      "TLS",
      "서브도메인",
      "와일드카드 인증서",
      "도메인 소유권 검증",
      "DNS 검증",
      "Amazon Certificate Manager",
      "Application Load Balancer"
    ],
    "Terms": [
      "AWS Certificate Manager (ACM)",
      "Public Certificate",
      "Private Certificate",
      "Wildcard Certificate",
      "Domain Ownership Validation",
      "DNS Validation",
      "Application Load Balancer",
      "TLS/SSL",
      "Apex Domain",
      "Subdomain"
    ],
    "SelectA": "AWS Certificate Manager (ACM) 콘솔에서 apex top 도메인(example.com)에 대한 퍼블릭 인증서와 *.example.com 와일드카드 인증서를 요청합니다.",
    "SelectA_Commentary": "외부 사용자 대상 HTTPS를 위해 퍼블릭 인증서를 발급받고, 모든 서브도메인을 커버할 수 있도록 와일드카드 인증서를 함께 발급받아야 하므로 적절한 선택입니다.",
    "SelectB": "AWS Certificate Manager (ACM) 콘솔에서 apex top 도메인(example.com)에 대한 프라이빗 인증서와 *.example.com 와일드카드 인증서를 요청합니다.",
    "SelectB_Commentary": "프라이빗 인증서는 내부용으로 사용하는 경우가 많아 공개 웹사이트 암호화에는 적합하지 않습니다.",
    "SelectC": "AWS Certificate Manager (ACM) 콘솔에서 apex top 도메인(example.com)에 대한 퍼블릭 및 프라이빗 인증서를 모두 요청합니다.",
    "SelectC_Commentary": "와일드카드 부분이 없어 모든 서브도메인을 커버하지 못하므로 요구사항을 충족할 수 없습니다.",
    "SelectD": "이메일 주소로 도메인 소유권을 검증합니다. 필요한 DNS 레코드를 DNS 제공자에 추가하여 DNS 검증으로 전환합니다.",
    "SelectD_Commentary": "이메일 검증 후 DNS 검증으로 전환하는 방법이지만, 문제에서 강조하는 효율적이고 명확한 도메인 검증 방식으로는 다소 복잡한 절차가 될 수 있습니다.",
    "SelectE": "DNS 제공자에 필요한 DNS 레코드를 추가하여 도메인 소유권을 검증합니다.",
    "SelectE_Commentary": "DNS 검증은 가장 간단하고 안정적이며, 별도의 이메일 발송 절차 없이 손쉽게 소유권을 확인할 수 있어 요구사항을 충족하는 적절한 방식입니다.",
    "Question_Description_recommedations": [
      "Q625",
      "Q608",
      "Q170",
      "Q169",
      "Q60"
    ],
    "SelectA_recommedations": [
      "Q577",
      "Q855",
      "Q233"
    ],
    "SelectB_recommedations": [
      "Q577",
      "Q855",
      "Q233"
    ],
    "SelectC_recommedations": [
      "Q577",
      "Q233",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q803",
      "Q538",
      "Q592"
    ],
    "SelectE_recommedations": [
      "Q803",
      "Q538",
      "Q592"
    ]
  },
  {
    "Question_Number": "Q645",
    "Question_Description": "한 회사는 규제 및 컴플라이언스 요구사항 때문에 온프레미스 key manager에서 암호화 키를 사용해야 합니다. 이 key manager는 AWS Cloud 바깥에 있으며, 회사는 다양한 벤더의 외부 key manager들을 지원하고자 합니다. 또한 회사는 AWS Cloud 밖에 보관되는 암호화 키를 사용하여 암호화와 복호화를 관리하기 원합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125583-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 클라우드 외부에 있는 암호화 키를 유지하며, 다양한 벤더에서 제공하는 외부 key manager를 사용해야 하는 상황에 대한 솔루션을 묻습니다. 운영 오버헤드를 최소화하면서 필요한 규제 및 컴플라이언스를 준수하려면 AWS KMS external key store를 사용해 외부 key manager를 활용하는 방법이 적합합니다. CloudHSM 기반 key store나 기본 KMS 관리형 key store는 결국 AWS 내부에서 키를 관리하게 되어 요구사항을 충족하기 어렵습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "온프레미스 key manager",
      "외부 key manager",
      "암호화 키",
      "운영 오버헤드 최소화",
      "AWS KMS external key store"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "AWS CloudHSM",
      "KMS external key store",
      "custom key store",
      "외부 키 관리자"
    ],
    "SelectA": "AWS CloudHSM key store를 사용하고 CloudHSM 클러스터를 백엔드로 구성합니다.",
    "SelectA_Commentary": "이는 키를 AWS 내의 CloudHSM에 저장하므로 회사의 요구사항(온프레미스에서 키를 관리하고자 함)을 충족하지 못합니다.",
    "SelectB": "AWS Key Management Service (AWS KMS) external key store를 사용하고 외부 key manager를 백엔드로 구성합니다.",
    "SelectB_Commentary": "키가 AWS 클라우드 밖에서 유지되고, 여러 벤더의 외부 key manager를 지원하며, 운영 오버헤드를 낮게 유지할 수 있는 정답 솔루션입니다.",
    "SelectC": "기본 AWS Key Management Service (AWS KMS) 관리형 key store를 사용합니다.",
    "SelectC_Commentary": "이 방식은 KMS가 AWS 내부에서 직접 키를 관리하므로 온프레미스 키 유지 요구사항에 부합하지 않습니다.",
    "SelectD": "AWS CloudHSM 클러스터를 백엔드로 하는 custom key store를 사용합니다.",
    "SelectD_Commentary": "custom key store 역시 CloudHSM 기반이므로 키가 여전히 AWS 내부에 저장되어, 요구사항을 충족하지 않습니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q970",
      "Q898",
      "Q529",
      "Q740"
    ],
    "SelectA_recommedations": [
      "Q645",
      "Q740",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q740",
      "Q645",
      "Q233"
    ]
  },
  {
    "Question_Number": "Q646",
    "Question_Description": "한 솔루션스 아키텍트가 AWS Cloud에서 고성능 컴퓨팅(HPC) 워크로드를 호스팅해야 합니다. 이 워크로드는 수백 대의 Amazon EC2 인스턴스에서 실행되며, 대규모 데이터셋을 분산 처리하기 위해 공유 파일 시스템에 대한 병렬 액세스가 필요합니다. 데이터셋은 여러 인스턴스에서 동시에 액세스됩니다. 워크로드는 1ms 이하의 지연 시간으로 액세스해야 합니다. 처리가 완료된 후 엔지니어들이 수동 후처리를 위해 데이터셋에 액세스해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125584-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HPC 환경에서 여러 인스턴스가 대규모 데이터셋을 동시에 액세스할 때 필요한 초저지연, 높은 처리량의 공유 파일 시스템을 구성하는 방법을 묻습니다. Amazon FSx for Lustre는 HPC 워크로드에 최적화되어 1ms 이하의 지연 시간과 병렬 I/O를 제공하므로 파일 기반의 빅데이터 및 시뮬레이션에 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2"
    ],
    "Keywords": [
      "고성능 컴퓨팅",
      "공유 파일 시스템",
      "병렬 액세스",
      "1ms 이하 지연",
      "대규모 데이터셋"
    ],
    "Terms": [
      "Amazon EC2",
      "HPC(High Performance Computing)",
      "Amazon EFS",
      "Amazon S3",
      "Amazon FSx for Lustre",
      "AWS Resource Access Manager"
    ],
    "SelectA": "Amazon Elastic File System(Amazon EFS)를 공유 파일 시스템으로 사용하고, Amazon EFS에서 데이터셋을 액세스합니다.",
    "SelectA_Commentary": "Amazon EFS는 유연성이 높지만 HPC에 필요한 초저지연 및 대규모 병렬 처리 요구사항을 충족하기에는 성능이 충분하지 않을 수 있습니다.",
    "SelectB": "Amazon S3 버킷을 마운트하여 공유 파일 시스템으로 사용하고, S3 버킷에서 직접 후처리를 수행합니다.",
    "SelectB_Commentary": "S3는 객체 스토리지로서 대규모 병렬 처리 시 즉시 접근성을 제공하기에 적합하지 않으며, 파일 시스템 수준의 낮은 지연을 보장하기 어렵습니다.",
    "SelectC": "Amazon FSx for Lustre를 공유 파일 시스템으로 사용합니다. 후처리를 위해 Amazon S3 버킷과 연결합니다.",
    "SelectC_Commentary": "Amazon FSx for Lustre는 HPC에 최적화된 공유 파일 시스템으로 1ms 이하의 지연과 병렬 처리를 지원하며, S3와의 연동을 통해 후처리에도 용이하므로 요구사항을 모두 충족합니다.",
    "SelectD": "AWS Resource Access Manager로 Amazon S3 버킷을 공유하도록 구성하고, 모든 인스턴스에서 이를 마운트하여 처리 및 후처리를 수행합니다.",
    "SelectD_Commentary": "S3 버킷을 Resource Access Manager로 공유하더라도 S3는 파일 시스템이 아니므로 필요로 하는 초저지연 및 병렬 파일 I/O 성능을 제공할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q857",
      "Q795",
      "Q162",
      "Q910",
      "Q369"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q695",
      "Q6"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q155"
    ],
    "SelectC_recommedations": [
      "Q407",
      "Q501",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q173",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q647",
    "Question_Description": "한 게임 회사가 Voice over IP 기능을 갖춘 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 전 세계 사용자에게 트래픽을 제공해야 하며, 여러 AWS Region 간 자동 페일오버를 통해 고가용성을 유지해야 합니다. 또한 회사는 사용자 디바이스의 IP 주소 캐싱에 의존하지 않고 지연 시간을 최소화하려고 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계에 분산된 사용자에게 VoIP 트래픽을 빠르고 안정적으로 전달하면서, 다중 AWS Region간 고가용성 및 자동 페일오버를 구현해야 하는 상황입니다. DNS 캐싱에 의존하지 않으려면 전역 가속 기능이 필요하며, 특히 비-HTTP(UDP) 기반 트래픽에 적합한 AWS Global Accelerator가 최적의 선택입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Voice over IP",
      "전 세계 사용자",
      "고가용성",
      "AWS Region 간 자동 페일오버",
      "지연 시간 최소화",
      "IP 주소 캐싱",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Health Checks",
      "Amazon Route 53",
      "Geolocation Routing Policy",
      "Amazon CloudFront",
      "Origins",
      "Application Load Balancer",
      "Path-based Routing",
      "IP Address Caching",
      "Voice over IP"
    ],
    "SelectA": "AWS Global Accelerator를 사용하고 Health Checks를 구성합니다.",
    "SelectA_Commentary": "Global Accelerator는 고정 IP를 제공하고, 네트워크 레벨 전송으로 VoIP 트래픽에 적합합니다. Health Check를 통해 Region 장애 시에도 자동으로 정상 리전으로 라우팅이 가능해 지연 시간을 최소화하고 고가용성을 보장합니다.",
    "SelectB": "Amazon Route 53의 지리적 라우팅(Geolocation Routing Policy)을 사용합니다.",
    "SelectB_Commentary": "DNS 기반 라우팅은 사용자 디바이스의 IP 주소 캐싱을 피하기 어렵고, 실시간으로 빠른 페일오버를 보장하기가 어렵습니다.",
    "SelectC": "여러 오리진을 포함하는 Amazon CloudFront 배포를 생성합니다.",
    "SelectC_Commentary": "CloudFront는 주로 HTTP/HTTPS 콘텐츠 전송에 최적화되어 있어 VoIP 트래픽의 실시간 전송 및 자동 페일오버 요구사항에 부적합합니다.",
    "SelectD": "Path-based 라우팅을 사용하는 Application Load Balancer를 생성합니다.",
    "SelectD_Commentary": "ALB는 단일 리전 내 트래픽 분산에 초점을 두고 있으므로, 다중 Region간 자동 페일오버나 낮은 지연 시간을 보장하기에는 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q700",
      "Q408",
      "Q68",
      "Q513",
      "Q487"
    ],
    "SelectA_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q264",
      "Q408"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q149"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q405",
      "Q357"
    ]
  },
  {
    "Question_Number": "Q648",
    "Question_Description": "한 기상 예측 회사가 수백 기가바이트의 데이터를 서브 밀리초 지연 시간으로 처리해야 합니다. 이 회사는 자체 데이터 센터에 고성능 컴퓨팅(HPC) 환경을 보유하고 있으며, 예측 능력을 확장하고 싶어 합니다. 솔루션스 아키텍트는 대규모 연속 처리량을 처리할 수 있는 고가용성 클라우드 스토리지 솔루션을 구상해야 합니다. 솔루션에 저장된 파일은 수천 개의 컴퓨팅 인스턴스가 동시에 접근하여 전체 데이터 세트를 처리할 수 있도록 지원해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125586-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HPC 환경에서 서브 밀리초 지연 시간과 강력한 처리량을 보장해야 하는 대규모 스토리지 솔루션을 찾는 것입니다. FSx for Lustre persistent 파일 시스템은 HPC 워크로드에서 필요로 하는 데이터 영속성과 고성능을 효과적으로 제공하므로 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "고성능 컴퓨팅(HPC)",
      "서브 밀리초 지연 시간",
      "대규모 처리량",
      "Amazon FSx for Lustre",
      "데이터 집합 동시 액세스"
    ],
    "Terms": [
      "Amazon FSx for Lustre scratch file systems",
      "Amazon FSx for Lustre persistent file systems",
      "Amazon Elastic File System (Amazon EFS)",
      "Bursting Throughput mode",
      "Provisioned Throughput mode",
      "고성능 컴퓨팅(HPC)"
    ],
    "SelectA": "Amazon FSx for Lustre scratch file systems를 사용합니다.",
    "SelectA_Commentary": "Scratch 유형은 임시 스토리지로 설계되어 영구 보관이 어렵습니다. 데이터 영속성이 필요한 HPC 워크로드에는 적합하지 않습니다.",
    "SelectB": "Amazon FSx for Lustre persistent file systems를 사용합니다.",
    "SelectB_Commentary": "FSx for Lustre의 영구 버전은 HPC 환경에서 요구하는 고성능과 전문적인 파일 시스템 기능을 제공하며 데이터 영속성을 보장하므로 정답입니다.",
    "SelectC": "Amazon EFS를 Bursting Throughput 모드로 사용합니다.",
    "SelectC_Commentary": "EFS의 순간적 버스팅은 일시적으로 처리량을 높일 수 있지만, HPC처럼 지속적으로 높은 처리량이 필요한 경우에 적합하지 않습니다.",
    "SelectD": "Amazon EFS를 Provisioned Throughput 모드로 사용합니다.",
    "SelectD_Commentary": "Provisioned Throughput은 일정 처리량을 확보할 수 있지만 HPC가 요구하는 대규모 연속 처리량과 서브 밀리초 지연 환경에는 부족할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q915",
      "Q506",
      "Q132",
      "Q622",
      "Q888"
    ],
    "SelectA_recommedations": [
      "Q407",
      "Q620",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q407",
      "Q620",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q704",
      "Q620",
      "Q352"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q299",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q649",
    "Question_Description": "한 ecommerce 회사가 온프레미스에서 PostgreSQL 데이터베이스를 운영 중이며, 데이터는 높은 IOPS를 제공하는 Amazon EBS 블록 스토리지를 사용하고 있습니다. 일일 최대 I/O 트랜잭션은 초당 15,000 IOPS를 넘지 않습니다. 회사는 Amazon RDS for PostgreSQL로 마이그레이션하고, 디스크 스토리지 용량과 관계없이 필요한 수준의 디스크 IOPS 성능을 프로비저닝하고자 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125588-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "디스크 용량과 IOPS를 독립적으로 설정하려면 GP3가 적합합니다. GP3는 최대 16,000 IOPS까지 설정 가능하며, GP2 대비 약 20% 저렴해 가장 경제적인 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "15,000 IOPS",
      "독립적 IOPS 설정",
      "비용 효율",
      "General Purpose SSD (gp3)"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Amazon EBS",
      "General Purpose SSD (gp2)",
      "Provisioned IOPS SSD (io1)",
      "General Purpose SSD (gp3)",
      "EBS Magnetic",
      "IOPS"
    ],
    "SelectA": "General Purpose SSD (gp2) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS를 프로비저닝합니다.",
    "SelectA_Commentary": "gp2는 IOPS가 볼륨 크기에 의존하고 비용이 더 높아, 최대 IOPS 설정 시 최적의 비용 효율을 제공하지 못합니다.",
    "SelectB": "Provisioned IOPS SSD (io1) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS를 프로비저닝합니다.",
    "SelectB_Commentary": "io1은 높은 IOPS를 제공하지만 gp3에 비해 비용이 더 크며, 별도의 이점 없이 경제성이 떨어집니다.",
    "SelectC": "General Purpose SSD (gp3) EBS 볼륨 스토리지 유형을 구성하고 15,000 IOPS를 프로비저닝합니다.",
    "SelectC_Commentary": "gp3는 볼륨 크기와 무관하게 필요한 IOPS를 설정할 수 있고, gp2 대비 20% 저렴해 가장 경제적입니다.",
    "SelectD": "EBS Magnetic 볼륨 유형으로 최대 IOPS를 달성합니다.",
    "SelectD_Commentary": "Magnetic 볼륨은 IOPS가 낮고 확장성도 제한적이므로 이 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q425",
      "Q940",
      "Q436",
      "Q579",
      "Q353"
    ],
    "SelectA_recommedations": [
      "Q425",
      "Q841",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q425",
      "Q353",
      "Q307"
    ],
    "SelectC_recommedations": [
      "Q425",
      "Q778",
      "Q353"
    ],
    "SelectD_recommedations": [
      "Q425",
      "Q673",
      "Q867"
    ]
  },
  {
    "Question_Number": "Q650",
    "Question_Description": "한 회사는 온프레미스 Microsoft SQL Server Enterprise Edition 데이터베이스를 AWS로 마이그레이션하려고 합니다. 회사의 온라인 애플리케이션은 이 데이터베이스를 사용해 트랜잭션을 처리합니다. 동시에 데이터 분석 팀은 동일한 프로덕션 데이터베이스로부터 분석 처리용 보고서를 실행합니다. 회사는 가능한 한 관리형 서비스로 이동하여 운영 오버헤드를 줄이고 싶어 합니다. 이러한 요구사항을 만족하면서 운영 오버헤드가 가장 적은 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125589-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Microsoft SQL Server를 AWS로 이전할 때, 트랜잭션 처리와 분석 업무를 동시에 처리하면서 운영 오버헤드를 최소화하는 방안을 묻습니다. 관리형 서비스인 Amazon RDS를 사용하면 직접 인프라를 관리하지 않아도 되며, Read Replica를 통해 분석 쿼리를 분산할 수 있어 운영이 간단해집니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "온프레미스 마이그레이션",
      "Microsoft SQL Server Enterprise Edition",
      "트랜잭션 처리",
      "분석 보고서",
      "관리형 서비스",
      "운영 오버헤드 최소화",
      "Amazon RDS",
      "Read Replicas"
    ],
    "Terms": [
      "Amazon RDS for Microsoft SQL Server",
      "Microsoft SQL Server on Amazon EC2",
      "Always On Read Replicas",
      "Amazon DynamoDB",
      "DynamoDB On-Demand Replicas",
      "Amazon Aurora MySQL",
      "Aurora Read Replicas"
    ],
    "SelectA": "Amazon RDS for Microsoft SQL Server로 마이그레이션합니다. 분석 보고서 용도로 Read Replica를 사용합니다.",
    "SelectA_Commentary": "가장 적은 운영 오버헤드로 SQL Server 환경을 유지할 수 있고, RDS Read Replica를 통해 분석 부하를 분산합니다.",
    "SelectB": "Amazon EC2에서 Microsoft SQL Server를 직접 운영합니다. Always On Read Replica를 사용해 분석을 수행합니다.",
    "SelectB_Commentary": "EC2에 SQL Server를 설치하면 OS 및 DB 인프라를 직접 관리해야 하므로 운영 오버헤드가 더 큽니다.",
    "SelectC": "Amazon DynamoDB로 마이그레이션하고, DynamoDB On-Demand Replica를 사용해 분석 용도로 복제합니다.",
    "SelectC_Commentary": "DynamoDB는 NoSQL 서비스이므로 기존 SQL Server 애플리케이션과 호환성이 떨어집니다.",
    "SelectD": "Amazon Aurora MySQL로 마이그레이션합니다. 분석 보고서 용도로 Aurora Read Replica를 사용합니다.",
    "SelectD_Commentary": "Microsoft SQL Server에서 MySQL로 변경 시 일부 SQL Server 기능이 호환되지 않을 수 있으며 마이그레이션 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q554",
      "Q192",
      "Q229",
      "Q596",
      "Q287"
    ],
    "SelectA_recommedations": [
      "Q247",
      "Q337",
      "Q376"
    ],
    "SelectB_recommedations": [
      "Q287",
      "Q229",
      "Q910"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectD_recommedations": [
      "Q946",
      "Q337",
      "Q247"
    ]
  },
  {
    "Question_Number": "Q651",
    "Question_Description": "한 회사가 Amazon S3 버킷에 대용량 이미지 파일들을 저장하고 있습니다. 이미지는 처음 180일 동안 즉시 액세스가 가능해야 합니다. 그 후 180일 동안은 접근 빈도가 낮으며, 360일 이후부터는 이미지를 아카이빙해야 하지만 요청 시 즉시 사용 가능해야 합니다. 5년이 지난 후에는 감사 담당자만 이미지를 볼 수 있어야 하며, 해당 시점에는 12시간 내에 복원 가능하면 됩니다. 이 과정에서 이미지가 손실되어서는 안 됩니다. 개발자는 처음 180일 동안 S3 Standard를 사용할 예정이며, S3 Lifecycle 규칙을 설정해야 합니다. 어떤 솔루션이 가장 비용 효율적으로 이러한 요구 사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125244-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 오랜 기간 동안 보관해야 하는 대용량 이미지를 S3의 적절한 스토리지 클래스로 전환해 비용을 절감하면서도 즉시 또는 빠른 액세스를 보장해야 하는 상황입니다. 180일 후 빈도 낮은 저장을 위해 높은 내구성과 가용성을 보장하는 S3 Standard-IA가 적합합니다. 360일 후 즉시 읽기에는 S3 Glacier Instant Retrieval이 좋고, 가장 장기 보관이 필요한 5년 후에는 S3 Glacier Deep Archive로 전환해 12시간 내 복원 조건을 만족하면서도 비용을 최소화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "이미지 아카이빙",
      "S3 Lifecycle",
      "즉시 액세스",
      "비용 효율",
      "오랜 보관"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "S3 Glacier Instant Retrieval",
      "S3 Glacier Flexible Retrieval",
      "S3 Glacier Deep Archive"
    ],
    "SelectA": "180일 후 S3 One Zone-Infrequent Access, 360일 후 S3 Glacier Instant Retrieval, 5년 후 S3 Glacier Deep Archive로 전환",
    "SelectA_Commentary": "One Zone-IA는 단일 가용 영역만 사용해 가용성이 낮습니다. 이미지 손실 위험이 커 요구사항을 충족하기 어렵습니다.",
    "SelectB": "180일 후 S3 One Zone-Infrequent Access, 360일 후 S3 Glacier Flexible Retrieval, 5년 후 S3 Glacier Deep Archive로 전환",
    "SelectB_Commentary": "One Zone-IA로 인한 높은 위험성과 Glacier Flexible Retrieval 사용 시 즉시 액세스를 지원하지 않아 요구사항에 부합하지 않습니다.",
    "SelectC": "180일 후 S3 Standard-Infrequent Access, 360일 후 S3 Glacier Instant Retrieval, 5년 후 S3 Glacier Deep Archive로 전환",
    "SelectC_Commentary": "높은 내구성·가용성을 유지하면서 필요 시 즉시 액세스가 가능해 가장 비용 효과적이며, 5년 후 Deep Archive로 이관해 장기 보관 비용도 최소화합니다.",
    "SelectD": "180일 후 S3 Standard-Infrequent Access, 360일 후 S3 Glacier Flexible Retrieval, 5년 후 S3 Glacier Deep Archive로 전환",
    "SelectD_Commentary": "Glacier Flexible Retrieval은 즉시 액세스를 제공하지 않아 360일 이후 즉시 사용 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q415",
      "Q23",
      "Q356",
      "Q498",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q778",
      "Q285",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q778",
      "Q285",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q778",
      "Q606"
    ],
    "SelectD_recommedations": [
      "Q285",
      "Q778",
      "Q606"
    ]
  },
  {
    "Question_Number": "Q652",
    "Question_Description": "한 회사는 매일 6시간 동안 대규모 데이터를 처리하는 작업이 있으며, 작업 중에는 어떤 데이터도 유실되어서는 안 됩니다. 솔루션스 아키텍트는 이 중요한 데이터 워크로드를 지원하기 위해 Amazon EMR 클러스터 구성을 설계하고 있습니다. 어떤 솔루션이 가장 비용 효율적으로 이 요구사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/125591-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 6시간 동안 운영되는 EMR 작업에서 데이터 무손실을 보장하면서 비용을 최소화할 방법을 묻습니다. 필요한 시간에만 클러스터를 구동하는 Transient cluster를 사용하고, 데이터가 저장되는 Core 노드는 On-Demand Instances로 구성해 안전성을 확보하며, Task 노드는 Spot Instances로 구성해 추가 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "EMR 클러스터",
      "비용 최적화",
      "On-Demand Instances",
      "Spot Instances",
      "데이터 무손실",
      "6시간 배치 작업"
    ],
    "Terms": [
      "Amazon EMR",
      "On-Demand Instances",
      "Spot Instances",
      "Transient cluster",
      "Long-running cluster",
      "Primary node",
      "Core nodes",
      "Task nodes"
    ],
    "SelectA": "상시(long-running) 클러스터로 구성하고, Primary 노드와 Core 노드를 On-Demand Instances로, Task 노드는 Spot Instances로 실행합니다.",
    "SelectA_Commentary": "운영 시간 외에도 상시 실행되어 비용이 더 들 수 있습니다. 일시적인 일과에는 적합하지 않습니다.",
    "SelectB": "일시(transient) 클러스터로 구성하고, Primary 노드와 Core 노드를 On-Demand Instances로, Task 노드는 Spot Instances로 실행합니다.",
    "SelectB_Commentary": "필요한 시간에만 클러스터를 구동하여 비용을 절감하고, Core 노드가 On-Demand이므로 데이터 무손실이 보장됩니다. 정답입니다.",
    "SelectC": "일시(transient) 클러스터로 구성하고, Primary 노드를 On-Demand Instance로, Core 노드와 Task 노드를 모두 Spot Instances로 실행합니다.",
    "SelectC_Commentary": "Core 노드를 Spot Instance로 사용하면 중단 시 데이터가 유실될 위험이 있어 조건을 충족하지 못합니다.",
    "SelectD": "상시(long-running) 클러스터로 구성하고, Primary 노드를 On-Demand Instance로, Core 노드와 Task 노드를 Spot Instances로 실행합니다.",
    "SelectD_Commentary": "Core 노드를 Spot Instances로 구성하면 중단 시 데이터 무손실 보장이 어렵고, 상시 실행으로 비용도 높아집니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q728",
      "Q525",
      "Q485",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q424",
      "Q1008"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ]
  },
  {
    "Question_Number": "Q653",
    "Question_Description": "한 회사가 사용자를 비용 센터에 매핑하는 Amazon RDS 데이터베이스를 운영하고 있습니다. 회사는 AWS Organizations에 속한 여러 계정을 보유하고 있습니다. 회사는 조직 내 특정 AWS 계정에서 생성되는 모든 리소스에 태그를 부여해야 합니다. 각 리소스에는 해당 리소스를 생성한 사용자의 비용 센터 ID로 태그를 추가해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126867-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 조직 내 특정 계정에서 생성되는 리소스에 자동으로 비용 센터 ID 태그를 입력해야 하는 시나리오입니다. 즉, 리소스 생성 시점을 포착해 적절한 태그를 부여하는 메커니즘이 필요합니다. EventBridge 룰과 AWS Lambda를 결합하여 AWS CloudTrail 이벤트가 발생할 때마다 Lambda 함수를 실행해 RDS 데이터베이스에서 사용자의 비용 센터 ID를 조회하고, 생성된 리소스에 태그를 자동으로 추가하는 방안이 최적입니다. SCP만으로는 실시간 태그 부여가 어렵거나 생성 자체를 제한할 수 있고, 스케줄 기반 솔루션(C 또는 D)은 즉각적인 태그 적용이 어려우므로 적합하지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon RDS",
      "사용자 비용 센터",
      "AWS Organizations",
      "리소스 태그"
    ],
    "Terms": [
      "Service Control Policy (SCP)",
      "AWS Organizations",
      "Organizational Unit (OU)",
      "AWS Lambda",
      "Amazon EventBridge",
      "AWS CloudTrail",
      "AWS CloudFormation",
      "RDS database",
      "Cost Center Tag"
    ],
    "SelectA": "관리 계정에서 특정 AWS 계정을 새로운 OU로 이동한 뒤, 올바른 비용 센터 태그가 있어야만 리소스를 생성할 수 있도록 SCP를 설정하고 해당 OU에 적용합니다.",
    "SelectA_Commentary": "SCP를 사용하면 리소스 태그 누락 시 생성이 막히지만, 자동으로 태그를 부여해 주지는 않습니다. 사용자가 직접 태그를 입력해야 하므로 요구사항을 완전히 충족하지 못합니다.",
    "SelectB": "AWS Lambda 함수를 생성하여 Lambda 함수가 RDS 데이터베이스에서 해당 비용 센터를 조회한 후 리소스를 태그하도록 합니다. AWS CloudTrail 이벤트에 반응하는 Amazon EventBridge 규칙을 구성하여 Lambda 함수를 호출합니다.",
    "SelectB_Commentary": "CloudTrail 이벤트 발생 시 Lambda가 자동으로 실행되어, 생성된 리소스에 적절한 비용 센터 태그를 부여하므로 요구사항을 가장 정확하게 충족합니다.",
    "SelectC": "AWS CloudFormation 스택으로 AWS Lambda 함수를 배포합니다. Lambda 함수가 RDS 데이터베이스에서 비용 센터를 조회해 리소스를 태그하도록 구성합니다. Amazon EventBridge 예약 규칙을 사용해 정기적으로 CloudFormation 스택을 호출합니다.",
    "SelectC_Commentary": "정해진 스케줄에만 태그 작업이 수행되어, 리소스 생성 시점에 즉시 태그를 적용하지 못하므로 실시간 요구사항에 부합하지 않습니다.",
    "SelectD": "AWS Lambda 함수를 만들어 리소스에 기본 비용 센터 값을 태그하도록 합니다. AWS CloudTrail 이벤트에 반응하는 Amazon EventBridge 규칙을 구성하여, 비용 센터 태그가 없는 리소스에 대해서만 Lambda 함수를 호출합니다.",
    "SelectD_Commentary": "기본 값만 태그하며, 개별 사용자별 정확한 비용 센터 ID를 적용하지 못합니다. 요구사항을 충족하기에는 정보가 부족합니다.",
    "Question_Description_recommedations": [
      "Q742",
      "Q330",
      "Q945",
      "Q168",
      "Q438"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q428",
      "Q936",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q428",
      "Q556",
      "Q791"
    ],
    "SelectD_recommedations": [
      "Q936",
      "Q791",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q654",
    "Question_Description": "한 회사가 최근 웹 애플리케이션을 AWS Cloud로 이전했습니다. 이 회사는 Amazon EC2 인스턴스를 사용하여 여러 프로세스로 애플리케이션을 호스팅하고 있습니다. 이 프로세스들은 정적 콘텐츠를 제공하는 Apache 웹 서버를 포함하며, PHP 애플리케이션이 로컬 Redis 서버를 통해 사용자 세션을 관리합니다. 회사는 아키텍처를 고가용성으로 설계하고, AWS에서 제공하는 매니지드 솔루션을 사용하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/128008-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 정적 콘텐츠와 PHP 애플리케이션, 세션 관리를 모두 고가용성과 매니지드 서비스로 구성하는 것입니다. CloudFront와 S3를 통해 정적 콘텐츠를 효율적으로 전달하고, Application Load Balancer와 Amazon ECS(AWS Fargate)로 확장 가능하고 고가용성인 PHP 환경을 구성할 수 있습니다. 또한 ElastiCache for Redis를 Multi-AZ로 설정함으로써 세션 관리를 안정적으로 수행할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "정적 콘텐츠",
      "PHP 애플리케이션",
      "Redis 세션",
      "고가용성",
      "매니지드 서비스"
    ],
    "Terms": [
      "Amazon EC2",
      "Apache Web Server",
      "PHP Application",
      "Redis server",
      "AWS Elastic Beanstalk",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon ElastiCache for Redis",
      "Amazon S3",
      "Amazon CloudFront",
      "Application Load Balancer",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate"
    ],
    "SelectA": "AWS Elastic Beanstalk를 사용하여 정적 콘텐츠와 PHP 애플리케이션을 호스팅하고, Elastic Beanstalk의 EC2 인스턴스를 퍼블릭 서브넷에 배포하고 퍼블릭 IP를 할당합니다.",
    "SelectA_Commentary": "Elastic Beanstalk만으로 웹 서버와 애플리케이션을 모두 처리할 수 있지만, 정적 콘텐츠를 별도로 최적화하거나 다중 AZ 구성이 충분히 명시되지 않아 고가용성 및 확장성 측면에서 부족합니다.",
    "SelectB": "AWS Lambda와 Amazon API Gateway로 정적 콘텐츠와 PHP 애플리케이션을 호스팅하고, Lambda 함수로 요청을 프록시합니다. API Gateway CORS 구성을 도메인에 맞게 설정하고, Amazon ElastiCache for Redis를 세션 정보용으로 설정합니다.",
    "SelectB_Commentary": "Lambda를 통한 정적 콘텐츠 서빙은 비효율적이며, 대규모 웹 애플리케이션을 Lambda로 모두 처리하는 것은 관리 오버헤드는 줄일 수 있으나, 트래픽 급증 시 비용과 제한 사항 고려가 필요해 적합하지 않습니다.",
    "SelectC": "백엔드 코드를 유지하면서 Amazon ElastiCache for Redis(Multi-AZ, 클러스터 모드 활성화)를 생성하고, 프론트엔드 자원을 Amazon S3로 복사합니다. 백엔드 코드는 계속 EC2 인스턴스를 참조하도록 구성합니다.",
    "SelectC_Commentary": "Redis를 매니지드 서비스로 옮기는 점은 좋지만, 여전히 EC2 단일 인스턴스 환경에서 PHP를 유지하므로 고가용성 및 완전 매니지드 아키텍처 요구사항을 충족하기 어렵습니다.",
    "SelectD": "Amazon CloudFront 배포를 구성하고, 정적 콘텐츠가 호스팅된 S3 버킷을 CloudFront 오리진으로 지정합니다. Application Load Balancer가 AWS Fargate 태스크에서 구동되는 Amazon ECS 서비스를 대상으로 트래픽을 전달하도록 구성합니다. PHP 애플리케이션은 Multi-AZ를 사용하는 Amazon ElastiCache for Redis 클러스터를 사용하도록 설정합니다.",
    "SelectD_Commentary": "정적 콘텐츠를 S3와 CloudFront로 처리해 전송 효율과 확장성을 확보하고, PHP 애플리케이션은 ECS Fargate를 통해 완전 매니지드 환경에서 고가용성을 구현할 수 있습니다. Redis 역시 Multi-AZ로 구성해 세션 데이터의 안정성을 보장하는 가장 이상적인 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q944",
      "Q790",
      "Q892",
      "Q194",
      "Q935"
    ],
    "SelectA_recommedations": [
      "Q654",
      "Q145",
      "Q664"
    ],
    "SelectB_recommedations": [
      "Q354",
      "Q775",
      "Q654"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q593",
      "Q944"
    ],
    "SelectD_recommedations": [
      "Q654",
      "Q537",
      "Q354"
    ]
  },
  {
    "Question_Number": "Q655",
    "Question_Description": "한 회사가 Auto Scaling group 안에 있는 Amazon EC2 인스턴스에서 웹 애플리케이션을 구동하고 있으며, 이 그룹은 target group을 가지고 있습니다. 이 애플리케이션은 사용자 경험 향상을 위해 session affinity(sticky sessions) 기능을 사용하도록 설계되었습니다. 애플리케이션은 공용 인터넷에서 endpoint로 접근 가능해야 하고, 추가 보안을 위해 WAF가 적용되어야 합니다. 또한 endpoint에는 session affinity(sticky sessions)가 구성되어 있어야 합니다. 이러한 요구 사항을 충족하기 위해 어떤 조합의 단계가 필요합니까? (2개를 선택하세요.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/128009-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션을 공용 인터넷에 노출하면서 AWS WAF를 적용하고, session affinity(sticky sessions)를 유지하도록 설계하는 방법을 묻습니다. ALB(Application Load Balancer)는 Application 계층에서 쿠키 기반의 세션 어피니티를 제공하며, AWS WAF와 쉽게 연동이 가능하므로 보안 요구사항과 세션 관리 요구사항을 동시에 충족할 수 있습니다. 따라서 ALB를 사용하고, 해당 엔드포인트에 AWS WAF를 연결하는 구성이 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "세션 어피니티",
      "sticky sessions",
      "공용 인터넷 엔드포인트",
      "WAF 적용",
      "보안"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "target group",
      "Application Load Balancer",
      "Network Load Balancer",
      "Gateway Load Balancer",
      "AWS WAF",
      "web ACL",
      "session affinity(sticky sessions)",
      "Elastic IP addresses"
    ],
    "SelectA": "Create a public Network Load Balancer. Specify the application target group.",
    "SelectA_Commentary": "Network Load Balancer는 전송 계층 기반이므로 sticky sessions를 지원하지 못합니다. 세션 어피니티 요구사항을 충족할 수 없습니다.",
    "SelectB": "Create a Gateway Load Balancer. Specify the application target group.",
    "SelectB_Commentary": "Gateway Load Balancer는 트래픽 검사 및 서드파티 네트워크 서비스 연결에 유리하지만, sticky sessions 같은 애플리케이션 계층 기능을 제공하지 않습니다.",
    "SelectC": "Create a public Application Load Balancer. Specify the application target group.",
    "SelectC_Commentary": "Application Load Balancer는 Layer 7에서 쿠키 기반의 session affinity를 제공하고, 공용 엔드포인트로 노출 가능하므로 이 요구사항에 적합합니다.",
    "SelectD": "Create a second target group. Add Elastic IP addresses to the EC2 instances.",
    "SelectD_Commentary": "Elastic IP addresses 방식은 부하 분산을 우회해 직접 트래픽을 받게 되어 세션 어피니티 적용이 어렵고, WAF와 연동하기도 까다롭습니다.",
    "SelectE": "Create a web ACL in AWS WAF. Associate the web ACL with the endpoint",
    "SelectE_Commentary": "AWS WAF의 web ACL을 엔드포인트(ALB)와 연동함으로써 애플리케이션 계층 보안을 적용할 수 있어 추가 보안 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q614",
      "Q749",
      "Q624",
      "Q318",
      "Q170"
    ],
    "SelectA_recommedations": [
      "Q170",
      "Q625",
      "Q644"
    ],
    "SelectB_recommedations": [
      "Q625",
      "Q644",
      "Q170"
    ],
    "SelectC_recommedations": [
      "Q170",
      "Q625",
      "Q644"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q655",
      "Q453"
    ],
    "SelectE_recommedations": [
      "Q165",
      "Q233",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q656",
    "Question_Description": "한 회사가 역사적 사건의 이미지를 저장하는 웹사이트를 운영하고 있습니다. 웹사이트 사용자는 이미지에 표시된 사건이 발생한 연도를 기준으로 이미지를 검색하고 볼 수 있어야 합니다. 평균적으로 각 이미지는 연간 한두 번 정도만 요청됩니다. 회사는 고가용성을 유지하면서 사용자에게 이미지를 제공할 수 있는 가장 비용 효율적인 솔루션을 원합니다. 어떤 솔루션이 이러한 요구사항을 가장 비용 효율적으로 충족할 수 있습니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/127135-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이미지는 드물게 요청되므로 S3 Standard-IA가 스토리지 비용을 절감하면서 고가용성을 제공하는 최적의 솔루션입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "이미지 저장",
      "연 1-2회 요청",
      "고가용성",
      "비용 효율"
    ],
    "Terms": [
      "Amazon Elastic Block Store(Amazon EBS)",
      "Amazon EFS",
      "Amazon S3 Standard",
      "Amazon S3 Standard-Infrequent Access(S3 Standard-IA)",
      "static website",
      "Amazon EC2"
    ],
    "SelectA": "Amazon EBS에 이미지를 저장하고, Amazon EC2에서 웹 서버를 사용합니다.",
    "SelectA_Commentary": "EBS는 EC2 인스턴스에 종속적이라 확장성이 낮고 비용이 더 많이 들 수 있습니다.",
    "SelectB": "Amazon EFS에 이미지를 저장하고, Amazon EC2에서 웹 서버를 사용합니다.",
    "SelectB_Commentary": "EFS는 주로 공유 파일 시스템에 적합하며, 요청 빈도가 낮은 데이터에는 비효율적일 수 있습니다.",
    "SelectC": "Amazon S3 Standard에 이미지를 저장하고, static website 기능을 사용해 이미지를 직접 제공합니다.",
    "SelectC_Commentary": "S3 Standard는 자주 액세스되는 객체에 적합하지만, 연간 요청 횟수가 적으면 더 저렴한 스토리지 클래스가 유리합니다.",
    "SelectD": "Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 이미지를 저장하고, static website 기능을 사용해 이미지를 직접 제공합니다.",
    "SelectD_Commentary": "요청 빈도가 낮을 때 비용 효율적이며, 고가용성도 제공하기 때문에 요구사항을 가장 잘 충족하는 정답입니다.",
    "Question_Description_recommedations": [
      "Q997",
      "Q794",
      "Q630",
      "Q49",
      "Q930"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q943",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q993",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q126",
      "Q23",
      "Q415"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q126",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q657",
    "Question_Description": "한 회사가 여러 비즈니스 유닛에서 사용하는 여러 AWS 계정을 AWS Organizations 조직 내에서 운영하고 있습니다. 이 회사는 전 세계 여러 오피스를 보유하고 있습니다. 전사적으로 사용 중인 보안 그룹 규칙을 업데이트하여 새 오피스 CIDR 범위를 허용하거나 기존 CIDR 범위를 제거해야 합니다. CIDR 범위를 업데이트하는 데 필요한 관리 오버헤드를 최소화하기 위해 이 회사는 보안 그룹 규칙 관리를 중앙화하고자 합니다. 가장 비용 효율적으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/127524-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 여러 AWS 계정에 걸쳐 새 오피스 CIDR 범위를 반영하거나 기존 CIDR 범위를 제거하는 작업을 단순화해야 합니다. Prefix List를 활용하면 단일 위치에서 CIDR을 관리할 수 있으며, Resource Access Manager로 공유하여 모든 계정 보안 그룹에 즉각 반영함으로써 가장 비용 효율적이고 중앙화된 보안 설정이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "CIDR 범위",
      "보안 그룹",
      "Prefix List",
      "AWS Resource Access Manager",
      "중앙화된 관리"
    ],
    "Terms": [
      "Security Group",
      "AWS Organizations",
      "CIDR",
      "AWS Resource Access Manager (AWS RAM)",
      "Prefix List",
      "AWS Firewall Manager",
      "AWS Security Hub",
      "AWS Lambda",
      "Management Account",
      "Customer Managed Prefix List",
      "AWS Managed Prefix List"
    ],
    "SelectA": "조직의 Management Account에 VPC 보안 그룹을 생성하고, CIDR 범위를 업데이트할 때마다 해당 보안 그룹을 갱신합니다.",
    "SelectA_Commentary": "관리 계정에서만 보안 그룹을 생성해도 다른 계정 보안 그룹을 손쉽게 일괄 적용하기 어려워, CIDR 범위 변경 시 매번 직접 업데이트해야 하므로 오버헤드가 줄지 않습니다.",
    "SelectB": "CIDR 리스트를 포함한 VPC Customer Managed Prefix List를 생성합니다. AWS Resource Access Manager(AWS RAM)으로 Prefix List를 조직 전체에 공유합니다. 조직 내 보안 그룹에서 Prefix List를 참조하도록 구성합니다.",
    "SelectB_Commentary": "Customer Managed Prefix List를 통해 단일 위치에서 CIDR 범위를 추가 또는 삭제할 수 있고, 이를 RAM으로 전체 조직에 공유하면 보안 그룹이 자동 반영되어 오버헤드와 비용이 최소화됩니다.",
    "SelectC": "AWS Managed Prefix List를 생성하고, AWS Security Hub 정책으로 조직 전체 보안 그룹 업데이트를 강제 적용합니다. CIDR 범위가 바뀌면 AWS Lambda 함수를 사용해 Prefix List를 자동 업데이트합니다.",
    "SelectC_Commentary": "AWS Managed Prefix List는 주로 AWS 서비스 IP 목록에 사용됩니다. Security Hub와 Lambda 연동은 구성과 운영이 복잡해져 비용 측면에서 비효율적입니다.",
    "SelectD": "중앙 관리용 AWS 계정에서 보안 그룹을 생성합니다. AWS Firewall Manager의 공통 보안 그룹 정책을 만들어 전체 조직에 적용합니다. 정책에서 앞서 생성한 보안 그룹을 기본 보안 그룹으로 지정합니다.",
    "SelectD_Commentary": "AWS Firewall Manager 정책을 쓰면 일부 보안 설정을 중앙 관리할 수 있으나, 설정 과정이 복잡하고 비용 효율성도 떨어질 수 있어 요구사항을 만족하기에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q1018",
      "Q828",
      "Q3"
    ],
    "SelectA_recommedations": [
      "Q950",
      "Q151",
      "Q15"
    ],
    "SelectB_recommedations": [
      "Q657",
      "Q950",
      "Q151"
    ],
    "SelectC_recommedations": [
      "Q657",
      "Q936",
      "Q945"
    ],
    "SelectD_recommedations": [
      "Q484",
      "Q529",
      "Q970"
    ]
  },
  {
    "Question_Number": "Q658",
    "Question_Description": "한 회사가 고성능 컴퓨팅(HPC) 워크로드에 파일 공유를 제공하기 위해 사내 NAS(Network-Attached Storage)를 사용하고 있습니다. 이 회사는 지연 시간에 민감한 HPC 워크로드와 스토리지를 AWS 클라우드로 마이그레이션하려고 합니다. 그리고 파일 시스템에서 NFS와 SMB 멀티 프로토콜 접근을 동시에 제공해야 합니다. 다음 중 최소 지연(latency)으로 이 요구 사항을 충족하는 솔루션을 모두 고르세요. (정답 2개)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126797-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HPC 워크로드를 AWS로 이전하면서, 지연 시간을 최소화하고 동시에 NFS/SMB 멀티 프로토콜 파일 공유를 제공해야 하는 상황입니다. HPC 특성상 밀집 노드 간에 네트워크 지연이 매우 중요하며, FSx for NetApp ONTAP은 NFS와 SMB를 모두 지원하므로 요구 사항을 충족합니다. 또한 클러스터 배치 그룹은 HPC 환경에서 심리스한 저지연 통신에 최적화되어 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2"
    ],
    "Keywords": [
      "HPC",
      "지연 시간 최소화",
      "NFS",
      "SMB",
      "파일 공유",
      "멀티 프로토콜",
      "Amazon FSx",
      "NAS"
    ],
    "Terms": [
      "Cluster Placement Group",
      "Partition Placement Group",
      "Compute Optimized EC2",
      "Amazon FSx for Lustre",
      "Amazon FSx for OpenZFS",
      "Amazon FSx for NetApp ONTAP"
    ],
    "SelectA": "컴퓨트 최적화 EC2 인스턴스를 클러스터 배치 그룹에 배포합니다.",
    "SelectA_Commentary": "클러스터 배치 그룹을 사용하면 HPC 워크로드 노드 간 레이턴시가 크게 줄어들어 최대 성능을 낼 수 있습니다.",
    "SelectB": "컴퓨트 최적화 EC2 인스턴스를 파티션 배치 그룹에 배포합니다.",
    "SelectB_Commentary": "파티션 배치 그룹은 대규모 분산 워크로드에 사용되지만, HPC 워크로드의 초저지연 요구 사항에는 클러스터 배치 그룹이 더 적합합니다.",
    "SelectC": "EC2 인스턴스를 Amazon FSx for Lustre 파일 시스템에 연결합니다.",
    "SelectC_Commentary": "FSx for Lustre는 고성능 POSIX 파일 시스템이나, NFS와 SMB 멀티 프로토콜 지원이 필요하면 적합하지 않습니다.",
    "SelectD": "EC2 인스턴스를 Amazon FSx for OpenZFS 파일 시스템에 연결합니다.",
    "SelectD_Commentary": "FSx for OpenZFS는 주로 NFS를 지원하므로 멀티 프로토콜로 SMB까지 동시에 지원하기 어려워 요구 사항에 부합하지 않습니다.",
    "SelectE": "EC2 인스턴스를 Amazon FSx for NetApp ONTAP 파일 시스템에 연결합니다.",
    "SelectE_Commentary": "FSx for NetApp ONTAP은 NFS와 SMB 등 멀티 프로토콜을 모두 지원하므로 HPC 환경에서 지연 시간을 최소화하며 요구 사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q795",
      "Q646",
      "Q445",
      "Q857",
      "Q283"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q361",
      "Q568"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q568"
    ],
    "SelectC_recommedations": [
      "Q407",
      "Q857",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q857",
      "Q746",
      "Q299"
    ],
    "SelectE_recommedations": [
      "Q857",
      "Q746",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q659",
    "Question_Description": "한 회사가 데이터 센터를 이전하면서 2주 이내에 50 TB의 데이터를 AWS로 안전하게 전송하기를 원합니다. 기존 데이터 센터는 이미 AWS로의 Site-to-Site VPN 연결이 90% 사용 중입니다. 이러한 요구사항을 만족하기 위해 솔루션스 아키텍트는 어떤 AWS 서비스를 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/128067-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 제한된 VPN 대역폭 환경에서 대규모 데이터를 신속하고 안전하게 전송하는 방법을 묻습니다. AWS Snowball Edge Storage Optimized를 활용하면 오프라인 방식으로 대역폭 제약을 피하면서 50 TB의 데이터를 효율적으로 전송할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4",
      "3.5"
    ],
    "Keywords": [
      "데이터 센터 이전",
      "2주 이내",
      "50TB 전송",
      "Site-to-Site VPN",
      "90% 사용",
      "AWS Snowball Edge Storage Optimized",
      "오프라인 전송"
    ],
    "Terms": [
      "AWS DataSync",
      "VPC endpoint",
      "AWS Direct Connect",
      "AWS Snowball Edge Storage Optimized",
      "AWS Storage Gateway",
      "Site-to-Site VPN"
    ],
    "SelectA": "AWS DataSync와 VPC endpoint를 사용하여 데이터를 전송합니다.",
    "SelectA_Commentary": "DataSync는 대역폭을 계속 사용하기 때문에 이미 90% 활용 중인 VPN 환경에서는 전송 속도가 충분히 나오지 않습니다.",
    "SelectB": "AWS Direct Connect를 구성하여 전송합니다.",
    "SelectB_Commentary": "Direct Connect는 별도의 전용 회선 구축이 필요해 설정과 시간이 많이 들고, 2주 내에 50TB를 옮기기에 적합하지 않을 수 있습니다.",
    "SelectC": "AWS Snowball Edge Storage Optimized를 사용하여 데이터를 오프라인으로 전송합니다.",
    "SelectC_Commentary": "인터넷 대역폭 사용이 거의 없고 물리 장치를 통해 대용량 데이터를 빠르게 마이그레이션할 수 있어 가장 유효한 선택입니다.",
    "SelectD": "AWS Storage Gateway를 사용하여 데이터를 업로드합니다.",
    "SelectD_Commentary": "Storage Gateway는 온프레미스 환경과 AWS 간의 하이브리드 스토리지 구성에 적합하지만, 대규모 오프라인 전송에는 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q64",
      "Q331",
      "Q113",
      "Q747",
      "Q844"
    ],
    "SelectA_recommedations": [
      "Q686",
      "Q515",
      "Q352"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q352",
      "Q865"
    ],
    "SelectC_recommedations": [
      "Q620",
      "Q702",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q620",
      "Q865"
    ]
  },
  {
    "Question_Number": "Q660",
    "Question_Description": "한 회사가 Amazon EC2 On-Demand Instances를 Auto Scaling group에 호스팅하고 있습니다. 애플리케이션 피크 시간대는 매일 같은 시간대에 발생합니다. 애플리케이션 사용자는 피크 시간대가 시작될 때 애플리케이션 성능이 느리다고 보고하며, 시작 후 2~3시간이 지나면 정상적으로 동작합니다. 회사는 피크 시간대가 시작될 때부터 애플리케이션이 원활히 작동하도록 보장하기를 원합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126994-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 같은 시간대에 예상되는 피크 트래픽을 사전에 처리할 수 있는 방안을 고민하는 상황입니다. 동적 스케일링은 실시간 지표를 기반으로 확장해 초기 부하에 늦게 대응할 수 있습니다. 스케줄링된 스케일링을 사용하면 피크시간 직전에 인스턴스를 추가로 준비해 둘 수 있어, 성능 저하 없이 사용자가 접속하는 순간부터 원활한 경험을 제공할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EC2 On-Demand Instances",
      "Auto Scaling group",
      "피크 시간대",
      "애플리케이션 성능",
      "Scheduled scaling policy"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Auto Scaling group",
      "Application Load Balancer",
      "Dynamic scaling policy",
      "Scheduled scaling policy",
      "CPU utilization",
      "Memory utilization"
    ],
    "SelectA": "Application Load Balancer를 구성하여 트래픽을 인스턴스에 적절히 분산시킵니다.",
    "SelectA_Commentary": "Application Load Balancer는 트래픽을 분산할 뿐, 피크 시작 시점에 인스턴스가 부족하면 여전히 성능 저하가 발생합니다.",
    "SelectB": "메모리 사용률을 기준으로 Auto Scaling group의 동적 스케일링 정책을 구성하여 새 인스턴스를 시작합니다.",
    "SelectB_Commentary": "메모리 지표 기반의 동적 스케일링은 트래픽 패턴이 예측 불가능할 때 유용하지만, 매일 같은 시간대 피크를 사전에 대비하기에는 적절하지 않습니다.",
    "SelectC": "CPU 사용률을 기준으로 Auto Scaling group의 동적 스케일링 정책을 구성하여 새 인스턴스를 시작합니다.",
    "SelectC_Commentary": "CPU 지표 기반의 동적 스케일링도 실시간 상황에 대응하므로, 피크 시간대 초기에 이미 성능 저하가 시작될 수 있습니다.",
    "SelectD": "피크 시간대 전에 미리 새 인스턴스를 시작하도록 Auto Scaling group에 스케줄링된 스케일링 정책을 구성합니다.",
    "SelectD_Commentary": "매일 같은 시간대에 예상되는 피크를 위해 미리 인스턴스를 추가 확보함으로써, 성능 저하 없이 피크 시작 시점을 대응할 수 있는 최적 해법입니다.",
    "Question_Description_recommedations": [
      "Q595",
      "Q1001",
      "Q271",
      "Q581",
      "Q210"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q405",
      "Q357"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q661",
    "Question_Description": "한 회사가 Amazon RDS 데이터베이스와 연결하는 애플리케이션을 AWS에서 운영하고 있습니다. 이 애플리케이션들은 주말과 연말 등 특정 시기에 스케일이 증가합니다. 회사는 데이터베이스와 연결되는 애플리케이션을 더 효과적으로 확장하기를 원하며, 이를 위해 운영상 부담을 최소화할 수 있는 방법을 찾고자 합니다. 어떤 솔루션이 이러한 요구사항을 가장 적은 운영 오버헤드로 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/127729-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon RDS Proxy는 데이터베이스 연결을 효율적으로 풀링하고 관리하여 애플리케이션이 많은 동시 연결을 사용해도 데이터베이스 자원을 효율적으로 활용하도록 도와줍니다. 완전관리형 서비스로 운영 부담이 적으며, 장애 극복 시에도 빠른 복구 시간을 제공해 확장성과 안정성을 모두 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "RDS 데이터베이스",
      "애플리케이션 스케일링",
      "운영 오버헤드 최소화",
      "연결 풀링",
      "Amazon RDS Proxy"
    ],
    "Terms": [
      "Amazon RDS",
      "Amazon RDS Proxy",
      "Amazon DynamoDB",
      "Amazon EC2",
      "AWS Lambda",
      "Connection Pooling",
      "Target Group"
    ],
    "SelectA": "Amazon DynamoDB를 사용하여 데이터베이스 용 타깃 그룹 구성을 통해 연결 풀링을 구현하고, 애플리케이션이 DynamoDB 엔드포인트를 사용하도록 변경합니다.",
    "SelectA_Commentary": "RDS 대신 DynamoDB를 사용하려면 애플리케이션 구조 자체를 크게 수정해야 하므로 사실상 DB 교체가 필요합니다. 요구사항 충족에도 불필요한 운영 부담이 커서 적합하지 않습니다.",
    "SelectB": "Amazon RDS Proxy를 데이터베이스의 타깃 그룹으로 사용합니다. 애플리케이션이 RDS Proxy 엔드포인트를 사용하도록 변경합니다.",
    "SelectB_Commentary": "RDS Proxy는 완전관리형 DB 프록시로서 연결 풀링을 자동화하고 확장성을 강화해 줍니다. 장애 복구 시간도 단축되므로 운영 오버헤드가 가장 적은 적합한 솔루션입니다.",
    "SelectC": "Amazon EC2에서 동작하는 커스텀 프록시를 데이터베이스와 애플리케이션 사이에 배포하고, 애플리케이션이 커스텀 프록시 엔드포인트를 사용하도록 변경합니다.",
    "SelectC_Commentary": "프록시 자체를 직접 구축·운영해야 하므로 인프라 관리와 확장성 고려가 필요합니다. 완전관리형 솔루션인 RDS Proxy 대비 운영 부담이 큽니다.",
    "SelectD": "AWS Lambda 함수를 이용해 데이터베이스 타깃 그룹 구성을 통한 연결 풀링을 제공하고, 애플리케이션이 Lambda 함수를 거쳐 연결하도록 합니다.",
    "SelectD_Commentary": "Lambda 함수를 사용해 연결 풀링 로직을 구현하는 것은 쉽지 않으며, 함수 호출 방식으로 인해 추가 지연과 복잡성이 증가해 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q269",
      "Q706",
      "Q193",
      "Q376",
      "Q726"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectB_recommedations": [
      "Q661",
      "Q269",
      "Q706"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q857",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q631",
      "Q443"
    ]
  },
  {
    "Question_Number": "Q662",
    "Question_Description": "한 회사가 AWS Cost Explorer를 사용하여 AWS 비용을 모니터링하고 있습니다. 회사는 Amazon Elastic Block Store(Amazon EBS) 스토리지 및 스냅샷 비용이 매달 증가하고 있음을 확인했지만, 실제로 매달 추가 EBS 스토리지를 구매하지는 않았습니다. 회사는 현재 사용 중인 스토리지에 대해 월간 비용을 최적화하고자 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126865-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 점차 증가하는 EBS 스토리지 및 스냅샷 비용을 어떻게 최소화할지 묻습니다. 스냅샷은 자동 관리가 가능하며, 필요하지 않은 스냅샷을 제거하고, Amazon Data Lifecycle Manager를 통해 정책에 따라 자동으로 생성 및 삭제하도록 설정하면 운영 오버헤드를 크게 줄이면서 비용도 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "월간 비용 최적화",
      "Amazon EBS 스토리지",
      "스냅샷 비용",
      "운영 오버헤드 최소화",
      "Amazon Data Lifecycle Manager(DLM)"
    ],
    "Terms": [
      "AWS Cost Explorer",
      "Amazon EBS",
      "Amazon EBS Elastic Volumes",
      "Amazon CloudWatch Logs",
      "Amazon Data Lifecycle Manager (DLM)"
    ],
    "SelectA": "Amazon CloudWatch Logs의 로그를 사용하여 Amazon EBS의 스토리지 사용량을 모니터링합니다. Amazon EBS Elastic Volumes를 사용해 EBS 볼륨 크기를 축소합니다.",
    "SelectA_Commentary": "스토리지 사용량 모니터링 및 볼륨 축소만으로는 스냅샷 비용이 증가하는 문제를 직접적으로 해결하기 어렵습니다.",
    "SelectB": "사용자 정의 스크립트를 통해 스토리지 사용량을 모니터링합니다. Amazon EBS Elastic Volumes를 사용해 EBS 볼륨 크기를 축소합니다.",
    "SelectB_Commentary": "이 방법은 스크립트 작성과 유지 보수가 필요해 운영 오버헤드가 높고, 스냅샷 정책 관리에 대한 직접적인 대응책이 되지 않습니다.",
    "SelectC": "만료되었거나 사용되지 않는 스냅샷을 모두 삭제하여 스냅샷 비용을 줄입니다.",
    "SelectC_Commentary": "만료된 스냅샷을 삭제하면 비용은 절감되지만, 향후 스냅샷 생성·정책 관리는 자동화되지 않아 여전히 수동 관리가 필요합니다.",
    "SelectD": "필수적이지 않은 스냅샷을 모두 삭제합니다. Amazon Data Lifecycle Manager를 사용하여 회사의 스냅샷 정책 요구사항에 따라 스냅샷을 생성 및 관리합니다.",
    "SelectD_Commentary": "불필요한 스냅샷을 제거해 즉시 비용을 낮추고, Amazon Data Lifecycle Manager로 자동화된 스냅샷 생성·삭제를 수행함으로써 운영 오버헤드를 최소화하는 최적의 해법입니다.",
    "Question_Description_recommedations": [
      "Q841",
      "Q425",
      "Q867",
      "Q937",
      "Q459"
    ],
    "SelectA_recommedations": [
      "Q867",
      "Q662",
      "Q425"
    ],
    "SelectB_recommedations": [
      "Q867",
      "Q552",
      "Q591"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ],
    "SelectD_recommedations": [
      "Q284",
      "Q728",
      "Q985"
    ]
  },
  {
    "Question_Number": "Q663",
    "Question_Description": "한 회사가 AWS에서 새로운 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 Amazon Elastic Container Service(Amazon ECS) 클러스터, 애플리케이션 자산을 저장하는 Amazon S3 버킷, 그리고 민감한 정보를 포함한 데이터 세트를 저장하는 Amazon RDS for MySQL 데이터베이스로 구성됩니다. 회사는 오직 ECS 클러스터만이 RDS for MySQL 데이터베이스와 S3 버킷의 데이터를 액세스하도록 보장하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126798-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 민감한 데이터를 위해 오직 Amazon ECS 클러스터만 접근할 수 있도록 하는 보안 제어 시나리오입니다. KMS를 통한 암호화 정책을 ECS 역할에만 허용함으로써 안전하게 접근을 제한할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon ECS 클러스터",
      "Amazon S3 버킷",
      "Amazon RDS for MySQL",
      "민감한 정보",
      "오직 ECS 클러스터만 접근",
      "데이터 세트",
      "보안"
    ],
    "Terms": [
      "ECS cluster",
      "Amazon ECS",
      "Amazon S3",
      "Amazon RDS for MySQL",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key",
      "AWS Managed Key",
      "KMS key policy",
      "ECS task execution role",
      "S3 Bucket Policy",
      "VPC Endpoint",
      "Security Group"
    ],
    "SelectA": "새로운 AWS KMS Customer Managed Key를 생성하여 S3 버킷과 RDS for MySQL 데이터베이스를 암호화합니다. 그리고 KMS 키 정책에 ECS 작업 실행 역할에 대한 암호화·복호화 권한을 부여합니다.",
    "SelectA_Commentary": "KMS 키 정책으로 오직 ECS 역할만 복호화 권한을 갖게 되어, RDS와 S3 데이터에 대한 ECS 전용 접근이 가능합니다.",
    "SelectB": "AWS KMS가 관리하는 AWS Managed Key를 생성하여 S3 버킷과 RDS for MySQL 데이터베이스를 암호화합니다. 그리고 S3 버킷 정책에 ECS 작업 실행 역할을 사용자로 지정합니다.",
    "SelectB_Commentary": "AWS Managed Key 설정만으로 RDS 접근 제한이 보장되지 않아, 오직 ECS만 액세스한다는 요구사항을 충족하지 못합니다.",
    "SelectC": "S3 버킷 정책을 생성하여 ECS 작업 실행 역할로만 버킷에 접근하도록 제한합니다. Amazon RDS for MySQL을 위한 VPC Endpoint를 생성하고, RDS 보안 그룹을 ECS 클러스터가 작동하는 서브넷만 허용하도록 업데이트합니다.",
    "SelectC_Commentary": "S3 접근은 역할에 제한되나, RDS 접근은 서브넷 단위여서 해당 서브넷 내 다른 리소스가 있을 경우 완전한 제한이 어렵습니다.",
    "SelectD": "Amazon RDS for MySQL을 위한 VPC Endpoint를 생성하고, RDS를 ECS 클러스터가 작동하는 서브넷에서만 접근 가능하도록 보안 그룹을 수정합니다. Amazon S3를 위한 VPC Endpoint를 생성하고, S3 버킷 정책에 해당 VPC Endpoint에서만 접근을 허용하도록 지정합니다.",
    "SelectD_Commentary": "VPC Endpoint를 사용해도 서브넷과 엔드포인트가 공유되는 다른 리소스가 접근할 수 있으므로 ECS만의 독점적 접근을 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q451",
      "Q998",
      "Q61",
      "Q977",
      "Q211"
    ],
    "SelectA_recommedations": [
      "Q371",
      "Q681",
      "Q36"
    ],
    "SelectB_recommedations": [
      "Q371",
      "Q681",
      "Q36"
    ],
    "SelectC_recommedations": [
      "Q663",
      "Q4",
      "Q185"
    ],
    "SelectD_recommedations": [
      "Q663",
      "Q451",
      "Q866"
    ]
  },
  {
    "Question_Number": "Q664",
    "Question_Description": "한 회사가 온프레미스에서 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 한 달에 두 번 피크 시간대에 지연 문제가 발생합니다. 지연 문제가 시작되면 애플리케이션의 CPU 사용률이 평소 대비 10배로 즉시 증가합니다. 회사는 지연 문제를 개선하기 위해 애플리케이션을 AWS로 마이그레이션하고, 사용자 수요가 증가할 때 자동으로 확장되도록 구성하고자 합니다. 회사는 AWS Elastic Beanstalk를 사용해 애플리케이션을 배포할 예정입니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126800-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매우 드문 간헐적 피크에 대비해 적절히 확장할 수 있는 Elastic Beanstalk 환경을 설계하는 내용입니다. 짧은 빈도로 발생하는 CPU 급증을 처리하기 위해서는 Burstable performance instances(T 계열)의 ‘unlimited mode’를 사용하면 크레딧을 추가로 사용하여 급격한 스파이크를 흡수할 수 있습니다. 또한 ‘scale based on requests’를 통해 동적 트래픽에도 자동 확장이 용이해집니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "AWS Elastic Beanstalk",
      "자동 확장",
      "지연 문제",
      "CPU 급증",
      "마이그레이션"
    ],
    "Terms": [
      "AWS Elastic Beanstalk",
      "Burstable performance instances",
      "Compute optimized instances",
      "Predictive scaling",
      "Scheduled scaling",
      "Scale based on requests"
    ],
    "SelectA": "Elastic Beanstalk 환경에서 burstable performance instances를 unlimited mode로 사용하도록 구성합니다. 요청 수 기준으로 확장하도록 설정합니다.",
    "SelectA_Commentary": "T 계열 unlimited 모드는 짧고 갑작스러운 CPU 스파이크를 잘 처리하고, 요청 수에 따라 자동 확장되므로 요구 사항을 충족합니다.",
    "SelectB": "Elastic Beanstalk 환경에서 compute optimized instances를 사용하도록 구성합니다. 요청 수 기준으로 확장하도록 설정합니다.",
    "SelectB_Commentary": "compute optimized 계열은 CPU 사용량이 지속적으로 높은 워크로드에 적합하나, 문제 상황은 간헐적 스파이크이며 일반 사용량은 낮으므로 비효율적입니다.",
    "SelectC": "Elastic Beanstalk 환경에서 compute optimized instances를 사용하도록 구성합니다. 스케줄 기반으로 확장하도록 설정합니다.",
    "SelectC_Commentary": "스케줄 기반 확장은 특정 시간에만 확장되므로, 예측이 어려운 간헐적 CPU 스파이크에 실시간 대응하기 어렵습니다.",
    "SelectD": "Elastic Beanstalk 환경에서 burstable performance instances를 unlimited mode로 사용하도록 구성합니다. 예측 기반 지표를 통한 확장으로 설정합니다.",
    "SelectD_Commentary": "Elastic Beanstalk에서는 예측 기반(Predictive) 확장이 공식적으로 지원되지 않으므로 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q252",
      "Q720",
      "Q114",
      "Q194",
      "Q1014"
    ],
    "SelectA_recommedations": [
      "Q664",
      "Q660",
      "Q351"
    ],
    "SelectB_recommedations": [
      "Q664",
      "Q194",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q664",
      "Q194",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q664",
      "Q660",
      "Q351"
    ]
  },
  {
    "Question_Number": "Q665",
    "Question_Description": "한 회사는 전 세계에 고객이 분포되어 있습니다. 이 회사는 시스템과 네트워크 인프라를 자동화하여 보안성을 유지하길 원합니다. 보안 팀은 모든 인프라 변경 사항을 추적하고 감사할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/128070-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "인프라를 코드(AWS CloudFormation)로 설정하면 보안 팀이 자동화를 통해 일관된 환경을 구축할 수 있고, AWS Config를 사용하면 모든 변경 사항이 기록되어 언제든지 감사와 추적이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "전 세계 고객",
      "자동화",
      "보안",
      "인프라 변경 사항",
      "AWS CloudFormation",
      "AWS Config"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS Config",
      "AWS CloudFormation",
      "AWS Service Catalog"
    ],
    "SelectA": "AWS Organizations를 사용하여 인프라를 설정합니다. AWS Config로 변경 사항을 추적합니다.",
    "SelectA_Commentary": "AWS Organizations는 계정 관리와 정책 적용에 유용하지만, 인프라 자동화 설계 도구로는 적합하지 않습니다.",
    "SelectB": "AWS CloudFormation을 사용하여 인프라를 설정합니다. AWS Config로 변경 사항을 추적합니다.",
    "SelectB_Commentary": "자동화된 인프라 구성과 변경 사항 감시를 모두 충족하는 최적의 조합입니다.",
    "SelectC": "AWS Organizations를 사용하여 인프라를 설정합니다. AWS Service Catalog로 변경 사항을 추적합니다.",
    "SelectC_Commentary": "AWS Service Catalog는 승인된 제품 포트폴리오 관리에 중점을 두며, 세밀한 인프라 변경 감사에는 적합하지 않습니다.",
    "SelectD": "AWS CloudFormation을 사용하여 인프라를 설정합니다. AWS Service Catalog로 변경 사항을 추적합니다.",
    "SelectD_Commentary": "Service Catalog는 프로비저닝 제어에 도움이 되지만, Config만큼 인프라 변경 사항을 상세 추적·감사할 수는 없습니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q122",
      "Q57",
      "Q189",
      "Q803"
    ],
    "SelectA_recommedations": [
      "Q945",
      "Q168",
      "Q3"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q970",
      "Q529"
    ],
    "SelectC_recommedations": [
      "Q945",
      "Q168",
      "Q3"
    ],
    "SelectD_recommedations": [
      "Q970",
      "Q529",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q666",
    "Question_Description": "한 스타트업 회사가 고객을 위한 웹사이트를 Amazon EC2 인스턴스에서 호스팅하고 있습니다. 이 웹사이트는 stateless Python 애플리케이션과 MySQL 데이터베이스로 구성되어 있으며, 적은 양의 트래픽만 처리합니다. 회사는 인스턴스의 신뢰성에 대해 염려하고 있으며, 고가용성 아키텍처로 이전할 계획입니다. 애플리케이션 코드는 수정할 수 없습니다. 웹사이트의 고가용성을 달성하기 위해 솔루션스 아키텍트는 어떤 조합의 작업을 수행해야 합니까? (두 개를 선택하세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/128269-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 단일 EC2 인스턴스 구성에서 발생할 수 있는 단일 장애점을 제거하고, 데이터베이스와 애플리케이션 레벨에서 고가용성을 확보하는 방법을 묻습니다. 데이터베이스를 Amazon RDS for MySQL Multi-AZ DB 인스턴스로 이전하면 자동으로 장애 조치가 가능해 높은 가용성을 보장합니다. 또한 Application Load Balancer와 Auto Scaling 그룹을 이용해 여러 Availability Zone에 걸쳐 인스턴스를 배포하면 트래픽 분산과 자동 확장이 가능해 서비스 중단 위험을 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "stateless Python 애플리케이션",
      "RDS for MySQL Multi-AZ",
      "Application Load Balancer",
      "Auto Scaling",
      "다중 AZ"
    ],
    "Terms": [
      "Amazon EC2",
      "stateless Python",
      "MySQL",
      "Amazon RDS for MySQL Multi-AZ",
      "Amazon DynamoDB",
      "DynamoDB auto scaling",
      "AWS DataSync",
      "Application Load Balancer",
      "Auto Scaling group",
      "Availability Zone",
      "Internet Gateway"
    ],
    "SelectA": "사용 중인 각 가용 영역에 인터넷 게이트웨이를 프로비저닝합니다.",
    "SelectA_Commentary": "인터넷 게이트웨이는 퍼블릭 서브넷에서 인터넷 연결을 제공하는 역할이지만, 이 자체로 고가용성이나 데이터베이스 이중화를 보장하지는 못하므로 오답입니다.",
    "SelectB": "데이터베이스를 Amazon RDS for MySQL Multi-AZ DB 인스턴스로 마이그레이션합니다.",
    "SelectB_Commentary": "Multi-AZ 구성은 자동 장애 조치로 고가용성을 보장하므로 정답입니다.",
    "SelectC": "데이터베이스를 Amazon DynamoDB로 마이그레이션하고, DynamoDB auto scaling을 활성화합니다.",
    "SelectC_Commentary": "DynamoDB로의 마이그레이션은 애플리케이션 코드 수정이 필요한 경우가 많아, 코드 변경이 불가능한 상황에는 적합하지 않습니다.",
    "SelectD": "AWS DataSync를 사용하여 여러 EC2 인스턴스 간 데이터베이스 데이터를 동기화합니다.",
    "SelectD_Commentary": "DataSync는 파일 시스템 데이터 동기화에 유용하지만 관계형 DB의 트랜잭션 무결성을 보장하거나 자동 장애 조치를 제공하지 않으므로 부적절합니다.",
    "SelectE": "서로 다른 두 개의 가용 영역에 분산된 EC2 인스턴스 Auto Scaling 그룹에 트래픽을 분산하기 위해 Application Load Balancer를 생성합니다.",
    "SelectE_Commentary": "여러 AZ에 걸쳐 인스턴스를 두고 ALB를 사용하면 트래픽 부하 분산, 장애 발생 시 자동 대체로 고가용성을 높일 수 있으므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q824",
      "Q236",
      "Q114",
      "Q768",
      "Q683"
    ],
    "SelectA_recommedations": [
      "Q187",
      "Q58",
      "Q917"
    ],
    "SelectB_recommedations": [
      "Q518",
      "Q466",
      "Q958"
    ],
    "SelectC_recommedations": [
      "Q1002",
      "Q845",
      "Q768"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q892",
      "Q244"
    ],
    "SelectE_recommedations": [
      "Q405",
      "Q275",
      "Q174"
    ]
  },
  {
    "Question_Number": "Q667",
    "Question_Description": "한 회사가 다년간의 마이그레이션 프로젝트 중에 데이터를 AWS로 이전하고 있습니다. 회사는 회사의 AWS Region과 온프레미스 위치에서 Amazon S3에 안전하게 액세스하려고 합니다. 데이터가 인터넷을 통과해서는 안 되며, 회사는 해당 Region과 온프레미스 간에 AWS Direct Connect를 이미 설정했습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/126802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 퍼블릭 인터넷을 사용하지 않고 AWS Region과 온프레미스 간에 Amazon S3에 접근하는 방법을 묻습니다. gateway endpoint는 VPC 내부 통신만 가능해 온프레미스 연결에 제약이 있고, KMS는 암호화 키 관리 기능만 제공합니다. interface endpoint는 온프레미스 환경에서도 AWS PrivateLink를 통해 안전하게 S3에 연결할 수 있어 요구 사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "데이터 마이그레이션",
      "AWS Direct Connect",
      "Amazon S3",
      "인터넷 트래픽 우회",
      "interface endpoint"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Direct Connect",
      "gateway endpoint",
      "interface endpoint",
      "AWS KMS",
      "VPC"
    ],
    "SelectA": "Amazon S3에 대한 gateway endpoints를 생성합니다. 이 gateway endpoints를 사용하여 Region과 온프레미스에서 안전하게 데이터를 액세스합니다.",
    "SelectA_Commentary": "gateway endpoint는 VPC 내부에서 전용 경로를 제공하나, 온프레미스에서의 직접 연결은 지원하지 않아 이 요구사항을 해결하지 못합니다.",
    "SelectB": "AWS Transit Gateway를 생성하여 Region과 온프레미스에서 Amazon S3에 안전하게 접근합니다.",
    "SelectB_Commentary": "Transit Gateway 자체로는 S3에 직접 연결할 수 없고, 별도의 endpoint 설계가 필요해 요건을 충족하기 어렵습니다.",
    "SelectC": "Amazon S3에 대한 interface endpoints를 생성합니다. 이 interface endpoints를 사용하여 Region과 온프레미스 위치에서 안전하게 데이터를 액세스합니다.",
    "SelectC_Commentary": "interface endpoint는 AWS PrivateLink를 이용해 VPC와 온프레미스 간에도 사설 경로를 제공하므로, 인터넷을 우회하고 보안을 보장하는 최적의 솔루션입니다.",
    "SelectD": "AWS Key Management Service (AWS KMS) 키를 사용하여 Region과 온프레미스에서 데이터를 안전하게 액세스합니다.",
    "SelectD_Commentary": "KMS는 데이터 암호화 및 키 관리를 제공하지만, 네트워크 트래픽 경로 제어와는 무관하므로 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q889",
      "Q134",
      "Q974",
      "Q862",
      "Q638"
    ],
    "SelectA_recommedations": [
      "Q889",
      "Q134",
      "Q974"
    ],
    "SelectB_recommedations": [
      "Q667",
      "Q889",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q889",
      "Q134",
      "Q868"
    ],
    "SelectD_recommedations": [
      "Q36",
      "Q916",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q668",
    "Question_Description": "한 회사가 AWS Organizations에서 새로운 Organization을 만들었습니다. 이 Organization에는 여러 개발 팀을 위한 계정들이 존재합니다. 개발 팀원들은 AWS IAM Identity Center(AWS Single Sign-On)를 사용해 이 계정들에 액세스합니다. 회사의 각 애플리케이션마다, 개발 팀은 사전에 정의된 애플리케이션 이름(Application Name)으로 리소스를 태그해야 합니다. 솔루션스 아키텍트는 애플리케이션 이름 태그가 승인된 값일 때만 리소스를 생성할 수 있도록 하는 솔루션을 설계해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/127661-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 개발 팀이 승인된 태그 값을 사용해야만 리소스를 생성하게 하여, 태깅 규정을 준수하도록 만드는 방법을 묻습니다. AWS Organizations에서 제공하는 Tag Policy를 사용하면 쉽게 태그를 표준화하고, 태그 값이 승인된 경우에만 리소스가 생성되도록 강제할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "IAM Identity Center",
      "애플리케이션 이름 태그",
      "리소스 생성 제어",
      "Tag Policy"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS IAM Identity Center (AWS Single Sign-On)",
      "IAM group conditional Allow",
      "Cross-account role",
      "Resource group in AWS Resource Groups",
      "Tag policy in Organizations"
    ],
    "SelectA": "IAM 그룹에 리소스 생성 시 애플리케이션 이름 태그를 지정하도록 하는 조건부 Allow 정책을 생성합니다.",
    "SelectA_Commentary": "IAM 그룹의 조건부 정책만으로 모든 계정에 걸친 일관된 태그 검증을 강제하기 어렵습니다.",
    "SelectB": "크로스 계정 역할을 생성하여 애플리케이션 이름 태그가 있는 모든 리소스를 Deny하는 정책을 설정합니다.",
    "SelectB_Commentary": "Deny 정책을 무조건 적용하면 태그 유무에 상관없이 리소스 생성이 제한되는 역효과가 납니다.",
    "SelectC": "AWS Resource Groups에서 리소스 그룹을 생성해, 모든 계정의 리소스에 태그가 적용되었는지 확인합니다.",
    "SelectC_Commentary": "Resource Groups는 태그 유효성을 강제하지 않고, 리소스의 집합 관리를 위한 도구로 요구사항 충족에 부적합합니다.",
    "SelectD": "Organizations에서 허용된 애플리케이션 이름 목록을 포함한 Tag Policy를 생성합니다.",
    "SelectD_Commentary": "Tag Policy를 통해 전체 Organization에 걸쳐 태그 표준을 적용하고, 승인된 태그 값만 허용할 수 있어 요구사항을 완벽히 충족합니다.",
    "Question_Description_recommedations": [
      "Q688",
      "Q28",
      "Q750",
      "Q945",
      "Q168"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q945",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q122",
      "Q665",
      "Q168"
    ]
  },
  {
    "Question_Number": "Q669",
    "Question_Description": "한 회사는 Amazon RDS for PostgreSQL에서 데이터베이스를 운영 중입니다. 회사는 마스터 사용자 비밀번호를 30일마다 로테이션하면서 보안을 강화할 수 있는 솔루션을 원합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/127660-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for PostgreSQL의 마스터 사용자 비밀번호를 정기적으로 로테이션하여 보안을 높이는 방법을 묻습니다. 가장 적은 운영 오버헤드로 자동화를 구현하려면, AWS Secrets Manager를 통한 비밀번호 로테이션이 가장 적합합니다. 다른 옵션들은 직접 스크립트를 작성하거나 수동 작업이 많아 운영 상의 복잡성이 증가하기 때문입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "마스터 사용자 비밀번호",
      "비밀번호 로테이션",
      "운영 오버헤드 최소화",
      "Amazon RDS for PostgreSQL",
      "AWS Secrets Manager"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS CLI",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "Password Rotation"
    ],
    "SelectA": "Amazon EventBridge를 사용해 30일마다 커스텀 AWS Lambda 함수를 호출하여 비밀번호를 로테이션합니다.",
    "SelectA_Commentary": "EventBridge와 Lambda를 활용할 수 있지만, 직접 로직을 구현해야 하므로 운영 복잡성과 관리 오버헤드가 증가합니다.",
    "SelectB": "AWS CLI의 modify-db-instance 명령어를 이용해 비밀번호를 변경합니다.",
    "SelectB_Commentary": "단순히 CLI 명령으로 변경하는 방식은 자동화가 어렵고 30일마다 수동으로 작업해야 하므로 운영 부담이 큽니다.",
    "SelectC": "AWS Secrets Manager와 Amazon RDS for PostgreSQL을 통합하여 비밀번호 자동 로테이션을 설정합니다.",
    "SelectC_Commentary": "Secrets Manager는 RDS 비밀번호 로테이션을 자동화해주어 운영 오버헤드를 크게 줄이고 보안을 강화할 수 있는 가장 적합한 솔루션입니다.",
    "SelectD": "AWS Systems Manager Parameter Store와 Amazon RDS for PostgreSQL을 통합하여 비밀번호 로테이션을 자동화합니다.",
    "SelectD_Commentary": "Parameter Store를 이용한 로테이션은 제한적이며, Secrets Manager만큼 직관적이고 간단하게 설정하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q847",
      "Q330",
      "Q742",
      "Q406",
      "Q951"
    ],
    "SelectA_recommedations": [
      "Q936",
      "Q791",
      "Q159"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q233",
      "Q682"
    ],
    "SelectC_recommedations": [
      "Q847",
      "Q669",
      "Q330"
    ],
    "SelectD_recommedations": [
      "Q847",
      "Q179",
      "Q669"
    ]
  },
  {
    "Question_Number": "Q670",
    "Question_Description": "한 회사가 Amazon DynamoDB 테이블을 사용하는 애플리케이션에 대한 테스트를 수행합니다. 이 테스트는 일주일에 한 번, 4시간 동안 실행됩니다. 회사는 테스트 중 애플리케이션이 테이블에 매초 수행하는 읽기 및 쓰기 작업량을 알고 있습니다. 현재 회사는 다른 용도로 DynamoDB를 사용하지 않습니다. 솔루션스 아키텍트는 테이블에 대한 비용을 최적화해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129711-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 간헐적인 테스트 사용 패턴에 맞춰 DynamoDB의 과금을 최적화하는 방안을 찾는 것입니다. 주 1회 4시간 동안만 트래픽이 발생하므로, 사용량에 따라 자동으로 확장·축소되는 On-demand mode가 최소 비용과 운영 편의성을 모두 충족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon DynamoDB",
      "주 1회 테스트",
      "4시간 테스트",
      "비용 최적화",
      "On-demand mode",
      "Provisioned mode",
      "DynamoDB reserved capacity",
      "read capacity units",
      "write capacity units"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "On-demand mode",
      "Provisioned mode",
      "DynamoDB reserved capacity",
      "read capacity units (RCU)",
      "write capacity units (WCU)"
    ],
    "SelectA": "On-demand mode를 선택하고, 필요한 읽기와 쓰기 용량을 적절히 업데이트합니다.",
    "SelectA_Commentary": "테스트 시간에 맞춰 실제로 사용한 만큼만 과금되므로, 짧은 구간에 집중된 워크로드에 가장 효율적인 비용 구조를 제공합니다.",
    "SelectB": "Provisioned mode를 선택하고, 필요한 읽기와 쓰기 용량을 적절히 업데이트합니다.",
    "SelectB_Commentary": "테스트 시간이 아닐 때도 프로비저닝된 용량에 대한 비용이 발생할 수 있어, 사용량이 적은 기간에는 비효율적입니다.",
    "SelectC": "DynamoDB reserved capacity를 1년 기간으로 구매합니다.",
    "SelectC_Commentary": "장기적이고 일정한 트래픽 시나리오가 아니므로, 단 4시간씩 주 1회 사용에서는 예약 용량이 오히려 비용 낭비가 됩니다.",
    "SelectD": "DynamoDB reserved capacity를 3년 기간으로 구매합니다.",
    "SelectD_Commentary": "더 긴 약정 기간이므로 사용 패턴이 불규칙한 환경에는 적합하지 않아, 오히려 비용 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q348",
      "Q79",
      "Q196",
      "Q799",
      "Q520"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q49"
    ],
    "SelectB_recommedations": [
      "Q997",
      "Q630",
      "Q49"
    ],
    "SelectC_recommedations": [
      "Q670",
      "Q348",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q670",
      "Q943",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q671",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 회사는 AWS 비용에 대한 재무 평가를 정기적으로 수행해 왔으며, 최근에 비정상적인 지출을 확인했습니다. 회사는 이러한 비정상 지출을 방지하기 위해 비용을 모니터링하고 지출 이상이 감지될 경우 관련 담당자에게 알림을 보내는 솔루션이 필요합니다. 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129712-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 비용 중 특히 예기치 못한 지출을 사전에 파악하고 대응하는 방법을 묻습니다. 가장 효과적인 방식은 AWS Cost Anomaly Detection 기능을 사용해 비용 패턴을 자동 분석하고 지출 이상이 발생하면 담당자에게 즉시 알림을 보내는 것입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비정상 지출",
      "비용 모니터링",
      "알림",
      "EC2",
      "AWS Cost Anomaly Detection"
    ],
    "Terms": [
      "AWS Budgets",
      "AWS Cost Anomaly Detection",
      "AWS Pricing Calculator",
      "Amazon CloudWatch",
      "AWS Billing and Cost Management",
      "Amazon EC2"
    ],
    "SelectA": "AWS Budgets 템플릿을 사용하여 zero spend budget을 생성합니다.",
    "SelectA_Commentary": "zero spend budget은 특정 임계값 이하를 모니터링하는 용도로 활용하기 어렵고, 예기치 못한 증가 지점을 감지하기엔 제한적입니다.",
    "SelectB": "AWS Billing and Cost Management 콘솔에서 AWS Cost Anomaly Detection monitor를 생성합니다.",
    "SelectB_Commentary": "비정상 지출 패턴을 자동으로 탐지하고, 담당자에게 알림을 발송하는 용도로 적합하여 요구사항을 정확히 충족합니다.",
    "SelectC": "현재 실행 중인 워크로드의 가격 세부 정보에 대해 AWS Pricing Calculator 견적을 생성합니다.",
    "SelectC_Commentary": "AWS Pricing Calculator는 예상 비용 견적 도구로, 실시간 지출 이상을 탐지하거나 알림 기능을 제공하지는 않습니다.",
    "SelectD": "Amazon CloudWatch를 사용하여 비용을 모니터링하고 비정상 지출을 식별합니다.",
    "SelectD_Commentary": "CloudWatch는 지표 모니터링에 적합하지만, AWS 비용 구조 분석에 특화된 기능은 없기 때문에 활용에 제한적입니다.",
    "Question_Description_recommedations": [
      "Q238",
      "Q167",
      "Q347",
      "Q993",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q728",
      "Q485",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q641",
      "Q31",
      "Q883"
    ],
    "SelectC_recommedations": [
      "Q284",
      "Q728",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q486",
      "Q485",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q672",
    "Question_Description": "한 마케팅 회사가 마케팅 캠페인으로부터 Amazon S3에 대량의 신규 클릭스트림 데이터를 수신하고 있습니다. 회사는 Amazon S3에 있는 클릭스트림 데이터를 빠르게 분석한 다음, 해당 데이터를 데이터 파이프라인에서 추가로 처리할지 여부를 결정해야 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129713-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장된 클릭스트림 데이터를 빠르게 분석하고, 추가 처리를 결정하기까지의 과정을 최소한의 설정 및 관리만으로 수행하는 방법을 묻는 것입니다. AWS Glue 크롤러를 사용해 스키마를 자동으로 생성하고 서버리스인 Amazon Athena로 즉시 SQL 질의를 실행하면, 별도의 인프라 구성 없이 빠르고 간편하게 데이터를 분석할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "클릭스트림 데이터",
      "분석",
      "운영 오버헤드 최소화",
      "Athena",
      "AWS Glue Crawler"
    ],
    "Terms": [
      "Amazon S3",
      "클릭스트림 데이터",
      "AWS Glue",
      "Amazon Athena",
      "Spark",
      "Hive Metastore",
      "Amazon EMR",
      "Amazon Kinesis Data Analytics"
    ],
    "SelectA": "Spark 카탈로그에서 외부 테이블을 생성하고, AWS Glue 잡을 구성하여 데이터를 질의합니다.",
    "SelectA_Commentary": "Spark 환경 설정과 카탈로그 관리를 직접 해야 하므로 운영 오버헤드가 더 높습니다.",
    "SelectB": "AWS Glue 크롤러로 데이터를 크롤링하고, Amazon Athena를 구성하여 데이터를 질의합니다.",
    "SelectB_Commentary": "서버리스 방식으로 스키마 자동 추출 및 즉시 쿼리가 가능하므로 설정이 간단하고 운영 부담이 가장 적은 최적의 해법입니다.",
    "SelectC": "Hive Metastore에서 외부 테이블을 생성하고, Amazon EMR의 Spark 잡을 구성하여 데이터를 질의합니다.",
    "SelectC_Commentary": "EMR 클러스터 및 Hive Metastore 운영이 필요해 설정이 복잡하고, 관리 오버헤드가 큽니다.",
    "SelectD": "AWS Glue 크롤러로 데이터를 크롤링하고, Amazon Kinesis Data Analytics를 구성하여 SQL로 데이터를 질의합니다.",
    "SelectD_Commentary": "Kinesis Data Analytics는 주로 실시간 스트리밍 데이터 처리에 적합하며, 정적 데이터 분석에는 다소 부적합해 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q43",
      "Q501",
      "Q155",
      "Q173",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q631",
      "Q568"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q173",
      "Q155"
    ],
    "SelectC_recommedations": [
      "Q229",
      "Q235",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q402",
      "Q292"
    ]
  },
  {
    "Question_Number": "Q673",
    "Question_Description": "어느 회사는 기존 데이터 센터에서 SMB 파일 서버를 운영하고 있습니다. 이 파일 서버는 생성된 파일의 최초 7일 동안 자주 액세스하는 대용량 파일을 저장합니다. 7일이 지난 후에는 최대 24시간 안에 파일을 복원하여 액세스할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129714-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "기존 데이터 센터의 SMB 파일 서버에 저장된 파일을 7일 동안은 자주 액세스하고, 이후에는 장기 보관이 필요하나 24시간 내 복원이 가능한 구조를 구현해야 합니다. Amazon S3 File Gateway를 사용하면 SMB 프로토콜과 S3를 직접 연결해 데이터를 투명하게 업로드할 수 있으며, 7일 후 S3 Glacier Deep Archive로 전환함으로써 비용을 절감하면서 24시간 이내에 파일을 복원할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "SMB 파일 서버",
      "7일 후 보관",
      "24시간 내 복원",
      "S3 Glacier Deep Archive"
    ],
    "Terms": [
      "SMB",
      "AWS DataSync",
      "Amazon S3 File Gateway",
      "Amazon FSx File Gateway",
      "S3 Lifecycle policy",
      "S3 Glacier Deep Archive",
      "S3 Glacier Flexible Retrieval",
      "Amazon S3"
    ],
    "SelectA": "SMB 파일 서버에서 생성된 지 7일이 지난 데이터를 AWS로 복사하기 위해 AWS DataSync를 사용합니다.",
    "SelectA_Commentary": "단순히 DataSync만 사용하면 파일을 AWS로 가져올 순 있으나, 별도의 장기 보관 전략이나 자동 전환 정책을 제공하지 않아 요구사항을 모두 충족하기 어렵습니다.",
    "SelectB": "Amazon S3 File Gateway를 생성하여 회사의 스토리지 공간을 확장합니다. 7일 후 해당 데이터를 S3 Glacier Deep Archive로 전환하는 S3 Lifecycle 정책을 만듭니다.",
    "SelectB_Commentary": "SMB와 바로 연동되는 S3 File Gateway를 통해 파일을 S3로 자동 업로드하고, Lifecycle 정책으로 7일 후 저비용 Glacier Deep Archive로 전환해 24시간 이내 복원을 보장하므로 요구사항에 가장 적합한 솔루션입니다.",
    "SelectC": "Amazon FSx File Gateway를 생성하여 회사의 스토리지 공간을 확장합니다. 7일 후 데이터를 전환하는 Amazon S3 Lifecycle 정책을 만듭니다.",
    "SelectC_Commentary": "FSx File Gateway는 SMB 대신 NFS 기반으로 동작할 수 있으나, S3로 직접 연결되어 Lifecycle 정책에서 Deep Archive까지 자동 전환하기에는 제한이 있어 요구사항을 제대로 충족하지 못합니다.",
    "SelectD": "각 사용자에게 Amazon S3에 대한 액세스를 구성합니다. 7일 후 해당 데이터를 S3 Glacier Flexible Retrieval로 전환하는 S3 Lifecycle 정책을 만듭니다.",
    "SelectD_Commentary": "단순 사용 권한 설정만으로는 파일을 SMB에서 S3로 효율적으로 전송하기 어렵고, Glacier Flexible Retrieval보다는 Deep Archive가 더 저렴하면서 24시간 내 복원을 지원하기 때문에 요구사항에 최적화되지 못합니다.",
    "Question_Description_recommedations": [
      "Q49",
      "Q997",
      "Q630",
      "Q930",
      "Q794"
    ],
    "SelectA_recommedations": [
      "Q918",
      "Q673",
      "Q719"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q415",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q23",
      "Q829"
    ],
    "SelectD_recommedations": [
      "Q285",
      "Q829",
      "Q606"
    ]
  },
  {
    "Question_Number": "Q674",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 Auto Scaling group으로 웹 애플리케이션을 운영하고 있습니다. 해당 애플리케이션은 Amazon RDS for PostgreSQL DB 인스턴스에서 실행되는 데이터베이스를 사용합니다. 트래픽이 증가하면 애플리케이션 성능이 저하되며, 특히 높은 트래픽 기간 동안 데이터베이스에 매우 무거운 읽기 부하가 발생합니다. 이러한 성능 문제를 해결하기 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까? (2개를 고르세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129716-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "읽기 집중 부하를 분산하기 위해서는 Amazon RDS for PostgreSQL의 read replica를 사용하고, 자주 조회되는 데이터를 캐싱할 수 있는 Amazon ElastiCache를 적용해 성능을 높이는 것이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Auto Scaling group",
      "read replica",
      "Amazon ElastiCache",
      "무거운 읽기 로드",
      "성능 문제"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon RDS for PostgreSQL",
      "DB instance",
      "read replica",
      "Amazon ElastiCache cluster",
      "Multi-AZ DB instance"
    ],
    "SelectA": "Turn on auto scaling for the DB instance.",
    "SelectA_Commentary": "RDS에는 직접적인 auto scaling 기능이 없어 적절한 해결책이 아닙니다.",
    "SelectB": "Create a read replica for the DB instance. Configure the application to send read traffic to the read replica.",
    "SelectB_Commentary": "read replica를 통해 읽기 부하를 분산하고 DB의 성능 병목을 완화할 수 있습니다.",
    "SelectC": "Convert the DB instance to a Multi-AZ DB instance deployment. Configure the application to send read traffic to the standby DB instance.",
    "SelectC_Commentary": "Multi-AZ는 장애 대비구성이며, standby로부터 읽기가 불가능해 읽기 부하 감소에 도움이 되지 않습니다.",
    "SelectD": "Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster.",
    "SelectD_Commentary": "ElastiCache를 사용해 자주 조회되는 데이터를 캐싱하면 DB의 읽기 부하를 줄이고 성능을 높일 수 있습니다.",
    "SelectE": "Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance.",
    "SelectE_Commentary": "애플리케이션과 DB를 가까운 AZ에 배치해도 근본적인 읽기 부하 문제는 해결되지 않습니다.",
    "Question_Description_recommedations": [
      "Q386",
      "Q726",
      "Q910",
      "Q193",
      "Q461"
    ],
    "SelectA_recommedations": [
      "Q578",
      "Q95",
      "Q177"
    ],
    "SelectB_recommedations": [
      "Q247",
      "Q337",
      "Q95"
    ],
    "SelectC_recommedations": [
      "Q633",
      "Q999",
      "Q90"
    ],
    "SelectD_recommedations": [
      "Q38",
      "Q481",
      "Q461"
    ],
    "SelectE_recommedations": [
      "Q461",
      "Q674",
      "Q130"
    ]
  },
  {
    "Question_Number": "Q675",
    "Question_Description": "한 회사가 애플리케이션을 운영하기 위해 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용하고 있습니다. 해당 회사는 규정 준수를 위해 매일 각 EBS 볼륨 스냅샷을 한 번씩 생성합니다. 회사는 EBS 볼륨 스냅샷이 실수로 삭제되는 것을 방지할 수 있는 아키텍처를 구현하려고 합니다. 스토리지 관리자 사용자의 관리자 권한을 변경하지 않으면서, 관리 부담을 최소화해야 합니다. 이러한 요구사항을 가장 적은 관리 노력으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129717-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EBS 스냅샷이 실수로 삭제되는 상황을 방지하면서 기존 사용자의 관리자 권한은 그대로 유지해야 하는 보안·데이터 보호 요구사항에 대한 솔루션을 묻습니다. 스냅샷에 태그를 부여하고 Recycle Bin 보존 규칙을 설정하면, 사용자가 스냅샷을 삭제해도 즉시 영구 삭제되지 않고 보존 기간 동안 복구할 수 있어 최소한의 관리 노력으로 실수 삭제를 방지할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "EBS 스냅샷",
      "규정 준수",
      "실수로 인한 삭제 방지",
      "Recycle Bin",
      "보존 규칙"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EBS Snapshot",
      "IAM role",
      "IAM policy",
      "AWS CLI",
      "Recycle Bin"
    ],
    "SelectA": "스냅샷 삭제 권한이 있는 IAM role을 생성하고 새 EC2 인스턴스에 연결합니다. 새 인스턴스에서 AWS CLI를 사용하여 스냅샷을 삭제합니다.",
    "SelectA_Commentary": "스냅샷 삭제 권한을 따로 관리해야 하고, EC2 인스턴스를 추가로 운영해야 하므로 관리가 복잡해집니다. 목적은 ‘실수 삭제 방지’인데, 이 방법은 추가 권한 분리 외에 보호 기능이 부족합니다.",
    "SelectB": "스냅샷 삭제를 거부하는 IAM policy를 생성하여 스토리지 관리자 사용자에게 연결합니다.",
    "SelectB_Commentary": "스냅샷 삭제를 전면적으로 막아버리면 스토리지 관리자 사용자의 기존 권한을 변경하게 됩니다. 문제의 요구사항은 관리자 권한을 유지하는 것이므로 적합하지 않습니다.",
    "SelectC": "스냅샷에 태그를 추가합니다. 해당 태그가 있는 EBS 스냅샷에 대해서 Recycle Bin에 보존 규칙을 생성합니다.",
    "SelectC_Commentary": "Delete 명령을 하더라도 스냅샷이 Recycle Bin에 일시적으로 보관되어 이후 복원할 수 있습니다. 관리자 권한을 바꾸지 않고 실수 삭제 방지를 달성할 수 있어 효율적입니다.",
    "SelectD": "EBS 스냅샷을 Lock하여 삭제를 방지합니다.",
    "SelectD_Commentary": "Lock 기능이 활성화되면 스냅샷 삭제를 막을 수 있으나, 실제 운영에서 Recycle Bin과 달리 세부 관리와 설정 절차가 더 복잡하거나 제한적일 수 있어 최소 관리 노력 측면에서는 덜 효율적입니다.",
    "Question_Description_recommedations": [
      "Q410",
      "Q329",
      "Q998",
      "Q453",
      "Q17"
    ],
    "SelectA_recommedations": [
      "Q494",
      "Q723",
      "Q96"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q476",
      "Q423"
    ],
    "SelectC_recommedations": [
      "Q689",
      "Q44",
      "Q825"
    ],
    "SelectD_recommedations": [
      "Q689",
      "Q122",
      "Q665"
    ]
  },
  {
    "Question_Number": "Q676",
    "Question_Description": "한 회사에서 Network Load Balancer, Auto Scaling group, Amazon EC2 인스턴스, 데이터베이스를 Amazon VPC에 배포하여 사용하는 애플리케이션이 있습니다. 이 회사는 Amazon VPC 내 네트워크 인터페이스에서 발생하는 트래픽(수신 및 송신) 정보를 거의 실시간으로 수집하고 싶어 합니다. 또한 이 정보를 Amazon OpenSearch Service로 전송하여 분석하려고 합니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129718-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon VPC의 트래픽 정보를 실시간에 가깝게 수집하여 Amazon OpenSearch Service로 전달하는 방안을 찾는 것입니다. VPC Flow Logs를 Amazon CloudWatch Logs로 전송한 후 Amazon Kinesis Data Firehose를 통해 손쉽고 빠르게 OpenSearch Service로 스트리밍할 수 있습니다. CloudTrail은 주로 관리 이벤트를 캡처하는 서비스이므로 부적절하며, Kinesis Data Streams 대신 Firehose를 사용하면 별도 처리 없이 직접 OpenSearch Service로 적재할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "VPC Flow Logs",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis Data Firehose",
      "Amazon OpenSearch Service",
      "네트워크 트래픽 로그"
    ],
    "Terms": [
      "Network Load Balancer",
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon VPC",
      "VPC Flow Logs",
      "Amazon CloudWatch Logs",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "Amazon OpenSearch Service",
      "AWS CloudTrail"
    ],
    "SelectA": "Amazon CloudWatch Logs에 로그 그룹을 생성하고, VPC Flow Logs를 해당 로그 그룹으로 전송합니다. Amazon Kinesis Data Streams를 사용해 이 로그를 OpenSearch Service로 스트리밍합니다.",
    "SelectA_Commentary": "Kinesis Data Streams는 사용자가 직접 소비자를 구성해야 하므로 추가 관리가 필요해, 간단하게 OpenSearch Service로 전송하기엔 최적이 아닙니다.",
    "SelectB": "Amazon CloudWatch Logs에 로그 그룹을 생성하고, VPC Flow Logs를 해당 로그 그룹으로 전송합니다. Amazon Kinesis Data Firehose를 사용해 이 로그를 OpenSearch Service로 스트리밍합니다.",
    "SelectB_Commentary": "가장 적합한 솔루션입니다. Kinesis Data Firehose는 별도 코드 작성 없이 거의 실시간으로 CloudWatch Logs 데이터를 OpenSearch Service로 전송합니다.",
    "SelectC": "AWS CloudTrail을 만들고, VPC Flow Logs가 해당 트레일로 전송되도록 설정합니다. Amazon Kinesis Data Streams를 사용해 이 로그를 OpenSearch Service로 스트리밍합니다.",
    "SelectC_Commentary": "CloudTrail은 API 호출 등의 로그를 수집하는 서비스이므로 네트워크 트래픽용으로는 적절하지 않습니다.",
    "SelectD": "AWS CloudTrail을 만들고, VPC Flow Logs가 해당 트레일로 전송되도록 설정합니다. Amazon Kinesis Data Firehose를 사용해 이 로그를 OpenSearch Service로 스트리밍합니다.",
    "SelectD_Commentary": "마찬가지로 CloudTrail은 목적에 맞지 않으며, VPC Flow Logs는 CloudWatch Logs로 보내는 것이 일반적인 구성입니다.",
    "Question_Description_recommedations": [
      "Q998",
      "Q35",
      "Q792",
      "Q135",
      "Q1016"
    ],
    "SelectA_recommedations": [
      "Q676",
      "Q27",
      "Q211"
    ],
    "SelectB_recommedations": [
      "Q676",
      "Q27",
      "Q748"
    ],
    "SelectC_recommedations": [
      "Q676",
      "Q451",
      "Q942"
    ],
    "SelectD_recommedations": [
      "Q676",
      "Q942",
      "Q451"
    ]
  },
  {
    "Question_Number": "Q677",
    "Question_Description": "한 회사가 프로덕션 Amazon EKS 클러스터에서 실행될 애플리케이션을 개발하고 있습니다. 해당 EKS 클러스터는 관리형 노드 그룹을 사용하며 On-Demand Instances로 구성되어 있습니다. 회사는 개발 작업을 위한 별도의 EKS 클러스터가 필요하며, 이 개발 클러스터는 애플리케이션의 복원력을 시험하기 위해 가끔만 사용될 것입니다. 모든 노드는 EKS 클러스터에서 관리되어야 하며, 가능한 한 비용 효율적이어야 합니다. 다음 중 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129827-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 큰 비용을 들이지 않고도 개발 환경을 구축하는 방법을 묻습니다. 개발 클러스터는 사용 빈도가 낮고, 모든 노드를 EKS가 직접 관리해야 하므로 Spot Instances만 사용하는 관리형 노드 그룹이 가장 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "개발 클러스터",
      "비용 효율성",
      "Spot Instances",
      "On-Demand Instances",
      "관리형 노드 그룹",
      "Amazon EKS"
    ],
    "Terms": [
      "Amazon EKS",
      "Managed Node Group",
      "On-Demand Instances",
      "Spot Instances",
      "Amazon EC2 Auto Scaling",
      "User Data"
    ],
    "SelectA": "Spot Instances만으로 구성된 관리형 노드 그룹을 생성합니다.",
    "SelectA_Commentary": "개발 클러스터를 가끔만 사용하는 경우, Spot Instances가 On-Demand 대비 매우 저렴하므로 비용을 크게 절감할 수 있습니다.",
    "SelectB": "관리형 노드 그룹 두 개를 생성합니다. 하나는 On-Demand Instances로, 다른 하나는 Spot Instances로 구성합니다.",
    "SelectB_Commentary": "두 가지 인스턴스 유형을 혼합하면 경쟁 가격 변화에 대응 가능하지만, 개발 클러스터가 적은 빈도로 사용되는 것을 감안하면 굳이 On-Demand가 필요하지 않아 비용만 증가합니다.",
    "SelectC": "Spot Instances를 사용하는 Auto Scaling group을 만들고, User Data로 EKS 노드 등록을 구성합니다.",
    "SelectC_Commentary": "Auto Scaling group과 User Data를 통한 직접 구성은 관리형 노드 그룹에 비해 추가 설정과 운영 부담이 있어 요구사항인 ‘EKS에서 모든 노드 관리’를 간소화하는 데 비효율적입니다.",
    "SelectD": "On-Demand Instances만으로 구성된 관리형 노드 그룹을 생성합니다.",
    "SelectD_Commentary": "On-Demand Instances는 안정적이지만, 사용 빈도가 낮은 개발 환경에서는 과도한 비용이 발생하므로 적절한 솔루션이 아닙니다.",
    "Question_Description_recommedations": [
      "Q591",
      "Q1013",
      "Q1008",
      "Q867",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q767",
      "Q49",
      "Q630"
    ],
    "SelectB_recommedations": [
      "Q300",
      "Q1013",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q677",
      "Q591",
      "Q937"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q1008",
      "Q424"
    ]
  },
  {
    "Question_Number": "Q678",
    "Question_Description": "한 회사가 Amazon S3에 민감한 데이터를 저장하고 있습니다. 솔루션스 아키텍트는 암호화 솔루션을 만들어야 합니다. 회사는 암호화되어야 하는 모든 데이터에 대해, 최소한의 노력으로 키 생성, 로테이션, 사용 중지(비활성화)를 완전히 제어할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129719-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장하는 민감한 데이터에 대해 키 생성, 로테이션, 비활성화를 모두 제어해야 할 때 어떤 암호화 방식을 사용해야 하는지를 묻습니다. 고객 관리형 키를 사용하면 키의 라이프사이클을 직접 관리할 수 있어 요구사항을 충족합니다. 따라서 SelectB가 올바른 선택지입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 데이터",
      "암호화 솔루션",
      "키 생성",
      "로테이션",
      "비활성화",
      "Amazon S3",
      "AWS KMS",
      "SSE-KMS",
      "SSE-S3",
      "고객 관리형 키"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Key Management Service (AWS KMS)",
      "server-side encryption",
      "AWS managed key",
      "customer managed key",
      "SSE-KMS",
      "SSE-S3",
      "Amazon EC2"
    ],
    "SelectA": "Amazon S3 managed encryption keys(SSE-S3)를 사용하는 기본 server-side encryption으로 민감한 데이터를 저장합니다.",
    "SelectA_Commentary": "SSE-S3는 AWS가 키를 전적으로 관리하므로 사용자가 키 생성·로테이션·비활성화를 직접 제어할 수 없습니다.",
    "SelectB": "AWS Key Management Service(AWS KMS)를 사용해 고객 관리형 키를 생성하고, 해당 키로 SSE-KMS 방식으로 S3 객체를 암호화합니다.",
    "SelectB_Commentary": "고객 관리형 키를 사용하면 조직이 키 생성부터 로테이션, 비활성화까지 모두 제어할 수 있어 요구사항을 만족합니다.",
    "SelectC": "AWS Key Management Service(AWS KMS)를 사용해 AWS 관리형 키를 생성하고, 해당 키로 SSE-KMS 방식으로 S3 객체를 암호화합니다.",
    "SelectC_Commentary": "AWS 관리형 키는 AWS가 관리하므로 키 로테이션 등 대부분의 작업을 사용자가 직접 제어하기 어렵습니다.",
    "SelectD": "Amazon EC2 인스턴스에 S3 객체를 다운로드한 뒤, 고객 관리형 키로 암호화하고 다시 S3에 업로드합니다.",
    "SelectD_Commentary": "직접 다운로드·재업로드하는 과정이 복잡하고 운영 부담이 크며, 키 관리와 로테이션을 간소화한다는 요구사항과 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q106",
      "Q44",
      "Q825",
      "Q154",
      "Q925"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q965",
      "Q862"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q640",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q640",
      "Q681",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q453",
      "Q612",
      "Q17"
    ]
  },
  {
    "Question_Number": "Q679",
    "Question_Description": "한 회사가 온프레미스 가상 머신(VM)을 AWS로 백업하고자 합니다. 회사의 백업 솔루션은 온프레미스 백업을 객체 형태로 Amazon S3 버킷에 내보냅니다. 이 S3 백업들은 30일 동안 보관되어야 하며, 30일이 지난 후에는 자동으로 삭제되어야 합니다. 이 요구사항을 충족하기 위해 어떤 조합의 단계가 필요합니까? (3개를 선택하세요.)",
    "Answer": "A,C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129721-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 30일 간 백업 파일을 안전하게 보관한 뒤 자동으로 삭제하여, 불필요한 보안 위험이나 저장 비용을 최소화하는 방법을 묻습니다. S3 Object Lock을 사용하면 객체를 일정 기간 동안 삭제 또는 수정할 수 없도록 보호할 수 있으며, 곁들여 Versioning과 Default Retention Period 설정을 통해 해당 기간 동안 데이터를 안전하게 유지한 후, 보관 기간이 지난 시점에 삭제가 가능해집니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "온프레미스 백업",
      "Amazon S3",
      "가상 머신",
      "30일 보관",
      "자동 삭제"
    ],
    "Terms": [
      "S3 Object Lock",
      "Object Versioning",
      "Default Retention Period",
      "S3 Lifecycle Policy",
      "Expire"
    ],
    "SelectA": "S3 버킷을 생성할 때 S3 Object Lock을 활성화합니다.",
    "SelectA_Commentary": "Object Lock을 통해 설정한 보존 기간 내에는 객체가 수정되거나 삭제되지 않도록 보장할 수 있어 필수적인 단계입니다.",
    "SelectB": "S3 버킷에 Object Versioning을 활성화합니다.",
    "SelectB_Commentary": "Object Lock을 사용하기 위해서는 버킷 버저닝이 필수 전제 조건이므로, 반드시 함께 설정되어야 합니다.",
    "SelectC": "해당 객체들에 대해 기본 보존 기간(30일)을 구성합니다.",
    "SelectC_Commentary": "Object Lock과 연동하여 30일 동안 데이터가 삭제되지 않도록 보장하는 설정으로, 특정 기간 동안 안전하게 백업 데이터를 보호해 줍니다.",
    "SelectD": "S3 Lifecycle 정책을 사용하여 객체를 30일 동안 보호합니다.",
    "SelectD_Commentary": "Lifecycle 정책만으로는 삭제 방지를 강제하지 못해, 무단 삭제를 막기 위한 Object Lock 필요성과 충돌합니다.",
    "SelectE": "S3 Lifecycle 정책을 구성하여 객체를 30일 후에 만료(expire) 처리합니다.",
    "SelectE_Commentary": "Object Lock을 사용하지 않는 시나리오에서 자동 삭제를 수행할 때 활용할 수 있지만, ‘30일 간 무단 삭제 방지’까지 요구하는 경우에는 충분하지 않습니다.",
    "SelectF": "백업 솔루션에서 객체에 30일 보존 태그를 지정하도록 설정합니다.",
    "SelectF_Commentary": "태그 기반 Lifecycle 정책을 구성할 때 유용하지만, 보존 기간 내 강제 보호를 위해서는 Object Lock과 Versioning 조합이 더 적절합니다.",
    "Question_Description_recommedations": [
      "Q862",
      "Q965",
      "Q109",
      "Q92",
      "Q678"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q825",
      "Q106"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q189",
      "Q122"
    ],
    "SelectD_recommedations": [
      "Q825",
      "Q44",
      "Q202"
    ],
    "SelectE_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectF_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q680",
    "Question_Description": "한 솔루션스 아키텍트는 파일을 Amazon S3 버킷에서 Amazon Elastic File System(Amazon EFS) 파일 시스템 및 다른 S3 버킷으로 복사해야 합니다. 파일은 지속적으로 복사되어야 하며, 원본 S3 버킷에는 계속 새로운 파일이 추가됩니다. 이미 복사된 파일은 원본 파일이 변경되는 경우에만 덮어써야 합니다. 가장 적은 운영 오버헤드로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129722-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷의 데이터를 EFS와 다른 S3 버킷으로 최소한의 운영 오버헤드로 동기화하는 방법을 묻습니다. AWS DataSync를 사용하면 소스 변경 시에만 데이터를 전송하는 설정을 통해 중복 복사를 방지하고, 자동화된 작업으로 지속적인 동기화를 구현할 수 있어 관리 부담이 매우 낮습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "S3 버킷",
      "Amazon EFS",
      "지속적 복사",
      "운영 오버헤드 최소화",
      "원본 파일 변경 시 덮어쓰기"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "Amazon Elastic File System (Amazon EFS)",
      "S3 Event Notification",
      "AWS Lambda",
      "Amazon EC2"
    ],
    "SelectA": "AWS DataSync 위치를 대상 S3 버킷과 EFS 파일 시스템 각각에 대해 생성하고, 두 위치를 대상으로 하는 태스크를 만듭니다. 전송 모드는 변경된 데이터만 전송하도록 설정합니다.",
    "SelectA_Commentary": "DataSync를 이용해 변경된 파일만 전송하면 불필요한 데이터 이동을 줄이고 자동화된 방식으로 연속 복사가 가능해 운영 오버헤드가 가장 낮습니다.",
    "SelectB": "AWS Lambda 함수를 생성하고, 함수에 EFS 파일 시스템을 마운트합니다. Amazon S3에서 파일이 생성되거나 변경될 때 S3 Event Notification으로 함수를 호출하도록 설정합니다. 함수를 통해 파일을 EFS 및 대상 S3 버킷으로 복사합니다.",
    "SelectB_Commentary": "Lambda를 통한 직접 복사는 가능하지만, EFS 마운팅 및 이벤트 처리를 매번 관리해야 하므로 운영 부담이 더 큽니다.",
    "SelectC": "AWS DataSync 위치를 대상 S3 버킷과 EFS 파일 시스템 각각에 대해 생성하고, 두 위치를 대상으로 하는 태스크를 만듭니다. 전송 모드는 모든 데이터를 전송하도록 설정합니다.",
    "SelectC_Commentary": "항상 모든 데이터를 전송하면 네트워크와 리소스가 불필요하게 사용되어 오버헤드가 증가합니다.",
    "SelectD": "가상 사설 클라우드(VPC) 내 EFS 파일 시스템과 같은 곳에 Amazon EC2 인스턴스를 실행하고, EFS 파일 시스템을 마운트합니다. 원본 S3 버킷에서 변경된 객체를 대상 S3 버킷과 마운트된 EFS 파일 시스템으로 주기적으로 동기화하는 스크립트를 작성합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 직접 운영하고 스크립트를 관리해야 하므로 오버헤드와 유지보수 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q155",
      "Q672",
      "Q173",
      "Q547",
      "Q292"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q155",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q155",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q155",
      "Q672"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q695",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q681",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스를 사용하고, Amazon EBS 볼륨에 데이터를 저장하고 있습니다. 모든 데이터는 AWS Key Management Service(AWS KMS)로 암호화된 상태여야 하며, 회사는 암호화 키의 회전을 제어할 수 있어야 합니다. 또한 운영 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129723-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EBS 볼륨을 암호화 시나리오에서 키 회전을 직접 제어하여 보안 요구 사항을 충족하면서, 운영 오버헤드도 최소화하는 방법을 결정하는 내용입니다. Customer managed key를 사용하면 사용자가 필요에 따라 직접 키 회전을 설정할 수 있고, 복잡도가 크지 않아 요구 사항을 만족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon EBS",
      "AWS Key Management Service",
      "암호화",
      "키 회전",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Customer managed key",
      "AWS managed key",
      "External KMS key",
      "AWS owned key",
      "키 회전",
      "암호화",
      "AWS KMS"
    ],
    "SelectA": "고객이 직접 생성한 customer managed key를 생성하여 EBS 볼륨을 암호화합니다.",
    "SelectA_Commentary": "사용자가 키 회전을 직접 제어할 수 있으며, AWS에서 제공하는 자동 관리를 활용할 수 있어 요구사항을 만족하면서 운영 오버헤드도 낮습니다.",
    "SelectB": "AWS managed key로 EBS 볼륨을 암호화하고 자동 키 회전을 구성합니다.",
    "SelectB_Commentary": "AWS managed key는 AWS에서 자동으로 키를 관리해 편리하나, 키 회전 시점을 직접 통제하기 어렵고 사용자 지정 관리 권한이 제한됩니다.",
    "SelectC": "내부에서 생성한 KMS 키(외부에서 가져온 키 재료 사용)로 EBS 볼륨을 암호화합니다.",
    "SelectC_Commentary": "키 재료를 외부에서 직접 관리하므로 보안 통제는 확장되지만, 키 관리 작업이 복잡해져 운영 오버헤드가 크게 증가합니다.",
    "SelectD": "AWS owned key로 EBS 볼륨을 암호화합니다.",
    "SelectD_Commentary": "AWS가 소유한 키는 사용자가 키 관리나 회전을 제어할 수 없어 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q371",
      "Q793",
      "Q998",
      "Q640"
    ],
    "SelectA_recommedations": [
      "Q371",
      "Q689",
      "Q681"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q689",
      "Q645"
    ],
    "SelectC_recommedations": [
      "Q189",
      "Q665",
      "Q689"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q740",
      "Q689"
    ]
  },
  {
    "Question_Number": "Q682",
    "Question_Description": "회사는 Amazon EC2 인스턴스에서 데이터 암호화를 강제 적용해야 하는 솔루션이 필요합니다. 솔루션은 자동으로 암호화되지 않은 리소스를 식별하고, 검색 결과에 대해 컴플라이언스 정책을 적용해야 합니다. 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129724-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스에서 저장 데이터(암호화 at rest)를 강제 적용하려는 시나리오입니다. 핵심은 암호화되지 않은 Amazon EBS 볼륨을 자동으로 감지하고 수정하며, 운영 오버헤드가 최소화되어야 한다는 점입니다. IAM Policy로 암호화되지 않은 볼륨 생성을 사전에 방지하고, AWS Config와 AWS Systems Manager를 통한 자동 탐지 및 수정까지 지원하는 옵션(A)이 가장 효율적이며 간단한 방법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "암호화",
      "Amazon EC2",
      "Amazon EBS",
      "자동 컴플라이언스"
    ],
    "Terms": [
      "IAM Policy",
      "AWS Config",
      "AWS Systems Manager",
      "AWS Key Management Service (AWS KMS)",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon Macie",
      "Amazon Inspector",
      "AWS Systems Manager Automation"
    ],
    "SelectA": "IAM policy를 사용하여 사용자가 암호화된 Amazon EBS 볼륨만 생성하도록 허용합니다. AWS Config와 AWS Systems Manager를 사용해 암호화되지 않은 EBS 볼륨을 자동으로 감지 및 수정합니다.",
    "SelectA_Commentary": "자동 탐지와 수정이 한번에 가능하며, 암호화되지 않은 볼륨 생성을 미리 차단해 운영 오버헤드가 가장 적습니다.",
    "SelectB": "AWS Key Management Service(AWS KMS)를 사용해 암호화된 Amazon EBS 볼륨에 대한 액세스를 관리합니다. AWS Lambda와 Amazon EventBridge를 사용해 암호화되지 않은 EBS 볼륨을 자동으로 감지하고 수정합니다.",
    "SelectB_Commentary": "Lambda와 EventBridge 설정이 추가되어 관리가 복잡해지며, 암호화되지 않은 생성 자체를 사전에 막지 못합니다.",
    "SelectC": "Amazon Macie를 사용하여 암호화되지 않은 Amazon EBS 볼륨을 감지합니다. AWS Systems Manager Automation 규칙을 사용해 기존 및 신규 EBS 볼륨을 자동으로 암호화합니다.",
    "SelectC_Commentary": "Amazon Macie는 주로 데이터 분류와 이상 탐지에 특화되어 있어 EBS 암호화 정책 enforce에는 상대적으로 부적합합니다.",
    "SelectD": "Amazon Inspector를 사용하여 암호화되지 않은 Amazon EBS 볼륨을 감지합니다. AWS Systems Manager Automation 규칙을 사용해 기존 및 신규 EBS 볼륨을 자동으로 암호화합니다.",
    "SelectD_Commentary": "Amazon Inspector는 주로 보안 취약점 스캔용으로, EBS 암호화 준수 확인에는 추가 구성이 필요해 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q100",
      "Q315",
      "Q329",
      "Q453",
      "Q480"
    ],
    "SelectA_recommedations": [
      "Q494",
      "Q681",
      "Q689"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q371",
      "Q640"
    ],
    "SelectC_recommedations": [
      "Q689",
      "Q675",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q689",
      "Q675",
      "Q805"
    ]
  },
  {
    "Question_Number": "Q683",
    "Question_Description": "한 회사가 다중 계층 온프레미스 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 단일 노드 MySQL database와 다중 노드 웹 tier로 구성되어 있습니다. 회사는 마이그레이션 시 애플리케이션에 대한 변경 사항을 최소화해야 하며, 마이그레이션 후 애플리케이션의 복원력을 향상시키는 것을 원합니다. 이러한 요구사항을 충족하기 위해 필요한 단계 조합은 무엇입니까? (두 가지를 고르세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129725-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 애플리케이션 구조를 크게 바꾸지 않으면서 AWS로 이전해 복원력(고가용성)을 높이는 최적의 방법을 찾는 것입니다. 정답은 (A)와 (C)로, 웹 tier는 Amazon EC2 + Application Load Balancer로 수평 확장을 용이하게 하고, 데이터베이스는 Amazon RDS Multi-AZ 배포로 구성해 장애 시 자동 장애 조치가 가능하도록 해줍니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "AWS 마이그레이션",
      "MySQL database",
      "다중 노드 웹 tier",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon RDS Multi-AZ",
      "복원력 향상"
    ],
    "Terms": [
      "MySQL database",
      "웹 tier",
      "Auto Scaling group",
      "Application Load Balancer",
      "Network Load Balancer",
      "Amazon RDS Multi-AZ",
      "AWS Lambda",
      "Amazon DynamoDB"
    ],
    "SelectA": "웹 tier를 Amazon EC2 인스턴스로 구성한 Auto Scaling group 뒤의 Application Load Balancer로 마이그레이션합니다.",
    "SelectA_Commentary": "EC2/ALB 구조는 기존 서버 기반 웹 tier를 그대로 옮기면서 확장성과 복원력을 강화하기에 적합합니다.",
    "SelectB": "database를 Network Load Balancer 뒤에 있는 Amazon EC2 인스턴스의 Auto Scaling group으로 마이그레이션합니다.",
    "SelectB_Commentary": "Network Load Balancer를 통한 DB 구성은 MySQL용으로 적합하지 않고, 자동 장애 조치 기능도 부족해 복원력 향상에 어려움이 있습니다.",
    "SelectC": "database를 Amazon RDS Multi-AZ 배포로 마이그레이션합니다.",
    "SelectC_Commentary": "Amazon RDS Multi-AZ는 자동 장애 조치와 고가용성을 제공하므로 마이그레이션 후 복원력을 크게 높일 수 있습니다.",
    "SelectD": "웹 tier를 AWS Lambda function으로 마이그레이션합니다.",
    "SelectD_Commentary": "애플리케이션을 서버리스로 재설계해야 하므로 변경 범위가 커지며, 최소 변경 요건에 부합하지 않습니다.",
    "SelectE": "database를 Amazon DynamoDB table로 마이그레이션합니다.",
    "SelectE_Commentary": "Relational DB(MySQL)를 NoSQL(DynamoDB)로 전환하려면 애플리케이션에 큰 변화를 주어야 하므로 최소 변경 요구사항에 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q182",
      "Q114",
      "Q843",
      "Q236",
      "Q824"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q275",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q69",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q843",
      "Q845",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q351",
      "Q8"
    ],
    "SelectE_recommedations": [
      "Q845",
      "Q1002",
      "Q78"
    ]
  },
  {
    "Question_Number": "Q684",
    "Question_Description": "한 회사가 온프레미스에서 AWS로 웹 애플리케이션을 마이그레이션하려고 합니다. 회사는 eu-central-1 리전 근처에 위치해 있지만, 규제 때문에 일부 애플리케이션은 eu-central-1 리전에서 실행할 수 없습니다. 또한 단일 자릿수 밀리초(싱글 디짓 밀리초)의 레이턴시를 달성하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/129726-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 특정 리전(eu-central-1)에 규제로 인해 애플리케이션을 배포할 수 없는 상황에서, 여전히 단일 자릿수 밀리초라는 매우 낮은 레이턴시를 달성해야 하는 시나리오입니다. AWS Local Zones는 애플리케이션 워크로드를 사용자와 물리적으로 가까운 위치에 배치해 초저지연을 실현하도록 도와주는 서비스입니다. 따라서 원본 리전으로 배포할 수 없는 규제 이슈를 피해, 최종적으로 단일 자릿수 밀리초의 네트워크 레이턴시를 얻을 수 있는 최적의 접근 방안은 Local Zones를 활용해 VPC를 연장하는 것입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.4"
    ],
    "Keywords": [
      "웹 애플리케이션 마이그레이션",
      "eu-central-1 규제",
      "싱글 디짓 밀리초 레이턴시",
      "AWS Local Zones",
      "VPC 연장"
    ],
    "Terms": [
      "AWS Local Zones",
      "VPC",
      "Amazon CloudFront",
      "AWS Wavelength Zones"
    ],
    "SelectA": "애플리케이션을 eu-central-1에 배포합니다. eu-central-1에서 Amazon CloudFront 엣지 로케이션으로 VPC를 확장합니다.",
    "SelectA_Commentary": "규제로 인해 eu-central-1 리전에 배포가 불가능하므로 적합하지 않습니다.",
    "SelectB": "애플리케이션을 AWS Local Zones에 배포하고, eu-central-1에서 Local Zone으로 VPC를 연장합니다.",
    "SelectB_Commentary": "AWS Local Zones를 통해 로컬 인프라 환경에서 초저지연을 제공할 수 있으므로 규제와 레이턴시 요구사항을 모두 만족합니다.",
    "SelectC": "애플리케이션을 eu-central-1에 배포합니다. eu-central-1에서 Amazon CloudFront의 리전별 엣지 캐시로 VPC를 확장합니다.",
    "SelectC_Commentary": "이 역시 eu-central-1 리전 사용이 전제로, 규제를 충족하지 않습니다.",
    "SelectD": "애플리케이션을 AWS Wavelength Zones에 배포하고, eu-central-1에서 Wavelength Zone으로 VPC를 연장합니다.",
    "SelectD_Commentary": "AWS Wavelength Zones는 이동통신사 5G 네트워크에 통합된 서비스로, 기존 온프레미스 환경에서의 마이그레이션 목적에는 부적합합니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q865",
      "Q443",
      "Q738",
      "Q737"
    ],
    "SelectA_recommedations": [
      "Q684",
      "Q280",
      "Q737"
    ],
    "SelectB_recommedations": [
      "Q684",
      "Q474",
      "Q686"
    ],
    "SelectC_recommedations": [
      "Q684",
      "Q280",
      "Q686"
    ],
    "SelectD_recommedations": [
      "Q684",
      "Q474",
      "Q686"
    ]
  },
  {
    "Question_Number": "Q685",
    "Question_Description": "한 회사의 전자상거래 웹사이트는 트래픽이 예측 불가능하며, AWS Lambda 함수를 사용하여 사설 Amazon RDS for PostgreSQL DB 인스턴스에 직접 액세스하고 있습니다. 회사는 데이터베이스 성능을 예측 가능하게 유지하고, Lambda 함수가 동시에 너무 많은 연결을 생성하여 데이터베이스에 과부하가 일어나지 않도록 하고 싶어 합니다. 이를 위해 솔루션스 아키텍트는 어떤 조치를 취해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133297-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 예측 불가능한 트래픽 상황에서 Lambda 함수가 RDS 인스턴스에 연결할 때 발생할 수 있는 연결 과부하를 막고, 안정적인 데이터베이스 성능을 유지하는 방법을 묻습니다. RDS Proxy를 사용하면 다수의 Lambda 함수 연결을 효과적으로 풀링하고 관리하여 과도한 연결로 인한 부하를 줄일 수 있으며, DB 인스턴스를 사설망에서 안전하게 보호하려면 Lambda도 VPC 내부에서 동작해야 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Lambda 함수",
      "RDS Proxy",
      "예측 가능한 DB 성능",
      "데이터베이스 연결 과부하 방지"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "AWS Lambda",
      "RDS Proxy",
      "VPC",
      "RDS custom endpoint"
    ],
    "SelectA": "클라이언트 드라이버를 RDS custom endpoint로 지정하고 Lambda 함수를 VPC 내부에 배포합니다.",
    "SelectA_Commentary": "RDS custom endpoint는 연결 관리를 위한 옵션이 아니며, 데이터베이스 연결 수 제한을 효과적으로 제어하기 어렵습니다.",
    "SelectB": "클라이언트 드라이버를 RDS proxy endpoint로 지정하고 Lambda 함수를 VPC 내부에 배포합니다.",
    "SelectB_Commentary": "RDS Proxy는 Lambda의 연결을 효율적으로 풀링하고 관리하여 DB 성능 저하를 방지하며, 사설 RDS 인스턴스에 접근하려면 Lambda도 VPC 내부에 있어야 합니다.",
    "SelectC": "클라이언트 드라이버를 RDS custom endpoint로 지정하고 Lambda 함수를 VPC 외부에 배포합니다.",
    "SelectC_Commentary": "VPC 외부 Lambda 함수는 사설 RDS에 접근할 수 없고, 연결 과부하 문제도 해결할 수 없습니다.",
    "SelectD": "클라이언트 드라이버를 RDS proxy endpoint로 지정하고 Lambda 함수를 VPC 외부에 배포합니다.",
    "SelectD_Commentary": "사설 RDS이므로 VPC 외부에서 접근할 수 없으며, 보안 그룹 및 서브넷 연결 설정이 불가능합니다.",
    "Question_Description_recommedations": [
      "Q726",
      "Q379",
      "Q376",
      "Q590",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q661",
      "Q269",
      "Q193"
    ],
    "SelectB_recommedations": [
      "Q661",
      "Q269",
      "Q193"
    ],
    "SelectC_recommedations": [
      "Q661",
      "Q269",
      "Q193"
    ],
    "SelectD_recommedations": [
      "Q661",
      "Q269",
      "Q193"
    ]
  },
  {
    "Question_Number": "Q686",
    "Question_Description": "회사는 애플리케이션을 개발 중이며, 애플리케이션 테스트에서 생성되는 데이터를 여러 온프레미스 위치에 저장하고 있습니다. 회사는 온프레미스 위치들을 AWS 클라우드의 AWS Region에 있는 VPC들과 연결해야 합니다. 향후 1년 동안 계정 수와 VPC 수가 늘어날 예정입니다. 네트워크 아키텍처는 새로운 연결을 관리하기 쉽게 만들어야 하며 확장성을 제공해야 합니다. 최소한의 관리 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132844-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 VPC와 온프레미스를 유연하게 연결하고 싶다면 Transit Gateway를 사용하는 것이 관리 오버헤드를 줄이고 확장성을 제공하는 가장 간단한 방법입니다. 선택지 C가 이를 충족하므로 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "온프레미스",
      "AWS Region",
      "VPC",
      "확장성",
      "네트워크 아키텍처",
      "Transit Gateway"
    ],
    "Terms": [
      "Transit Gateway",
      "VPC Peering",
      "VPN Connection",
      "Amazon EC2",
      "AWS Direct Connect",
      "VPN Attachments",
      "VPC Attachments"
    ],
    "SelectA": "VPC들 간의 Peering 연결을 설정하고, 온프레미스 위치와는 VPN 연결을 구성합니다.",
    "SelectA_Commentary": "VPC 피어링과 VPN을 각각 설정해야 하므로 연결 수가 늘어날 때마다 설정이 복잡해져서 관리 오버헤드가 크게 증가합니다.",
    "SelectB": "Amazon EC2 인스턴스를 실행하고, 해당 인스턴스에 VPN 소프트웨어를 설정하여 모든 VPC와 온프레미스 위치를 연결합니다.",
    "SelectB_Commentary": "EC2 인스턴스에 VPN 소프트웨어를 설치해 중계하는 방식은 단일 장애 지점이 될 수 있고, 추후 계정과 VPC가 늘어날 때 확장성과 운영 관리가 복잡합니다.",
    "SelectC": "Transit Gateway를 생성하고, VPC 연결을 위해 VPC Attachments를, 온프레미스 연결을 위해 VPN Attachments를 생성합니다.",
    "SelectC_Commentary": "Transit Gateway를 사용하면 여러 VPC와 온프레미스 연결을 중앙에서 간단하게 관리할 수 있고 확장이 용이해 관리 오버헤드가 최소화됩니다.",
    "SelectD": "온프레미스 위치와 중앙 VPC 간에 AWS Direct Connect 연결을 생성하고, 다른 VPC들은 Peering 연결을 통해 중앙 VPC와 연결합니다.",
    "SelectD_Commentary": "중앙 VPC에 Direct Connect를 연결한 뒤에도 다른 VPC와의 피어링 구성이 계속 필요해 관리가 복잡해지고, 계정이 늘어나면 확장성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q474",
      "Q361",
      "Q443",
      "Q547",
      "Q738"
    ],
    "SelectA_recommedations": [
      "Q686",
      "Q600",
      "Q474"
    ],
    "SelectB_recommedations": [
      "Q686",
      "Q857",
      "Q938"
    ],
    "SelectC_recommedations": [
      "Q957",
      "Q686",
      "Q734"
    ],
    "SelectD_recommedations": [
      "Q734",
      "Q686",
      "Q600"
    ]
  },
  {
    "Question_Number": "Q687",
    "Question_Description": "한 회사가 AWS를 사용하고 있으며, 매달 제조 공정에 필요한 리소스를 예측할 수 있는 솔루션이 필요합니다. 이 솔루션은 현재 Amazon S3 버킷에 보관된 과거 데이터를 활용해야 합니다. 이 회사는 기계 학습(ML) 경험이 없으며, 모델 학습과 예측을 위해 관리형 서비스를 사용하려고 합니다. 이러한 요구사항을 충족하는 조합은 무엇입니까? (두 개 선택)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132845-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ML 경험이 없는 조직이 빠르고 쉽게 월별 리소스 예측을 할 수 있도록 관리형 서비스를 활용하는 방법을 묻습니다. Amazon Forecast는 시계열 예측 전용의 완전 관리형 서비스이므로, 과거 데이터 학습 및 예측에 손쉽게 활용할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "관리형 서비스",
      "월별 리소스 예측",
      "제조 공정",
      "과거 데이터",
      "Amazon Forecast",
      "Amazon SageMaker"
    ],
    "Terms": [
      "Amazon SageMaker",
      "Amazon Forecast",
      "AWS Lambda",
      "Function URL",
      "Amazon S3",
      "Predictor",
      "모델 학습"
    ],
    "SelectA": "Amazon SageMaker 모델을 배포하고, 추론을 위해 SageMaker 엔드포인트를 생성합니다.",
    "SelectA_Commentary": "SageMaker는 강력한 서비스이지만 설정과 ML 지식이 어느 정도 필요해, 초보자에게는 다소 복잡할 수 있습니다.",
    "SelectB": "Amazon SageMaker를 사용하여 S3 버킷에 있는 과거 데이터를 이용해 모델을 학습시킵니다.",
    "SelectB_Commentary": "SageMaker에서 직접 학습을 수행하려면 ML 지식이 필요한 편이며, 완전 관리형 예측보다는 설정할 요소가 많습니다.",
    "SelectC": "AWS Lambda 함수에 Function URL을 구성하고, Amazon SageMaker 엔드포인트를 사용해 입력값 기반으로 예측을 생성합니다.",
    "SelectC_Commentary": "SageMaker 기반 예측 호출이므로 홈그라운드 수준의 ML 설정이 여전히 필요하며, 관리 부담이 있습니다.",
    "SelectD": "AWS Lambda 함수에 Function URL을 구성하고, Amazon Forecast predictor를 사용해 입력값 기반 예측을 생성합니다.",
    "SelectD_Commentary": "Amazon Forecast에서 이미 학습한 predictor를 간단한 API 호출로 사용 가능해, ML 경험이 없어도 손쉽게 예측을 수행할 수 있습니다.",
    "SelectE": "Amazon Forecast predictor를 생성하고, S3 버킷에 있는 과거 데이터를 사용해 학습시킵니다.",
    "SelectE_Commentary": "시계열 데이터 예측을 위한 완전 관리형 ML 서비스로, ML 배경지식 없이도 간단히 예측 모델을 만들 수 있습니다.",
    "Question_Description_recommedations": [
      "Q173",
      "Q155",
      "Q547",
      "Q501",
      "Q672"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q501",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q292"
    ],
    "SelectC_recommedations": [
      "Q576",
      "Q597",
      "Q175"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q175"
    ],
    "SelectE_recommedations": [
      "Q687",
      "Q501",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q688",
    "Question_Description": "한 회사가 AWS Organizations에서 여러 AWS 계정을 관리하고 있습니다. 이 회사는 AWS IAM Identity Center(AWS Single Sign-On)와 AWS Control Tower를 이미 계정에 구성해 두었습니다. 회사는 여러 계정에 걸쳐 사용자 권한을 관리하려고 합니다. 각 팀(개발자와 관리자)은 다른 권한이 필요하며, 새로 입사한 사용자가 발생해도 이 권한 구조에 편리하게 반영되어야 합니다. 가장 적은 운영 오버헤드로 이를 달성할 수 있는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132847-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 개발자와 관리자 팀의 접근 권한을 효율적으로 분리하여 관리하는 방법을 묻습니다. IAM Identity Center에서 그룹과 Permission Set을 통한 중앙 집중화로 신규 사용자에 대해서도 손쉽게 권한을 부여할 수 있기 때문에 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM Identity Center",
      "AWS Single Sign-On",
      "AWS Control Tower",
      "AWS Organizations",
      "개발자 권한",
      "관리자 권한",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "IAM Identity Center(AWS Single Sign-On)",
      "AWS Organizations",
      "AWS Control Tower",
      "IAM Policy",
      "Permission Set",
      "Developer Group",
      "Administrator Group"
    ],
    "SelectA": "각 계정마다 IAM Identity Center에서 개별 사용자를 생성합니다. 개발자와 관리자 그룹을 만들어, 해당 그룹에 사용자를 할당합니다. 그룹마다 세부 권한을 위한 커스텀 IAM 정책을 생성합니다.",
    "SelectA_Commentary": "각 계정별로 사용자와 그룹, 그리고 별도 정책을 관리해야 하므로 계정이 많아질수록 운영 오버헤드가 커집니다.",
    "SelectB": "각 계정마다 IAM Identity Center에서 개별 사용자를 생성합니다. 개발자와 관리자 그룹을 만들어, 해당 그룹에 사용자를 할당합니다. 세부 권한 부여를 위해 필요한 경우 각 사용자에 AWS 관리형 IAM 정책을 연결합니다.",
    "SelectB_Commentary": "사용자별로 AWS 관리형 정책을 직접 연결해야 하므로 유연성이 낮고, 사용자 수가 늘어나면 관리가 복잡해집니다.",
    "SelectC": "IAM Identity Center에 개별 사용자를 생성합니다. 개발자와 관리자 그룹을 만든 뒤, 각 그룹에 필요한 IAM 정책을 담은 새로운 Permission Set을 생성합니다. 해당 그룹을 적절한 계정에 연결하고, 그룹에 Permission Set을 할당합니다. 신규 인원이 합류하면 해당 그룹에 추가하기만 하면 됩니다.",
    "SelectC_Commentary": "그룹과 Permission Set을 통해 중앙에서 일관되게 관리하고, 새 사용자는 그룹에만 추가하면 되므로 운영 부담이 가장 적은 최적 해법입니다.",
    "SelectD": "IAM Identity Center에 개별 사용자를 생성합니다. 각 사용자에게 필요한 작업을 모두 포함한 IAM 정책으로 구성된 Permission Set을 만들고 할당합니다. 계정 내부에서 추가 권한이 필요하면 별도로 부여합니다. 새 사용자가 생길 때마다 IAM Identity Center에 사용자 계정을 등록하고 계정에 할당합니다.",
    "SelectD_Commentary": "사용자마다 Permission Set을 생성하고 추가 권한을 계정 내에서 재부여해야 해 중복 관리가 발생하며, 운영 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q668",
      "Q28",
      "Q750",
      "Q826",
      "Q981"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectB_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ]
  },
  {
    "Question_Number": "Q689",
    "Question_Description": "한 회사가 Amazon EBS 볼륨 암호화 전략을 표준화하고자 합니다. 또한 볼륨 암호화 확인 작업을 운영하는 데 필요한 비용과 설정 노력을 최소화하고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132849-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EBS 볼륨 암호화 여부를 쉽고 일관성 있게 확인할 수 있는 방법을 찾는 것입니다. AWS Config는 EBS 볼륨 암호화 상태를 자동으로 평가·감시할 수 있는 관리형 규칙을 제공하므로, 비용과 관리 부담을 최소화하며 표준화된 방식의 암호화 전략을 유지할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "EBS 볼륨 암호화",
      "표준화",
      "비용 최소화",
      "AWS Config",
      "관리형 규칙"
    ],
    "Terms": [
      "Amazon EBS",
      "Encryption",
      "AWS Config",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS Fargate",
      "AWS Identity and Access Management(IAM)",
      "AWS Cost Explorer"
    ],
    "SelectA": "EBS 볼륨 정보를 조회하고 암호화 여부를 확인하는 API 호출을 작성하여, Amazon EventBridge로 스케줄링된 AWS Lambda 함수가 해당 API를 실행하도록 합니다.",
    "SelectA_Commentary": "맞춤형 코드와 스케줄링 구성이 필요해 운영이 번거롭고, AWS Config가 제공하는 관리형 규칙에 비해 유지 비용과 설정 노력이 더 큽니다.",
    "SelectB": "EBS 볼륨 정보를 조회하고 암호화 여부를 확인하는 API 호출을 작성하여, AWS Fargate 태스크에서 해당 API를 실행합니다.",
    "SelectB_Commentary": "Fargate 환경 설정 및 응용 프로그램 배포가 필요해 추가 비용 및 관리 오버헤드가 발생하므로 간소화된 구성이 어렵습니다.",
    "SelectC": "IAM 정책을 통해 EBS 볼륨에 태그 사용을 요구하고, AWS Cost Explorer를 사용해 올바르지 않은 태그 리소스를 표시합니다. 태그가 없는 리소스를 수동으로 암호화합니다.",
    "SelectC_Commentary": "암호화 여부 확인보다는 태그 관리에 초점을 맞추어 완전한 암호화 검증 방안으로 적합하지 않습니다. 또 수동 과정이 필요해 운영이 복잡합니다.",
    "SelectD": "Amazon EBS 볼륨이 암호화되어 있는지 평가하고, 암호화되지 않은 볼륨에 플래그를 지정하도록 AWS Config 규칙을 생성합니다.",
    "SelectD_Commentary": "AWS Config의 관리형 규칙을 사용하면 자동으로 암호화 상태를 모니터링하고 바로 알림을 받을 수 있어, 비용과 구성 노력을 최소화하면서 안정적인 표준화 전략을 수행할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q831",
      "Q922",
      "Q313",
      "Q548",
      "Q682"
    ],
    "SelectA_recommedations": [
      "Q689",
      "Q34",
      "Q675"
    ],
    "SelectB_recommedations": [
      "Q689",
      "Q34",
      "Q675"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q689",
      "Q675",
      "Q492"
    ]
  },
  {
    "Question_Number": "Q690",
    "Question_Description": "한 회사는 정기적으로 GB 규모의 파일을 Amazon S3에 업로드합니다. 회사는 파일을 업로드한 뒤, Amazon EC2 Spot Instances 무리를 사용해 파일 형식을 트랜스코딩합니다. 온프레미스 데이터 센터에서 Amazon S3로 데이터를 업로드할 때와 Amazon S3에서 EC2 인스턴스로 데이터를 다운로드할 때 모두 처리량을 확장해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132852-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량 파일을 S3에 업로드하고 S3에서 EC2로 다운로드할 때 모두 높은 처리량을 확보해야 하는 상황입니다. 업로드 시에는 S3 Multipart Upload를 통해 파일을 분할하여 병렬 전송함으로써 처리량을 높일 수 있고, 다운로드 시에는 여러 byte-range를 병렬로 가져와 속도를 개선할 수 있습니다. 따라서 정답은 C와 D입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "GB 규모 파일",
      "S3 업로드 처리량 확장",
      "EC2 Spot Instances",
      "S3 다운로드 처리량 확장"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2 Spot Instances",
      "S3 Bucket Access Point",
      "S3 Multipart Upload",
      "byte-range fetch",
      "on-premises data center",
      "random prefix"
    ],
    "SelectA": "Use the S3 bucket access point instead of accessing the S3 bucket directly.",
    "SelectA_Commentary": "S3 Bucket Access Point는 보안과 액세스 관리를 간소화하지만, 업로드·다운로드 처리량 확장과는 직접적 관련이 적어 요구사항을 충족하기 어렵습니다.",
    "SelectB": "Upload the files into multiple S3 buckets.",
    "SelectB_Commentary": "여러 버킷에 분산해 업로드해도 추가적인 관리 부담이 생길 뿐, 업로드·다운로드 처리량 향상에 크게 기여하지 못합니다.",
    "SelectC": "Use S3 multipart uploads.",
    "SelectC_Commentary": "큰 파일을 여러 파트로 나누어 병렬 업로드함으로써 업로드 처리량을 크게 높일 수 있어 요구사항에 부합합니다.",
    "SelectD": "Fetch multiple byte-ranges of an object in parallel.",
    "SelectD_Commentary": "객체를 병렬로 다운받으면 다운로드 성능이 개선되어 요구사항을 충족합니다.",
    "SelectE": "Add a random prefix to each object when uploading the files.",
    "SelectE_Commentary": "이전에는 S3 파티션 최적화를 위해 무작위 prefix를 권장했지만, 현재는 자동 확장 기능이 있어 처리량 문제를 직접 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q818",
      "Q594",
      "Q257",
      "Q155",
      "Q680"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q672",
      "Q501",
      "Q43"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q672",
      "Q43"
    ],
    "SelectD_recommedations": [
      "Q77",
      "Q704",
      "Q496"
    ],
    "SelectE_recommedations": [
      "Q501",
      "Q2",
      "Q166"
    ]
  },
  {
    "Question_Number": "Q691",
    "Question_Description": "한 솔루션스 아키텍트가 여러 Availability Zone에 걸쳐 배포된 웹 애플리케이션을 위한 공유 스토리지 솔루션을 설계하고 있습니다. 웹 애플리케이션은 Amazon EC2 인스턴스(이하 EC2)로 구성된 Auto Scaling group에서 실행됩니다. 회사는 콘텐츠에 대해 자주 변경 작업을 할 예정입니다. 솔루션은 변경 사항이 발생하는 즉시 새로운 콘텐츠를 강력하게 일관성 있게 반환해야 합니다. 다음 중 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (두 가지를 고르세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132853-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다중 AZ 환경에서 빈번한 콘텐츠 변경을 즉시 반영할 수 있는 공유 스토리지가 필요한 상황입니다. Amazon EFS는 여러 AZ에 걸쳐 강력한 일관성과 높은 가용성을 제공하며, Amazon S3에 Cache-Control을 no-cache로 설정하고 Amazon CloudFront를 사용하면 최신 콘텐츠를 즉시 제공할 수 있습니다. 따라서 B와 E가 요구사항을 모두 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "공유 스토리지",
      "다중 AZ",
      "EC2 Auto Scaling",
      "빈번한 콘텐츠 변경",
      "강력한 일관성",
      "새로운 콘텐츠 즉시 반영"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "AWS Storage Gateway",
      "Volume Gateway (iSCSI)",
      "Amazon EFS",
      "Amazon EBS",
      "AWS DataSync",
      "Amazon S3",
      "Cache-Control",
      "Amazon CloudFront"
    ],
    "SelectA": "AWS Storage Gateway Volume Gateway iSCSI 블록 스토리지를 각 EC2 인스턴스에 마운트합니다.",
    "SelectA_Commentary": "Volume Gateway는 주로 온프레미스 환경 통합을 위해 사용되며, 다중 AZ 공유 파일시스템 용도로는 적절하지 않아 즉시 반영되는 강력한 일관성을 보장하기 어렵습니다.",
    "SelectB": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 생성하고, 이를 각 EC2 인스턴스에 마운트합니다.",
    "SelectB_Commentary": "EFS는 멀티 AZ를 지원하며 파일 변경 즉시 최신 데이터를 제공할 수 있어 강력한 일관성과 가용성을 보장합니다. 정답입니다.",
    "SelectC": "공유 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고, 이를 각 EC2 인스턴스에 마운트합니다.",
    "SelectC_Commentary": "EBS Multi-Attach 기능이 존재하지만, 복수 인스턴스 동시 마운트 시 파일 시스템 충돌 위험이 있으며 일반적으로 파일 공유 시나리오에는 적합하지 않습니다.",
    "SelectD": "AWS DataSync를 사용해 Auto Scaling group 내 EC2 호스트 간 데이터를 지속적으로 동기화합니다.",
    "SelectD_Commentary": "DataSync는 주기적이거나 대량 데이터 마이그레이션에 적합하지만, 실시간 변경 사항의 즉각적 반영이 필요한 시나리오에는 부담이 크고 운영이 복잡해집니다.",
    "SelectE": "Amazon S3 버킷을 생성해 웹 콘텐츠를 저장합니다. Cache-Control 헤더를 no-cache로 설정하고 Amazon CloudFront로 콘텐츠를 제공합니다.",
    "SelectE_Commentary": "S3는 강력한 읽기 후 쓰기 일관성을 제공하며, CloudFront와 함께 사용 시 no-cache 설정으로 변경 사항을 즉시 글로벌하게 배포할 수 있어 요구사항에 부합합니다. 정답입니다.",
    "Question_Description_recommedations": [
      "Q729",
      "Q275",
      "Q581",
      "Q595",
      "Q271"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q10",
      "Q48"
    ],
    "SelectB_recommedations": [
      "Q842",
      "Q102",
      "Q602"
    ],
    "SelectC_recommedations": [
      "Q602",
      "Q194",
      "Q312"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ],
    "SelectE_recommedations": [
      "Q784",
      "Q110",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q692",
    "Question_Description": "한 회사가 세 개의 AWS Region에 애플리케이션을 배포하고 있고, Application Load Balancer를 사용하고 있습니다. Amazon Route 53을 사용하여 이 세 Region 간의 트래픽을 분산하려고 합니다. 가장 높은 성능을 제공하려면 어떤 Route 53 구성을 사용해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132854-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자에게 가장 낮은 응답 시간을 제공하기 위해 여러 Region 간 트래픽을 자동으로 라우팅하는 방법을 묻습니다. Latency Policy는 사용자의 지리적 위치에 따라 가장 낮은 지연을 제공하는 Region으로 트래픽을 전달하므로, 가장 높은 성능을 보장합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "AWS Region",
      "Route 53",
      "Application Load Balancer",
      "트래픽 분산",
      "높은 성능"
    ],
    "Terms": [
      "Amazon Route 53",
      "Application Load Balancer",
      "A Record",
      "CNAME Record",
      "Latency Routing Policy",
      "Geolocation Policy",
      "Failover Policy",
      "Geoproximity Policy"
    ],
    "SelectA": "A 레코드를 생성하고 Latency Policy를 설정합니다.",
    "SelectA_Commentary": "가장 가까운(지연이 가장 낮은) Region으로 트래픽을 라우팅하여 높은 성능을 제공합니다. 정답입니다.",
    "SelectB": "A 레코드를 생성하고 Geolocation Policy를 설정합니다.",
    "SelectB_Commentary": "사용자의 물리적 위치 기반으로 라우팅하지만 지연 시간 최적화를 보장하지 못해 성능 면에서는 부적합합니다.",
    "SelectC": "CNAME 레코드를 생성하고 Failover Policy를 설정합니다.",
    "SelectC_Commentary": "장애 조치 시나리오 대비용이며, 주 트래픽 분산 및 최적의 성능 달성과는 목적이 다릅니다.",
    "SelectD": "CNAME 레코드를 생성하고 Geoproximity Policy를 설정합니다.",
    "SelectD_Commentary": "지리적 거리와 편향값을 기준으로 트래픽을 제어하지만, 순수 성능(지연 시간) 중심의 라우팅에 비해 복잡도가 높습니다.",
    "Question_Description_recommedations": [
      "Q530",
      "Q582",
      "Q12",
      "Q367",
      "Q474"
    ],
    "SelectA_recommedations": [
      "Q704",
      "Q352",
      "Q1015"
    ],
    "SelectB_recommedations": [
      "Q77",
      "Q587",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q865",
      "Q352"
    ],
    "SelectD_recommedations": [
      "Q352",
      "Q361",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q693",
    "Question_Description": "한 회사에서는 Application Load Balancer(ALB) 뒤에 Amazon EC2 인스턴스가 위치한 웹 애플리케이션을 운영 중이며, 이 애플리케이션에는 내장된 NoSQL 데이터베이스가 포함되어 있습니다. 해당 인스턴스들은 단일 Availability Zone에서 Amazon EC2 Auto Scaling 그룹으로 실행됩니다. 최근 트래픽 증가로 인해 애플리케이션이 고가용성을 갖추어야 하며 데이터베이스가 Eventually Consistent한 상태를 유지해야 합니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132855-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스에 내장된 데이터베이스를 고가용성 환경으로 전환하고 Eventually Consistent를 보장하는 동시에 운영 오버헤드를 최소화하는 방법을 묻습니다. 내장 NoSQL을 직접 복제하는 대신 다중 AZ에서 손쉽게 확장할 수 있는 Amazon DynamoDB로 마이그레이션하면 높은 가용성과 Eventually Consistent 특성을 간단하게 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "Eventually Consistent",
      "단일 Availability Zone",
      "Auto Scaling",
      "내장 NoSQL DB",
      "Amazon DynamoDB",
      "AWS DMS"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Network Load Balancer(NLB)",
      "Auto Scaling group",
      "Availability Zone",
      "NoSQL database",
      "Amazon DynamoDB",
      "AWS Database Migration Service(AWS DMS)"
    ],
    "SelectA": "Network Load Balancer로 교체하고, 내장 NoSQL 데이터베이스와 그 복제 서비스를 EC2 인스턴스에서 유지합니다.",
    "SelectA_Commentary": "ALB를 NLB로 변경해도 단일 AZ에 내장된 DB를 그대로 유지하면 고가용성을 확보하기 어렵고 관리가 복잡해집니다.",
    "SelectB": "Network Load Balancer로 교체하고, AWS Database Migration Service(AWS DMS)를 통해 내장 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.",
    "SelectB_Commentary": "DB 마이그레이션은 가능하지만, 여전히 단일 AZ에서 동작하는 인스턴스라 고가용성 요건을 충족하기 어렵습니다.",
    "SelectC": "Auto Scaling 그룹을 세 개의 Availability Zone으로 확장하고, 내장 NoSQL 데이터베이스의 복제 서비스를 EC2 인스턴스에서 유지합니다.",
    "SelectC_Commentary": "멀티 AZ로 확장은 고가용성에 도움이 되지만 내장 데이터베이스 복제 관리는 계속 직접 해야 하므로 운영 오버헤드가 큽니다.",
    "SelectD": "Auto Scaling 그룹을 세 개의 Availability Zone으로 확장하고, AWS DMS를 사용해 내장 NoSQL 데이터베이스를 Amazon DynamoDB로 마이그레이션합니다.",
    "SelectD_Commentary": "멀티 AZ 인프라와 데이터베이스를 DynamoDB로 이전해 Eventually Consistent 및 고가용성을 최소한의 운영 관리로 손쉽게 구현할 수 있는 정답입니다.",
    "Question_Description_recommedations": [
      "Q174",
      "Q333",
      "Q589",
      "Q246",
      "Q405"
    ],
    "SelectA_recommedations": [
      "Q693",
      "Q537",
      "Q405"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q537",
      "Q354"
    ],
    "SelectC_recommedations": [
      "Q691",
      "Q693",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q434",
      "Q210"
    ]
  },
  {
    "Question_Number": "Q694",
    "Question_Description": "한 회사가 AWS에서 쇼핑 애플리케이션을 구축 중입니다. 애플리케이션은 한 달에 한 번 변경되는 Catalog를 제공하며 트래픽 양에 맞춰 확장되어야 합니다. 회사는 애플리케이션에서 가능한 한 낮은 지연 시간을 원합니다. 각 사용자의 Shopping Cart 데이터는 고가용성을 가져야 합니다. 사용자가 연결이 끊겼다가 다시 연결하더라도 사용자 세션 데이터는 계속 사용 가능해야 합니다. 쇼핑 카트 데이터가 항상 보존되도록 하기 위해 Solutions Architect는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132857-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트래픽 증가에 따라 확장 가능하면서도 사용자의 Shopping Cart 데이터를 안정적으로 보존해야 하는 요구 사항을 해결하는 방법을 묻습니다. 분산 아키텍처에서 세션 정보를 관리하기 위해서는 고성능의 인메모리 데이터 스토어가 적합합니다. Amazon ElastiCache for Redis를 사용하면 빠른 응답 시간을 유지하면서도 세션 데이터를 안전하고 쉽게 사용할 수 있어, 요구사항인 낮은 지연 시간과 고가용성을 충족시킵니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "쇼핑 애플리케이션",
      "낮은 지연 시간",
      "고가용성",
      "Shopping Cart",
      "세션 데이터",
      "트래픽 확장",
      "Amazon ElastiCache for Redis",
      "Amazon DynamoDB"
    ],
    "Terms": [
      "Application Load Balancer",
      "Sticky sessions",
      "Amazon Aurora",
      "Amazon ElastiCache for Redis",
      "Amazon DynamoDB",
      "Amazon OpenSearch Service",
      "Amazon EC2",
      "Amazon EBS",
      "Snapshots"
    ],
    "SelectA": "Application Load Balancer에서 Sticky sessions(세션 어피니티)을 활성화하여 Amazon Aurora를 통한 Catalog 액세스를 구성합니다.",
    "SelectA_Commentary": "Sticky sessions는 특정 서버에 세션을 고정하므로 스케일 아웃에 불리하고, Aurora에 세션 정보를 저장하는 것은 세션 유지에 적합하지 않습니다.",
    "SelectB": "Amazon ElastiCache for Redis를 구성하여 Amazon DynamoDB에서 Catalog 데이터를 캐시하고, 사용자 세션의 Shopping Cart 데이터를 저장합니다.",
    "SelectB_Commentary": "ElastiCache for Redis는 분산 환경에서 세션 데이터를 처리하기에 적합하며, 빠른 응답과 고가용성을 모두 제공하므로 요구사항을 충족하는 최적의 솔루션입니다.",
    "SelectC": "Amazon OpenSearch Service를 구성하여 Amazon DynamoDB에서 Catalog 데이터를 캐시하고, 사용자 세션의 Shopping Cart 데이터를 저장합니다.",
    "SelectC_Commentary": "OpenSearch Service는 검색 및 분석에 최적화되어 있으며, 세션 데이터 보존을 위한 인메모리 캐시로 사용하기에는 부적절합니다.",
    "SelectD": "Amazon EC2 인스턴스와 Amazon EBS 스토리지를 사용하여 Catalog와 Shopping Cart를 저장하고, 자동 Snapshot을 구성합니다.",
    "SelectD_Commentary": "EC2와 EBS만으로는 멀티 인스턴스 또는 리전 간 확장이 어렵고, 사용자 세션 데이터 복원에도 추가적인 관리가 필요해 고가용성과 확장에 불리합니다.",
    "Question_Description_recommedations": [
      "Q171",
      "Q323",
      "Q288",
      "Q263",
      "Q479"
    ],
    "SelectA_recommedations": [
      "Q589",
      "Q217",
      "Q405"
    ],
    "SelectB_recommedations": [
      "Q768",
      "Q845",
      "Q48"
    ],
    "SelectC_recommedations": [
      "Q845",
      "Q768",
      "Q1002"
    ],
    "SelectD_recommedations": [
      "Q48",
      "Q194",
      "Q602"
    ]
  },
  {
    "Question_Number": "Q695",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)에 배포될 마이크로서비스 기반 애플리케이션을 구축하고 있습니다. 이 마이크로서비스들은 서로 상호 작용합니다. 회사는 향후 성능 문제를 식별하기 위해 애플리케이션에 대한 가시성을 확보하고 싶어합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132858-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EKS 기반 마이크로서비스의 성능 상태와 상호 작용을 가시적으로 모니터링하는 데 초점을 둡니다. Amazon CloudWatch Container Insights는 컨테이너 메트릭을 수집하고 시각화하며, AWS X-Ray는 분산 추적을 통해 마이크로서비스 간 요청 흐름을 파악할 수 있어 종합적인 성능 분석에 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "마이크로서비스",
      "Amazon EKS",
      "성능 문제",
      "가시성",
      "메트릭 수집",
      "AWS X-Ray",
      "CloudWatch Container Insights"
    ],
    "Terms": [
      "Amazon EKS",
      "microservices",
      "Amazon CloudWatch Container Insights",
      "AWS X-Ray",
      "AWS CloudTrail",
      "Amazon QuickSight",
      "AWS Trusted Advisor",
      "Amazon ElastiCache"
    ],
    "SelectA": "애플리케이션이 Amazon ElastiCache를 사용하도록 구성하여 마이크로서비스로 전송되는 요청 수를 줄입니다.",
    "SelectA_Commentary": "ElastiCache는 캐싱을 통해 요청을 줄일 수 있지만, 분산 추적이나 메트릭 수집 기능을 제공하지 않아 가시성 확보와 성능 문제 식별에는 직접적인 도움이 되지 않습니다.",
    "SelectB": "Amazon CloudWatch Container Insights를 구성하여 EKS 클러스터에서 메트릭을 수집합니다. AWS X-Ray를 구성하여 마이크로서비스 간 요청을 추적합니다.",
    "SelectB_Commentary": "CloudWatch Container Insights와 AWS X-Ray를 함께 사용하면 컨테이너 메트릭과 분산 추적 정보를 모두 확보할 수 있어, 애플리케이션의 성능 이슈를 손쉽게 파악하고 해결할 수 있는 최적의 솔루션입니다.",
    "SelectC": "AWS CloudTrail을 구성하여 API 호출을 검토합니다. Amazon QuickSight 대시보드를 구축하여 마이크로서비스 상호 작용을 관찰합니다.",
    "SelectC_Commentary": "CloudTrail은 AWS API 호출 감사용이고, QuickSight는 시각화 도구이므로 마이크로서비스 간 요청 흐름에 대한 심층 분산 추적 기능이나 컨테이너 메트릭 수집 면에서는 제한적입니다.",
    "SelectD": "AWS Trusted Advisor를 사용하여 애플리케이션의 성능을 파악합니다.",
    "SelectD_Commentary": "Trusted Advisor는 비용 최적화나 보안 설정 같은 모범 사례에 집중하므로, 마이크로서비스 간 트래픽 흐름을 추적하거나 실시간 메트릭을 수집하는 데는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q680",
      "Q746",
      "Q857",
      "Q219"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q361",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q515",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q361",
      "Q631"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q443",
      "Q631"
    ]
  },
  {
    "Question_Number": "Q696",
    "Question_Description": "한 회사가 고객들에게 안전하게 데이터를 제공해야 합니다. 이 회사는 고객 데이터를 처리하여 결과를 Amazon S3 버킷에 저장합니다. 모든 데이터는 엄격한 규제와 보안 요건이 적용되며, 저장 시점에 반드시 암호화되어야 합니다. 각 고객은 자신의 AWS 계정에서 자신의 데이터만 액세스할 수 있어야 하며, 회사 직원들은 데이터에 액세스할 수 없어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132859-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고객별로 분리된 권한과 저장 시점 암호화를 요구합니다. KMS를 통해 고객별 별도 키를 할당하고, KMS Key Policy에서 고객에게만 복호화를 허용하는 방식이 가장 적절하며, 회사 직원이 데이터에 접근하지 못하도록 제한할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "암호화된 데이터 저장",
      "고객별 접근 제어",
      "회사 직원 액세스 제한",
      "AWS 계정별 권한"
    ],
    "Terms": [
      "AWS Certificate Manager (ACM)",
      "AWS Key Management Service (AWS KMS)",
      "S3 Bucket Policy",
      "KMS Key Policy",
      "Server-Side Encryption",
      "Client-Side Encryption"
    ],
    "SelectA": "각 고객을 위해 AWS Certificate Manager(ACM) 인증서를 프로비저닝하고 클라이언트 단에서 데이터를 암호화합니다. Private Certificate Policy에서 고객이 제공한 IAM 역할 외 모든 Principal을 거부합니다.",
    "SelectA_Commentary": "ACM 인증서는 HTTPS 통신을 위한 인증서로, S3에 저장되는 데이터의 암호화와 직접적으로 연관되지 않아 요구 사항을 충족하기 어렵습니다.",
    "SelectB": "각 고객을 위해 별도의 AWS KMS 키를 프로비저닝하고 서버 단에서 데이터를 암호화합니다. S3 Bucket Policy에서 고객이 제공한 IAM 역할 외에는 데이터 복호화를 거부합니다.",
    "SelectB_Commentary": "Bucket Policy만으로 복호화 권한을 완벽히 제어하기는 어렵습니다. Decrypt 권한은 주로 KMS Key Policy에서 제어해야 합니다.",
    "SelectC": "각 고객을 위해 별도의 AWS KMS 키를 프로비저닝하고 서버 단에서 데이터를 암호화합니다. 각 KMS Key Policy에서 고객이 제공한 IAM 역할 외에는 데이터 복호화를 거부합니다.",
    "SelectC_Commentary": "KMS Key Policy를 사용해 복호화 권한을 고객 역할에만 부여하고, 회사 직원이 액세스하지 못하도록 완전 차단할 수 있어 요구 사항을 정확히 충족합니다.",
    "SelectD": "각 고객을 위해 AWS Certificate Manager(ACM) 인증서를 프로비저닝하고 클라이언트 단에서 데이터를 암호화합니다. Public Certificate Policy에서 고객이 제공한 IAM 역할 외 모든 Principal을 거부합니다.",
    "SelectD_Commentary": "ACM 인증서를 사용한 클라이언트 단 암호화로는 안정적인 저장 시점 암호화, 고객별 분리, 직원 접근 제한을 체계적으로 구현하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q925",
      "Q154",
      "Q825",
      "Q202",
      "Q965"
    ],
    "SelectA_recommedations": [
      "Q222",
      "Q780",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q550",
      "Q916"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q550",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q222",
      "Q780",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q697",
    "Question_Description": "한 솔루션스 아키텍트가 두 개의 퍼블릭 서브넷과 두 개의 프라이빗 서브넷을 포함하는 VPC를 생성했습니다. 기업 보안 정책상 모든 Amazon EC2 인스턴스는 프라이빗 서브넷에서만 실행되어야 합니다. 그러나 포트 80과 443에서 웹 서버를 운영하는 EC2 인스턴스를 프라이빗 서브넷에 배포했을 때 외부 인터넷 트래픽이 서버에 연결되지 않습니다. 이 문제를 해결하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132860-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 서버를 프라이빗 서브넷에 두면서 외부 인터넷에서 접근 가능한 방식을 설계하는 방법을 묻습니다. 프라이빗 서브넷에 있는 인스턴스에는 퍼블릭 IP가 없으므로 직접 접근이 불가능합니다. 인터넷에서 진입하려면 퍼블릭 서브넷에 인터넷에 연결되는 엔드포인트(예: 인터넷 연결이 가능한 ALB)를 두고, 해당 엔드포인트가 내부 인스턴스로 트래픽을 라우팅해야 합니다. 따라서 정답은 퍼블릭 서브넷에 인터넷-페이싱 ALB를 두고, EC2 인스턴스는 프라이빗 서브넷 목표 그룹에 연결하는 B입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "퍼블릭 서브넷",
      "프라이빗 서브넷",
      "EC2 인스턴스",
      "웹 서버",
      "보안 정책",
      "인터넷 트래픽",
      "포트 80",
      "포트 443",
      "ALB"
    ],
    "Terms": [
      "VPC",
      "public subnet",
      "private subnet",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer (ALB)",
      "NAT gateway",
      "security group",
      "Elastic IP",
      "DNS record",
      "ports 80 and 443"
    ],
    "SelectA": "EC2 인스턴스를 프라이빗 서브넷의 Auto Scaling 그룹에 연결하고, 웹사이트의 DNS 레코드를 Auto Scaling 그룹 식별자로 설정합니다.",
    "SelectA_Commentary": "Auto Scaling 그룹 식별자로 라우팅해도 퍼블릭 서브넷을 통한 외부 접근 경로가 생기지 않으므로 인바운드 트래픽 문제가 해결되지 않습니다.",
    "SelectB": "퍼블릭 서브넷에 인터넷 연결이 가능한 Application Load Balancer(ALB)를 프로비저닝하고, 해당 ALB의 타깃 그룹에 EC2 인스턴스를 추가합니다. 웹사이트의 DNS 레코드를 ALB로 설정합니다.",
    "SelectB_Commentary": "퍼블릭 서브넷에 위치한 ALB가 외부 트래픽을 받아 프라이빗 서브넷의 EC2 인스턴스로 전달하므로, 보안 정책을 충족하면서도 외부에서 웹 서버에 접속이 가능합니다.",
    "SelectC": "프라이빗 서브넷에 NAT 게이트웨이를 생성하고, 프라이빗 서브넷의 라우트 테이블에 디폴트 라우트를 NAT 게이트웨이에 추가합니다. NAT 게이트웨이에 퍼블릭 Elastic IP를 연결합니다.",
    "SelectC_Commentary": "NAT 게이트웨이는 내부 인스턴스가 인터넷에 접속(아웃바운드)할 수 있도록 해주지만, 외부에서 인바운드로 들어오는 트래픽을 처리하지 못합니다.",
    "SelectD": "EC2 인스턴스에 연결된 보안 그룹이 80번, 443번 포트를 허용하도록 설정하고, 웹사이트의 DNS 레코드를 EC2 인스턴스의 퍼블릭 IP로 지정합니다.",
    "SelectD_Commentary": "프라이빗 서브넷에 있는 인스턴스에는 퍼블릭 IP가 존재하지 않으므로 외부에서 직접 연결할 수 없고, 이 방식은 보안 정책에도 위배됩니다.",
    "Question_Description_recommedations": [
      "Q327",
      "Q232",
      "Q866",
      "Q950",
      "Q92"
    ],
    "SelectA_recommedations": [
      "Q396",
      "Q614",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q884",
      "Q927",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q803",
      "Q315",
      "Q682"
    ],
    "SelectD_recommedations": [
      "Q697",
      "Q218",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q698",
    "Question_Description": "한 회사가 AWS Fargate를 사용하는 Amazon EKS 클러스터에 새로운 애플리케이션을 배포하려고 합니다. 이 애플리케이션은 데이터 영속성을 위해 스토리지 솔루션이 필요합니다. 솔루션은 고가용성과 내결함성을 갖추어야 하고, 여러 애플리케이션 컨테이너 간에 공유가 가능해야 합니다. 또한 운영 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132861-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Fargate 기반 Amazon EKS 환경에서 여러 컨테이너가 동시에 사용할 수 있는 고가용성 및 내결함성 스토리지를 찾는 상황입니다. Amazon EFS는 자동 확장, 다중 AZ 지원을 통해 운영 오버헤드를 최소화하면서 영속적이고 공유 가능한 파일 시스템을 제공합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "내결함성",
      "공유 스토리지",
      "운영 오버헤드 최소화",
      "AWS Fargate",
      "Amazon EKS",
      "Amazon EFS",
      "데이터 영속성"
    ],
    "Terms": [
      "Amazon EBS",
      "EBS Multi-Attach",
      "Amazon EFS",
      "StorageClass",
      "AWS Fargate",
      "Amazon EKS",
      "AWS Lambda",
      "Availability Zone"
    ],
    "SelectA": "Amazon EBS 볼륨을 EKS 워커 노드가 있는 동일한 가용 영역에 생성합니다. 이를 EKS 클러스터 내 StorageClass 객체에 등록하고, EBS Multi-Attach를 사용해 컨테이너 간 데이터를 공유합니다.",
    "SelectA_Commentary": "EBS Multi-Attach는 아직 사용 사례가 제한적이며, 가용 영역별 볼륨 관리와 노드 장애 시 대응이 더 복잡해 운영 오버헤드가 높아집니다.",
    "SelectB": "Amazon EFS 파일 시스템을 생성합니다. EKS 클러스터 내 StorageClass 객체에 해당 파일 시스템을 등록합니다. 모든 컨테이너가 동일한 파일 시스템을 사용합니다.",
    "SelectB_Commentary": "Amazon EFS는 다중 AZ에 걸친 고가용성과 내결함성을 제공하며, 여러 컨테이너 간 간편하게 공유할 수 있어 운영 오버헤드가 가장 적습니다.",
    "SelectC": "하나의 Amazon EBS 볼륨을 생성합니다. 이를 EKS 클러스터 내 StorageClass 객체에 등록하고, 모든 컨테이너가 동일한 EBS 볼륨을 사용합니다.",
    "SelectC_Commentary": "단일 EBS 볼륨은 특정 AZ에 종속되고, 동시에 여러 컨테이너에서 쓰기는 제한적이어서 고가용성을 보장하기 어렵습니다.",
    "SelectD": "EKS 워커 노드가 있는 각각의 가용 영역에 Amazon EFS 파일 시스템을 생성합니다. 이를 StorageClass 객체에 등록하고, AWS Lambda 함수를 사용해 파일 시스템 간 데이터를 동기화합니다.",
    "SelectD_Commentary": "가용 영역마다 별도 파일 시스템을 운영해야 하므로 동기화 관리가 복잡해지고, 운영 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q996",
      "Q303",
      "Q563",
      "Q775",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q602",
      "Q563",
      "Q996"
    ],
    "SelectB_recommedations": [
      "Q563",
      "Q996",
      "Q602"
    ],
    "SelectC_recommedations": [
      "Q602",
      "Q563",
      "Q996"
    ],
    "SelectD_recommedations": [
      "Q563",
      "Q996",
      "Q775"
    ]
  },
  {
    "Question_Number": "Q699",
    "Question_Description": "한 회사가 로컬 데이터 센터에서 Docker containers를 사용하는 애플리케이션을 운영하고 있습니다. 애플리케이션은 컨테이너 호스트에 있는 볼륨에 영구 데이터를 저장하며, 컨테이너 인스턴스들은 이 영구 데이터를 사용합니다. 회사는 서버나 스토리지 인프라를 직접 관리하고 싶지 않아 완전관리형 서비스로 애플리케이션을 이전하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132862-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컨테이너 애플리케이션을 서버와 스토리지를 직접 관리 없이 완전관리형 서비스로 이전하는 방법을 묻습니다. AWS Fargate는 서버를 직접 프로비저닝하지 않고 컨테이너를 실행할 수 있는 완전관리형 서비스이며, Amazon EFS는 컨테이너가 공유 및 확장 가능한 영구 스토리지를 손쉽게 활용하도록 지원합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "완전관리형 서비스",
      "Docker containers",
      "영구 스토리지",
      "AWS Fargate",
      "Amazon EFS"
    ],
    "Terms": [
      "Docker containers",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon EKS",
      "Amazon EC2",
      "Amazon Elastic Block Store (Amazon EBS)",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon S3",
      "Persistent Volume",
      "무서버(서버리스)"
    ],
    "SelectA": "Amazon EKS와 self-managed 노드를 사용합니다. Amazon EC2 인스턴스에 연결된 Amazon EBS 볼륨을 생성하고, 이를 컨테이너의 persistent volume으로 마운트합니다.",
    "SelectA_Commentary": "self-managed 노드와 EC2 인스턴스를 사용해야 하므로 서버와 볼륨 관리를 직접 수행해야 하며 완전관리형 요구사항과 거리가 멉니다.",
    "SelectB": "Amazon ECS를 AWS Fargate 런치 타입으로 사용합니다. Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. EFS 볼륨을 컨테이너에 마운트해 영구 스토리지로 사용합니다.",
    "SelectB_Commentary": "서버∙스토리지 인프라 관리를 최소화하면서 컨테이너가 영구 스토리지로 EFS를 이용할 수 있는 완전관리형 솔루션으로 요구사항을 충족합니다.",
    "SelectC": "Amazon ECS를 AWS Fargate 런치 타입으로 사용합니다. Amazon S3 버킷을 생성하고, S3 버킷을 컨테이너에 마운트해 영구 스토리지로 사용합니다.",
    "SelectC_Commentary": "Fargate 컨테이너에서 S3를 네이티브 볼륨으로 직접 마운트하는 것은 일반적으로 지원되지 않아 추가 구성과 관리 부담이 큽니다.",
    "SelectD": "Amazon ECS를 Amazon EC2 런치 타입으로 사용합니다. Amazon Elastic File System(Amazon EFS) 볼륨을 생성합니다. EFS 볼륨을 컨테이너에 마운트하여 영구 스토리지로 사용합니다.",
    "SelectD_Commentary": "EC2 인스턴스 기반으로 서버 관리를 수행해야 하며, 완전관리형 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q252",
      "Q1014",
      "Q513",
      "Q149",
      "Q363"
    ],
    "SelectA_recommedations": [
      "Q563",
      "Q996",
      "Q602"
    ],
    "SelectB_recommedations": [
      "Q842",
      "Q698",
      "Q900"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q944",
      "Q698"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q900",
      "Q892"
    ]
  },
  {
    "Question_Number": "Q700",
    "Question_Description": "한 게임 회사가 여러 AWS Regions에 인터넷에 노출되는 새로운 애플리케이션을 출시하려고 합니다. 해당 애플리케이션은 TCP와 UDP 프로토콜을 사용하여 통신합니다. 이 회사는 글로벌 사용자를 위해 높은 가용성과 가장 낮은 지연 시간을 제공해야 합니다. 이러한 요구 사항을 만족하기 위해 솔루션스 아키텍트가 취해야 할 조합은 무엇입니까? (2개를 선택하세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132863-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 Region에서 TCP/UDP 기반 애플리케이션을 전 세계 사용자에게 안정적으로 배포해야 할 때의 접근 방안을 묻습니다. Network Load Balancer와 AWS Global Accelerator를 함께 사용하면 다중 리전에서 낮은 지연 시간과 고가용성을 동시에 보장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "글로벌 사용자",
      "높은 가용성",
      "낮은 지연 시간",
      "TCP와 UDP 프로토콜",
      "AWS Global Accelerator",
      "Network Load Balancer"
    ],
    "Terms": [
      "AWS Regions",
      "TCP",
      "UDP",
      "Network Load Balancer",
      "Application Load Balancer",
      "AWS Global Accelerator",
      "Amazon Route 53",
      "CloudFront"
    ],
    "SelectA": "각 Region에서 애플리케이션 앞에 internal Network Load Balancer를 생성합니다.",
    "SelectA_Commentary": "TCPㆍUDP 트래픽 처리에 적합한 Network Load Balancer는 고성능과 멀티 리전 환경에서의 고가용성을 확보할 수 있어 적절한 선택입니다.",
    "SelectB": "각 Region에서 애플리케이션 앞에 external Application Load Balancer를 생성합니다.",
    "SelectB_Commentary": "Application Load Balancer는 HTTP/HTTPS 트래픽에 최적화되어 있어 TCP/UDP 기반 애플리케이션에 적합하지 않고, 핵심 요구사항인 UDP 프로토콜 처리에 제한이 있습니다.",
    "SelectC": "각 Region에 있는 Load Balancer로 트래픽을 라우팅하기 위해 AWS Global Accelerator를 구성합니다.",
    "SelectC_Commentary": "Global Accelerator는 전 세계 사용자를 위한 지연 시간 단축과 고가용성을 제공하기 때문에 멀티 리전 배포 시 필수적인 옵션입니다.",
    "SelectD": "트래픽 분산을 위해 Amazon Route 53에 지리 위치(geolocation) 라우팅 정책을 설정합니다.",
    "SelectD_Commentary": "지리 위치 라우팅은 트래픽을 특정 위치별로 나누기에는 유용하지만, 실시간 성능 최적화 및 UDP 프로토콜 지원 측면에서 Global Accelerator만큼 효율적이지 않습니다.",
    "SelectE": "Amazon CloudFront를 구성하여 트래픽을 처리하고 각 Region의 애플리케이션으로 요청을 라우팅합니다.",
    "SelectE_Commentary": "CloudFront는 주로 HTTP/HTTPS 콘텐츠 전송에 사용되며, TCP/UDP 프로토콜 전송 및 멀티 리전 간 고가용성을 보장하는 Global Accelerator 대안으로는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q408",
      "Q987",
      "Q68",
      "Q647",
      "Q570"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q408",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q575",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q575",
      "Q224"
    ],
    "SelectD_recommedations": [
      "Q545",
      "Q991",
      "Q8"
    ],
    "SelectE_recommedations": [
      "Q8",
      "Q68",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q701",
    "Question_Description": "한 도시는 Application Load Balancer(ALB) 뒤 Amazon EC2 인스턴스에서 동작하는 웹 애플리케이션을 배포했습니다. 애플리케이션 사용자는 무작위 IP 주소에서 발생하는 DDoS 공격으로 인해 간헐적인 성능 저하를 겪고 있습니다. 도시는 최소한의 구성 변경으로 DDoS 소스에 대한 감사 추적(audit trail)을 제공할 수 있는 솔루션이 필요합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132865-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB 뒤에 있는 EC2 인스턴스를 보호하면서, DDoS 공격의 소스를 추적하고 최소한의 변경으로 손쉽게 방어 기능을 적용할 수 있는 방법을 묻습니다. AWS Shield Advanced 구독 시 DDoS 보호가 강화되고, AWS DDoS Response Team(DRT)과 연계하여 자동으로 완화 기능을 적용할 수 있어, 모니터링과 감사 추적에 유리합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "DDoS",
      "간헐적 성능 저하",
      "무작위 IP 주소",
      "최소한의 구성 변경",
      "감사 추적"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "AWS WAF",
      "Amazon Inspector",
      "AWS Shield Advanced",
      "AWS DDoS Response Team(DRT)",
      "Amazon CloudFront"
    ],
    "SelectA": "ALB에서 AWS WAF 웹 ACL을 활성화하고, 알려지지 않은 소스로부터의 트래픽을 차단하도록 규칙을 설정합니다.",
    "SelectA_Commentary": "WAF만으로는 광범위한 DDoS 방어와 자동 완화 및 DRT 지원이 부족하므로 요구사항을 모두 충족하기 어렵습니다.",
    "SelectB": "Amazon Inspector를 구독합니다. AWS DDoS Response Team(DRT)과 협업하여 서비스에 대응 조치를 통합합니다.",
    "SelectB_Commentary": "Amazon Inspector는 일반적으로 애플리케이션 보안 취약성 검사에 초점이 맞추어져 있어, DDoS 방어와는 직접적 관련이 적습니다.",
    "SelectC": "AWS Shield Advanced를 구독합니다. AWS DDoS Response Team(DRT)과 협업하여 서비스에 대응 조치를 통합합니다.",
    "SelectC_Commentary": "AWS Shield Advanced 구독은 가시성, 자동 완화 및 감사 추적에 유리하며, 필요 시 DRT가 직접 방어 정책을 설정하여 최소 구성 변경으로 DDoS 공격을 효과적으로 방어할 수 있습니다.",
    "SelectD": "애플리케이션용 Amazon CloudFront 배포를 생성하고, ALB를 오리진으로 설정합니다. CloudFront에서 AWS WAF 웹 ACL을 활성화하고, 알려지지 않은 소스로부터의 트래픽을 차단하도록 규칙을 설정합니다.",
    "SelectD_Commentary": "CloudFront와 WAF만 사용할 경우에도 DDoS 차단 효과가 있으나, DRT의 지원 및 상세 감사 추적, 추가 보호 기능은 Shield Advanced를 사용하는 옵션에 비해 제한적입니다.",
    "Question_Description_recommedations": [
      "Q437",
      "Q927",
      "Q169",
      "Q884",
      "Q35"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q426"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q426",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q396",
      "Q927",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q165",
      "Q749",
      "Q60"
    ]
  },
  {
    "Question_Number": "Q702",
    "Question_Description": "한 회사는 최근 해양 조사에서 수집한 200TB의 데이터를 AWS Snowball Edge Storage Optimized 디바이스에 복사했습니다. 이 회사는 AWS 상에서 고성능 컴퓨팅(HPC) 클러스터를 운영하여 석유 및 가스 매장지를 탐색하고 있습니다. 솔루션스 아키텍트는 HPC 클러스터가 Snowball Edge Storage Optimized 디바이스에 있는 데이터를 일관된 서브밀리초 지연 시간과 높은 처리량으로 액세스할 수 있도록 해야 합니다. 회사는 이 디바이스들을 다시 AWS로 보내고 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132866-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HPC 워크로드에 필요한 매우 낮은 지연 시간과 높은 처리량을 위한 스토리지를 결정하는 상황입니다. Snowball Edge에서 직접 FSx for Lustre로 데이터를 가져올 수 없으므로, 먼저 Amazon S3로 Import한 뒤 FSx for Lustre와 통합해 HPC 클러스터가 서브밀리초 지연 시간으로 접근하도록 설계하는 방법이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "서브밀리초 지연 시간",
      "높은 처리량",
      "HPC 클러스터",
      "Snowball Edge",
      "S3 버킷",
      "FSx for Lustre"
    ],
    "Terms": [
      "Snowball Edge Storage Optimized",
      "HPC 클러스터",
      "Sub-millisecond Latency",
      "High Throughput",
      "AWS Storage Gateway file gateway",
      "Amazon S3 bucket",
      "Amazon FSx for Lustre",
      "Amazon EFS"
    ],
    "SelectA": "Amazon S3 버킷을 생성하고 데이터를 해당 S3 버킷으로 Import합니다. 그런 다음 AWS Storage Gateway file gateway를 구성하여 S3 버킷을 마운트해 HPC 클러스터 인스턴스에서 액세스합니다.",
    "SelectA_Commentary": "Storage Gateway file gateway는 HPC 워크로드에 맞는 서브밀리초 지연 시간과 높은 I/O 요구사항을 만족하기 어렵습니다.",
    "SelectB": "Amazon S3 버킷을 생성하고 데이터를 해당 S3 버킷으로 Import합니다. Amazon FSx for Lustre 파일 시스템을 구성하여 S3 버킷과 통합한 뒤 HPC 클러스터 인스턴스에서 FSx for Lustre를 액세스합니다.",
    "SelectB_Commentary": "FSx for Lustre는 HPC 환경에 최적화되어 서브밀리초 지연 시간과 높은 처리량을 제공하므로 요구사항을 가장 잘 충족하는 솔루션입니다.",
    "SelectC": "Amazon S3 버킷과 Amazon Elastic File System(Amazon EFS)을 생성하고 데이터를 S3 버킷으로 Import합니다. 이후 데이터를 EFS로 복사하여 HPC 클러스터 인스턴스에서 액세스합니다.",
    "SelectC_Commentary": "EFS는 관리형 NFS 스토리지로 유연성이 있지만 HPC클래스의 극저지연, 고처리량 성능에는 부적합합니다.",
    "SelectD": "Amazon FSx for Lustre 파일 시스템을 생성하고 데이터를 직접 FSx for Lustre로 Import합니다. HPC 클러스터 인스턴스에서 해당 FSx for Lustre를 액세스합니다.",
    "SelectD_Commentary": "Snowball Edge에서 바로 FSx for Lustre로 가져오는 공식 통합 경로가 없어, 직접 Import가 불가능합니다.",
    "Question_Description_recommedations": [
      "Q795",
      "Q646",
      "Q857",
      "Q162",
      "Q113"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q155",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q407",
      "Q680",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q857",
      "Q6"
    ],
    "SelectD_recommedations": [
      "Q407",
      "Q795",
      "Q857"
    ]
  },
  {
    "Question_Number": "Q703",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에 NFS 서버를 보유하고 있으며, 주기적으로 소량의 데이터를 Amazon S3로 백업해야 합니다. 이러한 요구사항을 충족하면서 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132867-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 NFS 서버에서 주기적으로 발생하는 소량의 데이터를 S3로 백업할 때, 가장 비용 효율적이면서도 간단하게 구축할 수 있는 방안을 묻습니다. AWS DataSync를 사용하면 증분 동기화 및 스케줄링이 쉬워서 운영 부담과 비용을 모두 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "NFS 서버",
      "온프레미스",
      "소량의 데이터",
      "Amazon S3",
      "AWS DataSync",
      "비용 효율"
    ],
    "Terms": [
      "AWS Glue",
      "AWS DataSync",
      "AWS Transfer for SFTP",
      "AWS Direct Connect",
      "Amazon S3",
      "NFS"
    ],
    "SelectA": "AWS Glue를 설정하여 온프레미스 서버에서 Amazon S3로 데이터를 복사합니다.",
    "SelectA_Commentary": "AWS Glue는 주로 ETL 작업과 데이터 카탈로그 용도로 사용되므로, 단순 백업에는 과도한 비용과 설정이 필요해 비효율적입니다.",
    "SelectB": "온프레미스 서버에 AWS DataSync agent를 설정하고, 데이터를 Amazon S3와 동기화합니다.",
    "SelectB_Commentary": "DataSync는 파일 서버용 에이전트를 통해 자동화된 증분 동기화를 제공하므로 소량의 데이터를 주기적으로 전송할 때 비용과 운영 부담을 최소화합니다.",
    "SelectC": "AWS Transfer for SFTP를 사용하여 온프레미스에서 Amazon S3로 SFTP 동기화를 설정합니다.",
    "SelectC_Commentary": "AWS Transfer for SFTP는 파일 이동에는 편리하지만, DataSync처럼 자동 증분이나 파일시스템 전송 최적화를 제공하지 않아 더 비효율적일 수 있습니다.",
    "SelectD": "온프레미스 데이터 센터와 VPC 사이에 AWS Direct Connect 연결을 구성하고, 데이터를 Amazon S3로 복사합니다.",
    "SelectD_Commentary": "Direct Connect는 전송 대역폭이 크지만 구축 비용이 높고 작은 양의 데이터를 위한 주기적 백업에는 오버킬이 되어 비용 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q617",
      "Q806",
      "Q1003",
      "Q769",
      "Q911"
    ],
    "SelectA_recommedations": [
      "Q993",
      "Q943",
      "Q469"
    ],
    "SelectB_recommedations": [
      "Q918",
      "Q993",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q205",
      "Q285",
      "Q703"
    ],
    "SelectD_recommedations": [
      "Q471",
      "Q993",
      "Q860"
    ]
  },
  {
    "Question_Number": "Q704",
    "Question_Description": "한 온라인 비디오 게임 회사는 게임 서버에 초저지연(ultra-low latency)을 유지해야 합니다. 이 게임 서버들은 Amazon EC2 인스턴스에서 실행됩니다. 이 회사는 매초 수백만 건의 UDP 인터넷 트래픽 요청을 처리할 수 있는 솔루션이 필요합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132868-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "초저지연이 요구되는 UDP 트래픽을 효과적으로 처리하기 위해서는 Layer 4 수준에서 대규모 트래픽을 지원하는 Network Load Balancer가 적합합니다. NLB는 초당 수백만 건의 요청 처리와 UDP 프로토콜 지원에 강점이 있으며 비용 대비 성능이 우수합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "UDP 트래픽",
      "초저지연",
      "비용 효율",
      "Network Load Balancer"
    ],
    "Terms": [
      "Amazon EC2",
      "UDP",
      "Application Load Balancer",
      "Gateway Load Balancer",
      "Network Load Balancer",
      "AWS Regions"
    ],
    "SelectA": "인터넷 트래픽을 위해 필요한 프로토콜과 포트를 Application Load Balancer에 구성하고, 대상(Targets)으로 EC2 인스턴스를 지정합니다.",
    "SelectA_Commentary": "Application Load Balancer는 주로 HTTP/HTTPS(Layer 7) 기반에 최적화되어 있어 UDP 트래픽을 처리하기 어렵고 비용 효율도 떨어집니다.",
    "SelectB": "인터넷 트래픽을 위해 Gateway Load Balancer를 구성하고, 대상(Targets)으로 EC2 인스턴스를 지정합니다.",
    "SelectB_Commentary": "Gateway Load Balancer는 보안 또는 네트워크 어플라이언스 통합에 주로 사용되며, UDP 트래픽 분산을 위한 최적의 선택은 아닙니다.",
    "SelectC": "인터넷 트래픽을 위해 필요한 프로토콜과 포트를 Network Load Balancer에 구성하고, 대상(Targets)으로 EC2 인스턴스를 지정합니다.",
    "SelectC_Commentary": "Network Load Balancer는 Layer 4에서 초당 수백만 건의 UDP 요청 처리를 지원하며, 짧은 지연 시간과 높은 성능을 제공하는 최적의 선택입니다.",
    "SelectD": "별도의 AWS Regions에 동일한 게임 서버 세트를 구동하고, 인터넷 트래픽을 두 세트의 EC2 인스턴스로 라우팅합니다.",
    "SelectD_Commentary": "여러 리전으로 분산하는 것은 지연 측면에서 일부 이점이 있을 수 있지만, 트래픽 분산 및 비용 효율 관점에서 요구 사항을 직접적으로 해결하지 못합니다.",
    "Question_Description_recommedations": [
      "Q352",
      "Q1015",
      "Q746",
      "Q905",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q141",
      "Q358",
      "Q823"
    ],
    "SelectB_recommedations": [
      "Q823",
      "Q141",
      "Q815"
    ],
    "SelectC_recommedations": [
      "Q815",
      "Q823",
      "Q141"
    ],
    "SelectD_recommedations": [
      "Q976",
      "Q20",
      "Q474"
    ]
  },
  {
    "Question_Number": "Q705",
    "Question_Description": "한 회사가 VPC에서 3계층 애플리케이션을 운영하고 있으며, 데이터베이스 계층으로 Amazon RDS for MySQL DB instance를 사용하고 있습니다. 이 회사는 해당 MySQL DB instance를 Amazon Aurora PostgreSQL DB cluster로 마이그레이션하려 합니다. 이때 마이그레이션 과정에서 발생하는 모든 데이터 변경분도 새로운 데이터베이스에 반영되어야 합니다. 이러한 요구사항을 충족하기 위한 단계의 조합은 무엇입니까? (2개를 고르시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132870-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL에서 Amazon Aurora PostgreSQL로 마이그레이션하면서, 스키마 변환과 지속적 데이터 변경 복제가 필요한 시나리오입니다. MySQL 스키마를 PostgreSQL에 맞게 변환하고, 변경된 데이터를 실시간으로 동기화하기 위해서는 AWS DMS의 Schema Conversion과 CDC 태스크를 조합해 활용해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "마이그레이션",
      "데이터 변경 복제",
      "스키마 변환",
      "Change Data Capture",
      "AWS Database Migration Service"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Amazon Aurora PostgreSQL DB cluster",
      "AWS Database Migration Service (AWS DMS)",
      "Schema Conversion",
      "Change Data Capture (CDC)"
    ],
    "SelectA": "AWS Database Migration Service (AWS DMS) Schema Conversion을 사용하여 데이터베이스 오브젝트를 변환합니다.",
    "SelectA_Commentary": "MySQL에서 PostgreSQL로 스키마를 변환하는 필수 절차로, Aurora PostgreSQL로의 원활한 마이그레이션을 위해 반드시 필요합니다.",
    "SelectB": "AWS Database Migration Service (AWS DMS) Schema Conversion을 사용하여 RDS for MySQL DB instance에서 Aurora PostgreSQL read replica를 생성합니다.",
    "SelectB_Commentary": "Schema Conversion은 스키마 변환 역할이며, read replica 생성 기능을 제공하지 않으므로 잘못된 옵션입니다.",
    "SelectC": "RDS for MySQL DB instance에 대해 Aurora MySQL read replica를 구성합니다.",
    "SelectC_Commentary": "목표가 Aurora PostgreSQL이므로, Aurora MySQL read replica를 생성하는 것은 요구사항에 부합하지 않습니다.",
    "SelectD": "변경 데이터 캡처(CDC)를 사용하는 AWS Database Migration Service (AWS DMS) 태스크를 정의하여 데이터를 마이그레이션합니다.",
    "SelectD_Commentary": "마이그레이션 과정에서 발생하는 모든 데이터 변경을 실시간으로 전송해주므로, 요구사항 충족을 위한 핵심 단계입니다.",
    "SelectE": "replica lag가 0이 될 때 Aurora PostgreSQL read replica를 독립형 Aurora PostgreSQL DB cluster로 프로모션합니다.",
    "SelectE_Commentary": "해당 시나리오는 Aurora PostgreSQL로 직접 read replica를 생성해 증분 동기화하는 방식과 다르므로, 이 문제 해결에 맞는 조합이 아닙니다.",
    "Question_Description_recommedations": [
      "Q390",
      "Q601",
      "Q444",
      "Q125",
      "Q933"
    ],
    "SelectA_recommedations": [
      "Q843",
      "Q182",
      "Q293"
    ],
    "SelectB_recommedations": [
      "Q601",
      "Q705",
      "Q338"
    ],
    "SelectC_recommedations": [
      "Q601",
      "Q518",
      "Q705"
    ],
    "SelectD_recommedations": [
      "Q843",
      "Q133",
      "Q343"
    ],
    "SelectE_recommedations": [
      "Q755",
      "Q136",
      "Q601"
    ]
  },
  {
    "Question_Number": "Q706",
    "Question_Description": "한 회사가 여러 가용 영역에 배포된 Amazon RDS 인스턴스에서 동작하는 데이터베이스를 운영하고 있습니다. 이 회사는 주기적으로 스크립트를 실행하여 데이터베이스에 새로 추가된 항목을 보고합니다. 그러나 이 스크립트가 데이터베이스에 실행될 때 중요한 애플리케이션의 성능이 저하됩니다. 회사는 최소한의 비용으로 애플리케이션 성능을 개선하려고 합니다. 운영 오버헤드를 가장 적게 들이면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133216-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS 환경에서 주요 애플리케이션 성능 저하 없이 새로 추가된 데이터를 효율적으로 조회하는 방법을 묻습니다. Read Replica를 사용하면 읽기 트래픽을 분산하여 주 인스턴스 부담을 줄일 수 있으며 비용과 운영 복잡도도 낮출 수 있어 가장 적합한 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon RDS",
      "Multi-AZ",
      "Read Replica",
      "스크립트",
      "성능 개선",
      "비용 최소화"
    ],
    "Terms": [
      "Amazon RDS",
      "Multi-AZ Deployment",
      "Read Replica",
      "Amazon ElastiCache"
    ],
    "SelectA": "스크립트에 가장 활동이 적은 인스턴스를 식별하는 기능을 추가하고, 해당 인스턴스에 대해 스크립트를 실행합니다.",
    "SelectA_Commentary": "Multi-AZ 구성에서는 주 인스턴스와 대기 인스턴스가 동일하게 쓰기를 처리할 수 없고, 단순히 가장 유휴 상태의 인스턴스를 찾는 것만으로는 부담이 크게 줄지 않습니다.",
    "SelectB": "데이터베이스의 Read Replica를 생성하고, 스크립트를 오직 Read Replica에서만 실행하여 새로 추가된 항목을 조회합니다.",
    "SelectB_Commentary": "읽기 부하를 Read Replica로 오프로드하면 주 인스턴스 성능 저하를 막을 수 있고, 비용도 적게 들며 운영 오버헤드가 낮은 효과적인 방법입니다.",
    "SelectC": "개발 팀이 매일 하루가 끝날 때마다 데이터베이스에서 그날의 새 항목을 수동으로 내보내도록 지시합니다.",
    "SelectC_Commentary": "수작업 방식은 자동화가 없어 인력 투자와 오류 가능성이 높으며, 운영 오버헤드가 크고 편의성이 떨어집니다.",
    "SelectD": "Amazon ElastiCache를 사용하여 스크립트가 실행하는 일반적인 쿼리를 캐싱합니다.",
    "SelectD_Commentary": "ElastiCache로 일부 쿼리는 빠를 수 있으나, 새로 추가되는 항목을 실시간으로 확인해야 하는 스크립트에는 적합하지 않을 수 있고 관리 복잡도가 증가할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q661",
      "Q269",
      "Q193",
      "Q95",
      "Q726"
    ],
    "SelectA_recommedations": [
      "Q132",
      "Q888",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q506",
      "Q132",
      "Q888"
    ],
    "SelectC_recommedations": [
      "Q158",
      "Q888",
      "Q132"
    ],
    "SelectD_recommedations": [
      "Q746",
      "Q361",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q707",
    "Question_Description": "한 회사가 Application Load Balancer(ALB)를 사용하여 애플리케이션을 인터넷에 노출하고 있습니다. 회사는 애플리케이션 전반에서 비정상적인 트래픽 접근 패턴을 발견했습니다. 솔루션스 아키텍트는 이러한 비정상 패턴을 더 잘 이해하기 위해 인프라에 대한 가시성을 높이고 싶어 합니다. 이 요구 사항을 충족하면서 운영 효율성이 가장 높은 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132874-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB를 통해 유입되는 트래픽 패턴을 분석해 이상 징후를 파악하고, 이를 가장 간단하고 효율적으로 수행하는 방법을 찾는 것입니다. ALB Access Logging을 Amazon S3에 활성화하고 Athena를 통해 쿼리하면 별도의 인프라 구성 없이 빠르게 로그를 분석할 수 있어 운영 복잡성을 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "비정상 트래픽",
      "인프라 가시성",
      "운영 효율성",
      "ALB 액세스 로그",
      "Amazon S3",
      "Amazon Athena"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "AWS CloudTrail",
      "Amazon Athena",
      "Amazon S3",
      "Amazon EMR",
      "Amazon EC2"
    ],
    "SelectA": "AWS CloudTrail 로그에 대한 Amazon Athena 테이블을 생성하고, 필요한 정보를 조회할 쿼리를 작성합니다.",
    "SelectA_Commentary": "CloudTrail은 AWS API 호출을 기록하므로 ALB의 세부 트래픽 구성을 분석하기에는 한계가 있습니다. ALB Access Log와 직접 연계되지 않으므로 운영상 적절하지 않습니다.",
    "SelectB": "ALB Access Logging을 Amazon S3에 활성화하고, Amazon Athena에 테이블을 생성하여 로그를 쿼리합니다.",
    "SelectB_Commentary": "가장 효율적인 해결책입니다. ALB Access Log를 S3에 저장하고 Athena로 직접 분석하면 빠르고 간단하게 트래픽 패턴을 모니터링하고 이상 징후를 파악할 수 있습니다.",
    "SelectC": "ALB Access Logging을 Amazon S3에 활성화한 뒤, 각 로그 파일을 텍스트 에디터로 열어 필요한 정보를 직접 검색합니다.",
    "SelectC_Commentary": "수작업으로 파일을 열어 분석하는 방식은 데이터 양이 많아질수록 비효율적이며, 자동화와 확장성 측면에서 적합하지 않습니다.",
    "SelectD": "전용 Amazon EC2 인스턴스에서 Amazon EMR을 사용하여 ALB를 직접 쿼리하고 트래픽 접근 로그를 수집합니다.",
    "SelectD_Commentary": "EMR 클러스터 구성과 운영에 추가 비용과 작업이 필요하며, 기본 제공되는 S3와 Athena를 사용하는 것이 훨씬 단순하고 효율적입니다.",
    "Question_Description_recommedations": [
      "Q169",
      "Q625",
      "Q884",
      "Q437",
      "Q170"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q970",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q884",
      "Q862"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q884",
      "Q678"
    ],
    "SelectD_recommedations": [
      "Q480",
      "Q176",
      "Q682"
    ]
  },
  {
    "Question_Number": "Q708",
    "Question_Description": "한 회사가 AWS 환경에서 NAT gateway를 사용하려고 합니다. 이 회사의 Amazon EC2 인스턴스는 private subnet에 있고, NAT gateway를 통해 public internet에 연결할 수 있어야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132875-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "private subnet에 있는 Amazon EC2 인스턴스가 NAT gateway를 통해 public internet에 접속하려면, NAT gateway가 public subnet에 위치하고 internet gateway와 연결되어야 합니다. private subnet 내 NAT gateway는 외부 인터넷과 직접 통신할 수 없으므로 잘못된 구성입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "NAT gateway",
      "Amazon EC2",
      "private subnet",
      "public subnet",
      "public internet",
      "VPC"
    ],
    "Terms": [
      "public NAT gateway",
      "private NAT gateway",
      "public subnet",
      "private subnet",
      "Amazon EC2",
      "VPC"
    ],
    "SelectA": "EC2 인스턴스와 동일한 private subnet에 public NAT gateway를 생성합니다.",
    "SelectA_Commentary": "private subnet에서는 NAT gateway가 internet gateway에 직접 연결될 수 없으므로 외부 인터넷 접속이 불가능합니다.",
    "SelectB": "EC2 인스턴스와 동일한 private subnet에 private NAT gateway를 생성합니다.",
    "SelectB_Commentary": "private NAT gateway 역시 외부 인터넷 통신이 불가능하며, 온프레미스나 VPC 간 트래픽에 주로 사용됩니다.",
    "SelectC": "EC2 인스턴스가 있는 VPC 내 public subnet에 public NAT gateway를 생성합니다.",
    "SelectC_Commentary": "공용 서브넷에 NAT gateway를 두어 인터넷 게이트웨이와 연결함으로써 private subnet의 EC2가 정상적으로 인터넷에 접근할 수 있는 올바른 구성입니다.",
    "SelectD": "EC2 인스턴스가 있는 VPC 내 public subnet에 private NAT gateway를 생성합니다.",
    "SelectD_Commentary": "private NAT gateway는 인터넷 게이트웨이가 아닌 내부 통신용이며, 외부 인터넷 접속이 불가능합니다.",
    "Question_Description_recommedations": [
      "Q230",
      "Q10",
      "Q487",
      "Q545",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q708",
      "Q487",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q708",
      "Q487",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q708",
      "Q439",
      "Q487"
    ],
    "SelectD_recommedations": [
      "Q708",
      "Q439",
      "Q487"
    ]
  },
  {
    "Question_Number": "Q709",
    "Question_Description": "한 회사가 AWS Organizations에서 organization을 구성하였습니다. 이 회사는 root organizational unit (OU)에 있는 네 개의 AWS accounts에서 Amazon EC2 instances를 운영하고 있습니다. 세 개의 계정은 nonproduction accounts이고, 하나는 production account입니다. 해당 회사는 nonproduction accounts에서 특정 사이즈의 EC2 instances를 사용할 수 없도록 막길 원합니다. 이를 위해 service control policy (SCP)를 생성하여 prohibited types를 사용하는 인스턴스 런칭을 거부하도록 설정했습니다. 다음 중 SCP를 배포하여 이러한 요구사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132876-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 nonproduction 계정에서만 특정 EC2 타입을 제한하려면, SCP를 해당 계정이나 별도 OU에 적용해야 한다는 점을 묻습니다. production 계정을 분리하고 nonproduction만 제한하는 SelectB와 SelectE가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "nonproduction accounts",
      "production account",
      "Amazon EC2",
      "service control policy",
      "root OU",
      "prohibited instance types"
    ],
    "Terms": [
      "AWS Organizations",
      "root organizational unit (OU)",
      "AWS accounts",
      "Amazon EC2",
      "service control policy (SCP)",
      "nonproduction account",
      "production account",
      "management account"
    ],
    "SelectA": "조직의 root OU에 SCP를 연결합니다.",
    "SelectA_Commentary": "root OU에 적용하면 production 계정까지 제한되어 요구사항에 맞지 않습니다.",
    "SelectB": "세 개의 nonproduction Organizations member accounts에 SCP를 연결합니다.",
    "SelectB_Commentary": "nonproduction 계정만 직접 제한하므로 원하는 요구사항을 만족합니다. 올바른 선택입니다.",
    "SelectC": "Organizations management account에 SCP를 연결합니다.",
    "SelectC_Commentary": "management account는 전체 조직 관리 목적이며, 특정 계정만 제한하기에는 부적합합니다.",
    "SelectD": "production account를 위한 OU를 만들고 해당 OU에 SCP를 연결한 뒤, production member account를 새 OU로 이동시킵니다.",
    "SelectD_Commentary": "production 계정이 OU에 연결된 SCP의 영향을 받을 수 있어 불필요하고 해결책과 어긋납니다.",
    "SelectE": "필요한 계정을 위한 OU를 생성하고 그 OU에 SCP를 연결합니다. 이후 nonproduction member accounts를 새 OU로 이동시킵니다.",
    "SelectE_Commentary": "nonproduction 계정을 별도로 묶어 SCP를 적용하므로 production 계정에는 영향이 없으며 요구사항을 충족합니다. 올바른 선택입니다.",
    "Question_Description_recommedations": [
      "Q988",
      "Q560",
      "Q419",
      "Q878",
      "Q3"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q106",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q168",
      "Q945",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q106",
      "Q893"
    ],
    "SelectE_recommedations": [
      "Q678",
      "Q106",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q710",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 호스팅되는 웹사이트를 운영하며, Amazon S3에 저장된 기밀 데이터를 처리하고 있습니다. 보안상의 우려로 인해, 회사는 EC2 리소스와 Amazon S3 간에 사설이며 안전한 연결이 필요합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133462-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "해당 문제는 폐쇄형 네트워크 환경에서 EC2와 S3를 직접 연결해 데이터를 보호하는 방법을 묻습니다. S3에 대한 프라이빗 연결을 제공하는 VPC Endpoint를 통해 외부 인터넷을 거치지 않고 안전하게 통신이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "기밀 데이터",
      "사설 연결",
      "VPC 엔드포인트",
      "보안 액세스"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "VPC Endpoint",
      "S3 Bucket Policy",
      "IAM Policy",
      "NAT Gateway",
      "Access Key ID",
      "Secret Access Key"
    ],
    "SelectA": "S3 버킷 정책을 설정하여 VPC 엔드포인트에서의 액세스를 허용합니다.",
    "SelectA_Commentary": "VPC Endpoint를 통해 EC2에서 S3로 직접 연결할 수 있어 인터넷 노출을 줄이고 보안이 강화됩니다. 버킷 정책을 통해 VPC Endpoint에서만 접근을 허용할 수 있으므로 요구 사항을 충족합니다.",
    "SelectB": "IAM 정책을 설정하여 S3 버킷에 대한 읽기-쓰기 권한을 부여합니다.",
    "SelectB_Commentary": "IAM 정책은 인증 및 권한 부여 측면만 담당하며, 연결 자체가 사설 경로를 거치도록 보장하지 않습니다.",
    "SelectC": "NAT 게이트웨이를 설정하여 프라이빗 서브넷 밖의 리소스에 액세스합니다.",
    "SelectC_Commentary": "NAT 게이트웨이는 사설 서브넷에서 인터넷으로의 아웃바운드 트래픽을 가능하게 하지만, 여전히 외부 인터넷 경유이며 사설 연결 보장과는 거리가 있습니다.",
    "SelectD": "액세스 키 ID와 시크릿 액세스 키를 사용하여 S3 버킷에 액세스합니다.",
    "SelectD_Commentary": "자격 증명은 인증 수단일 뿐이며 EC2와 S3 간 사설 연결이 보장되지 않습니다. 데이터 전송 경로는 여전히 인터넷을 통하게 됩니다.",
    "Question_Description_recommedations": [
      "Q17",
      "Q453",
      "Q612",
      "Q480",
      "Q329"
    ],
    "SelectA_recommedations": [
      "Q92",
      "Q825",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q825",
      "Q925"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q711",
    "Question_Description": "한 전자상거래 회사가 AWS에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 기본 데이터베이스로 Multi-AZ 모드의 Amazon Aurora PostgreSQL 클러스터를 사용 중입니다. 최근 프로모션 캠페인 기간 동안 애플리케이션은 매우 높은 읽기 및 쓰기 부하를 경험했고, 사용자들은 애플리케이션에 접속 시 타임아웃 문제가 발생했습니다. 한 Solutions Architect는 이 애플리케이션 아키텍처를 더 확장 가능하고 고가용성으로 만들기를 원합니다. 가장 적은 다운타임으로 이러한 요구 사항을 충족하려면 어떤 솔루션을 구현해야 할까요?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132882-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 증가한 읽기·쓰기 부하를 처리하면서도 최대한 다운타임 없이 확장성과 고가용성을 보장하는 것입니다. 추가 리더 인스턴스를 통해 읽기 부하를 분산시키고, Amazon RDS Proxy를 사용하면 연결 관리를 효율화해 애플리케이션의 성능과 안정성을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "전자상거래",
      "Multi-AZ 모드",
      "Amazon Aurora PostgreSQL",
      "읽기 부하",
      "확장 가능",
      "고가용성",
      "다운타임 최소화",
      "추가 리더 인스턴스",
      "Amazon RDS Proxy"
    ],
    "Terms": [
      "Amazon Aurora PostgreSQL",
      "Multi-AZ",
      "Amazon EventBridge",
      "AWS Lambda",
      "Zero-Downtime Restart(ZDR)",
      "Database Activity Streams",
      "Amazon RDS Proxy",
      "Amazon ElastiCache for Redis",
      "AWS Database Migration Service(AWS DMS)",
      "Write-around approach",
      "Reader instance"
    ],
    "SelectA": "Aurora 클러스터를 소스로 Amazon EventBridge 규칙을 생성하고, Aurora 상태 변경 이벤트를 로그로 남길 AWS Lambda 함수를 구성합니다. 해당 Lambda 함수를 EventBridge 규칙 대상에 추가하고, 장애 조치에 대비해 추가 리더 노드를 추가합니다.",
    "SelectA_Commentary": "EventBridge와 Lambda를 통한 상태 추적은 유용할 수 있지만 단순 모니터링 및 로깅 중심이며, 읽기 부하 해소 및 연결 최적화 방안이 부족합니다.",
    "SelectB": "Aurora 클러스터를 수정하고 Zero-Downtime Restart(ZDR) 기능을 활성화합니다. Database Activity Streams를 사용하여 클러스터 상태를 추적합니다.",
    "SelectB_Commentary": "ZDR와 Database Activity Streams는 재시작 시의 다운타임은 줄일 수 있지만, 근본적으로 읽기 부하 처리나 연결 관리를 개선하는 직접적인 해결책은 아닙니다.",
    "SelectC": "Aurora 클러스터에 추가 리더 인스턴스를 추가합니다. Aurora 클러스터용 Amazon RDS Proxy 타겟 그룹을 생성합니다.",
    "SelectC_Commentary": "추가 리더 인스턴스를 통해 읽기 부하를 확장해 처리할 수 있고, Amazon RDS Proxy가 애플리케이션 연결을 효율적으로 관리하여 다운타임을 최소화하고 안정성을 높이는 최적의 솔루션입니다.",
    "SelectD": "Amazon ElastiCache for Redis를 생성하고, AWS Database Migration Service(AWS DMS)의 write-around 방식을 사용해 Aurora 클러스터에서 Redis로 데이터를 복제합니다.",
    "SelectD_Commentary": "Redis 캐싱 전략은 읽기 속도 향상에는 도움이 될 수 있지만, Aurora에 대한 직접 확장이나 가용성 개선 방안은 아니며, 추가 복잡성과 동기화 부담이 커 제대로 된 즉각적인 확장성 솔루션이 되기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q479",
      "Q288",
      "Q138",
      "Q454",
      "Q879"
    ],
    "SelectA_recommedations": [
      "Q569",
      "Q25",
      "Q87"
    ],
    "SelectB_recommedations": [
      "Q896",
      "Q338",
      "Q955"
    ],
    "SelectC_recommedations": [
      "Q601",
      "Q136",
      "Q462"
    ],
    "SelectD_recommedations": [
      "Q601",
      "Q338",
      "Q896"
    ]
  },
  {
    "Question_Number": "Q712",
    "Question_Description": "한 회사가 AWS에서 웹 애플리케이션을 설계 중입니다. 이 애플리케이션은 회사의 기존 데이터 센터와 회사의 VPC들 간 VPN 연결을 사용할 예정입니다. 회사는 Amazon Route 53을 DNS 서비스로 사용합니다. 애플리케이션은 VPC에서 온프레미스 서비스와 통신하기 위해 private DNS 레코드를 사용해야 합니다. 이러한 요구사항을 가장 안전하게 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132883-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC에서 온프레미스 DNS를 안전하게 조회하기 위해 어떤 설정이 필요한지 묻습니다. 온프레미스 DNS 서버로 쿼리를 전달하려면 VPC 내부에서 외부로 나가는 'outbound endpoint'가 적합하며, 이를 Route 53 Resolver와 resolver rule로 구성해 사용합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPN",
      "Amazon Route 53",
      "private DNS 레코드",
      "Route 53 Resolver outbound endpoint"
    ],
    "Terms": [
      "VPN",
      "VPC",
      "Amazon Route 53",
      "Route 53 Resolver inbound endpoint",
      "Route 53 Resolver outbound endpoint",
      "private hosted zone",
      "public hosted zone"
    ],
    "SelectA": "Route 53 Resolver outbound endpoint를 생성합니다. resolver rule을 생성합니다. 이 resolver rule을 VPC와 연결합니다.",
    "SelectA_Commentary": "VPC에서 온프레미스 DNS 서버로 안전하게 쿼리를 전달하기 위한 올바른 접근 방식입니다. outbound endpoint와 resolver rule을 통해 사설 DNS 레코드를 쉽게 조회할 수 있습니다.",
    "SelectB": "Route 53 Resolver inbound endpoint를 생성합니다. resolver rule을 생성합니다. 이 resolver rule을 VPC와 연결합니다.",
    "SelectB_Commentary": "inbound endpoint는 온프레미스나 다른 VPC가 VPC 내 DNS 레코드를 조회할 때 사용합니다. 여기서는 VPC에서 온프레미스 DNS 조회가 필요하므로 부적합합니다.",
    "SelectC": "Route 53 private hosted zone을 생성합니다. 이 private hosted zone을 VPC와 연결합니다.",
    "SelectC_Commentary": "VPC 내부 서비스의 DNS 레코드 전용 영역을 생성하는 것이며, 온프레미스 DNS 조회를 해결하지 못하므로 요구사항에 맞지 않습니다.",
    "SelectD": "Route 53 public hosted zone을 생성합니다. 서비스별 record를 생성하여 서비스 통신을 허용합니다.",
    "SelectD_Commentary": "public hosted zone은 퍼블릭 인터넷에서 검색 가능하므로 사설 DNS 통신이나 보안을 보장하기 어렵고, 요구사항인 온프레미스 서비스 연결에도 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q782",
      "Q950",
      "Q532",
      "Q810",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q135",
      "Q151",
      "Q532"
    ],
    "SelectB_recommedations": [
      "Q151",
      "Q135",
      "Q468"
    ],
    "SelectC_recommedations": [
      "Q468",
      "Q712",
      "Q151"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q106",
      "Q678"
    ]
  },
  {
    "Question_Number": "Q713",
    "Question_Description": "한 회사가 us-east-1 리전에서 사진 호스팅 서비스를 운영하고 있습니다. 이 서비스는 여러 국가의 사용자가 사진을 업로드하고 확인할 수 있도록 합니다. 일부 사진은 수개월 동안 자주 조회되지만, 어떤 사진은 일주일 미만으로만 조회됩니다. 애플리케이션은 사진당 최대 20MB까지 업로드를 허용합니다. 서비스는 각 사용자에게 어떤 사진을 표시할지 결정하기 위해 사진 메타데이터를 사용합니다. 어떤 솔루션이 적절한 사용자 접근성을 제공하면서 가장 비용 효율적입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132885-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다양한 조회 패턴의 사진을 비용 효율적으로 저장하면서, 동시에 빠른 조회를 보장할 수 있는 방법을 묻고 있습니다. Amazon S3 Intelligent-Tiering은 사진 조회 빈도에 따라 객체를 자동으로 적절한 티어로 이동하므로 다이나믹한 액세스 패턴에 가장 적합합니다. 메타데이터는 Amazon DynamoDB를 활용해 빠른 검색을 지원할 수 있으므로, 전반적인 사용자 접근성 및 비용 절감 측면에서 뛰어난 방식입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "S3 Intelligent-Tiering",
      "DynamoDB",
      "비용 효율",
      "사진 호스팅",
      "메타데이터"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon S3 Intelligent-Tiering",
      "Amazon S3 Standard",
      "S3 Lifecycle policy",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "Amazon S3 Glacier",
      "S3 Glacier Deep Archive",
      "Amazon OpenSearch Service"
    ],
    "SelectA": "Amazon DynamoDB에 사진을 저장하고, DynamoDB Accelerator(DAX)를 활성화하여 자주 조회되는 항목을 캐싱합니다.",
    "SelectA_Commentary": "DynamoDB는 대규모 구조화 데이터를 저장하는 데 적합하지만, 20MB 사진 같은 큰 객체를 저장하기에는 비용이 매우 높고 비효율적입니다.",
    "SelectB": "Amazon S3 Intelligent-Tiering 스토리지 클래스를 사용해 사진을 저장합니다. 사진 메타데이터와 해당 S3 위치는 DynamoDB에 저장합니다.",
    "SelectB_Commentary": "조회 빈도에 따라 S3 Intelligent-Tiering이 자동으로 객체 티어를 조정해 비용을 절감하며, DynamoDB는 빠른 메타데이터 조회를 지원하므로 가장 효율적인 솔루션입니다.",
    "SelectC": "Amazon S3 Standard 스토리지 클래스에 사진을 저장하고, 30일이 지난 사진은 S3 Lifecycle 정책으로 S3 Standard-Infrequent Access로 이동합니다. S3 객체 태그로 메타데이터를 관리합니다.",
    "SelectC_Commentary": "30일 기준 고정 정책은 사진 조회 패턴에 유연하게 대응하기 어렵고, 자주 조회되던 사진이 갑자기 조회가 줄어드는 경우를 효율적으로 처리하기 힘듭니다.",
    "SelectD": "Amazon S3 Glacier 스토리지 클래스에 사진을 저장하고, 30일이 지난 사진은 S3 Lifecycle 정책으로 S3 Glacier Deep Archive로 이동합니다. 사진 메타데이터와 해당 S3 위치를 Amazon OpenSearch Service에 저장합니다.",
    "SelectD_Commentary": "Glacier 계열은 장기 보관용으로, 잦은 접근이 필요한 사진을 조회하는 데 복구 비용과 시간이 많이 들어 실시간 대응에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q374",
      "Q66",
      "Q147",
      "Q1003",
      "Q49"
    ],
    "SelectA_recommedations": [
      "Q670",
      "Q79",
      "Q348"
    ],
    "SelectB_recommedations": [
      "Q799",
      "Q993",
      "Q415"
    ],
    "SelectC_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q912",
      "Q606",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q714",
    "Question_Description": "한 회사가 Application Load Balancer 뒤의 Amazon EC2 인스턴스들로 구성된 고가용성 웹 애플리케이션을 운영 중이며, Amazon CloudWatch 지표를 사용하고 있습니다. 트래픽이 증가함에 따라 일부 EC2 인스턴스가 처리되지 않은 요청으로 과부하 상태에 이르렀고, 해당 인스턴스들은 다른 인스턴스보다 더 많은 요청을 처리하면서 응답 속도 또한 느려집니다. 회사는 이미 과부하된 EC2 인스턴스에 새로운 요청을 전달하고 싶지 않습니다. 이를 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132887-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB 설정을 통해 과부하된 인스턴스에 대한 새로운 요청을 차단하고 트래픽을 균등하게 분산하는 방법을 묻습니다. 'RequestCountPerTarget'와 'ActiveConnectionCount' 지표를 활용하여 인스턴스 부하를 확인하고, 'least outstanding requests' 알고리즘으로 과부하를 방지합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성 웹 애플리케이션",
      "Application Load Balancer",
      "과부하",
      "CloudWatch 지표",
      "RequestCountPerTarget",
      "ActiveConnectionCount",
      "least outstanding requests",
      "round robin",
      "TargetResponseTime"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon CloudWatch",
      "round robin routing algorithm",
      "least outstanding requests algorithm",
      "RequestCountPerTarget",
      "ActiveConnectionCount",
      "RequestCount",
      "TargetResponseTime"
    ],
    "SelectA": "RequestCountPerTarget와 ActiveConnectionCount CloudWatch 지표에 기반한 round robin 라우팅 알고리즘을 사용합니다.",
    "SelectA_Commentary": "round robin은 단순 순환 방식으로, 이미 과부하된 인스턴스에 트래픽이 계속 전달될 수 있어 요구사항을 충족하지 못합니다.",
    "SelectB": "RequestCountPerTarget와 ActiveConnectionCount CloudWatch 지표에 기반한 least outstanding requests 알고리즘을 사용합니다.",
    "SelectB_Commentary": "각 인스턴스의 현재 요청 수와 연결 상태를 파악해 과부하 인스턴스를 제외하고 트래픽을 분산하므로, 문제 요구사항을 만족하는 최적의 방법입니다.",
    "SelectC": "RequestCount와 TargetResponseTime CloudWatch 지표에 기반한 round robin 라우팅 알고리즘을 사용합니다.",
    "SelectC_Commentary": "RequestCount는 ALB 전체 요청 건수를 나타내어 인스턴스별 과부하를 정확히 파악하기 어렵고, round robin 또한 부하 상태를 반영하지 못합니다.",
    "SelectD": "RequestCount와 TargetResponseTime CloudWatch 지표에 기반한 least outstanding requests 알고리즘을 사용합니다.",
    "SelectD_Commentary": "RequestCount 값이 ALB 전체 통계를 기준으로 하여 인스턴스별 실제 부하를 식별하기 어려워, 과부하 인스턴스를 효율적으로 제외할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q357",
      "Q275",
      "Q5",
      "Q1012",
      "Q405"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q311",
      "Q714"
    ],
    "SelectB_recommedations": [
      "Q351",
      "Q714",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q311",
      "Q351"
    ],
    "SelectD_recommedations": [
      "Q351",
      "Q660",
      "Q311"
    ]
  },
  {
    "Question_Number": "Q715",
    "Question_Description": "한 회사는 회사의 AWS 계정에서 여러 워크로드를 실행하기 위해 Amazon EC2, AWS Fargate, 그리고 AWS Lambda를 사용하고 있습니다. 회사는 Compute Savings Plans를 최대한 활용하고 싶어합니다. 또한 Compute Savings Plans의 커버리지가 감소할 때 알림을 받고 싶어합니다. 운영 효율성을 가장 높이면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132888-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Compute Savings Plans의 커버리지를 모니터링하고 감소 시점에 자동으로 알림을 받아 비용 활용도를 극대화하는 방법을 묻습니다. AWS Budgets를 사용하면 coverage threshold를 설정해 커버리지 수준이 특정 기준 이하로 떨어질 때 이메일 알림을 자동으로 발송할 수 있어 운영 효율성이 가장 뛰어납니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "AWS Fargate",
      "AWS Lambda",
      "Compute Savings Plans",
      "커버리지 감소 알림",
      "AWS Budgets",
      "운영 효율성"
    ],
    "Terms": [
      "Compute Savings Plans",
      "AWS Budgets",
      "Savings Plans coverage",
      "coverage threshold",
      "Amazon EC2",
      "AWS Fargate",
      "AWS Lambda",
      "Amazon Simple Email Service(Amazon SES)",
      "Savings Plans alert subscription"
    ],
    "SelectA": "AWS Budgets를 사용해 Savings Plans에 대한 일간 예산을 생성합니다. coverage threshold를 설정하여 적절한 이메일 수신자에게 알림을 보냅니다.",
    "SelectA_Commentary": "AWS Budgets에서 coverage threshold를 지정해 자동 알림을 받을 수 있어 운영 측면에서 간단하고 효과적입니다.",
    "SelectB": "Savings Plans의 coverage report를 실행하는 Lambda 함수를 생성합니다. Amazon Simple Email Service(Amazon SES)를 사용하여 해당 보고서를 적절한 이메일 수신자에게 전송합니다.",
    "SelectB_Commentary": "직접 Lambda 함수를 작성하고 보고서를 생성해야 하므로 운영 부담이 늘어나고, AWS Budgets에 비해 구성과 유지보수가 복잡합니다.",
    "SelectC": "Savings Plans 예산에 대한 AWS Budgets report를 생성합니다. 빈도를 일간으로 설정합니다.",
    "SelectC_Commentary": "일간 리포트를 통해 모니터링은 가능하지만, 커버리지 감소 시 즉시 알림 기능을 직접 설정하기 어렵고 대응이 지연될 수 있습니다.",
    "SelectD": "Savings Plans alert subscription을 생성합니다. 모든 알림 옵션을 활성화합니다. 알림을 받을 이메일 주소를 입력합니다.",
    "SelectD_Commentary": "기본 알림 기능만으로는 커버리지 수준을 목표치로 설정하고 세밀하게 모니터링하기가 어렵고, Budgets 기능 대비 알림 조건이 제한적입니다.",
    "Question_Description_recommedations": [
      "Q885",
      "Q543",
      "Q140",
      "Q467",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q885",
      "Q543",
      "Q467"
    ],
    "SelectB_recommedations": [
      "Q885",
      "Q715",
      "Q543"
    ],
    "SelectC_recommedations": [
      "Q885",
      "Q543",
      "Q467"
    ],
    "SelectD_recommedations": [
      "Q997",
      "Q630",
      "Q49"
    ]
  },
  {
    "Question_Number": "Q716",
    "Question_Description": "한 회사가 AWS 상에서 실시간 데이터 수집 솔루션을 운영하고 있습니다. 이 솔루션은 최신 버전의 Amazon Managed Streaming for Apache Kafka(Amazon MSK)로 구성됩니다. 이 솔루션은 3개 가용 영역에 걸친 사설 서브넷이 있는 VPC에 배포되어 있습니다. 솔루션스 아키텍트가 이 데이터 수집 솔루션을 인터넷에서 공개적으로 접근 가능하도록 재설계해야 합니다. 전송 중인 데이터도 암호화되어야 합니다. 이러한 요구 사항을 충족하면서 운영 효율성을 가장 높이는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132889-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이미 사설 서브넷에 위치한 Amazon MSK 클러스터를 인터넷에서도 직접 액세스해야 하며, 전송 중인 데이터는 암호화(TLS)를 적용해야 하는 상황입니다. 가장 효율적인 방법은 기존 VPC에 퍼블릭 서브넷을 추가하고, 해당 서브넷에서 Amazon MSK 클러스터를 구동한 다음 mutual TLS를 활성화해 보안을 유지하는 것입니다. 별도의 VPC 생성이나 ALB, NLB를 사용하는 것은 추가적인 네트워크 설정과 프로토콜 제약으로 인해 복잡성이 증가합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "실시간 데이터 수집",
      "공개적으로 접근 가능",
      "데이터 암호화",
      "Amazon MSK"
    ],
    "Terms": [
      "Amazon MSK",
      "VPC",
      "Private Subnet",
      "Public Subnet",
      "TLS",
      "mutual TLS authentication",
      "Application Load Balancer(ALB)",
      "Network Load Balancer(NLB)"
    ],
    "SelectA": "기존 VPC에 퍼블릭 서브넷을 구성하고, 해당 퍼블릭 서브넷에 MSK 클러스터를 배포합니다. MSK 클러스터의 보안 설정을 갱신하여 mutual TLS 인증을 활성화합니다.",
    "SelectA_Commentary": "기존 VPC를 그대로 활용해 퍼블릭 액세스를 제공하면서 TLS 암호화를 적용할 수 있어 운영상 가장 간단하고 효율적인 방법입니다.",
    "SelectB": "퍼블릭 서브넷이 있는 새 VPC를 생성하고, 그 퍼블릭 서브넷에 MSK 클러스터를 배포합니다. 이후 MSK 클러스터의 보안 설정을 갱신하여 mutual TLS 인증을 활성화합니다.",
    "SelectB_Commentary": "새 VPC를 구성하면 기존 환경과의 연결 설정 등 추가 작업이 필요해 운영 복잡도가 커집니다.",
    "SelectC": "사설 서브넷을 사용하는 Application Load Balancer(ALB)를 배포합니다. ALB 보안 그룹에 HTTPS 프로토콜을 위해 VPC CIDR 블록에서의 인바운드 트래픽을 허용하도록 구성합니다.",
    "SelectC_Commentary": "ALB는 주로 HTTP/HTTPS 프로토콜 트래픽에 적합하며, Kafka 트래픽(TCP/UDP)까지 처리하기엔 제한적이며 Public 접근도 어렵습니다.",
    "SelectD": "사설 서브넷을 사용하는 Network Load Balancer(NLB)를 배포합니다. 인터넷에서의 HTTPS 통신을 위해 NLB 리스너를 구성합니다.",
    "SelectD_Commentary": "NLB는 TCP 기반 트래픽을 처리할 수 있지만 사설 서브넷에 배포하면 인터넷 접근이 불가능하며 추가 구성이 필요해 운영 효율이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q15",
      "Q950",
      "Q805",
      "Q862",
      "Q92"
    ],
    "SelectA_recommedations": [
      "Q950",
      "Q135",
      "Q15"
    ],
    "SelectB_recommedations": [
      "Q950",
      "Q135",
      "Q15"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q1016",
      "Q169"
    ],
    "SelectD_recommedations": [
      "Q169",
      "Q60",
      "Q644"
    ]
  },
  {
    "Question_Number": "Q717",
    "Question_Description": "한 회사가 온프레미스 레거시 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 애플리케이션은 온프레미스 ERP(enterprise resource planning) 시스템에서 고객 주문 파일을 가져오며, 파일을 SFTP 서버로 업로드합니다. 또한 애플리케이션은 매시간 주문 파일이 있는지 확인하는 예약 작업을 사용합니다. 이미 온프레미스 네트워크와 연결된 AWS 계정이 있으며, 신규 AWS 환경은 기존 ERP 시스템과의 통합을 지원해야 합니다. 신규 애플리케이션은 보안성과 복원력을 갖추고, SFTP 프로토콜을 통해 ERP 시스템에서 오는 주문을 즉시 처리해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132890-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 ERP 시스템과 바로 연동할 수 있는 안전하고 고가용성인 SFTP 솔루션을 AWS에서 구현하는 방법을 묻습니다. 내부 전용(Internal) SFTP 서버를 두 개의 Availability Zone에서 운영하고, Amazon S3와 Lambda를 연동하여 주문 파일을 즉시 처리함으로써 보안성과 복원력을 모두 충족해야 합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "AWS로 마이그레이션",
      "온프레미스 ERP",
      "SFTP 프로토콜",
      "보안성과 복원력",
      "즉시 처리"
    ],
    "Terms": [
      "AWS Transfer Family SFTP",
      "Amazon S3",
      "Amazon Elastic File System (Amazon EFS)",
      "AWS Lambda",
      "S3 Event Notifications",
      "Transfer Family managed workflow",
      "AWS Step Functions",
      "Amazon EventBridge Scheduler",
      "Availability Zones",
      "on-premises enterprise resource planning (ERP)"
    ],
    "SelectA": "두 개의 Availability Zone에서 AWS Transfer Family SFTP 인터넷 공개 서버를 생성하고, Amazon S3 스토리지를 사용합니다. AWS Lambda 함수를 생성하여 S3 Event Notifications를 통해 s3:ObjectCreated:* 이벤트가 발생하면 함수를 호출하도록 설정합니다.",
    "SelectA_Commentary": "인터넷 공개 서버이므로 내부 전용 접근 요구 사항을 완전히 충족하기 어렵고, Transfer Family managed workflow를 활용하지 않아 처리 과정 단순화가 상대적으로 부족합니다.",
    "SelectB": "하나의 Availability Zone에서 AWS Transfer Family SFTP 인터넷 공개 서버를 생성하고, Amazon Elastic File System(Amazon EFS)를 스토리지로 사용합니다. AWS Lambda 함수를 생성하고, Transfer Family managed workflow를 통해 함수를 호출합니다.",
    "SelectB_Commentary": "한 개의 AZ만 사용하기 때문에 복원력이 낮아 고가용성 요건을 충족하지 못합니다.",
    "SelectC": "두 개의 Availability Zone에서 AWS Transfer Family SFTP 내부 서버를 생성하고, Amazon Elastic File System(Amazon EFS)를 스토리지로 사용합니다. 주문 파일 처리를 위해 AWS Step Functions 상태 머신을 생성하고, Amazon EventBridge Scheduler를 사용해 주기적으로 EFS를 확인합니다.",
    "SelectC_Commentary": "EventBridge Scheduler를 통한 주기적 확인으로 즉시 처리 요구 사항을 충족하기 어렵고, 실제 처리 흐름이 복잡해집니다.",
    "SelectD": "두 개의 Availability Zone에서 AWS Transfer Family SFTP 내부 서버를 생성하고, Amazon S3 스토리지를 사용합니다. AWS Lambda 함수를 생성하고, Transfer Family managed workflow를 통해 함수를 호출합니다.",
    "SelectD_Commentary": "내부 전용 SFTP 서버를 다중 AZ로 구성해 복원력을 높이고, Transfer Family managed workflow가 파일 업로드 시 즉시 Lambda를 호출해 보안성과 신속한 처리를 모두 만족합니다.",
    "Question_Description_recommedations": [
      "Q753",
      "Q843",
      "Q188",
      "Q293",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q636",
      "Q188",
      "Q98"
    ],
    "SelectB_recommedations": [
      "Q842",
      "Q102",
      "Q934"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q934"
    ],
    "SelectD_recommedations": [
      "Q188",
      "Q753",
      "Q987"
    ]
  },
  {
    "Question_Number": "Q718",
    "Question_Description": "한 회사는 내부(On Premises)에서 Apache Hadoop과 Apache Spark를 사용해 데이터를 처리하고 있습니다. 현재 인프라는 확장성이 부족하고 관리가 복잡합니다. 솔루션스 아키텍트는 확장 가능하면서 운영 복잡성을 줄이는 솔루션을 설계해야 합니다. 단, 데이터 처리는 반드시 사내(On Premises)에서 이루어져야 합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132891-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 사내(On Premises)에서 데이터 처리를 유지하면서도 확장성과 운영 편의성을 높이는 방법을 찾는 것입니다. AWS Outposts를 사용하면 물리적으로 사내에 하드웨어를 설치하여 AWS 리소스를 로컬로 활용할 수 있어, Amazon EMR을 사용한 Hadoop·Spark 처리 환경을 그대로 on premises에서 운영할 수 있습니다. 이는 관리 부담을 줄이면서도 확장 가능한 솔루션을 제공하므로 요구사항을 만족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2"
    ],
    "Keywords": [
      "Apache Hadoop",
      "Apache Spark",
      "데이터 처리",
      "On Premises",
      "AWS Outposts",
      "Amazon EMR"
    ],
    "Terms": [
      "AWS Site-to-Site VPN",
      "Hadoop Distributed File System (HDFS)",
      "Amazon EMR",
      "AWS DataSync",
      "AWS Outposts",
      "AWS Snowball",
      "Amazon S3"
    ],
    "SelectA": "AWS Site-to-Site VPN을 사용하여 on-premises HDFS 데이터 및 애플리케이션에 액세스하고, Amazon EMR 클러스터를 사용하여 데이터를 처리합니다.",
    "SelectA_Commentary": "VPN을 통해 EMR이 위치한 AWS 클라우드로 연결하지만, 데이터 처리를 클라우드 측에서 수행하므로 완전히 on premises 환경이라고 보기 어렵습니다.",
    "SelectB": "AWS DataSync를 사용하여 on-premises HDFS 클러스터에 연결하고, Amazon EMR 클러스터에서 데이터를 처리합니다.",
    "SelectB_Commentary": "DataSync는 데이터 전송에 집중된 서비스로, 결국 AWS 클라우드의 EMR에서 처리하므로 완전한 사내 처리 방식이 아닙니다.",
    "SelectC": "Apache Hadoop과 Apache Spark 애플리케이션을 AWS Outposts 위의 Amazon EMR 클러스터로 마이그레이션하여 on premises 환경에서 데이터를 처리합니다.",
    "SelectC_Commentary": "AWS Outposts를 통해 사내에 AWS 인프라를 설치하여 EMR을 구동하므로, 완전히 on premises에서 확장성과 편의성을 모두 충족하는 최적의 해법입니다.",
    "SelectD": "AWS Snowball 디바이스를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션하고, Amazon EMR 클러스터에서 데이터를 처리합니다.",
    "SelectD_Commentary": "Snowball로 데이터를 클라우드에 옮겨야 하므로 사내에서의 실시간 처리가 불가능하며 요구사항의 on premises 조건을 만족하지 않습니다.",
    "Question_Description_recommedations": [
      "Q83",
      "Q314",
      "Q968",
      "Q990",
      "Q631"
    ],
    "SelectA_recommedations": [
      "Q659",
      "Q771",
      "Q64"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q386",
      "Q990"
    ],
    "SelectC_recommedations": [
      "Q718",
      "Q83",
      "Q235"
    ],
    "SelectD_recommedations": [
      "Q249",
      "Q515",
      "Q557"
    ]
  },
  {
    "Question_Number": "Q719",
    "Question_Description": "한 회사가 온프레미스 스토리지에 있는 대규모 데이터를 AWS로 마이그레이션하고자 합니다. 동일한 AWS 리전에 있는 Windows, Mac, Linux 기반 Amazon EC2 인스턴스들이 SMB와 NFS 스토리지 프로토콜을 사용하여 이 데이터를 액세스해야 합니다. 회사는 일부 데이터는 자주 액세스하고, 나머지 데이터는 드물게 액세스합니다. 회사는 이 데이터를 호스팅하기 위한 솔루션을 설계해야 하며, 운영 오버헤드를 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132892-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다양한 운영체제(Windows, Mac, Linux)에서 SMB와 NFS 모두를 지원하는 파일 스토리지를 선택하고, 자주 접근하는 데이터와 드물게 접근하는 데이터를 자동으로 적절히 계층화하여 관리 오버헤드를 줄이는 방안을 찾는 것입니다. Amazon FSx for ONTAP은 SMB와 NFS 프로토콜을 모두 지원하며 auto tiering 정책을 통해 자주 사용하지 않는 데이터를 백엔드 스토리지로 옮겨 비용을 절감하고, 운영 복잡도를 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "AWS로 대규모 데이터 마이그레이션",
      "SMB와 NFS 스토리지 프로토콜",
      "운영 오버헤드 최소화",
      "자주 액세스/드물게 액세스 데이터"
    ],
    "Terms": [
      "Amazon EFS",
      "EFS Intelligent-Tiering",
      "AWS DataSync",
      "Amazon FSx for ONTAP",
      "Auto tiering policy",
      "Amazon S3 Intelligent-Tiering",
      "AWS Storage Gateway (S3 File Gateway)",
      "Amazon FSx for OpenZFS"
    ],
    "SelectA": "Amazon EFS 볼륨을 생성하고 EFS Intelligent-Tiering을 사용합니다. AWS DataSync를 통해 데이터를 EFS 볼륨으로 마이그레이션합니다.",
    "SelectA_Commentary": "EFS는 NFS 프로토콜만 지원하므로 Windows 환경에서 SMB 액세스가 필요한 요구사항을 충족하지 못합니다.",
    "SelectB": "Amazon FSx for ONTAP 인스턴스를 생성합니다. auto tiering 정책을 사용하는 FSx for ONTAP 파일 시스템을 만들고, 해당 볼륨으로 데이터를 마이그레이션합니다.",
    "SelectB_Commentary": "SMB와 NFS를 동시에 지원하여 Windows, Mac, Linux를 포함한 다양한 환경에서 접근 가능하며, auto tiering 기능을 통해 자주 사용하지 않는 데이터를 자동으로 저비용 스토리지로 옮겨 운영 오버헤드를 줄일 수 있습니다.",
    "SelectC": "S3 Intelligent-Tiering이 활성화된 Amazon S3 버킷을 생성하고, AWS Storage Gateway(S3 File Gateway)를 사용하여 데이터를 해당 S3 버킷으로 마이그레이션합니다.",
    "SelectC_Commentary": "S3 File Gateway를 통해 SMB나 NFS로 접근 가능하지만, 게이트웨이를 별도로 운영해야 하므로 FSx for ONTAP 대비 오버헤드가 더 커질 수 있습니다.",
    "SelectD": "Amazon FSx for OpenZFS 파일 시스템을 생성하고, 새 볼륨으로 데이터를 마이그레이션합니다.",
    "SelectD_Commentary": "OpenZFS는 주로 NFS 프로토콜을 제공하며, Windows에서 SMB 접근이 필요할 경우 별도의 설정이 필요해 운영이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q671",
      "Q238",
      "Q993",
      "Q985",
      "Q167"
    ],
    "SelectA_recommedations": [
      "Q591",
      "Q822",
      "Q31"
    ],
    "SelectB_recommedations": [
      "Q806",
      "Q703",
      "Q822"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q497",
      "Q356"
    ],
    "SelectD_recommedations": [
      "Q703",
      "Q806",
      "Q719"
    ]
  },
  {
    "Question_Number": "Q720",
    "Question_Description": "한 제조 회사에서 보고서 생성 애플리케이션을 AWS에서 운영하고 있습니다. 이 애플리케이션은 하나의 Amazon EC2 인스턴스에서 동작하며, 모놀리식 구조로 tightly coupled된 모듈을 포함하고 있습니다. 각 보고서는 약 20분에 걸쳐 생성되며, 새로운 기능을 추가할 때마다 애플리케이션이 점점 더 복잡해지고 있습니다. 소프트웨어 모듈을 패치할 때마다 애플리케이션에 다운타임이 발생하고, 보고서 생성 프로세스도 중단되면 처음부터 다시 시작해야 합니다. 회사는 다운타임을 최소화하면서, 유연하고 확장 가능하며 점진적으로 개선할 수 있는 아키텍처로 재설계를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132893-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모놀리식 애플리케이션을 마이크로서비스로 전환하여 각 모듈을 독립적으로 배포하고 운영함으로써 다운타임을 줄이는 방법을 묻습니다. Amazon ECS에서 마이크로서비스와 Service Auto Scaling을 사용하면, 각 서비스가 확장성과 가용성을 갖추게 되어 잦은 업데이트에도 애플리케이션 전체 중단 없이 빠르게 변경 사항을 적용할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "보고서 생성 애플리케이션",
      "모놀리식 구조",
      "마이크로서비스",
      "Amazon ECS",
      "Service Auto Scaling",
      "다운타임 최소화"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon EC2 Spot Instances",
      "Spot Fleet default allocation strategy",
      "Amazon ECS",
      "microservices",
      "service auto scaling",
      "AWS Elastic Beanstalk",
      "all-at-once deployment strategy"
    ],
    "SelectA": "AWS Lambda에서 하나의 함수로 애플리케이션을 동작시키고 최대한 많은 프로비저닝된 동시성을 설정합니다.",
    "SelectA_Commentary": "하나의 큰 Lambda 함수로 구현하면 모놀리식 특성이 유지되고, 긴 실행 시간(20분)에 대한 관리가 복잡해 다운타임 해결에 적합하지 않습니다.",
    "SelectB": "Amazon EC2 Spot Instances 위에서 마이크로서비스 형태로 애플리케이션을 구동하고 Spot Fleet 기본 할당 전략을 사용합니다.",
    "SelectB_Commentary": "비용 효율성은 있을 수 있지만, Spot Instances는 중단 가능성이 있으므로 다운타임 최소화 보장이 어렵고 마이크로서비스 전환만으로는 요구사항을 충분히 충족하기 어렵습니다.",
    "SelectC": "Amazon Elastic Container Service(Amazon ECS)에서 마이크로서비스로 애플리케이션을 구동하고 서비스 오토 스케일링을 적용합니다.",
    "SelectC_Commentary": "각 모듈을 독립된 서비스로 구성하면 개별 업데이트 시 애플리케이션 전체 다운타임을 최소화할 수 있고, 오토 스케일링으로 유연하고 확장 가능한 아키텍처를 구축할 수 있어 요구사항에 가장 부합합니다.",
    "SelectD": "AWS Elastic Beanstalk에서 단일 애플리케이션 환경으로 동작시키고 all-at-once 배포 전략을 사용합니다.",
    "SelectD_Commentary": "단일 환경과 all-at-once 방식은 배포 시점마다 전체 애플리케이션이 재시작되어 다운타임을 줄이기 어려우므로 문제 해결에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q194",
      "Q790",
      "Q413",
      "Q892",
      "Q252"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q8",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q660",
      "Q581",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q900",
      "Q194",
      "Q892"
    ],
    "SelectD_recommedations": [
      "Q664",
      "Q194",
      "Q584"
    ]
  },
  {
    "Question_Number": "Q721",
    "Question_Description": "한 회사가 대규모 웹 애플리케이션을 서버리스 microservices 아키텍처로 재설계하고자 합니다. 현재 애플리케이션은 Amazon EC2 인스턴스를 사용하며, Python으로 작성되어 있습니다. 회사는 웹 애플리케이션의 한 모듈을 microservice로 테스트하기로 결정했습니다. 해당 모듈은 초당 수백 건의 요청을 처리해야 합니다. 회사는 Python을 지원하는 AWS 솔루션에서 해당 microservice를 만들고 테스트하고자 하며, 자동으로 확장되고 최소 인프라 및 운영 지원만 필요하도록 구성하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132894-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버리스 방식으로 간편하게 확장하고 운영 부담을 줄이려는 상황에서 적합한 AWS 서비스를 고르는 것입니다. Python 코드를 자동으로 확장해주는 AWS Lambda가 가장 효율적이며 운영 오버헤드가 최소화됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "서버리스",
      "microservices",
      "AWS Lambda",
      "Python",
      "자동 확장",
      "최소 운영"
    ],
    "Terms": [
      "Amazon EC2",
      "Spot Fleet",
      "Amazon Linux",
      "AWS Elastic Beanstalk",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Auto Scaling",
      "AWS Lambda",
      "Python"
    ],
    "SelectA": "가장 최신 Amazon Linux를 실행하는 EC2 인스턴스의 Spot Fleet을 사용하고 Auto Scaling을 구성합니다.",
    "SelectA_Commentary": "직접 인스턴스를 관리해야 하므로 운영 부담이 높고 완전 서버리스가 아니므로 요구사항에 적합하지 않습니다.",
    "SelectB": "고가용성을 구성한 AWS Elastic Beanstalk 웹 서버 환경을 사용합니다.",
    "SelectB_Commentary": "Elastic Beanstalk는 자동 확장을 지원하지만, 여전히 서버 인프라 관리와 환경 설정이 필요하여 완전한 서버리스 접근에 비해 운영 부담이 큽니다.",
    "SelectC": "Amazon Elastic Kubernetes Service(Amazon EKS)를 사용합니다. 자체 관리형 EC2 인스턴스의 Auto Scaling 그룹을 실행합니다.",
    "SelectC_Commentary": "EKS 설정 및 클러스터 관리가 필요하여 구조가 복잡해지고 운영 부담이 증가합니다.",
    "SelectD": "커스텀 코드를 실행하는 AWS Lambda 함수를 사용합니다.",
    "SelectD_Commentary": "서버리스로 구성되어 자동 확장, 최소 인프라 및 운영 지원을 통해 요구사항을 모두 충족하기 때문에 가장 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q666",
      "Q198",
      "Q790",
      "Q114",
      "Q263"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q664",
      "Q194",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q563",
      "Q724",
      "Q996"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q8",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q722",
    "Question_Description": "한 회사가 온프레미스 위치에서 AWS 계정으로 AWS Direct Connect를 연결해 두었습니다. 해당 AWS 계정에는 동일한 AWS Region 안에 30개의 서로 다른 VPC가 있으며, 이 VPC들은 private VIF(virtual interface)를 사용 중입니다. 각 VPC는 회사가 관리하는 다른 네트워크와 겹치지 않는 CIDR 블록을 사용합니다. 회사는 네트워크 아키텍처를 중앙에서 관리하면서도 모든 VPC가 서로 통신하고 온프레미스 네트워크와도 통신할 수 있도록 하고 싶습니다. 이 요구사항을 충족하면서 가장 적은 운영 오버헤드를 가지는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132895-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다수의 VPC와 온프레미스 네트워크를 하나로 연결하여 중앙에서 관리하고, 모든 요소 간 통신을 가능하게 하면서 운영 오버헤드를 최소화하는 솔루션을 찾는 것입니다. Transit Gateway에 Transit VIF를 연결하면 별도의 Peering 설정이나 Private VIF 재생성이 필요 없어, 관리 복잡도를 크게 줄이고 확장성까지 확보할 수 있습니다. Direct Connect Gateway, Transit VPC, Site-to-Site VPN을 사용하는 경우 각각 추가적인 설정 및 복잡성이 증가해 요구사항과 달라집니다. 따라서 Transit Gateway를 활용하는 선택지가 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "AWS Direct Connect",
      "VPC",
      "Transit Gateway",
      "private VIF",
      "중앙화된 네트워킹",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Direct Connect",
      "AWS account",
      "VPC",
      "private VIF",
      "CIDR block",
      "Transit Gateway",
      "Direct Connect Gateway",
      "Virtual Private Gateway",
      "AWS Site-to-Site VPN"
    ],
    "SelectA": "Transit Gateway를 생성하고, Direct Connect 연결을 새 Transit VIF로 연결합니다. 그리고 Transit Gateway의 라우트 전파(route propagation) 기능을 활성화합니다.",
    "SelectA_Commentary": "Transit Gateway와 Transit VIF를 이용하면 여러 VPC와 온프레미스 간의 중앙 집중형 라우팅이 가능해 운영 오버헤드가 가장 적고 확장성이 뛰어납니다.",
    "SelectB": "Direct Connect Gateway를 생성하고, 기존 private VIF를 새 게이트웨이에 사용하도록 재구성합니다. 각 VPC마다 새로운 virtual private gateway를 만들어 연결합니다.",
    "SelectB_Commentary": "각 VPC별로 Virtual Private Gateway를 재구성하고 VIF를 재설정해야 하므로, 추가 작업과 관리가 늘어나 운영 오버헤드가 큽니다.",
    "SelectC": "Transit VPC를 생성하고, Direct Connect 연결을 Transit VPC에 연결합니다. 다른 모든 VPC들과 Region 내 VPC 피어링을 맺고 라우트 테이블을 업데이트합니다.",
    "SelectC_Commentary": "Transit VPC 아키텍처는 VPC 간 피어링과 추가 라우팅 구성을 요구해 관리 복잡도가 크고, 오버헤드가 증가합니다.",
    "SelectD": "온프레미스와 각 VPC 간에 AWS Site-to-Site VPN 연결을 만듭니다. 각 VPN 터널을 활성화하고 라우트 전파를 켭니다.",
    "SelectD_Commentary": "각 VPC마다 별도의 VPN 터널이 필요하여 관리가 매우 복잡해지고, 운영 비용도 증가하므로 요구사항과 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q68",
      "Q983",
      "Q439",
      "Q487",
      "Q504"
    ],
    "SelectA_recommedations": [
      "Q68",
      "Q722",
      "Q983"
    ],
    "SelectB_recommedations": [
      "Q722",
      "Q487",
      "Q448"
    ],
    "SelectC_recommedations": [
      "Q722",
      "Q68",
      "Q504"
    ],
    "SelectD_recommedations": [
      "Q487",
      "Q504",
      "Q439"
    ]
  },
  {
    "Question_Number": "Q723",
    "Question_Description": "한 회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행하고 있습니다. 이 EC2 인스턴스들은 연결된 IAM role과 해당 정책을 사용하여 Amazon RDS 데이터베이스에 연결합니다. 회사는 실행 중인 애플리케이션을 중단하지 않고 AWS Systems Manager를 사용해 EC2 인스턴스에 패치를 적용하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132900-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이미 기존 IAM role을 사용하는 EC2 인스턴스에 별도의 접근 권한을 부여해 안전하게 패치를 수행하는 방법을 묻습니다. 기본 호스트 구성(Default Host Configuration Management)을 사용하면 새 역할을 직접 구성하거나 기존 역할을 바꾸지 않고도 Systems Manager에서 인스턴스를 관리 및 패치할 수 있으므로, 선택지는 C가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Amazon RDS",
      "IAM role",
      "AWS Systems Manager",
      "패치"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "IAM role",
      "AWS Systems Manager",
      "AmazonSSMManagedInstanceCore",
      "Patch Manager",
      "Default Host Configuration Management"
    ],
    "SelectA": "새로운 IAM role을 생성하고 AmazonSSMManagedInstanceCore 정책을 연결합니다. 새 IAM role을 EC2 인스턴스와 기존 IAM role에 함께 연결합니다.",
    "SelectA_Commentary": "EC2 인스턴스에는 동시에 하나의 IAM role만 할당 가능하므로, 다른 역할을 중첩 연결하는 방법은 적절하지 않습니다.",
    "SelectB": "IAM user를 생성하고, AmazonSSMManagedInstanceCore 정책을 연결합니다. Systems Manager가 EC2 인스턴스를 관리하도록 이 IAM user를 사용하도록 설정합니다.",
    "SelectB_Commentary": "IAM user를 통한 접근은 권장되지 않으며, 강력한 보안 및 접근 관리를 위해 EC2 인스턴스 프로파일(role) 방식이 우선입니다.",
    "SelectC": "Systems Manager에서 Default Host Configuration Management를 활성화하여 EC2 인스턴스를 관리합니다.",
    "SelectC_Commentary": "Default Host Configuration Management가 자동으로 필요한 역할을 생성하고 할당해 주어 기존 IAM role과 충돌 없이 간단하게 패치 적용이 가능합니다. 정답입니다.",
    "SelectD": "기존 IAM role에서 기존 정책을 제거하고, AmazonSSMManagedInstanceCore 정책을 추가합니다.",
    "SelectD_Commentary": "기존 정책 제거 시 EC2 인스턴스에서 RDS 접근에 문제가 생길 수 있어 서비스에 지장을 줄 수 있으므로 부적절합니다.",
    "Question_Description_recommedations": [
      "Q61",
      "Q732",
      "Q179",
      "Q742",
      "Q838"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q476",
      "Q723"
    ],
    "SelectB_recommedations": [
      "Q233",
      "Q476",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q453",
      "Q329"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q476",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q724",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS)와 Kubernetes Horizontal Pod Autoscaler를 사용하여 컨테이너 애플리케이션을 운영하고 있습니다. 하루 동안 워크로드가 일정하지 않습니다. 솔루션스 아키텍트는 클러스터 내 기존 노드가 최대 용량에 도달했을 때 노드가 자동으로 확장되지 않아 성능 문제가 발생한다는 점을 확인했습니다. 가장 적은 운영 오버헤드로 이 문제를 해결할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132902-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS 내에서의 노드 확장 자동화에 관한 것입니다. Kubernetes Horizontal Pod Autoscaler만으로는 Pod 수는 늘어나지만, 노드 자체가 자동으로 추가되지 않으면 성능 병목이 발생할 수 있습니다. 이를 해결하기 위해 클러스터 레벨에서 노드를 자동으로 확장해 줄 솔루션이 필요합니다. ‘Kubernetes Cluster Autoscaler’를 사용하면 관리 오버헤드를 최소화하면서 실시간 워크로드 변화에 맞춰 노드 수를 자동 늘릴 수 있어 성능 문제를 완화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Amazon EKS",
      "Kubernetes Horizontal Pod Autoscaler",
      "Kubernetes Cluster Autoscaler",
      "노드 자동 확장",
      "컨테이너 애플리케이션",
      "성능 문제"
    ],
    "Terms": [
      "Amazon EKS",
      "Kubernetes Horizontal Pod Autoscaler",
      "Kubernetes Cluster Autoscaler",
      "AWS Lambda",
      "Amazon EC2 Auto Scaling group"
    ],
    "SelectA": "메모리 사용량을 추적하여 노드를 직접 확장합니다.",
    "SelectA_Commentary": "메모리 사용량만 추적하는 것은 Pod 오토스케일러와 별도로 노드를 직접 모니터링해야 하므로 운영 오버헤드가 큽니다.",
    "SelectB": "Kubernetes Cluster Autoscaler를 사용하여 클러스터 내 노드 수를 관리합니다.",
    "SelectB_Commentary": "Kubernetes Cluster Autoscaler는 Pod 수요에 맞춰 노드를 자동 증설하고 필요 없을 시 축소하므로 최소한의 관리로 확장이 가능합니다.",
    "SelectC": "AWS Lambda 함수를 사용해 EKS 클러스터 크기를 자동으로 조정합니다.",
    "SelectC_Commentary": "별도의 Lambda 함수를 작성 및 관리해야 하므로 모니터링 로직과 코드를 직접 유지해야 하며, 운영 오버헤드가 더 큽니다.",
    "SelectD": "Amazon EC2 Auto Scaling group을 사용하여 워크로드를 분산합니다.",
    "SelectD_Commentary": "EC2 Auto Scaling group만으로는 Kubernetes 클러스터 상태 반영에 제약이 있어 Pod 수와 연동이 복잡하며, 완전 자동화가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q563",
      "Q996",
      "Q522",
      "Q210",
      "Q660"
    ],
    "SelectA_recommedations": [
      "Q187",
      "Q58",
      "Q917"
    ],
    "SelectB_recommedations": [
      "Q724",
      "Q660",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q775",
      "Q563",
      "Q996"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q660",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q725",
    "Question_Description": "한 회사는 Amazon S3 Standard에 매달 약 300TB의 데이터를 보관하고 있습니다. 각 S3 객체는 보통 약 50GB 정도이며, 전 세계 애플리케이션에서 multipart upload 방식으로 자주 대체됩니다. S3 객체의 개수와 크기는 계속 동일하게 유지되고 있지만, 회사의 S3 스토리지 비용은 매달 증가하고 있습니다. 이러한 상황에서 비용을 절감하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132904-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 객체 수와 크기는 그대로이지만 스토리지 비용이 증가하는 원인을 파악하는 것입니다. 빈번한 multipart upload 과정에서 불완전하게 업로드된 객체가 계속 쌓여 S3 용량을 사용하고 있기 때문입니다. 따라서 불완전한 multipart upload 파일을 자동으로 삭제하는 Lifecycle 정책을 적용하면 스토리지 비용을 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon S3 Standard",
      "multipart upload",
      "S3 스토리지 비용",
      "Lifecycle policy",
      "incomplete multipart uploads"
    ],
    "Terms": [
      "S3 Lifecycle policy",
      "multipart upload",
      "Amazon S3 Transfer Acceleration",
      "Amazon CloudFront",
      "incomplete multipart uploads"
    ],
    "SelectA": "multipart upload 대신 Amazon S3 Transfer Acceleration을 사용합니다.",
    "SelectA_Commentary": "Transfer Acceleration은 전송 속도 향상 기능이며, 비용을 줄이는 데 직접적인 이점이 없습니다.",
    "SelectB": "불완전한 multipart uploads를 삭제하는 S3 Lifecycle 정책을 활성화합니다.",
    "SelectB_Commentary": "불필요하게 남아 있는 미완성 객체를 자동 삭제해 S3 스토리지 비용을 줄일 수 있는 가장 효과적인 방법입니다.",
    "SelectC": "객체가 너무 빠르게 아카이브되지 않도록 S3 inventory를 구성합니다.",
    "SelectC_Commentary": "아카이브 속도를 조절하는 방안이나 현재 문제(비용 증가)와 직접적 연관성이 부족합니다.",
    "SelectD": "Amazon CloudFront를 구성해 Amazon S3에 저장된 객체 수를 줄입니다.",
    "SelectD_Commentary": "CloudFront는 캐싱 솔루션으로 객체 수 자체를 줄이는 도구가 아니며, 근본 해결책이 되지 못합니다.",
    "Question_Description_recommedations": [
      "Q326",
      "Q415",
      "Q212",
      "Q88",
      "Q356"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q326",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q326",
      "Q725",
      "Q829"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q1003",
      "Q911"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q726",
    "Question_Description": "한 회사가 모바일 기기를 위한 멀티플레이어 게임을 배포했습니다. 게임은 위도와 경도 기반의 실시간 위치 추적을 요구하며, 위치 데이터를 빠르게 업데이트하고 조회할 수 있는 데이터 스토어가 필요합니다. 현재는 Amazon RDS for PostgreSQL DB 인스턴스와 리드 리플리카를 사용해 위치 데이터를 저장하고 있지만, 피크 사용 시간에 읽기/쓰기 성능이 부족해집니다. 게임 이용자 수도 급증하고 있습니다. 데이터 계층의 성능을 개선하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132906-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모바일 게임에서 위치 정보를 빠르게 읽고 쓰기 위해 DB 성능을 극적으로 향상시켜야 하는 상황입니다. RDS에 캐시 계층을 추가하면 높은 처리량과 실시간 응답을 보장할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "실시간 위치 추적",
      "Amazon RDS for PostgreSQL",
      "Multi-AZ",
      "Amazon OpenSearch Service",
      "Amazon DynamoDB Accelerator (DAX)",
      "Amazon ElastiCache for Redis",
      "성능 개선"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ",
      "Amazon OpenSearch Service",
      "Amazon DynamoDB Accelerator (DAX)",
      "Amazon ElastiCache for Redis"
    ],
    "SelectA": "기존 DB 인스턴스의 스냅샷을 생성합니다. Multi-AZ를 활성화하여 스냅샷을 복원합니다.",
    "SelectA_Commentary": "Multi-AZ 구성은 고가용성을 향상시키지만 대규모 읽기/쓰기 성능 문제 자체를 해결하기에는 부족합니다.",
    "SelectB": "Amazon RDS에서 Amazon OpenSearch Service로 마이그레이션하고 OpenSearch Dashboards를 사용합니다.",
    "SelectB_Commentary": "OpenSearch Service는 검색 및 로그 분석에 특화된 서비스로, 실시간 쓰기와 조회 성능 향상 목적에는 적합하지 않습니다.",
    "SelectC": "기존 DB 인스턴스 앞에 Amazon DynamoDB Accelerator(DAX)를 배포합니다. 게임이 DAX를 사용하도록 수정합니다.",
    "SelectC_Commentary": "DAX는 DynamoDB 전용 캐싱 서비스로서 PostgreSQL과 호환되지 않아 적절한 선택이 아닙니다.",
    "SelectD": "기존 DB 인스턴스 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 게임이 Redis를 사용하도록 수정합니다.",
    "SelectD_Commentary": "읽기 요청을 Redis로 캐싱하여 RDS 부하를 줄이고, 실시간 쓰기 및 조회 성능을 효율적으로 높일 수 있는 정답입니다.",
    "Question_Description_recommedations": [
      "Q376",
      "Q661",
      "Q269",
      "Q590",
      "Q95"
    ],
    "SelectA_recommedations": [
      "Q225",
      "Q523",
      "Q77"
    ],
    "SelectB_recommedations": [
      "Q269",
      "Q386",
      "Q776"
    ],
    "SelectC_recommedations": [
      "Q578",
      "Q472",
      "Q177"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q386",
      "Q229"
    ]
  },
  {
    "Question_Number": "Q727",
    "Question_Description": "한 회사가 Amazon DynamoDB 테이블에 중요한 데이터를 저장하고 있습니다. IT 관리자가 실수로 DynamoDB 테이블을 삭제하여 심각한 데이터 손실과 회사 운영에 큰 혼란이 발생했습니다. 회사는 앞으로 이러한 중단 상황이 재발하지 않도록 방지하고자 합니다. 최소한의 운영 오버헤드로 이 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132907-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실수로 인한 DynamoDB 테이블 삭제를 사전에 방지하거나, 최소한 신속히 복구할 수 있는 방안을 찾는 것입니다. 여러 옵션 중에서도 운영 오버헤드가 가장 적은 방법은 DynamoDB의 Deletion Protection을 활성화하는 것입니다. 이를 통해 테이블이 임의로 삭제되는 상황 자체를 최소화할 수 있어 데이터 손실과 복구 작업의 부담을 크게 줄일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon DynamoDB",
      "중요 데이터 보호",
      "테이블 삭제 방지",
      "오버헤드 최소화"
    ],
    "Terms": [
      "AWS CloudTrail",
      "Amazon EventBridge",
      "AWS Lambda",
      "DynamoDB Backup and Restore",
      "Deletion Protection",
      "Point-in-time Recovery"
    ],
    "SelectA": "AWS CloudTrail을 구성하고, Amazon EventBridge 규칙을 통해 DynamoDB 테이블 삭제 작업을 감지하고, AWS Lambda 함수로 자동 복구를 수행합니다.",
    "SelectA_Commentary": "감지와 자동 복구 과정을 설정해야 하므로 워크플로가 복잡해지고, 이벤트 발생 시 Lambda 복구 로직도 유지∙관리해야 하므로 운영 오버헤드가 큽니다.",
    "SelectB": "DynamoDB 테이블에 대한 백업 및 복구 계획을 수립하고, 필요 시 수동으로 테이블을 복구합니다.",
    "SelectB_Commentary": "백업 주기 설정, 수동 복구 절차 등이 필요해 운영 오버헤드가 높고, 실제 삭제 시 즉각적인 조치가 어려워 지연이 발생할 수 있습니다.",
    "SelectC": "DynamoDB 테이블에 Deletion Protection을 구성합니다.",
    "SelectC_Commentary": "가장 간단하고 즉각적인 해결책으로, 테이블 삭제 자체를 방지하여 실수로 인한 데이터 손실 위험을 근본적으로 제거합니다.",
    "SelectD": "DynamoDB 테이블에서 Point-in-time Recovery를 활성화합니다.",
    "SelectD_Commentary": "실수로 삭제된 경우 특정 시점으로 복원할 수 있지만, 삭제 자체를 막지 못하므로 복구 과정에 추가적인 시간이 소요됩니다.",
    "Question_Description_recommedations": [
      "Q279",
      "Q521",
      "Q176",
      "Q970",
      "Q898"
    ],
    "SelectA_recommedations": [
      "Q451",
      "Q428",
      "Q211"
    ],
    "SelectB_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ],
    "SelectC_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ]
  },
  {
    "Question_Number": "Q728",
    "Question_Description": "한 회사가 온프레미스 데이터 센터의 스토리지 용량이 부족해지고 있습니다. 회사는 AWS로 스토리지 인프라를 이전하려고 하며, 이를 위해 대역폭 비용을 최소화하려고 합니다. 또한 추가 비용 없이 데이터를 즉시 검색할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 스토리지 용량 부족과 대역폭 비용을 동시에 해결하면서, 데이터를 AWS에 안전하게 보관하고 필요 시 즉시 접근할 수 있도록 하는 방안을 찾는 것입니다. AWS Storage Gateway의 Cached Volumes 모드는 자주 액세스되는 데이터만 로컬에 보관하고 나머지를 Amazon S3에 저장함으로써 온프레미스 스토리지 사용량 감소와 즉각적인 액세스를 모두 충족합니다. 또한 빈번한 전체 전송이 필요 없으므로 대역폭 비용 역시 효율적으로 관리할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.4"
    ],
    "Keywords": [
      "온프레미스 스토리지 용량 부족",
      "대역폭 비용 최소화",
      "즉시 데이터 검색",
      "스토리지 인프라 마이그레이션"
    ],
    "Terms": [
      "Amazon S3 Glacier Vault",
      "Expedited Retrieval",
      "Provisioned Retrieval Capacity",
      "AWS Storage Gateway (Cached Volumes)",
      "AWS Storage Gateway (Stored Volumes)",
      "AWS Direct Connect",
      "Point-in-time Snapshots",
      "Amazon S3"
    ],
    "SelectA": "Amazon S3 Glacier Vault를 배포하고 Expedited Retrieval을 활성화합니다. 워크로드를 위해 Provisioned Retrieval Capacity를 활성화합니다.",
    "SelectA_Commentary": "S3 Glacier는 저비용 저장 공간이지만 즉시성이 떨어지고, Expedited Retrieval에도 추가 비용이 발생하여 요구사항인 '추가 비용 없는 즉시 검색'과 맞지 않습니다.",
    "SelectB": "AWS Storage Gateway를 Cached Volumes 모드로 배포합니다. Storage Gateway를 사용하여 데이터를 Amazon S3에 저장하면서 자주 액세스되는 데이터 하위 집합을 로컬에 유지합니다.",
    "SelectB_Commentary": "자주 사용되는 데이터는 온프레미스에, 나머지는 S3에 보관해 온프레미스 용량 문제와 즉시성, 비용 절감을 모두 만족시키는 최적의 솔루션입니다.",
    "SelectC": "AWS Storage Gateway를 Stored Volumes 모드로 배포하여 데이터를 로컬에 저장합니다. Storage Gateway를 사용하여 데이터의 시점별 스냅샷을 Amazon S3에 비동기적으로 백업합니다.",
    "SelectC_Commentary": "여전히 대부분의 데이터를 온프레미스에 저장하기 때문에 스토리지 용량 문제를 해결하기 어렵고, 원본이 로컬에 남아 대역폭 이점이 미미합니다.",
    "SelectD": "AWS Direct Connect를 배포하여 온프레미스 데이터 센터와 연결합니다. AWS Storage Gateway를 사용하여 데이터를 로컬에 저장하도록 구성합니다. 이후 Storage Gateway로 시점별 스냅샷을 Amazon S3에 비동기적으로 백업합니다.",
    "SelectD_Commentary": "전용 회선을 사용하면 안정적인 연결은 가능하지만, 여전히 로컬 스토리지 사용이 커서 용량 문제 해결에 적합하지 않으며 Direct Connect 자체 비용이 추가로 발생합니다.",
    "Question_Description_recommedations": [
      "Q985",
      "Q284",
      "Q541",
      "Q485",
      "Q525"
    ],
    "SelectA_recommedations": [
      "Q912",
      "Q285",
      "Q471"
    ],
    "SelectB_recommedations": [
      "Q497",
      "Q72",
      "Q471"
    ],
    "SelectC_recommedations": [
      "Q497",
      "Q72",
      "Q415"
    ],
    "SelectD_recommedations": [
      "Q835",
      "Q240",
      "Q497"
    ]
  },
  {
    "Question_Number": "Q729",
    "Question_Description": "한 회사가 여러 가용 영역(Availability Zone)에 걸쳐 VPC에서 3계층 웹 애플리케이션을 운영 중이며, 애플리케이션 계층은 Amazon EC2 인스턴스로 구성된 Auto Scaling group을 사용합니다. 회사는 각 리소스의 일간 및 주간 워크로드 추세를 분석하고, 예측된 사용량과 실시간 사용량 변화를 모두 반영하여 리소스를 적절히 확장하는 자동화된 스케일링 플랜이 필요합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트가 권장해야 할 스케일링 전략은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132911-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "일간·주간 워크로드를 분석하여 예측과 실시간 변화 모두에 대응하려면 Predictive Scaling과 Target Tracking을 함께 사용하는 것이 가장 효과적입니다. Predictive Scaling은 향후 리소스 요구량을 미리 파악해 사전에 확장하도록 돕고, Dynamic Scaling은 급변하는 실제 트래픽에도 적절히 대응하여 서비스 품질과 비용 효율성을 동시에 확보합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "자동화된 스케일링 플랜",
      "워크로드 추세 분석",
      "예측된 사용량",
      "실시간 사용량 변화",
      "Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "VPC",
      "Availability Zone",
      "Dynamic Scaling",
      "Step Scaling",
      "Predictive Scaling",
      "Target Tracking",
      "Scheduled Scaling",
      "Simple Scaling",
      "Cooldown"
    ],
    "SelectA": "EC2 인스턴스의 평균 CPU 사용률을 기준으로 Step Scaling 방식의 동적 스케일링을 구현합니다.",
    "SelectA_Commentary": "단순 CPU 지표만으로 스케일링을 결정하면 예측 기반 확장이 불가능하고, 주간·일간 추세를 고려하기 어렵습니다.",
    "SelectB": "Predictive Scaling을 활성화하여 예측 및 확장을 수행하고, Dynamic Scaling에 Target Tracking을 구성합니다.",
    "SelectB_Commentary": "일간·주간 추세를 예측 기반으로 반영하고, 실시간 트래픽 급등에도 자동 확장이 가능해 가장 적합한 솔루션입니다.",
    "SelectC": "웹 애플리케이션의 트래픽 패턴에 따라 자동화된 Scheduled Scaling 작업을 생성합니다.",
    "SelectC_Commentary": "스케줄 기반으로만 고정 확장을 수행하므로 예측과 실시간 급변 상황에 대한 탄력적인 대응이 어렵습니다.",
    "SelectD": "Simple Scaling 정책을 설정하고, EC2 인스턴스 시작 시간을 고려해 Cooldown 시간을 늘립니다.",
    "SelectD_Commentary": "Cooldown 시간 조정만으로는 다양한 패턴의 사용량 변화와 예측 확장을 처리하기에 부족합니다.",
    "Question_Description_recommedations": [
      "Q691",
      "Q639",
      "Q275",
      "Q758",
      "Q581"
    ],
    "SelectA_recommedations": [
      "Q584",
      "Q194",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q1001",
      "Q363",
      "Q967"
    ],
    "SelectC_recommedations": [
      "Q363",
      "Q8",
      "Q149"
    ],
    "SelectD_recommedations": [
      "Q584",
      "Q194",
      "Q757"
    ]
  },
  {
    "Question_Number": "Q730",
    "Question_Description": "한 택배 회사가 Amazon EC2 인스턴스와 Amazon Aurora MySQL DB 클러스터를 사용하는 애플리케이션을 운영하고 있습니다. 애플리케이션의 인기가 높아지면서 EC2 인스턴스의 사용량은 약간만 증가하지만, DB 클러스터 사용량이 훨씬 빠르게 증가합니다. 회사는 DB 클러스터 사용량을 줄이기 위해 read replica를 추가했지만 일시적으로만 부하가 줄었고, 이후에도 계속해서 부하가 증가하고 있습니다. 이 부하 증가를 유발하는 작업들은 모두 배달 상세 정보와 관련된 반복적인 읽기 쿼리입니다. 회사는 이러한 반복적인 읽기로 인한 DB 클러스터 부하를 줄여야 합니다. 가장 비용 효율적으로 이 요구사항을 충족할 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132913-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 DB 클러스터에 집중되는 반복적 읽기 부담을 줄이는 데 초점을 맞춥니다. read replica를 계속 추가하는 것은 비용이 증가할 수 있으므로, 캐싱을 통해 DB 부하를 완화하는 것이 비용 효율적입니다. Amazon ElastiCache for Redis를 통해 자주 요청되는 데이터를 캐싱하면 DB 쿼리 수를 크게 줄이고 운영 비용도 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon EC2 인스턴스",
      "Amazon Aurora MySQL DB 클러스터",
      "반복적인 읽기",
      "배달 상세 정보",
      "비용 효율적",
      "read replica",
      "Amazon ElastiCache for Redis",
      "Aurora Auto Scaling",
      "여러 writer 인스턴스"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Aurora MySQL DB cluster",
      "read replica",
      "Amazon ElastiCache for Redis",
      "Aurora Auto Scaling",
      "DB cluster",
      "writer instance"
    ],
    "SelectA": "애플리케이션과 DB 클러스터 사이에 Amazon ElastiCache for Redis 클러스터를 구현합니다.",
    "SelectA_Commentary": "자주 조회되는 데이터를 캐시에 저장해 DB 부하와 비용을 동시에 줄이는 가장 효율적인 방법입니다.",
    "SelectB": "DB 클러스터에 추가 read replica를 하나 더 추가합니다.",
    "SelectB_Commentary": "read replica만 계속 추가하면 비용이 계속 증가하고, 반복적 읽기를 근본적으로 줄이지 못합니다.",
    "SelectC": "Aurora read replica에 대해 Aurora Auto Scaling을 구성합니다.",
    "SelectC_Commentary": "부하에 따라 read replica가 자동으로 늘어나지만, 계속해서 리소스 비용이 증가할 수 있어 최적의 비용 효율을 보장하기 어렵습니다.",
    "SelectD": "DB 클러스터를 여러 writer 인스턴스로 수정합니다.",
    "SelectD_Commentary": "복수 writer 구성은 쓰기 확장에는 도움이 되지만, 읽기 부하 문제와 직접적으로 연관되지 않으며 오히려 관리가 복잡해질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q520",
      "Q196",
      "Q671",
      "Q867",
      "Q238"
    ],
    "SelectA_recommedations": [
      "Q196",
      "Q552",
      "Q79"
    ],
    "SelectB_recommedations": [
      "Q851",
      "Q79",
      "Q348"
    ],
    "SelectC_recommedations": [
      "Q485",
      "Q943",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q630",
      "Q997",
      "Q656"
    ]
  },
  {
    "Question_Number": "Q731",
    "Question_Description": "한 회사에는 Amazon DynamoDB 테이블을 사용하는 애플리케이션이 있습니다. 솔루션스 아키텍트는 테이블에 대한 많은 요청이 최신 데이터를 반환하지 않는다는 사실을 발견했습니다. 회사의 사용자들은 데이터베이스 성능과 관련된 다른 문제를 보고하지 않았으며, 지연 시간은 허용 가능한 범위입니다. 이 경우 솔루션스 아키텍트가 권장해야 할 설계 변경 사항은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132914-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기본적으로 Eventually Consistent Read를 사용하는 Amazon DynamoDB에서 최신 데이터가 즉시 반영되지 않아 발생하는 이슈를 해결하기 위한 방법을 묻고 있습니다. Strongly Consistent Read를 사용하면 쓰기가 완료된 최신 상태 데이터를 바로 읽어올 수 있어 요구사항에 부합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "DynamoDB",
      "최신 데이터",
      "Strongly Consistent Read",
      "Eventually Consistent Read"
    ],
    "Terms": [
      "Amazon DynamoDB Table",
      "Read Replica",
      "Global Secondary Index (GSI)",
      "Strongly Consistent Read",
      "Eventually Consistent Read"
    ],
    "SelectA": "테이블에 Read Replica를 추가합니다.",
    "SelectA_Commentary": "DynamoDB에서 Read Replica를 추가해도 기본 일관성 모델은 바뀌지 않아 최신 데이터 문제를 해결하지 못합니다.",
    "SelectB": "글로벌 보조 인덱스(GSI)를 사용합니다.",
    "SelectB_Commentary": "GSI는 다른 쿼리 패턴을 제공하지만 즉각적인 최신 데이터 보장은 하지 못하므로 문제 해결과 직접적 연관이 없습니다.",
    "SelectC": "테이블에 대해 Strongly Consistent Reads를 요청합니다.",
    "SelectC_Commentary": "Strongly Consistent Read를 사용하면 쓰기 직후 데이터를 즉시 읽을 수 있으므로 문제를 근본적으로 해결하는 최적의 방법입니다.",
    "SelectD": "테이블에 대해 Eventually Consistent Reads를 요청합니다.",
    "SelectD_Commentary": "기본 설정과 동일하므로 최신 데이터를 즉시 읽지 못하는 문제가 해결되지 않습니다.",
    "Question_Description_recommedations": [
      "Q578",
      "Q962",
      "Q472",
      "Q177",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q888",
      "Q132",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q506",
      "Q888",
      "Q132"
    ],
    "SelectC_recommedations": [
      "Q888",
      "Q158",
      "Q132"
    ],
    "SelectD_recommedations": [
      "Q888",
      "Q352",
      "Q158"
    ]
  },
  {
    "Question_Number": "Q732",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스와 Amazon RDS 데이터베이스로 애플리케이션을 배포했습니다. 회사는 최소 권한 원칙으로 데이터베이스 액세스 자격 증명을 구성했습니다. 회사의 보안 팀은 SQL 인젝션 및 기타 웹 기반 공격으로부터 애플리케이션과 데이터베이스를 보호하려 합니다. 운영 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132915-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 계층(L7)에서 발생하는 공격 방어가 핵심이며, AWS WAF를 통해 SQL 인젝션 등 웹 기반 공격을 효과적으로 막고 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "SQL 인젝션",
      "웹 기반 공격",
      "최소 운영 오버헤드",
      "AWS WAF",
      "RDS parameter groups"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "AWS WAF",
      "AWS Network Firewall",
      "security groups",
      "network ACLs",
      "RDS parameter groups"
    ],
    "SelectA": "security groups와 network ACLs를 사용하여 데이터베이스와 애플리케이션 서버를 보호합니다.",
    "SelectA_Commentary": "이는 주로 네트워크 계층(L3/L4)에 초점을 두어 웹 기반 공격(L7) 방어에 한계가 있습니다.",
    "SelectB": "AWS WAF로 애플리케이션을 보호하고, RDS parameter groups를 사용해 보안 설정을 구성합니다.",
    "SelectB_Commentary": "AWS WAF는 SQL 인젝션 등 웹 공격 방지 규칙을 제공하고, RDS 설정도 간단히 관리 가능하여 운영 오버헤드가 최소화됩니다.",
    "SelectC": "AWS Network Firewall을 사용하여 애플리케이션과 데이터베이스를 보호합니다.",
    "SelectC_Commentary": "네트워크 계층 방어에 중점을 두어 웹 앱 계층 보호에는 과도하며 관리 복잡도도 증가합니다.",
    "SelectD": "다른 기능별로 서로 다른 데이터베이스 계정을 애플리케이션 코드에서 사용하고, 과한 권한 부여를 피합니다.",
    "SelectD_Commentary": "권한 분산만으로 웹 계층(L7) SQL 인젝션 공격을 근본적으로 차단하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q61",
      "Q330",
      "Q742",
      "Q176",
      "Q901"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q233",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q853",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q592",
      "Q898"
    ],
    "SelectD_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q733",
    "Question_Description": "한 전자상거래 회사가 AWS Organizations에 속한 여러 AWS 계정에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션들은 모든 계정에서 Amazon Aurora PostgreSQL 데이터베이스를 사용합니다. 회사는 악의적인 활동을 방지하고, 데이터베이스에 대한 비정상적인 실패 또는 불완전한 로그인 시도를 식별해야 합니다. 가장 운영 효율성이 높은 방식으로 이 요건을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132916-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터베이스에 대한 잠재적 침입 시도를 빠르고 정확하게 감지하고 경고하는 방법을 묻는 보안 설계 시나리오입니다. 운영 효율성을 극대화하려면 자동화된 보안 서비스인 Amazon GuardDuty를 통해 Aurora PostgreSQL 로그인을 모니터링하는 방안이 최적의 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "악의적인 활동 방지",
      "비정상 로그인 시도 식별",
      "Amazon Aurora PostgreSQL",
      "Amazon GuardDuty",
      "Amazon RDS Protection"
    ],
    "Terms": [
      "AWS Organizations",
      "Amazon Aurora PostgreSQL",
      "Service Control Policy(SCP)",
      "Amazon GuardDuty",
      "Amazon RDS Protection",
      "Amazon CloudWatch Logs",
      "Amazon S3",
      "AWS CloudTrail"
    ],
    "SelectA": "조직의 루트에 Service Control Policy(SCP)를 적용하여 실패한 로그인 시도를 식별합니다.",
    "SelectA_Commentary": "SCP는 계정 권한을 제한하거나 허용하는 정책일 뿐, 데이터베이스 로그 감시나 경고 제공 기능을 수행하지 않으므로 적합하지 않습니다.",
    "SelectB": "조직의 멤버 계정들에 대해 Amazon GuardDuty의 Amazon RDS Protection 기능을 활성화합니다.",
    "SelectB_Commentary": "GuardDuty의 RDS Protection은 Aurora PostgreSQL에 대한 비정상 로그인 시도를 자동으로 분석하고 경고를 제공하므로, 운영 효율성과 보안 요구사항을 모두 충족하는 최적의 선택입니다.",
    "SelectC": "Aurora 일반 로그를 Amazon CloudWatch Logs의 로그 그룹에 게시하고, 해당 로그 데이터를 중앙 Amazon S3 버킷으로 내보냅니다.",
    "SelectC_Commentary": "로그를 직접 분석해야 하며 추가 관리 로직이 필요해 운영 오버헤드가 증가합니다. 자동으로 보안 이벤트를 감지·알림해주는 서비스에 비해 효율성이 떨어집니다.",
    "SelectD": "모든 Aurora PostgreSQL 데이터베이스 이벤트를 AWS CloudTrail에 게시하여 중앙 Amazon S3 버킷으로 전송합니다.",
    "SelectD_Commentary": "CloudTrail은 API 호출 추적에 중점을 둡니다. Aurora PostgreSQL의 내부 로그인 이벤트는 부분적으로만 캡처되며 GuardDuty처럼 자동 분석 및 경고 기능을 제공하지 않습니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q1018",
      "Q521",
      "Q908"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q774",
      "Q135"
    ],
    "SelectB_recommedations": [
      "Q330",
      "Q893",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q157",
      "Q27",
      "Q854"
    ],
    "SelectD_recommedations": [
      "Q942",
      "Q157",
      "Q733"
    ]
  },
  {
    "Question_Number": "Q734",
    "Question_Description": "한 회사가 기업 데이터 센터에서 us-east-1 리전의 VPC로 AWS Direct Connect 연결을 보유하고 있습니다. 이 회사는 최근 여러 개의 VPC와 eu-west-2 리전의 온프레미스 데이터 센터 사이에 Direct Connect 연결을 가진 회사를 인수했습니다. 두 회사의 VPC CIDR 블록은 중복되지 않습니다. 회사는 두 개의 리전과 데이터 센터 간 연결이 필요하며, 확장 가능하면서 운영 오버헤드를 줄일 수 있는 솔루션이 필요합니다. 솔루션스 아키텍트는 어떤 작업을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132920-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 두 리전과 온프레미스 간 연결을 단일 솔루션으로 확장 가능하게 구성하는 방법을 묻습니다. Direct Connect gateway를 사용하면 여러 리전의 VPC를 효과적으로 연결하고 운영 오버헤드를 줄일 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "AWS Direct Connect",
      "Direct Connect gateway",
      "Region 간 연결",
      "운영 오버헤드 감소",
      "확장성"
    ],
    "Terms": [
      "AWS Direct Connect",
      "VPC",
      "Data center",
      "Region",
      "CIDR blocks",
      "Inter-Region VPC peering",
      "Private virtual interfaces",
      "VPN appliances",
      "Amazon EC2",
      "AWS VPN CloudHub",
      "Direct Connect gateway",
      "Virtual private gateways"
    ],
    "SelectA": "us-east-1에 있는 VPC와 eu-west-2에 있는 VPC들 간 inter-Region VPC 페어링을 설정합니다.",
    "SelectA_Commentary": "VPC Peering은 리전 간 직접 연결을 지원하지만, 다수의 VPC와 온프레미스 연결까지 포함하면 관리가 복잡해집니다.",
    "SelectB": "us-east-1의 Direct Connect 연결에서 eu-west-2의 VPC들에 대해 private virtual interface를 만듭니다.",
    "SelectB_Commentary": "각 VPC마다 개별 인터페이스를 생성하는 방식은 확장성이 낮고, 운영 오버헤드가 높습니다.",
    "SelectC": "Amazon EC2에 호스팅된 완전 메시 VPN 네트워크용 VPN 어플라이언스를 구성하고, AWS VPN CloudHub로 데이터 센터 및 각 VPC 간 트래픽을 송수신합니다.",
    "SelectC_Commentary": "VPN에 기반한 메시 네트워크는 설정 및 유지보수에 많은 작업이 필요해 운영 오버헤드가 높습니다.",
    "SelectD": "기존 Direct Connect 연결을 Direct Connect gateway에 연결합니다. 각 리전에 있는 VPC의 virtual private gateway에서 Direct Connect gateway로 트래픽을 라우팅합니다.",
    "SelectD_Commentary": "Direct Connect gateway를 활용하면 다수의 리전과 VPC를 하나의 게이트웨이로 손쉽게 연결할 수 있어 확장성과 운영 효율을 모두 충족합니다.",
    "Question_Description_recommedations": [
      "Q686",
      "Q737",
      "Q684",
      "Q600",
      "Q474"
    ],
    "SelectA_recommedations": [
      "Q686",
      "Q474",
      "Q684"
    ],
    "SelectB_recommedations": [
      "Q734",
      "Q684",
      "Q737"
    ],
    "SelectC_recommedations": [
      "Q938",
      "Q686",
      "Q857"
    ],
    "SelectD_recommedations": [
      "Q734",
      "Q686",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q735",
    "Question_Description": "한 회사가 모바일 게임을 개발하고 있으며, 이 게임은 점수 업데이트를 백엔드 프로세서로 스트리밍한 뒤 리더보드에 결과를 게시합니다. 솔루션스 아키텍트는 대규모 트래픽 급증을 처리할 수 있고, 수신 순서대로 모바일 게임 업데이트를 처리하며, 처리된 업데이트를 고가용성 데이터베이스에 저장할 수 있는 솔루션을 설계해야 합니다. 또한 회사는 솔루션을 유지관리하는 데 필요한 운영 오버헤드를 최소화하고자 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 어떤 작업을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132922-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모바일 게임의 점수 업데이트를 실시간 스트리밍하고, 대규모 트래픽 급증에도 안정적으로 메시지를 순서대로 처리하여 고가용성 데이터베이스에 저장하는 방법을 묻습니다. Kinesis Data Streams와 AWS Lambda 조합은 무제한에 가까운 확장성과 순서 보장은 물론, 관리형 서비스로 운영 부담이 적습니다. 또한 Amazon DynamoDB는 고가용성과 무제한 확장이 가능하여 문제의 요구사항을 효과적으로 충족시킵니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "모바일 게임",
      "점수 업데이트",
      "Kinesis Data Streams",
      "AWS Lambda",
      "Amazon DynamoDB",
      "대규모 트래픽 급증",
      "수신 순서대로 처리",
      "고가용성 데이터베이스",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon EC2",
      "Auto Scaling",
      "Amazon Redshift",
      "Amazon SNS",
      "Amazon SQS",
      "Amazon RDS Multi-AZ"
    ],
    "SelectA": "점수 업데이트를 Amazon Kinesis Data Streams로 전송합니다. AWS Lambda로 Kinesis Data Streams에서 업데이트를 처리합니다. 처리된 업데이트를 Amazon DynamoDB에 저장합니다.",
    "SelectA_Commentary": "Kinesis Data Streams는 순서 보장과 손쉬운 확장을 지원하며, AWS Lambda로 서버 관리 없이 처리 업무를 수행할 수 있어 운영 부담이 낮습니다. Amazon DynamoDB는 고가용성과 확장성을 제공하므로 요구사항에 가장 적합합니다.",
    "SelectB": "점수 업데이트를 Amazon Kinesis Data Streams로 전송합니다. Auto Scaling이 구성된 Amazon EC2 인스턴스 플릿에서 업데이트를 처리합니다. 처리된 업데이트를 Amazon Redshift에 저장합니다.",
    "SelectB_Commentary": "Amazon EC2 인스턴스 플릿을 운영하려면 관리 및 유지보수 부담이 커집니다. 또한 Amazon Redshift는 데이터 웨어하우스에 적합하지만, 트랜잭션성 및 빠른 조회에는 DynamoDB만큼 효율적이지 않습니다.",
    "SelectC": "점수 업데이트를 Amazon Simple Notification Service (Amazon SNS) 주제로 전송합니다. AWS Lambda 함수를 SNS 주제에 구독시켜 업데이트를 처리합니다. 처리된 업데이트는 Amazon EC2에서 실행되는 SQL 데이터베이스에 저장합니다.",
    "SelectC_Commentary": "SNS는 브로드캐스팅 형태로 메시지를 전달하며 메시지 순서를 보장하지 않습니다. 게다가 EC2에 SQL DB를 직접 구축하면 관리 오버헤드가 커지고 고가용성 보장을 위해 추가 구성이 필요합니다.",
    "SelectD": "점수 업데이트를 Amazon Simple Queue Service (Amazon SQS) 대기열로 전송합니다. Auto Scaling이 설정된 Amazon EC2 인스턴스 플릿을 사용해 SQS 대기열의 업데이트를 처리합니다. 처리된 업데이트를 Amazon RDS Multi-AZ DB 인스턴스에 저장합니다.",
    "SelectD_Commentary": "SQS는 기본 FIFO 서비스가 있지만 EC2 인스턴스에 대한 유지관리 부담이 있고, Multi-AZ 구성의 RDS도 직접 운영해야 하므로 관리 오버헤드가 커져 요구사항과는 거리가 있습니다.",
    "Question_Description_recommedations": [
      "Q255",
      "Q58",
      "Q917",
      "Q491",
      "Q967"
    ],
    "SelectA_recommedations": [
      "Q768",
      "Q845",
      "Q1002"
    ],
    "SelectB_recommedations": [
      "Q198",
      "Q768",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q636",
      "Q45",
      "Q148"
    ],
    "SelectD_recommedations": [
      "Q203",
      "Q67",
      "Q944"
    ]
  },
  {
    "Question_Number": "Q736",
    "Question_Description": "회사는 여러 AWS 계정을 보유하고 있으며, 각 계정은 us-west-2 리전에서 애플리케이션을 운영하고 있습니다. 애플리케이션 로그는 각 계정의 Amazon S3 버킷에 저장됩니다. 회사는 이 로그들을 단일 S3 버킷으로 중앙화하여 분석하려고 합니다. 로그는 us-west-2 리전을 벗어나면 안 되며, 운영 오버헤드를 최소화해야 하고, 비용 효율적인 솔루션을 원합니다. 이러한 요구 사항을 만족하면서 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132923-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 계정에 분산되어 있는 S3 로그를 단일 버킷으로 중앙화하여, 로그가 리전을 벗어나지 않고 운영 오버헤드와 비용을 최소화하는 방법을 묻습니다. S3 Same-Region Replication(SRR)은 동일 리전 내에서 버킷 간 복제를 자동화하며, 비용과 운영 부담이 비교적 낮고 설정이 간단하므로 요구 사항에 쉽게 부합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "여러 AWS 계정",
      "us-west-2 리전",
      "로그 중앙화",
      "비용 효율성",
      "S3 Same-Region Replication"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Lifecycle Policy",
      "S3 Same-Region Replication",
      "PutObject API",
      "AWS Lambda",
      "s3:ObjectCreated:* 이벤트"
    ],
    "SelectA": "한 애플리케이션 S3 버킷에서 중앙화된 S3 버킷으로 객체를 복사하도록 S3 Lifecycle 정책을 생성합니다.",
    "SelectA_Commentary": "Lifecycle 정책은 객체의 스토리지 클래스를 전환하거나 만료할 때 주로 사용되며, 다른 버킷으로 항목을 자동 복사하는 데는 적합하지 않습니다.",
    "SelectB": "S3 Same-Region Replication을 사용하여 us-west-2 내 다른 S3 버킷으로 로그를 복제합니다. 이 S3 버킷을 로그 분석에 사용합니다.",
    "SelectB_Commentary": "SRR은 동일 리전 내 자동 복제를 제공하므로 로그가 리전을 벗어나지 않고, 자동화된 설정으로 운영 오버헤드를 낮추며 비용 대비 효율적으로 로그를 중앙화할 수 있습니다. 정답입니다.",
    "SelectC": "스크립트를 작성하여 매일 PutObject API로 버킷의 전체 콘텐츠를 us-west-2 내 다른 S3 버킷으로 복사합니다. 이 버킷을 로그 분석에 사용합니다.",
    "SelectC_Commentary": "스크립트 기반 복사는 관리 및 유지보수 부담이 높고, 대용량 로그를 매일 전부 복사해야 하므로 운영 오버헤드와 네트워크 비용이 큽니다.",
    "SelectD": "AWS Lambda 함수를 계정마다 작성하고, S3 버킷에 로그가 업로드(s3:ObjectCreated:*)될 때마다 트리거되어 다른 S3 버킷으로 복사합니다. 이 버킷을 로그 분석에 사용합니다.",
    "SelectD_Commentary": "Lambda 이벤트 트리거 설정은 가능하지만, 각 계정 버킷마다 함수를 배포하고 관리해야 하므로 오버헤드가 높아집니다. SRR에 비해 관리가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q960",
      "Q72",
      "Q829",
      "Q498",
      "Q469"
    ],
    "SelectA_recommedations": [
      "Q829",
      "Q498",
      "Q415"
    ],
    "SelectB_recommedations": [
      "Q736",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q736",
      "Q993",
      "Q469"
    ],
    "SelectD_recommedations": [
      "Q498",
      "Q829",
      "Q993"
    ]
  },
  {
    "Question_Number": "Q737",
    "Question_Description": "한 회사에서 전 세계 학생들에게 주문형 교육 동영상을 제공하는 애플리케이션을 운영 중이며, 승인된 콘텐츠 개발자가 동영상을 업로드할 수도 있습니다. 데이터는 us-east-2 리전의 Amazon S3 버킷에 저장되어 있습니다. 회사는 eu-west-2 리전과 ap-southeast-1 리전에 새로 S3 버킷을 만들었으며, 이 새로운 S3 버킷들로 데이터를 복제하고자 합니다. 또한 eu-west-2와 ap-southeast-1 근처의 개발자와 학생이 각각 업로드 및 스트리밍 시 지연을 최소화해야 합니다. 애플리케이션에 가장 적은 변화를 주면서 이 요구사항을 충족하기 위한 올바른 솔루션 조합은 무엇일까요? (2개를 고르시오.)",
    "Answer": "C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132924-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 리전에 걸쳐 동영상 업로드와 스트리밍 지연을 최소화하기 위한 S3 복제 및 Multi-Region Access Point 활용 방안을 묻습니다. Bidirectional(양방향) 복제로 모든 리전의 S3 버킷이 동기화되고, Multi-Region Access Point를 통해 사용자는 지리적으로 가까운 리전에 접근하여 업로드와 스트리밍 모두 빠른 속도로 처리할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "S3 버킷 복제",
      "지연 최소화",
      "개발자 업로드",
      "동영상 스트리밍",
      "다중 리전"
    ],
    "Terms": [
      "Amazon S3",
      "Cross-Region Replication",
      "S3 Multi-Region Access Point",
      "Bidirectional Replication",
      "Latency"
    ],
    "SelectA": "us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로, 그리고 us-east-2 S3 버킷에서 ap-southeast-1 S3 버킷으로 각각 단방향 복제를 구성합니다.",
    "SelectA_Commentary": "개발자가 유럽이나 아시아 리전에서 업로드하는 경우 여전히 us-east-2로 보내야 하므로 지연이 감소하지 않고, 3개 버킷 간 동기화가 완벽하지 않습니다.",
    "SelectB": "us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로 단방향 복제를 구성하고, eu-west-2 S3 버킷에서 ap-southeast-1 S3 버킷으로 단방향 복제를 구성합니다.",
    "SelectB_Commentary": "단계적인 체인 복제 방식이므로 업데이트가 즉시 동기화되지 않고, 업로드 지연도 여전하며 관리 복잡성이 높습니다.",
    "SelectC": "세 리전에 있는 모든 S3 버킷 간 양방향(bidirectional) 복제를 구성합니다.",
    "SelectC_Commentary": "세 리전이 동기화되어 어느 리전에서나 업로드해도 자동으로 다른 버킷과 동기화되어 지연이 크게 줄어듭니다. 다만 접근 경로 설정에 일부 변경이 필요합니다.",
    "SelectD": "S3 Multi-Region Access Point를 생성하고, 애플리케이션을 동영상 스트리밍을 위해 Multi-Region Access Point의 ARN으로만 수정합니다. 동영상 업로드에 대해서는 수정하지 않습니다.",
    "SelectD_Commentary": "스트리밍 속도는 빨라지지만 업로드 경로가 기존대로 us-east-2 버킷에만 종속되어 있으므로 개발자 지연 문제를 근본적으로 해결하지 못합니다.",
    "SelectE": "S3 Multi-Region Access Point를 생성하고, 애플리케이션을 동영상 스트리밍과 업로드 모두 Multi-Region Access Point의 ARN으로 사용하도록 수정합니다.",
    "SelectE_Commentary": "업로드와 스트리밍이 모두 지리적으로 가까운 리전에 연결되어 지연을 최소화합니다. 양방향 복제 정책과 함께 사용하면 데이터 동기화가 용이합니다.",
    "Question_Description_recommedations": [
      "Q43",
      "Q173",
      "Q501",
      "Q626",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q737",
      "Q684",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q737",
      "Q684",
      "Q738"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q626",
      "Q622"
    ],
    "SelectD_recommedations": [
      "Q737",
      "Q687",
      "Q686"
    ],
    "SelectE_recommedations": [
      "Q737",
      "Q687",
      "Q686"
    ]
  },
  {
    "Question_Number": "Q738",
    "Question_Description": "한 회사에 새로운 모바일 앱이 있습니다. 전 세계 어디에서나, 사용자는 자신이 선택한 주제에 대한 지역 뉴스를 볼 수 있습니다. 사용자는 앱 내부에서 사진과 동영상을 게시할 수도 있습니다. 사용자는 게시된 직후 몇 분 안에 콘텐츠를 자주 확인합니다. 새로운 콘텐츠가 빠르게 이전 콘텐츠를 대체하고, 이전 콘텐츠는 사라집니다. 뉴스의 지역적 특성으로 인해 사용자는 업로드된 AWS Region 내에서 90%의 콘텐츠를 소비합니다. 어떤 솔루션이 콘텐츠 업로드 시 가장 낮은 지연 시간을 제공하여 사용자 경험을 최적화할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132925-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "전 세계 사용자가 새로운 콘텐츠를 빠르게 업로드하고 소비하도록 최적화하는 문제입니다. S3 Transfer Acceleration은 업로드 경로를 최적화해 지연 시간을 크게 줄여 줍니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.4"
    ],
    "Keywords": [
      "모바일 앱",
      "지역 뉴스",
      "낮은 지연 시간",
      "Amazon S3",
      "S3 Transfer Acceleration",
      "사용자 경험 최적화"
    ],
    "Terms": [
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "Amazon S3",
      "Amazon EC2",
      "AWS Region"
    ],
    "SelectA": "Amazon S3에 콘텐츠를 업로드하고 저장합니다. 업로드를 위해 Amazon CloudFront를 사용합니다.",
    "SelectA_Commentary": "Amazon CloudFront는 주로 콘텐츠 다운로드(배포)에 최적화되어 있어 업로드 가속화에는 적합하지 않습니다.",
    "SelectB": "Amazon S3에 콘텐츠를 업로드하고 저장합니다. 업로드를 위해 S3 Transfer Acceleration을 사용합니다.",
    "SelectB_Commentary": "S3 Transfer Acceleration을 통해 CloudFront 엣지 로케이션을 활용해 업로드 속도를 크게 높일 수 있으므로 가장 낮은 지연 시간을 제공합니다.",
    "SelectC": "사용자와 가장 가까운 Region의 Amazon EC2 인스턴스로 콘텐츠를 업로드합니다. 그 후 데이터를 Amazon S3로 복사합니다.",
    "SelectC_Commentary": "EC2에 먼저 업로드한 뒤 S3로 복사하는 추가 단계를 거쳐야 하므로 지연 시간이 늘어나고 운영이 복잡해집니다.",
    "SelectD": "사용자와 가장 가까운 Region의 Amazon S3에 콘텐츠를 업로드하고 저장합니다. 여러 Amazon CloudFront 배포를 사용합니다.",
    "SelectD_Commentary": "여러 개의 CloudFront 배포를 구성하면 운영 복잡도가 상승하며, 업로드 자체를 가속화하는 데 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q443",
      "Q568",
      "Q361",
      "Q631",
      "Q865"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q43",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q672",
      "Q1015"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q501",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q280",
      "Q501",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q739",
    "Question_Description": "한 회사가 서버리스 아키텍처를 사용하는 신규 애플리케이션을 구축하려고 합니다. 이 아키텍처는 Amazon API Gateway REST API와 AWS Lambda 함수로 구성되어 들어오는 요청을 처리합니다. 회사는 이 API Gateway REST API에서 수신되는 메시지를 여러 Lambda 함수로 전달하고자 합니다. 또한 각 Lambda 함수가 필요한 메시지만 수신할 수 있도록 message filtering 기능이 필요합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 서비스는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132929-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 API로부터 전달된 메시지를 여러 Lambda 함수에 전달하면서, 각 함수가 필요한 메시지만을 분리할 수 있는 간단하고 확장성 있는 구조를 요구합니다. Amazon EventBridge는 이벤트 기반 아키텍처를 간편하게 구현하며 필터링 규칙을 통해 특정 조건에 맞는 메시지(이벤트)만 해당 Lambda 함수가 처리하도록 할 수 있습니다. 별도의 큐나 폴링 과정이 필요 없어 운영 오버헤드가 매우 낮습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "서버리스 아키텍처",
      "Amazon API Gateway",
      "AWS Lambda",
      "message filtering",
      "Amazon SNS",
      "Amazon SQS",
      "Amazon EventBridge",
      "Amazon MSK"
    ],
    "Terms": [
      "Amazon API Gateway",
      "REST API",
      "AWS Lambda",
      "Amazon SNS (Simple Notification Service)",
      "Amazon SQS (Simple Queue Service)",
      "Amazon EventBridge",
      "Amazon Managed Streaming for Apache Kafka (Amazon MSK)"
    ],
    "SelectA": "API Gateway REST API에서 받은 요청을 Amazon SNS 토픽으로 전송합니다. SNS 토픽에 Amazon SQS 큐들을 구독시킵니다. 대상 Lambda 함수들은 서로 다른 SQS 큐들을 폴링하도록 구성합니다.",
    "SelectA_Commentary": "SNS가 message filtering을 지원하지만, SQS 큐를 여러 개 생성하고 각 Lambda 함수에서 이를 폴링해야 하므로 오버헤드가 상대적으로 높습니다.",
    "SelectB": "API Gateway REST API에서 받은 요청을 Amazon EventBridge로 전송합니다. EventBridge가 대상 Lambda 함수들을 호출하도록 구성합니다.",
    "SelectB_Commentary": "EventBridge의 필터링 규칙을 사용해 각 Lambda 함수에 필요한 메시지만 전달할 수 있습니다. 큐나 폴링 과정 없이 이벤트가 직접 Lambda 함수로 전달되어 오버헤드가 가장 적은 솔루션입니다.",
    "SelectC": "API Gateway REST API에서 받은 요청을 Amazon MSK(Amazon Managed Streaming for Apache Kafka)에 전송합니다. Amazon MSK가 메시지를 대상 Lambda 함수들에게 게시하도록 구성합니다.",
    "SelectC_Commentary": "카프카 클러스터 설정, 운영 및 모니터링에 대한 부담이 크고, 단순 메시지 분배에는 과도한 솔루션입니다.",
    "SelectD": "API Gateway REST API에서 받은 요청을 여러 Amazon SQS 큐로 전송합니다. 대상 Lambda 함수들은 서로 다른 SQS 큐들을 폴링하도록 구성합니다.",
    "SelectD_Commentary": "직접 큐를 분산해 전송하므로 메시지 필터링 기능이 자동으로 제공되지 않으며, 각 큐를 개별적으로 폴링해야 하므로 운영 오버헤드가 높습니다.",
    "Question_Description_recommedations": [
      "Q207",
      "Q25",
      "Q785",
      "Q10",
      "Q87"
    ],
    "SelectA_recommedations": [
      "Q10",
      "Q636",
      "Q489"
    ],
    "SelectB_recommedations": [
      "Q569",
      "Q10",
      "Q739"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q775",
      "Q739"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q739",
      "Q207"
    ]
  },
  {
    "Question_Number": "Q740",
    "Question_Description": "한 회사가 아카이브 파일 수백만 개를 Amazon S3로 마이그레이션했습니다. 솔루션스 아키텍트는 customer-provided key를 사용해 모든 아카이브 데이터를 암호화하는 솔루션을 구현해야 합니다. 이 솔루션은 이미 존재하는 암호화되지 않은 객체와 향후 업로드되는 객체 모두를 암호화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132930-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "기존 S3 객체와 앞으로 업로드될 객체를 모두 customer-provided key(SSE-C)로 암호화해야 하는 문제입니다. S3 Inventory를 활용하면 각 객체의 암호화 상태를 파악할 수 있고, 이를 기반으로 S3 Batch Operations로 미암호화 객체를 일괄 암호화할 수 있습니다. 또한 S3 default encryption을 SSE-C로 설정하면 향후 업로드되는 객체도 자동 암호화가 적용되어 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "아카이브 데이터",
      "기존 객체 암호화",
      "향후 객체 암호화",
      "customer-provided key (SSE-C)",
      "S3 Batch Operations",
      "S3 Inventory",
      "S3 default encryption"
    ],
    "Terms": [
      "Amazon S3",
      "S3 default encryption",
      "S3 Batch Operations",
      "S3 Inventory",
      "S3 Storage Lens",
      "AWS usage report",
      "SSE-C",
      "SSE-KMS"
    ],
    "SelectA": "Amazon S3 Inventory 보고서에서 암호화되지 않은 객체 목록을 필터링해 생성합니다. S3 Batch Operations 작업을 구성해 해당 리스트의 객체를 customer-provided key(SSE-C)를 사용한 서버 사이드 암호화로 암호화합니다. 이후 S3 default encryption 기능을 설정해 customer-provided key(SSE-C)로 암호화를 적용합니다.",
    "SelectA_Commentary": "S3 Inventory로 미암호화 객체 목록을 확보하고, Batch Operations로 일괄 암호화한 뒤, default encryption으로 새 객체까지 자동 암호화하므로 요구사항을 완벽히 충족합니다.",
    "SelectB": "S3 Storage Lens 지표를 사용해 암호화되지 않은 S3 버킷을 식별합니다. S3 default encryption 기능을 AWS KMS key(SSE-KMS)를 사용한 서버 사이드 암호화로 설정합니다.",
    "SelectB_Commentary": "customer-provided key(SSE-C)가 아닌 AWS KMS key(SSE-KMS)를 사용하므로 문제에서 요구하는 조건에 부합하지 않습니다.",
    "SelectC": "Amazon S3에 대한 AWS usage report를 필터링해 암호화되지 않은 객체 리스트를 생성합니다. AWS Batch 작업을 구성해 해당 리스트의 객체를 AWS KMS key(SSE-KMS)를 사용한 서버 사이드 암호화로 암호화합니다. 이후 S3 default encryption 기능을 SSE-KMS로 설정합니다.",
    "SelectC_Commentary": "AWS usage report는 객체별 암호화 상태 정보를 제공하지 않으며, 또한 SSE-KMS를 사용하는 것이므로 요구사항(고객 제공 키)에 맞지 않습니다.",
    "SelectD": "Amazon S3에 대한 AWS usage report를 필터링해 암호화되지 않은 객체 목록을 생성합니다. S3 default encryption 기능을 customer-provided key(SSE-C)로 설정합니다.",
    "SelectD_Commentary": "기존 객체 암호화 방식으로 usage report를 사용하지만, 이는 객체별 암호화 상태 정보를 제공하지 못해 미암호화 객체 식별이 어렵습니다.",
    "Question_Description_recommedations": [
      "Q965",
      "Q696",
      "Q202",
      "Q44",
      "Q678"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q185",
      "Q862"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q640",
      "Q36"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q36",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q740",
      "Q862",
      "Q185"
    ]
  },
  {
    "Question_Number": "Q741",
    "Question_Description": "회사의 도메인 이름 레코드를 호스팅하는 DNS provider에서 장애가 발생하여 AWS에서 운영되는 웹사이트에 서비스 중단이 발생하고 있습니다. 회사는 더 탄력적인 managed DNS 서비스로 옮기고, 해당 서비스가 AWS에서 동작하기를 원합니다. 솔루션스 아키텍트는 DNS 호스팅 서비스를 빠르게 마이그레이션하기 위해 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132931-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DNS provider 장애로 인한 서비스 중단을 해결하기 위해 AWS 기반의 안정적인 DNS 서비스로 신속히 이전하는 방법을 묻습니다. Amazon Route 53 public hosted zone을 생성하고 기존 레코드를 zone file로 가져오면, 외부 사용자에게 즉시 도메인이 정상적으로 해석되도록 할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DNS 장애",
      "도메인 레코드",
      "AWS 웹사이트",
      "Amazon Route 53",
      "public hosted zone",
      "zone file",
      "관리형 DNS",
      "마이그레이션"
    ],
    "Terms": [
      "Amazon Route 53 public hosted zone",
      "Amazon Route 53 private hosted zone",
      "Simple AD",
      "AWS Directory Service for Microsoft Active Directory",
      "Route 53 Resolver inbound endpoint",
      "VPC",
      "DNS queries",
      "zone transfer"
    ],
    "SelectA": "도메인 이름에 대해 Amazon Route 53 public hosted zone을 생성하고, 이전 provider에 호스팅된 도메인 레코드가 담긴 zone file을 가져옵니다.",
    "SelectA_Commentary": "public hosted zone은 외부에 공개되는 DNS 환경을 제공하므로 웹사이트 접근이 문제없이 가능해집니다. zone file을 통해 빠르게 기존 DNS 설정을 이전할 수 있어 가장 적합한 해결책입니다.",
    "SelectB": "도메인 이름에 대해 Amazon Route 53 private hosted zone을 생성하고, 이전 provider에 호스팅된 도메인 레코드가 담긴 zone file을 가져옵니다.",
    "SelectB_Commentary": "private hosted zone은 VPC 내부에서만 유효하므로, 인터넷에서 접근해야 하는 웹사이트의 DNS로는 사용할 수 없어 적합하지 않습니다.",
    "SelectC": "AWS에 Simple AD 디렉터리를 생성합니다. DNS provider와 AWS Directory Service for Microsoft Active Directory 간 zone transfer를 활성화하여 도메인 레코드를 동기화합니다.",
    "SelectC_Commentary": "Active Directory 및 추가 구성이 요구되어 마이그레이션 과정이 복잡해집니다. 신속한 DNS 이전 목적과는 거리가 멉니다.",
    "SelectD": "VPC 내에 Amazon Route 53 Resolver inbound endpoint를 생성하고, provider DNS가 DNS 쿼리를 전달할 IP 주소로 해당 endpoint를 지정해 도메인 쿼리를 포워딩하도록 구성합니다.",
    "SelectD_Commentary": "이 접근 방법은 기존 DNS provider를 계속 사용해야 하므로, 장애 발생 시 원인이 해결되지 않아 빠른 이전을 달성할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q627",
      "Q983",
      "Q293",
      "Q869",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q264",
      "Q544"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q264",
      "Q544"
    ],
    "SelectC_recommedations": [
      "Q741",
      "Q627",
      "Q545"
    ],
    "SelectD_recommedations": [
      "Q264",
      "Q439",
      "Q545"
    ]
  },
  {
    "Question_Number": "Q742",
    "Question_Description": "한 회사가 Amazon RDS 데이터베이스와 연결되는 AWS 애플리케이션을 개발하고 있습니다. 이 회사는 애플리케이션 구성을 손쉽게 관리하고, 데이터베이스 및 다른 서비스에 대한 자격 증명을 안전하게 저장하고 검색하기를 원합니다. 가장 적은 관리 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132932-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 구성과 자격 증명을 안전하게 관리하는 방법을 묻습니다. AWS AppConfig는 구성 변경을 중앙에서 손쉽게 배포하도록 돕고, AWS Secrets Manager는 자격 증명을 안전하게 관리·회전할 수 있어 최소한의 운영 작업으로 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon RDS",
      "애플리케이션 구성",
      "자격 증명 안전 저장",
      "AWS Secrets Manager",
      "AWS AppConfig"
    ],
    "Terms": [
      "AWS AppConfig",
      "AWS Secrets Manager",
      "AWS Lambda",
      "AWS Systems Manager Parameter Store",
      "Amazon S3",
      "Amazon RDS"
    ],
    "SelectA": "AWS AppConfig를 사용하여 애플리케이션 구성을 저장 및 관리합니다. AWS Secrets Manager를 사용하여 자격 증명을 저장하고 검색합니다.",
    "SelectA_Commentary": "AWS AppConfig로 구성 변경을 쉽게 배포하고, Secrets Manager가 자격 증명의 자동 회전 및 보안을 제공하므로 관리 오버헤드가 가장 낮은 정답입니다.",
    "SelectB": "AWS Lambda를 사용하여 애플리케이션 구성을 저장 및 관리합니다. AWS Systems Manager Parameter Store를 사용하여 자격 증명을 저장하고 검색합니다.",
    "SelectB_Commentary": "Lambda로 직접 구성 관리는 별도 코드 및 배포 과정이 필요해 오버헤드가 높아집니다. Parameter Store만으로는 Credentials 회전 등 세밀한 관리가 제한적입니다.",
    "SelectC": "암호화된 애플리케이션 구성 파일을 Amazon S3에 저장합니다. S3에 다른 파일을 생성하여 자격 증명을 저장하고 검색합니다.",
    "SelectC_Commentary": "S3를 활용해 암호화 파일을 관리할 수 있지만, 파일 상태 관리와 버전 관리가 추가로 필요해 관리 오버헤드가 큽니다.",
    "SelectD": "AWS AppConfig를 사용하여 애플리케이션 구성을 저장 및 관리합니다. Amazon RDS에 자격 증명을 저장하고 검색합니다.",
    "SelectD_Commentary": "Amazon RDS에 자격 증명을 저장하는 것은 추천되지 않는 보안 방식이며, 관리자 부담과 유지보수 이슈가 증가하므로 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q330",
      "Q732",
      "Q61",
      "Q653",
      "Q847"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q233",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q936",
      "Q289",
      "Q791"
    ],
    "SelectC_recommedations": [
      "Q106",
      "Q678",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q847",
      "Q61",
      "Q330"
    ]
  },
  {
    "Question_Number": "Q743",
    "Question_Description": "한 회사가 Amazon RDS MySQL DB instance와 통신할 때, 전송 중인 애플리케이션 데이터를 모두 암호화해야 합니다. 최근 보안 감사에서 AWS Key Management Service(AWS KMS)를 사용하여 데이터가 저장 시(At rest) 암호화되어 있음은 확인되었지만, 전송 중 암호화가 활성화되어 있지 않은 것으로 드러났습니다. 이 보안 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132933-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS MySQL 환경에서 전송 중(SSL/TLS)을 통한 데이터 암호화를 설정하는 방법을 묻습니다. 이미 AWS KMS로 저장 시 암호화는 이루어지고 있으므로, 전송 중 암호화를 위해서는 AWS에서 제공하는 루트 인증서를 사용해 DB 연결 시 SSL/TLS를 활성화해야 합니다. 이는 보안 요구 사항을 충족하는 가장 간단하고 표준적인 방식입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "전송 중 암호화",
      "Amazon RDS MySQL",
      "AWS KMS",
      "루트 인증서",
      "SSL/TLS 연결"
    ],
    "Terms": [
      "Amazon RDS",
      "MySQL",
      "AWS Key Management Service(AWS KMS)",
      "SSL/TLS",
      "루트 인증서",
      "IAM Database Authentication"
    ],
    "SelectA": "데이터베이스에서 IAM database authentication을 활성화합니다.",
    "SelectA_Commentary": "IAM Database Authentication은 인증 방법일 뿐 전송 중 암호화를 자동으로 보장하지 않습니다.",
    "SelectB": "자가 서명한 인증서를 제공합니다. RDS instance와의 모든 연결에 이 인증서를 사용합니다.",
    "SelectB_Commentary": "자가 서명 인증서는 보안 표준에 부합하지 않을 수 있으며, AWS가 사용하는 공식 인증서 대신 권장되지 않습니다.",
    "SelectC": "RDS instance의 스냅샷을 생성한 뒤 해당 스냅샷을 암호화가 활성화된 신규 인스턴스로 복원합니다.",
    "SelectC_Commentary": "이는 이미 저장 시(At rest) 암호화가 설정된 상태에서는 무의미하며, 전송 중 암호화에는 영향이 없습니다.",
    "SelectD": "AWS에서 제공하는 루트 인증서를 다운로드받습니다. RDS instance와의 모든 연결에 이 인증서를 제공합니다.",
    "SelectD_Commentary": "AWS에서 제공하는 루트 인증서를 사용해 SSL/TLS를 활성화함으로써 전송 중 암호화를 간단하고 안전하게 구현할 수 있는 정답입니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q681",
      "Q339",
      "Q640",
      "Q793"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectB_recommedations": [
      "Q330",
      "Q893",
      "Q847"
    ],
    "SelectC_recommedations": [
      "Q330",
      "Q742",
      "Q847"
    ],
    "SelectD_recommedations": [
      "Q330",
      "Q61",
      "Q732"
    ]
  },
  {
    "Question_Number": "Q744",
    "Question_Description": "한 회사에서는 Elastic Load Balancing(ELB) 로드 밸런서 뒤에서 동작할 Amazon EC2 인스턴스로 구성된 새로운 웹 서비스를 설계하고 있습니다. 그러나 웹 서비스 클라이언트 중 다수가 방화벽에서 허용된 IP 주소로만 통신할 수 있다고 합니다. 이러한 고객 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 추천해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132934-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 방화벽에 허용한 IP 주소만 접근할 수 있는 고객 환경에서, 동일한 고정 IP 주소를 제공해야 하는 상황을 다룹니다. NLB는 Elastic IP를 할당하여 고정 IP 주소를 제공할 수 있어 간단히 방화벽 화이트리스트에 등록 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Network Load Balancer",
      "Elastic IP 주소",
      "방화벽 IP 화이트리스트",
      "Amazon EC2",
      "Elastic Load Balancing"
    ],
    "Terms": [
      "Network Load Balancer(NLB)",
      "Application Load Balancer(ALB)",
      "Elastic IP",
      "Amazon Route 53",
      "EC2 인스턴스",
      "프록시"
    ],
    "SelectA": "연결된 Elastic IP 주소가 있는 Network Load Balancer",
    "SelectA_Commentary": "NLB는 Elastic IP를 연결해 고정 IP를 제공하므로 방화벽 등록이 용이합니다. 이 방식이 고객 요구사항을 직접적으로 만족합니다.",
    "SelectB": "연결된 Elastic IP 주소가 있는 Application Load Balancer",
    "SelectB_Commentary": "ALB는 기본적으로 고정 IP가 보장되지 않으므로 방화벽 화이트리스트 요구사항을 충족하기 어렵습니다.",
    "SelectC": "Amazon Route 53 호스티드 존의 A 레코드를 Elastic IP 주소와 매핑",
    "SelectC_Commentary": "Route 53에 A 레코드를 설정해도 백엔드인 ALB 또는 EC2의 IP가 고정되지 않으면 방화벽 화이트리스트 문제를 해결하기 어렵습니다.",
    "SelectD": "퍼블릭 IP가 있는 EC2 인스턴스를 프록시로 두고 로드 밸런서 앞에 배치",
    "SelectD_Commentary": "EC2 프록시를 사용하면 관리 오버헤드가 커집니다. 또한 실제 트래픽을 처리하는 로드 밸런서와의 연결 안정성 확보가 어려울 수 있습니다.",
    "Question_Description_recommedations": [
      "Q437",
      "Q382",
      "Q35",
      "Q170",
      "Q675"
    ],
    "SelectA_recommedations": [
      "Q170",
      "Q625",
      "Q744"
    ],
    "SelectB_recommedations": [
      "Q170",
      "Q625",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q321",
      "Q682",
      "Q970"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q96",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q745",
    "Question_Description": "한 회사가 새 AWS account를 개설했습니다. 이 account는 새로 프로비저닝되었으며 기본 설정에 아무런 변경 사항도 적용되지 않았습니다. 회사는 AWS account root user의 보안에 대해 우려하고 있습니다. root user를 안전하게 보호하려면 어떻게 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132935-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS account root user의 올바른 사용 방안을 묻습니다. root user는 계정 전체 권한을 갖기 때문에 가능한 한 사용을 제한하고, 보안을 강화해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "root user",
      "보안",
      "IAM user",
      "MFA",
      "AWS 보안 모범 사례"
    ],
    "Terms": [
      "root user",
      "IAM",
      "Multi-Factor Authentication(MFA)",
      "AWS Management Console",
      "Access Key"
    ],
    "SelectA": "일상적인 관리자 작업용으로 IAM user를 생성하고 root user를 비활성화합니다.",
    "SelectA_Commentary": "root user를 비활성화하는 것은 지원되지 않으며, MFA 설정이 누락되었습니다.",
    "SelectB": "일상적인 관리자 작업용으로 IAM user를 생성하고 root user에 Multi-Factor Authentication을 활성화합니다.",
    "SelectB_Commentary": "AWS 보안 모범 사례에 따라 root user의 사용을 최소화하고 MFA를 적용하는 가장 안전한 방법입니다. 정답",
    "SelectC": "root user의 Access Key를 생성하고 매일 AWS Management Console 대신 이 Access Key를 사용합니다.",
    "SelectC_Commentary": "root user 권한을 계속 사용하면 보안 위험이 큽니다. MFA 구성도 누락되었습니다.",
    "SelectD": "root user 자격 증명을 가장 선임된 솔루션스 아키텍트에게 제공하고, 매일 관리자 업무에 root user를 사용합니다.",
    "SelectD_Commentary": "root user에 대한 액세스를 타인에게 공유하는 것은 위험하며, MFA 설정도 없으므로 보안 모범 사례에 어긋납니다.",
    "Question_Description_recommedations": [
      "Q233",
      "Q878",
      "Q780",
      "Q137",
      "Q797"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q233",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q797",
      "Q233",
      "Q745"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q745",
      "Q898"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q332",
      "Q745"
    ]
  },
  {
    "Question_Number": "Q746",
    "Question_Description": "한 회사가 거의 실시간으로 스트리밍 데이터를 처리하는 애플리케이션을 배포하려고 합니다. 이를 위해 Amazon EC2 인스턴스를 사용할 계획입니다. 네트워크 아키텍처는 노드 간 가능한 가장 낮은 지연 시간을 제공하도록 구성 가능해야 합니다. 이 요구사항을 충족하는 네트워크 솔루션 조합은 무엇입니까? (두 개를 선택하세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132936-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2 인스턴스로 스트리밍 데이터를 처리할 때, 노드 간 통신을 위해 가장 낮은 지연 시간을 보장해야 하는 상황입니다. Enhanced networking과 Cluster placement group이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.4"
    ],
    "Keywords": [
      "실시간 스트리밍 데이터",
      "Amazon EC2",
      "네트워크 지연 시간 최소화",
      "Enhanced networking",
      "Cluster placement group"
    ],
    "Terms": [
      "Amazon EC2",
      "Enhanced networking",
      "Cluster placement group",
      "Elastic Network Interface",
      "Amazon EBS",
      "EBS optimized instance"
    ],
    "SelectA": "각 EC2 인스턴스에서 Enhanced networking을 활성화하고 구성합니다.",
    "SelectA_Commentary": "Enhanced networking은 인스턴스 간 통신에 대해 높은 PPS 성능과 낮은 지연 시간을 제공하므로 필수적입니다.",
    "SelectB": "EC2 인스턴스들을 서로 다른 계정으로 분리하여 그룹화합니다.",
    "SelectB_Commentary": "계정을 분리해도 네트워크 성능 향상과는 직접적인 관련이 없어 지연 시간 개선 효과가 거의 없습니다.",
    "SelectC": "EC2 인스턴스들을 Cluster placement group에 배치합니다.",
    "SelectC_Commentary": "Cluster placement group은 단일 가용 영역 내 인스턴스 배치를 최적화해, 높은 네트워크 처리량과 매우 낮은 지연 시간을 제공합니다.",
    "SelectD": "각 EC2 인스턴스에 다중 Elastic Network Interface를 연결합니다.",
    "SelectD_Commentary": "ENI를 여러 개 사용하는 것은 트래픽 분산에는 도움이 될 수 있지만, 지연 시간을 근본적으로 줄이는 최적의 방법은 아닙니다.",
    "SelectE": "Amazon EBS 최적화 유형 인스턴스를 사용합니다.",
    "SelectE_Commentary": "EBS 최적화는 EBS I/O 성능에 집중된 기능이므로, 노드 간 지연 시간을 크게 줄이는 데는 직접적 도움이 안 됩니다.",
    "Question_Description_recommedations": [
      "Q568",
      "Q361",
      "Q443",
      "Q547",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q704",
      "Q352"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q857",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q704",
      "Q746",
      "Q857"
    ],
    "SelectE_recommedations": [
      "Q361",
      "Q501",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q747",
    "Question_Description": "한 금융 서비스 회사가 두 개의 데이터 센터를 종료하고, 100TB 이상의 데이터를 AWS로 마이그레이션하려고 합니다. 이 데이터는 수백만 개의 소규모 파일이 하위 폴더의 깊은 계층 구조에 저장되어 있으며, 대부분이 비정형 데이터입니다. 또한 회사의 파일 스토리지는 다수의 벤더가 제공하는 SMB 기반 스토리지 유형으로 구성되어 있습니다. 회사는 마이그레이션 후에도 애플리케이션에서 데이터를 액세스하는 방식을 변경하고 싶지 않습니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하려면 솔루션스 아키텍트가 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132938-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 복잡한 SMB 기반 파일 구조를 그대로 유지하면서 대규모 데이터를 AWS로 이전하려는 요구 사항을 해결하는 방법을 묻습니다. Amazon FSx for Windows File Server는 SMB 프로토콜을 지원하므로, 애플리케이션 수정을 최소화하고 손쉽게 마이그레이션할 수 있습니다. AWS DataSync를 통해 데이터 전송 작업을 자동화하면 운영 오버헤드도 크게 줄어듭니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "데이터 마이그레이션",
      "SMB",
      "비정형 데이터",
      "운영 오버헤드",
      "Amazon FSx for Windows File Server",
      "AWS DataSync"
    ],
    "Terms": [
      "AWS Direct Connect",
      "Amazon S3",
      "AWS DataSync",
      "Amazon FSx for Lustre",
      "Amazon FSx for Windows File Server",
      "AWS Storage Gateway",
      "SMB-based",
      "unstructured data"
    ],
    "SelectA": "AWS Direct Connect를 사용하여 데이터를 Amazon S3로 마이그레이션합니다.",
    "SelectA_Commentary": "Amazon S3는 객체 스토리지로, SMB 기반 파일 접근 방식을 유지하기 어렵습니다. 애플리케이션의 파일 액세스 구조를 변경해야 하므로 적합하지 않습니다.",
    "SelectB": "AWS DataSync를 사용하여 데이터를 Amazon FSx for Lustre로 마이그레이션합니다.",
    "SelectB_Commentary": "Amazon FSx for Lustre는 HPC 워크로드에 최적화된 파일 시스템으로, Windows 환경의 SMB 호환성을 그대로 보장하지 않아 요구 사항을 충족하기 어렵습니다.",
    "SelectC": "AWS DataSync를 사용하여 데이터를 Amazon FSx for Windows File Server로 마이그레이션합니다.",
    "SelectC_Commentary": "SMB를 그대로 지원하는 네이티브 Windows 파일 시스템이라 애플리케이션 수정이 거의 없고, AWS DataSync로 마이그레이션을 자동화해 운영 부담을 줄일 수 있어 정답입니다.",
    "SelectD": "AWS Direct Connect를 사용하여 온프레미스 파일 스토리지를 AWS Storage Gateway volume gateway로 마이그레이션합니다.",
    "SelectD_Commentary": "AWS Storage Gateway volume gateway는 iSCSI 기반 접근 방식이라 SMB 호환성이 부족하고 추가 구성 및 운영이 필요해 오버헤드가 커집니다.",
    "Question_Description_recommedations": [
      "Q113",
      "Q895",
      "Q443",
      "Q361",
      "Q568"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q407",
      "Q361",
      "Q515"
    ],
    "SelectC_recommedations": [
      "Q301",
      "Q287",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q734",
      "Q957",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q748",
    "Question_Description": "한 회사가 AWS Organizations의 조직을 사용하여 애플리케이션이 포함된 AWS 계정을 관리하고 있습니다. 이 회사는 조직 내에 전용 모니터링 멤버 계정을 설정했습니다. 이 회사는 Amazon CloudWatch를 사용하여 여러 계정에서 관측 가능성(observability) 데이터를 쿼리하고 시각화하고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132939-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 CloudWatch 데이터를 통합 모니터링 계정으로 모아 효과적으로 시각화할 수 있는 방법을 묻습니다. 정답인 SelectA는 CloudWatch cross-account observability 사용을 통해 각 계정에서 모니터링 계정으로 데이터를 간단히 공유하도록 설계되어 운영 부담을 크게 줄입니다. 다른 선택지는 교차 계정 접근 권한을 일일이 부여하거나 SCP만으로는 충분하지 않아, 요구사항을 만족시키지 못하거나 실행이 복잡합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "모니터링 멤버 계정",
      "Amazon CloudWatch",
      "observability 데이터",
      "CloudWatch cross-account observability",
      "AWS CloudFormation 템플릿"
    ],
    "Terms": [
      "AWS Organizations",
      "CloudWatch cross-account observability",
      "Amazon CloudWatch",
      "AWS CloudFormation",
      "Service Control Policies (SCP)",
      "IAM 사용자",
      "IAM 정책",
      "교차 계정 IAM 정책"
    ],
    "SelectA": "CloudWatch cross-account observability를 모니터링 계정에서 활성화합니다. 모니터링 계정에서 제공한 AWS CloudFormation 템플릿을 각 AWS 계정에 배포하여 모니터링 계정과 데이터를 공유합니다.",
    "SelectA_Commentary": "CloudWatch cross-account observability 기능과 CloudFormation을 활용해 각 계정이 자동으로 모니터링 계정에 데이터를 공유하도록 구성하므로, 요구사항을 가장 간단하고 효율적으로 충족합니다.",
    "SelectB": "Organizations 루트 조직 단위(OU)에서 모니터링 계정에 대해 CloudWatch에 대한 액세스를 부여하기 위해 Service Control Policies(SCP)를 설정합니다.",
    "SelectB_Commentary": "SCP를 통해 접근 제한을 조정할 수 있지만, 계정 간 모니터링 데이터 공유를 자동화하거나 시각화 구성까지 보장하지 못해 요구사항을 충분히 충족하지 못합니다.",
    "SelectC": "모니터링 계정에 새 IAM 사용자를 구성합니다. 각 AWS 계정에서 이 IAM 사용자가 해당 계정의 CloudWatch 데이터를 쿼리하고 시각화하도록 IAM 정책을 구성하고, 새 IAM 사용자에 연결합니다.",
    "SelectC_Commentary": "IAM 사용자와 정책을 개별 계정마다 설정해야 하므로 관리와 유지가 복잡해집니다. 실제 교차 계정 데이터 통합보다는 계정별 접근만 가능해 운영이 비효율적입니다.",
    "SelectD": "모니터링 계정에 새 IAM 사용자를 생성합니다. 각 AWS 계정에서 교차 계정 IAM 정책을 만들어 새 IAM 사용자에 연결합니다.",
    "SelectD_Commentary": "이 방법은 계정 간 IAM 정책 설정에 많은 작업이 필요하며, CloudWatch 통합 모니터링 핵심 요구사항인 관측 데이터의 일원화와 손쉬운 시각화를 보장하지 못합니다.",
    "Question_Description_recommedations": [
      "Q945",
      "Q168",
      "Q1018",
      "Q27",
      "Q619"
    ],
    "SelectA_recommedations": [
      "Q748",
      "Q27",
      "Q387"
    ],
    "SelectB_recommedations": [
      "Q748",
      "Q709",
      "Q560"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q476",
      "Q222",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q749",
    "Question_Description": "한 회사의 웹사이트는 대중에 제품을 판매하는 데 사용됩니다. 사이트는 Application Load Balancer(ALB) 뒤의 Auto Scaling group에 속한 Amazon EC2 인스턴스에서 구동됩니다. 또한 Amazon CloudFront distribution이 있으며, AWS WAF를 사용하여 SQL injection 공격으로부터 보호하고 있습니다. ALB는 CloudFront distribution의 오리진 역할을 합니다. 최근 보안 로그를 검토한 결과, 웹사이트에 대한 접근을 차단해야 하는 외부 악성 IP가 발견되었습니다. 애플리케이션을 보호하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132940-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션 계층에서 악의적인 IP 주소를 효율적으로 차단하는 방법을 묻습니다. AWS WAF는 Application Load Balancer와 CloudFront를 통한 트래픽에 대한 규칙을 적용해 IP 기반 필터링을 손쉽게 수행할 수 있어 가장 적합합니다. 다른 옵션들은 사이트 전체를 보호하지 못하거나 과도한 설정 변경이 필요합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "ALB 뒤의 Amazon EC2",
      "AWS WAF를 통한 SQL injection 방어",
      "외부 악성 IP 차단"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Amazon CloudFront distribution",
      "AWS WAF",
      "network ACL",
      "security group",
      "SQL injection",
      "IP match condition"
    ],
    "SelectA": "CloudFront distribution에 대한 Network ACL을 수정하여 악성 IP 주소를 차단합니다.",
    "SelectA_Commentary": "CloudFront에 직접 Network ACL을 구성할 수 없으므로 적합한 방법이 아닙니다.",
    "SelectB": "AWS WAF 설정을 수정하여 악성 IP 주소를 차단하는 IP match condition을 추가합니다.",
    "SelectB_Commentary": "AWS WAF는 애플리케이션 계층에서 필터링을 적용하기에 가장 효과적이므로 정답입니다. 간단한 설정으로 전체 트래픽을 대상으로 규칙을 적용할 수 있습니다.",
    "SelectC": "ALB 뒤 타겟 그룹의 EC2 인스턴스에 대한 Network ACL을 수정하여 악성 IP 주소를 차단합니다.",
    "SelectC_Commentary": "Network ACL을 인스턴스가 속한 서브넷에서 변경해도 CloudFront에서 오는 트래픽에 제한이 적용되지 않을 수 있으며, 설정이 복잡해집니다.",
    "SelectD": "ALB 뒤 타겟 그룹의 EC2 인스턴스에 대한 Security Group을 수정하여 악성 IP 주소를 차단합니다.",
    "SelectD_Commentary": "Security Group은 상태 저장 방화벽으로 특정 IP를 막을 수 있지만, CloudFront와의 통신은 ALB 기준으로 이루어지므로 전체 트래픽을 제어하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q340",
      "Q927",
      "Q60",
      "Q180",
      "Q884"
    ],
    "SelectA_recommedations": [
      "Q855",
      "Q172",
      "Q577"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q96",
      "Q1019"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q437",
      "Q218"
    ],
    "SelectD_recommedations": [
      "Q60",
      "Q973",
      "Q437"
    ]
  },
  {
    "Question_Number": "Q750",
    "Question_Description": "한 회사는 10개의 AWS 계정을 포함한 AWS Organizations를 구성했습니다. 솔루션 아키텍트는 수천 명의 직원들에게 이 계정들에 대한 접근 권한을 제공해야 합니다. 회사에는 이미 기존 identity provider(IdP)가 있으며, 이를 통해 AWS에 인증하기를 원합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132941-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정을 중앙 관리하고, 이미 존재하는 IdP를 활용하여 수천 명의 사용자에게 손쉽게 접근 권한을 부여하는 방안을 찾는 것입니다. AWS IAM Identity Center(AWS SSO)를 사용하면 외부 IdP와 연동을 통해 한 번의 인증으로 다양한 AWS 계정에 액세스하도록 구성할 수 있으며, 대규모 사용자 관리를 단순화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Organizations",
      "기존 IdP",
      "IAM Identity Center",
      "액세스 관리"
    ],
    "Terms": [
      "AWS Organizations",
      "Identity provider(IdP)",
      "IAM user",
      "Root user",
      "AWS IAM Identity Center (AWS Single Sign-On)",
      "Federated authentication",
      "AWS Resource Access Manager (AWS RAM)"
    ],
    "SelectA": "필요한 AWS 계정에 IAM 사용자들을 생성하고, 기존 IdP에 연동하여 연합(federated) 인증을 구성합니다.",
    "SelectA_Commentary": "수천 명의 사용자를 IAM 사용자로 각각 생성 및 운영하는 것은 관리 부담이 매우 큽니다. 운영과 계정 동기화 면에서도 비효율적입니다.",
    "SelectB": "AWS 계정의 root 사용자에 기존 IdP에서 동기화된 이메일 주소와 비밀번호를 설정해 둡니다.",
    "SelectB_Commentary": "root 사용자는 보안상 절대적으로 제한적으로 사용해야 하며, 대규모 사용자 관리를 root 계정으로 운영하는 것은 매우 위험하고 권장되지 않습니다.",
    "SelectC": "AWS IAM Identity Center(AWS Single Sign-On)을 구성합니다. IAM Identity Center를 기존 IdP에 연결하고, 사용자를 IdP에서 프로비저닝합니다.",
    "SelectC_Commentary": "IAM Identity Center는 외부 IdP와 연동하여 AWS 계정에 대한 중앙화된 인증과 권한 부여를 제공하기 때문에, 대규모 사용자 관리에 가장 적합한 솔루션입니다.",
    "SelectD": "AWS Resource Access Manager(AWS RAM)을 사용하여 기존 IdP 사용자들과 AWS 계정 접근 권한을 공유합니다.",
    "SelectD_Commentary": "AWS RAM은 리소스 공유 서비스이므로, 인증을 직접 관리하는 기능은 제공하지 않습니다. 외부 IdP와의 연동이나 대규모 사용자 인증을 해결하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q826",
      "Q668",
      "Q28",
      "Q945",
      "Q688"
    ],
    "SelectA_recommedations": [
      "Q476",
      "Q222",
      "Q750"
    ],
    "SelectB_recommedations": [
      "Q233",
      "Q745",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q688",
      "Q668",
      "Q750"
    ],
    "SelectD_recommedations": [
      "Q981",
      "Q751",
      "Q222"
    ]
  },
  {
    "Question_Number": "Q751",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 AWS 계정에 대한 AWS Identity and Access Management (IAM) 권한 부여 모델을 설계하고 있습니다. 회사는 5명의 특정 직원을 지정하여 AWS 계정의 AWS 서비스 및 리소스에 대한 전체 액세스 권한을 부여했습니다. 솔루션스 아키텍트는 5명의 지정된 직원 각각에 대해 IAM user를 생성하고 IAM user group을 생성했습니다. 이 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133081-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "IAM user와 user group을 이용해 5명의 직원에게 전체 권한을 부여하는 문제이며, resource-based policy는 리소스 수준에서 적용되므로 맞지 않습니다. 모든 서비스 권한을 부여하려면 AdministratorAccess identity-based policy가 필요합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "IAM 권한 부여 모델",
      "AdministratorAccess",
      "SystemAdministrator",
      "resource-based policy",
      "identity-based policy",
      "전체 액세스"
    ],
    "Terms": [
      "AWS Identity and Access Management (IAM)",
      "IAM user",
      "IAM user group",
      "AdministratorAccess policy",
      "SystemAdministrator policy",
      "identity-based policy",
      "resource-based policy"
    ],
    "SelectA": "AdministratorAccess resource-based policy를 IAM user group에 연결하고, 5명의 지정된 IAM 사용자를 user group에 추가합니다.",
    "SelectA_Commentary": "resource-based policy는 특정 리소스에만 직접 적용하므로 user group에는 부적합합니다.",
    "SelectB": "SystemAdministrator identity-based policy를 IAM user group에 연결하고, 5명의 지정된 IAM 사용자를 user group에 추가합니다.",
    "SelectB_Commentary": "SystemAdministrator policy는 일부 서비스에만 권한을 허용하여 전체 서비스 접근 요구 사항을 충족하지 못합니다.",
    "SelectC": "AdministratorAccess identity-based policy를 IAM user group에 연결하고, 5명의 지정된 IAM 사용자를 user group에 추가합니다.",
    "SelectC_Commentary": "AdministratorAccess policy는 모든 AWS 서비스와 리소스에 대한 전체 권한을 제공하므로 요구 사항에 부합하는 정답입니다.",
    "SelectD": "SystemAdministrator resource-based policy를 IAM user group에 연결하고, 5명의 지정된 IAM 사용자를 user group에 추가합니다.",
    "SelectD_Commentary": "SystemAdministrator에 더해 resource-based policy 적용 역시 IAM user group에는 알맞지 않아 전체 액세스 요건을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q395",
      "Q222",
      "Q780",
      "Q476",
      "Q924"
    ],
    "SelectA_recommedations": [
      "Q423",
      "Q253",
      "Q751"
    ],
    "SelectB_recommedations": [
      "Q423",
      "Q253",
      "Q395"
    ],
    "SelectC_recommedations": [
      "Q423",
      "Q751",
      "Q253"
    ],
    "SelectD_recommedations": [
      "Q423",
      "Q253",
      "Q395"
    ]
  },
  {
    "Question_Number": "Q752",
    "Question_Description": "한 회사가 가상 머신(VMs)을 기반으로 하는 다중 계층 결제 처리 애플리케이션을 운영하고 있습니다. 이 계층 간의 통신은 정확히 한 번만 전달이 보장되는 서드 파티 미들웨어 솔루션을 통해 비동기적으로 이루어지고 있습니다. 회사는 인프라 관리가 최소화되는 솔루션을 원하며, 애플리케이션 메시징에 대해 정확히 한 번 전달이 보장되어야 합니다. 이러한 요구사항을 충족하는 조합으로 적절한 것은 무엇입니까? (2개를 고르시오)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133405-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 간 메시징에서 정확히 한 번의 전달을 보장하면서도, 인프라 관리를 최소화하는 방법을 찾는 것이 핵심입니다. Amazon SQS FIFO Queue는 메시지 중복을 방지하고 순서를 보장하며 정확히 한 번 전달이 가능합니다. 또한 서버리스 기반의 AWS Lambda를 사용하면 VM, 컨테이너 등 추가 인프라를 직접 관리할 필요가 없어 인프라 관리 부담을 크게 줄일 수 있습니다. 따라서 'AWS Lambda + Amazon SQS FIFO' 조합이 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "결제 처리 애플리케이션",
      "정확히 한 번 전달",
      "인프라 관리 최소화"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon EC2",
      "Amazon SNS",
      "Amazon SQS FIFO Queue",
      "Amazon EKS"
    ],
    "SelectA": "아키텍처의 컴퓨트 계층에 AWS Lambda를 사용합니다.",
    "SelectA_Commentary": "서버리스 방식으로 인프라를 직접 관리할 필요가 없어 관리 부담을 크게 줄여줍니다.",
    "SelectB": "아키텍처의 컴퓨트 계층에 Amazon EC2 인스턴스를 사용합니다.",
    "SelectB_Commentary": "EC2 인스턴스를 직접 운영·관리해야 하므로 인프라 관리가 증가합니다.",
    "SelectC": "계층 간 메시징 컴포넌트로 Amazon SNS를 사용합니다.",
    "SelectC_Commentary": "SNS는 주로 푸시 기반 서비스로, 정확히 한 번 전달을 보장하지 않으므로 요구사항을 충족하기 어렵습니다.",
    "SelectD": "계층 간 메시징 컴포넌트로 Amazon SQS FIFO Queue를 사용합니다.",
    "SelectD_Commentary": "FIFO Queue를 사용하면 메시지 중복 방지와 순서 보장, 정확히 한 번 전달을 지원하여 요구사항을 충족합니다.",
    "SelectE": "컴퓨트 계층에 Amazon Elastic Kubernetes Service(Amazon EKS) 기반 컨테이너를 사용합니다.",
    "SelectE_Commentary": "EKS 클러스터를 직접 구성·관리해야 하므로 인프라 관리 부담이 증가합니다.",
    "Question_Description_recommedations": [
      "Q149",
      "Q163",
      "Q967",
      "Q363",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q8",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectC_recommedations": [
      "Q615",
      "Q363",
      "Q187"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q194",
      "Q8"
    ],
    "SelectE_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q753",
    "Question_Description": "한 회사는 매일 SFTP를 통해 온프레미스 파일 시스템에 도착하는 보고서 파일을 분석하는 야간 배치 처리 루틴을 운영하고 있습니다. 회사는 이 솔루션을 AWS 클라우드로 이전하려고 합니다. 솔루션은 고가용성과 탄력성을 갖추어야 하며, 운영 부담을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132944-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 SFTP로 전송되는 파일을 빠르고 안정적으로 처리할 수 있는 방안을 묻습니다. AWS Transfer for SFTP와 Amazon EFS 조합은 EC2와 함께 손쉽게 확장되며, 고가용성과 탄력성을 제공하므로 운영 노력을 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "SFTP",
      "Amazon EFS",
      "야간 배치 처리",
      "고가용성",
      "탄력성",
      "운영 부담 최소화"
    ],
    "Terms": [
      "AWS Transfer for SFTP",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon Elastic Block Store (Amazon EBS)",
      "Amazon S3",
      "Scheduled Scaling"
    ],
    "SelectA": "AWS Transfer for SFTP와 Amazon EFS 파일 시스템을 배포합니다. Amazon EC2 인스턴스를 Auto Scaling 그룹과 스케줄링된 스케일링 정책으로 구성하여 배치 작업을 수행합니다.",
    "SelectA_Commentary": "AWS Transfer for SFTP로 바로 Amazon EFS에 파일을 수신하고, EC2가 필요한 시점에만 배치를 실행하도록 구성하여 고가용성과 탄력성을 확보하고 운영 부담을 최소화합니다.",
    "SelectB": "Amazon EC2 인스턴스에 Linux 및 SFTP 서비스를 설치합니다. Amazon EBS 볼륨을 스토리지로 사용하고, 최소 및 원하는 인스턴스 수를 1로 설정한 Auto Scaling 그룹을 구성합니다.",
    "SelectB_Commentary": "EBS 볼륨에 파일을 저장할 경우 다중 인스턴스 환경에서 확장성과 가용성 관리가 어려워집니다. 또한 한 대의 인스턴스에 의존하므로 장애 시 복원력이 낮습니다.",
    "SelectC": "Amazon EC2 인스턴스에 Linux 및 SFTP 서비스를 설치합니다. Amazon EFS 파일 시스템을 스토리지로 사용하고, 최소 및 원하는 인스턴스 수를 1로 설정한 Auto Scaling 그룹을 구성합니다.",
    "SelectC_Commentary": "EFS 사용은 가능하지만, EC2 인스턴스 자체에 SFTP 서버를 직접 구성해야 하므로 운영 부담이 증가합니다. AWS Transfer for SFTP를 사용하면 더 간단한 관리가 가능합니다.",
    "SelectD": "AWS Transfer for SFTP와 Amazon S3 버킷을 배포합니다. 애플리케이션을 수정하여 Amazon S3에서 배치 파일을 끌어와 EC2 인스턴스에서 처리하도록 합니다. 스케줄링된 스케일링 정책이 적용된 EC2 인스턴스를 사용합니다.",
    "SelectD_Commentary": "S3로 전송 후 EC2가 가져가도록 애플리케이션을 수정해야 하므로 추가 개발 및 운영 부담이 큽니다. EFS를 사용하면 파일을 EC2에서 직접 액세스할 수 있어 훨씬 단순합니다.",
    "Question_Description_recommedations": [
      "Q188",
      "Q784",
      "Q802",
      "Q1014",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q102",
      "Q944",
      "Q842"
    ],
    "SelectB_recommedations": [
      "Q102",
      "Q837",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q102",
      "Q842",
      "Q753"
    ],
    "SelectD_recommedations": [
      "Q188",
      "Q753",
      "Q102"
    ]
  },
  {
    "Question_Number": "Q754",
    "Question_Description": "한 회사가 여러 AWS Region의 Amazon EC2 인스턴스에 배포된 HTTP 기반 애플리케이션을 전 세계 사용자들에게 제공하고 있습니다. 회사는 애플리케이션의 가용성과 성능을 개선하고자 하며, 애플리케이션의 가용성이나 보안을 해치거나 과도한 리소스를 소모할 수 있는 일반적인 웹 공격에서 애플리케이션을 보호하기 원합니다. 또한 정적 IP 주소를 사용해야 합니다. 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132945-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계적으로 배포된 HTTP 애플리케이션에 대해 가용성과 성능을 높이면서, 웹 공격 방지를 위해 WAF를 적용하고, 정적 IP 주소를 만족시키는 올바른 로드 밸런싱 및 글로벌 접근 방식을 찾는 것입니다. HTTP 프로토콜 처리와 웹 계층 보호를 위해 ALB 및 WAF가 필요하며, 정적 IP 주소는 AWS Global Accelerator를 통해 제공됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "HTTP 기반 애플리케이션",
      "전 세계 사용자",
      "가용성과 성능 개선",
      "AWS WAF",
      "정적 IP 주소",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Region",
      "HTTP 기반 애플리케이션",
      "Application Load Balancer(ALB)",
      "Network Load Balancer(NLB)",
      "AWS WAF",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon Route 53",
      "Latency-based routing"
    ],
    "SelectA": "각 Region의 EC2 인스턴스를 Network Load Balancer(NLB) 뒤에 배치합니다. NLB에 AWS WAF를 배포합니다. 그런 다음 AWS Global Accelerator로 가속기(Accelerator)를 생성하고 NLB들을 엔드포인트로 등록합니다.",
    "SelectA_Commentary": "NLB는 4계층에서 동작해 HTTP 기반 트래픽에 적합하지 않으며, 일반적으로 WAF는 ALB나 CloudFront 단에서 활용합니다. HTTP 처리 계층과 보안 제어에 제약이 생길 수 있습니다.",
    "SelectB": "각 Region의 EC2 인스턴스를 Application Load Balancer(ALB) 뒤에 배치합니다. ALB에 AWS WAF를 배포합니다. 그런 다음 AWS Global Accelerator로 가속기를 생성하고 ALB들을 엔드포인트로 등록합니다.",
    "SelectB_Commentary": "HTTP 기반 트래픽을 처리하기 위한 최적의 로드 밸런서(ALB)와 WAF를 결합하여 보안을 강화하고, Global Accelerator가 정적 IP를 제공해 전 세계 사용자에게 낮은 지연을 제공합니다. 정답입니다.",
    "SelectC": "각 Region의 EC2 인스턴스를 Network Load Balancer(NLB) 뒤에 배치합니다. NLB에 AWS WAF를 배포합니다. 그런 다음 Amazon CloudFront 배포를 생성하고, Amazon Route 53 지연 시간 기반 라우팅으로 NLB들을 연결하는 오리진을 구성합니다.",
    "SelectC_Commentary": "CloudFront와 지연 시간 기반 라우팅으로 글로벌 사용자 성능을 어느 정도 향상할 수 있으나, 정적 IP 주소 제공을 위해서는 Global Accelerator가 필요하며, HTTP 기반 애플리케이션에는 ALB가 적절합니다.",
    "SelectD": "각 Region의 EC2 인스턴스를 Application Load Balancer(ALB) 뒤에 배치합니다. Amazon Route 53 지연 시간 기반 라우팅을 사용하는 오리진으로 ALB를 지정한 Amazon CloudFront 배포를 생성합니다. AWS WAF를 CloudFront 배포에 배포합니다.",
    "SelectD_Commentary": "이 방식은 CloudFront가 전 세계 캐싱과 보안을 제공할 수 있으나, 정적 IP 주소가 반드시 필요한 요구사항을 충족하기 위해서는 Global Accelerator를 활용해야 합니다.",
    "Question_Description_recommedations": [
      "Q20",
      "Q976",
      "Q686",
      "Q818",
      "Q474"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q358",
      "Q530"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q272",
      "Q266"
    ],
    "SelectC_recommedations": [
      "Q815",
      "Q530",
      "Q358"
    ],
    "SelectD_recommedations": [
      "Q12",
      "Q358",
      "Q692"
    ]
  },
  {
    "Question_Number": "Q755",
    "Question_Description": "회사의 데이터 플랫폼은 Amazon Aurora MySQL DB를 사용 중이며, 여러 Availability Zone에 걸쳐 여러 read replica와 DB 인스턴스를 운영하고 있습니다. 최근 사용자들이 데이터베이스의 'too many connections' 에러를 보고하고 있으며, 또한 read replica가 primary writer로 승격될 때의 failover 시간을 20% 단축하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132946-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Aurora MySQL 환경에서 많은 연결 오류('too many connections')와 failover 시간을 단축하고자 하는 상황을 해결하는 방법을 묻습니다. Amazon RDS Proxy를 사용하면 애플리케이션 측 연결을 풀링하고 공유할 수 있어 연결 수를 효율적으로 관리할 수 있고, 장애 발생 시 connection preservation을 통해 failover 시간을 줄일 수 있습니다. 따라서 Aurora 환경을 그대로 유지하면서 요구사항을 충족시키기에 알맞은 해법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon Aurora MySQL",
      "read replica",
      "failover 시간",
      "too many connections",
      "Amazon RDS Proxy"
    ],
    "Terms": [
      "Amazon Aurora MySQL",
      "read replica",
      "Multi-AZ",
      "Amazon RDS Proxy",
      "Amazon DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Amazon Redshift",
      "failover",
      "connection pooling"
    ],
    "SelectA": "Amazon Aurora를 Amazon RDS의 Multi-AZ cluster 배포로 전환합니다.",
    "SelectA_Commentary": "Aurora 자체가 고가용성과 확장성을 제공하므로 굳이 RDS로 전환할 필요가 없습니다. 또한 Multi-AZ 구성만으로는 연결 수 과다 문제나 failover 시간 단축을 보장하기 어렵습니다.",
    "SelectB": "Amazon RDS Proxy를 Aurora DB 앞단에 배치합니다.",
    "SelectB_Commentary": "RDS Proxy는 연결 풀링과 애플리케이션 연결 유지 기능을 제공하여 failover 시간을 줄이고 'too many connections' 문제를 완화합니다. 따라서 요구사항을 모두 충족하는 정답입니다.",
    "SelectC": "Amazon DynamoDB로 전환하고 DynamoDB Accelerator(DAX)를 사용해 읽기 연결을 처리합니다.",
    "SelectC_Commentary": "DynamoDB는 NoSQL DB로, Aurora MySQL 기반의 관계형 DB 워크로드 구조와 크게 달라 마이그레이션 및 애플리케이션 변경이 매우 큽니다. failover 시간 단축 요구에도 직접적으로 부합하지 않습니다.",
    "SelectD": "Amazon Redshift로 전환하고 relocation 기능을 사용합니다.",
    "SelectD_Commentary": "Amazon Redshift는 주로 데이터 웨어하우징 및 분석용으로 적합하며, 트랜잭션 처리와 빠른 failover가 필요한 OLTP 시나리오에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q896",
      "Q527",
      "Q462",
      "Q955",
      "Q136"
    ],
    "SelectA_recommedations": [
      "Q601",
      "Q338",
      "Q466"
    ],
    "SelectB_recommedations": [
      "Q601",
      "Q518",
      "Q843"
    ],
    "SelectC_recommedations": [
      "Q78",
      "Q1002",
      "Q768"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q756",
    "Question_Description": "한 회사가 Amazon S3에 텍스트 파일을 저장하고 있습니다. 이 텍스트 파일에는 고객 채팅 메시지, 날짜 및 시간 정보, 그리고 고객 PII(개인 식별 정보)가 포함되어 있습니다. 회사는 외부 서비스 제공업체에게 품질 관리를 위해 대화 샘플을 제공해야 하며, 가장 최근 대화까지 무작위로 샘플을 선택하도록 해야 합니다. 하지만 회사는 고객 PII를 공유해서는 안 됩니다. 또한 고객 대화 수가 증가하더라도 확장 가능해야 하며, 운영 오버헤드가 최소여야 합니다. 이 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132947-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고객 PII를 제거하면서도 무작위로 대화 샘플을 제공해야 하는 보안 요구사항 관련입니다. Object Lambda Access Point를 사용하면 파일을 별도로 복제하거나 유지할 필요 없이, 요청 시점에 PII를 자동으로 제거하므로 운영 오버헤드가 최소화됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon S3",
      "고객 PII",
      "무작위 샘플",
      "운영 오버헤드 최소화",
      "확장성",
      "Object Lambda Access Point"
    ],
    "Terms": [
      "Amazon S3",
      "PII",
      "Object Lambda Access Point",
      "AWS Lambda function",
      "Amazon EC2",
      "Amazon DynamoDB",
      "Batch Process",
      "웹 애플리케이션",
      "Redaction"
    ],
    "SelectA": "Object Lambda Access Point를 생성합니다. 해당 Access Point에서 파일을 읽을 때 PII를 제거하도록 AWS Lambda function을 구성합니다. 외부 서비스 제공업체가 이 Object Lambda Access Point를 통해 파일에 접근하도록 합니다.",
    "SelectA_Commentary": "필요할 때마다 실시간으로 PII가 제거되므로 추가 스토리지나 배치 작업이 필요하지 않으며, 운영 오버헤드가 가장 적습니다.",
    "SelectB": "Amazon EC2 인스턴스에서 정기적으로 모든 신규 파일을 읽고, 해당 파일에서 PII를 제거한 뒤 다른 Amazon S3 버킷에 적재하는 배치 프로세스를 생성합니다. 외부 서비스 제공업체에는 PII가 없는 버킷에 접근하도록 지시합니다.",
    "SelectB_Commentary": "배치 작업으로 인해 추가 인프라 운영과 파일 복제가 필요하므로 오버헤드가 증가합니다.",
    "SelectC": "Amazon EC2 인스턴스에서 웹 애플리케이션을 생성합니다. 이 애플리케이션은 파일 목록을 제공하고, 파일에서 PII를 제거한 뒤, 외부 서비스 제공업체가 다운로드할 수 있도록 새 버전을 제공합니다.",
    "SelectC_Commentary": "직접 웹 애플리케이션을 구축하고 파일 처리를 해야 하므로 운영 관리가 복잡하며 오버헤드가 높습니다.",
    "SelectD": "Amazon DynamoDB 테이블을 생성합니다. 새 파일이 Amazon S3에 업로드될 때, PII가 아닌 데이터만 읽어 DynamoDB 테이블에 저장하도록 AWS Lambda function을 구성합니다. 외부 서비스 제공업체에는 DynamoDB 테이블에 대한 액세스를 부여합니다.",
    "SelectD_Commentary": "별도의 테이블 및 정규화 과정을 통해 데이터를 관리해야 하므로 구현과 유지가 복잡하며, 파일 전체 내용을 다루지 못할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q533",
      "Q106",
      "Q678",
      "Q154",
      "Q359"
    ],
    "SelectA_recommedations": [
      "Q791",
      "Q913",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q533",
      "Q838",
      "Q453"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q480",
      "Q100"
    ],
    "SelectD_recommedations": [
      "Q533",
      "Q727",
      "Q279"
    ]
  },
  {
    "Question_Number": "Q757",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 레거시 시스템을 운영하고 있습니다. 애플리케이션 코드는 수정할 수 없으며, 시스템은 하나 이상의 인스턴스에서 실행될 수 없습니다. 솔루션스 아키텍트는 이 시스템의 복구 시간을 개선할 수 있는 탄력적인 솔루션을 설계해야 합니다. 이러한 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 추천해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133082-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "단일 Amazon EC2 인스턴스에 대한 장애 복구 시간을 단축하려면, 인스턴스 상태 모니터링 후 자동으로 복구가 가능한 방안을 도입해야 합니다. Amazon CloudWatch alarm을 이용하면 장애 시 인스턴스를 자동 복구하여 빠른 복구 시간을 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "복구 시간 개선",
      "단일 인스턴스",
      "Amazon CloudWatch alarm"
    ],
    "Terms": [
      "Amazon EC2 instance",
      "termination protection",
      "Multi-AZ deployment",
      "Amazon CloudWatch alarm",
      "Amazon EBS volumes",
      "RAID configuration"
    ],
    "SelectA": "EC2 인스턴스에 대한 termination protection을 활성화합니다.",
    "SelectA_Commentary": "termination protection은 인스턴스가 실수로 삭제되는 것을 방지하는 기능으로, 실제 복구 시간을 개선하지 못합니다.",
    "SelectB": "EC2 인스턴스를 Multi-AZ 배포로 구성합니다.",
    "SelectB_Commentary": "Multi-AZ 배포는 여러 인스턴스를 필요로 하지만, 문제의 조건상 인스턴스를 하나만 사용할 수 있으므로 적용할 수 없습니다.",
    "SelectC": "장애 발생 시 EC2 인스턴스를 복구하기 위해 Amazon CloudWatch alarm을 생성합니다.",
    "SelectC_Commentary": "CloudWatch alarm에서 인스턴스 상태를 모니터링하고 자동으로 복구할 수 있어, 복구 시간을 단축하는 가장 적절한 솔루션입니다.",
    "SelectD": "스토리지 중복성을 위해 두 개의 Amazon EBS 볼륨을 RAID 구성으로 사용하여 EC2 인스턴스를 실행합니다.",
    "SelectD_Commentary": "RAID 구성은 스토리지 장애에 대한 내결함성을 높이지만, 인스턴스 자체의 복구 시간을 직접적으로 개선하지 못합니다.",
    "Question_Description_recommedations": [
      "Q244",
      "Q584",
      "Q252",
      "Q413",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q584",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q244",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q602",
      "Q584",
      "Q195"
    ]
  },
  {
    "Question_Number": "Q758",
    "Question_Description": "한 회사가 세 개의 Availability Zone에 걸쳐 있는 VPC에 컨테이너화된 애플리케이션 워크로드를 배포하려고 합니다. 회사는 Availability Zone 간에 고가용성이 필요하며, 애플리케이션 수정은 최소화해야 합니다. 이러한 요구사항을 만족하면서 운영 오버헤드를 최소화할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132948-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 세 Availability Zone에 걸친 컨테이너 애플리케이션을 간편하고 안정적으로 운영하려는 시나리오입니다. Amazon ECS를 활용하면 Kubernetes 구성 등 추가 작업이 줄어 애플리케이션 변경과 운영 부담이 최소화됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "컨테이너화된 애플리케이션",
      "고가용성",
      "운영 오버헤드 최소화",
      "세 개의 Availability Zone",
      "VPC"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon ECS Service Auto Scaling",
      "Target Tracking Scaling",
      "Task Placement Strategy",
      "Availability Zone",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Self-managed Nodes",
      "Application Auto Scaling",
      "Amazon EC2 Reserved Instances",
      "Spread Placement Group",
      "AWS Lambda",
      "VPC"
    ],
    "SelectA": "Amazon ECS를 사용합니다. Amazon ECS Service Auto Scaling을 Target Tracking Scaling으로 구성합니다. 최소 용량을 3으로 설정하고 Task Placement Strategy를 Availability Zone으로 Spread하도록 설정합니다.",
    "SelectA_Commentary": "ECS는 EC2 노드 설정이 간단하며, 애플리케이션 수정 없이도 고가용성을 확보할 수 있어 운영 오버헤드가 가장 적은 해법입니다.",
    "SelectB": "Amazon EKS Self-managed Nodes를 사용합니다. Application Auto Scaling을 Target Tracking Scaling으로 구성합니다. 최소 용량을 3으로 설정합니다.",
    "SelectB_Commentary": "Self-managed Nodes는 Kubernetes 구성, 노드 보안 관리 등이 추가로 필요해 운영이 복잡합니다.",
    "SelectC": "Amazon EC2 Reserved Instances를 사용합니다. 세 개의 EC2 인스턴스를 Spread Placement Group에 배포합니다. Auto Scaling 그룹을 Target Tracking Scaling으로 구성하고 최소 용량을 3으로 설정합니다.",
    "SelectC_Commentary": "EC2 인스턴스 개별 관리와 Reservation 사용으로 유연성이 떨어지고, 컨테이너 기반 환경처럼 자동화된 배포와 관리가 어렵습니다.",
    "SelectD": "AWS Lambda 함수를 사용합니다. Lambda 함수를 VPC에 연결합니다. Application Auto Scaling으로 Lambda를 확장 가능한 대상으로 설정하고 최소 용량을 3으로 설정합니다.",
    "SelectD_Commentary": "Lambda는 짧은 함수 실행에 적합하며, 컨테이너 애플리케이션 전환 시 코드 수정 범위가 커지고 상태ful 미들웨어 구성에 제약이 큽니다.",
    "Question_Description_recommedations": [
      "Q729",
      "Q639",
      "Q691",
      "Q987",
      "Q504"
    ],
    "SelectA_recommedations": [
      "Q874",
      "Q210",
      "Q900"
    ],
    "SelectB_recommedations": [
      "Q724",
      "Q563",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q595",
      "Q581"
    ],
    "SelectD_recommedations": [
      "Q404",
      "Q785",
      "Q775"
    ]
  },
  {
    "Question_Number": "Q759",
    "Question_Description": "한 미디어 회사가 영화를 Amazon S3에 저장하고 있습니다. 각 영화는 1GB부터 10GB 범위의 단일 비디오 파일로 저장됩니다. 이 회사는 사용자가 영화를 구매하면 5분 이내에 스트리밍 콘텐츠를 제공할 수 있어야 합니다. 20년 미만 된 영화가 20년 이상 된 영화보다 수요가 더 높습니다. 회사는 수요에 따라 호스팅 서비스 비용을 최소화하고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132949-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 영화 파일을 S3의 적절한 스토리지 클래스로 저장해 비용을 절감하면서, 구매 후 5분 이내에 스트리밍 가능하도록 하는 방법을 묻습니다. 1GB~10GB의 파일을 빠르게 접근해야 하므로 S3 Glacier 계열처럼 복원 시간이 오래 걸리는 옵션은 적합하지 않습니다. S3 Standard나 S3 Standard-IA는 즉시 또는 매우 빠르게 데이터를 제공할 수 있으므로 5분 내 스트리밍 요구를 충족시킬 수 있습니다. 따라서 오래된 영화는 수요가 낮을 때 S3 Standard-IA로 비용을 절감하고, 필요 시 표준 액세스로 곧바로 스트리밍할 수 있는 B가 정답입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "비디오 파일",
      "5분 이내 스트리밍",
      "20년 기준",
      "비용 최적화"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Lifecycle policy",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Intelligent-Tiering",
      "S3 Glacier Flexible Retrieval",
      "Expedited retrieval",
      "Bulk retrieval",
      "Standard retrieval"
    ],
    "SelectA": "모든 미디어 콘텐츠를 Amazon S3에 저장하고, 수요가 감소하면 S3 Lifecycle policy를 사용해 Infrequent Access tier로 이동합니다.",
    "SelectA_Commentary": "수요 감소 시점에 자동 이동은 가능하지만, 구체적으로 오랜 기간이 지난 영화가 거의 접근되지 않더라도 IA로만 이동하면 추가적인 클래스 세분화 없이 비용 최적화 폭이 제한됩니다.",
    "SelectB": "새로운 영화 비디오 파일은 S3 Standard에 저장하고, 오래된 영화 비디오 파일은 S3 Standard-Infrequent Access (S3 Standard-IA)에 저장합니다. 사용자가 오래된 영화를 주문할 때 Standard retrieval을 사용해 비디오 파일을 가져옵니다.",
    "SelectB_Commentary": "S3 Standard와 S3 Standard-IA는 밀리초~초 단위 응답이 가능해 5분 내 스트리밍을 보장하며, 수요가 낮은 파일에 대한 비용도 절감할 수 있는 최적의 솔루션입니다. (정답)",
    "SelectC": "새로운 영화 비디오 파일은 S3 Intelligent-Tiering에 저장하고, 오래된 영화 비디오 파일은 S3 Glacier Flexible Retrieval에 저장합니다. 사용자가 오래된 영화를 주문할 때 expedited retrieval을 사용해 비디오 파일을 가져옵니다.",
    "SelectC_Commentary": "Expedited retrieval이 1~5분 내 복원을 목표로 하지만, 파일이 250MB 이상이면 속도 보장이 어려워 1GB~10GB 대용량에서는 5분 내 스트리밍이 확실치 않습니다.",
    "SelectD": "새로운 영화 비디오 파일은 S3 Standard에 저장하고, 오래된 영화 비디오 파일은 S3 Glacier Flexible Retrieval에 저장합니다. 사용자가 오래된 영화를 주문할 때 bulk retrieval을 사용해 비디오 파일을 가져옵니다.",
    "SelectD_Commentary": "Bulk retrieval은 복원에 수 시간 이상 걸릴 수 있어 5분 내 스트리밍 요구를 충족시키지 못하므로 부적합한 방식입니다.",
    "Question_Description_recommedations": [
      "Q285",
      "Q66",
      "Q606",
      "Q911",
      "Q890"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q911",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q356",
      "Q415",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q486",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q126",
      "Q356"
    ]
  },
  {
    "Question_Number": "Q760",
    "Question_Description": "솔루션스 아키텍트는 벤더가 Docker container 이미지로 제공하는 애플리케이션을 위한 아키텍처를 설계해야 합니다. 이 컨테이너에는 임시 파일을 위한 50GB의 스토리지가 필요하며, 인프라는 serverless여야 합니다. 이러한 요구사항을 최소한의 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132950-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 50GB 이상의 임시 스토리지가 필요한 컨테이너 환경을 serverless 방식으로 구현하는 방안을 묻습니다. AWS Lambda는 임시 스토리지 용량 제한과 장기 구동에 제약이 있으므로 적합하지 않으며, Amazon EC2 기반 ECS는 serverless가 아니어서 운영 오버헤드가 큽니다. 반면 Amazon ECS Fargate는 서버 관리를 하지 않으면서 EFS를 마운트하여 50GB 이상의 공간을 확보할 수 있어 최적의 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "serverless",
      "Docker container",
      "50GB 임시 스토리지",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon EFS"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "Amazon Elastic Block Store (Amazon EBS)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "Amazon Elastic File System (Amazon EFS)",
      "Docker container image"
    ],
    "SelectA": "AWS Lambda 함수에서 Docker container 이미지를 사용하고 Amazon S3 볼륨을 50GB 이상 마운트합니다.",
    "SelectA_Commentary": "Lambda는 제한된 임시 스토리지로 운영하기 어렵고, S3를 직접 볼륨으로 사용하는 방식도 일반적이지 않아 부적합합니다.",
    "SelectB": "AWS Lambda 함수에서 Docker container 이미지를 사용하고 Amazon EBS 볼륨을 50GB 이상 마운트합니다.",
    "SelectB_Commentary": "Lambda는 EBS 직접 마운트가 불가능하며, 대규모 스토리지를 포함한 장기 컨테이너 구동에 적합하지 않습니다.",
    "SelectC": "AWS Fargate 실행 유형을 사용하는 Amazon ECS 클러스터를 생성하고, Amazon EFS 볼륨을 사용하는 컨테이너 이미지 태스크 정의를 만든 뒤 서비스로 배포합니다.",
    "SelectC_Commentary": "ECS Fargate로 serverless 환경에서 EFS를 통해 50GB 이상의 파일 스토리지를 제공하며 운영 부담이 최소화됩니다.",
    "SelectD": "Amazon EC2 실행 유형을 사용하는 Amazon ECS 클러스터를 생성하고, 50GB 이상의 Amazon EBS 볼륨을 사용하는 컨테이너 이미지 태스크 정의로 서비스를 배포합니다.",
    "SelectD_Commentary": "EC2 기반은 서버 관리를 직접 해야 하므로 serverless 요건을 충족하지 못하며 운영 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q699",
      "Q52",
      "Q351",
      "Q772",
      "Q252"
    ],
    "SelectA_recommedations": [
      "Q760",
      "Q404",
      "Q18"
    ],
    "SelectB_recommedations": [
      "Q760",
      "Q775",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q698",
      "Q303",
      "Q842"
    ],
    "SelectD_recommedations": [
      "Q837",
      "Q602",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q761",
    "Question_Description": "한 회사가 사내 LDAP directory service를 사용하여 AWS Management Console에 대한 사용자 인증을 해야 합니다. 해당 directory service는 Security Assertion Markup Language(SAML)과 호환되지 않습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133326-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "LDAP과 직접 SAML 연동이 어려운 경우, on-premises 환경에서 LDAP 사용자 정보를 기반으로 AWS STS를 통해 일시적 자격 증명을 발급하는 브로커를 구현하면 보안 요구 사항을 충족하고 유연성을 확보할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "사내 LDAP directory service",
      "사용자 인증",
      "AWS Management Console",
      "SAML"
    ],
    "Terms": [
      "AWS Management Console",
      "IAM",
      "AWS IAM Identity Center(AWS Single Sign-On)",
      "SAML",
      "AWS STS(Security Token Service)",
      "LDAP directory service",
      "on-premises",
      "short-lived credentials",
      "IAM credentials"
    ],
    "SelectA": "AWS와 사내 LDAP 간에 AWS IAM Identity Center(AWS Single Sign-On)를 활성화합니다.",
    "SelectA_Commentary": "AWS IAM Identity Center는 SAML 기반 또는 특정 디렉터리 통합을 요구해 LDAP 직접 연동이 어렵습니다.",
    "SelectB": "AWS 자격 증명을 사용하는 IAM 정책을 생성하고, 이 정책을 LDAP에 통합합니다.",
    "SelectB_Commentary": "IAM 정책만으로 LDAP 사용자를 직접 인증할 수 없으며, 보안 토큰 발급 과정이 필요합니다.",
    "SelectC": "LDAP 자격 증명이 업데이트될 때마다 IAM 자격 증명을 회전하는 프로세스를 설정합니다.",
    "SelectC_Commentary": "자격 증명 동기화만으로는 LDAP 사용자를 실시간으로 인증할 수 없고 운영 복잡도가 증가합니다.",
    "SelectD": "사내에 커스텀 identity broker 애플리케이션 또는 프로세스를 개발하여, AWS STS를 통해 일시적 자격 증명을 발급받도록 합니다.",
    "SelectD_Commentary": "SAML 미호환 LDAP 환경에서 사용자를 인증한 뒤 STS를 통해 AWS 접근 권한을 위임하는 가장 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q826",
      "Q28",
      "Q780",
      "Q750",
      "Q1018"
    ],
    "SelectA_recommedations": [
      "Q28",
      "Q761",
      "Q688"
    ],
    "SelectB_recommedations": [
      "Q222",
      "Q476",
      "Q780"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q222",
      "Q476",
      "Q750"
    ]
  },
  {
    "Question_Number": "Q762",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스를 시작하기 위해 여러 Amazon Machine Images(AMIs)를 AWS 계정에 저장하고 있습니다. 이 AMI들은 회사 운영에 필수적인 중요한 데이터와 구성 정보를 포함하고 있습니다. 회사는 실수로 삭제된 AMIs를 신속하고 효율적으로 복원할 수 있는 솔루션을 구현하고자 합니다. 이때 운영 오버헤드를 가장 적게 사용하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132951-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실수로 삭제된 AMI를 빠르고 간편하게 복원하기 위한 방법을 묻고 있습니다. Recycle Bin을 사용하면 별도의 리소스 구성 없이도 삭제된 AMI를 일정 기간 동안 복원할 수 있으며, 다른 계정 복사나 S3 업로드 대비 운영 오버헤드가 낮습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon Machine Images",
      "실수로 삭제된 AMIs",
      "빠른 복원",
      "운영 오버헤드 최소화",
      "Recycle Bin"
    ],
    "Terms": [
      "Amazon Machine Images (AMIs)",
      "Amazon EC2",
      "Recycle Bin",
      "Amazon EBS Snapshots",
      "Amazon S3",
      "Cross-Region Replication",
      "AWS 계정"
    ],
    "SelectA": "Amazon Elastic Block Store(Amazon EBS) 스냅샷을 생성하고 이를 별도의 AWS 계정에 저장합니다.",
    "SelectA_Commentary": "EBS 스냅샷을 주기적으로 만들고 별도 계정에 관리해야 하므로 시간이 많이 들고 운영이 복잡해집니다.",
    "SelectB": "주기적으로 모든 AMIs를 다른 AWS 계정으로 복사합니다.",
    "SelectB_Commentary": "AMI를 정기적으로 복사해 관리할 추가 작업이 필요하며, 여러 계정 간 운영 오버헤드가 큽니다.",
    "SelectC": "Recycle Bin에서 보존 규칙(retention rule)을 생성합니다.",
    "SelectC_Commentary": "정답입니다. Recycle Bin을 사용하면 삭제된 AMI를 지정된 기간 동안 자동 보존하고 필요한 경우 간편하게 복원할 수 있어 운영 오버헤드가 가장 적습니다.",
    "SelectD": "Cross-Region Replication이 적용된 Amazon S3 버킷에 AMI를 업로드합니다.",
    "SelectD_Commentary": "AMI를 S3로 업로드하고 CRR까지 설정해야 하므로 절차가 복잡하며, 비용 및 운영 부담이 증가합니다.",
    "Question_Description_recommedations": [
      "Q892",
      "Q963",
      "Q508",
      "Q790",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q602",
      "Q842",
      "Q312"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q293",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q362",
      "Q863",
      "Q133"
    ],
    "SelectD_recommedations": [
      "Q891",
      "Q241",
      "Q224"
    ]
  },
  {
    "Question_Number": "Q763",
    "Question_Description": "한 회사가 온프레미스에 보관 중인 150TB의 아카이브 이미지 데이터를 다음 달 내로 AWS Cloud로 옮겨야 합니다. 회사의 현재 네트워크 연결은 야간에만 최대 100Mbps 업로드를 허용합니다. 이 데이터를 마이그레이션 마감일에 맞추어 옮기면서 가장 비용 효율적인 메커니즘은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132952-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "야간에만 제한적으로 업로드가 가능하고 마이그레이션 기간이 정해진 상황에서, 여러 AWS Snowball 디바이스를 병렬로 활용하면 네트워크 병목과 전송 시간을 단축하며 비용 효율적으로 대량 데이터를 안전하게 옮길 수 있습니다. 온라인 전송(Transfer Acceleration 등)만으로는 150TB를 신속하게 처리하기 어려워 기한 내 마이그레이션을 보장하기 어렵습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "150TB",
      "마이그레이션",
      "온프레미스",
      "비용 효율",
      "AWS Snowball"
    ],
    "Terms": [
      "AWS Snowmobile",
      "AWS Snowball",
      "Amazon S3 Transfer Acceleration",
      "Amazon S3 VPC endpoint",
      "VPN"
    ],
    "SelectA": "AWS Snowmobile을 사용하여 데이터를 AWS로 배송합니다.",
    "SelectA_Commentary": "AWS Snowmobile은 엑사바이트 급 데이터 전송에 적합하며 규모가 너무 크고 비용이 높아 150TB 전송에는 과도한 솔루션입니다.",
    "SelectB": "여러 AWS Snowball 디바이스를 주문해 데이터를 AWS로 배송합니다.",
    "SelectB_Commentary": "병렬 전송으로 마감일 내 대량 데이터를 안전하게 옮길 수 있으며, 비용 측면에서도 가장 적합한 솔루션입니다.",
    "SelectC": "Amazon S3 Transfer Acceleration을 활성화하고 데이터를 안전하게 업로드합니다.",
    "SelectC_Commentary": "Transfer Acceleration은 전송 속도를 높여주지만, 150TB 대규모 데이터를 야간 100Mbps로 옮기기에는 시간이 부족할 수 있습니다.",
    "SelectD": "Amazon S3 VPC endpoint를 생성하고 VPN을 설정해 업로드합니다.",
    "SelectD_Commentary": "네트워크 보안과 전송 효율은 확보할 수 있으나, 인터넷 대역폭 제한으로 마감일을 맞추기 어려워집니다.",
    "Question_Description_recommedations": [
      "Q583",
      "Q778",
      "Q617",
      "Q525",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q300",
      "Q486",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q728",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q943",
      "Q486"
    ],
    "SelectD_recommedations": [
      "Q497",
      "Q471",
      "Q860"
    ]
  },
  {
    "Question_Number": "Q764",
    "Question_Description": "한 회사가 온프레미스에서 운영 중인 3티어 애플리케이션(웹 계층, 애플리케이션 계층은 타사 VM, 데이터베이스 계층은 MySQL)을 AWS로 마이그레이션하려고 합니다. 회사는 기존 아키텍처에서 가능한 한 적은 변경만을 적용하기 원하며, 데이터베이스 계층은 특정 시점(Point-in-Time)으로 복원할 수 있는 기능이 필요합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132954-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 MySQL 기반 3티어 애플리케이션을 AWS로 이전할 때, 아키텍처 변화와 운영 오버헤드를 최소화하면서 MySQL의 Point-in-Time 복원을 지원하는 방안을 묻습니다. 웹 계층은 외부 접근이 필요하므로 Public Subnet에, 애플리케이션 계층과 데이터베이스 계층은 보안을 위해 Private Subnet에 배치하는 전형적인 3티어 구성이 핵심입니다. RDS for MySQL은 MySQL 호환성과 함께 자동 백업, 포인트인타임 복원을 지원하므로 기존 환경을 거의 변경하지 않고 도입할 수 있어 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "3티어 애플리케이션",
      "온프레미스",
      "MySQL",
      "포인트인타임 복구",
      "최소 운영 오버헤드"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "Amazon Aurora MySQL",
      "Private Subnets",
      "Public Subnets",
      "Point-in-Time Recovery"
    ],
    "SelectA": "웹 계층과 애플리케이션 계층을 Private Subnet의 Amazon EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 Private Subnet의 Amazon RDS for MySQL로 마이그레이션합니다.",
    "SelectA_Commentary": "웹 계층이 Private Subnet에 있으면 외부 접근이 불편해지고 추가 설정(예: NAT, 로드 밸런서)으로 인해 운영 복잡도가 높아져 요구사항에 부합하지 않습니다.",
    "SelectB": "웹 계층을 Public Subnet의 Amazon EC2 인스턴스로, 애플리케이션 계층을 Private Subnet의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 Private Subnet의 Amazon Aurora MySQL로 마이그레이션합니다.",
    "SelectB_Commentary": "Aurora MySQL도 MySQL 호환성과 포인트인타임 복원을 제공하지만, 기존 MySQL에서의 전환 시 호환성 체크 등 추가 고려가 필요해 운영 부담이 생길 수 있습니다.",
    "SelectC": "웹 계층을 Public Subnet의 Amazon EC2 인스턴스로, 애플리케이션 계층을 Private Subnet의 EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 Private Subnet의 Amazon RDS for MySQL로 마이그레이션합니다.",
    "SelectC_Commentary": "기존 MySQL 환경과 가장 유사하며, 웹 계층을 Public Subnet에 두어 접근성을 확보하고 RDS for MySQL이 자동 백업과 포인트인타임 복구를 제공해 최소 변경과 운영 오버헤드로 요구사항을 충족합니다.",
    "SelectD": "웹 계층과 애플리케이션 계층을 Public Subnet의 Amazon EC2 인스턴스로 마이그레이션합니다. 데이터베이스 계층을 Public Subnet의 Amazon Aurora MySQL로 마이그레이션합니다.",
    "SelectD_Commentary": "데이터베이스를 Public Subnet에 배치하면 보안과 접근 제한이 어려워 관리 오버헤드가 커집니다. 또한 Aurora 마이그레이션 시 고려사항도 있어 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q236",
      "Q843",
      "Q720",
      "Q194",
      "Q683"
    ],
    "SelectA_recommedations": [
      "Q824",
      "Q944",
      "Q195"
    ],
    "SelectB_recommedations": [
      "Q824",
      "Q194",
      "Q708"
    ],
    "SelectC_recommedations": [
      "Q125",
      "Q824",
      "Q843"
    ],
    "SelectD_recommedations": [
      "Q824",
      "Q194",
      "Q879"
    ]
  },
  {
    "Question_Number": "Q765",
    "Question_Description": "개발 팀이 다른 회사와 협업하여 통합 제품을 만들고 있습니다. 다른 회사는 개발 팀 계정에 있는 Amazon Simple Queue Service(Amazon SQS) 큐에 접근해야 합니다. 해당 회사는 본인의 계정 권한을 양도하지 않고 큐를 폴링(poll)할 수 있길 원합니다. 솔루션스 아키텍트는 어떻게 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132956-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 외부 회사가 자신의 권한을 유지하면서 Amazon SQS queue를 폴링할 수 있도록 안전하고 적절한 권한 부여 방식을 찾는 것입니다. SQS access policy는 다른 계정에 세분화된 권한을 부여할 수 있는 가장 적합한 방법이며, 외부 계정에 IAM 권한을 변경하도록 요구하지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon SQS queue",
      "폴링",
      "Cross-account access",
      "SQS access policy"
    ],
    "Terms": [
      "Amazon Simple Queue Service (Amazon SQS)",
      "IAM policy",
      "SQS access policy",
      "Amazon SNS",
      "instance profile"
    ],
    "SelectA": "인스턴스 프로필(instance profile)을 생성하여 다른 회사가 SQS queue에 액세스할 수 있도록 합니다.",
    "SelectA_Commentary": "instance profile은 주로 EC2 인스턴스에 역할을 할당할 때 사용하므로, 외부 회사가 직접 SQS queue를 폴링하기에는 적절하지 않습니다.",
    "SelectB": "다른 회사가 SQS queue에 액세스할 수 있도록 IAM policy를 생성합니다.",
    "SelectB_Commentary": "IAM policy를 이용하려면 다른 회사 계정에 정책을 적용하거나 역할 교차 인증 등이 필요합니다. 외부 계정에 직접 세분화된 권한을 부여하기에는 적합하지 않습니다.",
    "SelectC": "다른 회사가 SQS queue에 액세스할 수 있도록 SQS access policy를 생성합니다.",
    "SelectC_Commentary": "SQS access policy를 사용하면 외부 계정에 대해 세분화된 접근 권한을 쉽게 설정할 수 있어, 다른 회사가 자신의 계정 권한을 변경할 필요 없이 안전하게 폴링할 수 있습니다.",
    "SelectD": "다른 회사가 SQS queue에 액세스할 수 있도록 Amazon SNS access policy를 생성합니다.",
    "SelectD_Commentary": "SNS access policy는 Amazon SNS 주제(Topic)에 대한 접근을 제어합니다. SQS queue에 대한 직접 권한 부여가 아니므로 요구사항을 충족시키지 못합니다.",
    "Question_Description_recommedations": [
      "Q364",
      "Q893",
      "Q965",
      "Q204",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q765",
      "Q893",
      "Q364"
    ],
    "SelectB_recommedations": [
      "Q765",
      "Q476",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q765",
      "Q965",
      "Q233"
    ],
    "SelectD_recommedations": [
      "Q765",
      "Q364",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q766",
    "Question_Description": "회사의 개발자들은 최신 버전의 Amazon Linux가 실행되는 회사의 Amazon EC2 인스턴스에 대해 SSH 접근을 위한 안전한 방식을 원합니다. 이 개발자들은 재택근무와 사내 오피스에서 근무합니다. 회사는 이 솔루션에 AWS 서비스를 활용하기를 원합니다. 해당 EC2 인스턴스들은 VPC의 프라이빗 서브넷에서 호스팅되고 있으며 퍼블릭 서브넷에 배포된 NAT 게이트웨이를 통해 인터넷에 액세스합니다. 가장 비용 효율적으로 이 요구사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132957-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SSH 접속을 안전하고 간편하게 제공해야 하는 상황에서 추가 인프라 비용까지 최소화하는 방안을 묻습니다. VPN이나 bastion host는 구성과 운영 비용이 증가하기 쉽습니다. 반면 Session Manager는 별도 키 관리나 서버가 필요 없고 IAM 권한만으로 안전하게 접속이 가능하므로 가장 비용 효율적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "SSH 접근",
      "Amazon EC2",
      "Amazon Linux",
      "원격 근무",
      "bastion host",
      "Session Manager",
      "VPC 프라이빗 서브넷",
      "NAT 게이트웨이",
      "비용 효율성"
    ],
    "Terms": [
      "SSH",
      "VPC",
      "NAT Gateway",
      "AWS Site-to-Site VPN",
      "bastion host",
      "AWS Systems Manager Session Manager",
      "AmazonSSMManagedInstanceCore IAM policy",
      "EC2 Instance Connect"
    ],
    "SelectA": "EC2 인스턴스와 동일한 서브넷에 bastion host를 생성하고, ec2:CreateVpnConnection IAM 권한을 개발자에게 부여한 후 EC2 Instance Connect를 설치합니다.",
    "SelectA_Commentary": "bastion host를 프라이빗 서브넷에 두고 VPN 권한까지 부여해야 하므로 관리가 복잡해집니다. 비용과 운영 측면에서 Session Manager보다 비효율적입니다.",
    "SelectB": "기업 네트워크와 VPC 간에 AWS Site-to-Site VPN 연결을 생성하고, 사내 근무 시에는 이 VPN을 사용해 EC2 인스턴스에 접속하도록 하며 원격 근무 시에는 별도의 VPN을 추가로 설정하도록 안내합니다.",
    "SelectB_Commentary": "사내와 원격 각각 다른 VPN 구성이 필요해 복잡도가 증가합니다. 추가 연결 비용과 구성 관리 부담이 커져서 권장되지 않습니다.",
    "SelectC": "VPC 퍼블릭 서브넷에 bastion host를 생성하고, 보안 그룹 및 SSH 키를 개발자들의 사내/원격 네트워크에서만 연결 가능하도록 설정한 뒤 SSH를 통해 bastion host를 거쳐 EC2 인스턴스에 접속하도록 안내합니다.",
    "SelectC_Commentary": "퍼블릭 서브넷에 bastion host를 두어 SSH를 중계할 수는 있지만, 인스턴스 비용과 설정 복잡도가 추가로 발생해 Session Manager에 비해 덜 효율적입니다.",
    "SelectD": "AmazonSSMManagedInstanceCore IAM 정책을 EC2 인스턴스에 연결된 IAM 역할에 부착하고, 개발자들에게 AWS Systems Manager Session Manager를 이용해 EC2 인스턴스에 접속하라고 안내합니다.",
    "SelectD_Commentary": "Session Manager를 사용하면 별도의 SSH 키나 bastion host가 필요 없으며, IAM 권한 기반으로 안전하고 비용 효율적으로 관리할 수 있으므로 최적의 해결책입니다.",
    "Question_Description_recommedations": [
      "Q319",
      "Q232",
      "Q218",
      "Q115",
      "Q697"
    ],
    "SelectA_recommedations": [
      "Q73",
      "Q96",
      "Q232"
    ],
    "SelectB_recommedations": [
      "Q782",
      "Q712",
      "Q866"
    ],
    "SelectC_recommedations": [
      "Q73",
      "Q232",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q517",
      "Q723",
      "Q96"
    ]
  },
  {
    "Question_Number": "Q767",
    "Question_Description": "한 제약 회사가 새로운 약을 개발하고 있습니다. 지난 몇 달 동안 생성되는 데이터의 양이 기하급수적으로 증가했습니다. 연구진은 전체 데이터셋 중 일부(subset)에 대해 최소 지연으로 즉시 액세스할 수 있어야 하지만, 전체 데이터셋을 매일 액세스할 필요는 없습니다. 현재 모든 데이터는 온프레미스 스토리지 어레이에 저장되어 있으며, 회사는 지속적인 자본 비용을 줄이길 원합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 어떤 스토리지 솔루션을 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132996-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Volume Gateway의 캐시 볼륨은 자주 쓰이는 데이터만 온프레미스에 캐싱하고 나머지를 Amazon S3에 저장해 운영 비용을 절감하면서도 필요한 데이터 subset에는 즉시 액세스를 제공합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "데이터셋",
      "기하급수적 증가",
      "subset 즉시 액세스",
      "온프레미스 스토리지",
      "자본 비용 절감"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "AWS Storage Gateway",
      "file gateway",
      "volume gateway",
      "cached volumes",
      "AWS Site-to-Site VPN",
      "Amazon EFS"
    ],
    "SelectA": "AWS DataSync를 cron 스케줄로 실행하여 데이터를 Amazon S3 버킷으로 지속적으로 마이그레이션합니다.",
    "SelectA_Commentary": "단순히 DataSync로 데이터만 옮길 경우, 사용 빈도가 높은 데이터subset에 대한 온프레미스 캐싱 기능이 없어 즉시 접근성 면에서 제한적입니다.",
    "SelectB": "AWS Storage Gateway file gateway를 배포하고 대상 스토리지를 Amazon S3 버킷으로 설정합니다. 데이터를 Storage Gateway 어플라이언스로 마이그레이션합니다.",
    "SelectB_Commentary": "file gateway는 SMB나 NFS 파일 인터페이스를 제공하지만, 캐시된 볼륨 수준의 접근성보다는 파일 단위 접근에 중점을 두어 요구 사항에 최적화되진 않습니다.",
    "SelectC": "AWS Storage Gateway volume gateway(캐시드 볼륨 모드)를 배포하고 대상 스토리지를 Amazon S3 버킷으로 설정합니다. 데이터를 Storage Gateway 어플라이언스로 마이그레이션합니다.",
    "SelectC_Commentary": "자주 액세스되는 데이터는 온프레미스 캐시에 저장되고, 나머지는 Amazon S3에 저장되어 자본 비용을 절감하면서도 최소 지연 접근이 가능합니다.",
    "SelectD": "온프레미스 환경에서 AWS로의 AWS Site-to-Site VPN 연결을 구성하고, Amazon EFS 파일 시스템으로 데이터를 마이그레이션합니다.",
    "SelectD_Commentary": "EFS는 여러 EC2 인스턴스에서 공유가 가능하지만, 캐시 기능이 부족해 자주 요구되는 온프레미스 데이터 접근에 대한 지연이 발생할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q49",
      "Q656",
      "Q794",
      "Q997",
      "Q630"
    ],
    "SelectA_recommedations": [
      "Q918",
      "Q769",
      "Q829"
    ],
    "SelectB_recommedations": [
      "Q497",
      "Q23",
      "Q415"
    ],
    "SelectC_recommedations": [
      "Q497",
      "Q346",
      "Q471"
    ],
    "SelectD_recommedations": [
      "Q822",
      "Q719",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q768",
    "Question_Description": "한 회사가 비즈니스 핵심 애플리케이션을 Amazon EC2 인스턴스에서 구동 중이며, 해당 애플리케이션은 데이터를 Amazon DynamoDB 테이블에 저장합니다. 이 회사는 지난 24시간 내 원하는 시점으로 테이블을 복원할 수 있어야 합니다. 이러한 요구 사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132960-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon DynamoDB 테이블의 백업 및 복구를 다루며, 매우 중요한 데이터를 지난 24시간 내 아무 시점으로 빠르고 간단하게 되돌려야 한다는 점이 핵심입니다. point-in-time recovery 기능은 자동화된 방식으로 최소한의 운영 오버헤드로 해당 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "비즈니스 핵심 애플리케이션",
      "Amazon DynamoDB 테이블",
      "24시간 내 시점 복원",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon DynamoDB",
      "Point-in-time recovery",
      "AWS Backup",
      "AWS Lambda",
      "Amazon S3",
      "DynamoDB Streams"
    ],
    "SelectA": "테이블에 대해 point-in-time recovery를 구성합니다.",
    "SelectA_Commentary": "point-in-time recovery를 활성화하면 지난 24시간 내 특정 시점으로 테이블을 복원할 수 있어 운영 부담이 가장 적고 요구사항을 만족합니다.",
    "SelectB": "테이블에 대해 AWS Backup을 사용합니다.",
    "SelectB_Commentary": "AWS Backup을 통해 백업 자동화가 가능하지만, 충분히 세밀한 시점 복원보다는 스케줄 기반 백업에 초점이 있어 매 시점 복원은 어렵습니다.",
    "SelectC": "AWS Lambda 함수를 사용하여 테이블을 매시간 온디맨드 백업합니다.",
    "SelectC_Commentary": "매시간 함수로 백업을 수행하면 시점 간격이 커지고 Lambda 스케줄 관리가 필요해 운영 부담이 증가합니다.",
    "SelectD": "테이블에서 streams를 활성화하고 지난 24시간 변경 로그를 Amazon S3에 저장합니다.",
    "SelectD_Commentary": "DynamoDB Streams를 통해 변경 사항을 추적할 수 있지만, 원하는 시점으로 테이블 전체를 복원하기 위해서는 추가 구현과 관리가 필요해 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q114",
      "Q400",
      "Q194",
      "Q584",
      "Q1002"
    ],
    "SelectA_recommedations": [
      "Q764",
      "Q187",
      "Q362"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q293",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q8",
      "Q363"
    ],
    "SelectD_recommedations": [
      "Q784",
      "Q8",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q769",
    "Question_Description": "한 회사가 Amazon S3 버킷에 파일을 업로드하는 애플리케이션을 운영하고 있습니다. 업로드 파일은 5초 미만의 시간이 소요되는 메타데이터 추출 처리를 거칩니다. 파일 업로드 빈도는 시간당 몇 개에서부터 동시에 수백 개까지 다양합니다. 회사는 이 요구사항을 충족하면서도 비용 효율적인 아키텍처를 원합니다. 어떤 솔루션을 권장해야 할까요?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132997-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 업로드된 파일의 메타데이터를 빠르고 저렴하게 추출하기 위해 이벤트 기반 처리를 설계해야 합니다. S3 이벤트로 Lambda를 직접 호출하면 사용한 만큼만 비용이 청구되어, 동시 업로드에도 유연하게 대응하며 운영이 간단해집니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "S3 버킷",
      "파일 업로드",
      "메타데이터 추출",
      "비용 효율성",
      "동시 업로드"
    ],
    "Terms": [
      "AWS CloudTrail",
      "AWS AppSync",
      "Amazon Kinesis Data Streams",
      "Amazon Simple Notification Service (SNS)",
      "AWS Lambda function",
      "S3 event notification",
      "파일 업로드",
      "메타데이터 추출"
    ],
    "SelectA": "S3 API 호출을 AWS CloudTrail에 로그로 남기도록 설정하고, AWS AppSync를 사용하여 파일을 처리합니다.",
    "SelectA_Commentary": "CloudTrail은 주로 감사 및 로그 용도이고, AppSync는 GraphQL 기반 API 서비스이므로 파일 메타데이터 추출 업무와 직접적으로 맞지 않아 적합하지 않습니다.",
    "SelectB": "S3 버킷에서 객체 생성 이벤트를 감지하도록 설정하고, AWS Lambda function을 호출하여 파일을 처리합니다.",
    "SelectB_Commentary": "S3 이벤트 알림으로 Lambda function을 자동 호출해 파일 메타데이터를 추출할 수 있어 비용과 운영 복잡도를 모두 줄이는 최적 솔루션입니다.",
    "SelectC": "Amazon Kinesis Data Streams를 구성해 데이터를 전송하고 Amazon S3로 보낸 뒤, AWS Lambda function으로 파일을 처리하도록 합니다.",
    "SelectC_Commentary": "Kinesis는 실시간 스트리밍 분석에 적합하며, 단순 파일 처리만 진행하려면 오버엔지니어링으로 비용과 구성이 복잡해집니다.",
    "SelectD": "Amazon Simple Notification Service (SNS) 토픽을 이용해 S3에 업로드된 파일을 처리하고, 이를 AWS Lambda function과 연동시킵니다.",
    "SelectD_Commentary": "SNS를 통해 처리 흐름을 구성할 수 있지만, S3가 이벤트를 직접 Lambda에 전달할 수 있으므로 SNS를 추가하는 것은 불필요한 단계입니다.",
    "Question_Description_recommedations": [
      "Q1003",
      "Q469",
      "Q606",
      "Q911",
      "Q285"
    ],
    "SelectA_recommedations": [
      "Q534",
      "Q993",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q993",
      "Q469",
      "Q829"
    ],
    "SelectC_recommedations": [
      "Q993",
      "Q799",
      "Q373"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q829",
      "Q498"
    ]
  },
  {
    "Question_Number": "Q770",
    "Question_Description": "한 회사의 애플리케이션이 Amazon EC2 인스턴스에 배포되어 있으며, 이벤트 드리븐 아키텍처를 위해 AWS Lambda 함수를 사용합니다. 회사는 기능을 프로덕션에 배포하기 전에 다른 AWS account에서 새로운 기능을 테스트하기 위한 비프로덕션(development) 환경을 사용합니다. 프로덕션 인스턴스는 서로 다른 시간대의 고객으로 인해 상시로 사용되고, 비프로덕션 인스턴스는 주중 업무 시간에만 사용하며 주말에는 사용되지 않습니다. 회사는 AWS에서 애플리케이션을 운영하는 비용을 최대한 절감하고 싶어합니다. 가장 비용 효율적으로 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132998-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프로덕션 인스턴스처럼 항상 운용되는 워크로드와, 사용 시간이 제한적인 비프로덕션 인스턴스를 어떻게 비용 효율적으로 운영할지를 묻습니다. 프로덕션에는 할인률이 큰 Compute Savings Plans 같은 장기 할인 모델을, 비프로덕션에는 On-Demand Instances를 사용하면서 사용하지 않을 때는 종료해 비용을 줄이는 것이 핵심 전략입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "프로덕션 상시 활용",
      "비프로덕션 업무 시간 활용",
      "비용 최적화",
      "Compute Savings Plans",
      "On-Demand Instances"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "AWS account",
      "On-Demand Instances",
      "Reserved Instances",
      "Compute Savings Plans",
      "EC2 Instance Savings Plans",
      "Dedicated Hosts"
    ],
    "SelectA": "프로덕션 인스턴스에는 On-Demand Instances를 사용하고, 주말에만 Dedicated Hosts를 사용하여 비프로덕션 인스턴스를 운영합니다.",
    "SelectA_Commentary": "주말에만 Dedicated Hosts를 사용하는 것은 실제 사용 패턴과 맞지 않고, On-Demand 비용도 상시 부담되므로 최적의 해법이 아닙니다.",
    "SelectB": "프로덕션 인스턴스와 비프로덕션 인스턴스 모두 Reserved Instances를 사용합니다. 비사용 시 비프로덕션 인스턴스를 종료합니다.",
    "SelectB_Commentary": "Reserved Instances는 항상 인스턴스를 켜두는 경우에 적합하나, 비프로덕션의 실제 사용 시간 대비 비용 절감이 제한적입니다.",
    "SelectC": "프로덕션 인스턴스에는 Compute Savings Plans를 사용하고, 비프로덕션 인스턴스에는 On-Demand Instances를 사용합니다. 비사용 시 비프로덕션 인스턴스를 종료합니다.",
    "SelectC_Commentary": "항상 구동되는 프로덕션에는Compute Savings Plans를 적용해 비용을 절감하고, 사용량이 적은 비프로덕션에는 On-Demand Instances를 쓰면서 사용하지 않을 때는 종료해 비용을 최소화합니다. 가장 비용 효율적입니다.",
    "SelectD": "프로덕션 인스턴스에는 Dedicated Hosts를 사용하고, 비프로덕션 인스턴스에는 EC2 Instance Savings Plans를 사용합니다.",
    "SelectD_Commentary": "Dedicated Hosts는 라이선싱이나 호스트 제어가 필요한 경우에 적합하지만, 비용이 매우 높습니다. 일반적 요구사항에는 과도한 비용이 들기 때문에 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q140",
      "Q671",
      "Q238",
      "Q417",
      "Q882"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q300",
      "Q1008"
    ],
    "SelectB_recommedations": [
      "Q767",
      "Q49",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q885",
      "Q1013",
      "Q715"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q885",
      "Q300"
    ]
  },
  {
    "Question_Number": "Q771",
    "Question_Description": "한 회사에서 온프레미스 Oracle 관계형 데이터베이스에 데이터를 저장하고 있습니다. 해당 회사는 Amazon Aurora PostgreSQL에서 데이터를 분석하기 위해 이 데이터를 이용할 수 있어야 합니다. 회사는 AWS Site-to-Site VPN 연결을 통해 온프레미스 네트워크를 AWS와 연결하고 있습니다. 그리고 Aurora PostgreSQL로 마이그레이션하는 동안 원본 데이터베이스에서 발생하는 변경 사항을 캡처해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/132999-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Oracle DB의 스키마 변환과 동시에 변경 사항(트랜잭션 업데이트)을 실시간 또는 근접 실시간으로 복제하여 Aurora PostgreSQL로 전환하려는 요구사항이 핵심입니다. AWS Schema Conversion Tool로 호환 스키마를 생성하고, AWS DMS를 통해 전체 로드 및 변경 사항 복제를 수행하는 것이 가장 적합한 솔루션입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "온프레미스 Oracle",
      "Amazon Aurora PostgreSQL",
      "Site-to-Site VPN",
      "마이그레이션 중 변경 사항 캡처"
    ],
    "Terms": [
      "AWS Schema Conversion Tool (AWS SCT)",
      "AWS Database Migration Service (AWS DMS)",
      "Oracle",
      "Aurora PostgreSQL",
      "AWS DataSync",
      "Amazon S3",
      "aws_s3 extension",
      "AWS Snowball",
      "Full-load migration"
    ],
    "SelectA": "AWS Schema Conversion Tool (AWS SCT)을 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service (AWS DMS) full-load migration 태스크를 사용하여 데이터를 마이그레이션합니다.",
    "SelectA_Commentary": "전체 로드만 수행하므로 마이그레이션 도중 발생하는 변경 사항을 실시간으로 캡처하지 못합니다.",
    "SelectB": "AWS DataSync를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션합니다. Aurora PostgreSQL의 aws_s3 extension을 사용하여 S3의 데이터를 Aurora PostgreSQL로 가져옵니다.",
    "SelectB_Commentary": "S3로의 이관 후 가져오기는 일회성으로 진행되므로, 원본 DB의 변경 사항을 지속적으로 반영하기 어렵습니다.",
    "SelectC": "AWS Schema Conversion Tool (AWS SCT)을 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환합니다. AWS Database Migration Service (AWS DMS)를 사용하여 기존 데이터를 마이그레이션하고 이후 발생하는 변경 사항도 복제합니다.",
    "SelectC_Commentary": "스키마 변환 후 DMS로 전체 데이터 로드와 지속적인 변경 사항 복제를 동시에 처리할 수 있어 요구사항을 만족합니다.",
    "SelectD": "AWS Snowball 디바이스를 사용하여 데이터를 Amazon S3 버킷으로 이전합니다. Aurora PostgreSQL의 aws_s3 extension을 사용하여 S3의 데이터를 Aurora PostgreSQL로 가져옵니다.",
    "SelectD_Commentary": "Snowball은 물리적 디바이스를 통해 데이터를 이전하기 때문에, 변경 사항을 실시간으로 반영하기에는 부적합합니다.",
    "Question_Description_recommedations": [
      "Q235",
      "Q886",
      "Q175",
      "Q659",
      "Q64"
    ],
    "SelectA_recommedations": [
      "Q235",
      "Q886",
      "Q481"
    ],
    "SelectB_recommedations": [
      "Q381",
      "Q292",
      "Q38"
    ],
    "SelectC_recommedations": [
      "Q235",
      "Q886",
      "Q771"
    ],
    "SelectD_recommedations": [
      "Q381",
      "Q292",
      "Q834"
    ]
  },
  {
    "Question_Number": "Q772",
    "Question_Description": "한 회사가 Docker container로 애플리케이션을 빌드했고, 이를 AWS Cloud에서 실행해야 합니다. 회사는 애플리케이션을 호스팅하기 위해 managed service를 사용하고자 합니다. 각 container 서비스의 수요에 따라 적절히 확장(Scale in/out)되어야 하며, 추가적인 운영 상의 오버헤드나 인프라 관리는 없어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? (두 개를 선택하세요.)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133002-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Docker container 기반 애플리케이션을 AWS에서 손쉽게 관리하고 필요에 따라 자동 확장하기 위한 방안을 묻습니다. ECS 또는 EKS에서 Fargate를 사용하면 서버를 직접 관리하지 않아도 되며, 수요에 맞게 자동으로 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Docker 컨테이너",
      "managed service",
      "자동 확장",
      "AWS Fargate"
    ],
    "Terms": [
      "Docker",
      "AWS Fargate",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Amazon EC2 Worker Nodes",
      "AWS Lambda",
      "Amazon API Gateway"
    ],
    "SelectA": "Amazon Elastic Container Service(Amazon ECS)와 AWS Fargate를 사용합니다.",
    "SelectA_Commentary": "ECS에서 Fargate를 사용하면 클러스터 인프라를 직접 관리하지 않아도 되고, 필요한 만큼 자동으로 컨테이너를 확장할 수 있어 운영 부담이 거의 없습니다.",
    "SelectB": "Amazon Elastic Kubernetes Service(Amazon EKS)와 AWS Fargate를 사용합니다.",
    "SelectB_Commentary": "EKS와 Fargate를 결합하면 Kubernetes 워커 노드를 직접 관리할 필요가 없어지고, 컨테이너 수요에 따라 자동 확장이 가능해 관리 오버헤드를 최소화합니다.",
    "SelectC": "Amazon API Gateway를 프로비저닝하고, AWS Lambda와 연동해 컨테이너를 실행합니다.",
    "SelectC_Commentary": "API Gateway와 Lambda만으로 Docker 컨테이너를 직접 실행하는 것은 일반적인 패턴이 아니며, 지속적 컨테이너 워크로드에 적합하지 않습니다.",
    "SelectD": "Amazon Elastic Container Service(Amazon ECS)와 Amazon EC2 워커 노드를 사용합니다.",
    "SelectD_Commentary": "EC2 워커 노드를 사용하면 서버 인프라를 직접 프로비저닝하고 클러스터를 관리해야 하므로 운영 및 관리 오버헤드가 발생합니다.",
    "SelectE": "Amazon Elastic Kubernetes Service(Amazon EKS)와 Amazon EC2 워커 노드를 사용합니다.",
    "SelectE_Commentary": "EKS에서 EC2 워커 노드를 구성하는 경우에도 노드 프로비저닝 및 관리를 직접 해야 하므로 추가적인 관리 부담이 생깁니다.",
    "Question_Description_recommedations": [
      "Q351",
      "Q900",
      "Q1010",
      "Q699",
      "Q209"
    ],
    "SelectA_recommedations": [
      "Q900",
      "Q698",
      "Q303"
    ],
    "SelectB_recommedations": [
      "Q698",
      "Q563",
      "Q775"
    ],
    "SelectC_recommedations": [
      "Q10",
      "Q354",
      "Q207"
    ],
    "SelectD_recommedations": [
      "Q900",
      "Q194",
      "Q892"
    ],
    "SelectE_recommedations": [
      "Q563",
      "Q996",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q773",
    "Question_Description": "한 전자상거래 회사가 계절별 온라인 세일을 진행하고 있습니다. 이 회사는 여러 Availability Zone에 걸쳐 Amazon EC2 인스턴스에서 웹사이트를 호스팅하고 있습니다. 회사는 세일 기간 중 급격한 트래픽 증가를 웹사이트가 감당할 수 있도록 하길 원합니다. 가장 비용 효율적으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133004-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 짧은 기간에 트래픽이 급상승하는 상황에서, 최소의 비용으로 탄력적인 확장을 구현하는 방법을 묻습니다. 트래픽 증가 시점에 맞춰 Auto Scaling group이 필요 시 새로운 인스턴스를 자동으로 추가하고, 사용하지 않을 때는 줄여서 비용을 절감합니다. 사전에 구성된 AMI를 사용하면 인스턴스 구동 시간을 단축하고 확장 속도를 높일 수 있어 가장 비용 효율적인 해결책이 됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 효율적",
      "계절별 온라인 세일",
      "급격한 트래픽 증가",
      "Auto Scaling group",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Auto Scaling group",
      "Amazon Machine Image (AMI)",
      "Amazon CloudFront",
      "Amazon ElastiCache"
    ],
    "SelectA": "Auto Scaling group을 충분히 큰 사이즈로 구성한 뒤, Amazon EC2 인스턴스의 절반을 중지시킵니다. 트래픽이 증가하면 중지된 인스턴스를 다시 시작해 확장하도록 설정합니다.",
    "SelectA_Commentary": "중지된 인스턴스도 EBS 비용이 발생하고, 초과 용량을 유지해야 하므로 비용 효율성이 떨어집니다.",
    "SelectB": "웹사이트용 Auto Scaling group을 생성하고, 확장 없이도 높은 트래픽을 처리할 수 있도록 그룹의 최소 크기를 크게 설정합니다.",
    "SelectB_Commentary": "항상 최대 규모로 인스턴스를 가동하므로, 트래픽이 많지 않은 시간에도 불필요한 비용이 발생합니다.",
    "SelectC": "Amazon CloudFront와 Amazon ElastiCache를 사용해 Auto Scaling group을 오리진으로 하여 동적 콘텐츠를 캐싱합니다. 캐시가 모두 채워진 후에는 인스턴스 규모를 축소합니다.",
    "SelectC_Commentary": "캐싱 설정이 유용하긴 하지만, 동적 콘텐츠 캐싱은 구현이 복잡하고 모든 상황에서 비용 절감 효과가 크지 않을 수 있습니다.",
    "SelectD": "트래픽 증가 시 자동으로 확장(Scale out)하도록 Auto Scaling group을 구성합니다. 사전에 구성된 Amazon Machine Image (AMI)를 사용하는 Launch Template을 만들어 새 인스턴스를 빠르게 시작합니다.",
    "SelectD_Commentary": "필요할 때만 인스턴스를 늘리고, 사전 구성된 AMI를 사용해 빠르게 확장하므로 가장 비용 효과적입니다.",
    "Question_Description_recommedations": [
      "Q238",
      "Q671",
      "Q347",
      "Q118",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q290",
      "Q937",
      "Q505"
    ],
    "SelectB_recommedations": [
      "Q290",
      "Q485",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q290",
      "Q937",
      "Q822"
    ],
    "SelectD_recommedations": [
      "Q245",
      "Q290",
      "Q822"
    ]
  },
  {
    "Question_Number": "Q774",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 컴플라이언스 정책을 자동화해야 합니다. 해당 정책은 security group에 0.0.0.0/0에서의 SSH 기반 접근을 허용하는 규칙을 둘 수 없다고 명시합니다. 회사는 해당 정책을 위반하는 상황이 발생하면 즉시 알림을 받아야 하며, 가능한 한 신속하고 운영 오버헤드가 적은 해결책이 필요합니다. 어떤 솔루션이 이러한 요구사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133006-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 security group에서 0.0.0.0/0로의 SSH 허용을 방지하고, 이를 모니터링하여 위반 시 즉시 알림을 보내는 방법을 찾는 것입니다. 운영 오버헤드를 최소화하려면 AWS에서 제공하는 자동화된 규칙과 알림 기능을 사용하는 것이 가장 효율적입니다. 특히 AWS Config의 restricted-ssh managed rule을 활성화해둔 상태에서 비준수 규칙이 감지되면 Amazon SNS로 알림을 받는 구조가 자동화와 유지보수 측면에서 유리합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "security group",
      "SSH 0.0.0.0/0 차단",
      "컴플라이언스 모니터링",
      "알림 자동화"
    ],
    "Terms": [
      "security group",
      "AWS Lambda",
      "AWS Config",
      "restricted-ssh AWS Config managed rule",
      "Amazon Simple Notification Service (Amazon SNS)",
      "IAM role",
      "service control policy (SCP)",
      "network ACL"
    ],
    "SelectA": "security group에서 0.0.0.0/0로 SSH가 열려 있는지 모니터링하는 AWS Lambda 스크립트를 작성하고, 발견 시마다 알림을 생성합니다.",
    "SelectA_Commentary": "직접 Lambda를 개발·운영해야 하므로 추가 관리 부담이 있고 실시간 모니터링도 직접 구현해야 합니다.",
    "SelectB": "restricted-ssh AWS Config managed rule을 활성화하고, 비준수 규칙이 생성되면 Amazon SNS 알림을 발생시킵니다.",
    "SelectB_Commentary": "AWS Config 내장 규칙 사용으로 설정이 간단하며 자동 모니터링과 알림이 가능해 운영 오버헤드가 가장 적습니다.",
    "SelectC": "security group과 network ACL을 전역적으로 오픈할 수 있는 IAM role을 생성하고, 해당 role이 사용될 때마다 Amazon SNS로 알림을 생성합니다.",
    "SelectC_Commentary": "role 사용 시점에만 알림이 발생하므로 보안 그룹 규칙 자체 변경 모니터링에 한계가 있으며, 권한 관리도 복잡합니다.",
    "SelectD": "비관리자 사용자가 security group을 생성·편집하지 못하도록 service control policy(SCP)를 설정하고, 관리자 권한이 필요한 규칙 요청 시 티켓 시스템에 알림을 생성합니다.",
    "SelectD_Commentary": "SCP로 제한은 가능하지만 이미 생성된 규칙에 대한 실시간 모니터링이 어렵고 관리자 승인 프로세스가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q803",
      "Q893",
      "Q53",
      "Q592",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q936",
      "Q289"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q793",
      "Q134"
    ],
    "SelectC_recommedations": [
      "Q395",
      "Q233",
      "Q624"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q318",
      "Q135"
    ]
  },
  {
    "Question_Number": "Q775",
    "Question_Description": "한 회사가 단일 AWS 계정에서 애플리케이션을 배포했습니다. 이 애플리케이션은 AWS Lambda와 Amazon Elastic Kubernetes Service(Amazon EKS)에서 실행되는 마이크로서비스로 구성됩니다. 각 마이크로서비스는 별도의 팀이 담당하며, 회사는 여러 AWS 계정을 사용 중이라 각 팀에 해당 팀의 마이크로서비스용 계정을 부여하려고 합니다. 솔루션스 아키텍트는 마이크로서비스 간 서비스 간 통신을 HTTPS(포트 443)를 통해 제공하고, 동시에 서비스 디스커버리를 위한 서비스 레지스트리를 구현해야 합니다. 이러한 요구 사항을 만족하면서도 관리 오버헤드를 최소화하기 위해 가장 적합한 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133007-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정 간 마이크로서비스가 HTTPS로 통신하면서, 서비스 디스커버리를 제공해야 하는 시나리오입니다. 가장 적은 관리 오버헤드로 이를 달성하기 위해서는 각 마이크로서비스를 손쉽게 등록하고 VPC들을 연결할 수 있는 서비스 네트워크 솔루션이 핵심입니다. VPC Lattice는 마이크로서비스 통신과 서비스 디스커버리를 간소화해 주므로 가장 효과적인 답이 됩니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "애플리케이션",
      "마이크로서비스",
      "AWS Lambda",
      "Amazon EKS",
      "서비스 간 통신",
      "HTTPS",
      "서비스 레지스트리",
      "서비스 디스커버리",
      "VPC Lattice",
      "관리 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon Elastic Kubernetes Service(Amazon EKS)",
      "AWS Lambda",
      "AWS Network Firewall",
      "Transit Gateway",
      "HTTPS",
      "VPC Lattice",
      "Network Load Balancer (NLB)",
      "AWS PrivateLink",
      "VPC Peering",
      "Prefix List",
      "Service Registry",
      "Service Discovery"
    ],
    "SelectA": "검사(inspection) VPC를 생성하고 해당 VPC에 AWS Network Firewall을 배포합니다. 새로운 Transit Gateway와 연결하여 VPC 간 트래픽을 검사 VPC로 라우팅하고, 방화벽 규칙을 통해 HTTPS 통신만 허용합니다.",
    "SelectA_Commentary": "보안을 위한 방화벽 구성이지만, 마이크로서비스 디스커버리를 위한 서비스 레지스트리가 제공되지 않으며, 설정이 복잡해 관리 오버헤드가 큽니다.",
    "SelectB": "VPC Lattice 서비스 네트워크를 생성합니다. 마이크로서비스들을 서비스 네트워크에 연동하고 각 서비스에 HTTPS 리스너를 정의합니다. 마이크로서비스 컴퓨팅 리소스를 대상(target)으로 등록하고, 서비스와 통신해야 하는 VPC를 식별하여 서비스 네트워크에 연결합니다.",
    "SelectB_Commentary": "VPC Lattice는 마이크로서비스를 서비스 네트워크로 손쉽게 구성하고 HTTPS 통신 및 서비스 디스커버리를 단순하게 제공하므로 관리가 간소해집니다. 정답입니다.",
    "SelectC": "HTTPS 리스너가 있는 Network Load Balancer(NLB)와 각 마이크로서비스용 대상 그룹을 생성합니다. 각 마이크로서비스용으로 AWS PrivateLink 엔드포인트 서비스를 생성하고, 서비스를 사용해야 하는 각 VPC에 인터페이스 VPC 엔드포인트를 만듭니다.",
    "SelectC_Commentary": "Microservice마다 NLB와 PrivateLink 구성을 해야 하므로 관리 오버헤드와 설정이 복잡해집니다. 또한 별도의 서비스 디스커버리 메커니즘을 추가로 구현해야 합니다.",
    "SelectD": "마이크로서비스가 있는 VPC들 간 피어링 연결을 생성합니다. 클라이언트가 연결을 요구하는 각 서비스별 Prefix List를 만들고, 라우트 테이블을 구성하여 해당 VPC로 트래픽을 라우팅합니다. 보안 그룹을 구성해 HTTPS만 허용합니다.",
    "SelectD_Commentary": "VPC Peering과 Prefix List를 통한 연결 방식은 서비스 레지스트리나 서비스 디스커버리를 제공하지 않으며, VPC 간 연결 관리가 증가해 오버헤드가 높아집니다.",
    "Question_Description_recommedations": [
      "Q900",
      "Q996",
      "Q194",
      "Q293",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q487",
      "Q708",
      "Q439"
    ],
    "SelectB_recommedations": [
      "Q439",
      "Q504",
      "Q487"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q487",
      "Q775"
    ],
    "SelectD_recommedations": [
      "Q439",
      "Q504",
      "Q487"
    ]
  },
  {
    "Question_Number": "Q776",
    "Question_Description": "한 회사는 모바일 게임을 운영하고 있으며, 대부분의 메타데이터를 Amazon RDS DB instance에서 읽어옵니다. 이 게임이 인기를 얻으면서 게임 메타데이터 로드 시간과 관련된 속도 저하가 발생했습니다. 성능 지표에 따르면 단순히 DB를 스케일업하는 것만으로는 해결이 어렵습니다. 솔루션스 아키텍트는 스냅샷, 복제(Replication), 서브 밀리초(sub-millisecond) 응답 시간을 모두 고려할 수 있는 방안을 모색해야 합니다. 이러한 문제를 해결하기 위해 솔루션스 아키텍트는 어떤 조치를 권장해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133008-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실시간 대규모 트래픽 상황에서 RDS 성능 병목을 해결하고, 스냅샷과 복제 기능을 활용하며 서브 밀리초 응답 시간을 요구합니다. 단순 스케일업 대신 캐싱 계층을 추가하여 핫 데이터를 빠르게 처리하고, Redis의 Snapshot과 복제 기능으로 안정성을 보장하는 솔루션이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "모바일 게임",
      "Amazon RDS",
      "서브 밀리초",
      "스냅샷",
      "복제",
      "ElastiCache",
      "Redis"
    ],
    "Terms": [
      "Amazon RDS DB instance",
      "Amazon Aurora with Aurora Replicas",
      "Amazon DynamoDB with global tables",
      "Amazon ElastiCache for Redis",
      "Amazon ElastiCache for Memcached",
      "Replication",
      "Snapshots",
      "Sub-millisecond response times"
    ],
    "SelectA": "데이터베이스를 Amazon Aurora로 마이그레이션하고, Aurora Replicas를 사용합니다.",
    "SelectA_Commentary": "Aurora로 이전해도 읽기 성능은 좋아질 수 있지만, 캐싱과 서브 밀리초 응답을 필요로 하는 즉시성 문제 해결에는 부적합합니다.",
    "SelectB": "데이터베이스를 Amazon DynamoDB로 마이그레이션하고, Global Tables를 사용합니다.",
    "SelectB_Commentary": "DynamoDB 전환은 스키마 재설계와 마이그레이션 부담이 큽니다. 또한 문제는 주로 메타데이터 조회에 대한 캐싱이므로 꼭 DynamoDB가 필요한 것은 아닙니다.",
    "SelectC": "데이터베이스 앞단에 Amazon ElastiCache for Redis 계층을 추가합니다.",
    "SelectC_Commentary": "Redis는 Snapshot, 복제 기능을 모두 갖추고 있으며 서브 밀리초 응답 속도를 제공합니다. 즉시 캐시 계층을 통해 RDS 부하와 지연 시간을 크게 줄일 수 있는 최적의 방안입니다.",
    "SelectD": "데이터베이스 앞단에 Amazon ElastiCache for Memcached 계층을 추가합니다.",
    "SelectD_Commentary": "Memcached는 캐싱에 적합하나 Redis가 제공하는 Snapshot과 복제 기능을 제공하지 않으므로 스냅샷 및 복제 요구 사항을 만족시키기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q95",
      "Q590",
      "Q661",
      "Q269",
      "Q386"
    ],
    "SelectA_recommedations": [
      "Q620",
      "Q361",
      "Q622"
    ],
    "SelectB_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q746",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q229",
      "Q704",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q777",
    "Question_Description": "한 회사는 멀티 계정 AWS 환경 구성을 위해 AWS Organizations를 사용하고 있습니다. 회사의 Security OU에서 승인된 Amazon Machine Image(AMI)를 개발 OU에 공유해야 합니다. 이 AMI들은 AWS Key Management Service(AWS KMS)로 암호화된 스냅샷을 사용해 생성되었습니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까? (두 가지를 선택하십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133009-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Organizations를 사용해 여러 계정 간 AMI를 안전하게 공유하는 방법을 묻습니다. AMI 사용 권한(Launch Permission)을 부여하고, AMI를 해독할 수 있도록 KMS 키 정책을 적절히 업데이트해야 합니다. 따라서 개발 OU에 대한 AMI 런치 권한과 KMS 키 정책 수정이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Organizations",
      "멀티 계정",
      "Security OU",
      "Development OU",
      "AMI 공유",
      "AWS KMS",
      "암호화된 스냅샷",
      "런치 권한",
      "Key Policy"
    ],
    "Terms": [
      "AWS Organizations",
      "Organizational Unit (OU)",
      "Amazon Machine Image (AMI)",
      "AWS Key Management Service (AWS KMS)",
      "Encrypted Snapshots",
      "Key Policy",
      "Launch Permission"
    ],
    "SelectA": "AMI에 대한 런치 권한 목록에 개발 팀의 OU Amazon Resource Name(ARN)을 추가합니다.",
    "SelectA_Commentary": "개발 OU가 AMI를 사용할 수 있도록 권한을 부여해 필요한 공유를 달성합니다. 우선적으로 필요한 조치 중 하나로 정답입니다.",
    "SelectB": "AMI에 대한 런치 권한 목록에 Organizations 루트 ARN을 추가합니다.",
    "SelectB_Commentary": "루트 ARN을 사용해 모든 하위 OU를 포함할 수 있지만, 이 문제는 특정 개발 OU만을 대상으로 하므로 과도한 권한 부여로 적절치 않습니다.",
    "SelectC": "스냅샷을 복호화하는 데 사용되는 AWS KMS 키를 개발 팀의 OU가 사용할 수 있도록 Key Policy를 업데이트합니다.",
    "SelectC_Commentary": "AMI를 사용할 때 암호화 스냅샷 해독이 필수이므로, 개발 OU에 KMS 사용 권한을 제공해야 합니다. 정답입니다.",
    "SelectD": "AMI에 대한 런치 권한 목록에 개발 팀의 계정 ARN을 추가합니다.",
    "SelectD_Commentary": "OU 전체가 아닌 특정 계정만 지정하므로 여러 계정이 속한 OU는 포괄하지 못합니다. 명시된 요구사항에 부합하지 않습니다.",
    "SelectE": "AWS KMS 키를 재생성하고, Organizations 루트 ARN이 AWS KMS 키를 사용할 수 있도록 Key Policy를 추가합니다.",
    "SelectE_Commentary": "새로운 키 생성은 불필요하며, 특정 개발 OU에 권한을 부여하는 방식이 요구되므로 적절한 해법이 아닙니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q988",
      "Q945",
      "Q681",
      "Q560"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q34",
      "Q592"
    ],
    "SelectB_recommedations": [
      "Q665",
      "Q478",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q550",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q665",
      "Q189",
      "Q122"
    ],
    "SelectE_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q778",
    "Question_Description": "한 데이터 분석 회사는 전 세계에 분산된 80개의 사무실을 보유하고 있습니다. 각 사무실당 1PB의 데이터를 보유하며, 인터넷은 1~2Gbps 대역폭을 갖추고 있습니다. 이 회사는 대량의 데이터를 단 한 번 Amazon S3로 이전해야 하며, 4주 이내에 완료해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133010-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 여러 사무실에서 대량의 데이터를 제시간에, 그리고 비용 효율적으로 Amazon S3로 이전해야 하는 상황을 묻습니다. 인터넷 대역폭만으로는 4주 제한을 맞추기 어려울 수 있어 물리적 디바이스인 AWS Snowball Edge를 활용하는 것이 가장 비용 효율적입니다. AWS Direct Connect나 AWS Snowmobile은 비용이나 범용성 면에서 비효율적이며, AWS Storage Gateway는 대규모 오프라인 전송보다는 지속적인 하이브리드 스토리지 구성에 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.4"
    ],
    "Keywords": [
      "단 한 번의 대규모 데이터 이전",
      "4주 이내 마이그레이션",
      "비용 효율",
      "1PB 데이터",
      "글로벌 사무실"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Direct Connect",
      "AWS Snowball Edge",
      "Storage-optimized",
      "AWS Snowmobile",
      "AWS Storage Gateway",
      "Volume Gateway"
    ],
    "SelectA": "각 사무실마다 새로운 10Gbps AWS Direct Connect 연결을 구축하고 Amazon S3로 데이터를 전송합니다.",
    "SelectA_Commentary": "모든 사무실에 Direct Connect를 설치하는 것은 초기 구축 비용이 매우 높고 시간도 많이 소요되어 비현실적입니다.",
    "SelectB": "여러 대의 AWS Snowball Edge storage-optimized 디바이스를 사용하여 데이터를 Amazon S3로 전송합니다.",
    "SelectB_Commentary": "대량 데이터를 오프라인으로 전송할 수 있어 시간과 비용을 절감합니다. 글로벌 사무실 간 분산 환경에서도 유연하고 확장 가능합니다.",
    "SelectC": "AWS Snowmobile을 사용하여 데이터를 Amazon S3로 전송합니다.",
    "SelectC_Commentary": "Snowmobile은 엑사바이트급 초대형 마이그레이션에 특화되어 있어 규모가 과도하며, 사무실 간 분산 처리에 비효율적입니다.",
    "SelectD": "AWS Storage Gateway Volume Gateway를 설정해 데이터를 Amazon S3로 전송합니다.",
    "SelectD_Commentary": "Storage Gateway는 주로 온프레미스와 클라우드를 연계해 지속적으로 사용하는 용도이며, 이처럼 대규모 일회성 전송에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q583",
      "Q285",
      "Q911",
      "Q759",
      "Q606"
    ],
    "SelectA_recommedations": [
      "Q499",
      "Q835",
      "Q240"
    ],
    "SelectB_recommedations": [
      "Q285",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q943",
      "Q911"
    ],
    "SelectD_recommedations": [
      "Q497",
      "Q415",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q779",
    "Question_Description": "한 회사가 Amazon Elastic File System(Amazon EFS) 파일 시스템에 기준이 되는(reference) 데이터세트를 보관하고 있습니다. 회사의 Amazon EC2 인스턴스에서 해당 데이터세트를 읽어야 하지만, 이 애플리케이션들은 데이터세트를 변경할 수 없어야 합니다. 회사는 IAM 액세스 컨트롤을 사용하여 애플리케이션이 데이터세트를 수정하거나 삭제하지 못하도록 하길 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133011-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EFS에 저장된 데이터세트에 대해 EC2 인스턴스가 읽기만 가능하도록, IAM 및 POSIX 권한을 활용해 쓰기와 삭제를 차단하는 방법을 묻습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon EFS",
      "EC2 인스턴스",
      "read-only",
      "IAM 액세스 컨트롤",
      "데이터세트 변경 금지",
      "EFS access point",
      "POSIX 권한"
    ],
    "Terms": [
      "Amazon Elastic File System(Amazon EFS)",
      "Amazon EC2",
      "IAM access control",
      "resource policy",
      "identity policy",
      "EFS access point",
      "Portable Operating System Interface (POSIX)",
      "read-only mode"
    ],
    "SelectA": "Amazon EFS 파일 시스템을 EC2 인스턴스 내에서 read-only 모드로 마운트합니다.",
    "SelectA_Commentary": "OS에서 read-only 마운트만 설정하면 IAM 차원의 제어가 불충분해, 보안 및 관리 측면에서 한계가 있습니다.",
    "SelectB": "EFS 파일 시스템에 대한 resource policy를 생성하고, EC2 인스턴스에 연결된 IAM role에 대해 elasticfilesystem:ClientWrite 동작을 거부(deny)합니다.",
    "SelectB_Commentary": "resource policy로 한 번에 적용 가능하나, 세분화된 애플리케이션별 접근 제어가 어려워 유연성이 떨어집니다.",
    "SelectC": "EFS 파일 시스템에 대한 identity policy를 생성하고, EFS 파일 시스템에 대해 elasticfilesystem:ClientWrite 동작을 거부(deny)합니다.",
    "SelectC_Commentary": "identity policy로도 접근 권한을 제한할 수 있지만, 각 역할별로 정책을 관리해야 하므로 운영이 복잡할 수 있습니다.",
    "SelectD": "각 애플리케이션용 EFS access point를 생성하고, Portable Operating System Interface (POSIX) 파일 권한을 사용하여 루트 디렉터리의 파일에 대해 read-only 액세스를 허용합니다.",
    "SelectD_Commentary": "EFS access point와 POSIX 권한 조합으로 IAM 기반 접근 제어를 구현하여, 쓰기와 삭제 없이 안전하게 데이터를 공유할 수 있는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q675",
      "Q998",
      "Q710",
      "Q681",
      "Q410"
    ],
    "SelectA_recommedations": [
      "Q779",
      "Q453",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q779",
      "Q494",
      "Q453"
    ],
    "SelectC_recommedations": [
      "Q779",
      "Q494",
      "Q423"
    ],
    "SelectD_recommedations": [
      "Q779",
      "Q774",
      "Q873"
    ]
  },
  {
    "Question_Number": "Q780",
    "Question_Description": "한 회사가 AWS account에서 작업을 수행하기 위해 외부 벤더를 고용했습니다. 벤더는 자신이 소유한 AWS account에 호스팅된 자동화된 툴을 사용하고 있습니다. 현재 벤더는 회사의 AWS account에 대한 IAM 액세스 권한이 없습니다. 회사는 벤더에게 회사의 AWS account에 대한 액세스를 부여해야 합니다. 어떤 솔루션이 가장 안전하게 이 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133014-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회사의 AWS account에 외부 벤더가 최소 권한으로 안전하게 접근하게 만드는 방법을 묻습니다. 보안 모범 사례에 따르면 cross-account 접근에는 IAM role을 사용하고, 필요한 권한만을 IAM policies로 부여하여 임시 자격 증명을 사용하도록 하는 것이 가장 안전하고 유연한 방식입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "외부 벤더",
      "AWS account",
      "IAM 액세스",
      "가장 안전하게",
      "권한 부여"
    ],
    "Terms": [
      "IAM role",
      "IAM user",
      "IAM group",
      "permission boundary",
      "IAM policies"
    ],
    "SelectA": "회사의 account에 IAM role을 생성하여 벤더의 IAM role에 권한을 위임합니다. 벤더가 필요한 권한에 대한 적절한 IAM policies를 role에 연결합니다.",
    "SelectA_Commentary": "cross-account 접근은 IAM role을 사용하는 것이 업계 모범 사례이며, 벤더는 필요한 시점에만 role을 assume할 수 있어 보안성이 뛰어납니다.",
    "SelectB": "회사의 account에 패스워드 복잡성 요구 사항을 충족하는 IAM user를 생성합니다. 벤더가 필요한 권한을 IAM policies로 연결합니다.",
    "SelectB_Commentary": "고정 자격 증명을 부여하면 정보 유출 시 위험이 커지며, 접근 시점을 통제하기 어려워 보안 측면에서 취약합니다.",
    "SelectC": "회사의 account에 IAM group을 생성합니다. 벤더 account의 자동화 툴 IAM user를 이 그룹에 추가합니다. 벤더가 필요한 권한을 그룹에 연결합니다.",
    "SelectC_Commentary": "벤더 account의 IAM user를 그룹에 직접 추가하는 cross-account 구성은 지원되지 않으며, role 기반 접근이 더 안전하고 권장됩니다.",
    "SelectD": "회사의 account에 permission boundary를 적용하여 벤더 account를 허용하는 IAM user를 생성합니다. 필요한 권한을 IAM policies로 연결합니다.",
    "SelectD_Commentary": "permission boundary로 권한 한도를 설정할 수 있지만, 여전히 고정 자격 증명을 제공하므로 role을 사용하는 것만큼 안전하지 않습니다.",
    "Question_Description_recommedations": [
      "Q222",
      "Q476",
      "Q233",
      "Q745",
      "Q395"
    ],
    "SelectA_recommedations": [
      "Q423",
      "Q780",
      "Q429"
    ],
    "SelectB_recommedations": [
      "Q780",
      "Q423",
      "Q429"
    ],
    "SelectC_recommedations": [
      "Q395",
      "Q780",
      "Q429"
    ],
    "SelectD_recommedations": [
      "Q423",
      "Q780",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q781",
    "Question_Description": "한 회사가 AWS Cloud에서 실험용 워크로드를 운영하려고 합니다. 회사는 클라우드 지출을 위한 예산을 마련해 두었으며, CFO는 각 부서별 클라우드 지출에 대한 책임 관리를 원하고 있습니다. CFO는 지출이 예산의 60%에 도달할 때 알림을 받고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133015-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CFO가 부서별로 클라우드 사용 비용을 확인하고, 예산 대비 지출이 60%에 달했을 때 자동으로 알림을 받고자 할 때 어떤 방법이 가장 적절한지 묻습니다. AWS Budgets를 활용해 미리 지출 한도를 설정해 두면, 특정 퍼센트 초과 시 자동으로 알림을 전송하면서 부서별 책임 관리도 간편하게 수행할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "클라우드 지출",
      "예산",
      "지출 임계값",
      "부서별 책임",
      "CFO",
      "알림",
      "AWS Budgets"
    ],
    "Terms": [
      "cost allocation tags",
      "AWS resources",
      "AWS Budgets",
      "usage budgets",
      "AWS Cost Explorer",
      "AWS Cost Anomaly Detection",
      "AWS Support API",
      "AWS Trusted Advisor",
      "spending threshold"
    ],
    "SelectA": "AWS 리소스에 cost allocation tag를 사용하여 소유자를 라벨링합니다. AWS Budgets에서 usage budget을 생성합니다. 예산이 60%를 초과할 때 알림을 받도록 알림 임계값을 추가합니다.",
    "SelectA_Commentary": "AWS Budgets는 지출 한도를 미리 설정하고 비용이 일정 비율을 넘어설 시 자동으로 알림을 보내는 핵심 서비스입니다. cost allocation tag로 부서별로 태깅해 책임 구분도 명확히 할 수 있어 문제 요구사항에 부합합니다.",
    "SelectB": "AWS Cost Explorer의 예측을 사용하여 리소스 소유자를 파악합니다. AWS Cost Anomaly Detection을 사용하여 지출이 예산의 60%를 초과할 때 알림 임계값 알림을 생성합니다.",
    "SelectB_Commentary": "AWS Cost Anomaly Detection은 급격한 비용 변동 감지에 특화된 서비스로, 예산 사용률 기반의 알림 설정에는 적합하지 않습니다. 또한 관련 태그 관리가 없어 부서별 책임 트래킹이 제한적입니다.",
    "SelectC": "AWS 리소스에 cost allocation tag를 사용하여 소유자를 라벨링합니다. AWS Support API와 AWS Trusted Advisor를 사용해 지출이 예산의 60%를 초과할 때 알림 임계값 알림을 생성합니다.",
    "SelectC_Commentary": "AWS Trusted Advisor는 리소스 최적화와 보안 권장 사항 등을 제안하지만, 사용자가 원하는 예산 기반 알림 설정을 직접적으로 제공하지는 않습니다. 따라서 요구사항과는 거리가 있습니다.",
    "SelectD": "AWS Cost Explorer의 예측으로 리소스 소유자를 파악합니다. AWS Budgets에서 usage budget을 생성합니다. 예산이 60%를 초과할 때 알림을 받도록 알림 임계값을 추가합니다.",
    "SelectD_Commentary": "Cost Explorer는 비용 사용 패턴과 예측을 제공하지만, 부서별 소유자 태깅이 바로 연결되지 않는 점이 있어 책임 관리가 복잡해집니다. A 옵션처럼 cost allocation tag를 활용하는 것이 더 명확합니다.",
    "Question_Description_recommedations": [
      "Q485",
      "Q728",
      "Q985",
      "Q486",
      "Q300"
    ],
    "SelectA_recommedations": [
      "Q31",
      "Q641",
      "Q781"
    ],
    "SelectB_recommedations": [
      "Q641",
      "Q459",
      "Q715"
    ],
    "SelectC_recommedations": [
      "Q31",
      "Q459",
      "Q641"
    ],
    "SelectD_recommedations": [
      "Q641",
      "Q459",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q782",
    "Question_Description": "한 회사가 내부 웹 애플리케이션을 AWS에 배포하려고 합니다. 이 웹 애플리케이션은 오직 회사의 오피스에서만 접근 가능해야 합니다. 또한 이 웹 애플리케이션은 인터넷으로부터 보안 패치를 다운로드해야 합니다. 회사는 이미 VPC를 생성하고 회사 오피스와 AWS 간에 AWS Site-to-Site VPN 연결을 구성했습니다. 솔루션스 아키텍트는 해당 웹 애플리케이션을 위해 안전한 아키텍처를 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133016-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사내 전용 접근과 인터넷 패치 다운로드를 모두 충족하기 위한 VPC 보안 구성이 핵심입니다. 내부 ALB와 private subnet에 웹 서버를 두고 NAT Gateway를 통해 인터넷에 접속해 보안 패치를 받을 수 있도록 설계해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "내부 웹 애플리케이션",
      "오피스에서만 접근",
      "인터넷 보안 패치",
      "private subnet",
      "internal Application Load Balancer",
      "NAT Gateway"
    ],
    "Terms": [
      "AWS Site-to-Site VPN",
      "Amazon EC2",
      "public subnet",
      "private subnet",
      "Application Load Balancer (ALB)",
      "NAT Gateway",
      "Internet Gateway",
      "Security Group",
      "CIDR block",
      "VPC"
    ],
    "SelectA": "Amazon EC2 인스턴스를 public subnet에 배포하고, public Application Load Balancer 뒤에 둡니다. VPC에 Internet Gateway를 연결하고 ALB 보안 그룹 Inbound 소스를 0.0.0.0/0으로 설정합니다.",
    "SelectA_Commentary": "public subnet 사용과 0.0.0.0/0 허용으로 인해 인터넷에 직접 노출되어 오피스 전용이라는 요구 사항을 만족하지 못합니다.",
    "SelectB": "Amazon EC2 인스턴스를 private subnet에 배포하고, internal Application Load Balancer 뒤에 둡니다. public subnet에 NAT Gateway를 배포하고 VPC에 Internet Gateway를 연결합니다. ALB 보안 그룹 Inbound 소스를 회사 오피스 CIDR로 설정합니다.",
    "SelectB_Commentary": "사내 접근만 허용하는 내부용 ALB와, NAT Gateway를 통한 인터넷 패치 다운로드가 모두 가능해 요구 사항을 충족하는 최적의 솔루션입니다.",
    "SelectC": "public subnet에 있는 Amazon EC2 인스턴스를 internal Application Load Balancer 뒤에 둡니다. private subnet에 NAT Gateway를 배포하고 VPC에 Internet Gateway를 연결합니다. ALB 보안 그룹 Outbound를 회사 오피스 CIDR로 설정합니다.",
    "SelectC_Commentary": "EC2 인스턴스가 public subnet에 있어 외부에서 접근 가능할 우려가 있으며, ALB 설정도 요구사항을 제대로 충족하지 못합니다.",
    "SelectD": "private subnet에 있는 Amazon EC2 인스턴스를 public Application Load Balancer 뒤에 둡니다. VPC에 Internet Gateway를 연결하고 ALB 보안 그룹 Outbound를 0.0.0.0/0으로 설정합니다.",
    "SelectD_Commentary": "public ALB가 외부 트래픽을 직접 수용하므로 오피스에서만 접근 가능하도록 제한하기 어렵고 보안 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q950",
      "Q15",
      "Q810",
      "Q712",
      "Q151"
    ],
    "SelectA_recommedations": [
      "Q282",
      "Q1016",
      "Q509"
    ],
    "SelectB_recommedations": [
      "Q282",
      "Q1016",
      "Q509"
    ],
    "SelectC_recommedations": [
      "Q282",
      "Q1016",
      "Q509"
    ],
    "SelectD_recommedations": [
      "Q282",
      "Q1016",
      "Q509"
    ]
  },
  {
    "Question_Number": "Q783",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 실행되는 커스텀 애플리케이션으로 회계 기록을 유지 관리하고 있습니다. 회사는 이 애플리케이션 데이터를 개발 및 유지 관리하기 위해 AWS에서 관리하는 서비스로 마이그레이션해야 합니다. 솔루션은 운영 지원이 최소화되어야 하며, 데이터 변경 이력이 불변(immutable)이고 암호학적으로 검증 가능한 로그가 제공되어야 합니다. 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133018-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회계 데이터를 안전하게 보관하며 변경 이력을 불변으로 추적하기 위한 관리형 솔루션을 찾는 질문입니다. Amazon QLDB는 이 요구사항을 충족하며, 운영 부담과 비용을 모두 절감합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "회계 기록",
      "운영 지원 최소화",
      "불변 로그",
      "암호학적 검증",
      "비용 효율적",
      "Amazon QLDB"
    ],
    "Terms": [
      "Amazon QLDB",
      "Amazon Neptune",
      "Amazon Timestream",
      "Amazon Redshift",
      "Amazon EC2",
      "immutable ledger",
      "cryptographically verifiable logs"
    ],
    "SelectA": "애플리케이션의 기록을 Amazon Redshift 클러스터로 복사합니다.",
    "SelectA_Commentary": "Amazon Redshift는 데이터 웨어하우스 서비스로, 불변 형태의 변경 이력 보장이나 암호학적 검증이 필요한 감사 워크로드에는 적합하지 않습니다.",
    "SelectB": "애플리케이션의 기록을 Amazon Neptune 클러스터로 복사합니다.",
    "SelectB_Commentary": "Amazon Neptune은 그래프 데이터베이스로, 회계 데이터에 요구되는 불변 원장 기능과 암호학적 검증을 제공하지 못합니다.",
    "SelectC": "애플리케이션의 기록을 Amazon Timestream 데이터베이스로 복사합니다.",
    "SelectC_Commentary": "Amazon Timestream은 시계열 데이터베이스로, 회계 요구사항인 불변 추적이나 감사를 위한 원장 기능을 제공하지 않습니다.",
    "SelectD": "애플리케이션의 기록을 Amazon Quantum Ledger Database(Amazon QLDB) 원장으로 복사합니다.",
    "SelectD_Commentary": "Amazon QLDB는 불변 원장과 암호학적으로 검증 가능한 이력을 제공하므로, 감사 및 무결성이 중요한 회계 데이터에 최적이며 운영 및 비용 측면에서도 효과적입니다.",
    "Question_Description_recommedations": [
      "Q492",
      "Q329",
      "Q480",
      "Q682",
      "Q315"
    ],
    "SelectA_recommedations": [
      "Q592",
      "Q893",
      "Q831"
    ],
    "SelectB_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q592",
      "Q122"
    ],
    "SelectD_recommedations": [
      "Q176",
      "Q279",
      "Q765"
    ]
  },
  {
    "Question_Number": "Q784",
    "Question_Description": "한 회사의 마케팅 데이터가 여러 소스에서 Amazon S3 버킷으로 업로드됩니다. 일련의 데이터 준비 작업은 보고용으로 데이터를 집계합니다. 이 데이터 준비 작업들은 정기적으로 병렬 실행되어야 하며, 일부 작업은 이후에 특정 순서대로 실행되어야 합니다. 회사는 작업 오류 처리, 재시도 로직, 상태 관리를 위한 운영 오버헤드를 제거하고 싶습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133019-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 데이터 준비 작업을 주기적으로 병렬 실행하면서도 일부 작업은 특정 순서를 유지해야 할 때, 운영 오버헤드를 최소화하는 방법을 찾는 것입니다. AWS Glue DataBrew는 데이터 준비 작업을 쉽고 자동화할 수 있으며, AWS Step Functions는 병렬 처리, 오류 처리, 재시도 로직, 상태 관리를 간편하게 구성할 수 있어 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "마케팅 데이터",
      "병렬 실행",
      "정기적 스케줄",
      "특정 순서",
      "오류 처리",
      "재시도 로직",
      "상태 관리",
      "AWS Glue DataBrew",
      "AWS Step Functions"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon EventBridge Scheduler",
      "Amazon Athena",
      "AWS Glue DataBrew",
      "AWS Step Functions",
      "AWS Data Pipeline"
    ],
    "SelectA": "S3 버킷에 데이터가 업로드되면 즉시 이를 처리하는 AWS Lambda 함수를 사용합니다. 정기적으로 다른 Lambda 함수를 호출합니다.",
    "SelectA_Commentary": "이 접근 방식은 병렬 실행 및 특정 순서 처리를 직접 관리해야 하고, 오류 처리와 상태 관리를 Lambda 레벨에서 구현해야 해 운영 오버헤드가 높습니다.",
    "SelectB": "Amazon Athena로 데이터를 처리합니다. Amazon EventBridge Scheduler로 Athena를 정기적으로 호출합니다.",
    "SelectB_Commentary": "정기 처리는 가능하지만, 병렬 실행 및 순서 제어가 제한적이며, 오류 처리와 상태 관리를 별도로 구성해야 해 복잡도가 높아집니다.",
    "SelectC": "AWS Glue DataBrew를 사용해 데이터를 처리합니다. AWS Step Functions 상태 기계를 사용해 DataBrew 데이터 준비 작업을 실행합니다.",
    "SelectC_Commentary": "AWS Glue DataBrew로 간편하게 데이터를 준비하고, AWS Step Functions에서 병렬 실행, 오류 처리, 재시도, 순서 제어까지 쉽게 구성할 수 있어 운영 오버헤드를 최소화합니다.",
    "SelectD": "AWS Data Pipeline을 사용해 데이터를 처리합니다. 자정에 한 번씩 Data Pipeline을 실행하도록 스케줄합니다.",
    "SelectD_Commentary": "단일 일괄 처리 중심이므로 병렬 실행과 특정 순서 제어가 유연하지 않고, 추가적인 오류 처리와 상태 관리 작업도 더 많은 수작업이 필요합니다.",
    "Question_Description_recommedations": [
      "Q110",
      "Q94",
      "Q1014",
      "Q149",
      "Q252"
    ],
    "SelectA_recommedations": [
      "Q404",
      "Q785",
      "Q18"
    ],
    "SelectB_recommedations": [
      "Q569",
      "Q351",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q897",
      "Q843",
      "Q293"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q293",
      "Q363"
    ]
  },
  {
    "Question_Number": "Q785",
    "Question_Description": "한 솔루션스 아키텍트가 여러 가용 영역에 걸쳐 사설 서브넷에서 실행되는 AWS Lambda 기반 결제 처리 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 여러 Lambda 함수를 사용하며 하루에 수백만 건의 트랜잭션을 처리합니다. 아키텍처는 중복 결제가 처리되지 않도록 보장해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133021-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 결제 프로세스에서 중복 트랜잭션을 방지하는 것입니다. Amazon SQS FIFO queue는 메시지를 정확히 한 번씩 처리하며 주문 보장과 중복 억제 기능을 제공하므로 중복 결제를 막을 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "결제 처리",
      "중복 결제 방지",
      "AWS Lambda",
      "Amazon SQS FIFO queue",
      "중복 없는 메시지 처리"
    ],
    "Terms": [
      "AWS Lambda",
      "Availability Zone",
      "Private Subnet",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Standard Queue",
      "FIFO Queue",
      "Amazon DynamoDB",
      "DynamoDB Streams"
    ],
    "SelectA": "Lambda로 모든 결제 대기 건을 조회하여 Amazon S3 버킷에 게시합니다. 해당 S3 버킷의 이벤트 알림을 설정하여 다른 Lambda 함수로 결제 대기 건을 처리하도록 합니다.",
    "SelectA_Commentary": "S3 이벤트 트리거 방식은 중복 처리를 확실히 막기가 어렵고, 상태 관리를 위해 추가 구성과 로직이 필요합니다.",
    "SelectB": "Lambda로 모든 결제 대기 건을 조회하여 Amazon Simple Queue Service (Amazon SQS) 표준 큐에 게시합니다. 다른 Lambda 함수가 SQS 큐를 폴링하여 결제 대기 건을 처리하도록 구성합니다.",
    "SelectB_Commentary": "표준 큐는 최소 1회 이상 메시지를 전달하므로 중복 메시지가 발생해 중복 결제의 위험이 남습니다.",
    "SelectC": "Lambda로 모든 결제 대기 건을 조회하여 Amazon Simple Queue Service (Amazon SQS) FIFO 큐에 게시합니다. 다른 Lambda 함수가 FIFO 큐를 폴링하여 결제 대기 건을 처리하도록 구성합니다.",
    "SelectC_Commentary": "FIFO 큐는 정확히 한 번씩 메시지를 전달하며, 중복 억제 기능을 제공해 중복 결제 발생을 방지합니다.",
    "SelectD": "Lambda로 모든 결제 대기 건을 조회하여 Amazon DynamoDB 테이블에 저장합니다. DynamoDB Streams를 설정해 다른 Lambda 함수가 테이블 변경 사항을 처리하도록 합니다.",
    "SelectD_Commentary": "DynamoDB Streams는 실시간 처리가 가능하나, 자체 로직으로 중복 제어를 구현해야 하며 FIFO 큐보다 단순성이 떨어집니다.",
    "Question_Description_recommedations": [
      "Q531",
      "Q513",
      "Q404",
      "Q1014",
      "Q112"
    ],
    "SelectA_recommedations": [
      "Q404",
      "Q785",
      "Q18"
    ],
    "SelectB_recommedations": [
      "Q98",
      "Q785",
      "Q404"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q404",
      "Q98"
    ],
    "SelectD_recommedations": [
      "Q1002",
      "Q785",
      "Q207"
    ]
  },
  {
    "Question_Number": "Q786",
    "Question_Description": "한 회사가 사내 데이터 센터에서 여러 워크로드를 운영하고 있습니다. 회사의 데이터 센터는 증가하는 비즈니스 요구 사항을 충족하기 위해 충분히 빠르게 확장할 수 없습니다. 회사는 온프레미스 서버와 워크로드에 대한 사용량과 구성 데이터를 수집하여 AWS로의 마이그레이션을 계획하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133022-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 확장 한계가 있는 사내 데이터 센터 환경에서, 앞으로의 AWS 마이그레이션 계획을 위해 온프레미스 서버와 워크로드의 사용량·구성 정보를 효율적으로 수집하는 방안을 묻습니다. AWS Migration Hub와 AWS Application Discovery Service는 이런 데이터를 자동으로 수집·분석해줌으로써 구체적이고 빠른 마이그레이션 전략 수립이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "온프레미스 서버",
      "마이그레이션",
      "AWS Migration Hub",
      "AWS Application Discovery Service",
      "사용량 및 구성 데이터"
    ],
    "Terms": [
      "AWS Migration Hub",
      "AWS Systems Manager",
      "AWS Application Discovery Service",
      "AWS Schema Conversion Tool(AWS SCT)",
      "AWS Trusted Advisor",
      "AWS Database Migration Service(AWS DMS)"
    ],
    "SelectA": "AWS Migration Hub에서 홈 AWS Region을 설정합니다. AWS Systems Manager를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
    "SelectA_Commentary": "Systems Manager는 서버 인벤토리나 패치 관리 등에 유용하지만, 마이그레이션 실사에 특화된 상세 데이터 수집에는 제한적입니다.",
    "SelectB": "AWS Migration Hub에서 홈 AWS Region을 설정합니다. AWS Application Discovery Service를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
    "SelectB_Commentary": "AWS Application Discovery Service는 마이그레이션에 필요한 서버 사용량·구성 메타데이터를 자동 수집하며, Migration Hub에서 중앙 관리가 가능해 가장 적합합니다.",
    "SelectC": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성합니다. AWS Trusted Advisor를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
    "SelectC_Commentary": "AWS SCT는 DB 스키마 변환 툴이고, Trusted Advisor는 AWS 계정 환경 모범 사례 점검 용도로, 온프레미스 환경 정보를 실제로 수집·분석하기에는 적합하지 않습니다.",
    "SelectD": "AWS Schema Conversion Tool(AWS SCT)을 사용하여 관련 템플릿을 생성합니다. AWS Database Migration Service(AWS DMS)를 사용하여 온프레미스 서버에 대한 데이터를 수집합니다.",
    "SelectD_Commentary": "AWS SCT와 DMS는 주로 DB 스키마 및 데이터 마이그레이션에 초점이 맞추어져 있으며, 전체 서버 워크로드 사용량과 상세 구성 정보를 수집하는 데는 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q519",
      "Q112",
      "Q149",
      "Q802",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q224",
      "Q68",
      "Q241"
    ],
    "SelectB_recommedations": [
      "Q241",
      "Q68",
      "Q293"
    ],
    "SelectC_recommedations": [
      "Q293",
      "Q843",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q843",
      "Q944",
      "Q354"
    ]
  },
  {
    "Question_Number": "Q787",
    "Question_Description": "한 회사가 모든 기능이 활성화된 AWS Organizations를 사용 중입니다. 이 회사는 기존 및 신규 AWS 계정의 모든 API 호출과 로그인에 대해 감사(audit)가 이루어져야 한다고 요구합니다. 또한 회사는 추가 작업을 최소화하고 비용을 절감하기 위해 관리형 솔루션이 필요합니다. 마지막으로 어떤 AWS 계정이 AWS Foundational Security Best Practices(FSBP) 표준을 준수하지 않는지에 대한 정보를 받아야 합니다. 이러한 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133023-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 API 호출 및 로그인을 중앙에서 감사하고, AWS Foundational Security Best Practices 표준 준수 여부를 쉽게 파악하고자 할 때 어떤 솔루션이 가장 적은 운영 오버헤드를 갖는지 묻습니다. AWS Control Tower는 자동으로 여러 계정을 관리하고 모범사례 가이드라인을 적용하기 용이하며, AWS Security Hub를 통해 FSBP 준수 여부를 확인할 수 있어 요구 사항을 간단히 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Organizations",
      "API 호출 감사",
      "로그인 감사",
      "AWS Foundational Security Best Practices",
      "운영 오버헤드 최소화",
      "AWS Control Tower",
      "AWS Security Hub"
    ],
    "Terms": [
      "AWS Control Tower",
      "AWS Organizations",
      "Account Factory",
      "AWS Security Hub",
      "AWS Foundational Security Best Practices(FSBP)",
      "Amazon GuardDuty",
      "AWS Managed Services (AMS) Accelerate",
      "Multi-Account Landing Zone (MALZ)",
      "RFC"
    ],
    "SelectA": "AWS Control Tower 환경을 Organizations 관리 계정에 배포하고, AWS Security Hub와 AWS Control Tower Account Factory를 활성화합니다.",
    "SelectA_Commentary": "Organizations 관리 계정에서 AWS Control Tower를 설정하면 계정 생성부터 감사와 보안 정책 적용, FSBP 모니터링까지 자동화됩니다. 운영 오버헤드가 가장 낮아 정답입니다.",
    "SelectB": "AWS Control Tower 환경을 별도의 Organizations 멤버 계정에 배포하고, AWS Security Hub와 AWS Control Tower Account Factory를 활성화합니다.",
    "SelectB_Commentary": "관리 계정이 아닌 멤버 계정에 Control Tower를 배포하면 구성 및 운영이 복잡해집니다. 표준적인 관리 계정 배포 방식보다 오버헤드가 커 적합하지 않습니다.",
    "SelectC": "AWS Managed Services (AMS) Accelerate를 사용해 Multi-Account Landing Zone(MALZ)을 구축합니다. 그런 다음 RFC를 제출해 Amazon GuardDuty를 셀프 프로비저닝합니다.",
    "SelectC_Commentary": "AMS Accelerate 이용 시 관리형 서비스 제공은 가능하지만, GuardDuty만으로 FSBP 표준 총체적 확인이 어렵고 운영 절차가 추가되어 요구사항 대비 오버헤드가 높습니다.",
    "SelectD": "AWS Managed Services (AMS) Accelerate를 사용해 Multi-Account Landing Zone(MALZ)을 구축합니다. 그런 다음 RFC를 제출해 AWS Security Hub를 셀프 프로비저닝합니다.",
    "SelectD_Commentary": "Security Hub를 통해 FSBP를 확인할 수 있지만 AMS 사용과 RFC 요청 프로세스로 인해 운영 절차가 복잡해집니다. Control Tower에 비해 오버헤드가 더 큽니다.",
    "Question_Description_recommedations": [
      "Q945",
      "Q168",
      "Q828",
      "Q1018",
      "Q748"
    ],
    "SelectA_recommedations": [
      "Q688",
      "Q668",
      "Q945"
    ],
    "SelectB_recommedations": [
      "Q688",
      "Q668",
      "Q28"
    ],
    "SelectC_recommedations": [
      "Q121",
      "Q961",
      "Q451"
    ],
    "SelectD_recommedations": [
      "Q121",
      "Q688",
      "Q961"
    ]
  },
  {
    "Question_Number": "Q788",
    "Question_Description": "한 회사가 Amazon S3 버킷에 10TB의 Apache Parquet 형식 로그 파일을 저장해 두었습니다. 회사에서는 필요한 경우에만 이 로그 파일들에 대해 SQL을 사용하여 분석해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133024-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 보관된 데이터를 SQL로 분석해야 할 때, 낮은 빈도임에도 대규모 데이터를 효율적으로 처리하는 방법을 묻습니다. 서버리스로 사용량에 따라 비용을 지불하는 Amazon Athena와 AWS Glue를 통해 빠르고 간단하게 메타데이터를 구성해 Parquet 데이터를 직접 조회하는 방안이 가장 저렴합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "로그 파일",
      "Apache Parquet",
      "Amazon S3",
      "SQL 분석",
      "비용 효율"
    ],
    "Terms": [
      "Amazon S3",
      "Apache Parquet",
      "SQL",
      "Amazon Aurora MySQL",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon Redshift",
      "Redshift Spectrum",
      "AWS Glue crawler",
      "Amazon Athena",
      "Amazon EMR",
      "Apache Spark SQL"
    ],
    "SelectA": "Amazon Aurora MySQL 데이터베이스를 생성하고, AWS DMS를 사용해 S3 버킷의 데이터를 Aurora로 마이그레이션합니다. 이후 Aurora 데이터베이스에 SQL 쿼리를 실행합니다.",
    "SelectA_Commentary": "Aurora 클러스터를 상시 운영해야 하므로, 가끔만 사용하는 경우에는 유지 비용이 과도하게 듭니다.",
    "SelectB": "Amazon Redshift 클러스터를 생성하고, Redshift Spectrum을 통해 S3 버킷에 있는 데이터에 직접 SQL 쿼리를 실행합니다.",
    "SelectB_Commentary": "Redshift 클러스터 자체 유지 비용이 크고, 가끔 쓰는 작업에 비해 과도한 자원 할당이 발생할 수 있습니다.",
    "SelectC": "AWS Glue crawler를 생성하여 S3 버킷에 대한 테이블 메타데이터를 저장하고 가져옵니다. Amazon Athena를 사용해 S3 버킷의 데이터에 직접 SQL 쿼리를 실행합니다.",
    "SelectC_Commentary": "서버리스로 필요할 때만 비용을 지불하며, Glue crawler와 Athena 조합으로 Parquet 데이터를 간편하고 저렴하게 분석 가능합니다.",
    "SelectD": "Amazon EMR 클러스터를 생성하고, Apache Spark SQL을 사용하여 S3 버킷에 있는 데이터에 직접 SQL 쿼리를 실행합니다.",
    "SelectD_Commentary": "EMR 클러스터를 구성·관리해야 하며, 간헐적 사용에 비해 인프라 운용 비용이 높아집니다.",
    "Question_Description_recommedations": [
      "Q975",
      "Q799",
      "Q88",
      "Q167",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q449",
      "Q435",
      "Q411"
    ],
    "SelectB_recommedations": [
      "Q31",
      "Q449",
      "Q167"
    ],
    "SelectC_recommedations": [
      "Q993",
      "Q469",
      "Q829"
    ],
    "SelectD_recommedations": [
      "Q652",
      "Q449",
      "Q993"
    ]
  },
  {
    "Question_Number": "Q789",
    "Question_Description": "한 회사가 AWS CloudFormation 스택을 통해 Inline Policy나 정책에 \"*\"가 포함된 AWS Identity and Access Management(IAM) 리소스를 배포하지 못하도록 해야 합니다. 또한 Amazon EC2 인스턴스에 Public IP 주소를 사용하는 배포도 금지해야 합니다. 이 회사는 AWS Organizations에서 AWS Control Tower를 사용 중입니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133025-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 보안 위험을 미연에 차단하기 위한 AWS Control Tower 사용 방법을 묻습니다. Inline Policy 또는 ‘*’ 권한이 포함된 IAM 리소스를 배포하거나, Public IP를 사용하는 EC2 인스턴스를 허용하지 않도록 해야 합니다. Detective Controls는 사후에 감지하거나 교정하는 방식인 반면, Proactive Controls는 애초 배포 자체를 차단할 수 있습니다. 따라서 배포 전 단계에서 리소스가 제한 사항을 위배하는지 검사하고, 위배 시 즉시 차단할 수 있는 Proactive Controls가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "IAM 리소스 제한",
      "Inline Policy 제한",
      "EC2 Public IP 금지",
      "AWS Control Tower",
      "Proactive Controls",
      "Detective Controls",
      "Service Control Policy(SCP)"
    ],
    "Terms": [
      "AWS CloudFormation",
      "AWS Identity and Access Management (IAM)",
      "Inline Policy",
      "Amazon EC2",
      "Public IP addresses",
      "AWS Control Tower",
      "AWS Organizations",
      "AWS Config",
      "AWS Systems Manager Session Manager",
      "service control policy (SCP)",
      "Detective controls",
      "Proactive controls"
    ],
    "SelectA": "AWS Control Tower Proactive Controls를 사용하여 Public IP 주소가 있는 EC2 인스턴스와 Inline Policy에 ‘*’ 권한이 있는 IAM 리소스 배포를 차단합니다.",
    "SelectA_Commentary": "Proactive Controls로 배포 단계에서 즉시 검사하고 차단하기 때문에 가장 효과적이며, 보안 요구사항을 사전에 충족할 수 있습니다.",
    "SelectB": "AWS Control Tower Detective Controls를 사용하여 Public IP 주소가 있는 EC2 인스턴스와 Inline Policy에 ‘*’ 권한이 있는 IAM 리소스 배포를 차단합니다.",
    "SelectB_Commentary": "Detective Controls는 사후 모니터링용으로, 이미 생성된 리소스에 대해 위반 사항을 찾아내는 방식이므로 사전 차단에는 적합하지 않습니다.",
    "SelectC": "AWS Config 규칙을 만들어 EC2 및 IAM 규정 준수를 검사하고, 미준수 시 AWS Systems Manager Session Manager 오토메이션으로 해당 리소스를 삭제하도록 구성합니다.",
    "SelectC_Commentary": "AWS Config는 사후 감지 및 교정에 중점을 두어, 리소스가 이미 배포된 후에야 수정 조치를 취합니다. 즉각적으로 배포를 막기에는 적합하지 않습니다.",
    "SelectD": "Service Control Policy(SCP)를 사용하여 비준수 상태를 유발하는 EC2 및 IAM 작업을 차단합니다.",
    "SelectD_Commentary": "SCP는 조직 전체 정책 제어에 유용하지만, Control Tower의 Proactive Controls처럼 배포 단계를 세밀하게 제어하기는 까다롭습니다. 또한 구성 및 유지보수가 복잡할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q96",
      "Q688",
      "Q494",
      "Q387",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q789",
      "Q96",
      "Q494"
    ],
    "SelectB_recommedations": [
      "Q789",
      "Q96",
      "Q494"
    ],
    "SelectC_recommedations": [
      "Q517",
      "Q222",
      "Q96"
    ],
    "SelectD_recommedations": [
      "Q494",
      "Q789",
      "Q96"
    ]
  },
  {
    "Question_Number": "Q790",
    "Question_Description": "한 회사의 웹 애플리케이션이 AWS Cloud에 호스팅되어 있으며, 최근 인기로 인해 웹 트래픽이 급증했습니다. 현재 이 웹 애플리케이션은 퍼블릭 서브넷에 위치한 단일 Amazon EC2 인스턴스에서 동작하며, 증가한 트래픽 수요를 처리하지 못하고 있습니다. 회사는 웹 애플리케이션을 재작성하지 않고도 고가용성과 확장성을 제공할 수 있는 솔루션이 필요합니다. 어떤 조합의 단계가 이러한 요구 사항을 충족할 수 있습니까? (2개를 고르시오.)",
    "Answer": "B,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133027-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 애플리케이션을 재작성하지 않고도 웹 트래픽 증가에 대응하기 위해 고가용성과 확장성을 확보하는 방법을 묻습니다. Amazon EC2 Auto Scaling을 사용해 여러 Availability Zone에서 인스턴스 수를 유연하게 늘리고 줄이며, Application Load Balancer를 퍼블릭 서브넷에 구성해 사용자 트래픽을 여러 인스턴스로 분산함으로써 높은 가용성과 확장성을 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "확장성",
      "Amazon EC2 Auto Scaling",
      "Application Load Balancer",
      "퍼블릭 서브넷",
      "프라이빗 서브넷"
    ],
    "Terms": [
      "AWS Cloud",
      "Amazon EC2",
      "퍼블릭 서브넷",
      "프라이빗 서브넷",
      "Auto Scaling",
      "NAT gateway",
      "Application Load Balancer",
      "Availability Zone",
      "Compute Optimized",
      "Memory Optimized"
    ],
    "SelectA": "기존 EC2 인스턴스를 더 큰 Compute Optimized 인스턴스로 교체합니다.",
    "SelectA_Commentary": "단일 인스턴스 규모만 키우는 것은 수직 확장으로 고가용성을 확보하기 어렵고, 트래픽이 상당히 증가하면 한계가 있습니다.",
    "SelectB": "프라이빗 서브넷에 다중 Availability Zone 구성으로 Amazon EC2 Auto Scaling을 설정합니다.",
    "SelectB_Commentary": "Auto Scaling을 통해 여러 인스턴스를 자동으로 확장하거나 축소하며, 여러 AZ에 분산 배포하여 장애에 대비할 수 있으므로 고가용성과 확장성을 달성할 수 있습니다.",
    "SelectC": "퍼블릭 서브넷에 NAT gateway를 구성하여 웹 요청을 처리합니다.",
    "SelectC_Commentary": "NAT gateway는 주로 내부 리소스가 외부에 액세스할 때 사용하는 것이며, 외부 요청(인바운드 트래픽)에 직접 대응하는 용도는 아닙니다.",
    "SelectD": "기존 EC2 인스턴스를 더 큰 Memory Optimized 인스턴스로 교체합니다.",
    "SelectD_Commentary": "메모리를 늘려도 트래픽 증가에 따른 수평 확장 및 고가용성을 보장하지 못하므로 요구 사항을 충족하기 어렵습니다.",
    "SelectE": "퍼블릭 서브넷에 Application Load Balancer를 구성하여 웹 트래픽을 분산합니다.",
    "SelectE_Commentary": "ALB를 사용하면 들어오는 트래픽을 여러 인스턴스로 분산하여 단일 인스턴스 과부하를 방지하고 고가용성을 높일 수 있습니다.",
    "Question_Description_recommedations": [
      "Q892",
      "Q194",
      "Q757",
      "Q244",
      "Q413"
    ],
    "SelectA_recommedations": [
      "Q194",
      "Q584",
      "Q757"
    ],
    "SelectB_recommedations": [
      "Q691",
      "Q595",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q230",
      "Q708",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectE_recommedations": [
      "Q545",
      "Q405",
      "Q357"
    ]
  },
  {
    "Question_Number": "Q791",
    "Question_Description": "한 회사가 AWS Lambda functions를 환경 변수와 함께 사용하고 있습니다. 회사는 개발자가 환경 변수를 평문으로 볼 수 없도록 하고 싶습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133030-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Lambda 환경 변수를 평문으로 노출하지 않도록 하는 방법을 묻습니다. AWS Key Management Service(AWS KMS) 내부 키를 이용해 환경 변수를 암호화하면, 개발자가 평문으로 확인하지 못하도록 할 수 있습니다. Lambda에서 제공하는 encryption helpers를 이용해 KMS로 암호화·복호화 과정을 처리하여 안전하게 환경 변수를 관리하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "AWS Lambda",
      "환경 변수",
      "개발자 접근 제한",
      "암호화"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon EC2",
      "AWS CloudHSM",
      "SSL encryption",
      "AWS Certificate Manager (ACM)",
      "AWS Key Management Service (AWS KMS)",
      "Encryption helpers",
      "Environment variables"
    ],
    "SelectA": "Lambda functions 대신 Amazon EC2 인스턴스로 코드를 배포합니다.",
    "SelectA_Commentary": "단순히 EC2로 이전하는 것은 환경 변수 노출 문제를 근본적으로 해결하지 않으며, 추가 운영 부담도 발생합니다.",
    "SelectB": "Lambda functions에 대해 SSL encryption을 구성하고 AWS CloudHSM을 사용해 환경 변수를 저장 및 암호화합니다.",
    "SelectB_Commentary": "SSL은 전송 구간 암호화에 초점이 맞춰져 있으며, CloudHSM으로 Lambda 환경 변수를 직접 암호화하는 일반적인 방법은 아닙니다.",
    "SelectC": "AWS Certificate Manager(ACM)에서 인증서를 생성하고 Lambda functions에서 해당 인증서를 사용해 환경 변수를 암호화하도록 구성합니다.",
    "SelectC_Commentary": "ACM 인증서는 주로 HTTPS 통신 등을 위한 것이며, Lambda 환경 변수 암호화 기능에 직접 연결되지 않습니다.",
    "SelectD": "AWS Key Management Service(AWS KMS) 키를 생성하고, Lambda functions에 encryption helpers를 활성화하여 이 KMS 키로 환경 변수를 저장 및 암호화합니다.",
    "SelectD_Commentary": "AWS KMS를 사용하면 Lambda 환경 변수를 안전하게 암호화할 수 있으며, 개발자는 평문을 볼 수 없도록 제한할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q936",
      "Q289",
      "Q34",
      "Q898",
      "Q159"
    ],
    "SelectA_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q855",
      "Q913"
    ],
    "SelectC_recommedations": [
      "Q791",
      "Q550",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q640",
      "Q916",
      "Q550"
    ]
  },
  {
    "Question_Number": "Q792",
    "Question_Description": "한 분석 회사가 Amazon VPC를 사용하여 여러 계층(multi-tier) 서비스를 운영하고 있습니다. 이 회사는 RESTful API를 통해 수백만 명의 사용자에게 웹 분석 서비스를 제공하고자 합니다. 사용자들은 API에 접근하기 위해 인증 서비스를 통해 검증을 받아야 합니다. 가장 운영 효율성이 높은 방법은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133031-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 많은 사용자를 대상으로 하는 안전하고 편리한 인증 방식을 찾는 상황입니다. Amazon Cognito user pool을 사용하면 사용자 관리와 인증 과정을 간단하게 처리할 수 있고, API Gateway의 Cognito authorizer로 연동하여 RESTful API에 손쉽게 적용 가능합니다. 이는 서버리스 아키텍처로서 확장성과 관리 편의성 측면에서 높은 운영 효율성을 제공합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "RESTful API",
      "인증 서비스",
      "운영 효율성",
      "Amazon Cognito",
      "Amazon API Gateway"
    ],
    "Terms": [
      "Amazon VPC",
      "RESTful API",
      "Amazon Cognito user pool",
      "Amazon Cognito identity pool",
      "Amazon API Gateway REST APIs",
      "Amazon API Gateway HTTP APIs",
      "Cognito authorizer",
      "AWS Lambda",
      "Lambda authorizer",
      "IAM user",
      "IAM authorizer"
    ],
    "SelectA": "Amazon Cognito user pool을 설정하여 사용자 인증을 처리하고, Amazon API Gateway REST APIs를 Cognito authorizer와 연동합니다.",
    "SelectA_Commentary": "Cognito user pool은 사용자 가입, 로그인, 토큰 발급을 모두 관리하며, REST API와 결합하면 안전하고 운영 부담이 적습니다. 대규모 사용자 인증 요구사항을 효율적으로 충족시킵니다.",
    "SelectB": "Amazon Cognito identity pool을 설정하여 사용자 인증을 처리하고, Amazon API Gateway HTTP APIs를 Cognito authorizer와 연동합니다.",
    "SelectB_Commentary": "Identity pool은 주로 임시 AWS 자격 증명 발급에 적합하며 직접적인 사용자 인증 관리가 목적일 때는 user pool이 더 알맞습니다.",
    "SelectC": "AWS Lambda 함수를 구성하여 사용자 인증을 처리하고, Amazon API Gateway REST APIs에 Lambda authorizer를 구현합니다.",
    "SelectC_Commentary": "Lambda authorizer를 통해 맞춤형 인증 로직을 구성할 수 있지만, 고도화와 유지 관리에 추가 노력이 필요해 운영 효율이 떨어질 수 있습니다.",
    "SelectD": "IAM user를 구성하여 사용자 인증을 처리하고, Amazon API Gateway HTTP APIs에 IAM authorizer를 적용합니다.",
    "SelectD_Commentary": "IAM user는 다수의 인터넷 사용자 인증 용도로 설계되지 않았으며, 대규모 사용자 직접 관리는 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q15",
      "Q950",
      "Q468",
      "Q91",
      "Q254"
    ],
    "SelectA_recommedations": [
      "Q200",
      "Q366",
      "Q1011"
    ],
    "SelectB_recommedations": [
      "Q200",
      "Q366",
      "Q1011"
    ],
    "SelectC_recommedations": [
      "Q159",
      "Q428",
      "Q791"
    ],
    "SelectD_recommedations": [
      "Q1019",
      "Q222",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q793",
    "Question_Description": "한 회사가 고객용 모바일 앱을 운영하고 있습니다. 앱의 데이터는 민감하며, 저장 시 항상 암호화되어야 합니다. 회사는 AWS Key Management Service(AWS KMS)를 사용하고 있습니다. 회사는 KMS key가 실수로 삭제되는 것을 방지하기 위한 솔루션이 필요합니다. 또한 사용자가 KMS key를 삭제하려고 시도할 때 Amazon Simple Notification Service(Amazon SNS)를 통해 관리자에게 이메일 알림을 보내야 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133032-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 KMS key가 실수로 삭제되는 것을 방지하면서, 사용자가 삭제를 시도할 때 Amazon SNS를 통해 관리자에게 통지하는 일을 자동화하는 방안을 묻습니다. 정답 솔루션은 추가적인 코드나 복잡한 설정 없이 자동으로 삭제를 취소하고 알림을 보낼 수 있어야 하므로, 운영 오버헤드를 최소화하는 선택지를 찾는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "KMS key",
      "AWS Key Management Service",
      "Amazon SNS",
      "이메일 알림",
      "실수로 삭제 방지",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS KMS",
      "KMS key",
      "Amazon SNS",
      "Amazon EventBridge",
      "AWS Config",
      "AWS Lambda",
      "Amazon CloudWatch",
      "AWS Systems Manager Automation",
      "AWS CloudTrail"
    ],
    "SelectA": "Amazon EventBridge 규칙을 생성해 사용자가 KMS key를 삭제하려고 할 때 반응하도록 합니다. AWS Config 규칙을 구성해 KMS key의 삭제를 취소하게 합니다. 이 AWS Config 규칙을 EventBridge 규칙의 대상(target)으로 추가합니다. 그리고 SNS 토픽을 생성해 관리자에게 알립니다.",
    "SelectA_Commentary": "AWS Config 규칙을 작성하고 EventBridge 규칙을 연계해야 하므로 다소 설정이 복잡할 수 있어, 운영 오버헤드가 증가할 수 있습니다.",
    "SelectB": "KMS key 삭제를 방지하기 위한 사용자 지정 로직을 가진 AWS Lambda 함수를 만듭니다. 사용자가 KMS key를 삭제하려고 할 때 활성화되는 Amazon CloudWatch 알람을 생성합니다. DeleteKey 작업이 수행될 때 Lambda 함수를 호출하도록 Amazon EventBridge 규칙을 생성합니다. SNS 토픽을 생성하고, EventBridge 규칙이 이 SNS로 메시지를 게시해 관리자에게 알리도록 구성합니다.",
    "SelectB_Commentary": "Lambda 함수를 직접 작성해 로직을 관리해야 하므로 운영적인 부담이 크고 구성 요소가 많아집니다.",
    "SelectC": "KMS DeleteKey 작업이 수행될 때 반응하는 Amazon EventBridge 규칙을 생성합니다. 규칙이 AWS Systems Manager Automation runbook을 시작하도록 구성합니다. runbook에서 KMS key의 삭제를 취소하도록 설정합니다. SNS 토픽을 생성하고, EventBridge 규칙에서 SNS 메시지를 게시해 관리자에게 알리도록 구성합니다.",
    "SelectC_Commentary": "사용자 지정 코드가 필요 없고, Systems Manager Automation이 자동으로 삭제를 취소해주므로 운영 및 관리가 단순합니다. 요구 사항을 가장 적은 오버헤드로 충족하는 솔루션입니다.",
    "SelectD": "AWS CloudTrail 트레일을 생성합니다. 트레일이 새롭게 만든 Amazon CloudWatch 로그 그룹으로 로그를 전송하도록 구성합니다. 해당 CloudWatch 로그 그룹에 대한 메트릭 필터를 기반으로 일정 기준을 만족할 때 동작하는 CloudWatch 알람을 생성합니다. KMS DeleteKey 작업이 실행될 때 Amazon SNS를 사용해 관리자에게 알리도록 알람을 구성합니다.",
    "SelectD_Commentary": "KMS key 삭제 시도를 알림 받을 수 있지만, 자동으로 삭제를 취소하는 기능은 없으므로 문제의 요구 사항을 완전히 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q916",
      "Q681",
      "Q640",
      "Q371",
      "Q929"
    ],
    "SelectA_recommedations": [
      "Q793",
      "Q916",
      "Q640"
    ],
    "SelectB_recommedations": [
      "Q640",
      "Q793",
      "Q550"
    ],
    "SelectC_recommedations": [
      "Q793",
      "Q916",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q793",
      "Q916",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q794",
    "Question_Description": "한 회사가 자사의 모바일 앱 사용 현황을 분석하고 보고서를 생성하기를 원합니다. 앱은 인기가 많으며 전 세계 사용자 기반을 가지고 있습니다. 회사는 애플리케이션 사용 현황을 분석하기 위해 커스텀 보고서 생성 프로그램을 사용합니다. 이 프로그램은 매월 마지막 주에 여러 보고서를 생성하며, 각 보고서 생성에는 10분 미만이 소요됩니다. 회사는 매월 마지막 주 이외에는 이 프로그램을 거의 사용하지 않습니다. 회사는 보고서가 요청될 때 가능한 한 빠르게 보고서를 생성하길 원합니다. 어떤 솔루션이 비용 효율적으로 이 요구사항을 만족시킬 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133033-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용 빈도가 낮고 실행 시간이 짧은 작업을 가장 경제적으로 처리하는 방법을 묻습니다. AWS Lambda는 사용한 만큼만 비용을 지불하므로, 간헐적이고 짧은 실행에 매우 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "모바일 앱",
      "전 세계 사용자",
      "커스텀 보고서 생성 프로그램",
      "월말 집중 사용",
      "10분 미만 실행",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Amazon EC2 Spot Instances",
      "AWS Lambda",
      "Amazon EventBridge",
      "Amazon Elastic Container Service (Amazon ECS)"
    ],
    "SelectA": "Amazon EC2 On-Demand Instances를 사용하여 프로그램을 실행합니다. 보고서가 요청될 때 Amazon EventBridge 규칙을 통해 EC2를 기동하고, 월말에는 EC2 인스턴스를 계속 구동합니다.",
    "SelectA_Commentary": "On-Demand Instances를 매월 마지막 주에 계속 구동하면 비용이 높아질 수 있어, 낮은 빈도로 실행되는 작업에는 비효율적입니다.",
    "SelectB": "AWS Lambda에서 프로그램을 실행합니다. 보고서가 요청될 때 Amazon EventBridge 규칙을 통해 Lambda 함수를 호출합니다.",
    "SelectB_Commentary": "실행 시간이 짧고 월말 외에는 거의 사용하지 않으므로, 사용한 시간만큼만 과금되는 Lambda가 비용과 운영 면에서 가장 효율적입니다.",
    "SelectC": "Amazon ECS에서 프로그램을 실행합니다. 보고서가 요청될 때 스케줄링하여 프로그램을 구동하도록 설정합니다.",
    "SelectC_Commentary": "ECS Fargate로 단발성 실행이 가능하지만 설정이 다소 복잡할 수 있습니다. Lambda 대비 짧은 실행에 대한 비용 효율성이 떨어질 수 있습니다.",
    "SelectD": "Amazon EC2 Spot Instances를 사용하여 프로그램을 실행합니다. 보고서가 요청될 때 Amazon EventBridge 규칙을 통해 인스턴스를 시작하고, 월말에는 인스턴스를 계속 구동합니다.",
    "SelectD_Commentary": "Spot Instances는 저렴하지만 중단 위험이 생길 수 있고, 월말에 계속 구동 시 비용이 누적될 수 있어 사용 패턴에 적합하지 않을 수 있습니다.",
    "Question_Description_recommedations": [
      "Q656",
      "Q997",
      "Q49",
      "Q630",
      "Q930"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q1008",
      "Q146"
    ],
    "SelectB_recommedations": [
      "Q807",
      "Q485",
      "Q770"
    ],
    "SelectC_recommedations": [
      "Q486",
      "Q728",
      "Q300"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q552",
      "Q1008"
    ]
  },
  {
    "Question_Number": "Q795",
    "Question_Description": "한 회사가 AWS Cloud에서 밀접하게 결합된 고성능 컴퓨팅(HPC) 환경을 설계하고 있습니다. 이 회사는 HPC 환경을 네트워킹 및 스토리지 측면에서 최적화할 수 있는 기능들을 포함해야 합니다. 다음 중 어떤 솔루션 조합이 이러한 요구 사항을 충족합니까? (두 가지를 선택하세요.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133034-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "본 문제는 밀접 결합형 HPC 환경에서 필요한 고성능 네트워킹과 고성능 스토리지를 어떻게 구성할지 묻고 있습니다. HPC 클러스터에서는 높은 대역폭과 낮은 지연을 제공하는 네트워크 연결(Elastic Fabric Adapter)과 동시에 대규모의 병렬 I/O를 지원하는 스토리지 솔루션(Amazon FSx for Lustre)을 활용하는 것이 핵심입니다. 이를 통해 데이터 집중형 혹은 계산 집중형 워크로드를 효율적으로 운영할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2"
    ],
    "Keywords": [
      "HPC 환경",
      "네트워킹 최적화",
      "스토리지 최적화",
      "고성능 컴퓨팅",
      "밀접 결합"
    ],
    "Terms": [
      "Elastic Fabric Adapter (EFA)",
      "Amazon FSx for Lustre",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "AWS Elastic Beanstalk",
      "Amazon EC2"
    ],
    "SelectA": "AWS Global Accelerator에서 accelerator를 생성합니다. accelerator에 대해 custom routing을 구성합니다.",
    "SelectA_Commentary": "글로벌 사용자를 위한 트래픽 가속 솔루션으로 HPC 내부 통신 최적화와는 거리가 있습니다.",
    "SelectB": "Amazon FSx for Lustre 파일 시스템을 생성합니다. 해당 파일 시스템을 scratch 스토리지로 구성합니다.",
    "SelectB_Commentary": "FSx for Lustre의 scratch 스토리지는 HPC 환경에서 대규모 병렬 I/O를 빠르게 처리하는 데 적합합니다.",
    "SelectC": "Amazon CloudFront 배포를 생성합니다. 뷰어 프로토콜 정책을 HTTP 및 HTTPS로 구성합니다.",
    "SelectC_Commentary": "CloudFront는 주로 콘텐츠 배포에 최적화된 서비스로 HPC 노드 간 밀접 연결에는 도움이 되지 않습니다.",
    "SelectD": "Amazon EC2 인스턴스를 시작하고 Elastic Fabric Adapter(EFA)를 인스턴스에 연결합니다.",
    "SelectD_Commentary": "EFA는 HPC 애플리케이션에 요구되는 높은 처리량과 낮은 지연의 네트워크 성능을 제공합니다.",
    "SelectE": "AWS Elastic Beanstalk 배포를 생성하여 환경을 관리합니다.",
    "SelectE_Commentary": "Elastic Beanstalk는 웹 애플리케이션에 집중된 관리형 서비스로 HPC 환경 구성에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q857",
      "Q646",
      "Q162",
      "Q631",
      "Q361"
    ],
    "SelectA_recommedations": [
      "Q352",
      "Q361",
      "Q704"
    ],
    "SelectB_recommedations": [
      "Q99",
      "Q407",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q361",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q857",
      "Q746",
      "Q620"
    ],
    "SelectE_recommedations": [
      "Q746",
      "Q361",
      "Q695"
    ]
  },
  {
    "Question_Number": "Q796",
    "Question_Description": "회사는 원치 않는 콘텐츠가 포함된 사진이 회사의 웹 애플리케이션에 업로드되지 않도록 방지하는 솔루션을 필요로 합니다. 이 솔루션은 Machine Learning(ML) 모델을 직접 학습시키지 않아야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133035-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon Rekognition은 사전에 학습된 서비스를 사용하므로 ML 모델을 따로 학습할 필요가 없으며, 사진에서 부적절한 콘텐츠를 효율적으로 식별해 보안 요구사항을 충족시킵니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "원치 않는 콘텐츠 필터링",
      "사진 업로드 방지",
      "ML 모델 미학습",
      "Amazon Rekognition"
    ],
    "Terms": [
      "Amazon SageMaker Autopilot",
      "AWS Lambda",
      "Amazon Rekognition",
      "Lambda function URL",
      "Amazon CloudFront function",
      "Amazon Comprehend",
      "Amazon Rekognition Video"
    ],
    "SelectA": "Amazon SageMaker Autopilot를 사용하여 모델을 생성 및 배포합니다. 실시간 엔드포인트를 생성하여 새로운 사진이 업로드될 때 웹 애플리케이션이 이를 호출합니다.",
    "SelectA_Commentary": "새로운 ML 모델을 학습하는 방식으로, 문제에서 요구하는 '모델 학습 없이'라는 조건을 충족하지 못합니다.",
    "SelectB": "AWS Lambda 함수를 생성하고 Amazon Rekognition을 사용하여 원치 않는 콘텐츠를 감지합니다. 새로운 사진이 업로드될 때 웹 애플리케이션이 Lambda function URL을 호출하도록 구성합니다.",
    "SelectB_Commentary": "Amazon Rekognition은 사전 학습된 모델이므로 별도 모델 학습이 필요 없으며 사진 분석에 적합한 방식으로 요구사항을 충족합니다.",
    "SelectC": "Amazon CloudFront function을 생성하고 Amazon Comprehend를 사용하여 원치 않는 콘텐츠를 감지합니다. 이 function을 웹 애플리케이션에 연결합니다.",
    "SelectC_Commentary": "Amazon Comprehend는 텍스트 분석 서비스로 이미지를 분석할 수 없으므로 요구사항에 부합하지 않습니다.",
    "SelectD": "AWS Lambda 함수를 생성하고 Amazon Rekognition Video를 사용하여 원치 않는 콘텐츠를 감지합니다. 새로운 사진이 업로드될 때 웹 애플리케이션이 Lambda function URL을 호출하도록 구성합니다.",
    "SelectD_Commentary": "Amazon Rekognition Video는 동영상 분석용 서비스로, 사진만 처리해야 하는 요구사항과 일치하지 않습니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q665",
      "Q57",
      "Q122",
      "Q850"
    ],
    "SelectA_recommedations": [
      "Q831",
      "Q548",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q172",
      "Q791",
      "Q291"
    ],
    "SelectD_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ]
  },
  {
    "Question_Number": "Q797",
    "Question_Description": "한 회사는 AWS를 사용하여 전자상거래 플랫폼을 운영하고 있습니다. 이 플랫폼은 회사의 핵심적인 운영에 해당하며 매우 높은 트래픽과 거래를 처리합니다. 회사는 AWS 계정의 root user 자격 증명을 보호하기 위해 multi-factor authentication(MFA) 기기를 설정했습니다. 회사는 이 MFA 기기를 분실하더라도 root user 계정에 대한 액세스를 잃지 않도록 하고 싶습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133036-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회사의 핵심 운영을 담당하는 AWS 계정을 안전하게 보호하면서, MFA 기기 분실 시에도 root user 계정에 접근할 수 있는 방법을 묻습니다. 정답은 root user에게 추가 MFA 기기를 설정하는 방법입니다. 이를 통해 언제든지 여분의 MFA를 사용해 루트 계정에 접근 가능하므로, 단일 MFA 기기 분실의 위험을 효과적으로 대비할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "root user 계정",
      "MFA 기기 분실",
      "액세스 보장",
      "백업 MFA"
    ],
    "Terms": [
      "AWS",
      "root user",
      "multi-factor authentication(MFA)",
      "administrator account",
      "IAM user",
      "credentials"
    ],
    "SelectA": "MFA 기기를 분실했을 때 로그인을 위해 사용할 backup administrator account를 설정한다.",
    "SelectA_Commentary": "backup administrator account만으로는 root user 계정 잠금 시 문제를 해결하기 어렵고, 루트 계정 권한을 완전히 대체하기도 어렵습니다.",
    "SelectB": "root user 계정에 여러 개의 MFA 기기를 등록하여 재해 상황에 대비한다.",
    "SelectB_Commentary": "루트 사용자에게 다중 MFA를 설정하면 하나를 분실해도 다른 MFA로 인증할 수 있어 루트 계정에 대한 액세스를 잃지 않습니다.",
    "SelectC": "root 계정에 접근할 수 없을 때 새 administrator account를 생성한다.",
    "SelectC_Commentary": "root 계정에 접근할 수 없으면 새 관리자 계정도 생성하기가 어려워 실질적인 대책이 되기 어렵습니다.",
    "SelectD": "root 계정에 접근할 수 없을 경우 다른 IAM user에게 administrator policy를 부여한다.",
    "SelectD_Commentary": "이미 루트 계정 자체에 접근 불가 상황인데 다른 IAM user에 권한을 부여해도 루트 사용자 권한을 대체하기가 쉽지 않습니다.",
    "Question_Description_recommedations": [
      "Q745",
      "Q233",
      "Q878",
      "Q222",
      "Q780"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q797",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q797",
      "Q233",
      "Q745"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q332",
      "Q774"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q429",
      "Q423"
    ]
  },
  {
    "Question_Number": "Q798",
    "Question_Description": "한 소셜 미디어 회사가 사용자들을 위한 보상 프로그램 웹사이트를 만들고 있습니다. 사용자가 웹사이트에 동영상을 생성해서 업로드할 때마다 회사는 사용자에게 포인트를 부여합니다. 사용자는 이 포인트를 회사의 제휴 파트너에게서 제공받는 선물이나 할인으로 교환할 수 있습니다. 고유 ID가 사용자를 식별하며, 파트너는 보상을 검증하기 위해 이 ID를 참조합니다. 파트너들은 회사가 사용자에게 포인트를 부여할 때, 사용자 ID를 HTTP endpoint로 알림받고 싶어 합니다. 매일 수백 개가 넘는 업체들이 제휴 파트너로 등록하기를 희망합니다. 회사는 새로운 파트너를 신속하고 확장 가능하게 추가할 수 있는 아키텍처를 설계하고자 합니다. 운영상 구현 노력을 최소화하면서 이를 달성할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/133037-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 신규 파트너를 빠르게 추가하고, HTTP endpoint로 사용자 ID 알림을 전송해야 하는 확장 가능한 아키텍처 설계를 묻습니다. 최소한의 구현 노력으로 다수 파트너에게 메시지를 전달할 수 있는 Amazon SNS가 최적의 선택입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "보상 프로그램",
      "HTTP endpoint",
      "확장성",
      "Amazon SNS topic"
    ],
    "Terms": [
      "Amazon Timestream",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "HTTP endpoint",
      "AWS Step Functions",
      "Amazon Kinesis Data Streams"
    ],
    "SelectA": "Amazon Timestream 데이터베이스를 생성해 제휴 파트너 목록을 저장합니다. AWS Lambda 함수를 구현해 해당 목록을 읽고, 회사가 사용자에게 포인트를 부여할 때 Lambda 함수가 각 파트너에게 사용자 ID를 전송하도록 구성합니다.",
    "SelectA_Commentary": "파트너 증가 시 Lambda 설정과 파트너 목록 관리가 복잡해져 확장성 측면에서 부담이 큽니다.",
    "SelectB": "Amazon Simple Notification Service(Amazon SNS) topic을 생성합니다. endpoint 프로토콜을 선택하고, 파트너를 topic에 구독시킵니다. 회사가 사용자에게 포인트를 부여할 때 topic에 사용자 ID를 발행(publish)합니다.",
    "SelectB_Commentary": "SNS topic을 통해 파트너들은 쉽고 빠르게 구독할 수 있으며, 한 번의 발행으로 모두에게 알림을 전달해 확장성과 구현 편의성이 우수합니다.",
    "SelectC": "AWS Step Functions state machine을 생성합니다. 각 제휴 파트너용 태스크를 생성하고, 회사가 사용자에게 포인트를 부여할 때 사용자 ID를 인풋으로 state machine을 호출합니다.",
    "SelectC_Commentary": "파트너마다 태스크를 관리해야 하므로 늘어나는 파트너 수에 따라 작업 흐름이 복잡해지고 유지보수 비용이 커집니다.",
    "SelectD": "Amazon Kinesis Data Streams에 data stream을 생성합니다. 프로듀서와 컨슈머 애플리케이션을 구현하고, data stream에 제휴 파트너 목록을 저장합니다. 회사가 사용자에게 포인트를 부여할 때 사용자 ID를 전송합니다.",
    "SelectD_Commentary": "Kinesis 기반 구성은 직접 애플리케이션을 개발해야 하며, HTTP endpoint 구독 기능도 별도 구현이 필요해 작업량과 관리 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q567",
      "Q362",
      "Q51",
      "Q149",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q531",
      "Q404"
    ],
    "SelectB_recommedations": [
      "Q148",
      "Q636",
      "Q489"
    ],
    "SelectC_recommedations": [
      "Q18",
      "Q81",
      "Q351"
    ],
    "SelectD_recommedations": [
      "Q845",
      "Q798",
      "Q10"
    ]
  },
  {
    "Question_Number": "Q799",
    "Question_Description": "한 회사가 Amazon S3 버킷에 텍스트 파일 형태로 저장된 레시피 기록에서 재료 이름을 추출해야 합니다. 웹 애플리케이션은 추출된 재료 이름을 사용하여 Amazon DynamoDB 테이블을 조회하고 영양 점수를 결정합니다. 애플리케이션은 비식품 기록이나 오류 역시 처리할 수 있습니다. 이 솔루션을 개발하기 위해 머신 러닝 지식이 있는 직원은 없습니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 방법은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135257-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 주된 의도는 텍스트 파일에서 재료 이름을 추출하여 DynamoDB를 조회하는 과정을 최소한의 비용과 전문 지식으로 구현하는 것입니다. Amazon Comprehend는 자연어 처리를 위해 사전 학습된 모델을 제공하므로 쉽게 적용 가능하며, 서버리스 서비스인 AWS Lambda와 S3 Event Notifications를 연계해 자동화하면 운영 비용과 복잡도를 모두 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "레시피 기록",
      "재료 이름 추출",
      "비용 효율",
      "AWS Lambda",
      "Amazon Comprehend",
      "Amazon DynamoDB",
      "S3 Event Notifications"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Lambda",
      "Amazon Comprehend",
      "Amazon DynamoDB",
      "Amazon EventBridge",
      "Amazon Forecast",
      "Amazon Polly",
      "Amazon SNS",
      "Amazon SageMaker",
      "S3 Event Notifications"
    ],
    "SelectA": "S3 Event Notifications를 사용하여 PutObject 요청이 발생할 때 AWS Lambda 함수를 호출합니다. Lambda 함수에서 Amazon Comprehend를 통해 객체를 분석하고 재료 이름을 추출하도록 프로그래밍합니다. 그 결과를 Amazon DynamoDB 테이블에 저장합니다.",
    "SelectA_Commentary": "Amazon Comprehend는 텍스트에서 엔티티를 손쉽게 추출할 수 있어 머신 러닝 지식 없이도 빠르고 간단하게 구현 가능합니다. 서버리스 함수인 Lambda와 연계하면 사용한 만큼만 비용을 지불하므로 비용 효율이 뛰어납니다.",
    "SelectB": "Amazon EventBridge 규칙을 사용하여 PutObject 요청이 발생할 때 AWS Lambda 함수를 호출합니다. Lambda 함수에서 Amazon Forecast를 사용하여 객체를 분석하고 재료 이름을 추출하도록 프로그래밍합니다. 예측 결과를 Amazon DynamoDB 테이블에 저장합니다.",
    "SelectB_Commentary": "Amazon Forecast는 시계열 예측 서비스로, 텍스트 추출 작업에 부적합하며 비용 효율성도 떨어집니다.",
    "SelectC": "S3 Event Notifications를 사용하여 PutObject 요청이 발생할 때 AWS Lambda 함수를 호출합니다. Amazon Polly로 레시피 기록의 오디오 파일을 생성하고, 이 파일을 S3 버킷에 저장합니다. Amazon SNS를 사용해 메시지로 파일 URL을 직원들에게 전송하고, 직원들에게 오디오를 듣고 영양 점수를 계산하도록 합니다. 재료 이름을 Amazon DynamoDB 테이블에 저장합니다.",
    "SelectC_Commentary": "오디오로 변환 후 사람이 직접 분석해야 하므로 자동화 목표에도 맞지 않고, 인건비와 시간이 들어 비효율적입니다.",
    "SelectD": "Amazon EventBridge 규칙을 사용하여 PutObject 요청이 발생할 때 AWS Lambda 함수를 호출합니다. Lambda 함수에서 Amazon SageMaker를 사용하여 객체를 분석하고 재료 이름을 추출하도록 프로그래밍합니다. 추론 결과를 Amazon DynamoDB 테이블에 저장합니다.",
    "SelectD_Commentary": "Amazon SageMaker는 ML 모델을 직접 개발·훈련해야 하는 경우가 많아 전문 지식 및 추가 비용이 필요하며, 간단한 텍스트 추출 작업에는 과도한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q79",
      "Q348",
      "Q469",
      "Q829",
      "Q498"
    ],
    "SelectA_recommedations": [
      "Q799",
      "Q993",
      "Q469"
    ],
    "SelectB_recommedations": [
      "Q196",
      "Q348",
      "Q79"
    ],
    "SelectC_recommedations": [
      "Q799",
      "Q469",
      "Q829"
    ],
    "SelectD_recommedations": [
      "Q799",
      "Q79",
      "Q348"
    ]
  },
  {
    "Question_Number": "Q800",
    "Question_Description": "한 회사가 주 AWS 계정(VPC 환경)에서 실행될 AWS Lambda 함수를 만들어야 합니다. 이 Lambda 함수는 보조 AWS 계정에 있는 Amazon Elastic File System(Amazon EFS) 파일 시스템에 저장된 파일에 접근해야 합니다. 회사가 파일을 추가할 때 솔루션은 수요에 맞춰 확장 가능해야 하며, 비용 효율이 가장 중요한 요구사항입니다. 어떤 솔루션이 이 요구사항을 가장 비용 효율적으로 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135258-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "VPC Peering을 통해 다른 계정에 있는 EFS에 직접 접근하면 중복 저장 없이 안전하며, 가장 비용 효율적인 확장성을 확보할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "Lambda 함수",
      "VPC Peering",
      "Amazon EFS",
      "파일 시스템",
      "비용 효율"
    ],
    "Terms": [
      "AWS Lambda",
      "VPC",
      "Amazon EFS",
      "AWS DataSync",
      "VPC Peering",
      "Lambda Layer"
    ],
    "SelectA": "주 계정에 새로운 EFS 파일 시스템을 생성하고 AWS DataSync를 사용해 기존 EFS 파일 시스템의 내용을 복사합니다.",
    "SelectA_Commentary": "별도의 EFS 복제에 따른 비용과 운영 복잡성이 증가하여 가장 비용 효율적이지 않습니다.",
    "SelectB": "주 계정과 보조 계정의 VPC 간에 VPC Peering 연결을 생성합니다.",
    "SelectB_Commentary": "VPC Peering을 통해 두 계정 간 안전하고 직접적인 네트워크 트래픽이 가능해 추가 복제 비용 없이 접근할 수 있어 정답입니다.",
    "SelectC": "보조 계정에 파일 시스템이 마운트된 두 번째 Lambda 함수를 만들고, 주 계정의 Lambda 함수가 이를 호출하도록 합니다.",
    "SelectC_Commentary": "Lambda 호출 체인을 추가로 구성해야 하므로 복잡도가 증가하고 관리 오버헤드가 높습니다.",
    "SelectD": "파일 시스템의 내용을 Lambda Layer로 옮기고, 해당 Lambda Layer 사용 권한을 보조 계정에 부여합니다.",
    "SelectD_Commentary": "Lambda Layer는 코드나 라이브러리 공유에 주로 사용됩니다. 대규모 파일 접근에는 적합하지 않아 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q770",
      "Q882",
      "Q417",
      "Q277",
      "Q822"
    ],
    "SelectA_recommedations": [
      "Q867",
      "Q703",
      "Q167"
    ],
    "SelectB_recommedations": [
      "Q374",
      "Q860",
      "Q471"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q656",
      "Q630"
    ],
    "SelectD_recommedations": [
      "Q807",
      "Q728",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q801",
    "Question_Description": "한 금융 회사가 매우 민감한 데이터를 Amazon S3 버킷에 저장해야 합니다. 이 회사는 데이터가 전송 중(in transit)과 저장 시(at rest)에 모두 암호화되기를 원합니다. 또한 암호화 키는 AWS 클라우드 외부에서 직접 관리해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135259-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터 전송 중과 저장 시 모두 암호화를 보장하되, 암호화 키를 AWS 외부에서 관리해야 하는 요구 사항을 해결하는 솔루션을 묻습니다. SSE-KMS는 KMS를 활용하므로 키가 AWS 내부에 존재합니다. 유일하게 회사 측에서 키를 소유 및 제어할 수 있는 방법은 회사 자체 데이터 센터에서 암호화한 후 S3에 업로드하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 데이터",
      "암호화",
      "AWS 클라우드 외부",
      "Amazon S3 버킷",
      "전송 중(in transit) 암호화",
      "저장 시(at rest) 암호화"
    ],
    "Terms": [
      "Amazon S3",
      "Server-side encryption (SSE)",
      "AWS Key Management Service (AWS KMS)",
      "Client-side encryption",
      "SSE-KMS",
      "Encryption key management"
    ],
    "SelectA": "AWS KMS의 customer managed key를 사용한 server-side encryption (SSE)로 S3 버킷의 데이터를 암호화합니다.",
    "SelectA_Commentary": "customer managed key여도 AWS KMS에 키가 존재하므로 회사가 키를 온프레미스에서 완전히 관리할 수 없습니다.",
    "SelectB": "AWS KMS의 AWS managed key를 사용한 server-side encryption (SSE)로 S3 버킷의 데이터를 암호화합니다.",
    "SelectB_Commentary": "AWS managed key는 AWS에서 키를 전적으로 관리하므로 회사가 외부에서 직접 관리하는 것과는 거리가 있습니다.",
    "SelectC": "기본 server-side encryption (SSE)로 S3 버킷의 데이터를 암호화합니다.",
    "SelectC_Commentary": "기본 SSE 역시 AWS에서 키를 관리하므로 클라우드 외부에 키를 완전히 두는 요구 사항을 충족하지 못합니다.",
    "SelectD": "회사의 데이터 센터에서 먼저 데이터를 암호화한 다음, 암호화된 데이터를 S3 버킷에 저장합니다.",
    "SelectD_Commentary": "회사 자체 시스템에서 암호화 키를 직접 제어 및 관리하므로 AWS 클라우드 외부 키 관리 요구 사항을 충족하며 전송 중과 저장 시 모두 암호화가 가능합니다.",
    "Question_Description_recommedations": [
      "Q109",
      "Q965",
      "Q862",
      "Q270",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q640",
      "Q681",
      "Q36"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q640",
      "Q916"
    ],
    "SelectC_recommedations": [
      "Q740",
      "Q678",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q802",
    "Question_Description": "한 회사가 결제 애플리케이션을 AWS에서 운영하고 싶어 합니다. 이 애플리케이션은 모바일 디바이스로부터 결제 알림을 받아야 하며, 결제 알림은 간단한 검증 후 추가 처리를 위해 전송됩니다. 백엔드 처리 애플리케이션은 오래 실행되며 처리 과정에서 컴퓨팅 및 메모리 조정이 필요합니다. 회사는 인프라 관리를 원치 않습니다. 가장 적은 오퍼레이셔널 오버헤드를 요구사항으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135260-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모바일 디바이스에서 오는 결제 알림을 간단히 검증한 뒤 서버 측에서 대기 시간이 긴 처리를 수행하는 아키텍처를 선택하는 상황입니다. 인프라를 직접 관리하고 싶지 않고, 오퍼레이셔널 오버헤드를 최소화해야 한다는 점이 핵심입니다. 서버리스 기반의 AWS Lambda와 컨테이너 서비스인 Amazon ECS를 Fargate로 구성하면 확장성과 관리 편의성을 모두 확보할 수 있으므로 정답입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "인프라 관리 최소화",
      "서버리스",
      "AWS Fargate",
      "Amazon ECS",
      "AWS Lambda",
      "결제 알림",
      "오퍼레이셔널 오버헤드"
    ],
    "Terms": [
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon EventBridge",
      "Amazon API Gateway",
      "AWS Step Functions",
      "AWS Lambda",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Amazon EKS Anywhere",
      "Amazon EC2 Spot Instances",
      "Amazon Spot Fleet",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate"
    ],
    "SelectA": "Amazon SQS 큐를 생성하고, Amazon EventBridge 규칙을 사용해 모바일 디바이스에서 결제 알림을 받습니다. 결제 알림 검증 후 백엔드 애플리케이션으로 전송합니다. 백엔드 애플리케이션은 Amazon EKS Anywhere에 배포하여 독립형 클러스터를 생성합니다.",
    "SelectA_Commentary": "Amazon EKS Anywhere를 자체 클러스터로 운영하면 서버 관리가 여전히 필요합니다. 인프라를 직접 운영하므로 오퍼레이셔널 오버헤드가 높습니다.",
    "SelectB": "Amazon API Gateway API를 생성하고 AWS Step Functions 스테이트 머신과 통합하여 모바일 디바이스에서 결제 알림을 받습니다. 스테이트 머신을 호출해 결제 알림을 검증 후 백엔드 애플리케이션으로 전송합니다. 백엔드 애플리케이션은 Amazon EKS에 배포하고 자체 관리 노드로 구성합니다.",
    "SelectB_Commentary": "Amazon EKS에 자체 관리 노드를 사용하면 여전히 운영 및 노드 관리를 직접 수행해야 합니다. 완전한 서버리스보다 오버헤드가 큽니다.",
    "SelectC": "Amazon SQS 큐를 생성하고, Amazon EventBridge 규칙을 사용해 모바일 디바이스에서 결제 알림을 받습니다. 결제 알림 검증 후 백엔드 애플리케이션으로 전송합니다. 백엔드 애플리케이션은 Amazon EC2 Spot Instances상에서 실행하며, Spot Fleet을 디폴트 할당 전략으로 구성합니다.",
    "SelectC_Commentary": "Spot Instances는 비용 절감은 가능하지만 서버 관리는 여전히 필요합니다. 노드 중단 시 대응 전략도 추가로 고려해야 해 오퍼레이셔널 오버헤드가 높습니다.",
    "SelectD": "Amazon API Gateway API를 생성하고 AWS Lambda와 통합해 모바일 디바이스에서 결제 알림을 받습니다. Lambda 함수를 호출해 결제 알림을 검증 후 백엔드 애플리케이션으로 전송합니다. 백엔드 애플리케이션은 Amazon ECS에 배포하고, AWS Fargate 런치 타입으로 구성합니다.",
    "SelectD_Commentary": "API Gateway + Lambda 조합으로 서버리스 검증을 수행하고, Fargate로 컨테이너를 운영해 인프라 관리 부담이 최소화됩니다. 확장성, 비용 측면에서 모두 유리한 최적 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q149",
      "Q163",
      "Q519",
      "Q786",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q67",
      "Q569",
      "Q996"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q775",
      "Q207"
    ],
    "SelectC_recommedations": [
      "Q944",
      "Q67",
      "Q203"
    ],
    "SelectD_recommedations": [
      "Q739",
      "Q207",
      "Q10"
    ]
  },
  {
    "Question_Number": "Q803",
    "Question_Description": "한 솔루션스 아키텍트가 한 회사의 사용자 인증 솔루션을 설계하고 있습니다. 이 솔루션은 불규칙한 지리적 위치, IP 주소 또는 디바이스에서 로그인하는 사용자에게 2단계 인증을 적용해야 합니다. 또한 이 솔루션은 수백만 명의 사용자를 수용할 수 있도록 확장 가능해야 합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135472-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "위험 기반 적응형 인증이 가능하고 수백만 명의 사용자 규모까지 확장할 수 있는 방안을 찾는 문제입니다. Amazon Cognito user pools는 위험도를 토대로 MFA를 유연하게 적용할 수 있어 요구사항에 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "2단계 인증",
      "위험 기반 적응형 인증",
      "지리적 위치",
      "수백만 명의 사용자",
      "확장 가능성",
      "Amazon Cognito"
    ],
    "Terms": [
      "Amazon Cognito user pools",
      "Amazon Cognito identity pools",
      "AWS Identity and Access Management (IAM)",
      "AllowManageOwnUserMFA",
      "AWS IAM Identity Center (AWS Single Sign-On)",
      "risk-based adaptive authentication",
      "multifactor authentication (MFA)"
    ],
    "SelectA": "사용자 인증을 위해 Amazon Cognito user pools을 구성합니다. multifactor authentication(MFA)가 활성화된 위험 기반 적응형 인증(risk-based adaptive authentication) 기능을 사용합니다.",
    "SelectA_Commentary": "Cognito user pools에 내장된 위험 기반 적응형 인증으로 지정된 조건(지리적 위치, 디바이스 등)에 따라 MFA를 자동 적용하고, 대규모 사용자 관리가 가능하므로 요구사항에 부합합니다.",
    "SelectB": "사용자 인증을 위해 Amazon Cognito identity pools을 구성합니다. multi-factor authentication(MFA)를 활성화합니다.",
    "SelectB_Commentary": "Cognito identity pools는 퍼블릭 ID 공급, 임시 자격 증명 등에 초점이 있어 위험 기반 MFA 정책을 세밀하게 적용하기 어렵고, 일반 사용자 인증으로는 적합하지 않습니다.",
    "SelectC": "사용자 인증을 위해 AWS Identity and Access Management(IAM) 사용자를 구성합니다. AllowManageOwnUserMFA 작업을 허용하는 IAM 정책을 연결합니다.",
    "SelectC_Commentary": "IAM 사용자는 대규모 외부 사용자 관리에 권장되지 않으며, 세밀한 위험 기반 인증을 쉽게 구현하기도 어렵습니다.",
    "SelectD": "사용자 인증을 위해 AWS IAM Identity Center(AWS Single Sign-On) 인증을 구성합니다. multi-factor authentication(MFA)가 필요하도록 permission sets을 설정합니다.",
    "SelectD_Commentary": "IAM Identity Center는 사내 SSO용으로 주로 쓰이며, 위험 기반 MFA 기능을 바로 제공하지 않으므로 해당 요구사항과는 다소 거리가 있습니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q665",
      "Q57",
      "Q122",
      "Q189"
    ],
    "SelectA_recommedations": [
      "Q366",
      "Q797",
      "Q871"
    ],
    "SelectB_recommedations": [
      "Q366",
      "Q898",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q780",
      "Q797",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q688",
      "Q668",
      "Q28"
    ]
  },
  {
    "Question_Number": "Q804",
    "Question_Description": "한 회사는 Amazon S3 data lake를 보유하고 있습니다. 이 회사는 해당 data lake에 있는 데이터를 매일 변환하여 data warehouse에 적재해야 합니다. 이 data warehouse는 대규모 병렬 처리(MPP) 기능이 필요합니다. 데이터 분석가는 SQL 명령어를 사용하여 데이터에 대한 machine learning(ML) 모델을 생성하고 학습해야 합니다. 또한 가능한 한 serverless AWS 서비스를 사용해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135261-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에서 매일 대량 데이터를 변환하여 MPP를 지원하는 data warehouse에 적재하고, SQL 기반 ML 모델을 운용해야 한다는 것이 핵심입니다. serverless 중심으로 구현해야 하므로, AWS Glue와 Amazon Redshift Serverless 조합이 적합하며, Amazon Redshift ML을 통해 SQL로 ML 모델을 손쉽게 생성하고 학습할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "Amazon S3 data lake",
      "data warehouse",
      "대규모 병렬 처리(MPP)",
      "serverless AWS",
      "SQL 명령어",
      "machine learning(ML)",
      "Amazon Redshift Serverless",
      "Amazon Redshift ML",
      "AWS Glue job"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EMR",
      "AWS Glue",
      "Amazon Redshift",
      "Amazon Redshift ML",
      "Amazon Aurora Serverless",
      "Amazon Athena"
    ],
    "SelectA": "매일 Amazon EMR job을 실행하여 데이터를 변환하고 Amazon Redshift로 로드합니다. Amazon Redshift ML을 사용하여 ML 모델을 생성 및 훈련합니다.",
    "SelectA_Commentary": "Amazon Redshift 자체는 MPP 제공이 가능하지만, Amazon EMR은 serverless가 아니므로 요구사항의 '가능한 한 serverless' 조건에 부합하지 않습니다.",
    "SelectB": "매일 Amazon EMR job을 실행하여 데이터를 변환하고 Amazon Aurora Serverless로 로드합니다. Amazon Aurora ML을 사용하여 ML 모델을 생성 및 훈련합니다.",
    "SelectB_Commentary": "Amazon Aurora Serverless는 데이터 웨어하우스로서의 MPP 기능을 제공하지 않으므로, 고성능 대량 데이터 분석에 적합하지 않습니다.",
    "SelectC": "매일 AWS Glue job을 실행하여 데이터를 변환하고 Amazon Redshift Serverless로 로드합니다. Amazon Redshift ML을 사용하여 ML 모델을 생성 및 훈련합니다.",
    "SelectC_Commentary": "AWS Glue와 Amazon Redshift Serverless 모두 serverless 서비스이며 MPP, SQL 기반 ML 모델 구축 요구사항을 충족하므로 가장 적합한 솔루션입니다.",
    "SelectD": "매일 AWS Glue job을 실행하여 데이터를 변환하고 Amazon Athena 테이블로 로드합니다. Amazon Athena ML을 사용하여 ML 모델을 생성 및 훈련합니다.",
    "SelectD_Commentary": "Amazon Athena는 쿼리 서비스로서 데이터 웨어하우스 수준의 MPP를 제공하지 않아 고성능 분석 요구사항을 완전히 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q603",
      "Q687",
      "Q834",
      "Q292",
      "Q33"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q687"
    ],
    "SelectB_recommedations": [
      "Q603",
      "Q687",
      "Q235"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q804",
      "Q687"
    ],
    "SelectD_recommedations": [
      "Q687",
      "Q103",
      "Q361"
    ]
  },
  {
    "Question_Number": "Q805",
    "Question_Description": "한 회사가 자체 데이터 센터에서 Kubernetes 환경으로 컨테이너를 실행하고 있습니다. 이 회사는 Amazon EKS와 다른 AWS managed services를 사용하고자 합니다. 하지만 컴플라이언스를 위해 데이터는 회사 데이터 센터에만 로컬로 저장되어야 하며, 어떤 원격 사이트나 클라우드에도 저장될 수 없습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135262-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 컴플라이언스 준수를 위해 온프레미스에서 Amazon EKS 등 AWS managed services를 사용하는 방법을 묻습니다. AWS Outposts는 회사 데이터 센터에 설치되어 완전한 AWS 인프라를 로컬에서 제공함으로써 데이터가 외부로 나가지 않도록 하면서 Kubernetes를 비롯한 모든 AWS 서비스를 사용할 수 있게 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "Kubernetes 환경",
      "로컬 데이터 센터",
      "Amazon EKS",
      "AWS managed services",
      "컴플라이언스",
      "AWS Outposts"
    ],
    "Terms": [
      "AWS Local Zones",
      "AWS Snowmobile",
      "AWS Outposts rack",
      "AWS Snowball Edge Storage Optimized node",
      "Kubernetes",
      "Amazon Elastic Kubernetes Service(Amazon EKS)"
    ],
    "SelectA": "회사의 데이터 센터에 AWS Local Zones를 배포합니다.",
    "SelectA_Commentary": "AWS Local Zones는 AWS가 구축하는 물리적 장소이며 완전한 온프레미스 솔루션이 아닙니다. 회사 데이터 센터에 직접 설치할 수 없으므로 요구 사항에 부합하지 않습니다.",
    "SelectB": "회사 데이터 센터에 AWS Snowmobile을 사용합니다.",
    "SelectB_Commentary": "AWS Snowmobile은 대규모 데이터 이전 장비로, 임시적인 대량 데이터 전송용입니다. 지속적으로 EKS와 서비스를 운영하는 목적에는 부적합합니다.",
    "SelectC": "회사 데이터 센터에 AWS Outposts rack을 설치합니다.",
    "SelectC_Commentary": "AWS Outposts는 실제 하드웨어를 회사 데이터 센터에 두어 AWS 서비스를 로컬에서 바로 실행할 수 있도록 합니다. 데이터가 외부로 나가지 않으므로 컴플라이언스를 충족합니다.",
    "SelectD": "데이터 센터에 AWS Snowball Edge Storage Optimized 노드를 설치합니다.",
    "SelectD_Commentary": "AWS Snowball Edge는 오프라인 데이터 전송이나 제한된 엣지 컴퓨팅이 목적입니다. Amazon EKS와 다른 AWS 서비스를 완전하게 실행하기에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q371",
      "Q492",
      "Q529",
      "Q548",
      "Q681"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q831"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q592",
      "Q529"
    ],
    "SelectD_recommedations": [
      "Q893",
      "Q592",
      "Q898"
    ]
  },
  {
    "Question_Number": "Q806",
    "Question_Description": "한 소셜 미디어 회사가 데이터를 수집하고 처리하는 워크로드를 운영하고 있습니다. 이 워크로드는 on-premises NFS 스토리지에 데이터를 저장하고 있으며, 회사의 비즈니스 요구가 커짐에 따라 이 데이터 스토어가 충분히 빠르게 확장되지 못하고 있습니다. 회사는 현재 데이터 스토어를 AWS로 마이그레이션하여 운용하고 싶어 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135263-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "on-premises NFS 스토리지를 AWS로 옮기면서 기존 애플리케이션이나 워크플로를 변경하지 않고, 비용 효율적으로 확장 가능한 스토리지 환경을 구성하는 것이 핵심입니다. Amazon S3 File Gateway를 사용하면 로컬 NFS 프로토콜 방식 그대로 데이터를 Amazon S3에 저장하고, S3 Lifecycle 정책으로 낮은 빈도의 데이터는 저비용 스토리지 클래스로 자동 전환할 수 있어 가장 경제적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "on-premises NFS 스토리지",
      "마이그레이션",
      "비용 효율성",
      "AWS Storage Gateway",
      "Amazon S3 File Gateway",
      "Amazon S3 Lifecycle 정책"
    ],
    "Terms": [
      "AWS Storage Gateway Volume Gateway",
      "Amazon S3 File Gateway",
      "Amazon EFS Standard-IA",
      "Amazon EFS One Zone-IA",
      "Lifecycle policy",
      "NFS"
    ],
    "SelectA": "AWS Storage Gateway Volume Gateway를 설정합니다. Amazon S3 Lifecycle 정책을 사용하여 데이터를 적절한 스토리지 클래스로 전환합니다.",
    "SelectA_Commentary": "Volume Gateway는 블록 스토리지(iSCSI) 방식이라, 기존 NFS 구성과 호환을 위해 추가 구성이 필요해 복잡해질 수 있습니다. 파일 기반 워크로드에는 적합하지 않아 비용 효율성이 떨어집니다.",
    "SelectB": "AWS Storage Gateway Amazon S3 File Gateway를 설정합니다. Amazon S3 Lifecycle 정책을 사용하여 데이터를 적절한 스토리지 클래스로 전환합니다.",
    "SelectB_Commentary": "NFS 프로토콜을 그대로 사용하면서 Amazon S3에 직접 파일을 저장하고, Lifecycle 정책으로 효율적인 스토리지 클래스로 자동 전환이 가능해 기존 워크플로를 거의 바꾸지 않고도 비용을 절감할 수 있는 최적의 솔루션입니다.",
    "SelectC": "Amazon Elastic File System (Amazon EFS) Standard-Infrequent Access (Standard-IA) 스토리지 클래스를 사용합니다. Infrequent access lifecycle 정책을 활성화합니다.",
    "SelectC_Commentary": "EFS를 사용하는 경우 애플리케이션을 재설정해야 할 수 있으며, on-premises NFS를 직접 AWS로 확장하는 기능이 없어서 마이그레이션 과정이 더 복잡하고 비용 효율성이 제한적입니다.",
    "SelectD": "Amazon Elastic File System (Amazon EFS) One Zone-Infrequent Access (One Zone-IA) 스토리지 클래스를 사용합니다. Infrequent access lifecycle 정책을 활성화합니다.",
    "SelectD_Commentary": "One Zone-IA는 단일 AZ만 활용하기 때문에 가용성이 상대적으로 낮으며, 여전히 EFS로의 전환을 위해 애플리케이션 구성이 필요해 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q617",
      "Q703",
      "Q728",
      "Q985",
      "Q284"
    ],
    "SelectA_recommedations": [
      "Q497",
      "Q415",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q415",
      "Q497",
      "Q346"
    ],
    "SelectC_recommedations": [
      "Q277",
      "Q822",
      "Q800"
    ],
    "SelectD_recommedations": [
      "Q822",
      "Q800",
      "Q277"
    ]
  },
  {
    "Question_Number": "Q807",
    "Question_Description": "한 회사가 마케팅 이벤트 중 메시지 큐에서 계속 증가하는 메시지를 처리하기 위해 AWS Lambda 함수를 높은 동시성으로 사용하고 있습니다. 이 Lambda 함수들은 메시지를 처리하기 위해 CPU 집약적인 코드를 사용합니다. 회사는 컴퓨팅 비용을 줄이는 동시에 고객에게 제공되는 서비스 지연 시간을 유지하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135552-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CPU 집약적인 AWS Lambda 함수를 효율적으로 운영하며 동시에 비용을 절감하고자 할 때의 설정 방법을 묻습니다. Lambda는 할당된 메모리에 비례해 CPU 자원을 배정하므로, CPU 집약적인 코드일수록 더 많은 메모리를 설정하면 실행 시간이 줄어들어 결과적으로 비용 절감에 도움이 됩니다. Reserved Concurrency를 사용하면 특정 함수의 동시 실행 한도를 보장할 수 있지만, Provisioned Concurrency를 사용하면 비용이 증가합니다. 따라서 필요한 동시성을 확보하고, CPU 성능을 높여 처리 시간을 단축하여 비용을 절감하는 것이 핵심 포인트입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS Lambda",
      "높은 동시성",
      "CPU 집약적 처리",
      "컴퓨팅 비용 절감",
      "서비스 지연 시간 유지"
    ],
    "Terms": [
      "Reserved Concurrency",
      "Provisioned Concurrency",
      "AWS Compute Optimizer"
    ],
    "SelectA": "Lambda 함수에 대해 reserved concurrency를 구성하고, Lambda 함수에 할당된 메모리를 줄이십시오.",
    "SelectA_Commentary": "메모리를 줄이면 CPU 자원도 감소하여 처리 시간이 길어질 수 있으므로 비용과 성능 모두 비효율적입니다.",
    "SelectB": "Lambda 함수에 대해 reserved concurrency를 구성하고, AWS Compute Optimizer 권장 사항에 따라 메모리를 늘리십시오.",
    "SelectB_Commentary": "Reserved Concurrency로 동시 실행을 보장하고, 메모리를 늘려 CPU 리소스를 확보하면 처리 시간을 줄여 비용과 성능을 균형 있게 충족할 수 있습니다.",
    "SelectC": "Lambda 함수에 대해 provisioned concurrency를 구성하고, Lambda 함수에 할당된 메모리를 줄이십시오.",
    "SelectC_Commentary": "Provisioned Concurrency는 콜드 스타트 문제를 해결하지만, 별도 비용이 발생합니다. 여기에 메모리까지 줄이면 처리 시간이 늘어나 비용 효율이 떨어집니다.",
    "SelectD": "Lambda 함수에 대해 provisioned concurrency를 구성하고, AWS Compute Optimizer 권장 사항에 따라 메모리를 늘리십시오.",
    "SelectD_Commentary": "Provisioned Concurrency 자체가 유연성과 비용 측면에서 부담이 크므로, 이 문제의 목표인 비용 절감과는 상충될 수 있습니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q238",
      "Q671",
      "Q525",
      "Q770"
    ],
    "SelectA_recommedations": [
      "Q807",
      "Q882",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q807",
      "Q715",
      "Q882"
    ],
    "SelectC_recommedations": [
      "Q807",
      "Q882",
      "Q128"
    ],
    "SelectD_recommedations": [
      "Q807",
      "Q715",
      "Q882"
    ]
  },
  {
    "Question_Number": "Q808",
    "Question_Description": "한 회사가 Amazon ECS에서 워크로드를 운영하고 있습니다. ECS 태스크 정의에서 사용하는 컨테이너 이미지는 Common Vulnerabilities and Exposures(CVEs)에 대한 스캔이 필요합니다. 새로 생성되는 컨테이너 이미지도 스캔해야 합니다. 워크로드 변경을 최소화하면서 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135473-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon ECS에서 컨테이너 이미지의 취약점을 자동으로 점검하고, 새로 생성되는 이미지까지 스캔해야 하는 상황에서 최소한의 변경으로 요구사항을 충족시키는 방법을 묻습니다. Amazon ECR의 ‘scan on push’ 기능을 통해 이미지가 푸시될 때마다 간편하게 스캔을 수행할 수 있어, 작업 부담을 크게 늘리지 않고도 CVE 검사 요구사항을 만족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Amazon ECS",
      "컨테이너 이미지",
      "CVEs",
      "Amazon ECR",
      "scan on push"
    ],
    "Terms": [
      "Amazon ECS",
      "Amazon ECR",
      "ECR basic scan",
      "ECR enhanced scan",
      "Amazon S3",
      "Amazon Macie",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "AWS Lambda",
      "Amazon Inspector"
    ],
    "SelectA": "Amazon ECR을 프라이빗 이미지 리포지토리로 사용하여 컨테이너 이미지를 저장합니다. ECR basic scan을 위해 scan on push 필터를 지정합니다.",
    "SelectA_Commentary": "Amazon ECR의 scan on push 기능으로 새 이미지 푸시에 대한 자동 스캔이 가능하며, ECS와의 연동이 자연스러워 워크로드 변경이 거의 필요 없습니다.",
    "SelectB": "컨테이너 이미지를 Amazon S3 버킷에 저장합니다. Amazon Macie로 이미지를 스캔하고, s3:ObjectCreated:Put 이벤트에 대해 S3 Event Notification을 설정해 Macie 스캔을 트리거합니다.",
    "SelectB_Commentary": "Amazon Macie는 주로 데이터 유출 및 민감 정보 탐지에 특화되어 있어 컨테이너 취약점 검사에는 적합하지 않으며, 별도의 설정과 관리가 필요해 번거롭습니다.",
    "SelectC": "워크로드를 Amazon Elastic Kubernetes Service(Amazon EKS)로 배포하고, Amazon ECR을 프라이빗 이미지 리포지토리로 사용합니다. ECR enhanced scan을 위해 scan on push 필터를 지정합니다.",
    "SelectC_Commentary": "EKS로 변경하는 것은 ECS에서 EKS로의 마이그레이션이 필요하므로 워크로드 변화가 큽니다. 최소 변경이라는 요구사항을 충족하기 어렵습니다.",
    "SelectD": "버전 관리가 활성화된 Amazon S3 버킷에 컨테이너 이미지를 저장합니다. s3:ObjectCreated:* 이벤트에 대한 S3 Event Notification으로 AWS Lambda 함수를 호출하고, Lambda가 Amazon Inspector 스캔을 실행하도록 구성합니다.",
    "SelectD_Commentary": "S3 버킷과 Lambda, Amazon Inspector를 따로 연계해야 하므로 설정이 복잡하며, ECS 이미지 관리에 직접적이지 않아 추가적인 변경이 큽니다.",
    "Question_Description_recommedations": [
      "Q492",
      "Q329",
      "Q15",
      "Q682",
      "Q950"
    ],
    "SelectA_recommedations": [
      "Q689",
      "Q825",
      "Q44"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q202",
      "Q270"
    ],
    "SelectC_recommedations": [
      "Q805",
      "Q371",
      "Q535"
    ],
    "SelectD_recommedations": [
      "Q289",
      "Q403",
      "Q270"
    ]
  },
  {
    "Question_Number": "Q809",
    "Question_Description": "한 회사가 AWS Batch 잡을 사용하여 매일 마감 영업 프로세스를 실행하고 있습니다. 이 회사는 AWS Batch 잡이 성공(SUCCEEDED)했을 때 서드 파티 리포팅 애플리케이션을 자동으로 호출하는 서버리스 방식의 솔루션이 필요합니다. 이 리포팅 애플리케이션은 username과 password를 사용하여 인증하는 HTTP API 인터페이스를 제공합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135695-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Batch의 잡 성공 이벤트를 트리거로 하여 외부 HTTP API를 자동으로 호출해야 하는 시나리오입니다. Amazon EventBridge의 API Destination 기능을 사용하면 인증 정보를 안전하게 등록하고, 이벤트 기반으로 서드 파티 API를 직접 호출할 수 있어 서버리스 및 느슨한 결합 아키텍처를 간단하게 구현할 수 있습니다. 따라서 운영 오버헤드를 최소화하고 확장성 및 유지보수성을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "AWS Batch",
      "서버리스",
      "외부 API 호출",
      "EventBridge API Destination",
      "username and password 인증"
    ],
    "Terms": [
      "AWS Batch",
      "Amazon EventBridge",
      "EventBridge rule",
      "API Destination",
      "Amazon Lambda",
      "Amazon API Gateway",
      "HTTP API",
      "username and password"
    ],
    "SelectA": "Amazon EventBridge 규칙에서 AWS Batch 잡의 SUCCEEDED 이벤트를 매칭하도록 구성합니다. username과 password를 사용하여 외부 API를 EventBridge API Destination으로 설정합니다. 이 API Destination을 EventBridge 규칙의 대상으로 지정합니다.",
    "SelectA_Commentary": "서드 파티 API를 직접 호출하기 위해 EventBridge API Destination을 사용하므로 별도 Lambda 구성 없이 서버리스 아키텍처를 구성할 수 있으며, 인증도 EventBridge에서 설정할 수 있어 가장 효율적인 솔루션입니다.",
    "SelectB": "Amazon EventBridge Scheduler를 구성하여 AWS Batch 잡 SUCCEEDED 이벤트를 매칭합니다. AWS Lambda 함수를 설정하여 username과 password로 서드 파티 API를 호출합니다. 해당 Lambda 함수를 EventBridge 규칙 대상으로 설정합니다.",
    "SelectB_Commentary": "Lambda를 추가로 사용해야 하므로 구성 요소가 늘어나며, EventBridge API Destination 대신 Lambda 함수를 직접 호출해야 해서 관리 부담이 다소 커집니다.",
    "SelectC": "AWS Batch 잡에서 job SUCCEEDED 이벤트를 Amazon API Gateway REST API로 전달하도록 구성합니다. 이 API Gateway에 HTTP 프록시 통합을 설정하여 username과 password를 사용해 서드 파티 API를 호출합니다.",
    "SelectC_Commentary": "Batch → API Gateway → 서드 파티 API 구조로, EventBridge를 사용하지 않아 별도의 API Gateway 설정과 배포가 필요하고, 이벤트 기반 구조가 아님에 따라 상대적으로 더 복잡해집니다.",
    "SelectD": "AWS Batch 잡에서 job SUCCEEDED 이벤트를 Amazon API Gateway REST API로 전달하도록 구성합니다. API Gateway REST API에서 프록시 통합으로 AWS Lambda 함수를 연결합니다. username과 password를 사용하여 Lambda 함수가 서드 파티 API를 호출하도록 설정합니다.",
    "SelectD_Commentary": "이 또한 Batch → API Gateway → Lambda → 서드 파티 API로 흐름이 많아, EventBridge API Destination을 활용하는 방식보다 복잡도가 커지고 전반적인 구성이 번거롭습니다.",
    "Question_Description_recommedations": [
      "Q10",
      "Q775",
      "Q489",
      "Q207",
      "Q293"
    ],
    "SelectA_recommedations": [
      "Q809",
      "Q569",
      "Q10"
    ],
    "SelectB_recommedations": [
      "Q809",
      "Q569",
      "Q785"
    ],
    "SelectC_recommedations": [
      "Q809",
      "Q10",
      "Q739"
    ],
    "SelectD_recommedations": [
      "Q809",
      "Q739",
      "Q10"
    ]
  },
  {
    "Question_Number": "Q810",
    "Question_Description": "한 회사가 벤더로부터 데이터를 수집하고 처리하고 있습니다. 벤더는 자체 AWS 계정의 Amazon RDS for MySQL 데이터베이스에 데이터를 저장하고 있습니다. 이 회사의 VPC에는 인터넷 게이트웨이, AWS Direct Connect 연결, 또는 AWS Site-to-Site VPN 연결이 없습니다. 이때 회사는 벤더의 데이터베이스에 있는 데이터를 액세스해야 합니다. 어떤 솔루션이 이러한 요구사항을 충족할까요?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135264-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회사 VPC와 벤더 VPC 간 인터넷 게이트웨이 없이 안전하게 Amazon RDS for MySQL에 접근하는 방법을 묻습니다. 벤더가 NLB 앞에 RDS를 두고 AWS PrivateLink로 회사 VPC에 프라이빗 연결을 제공하면, 추가 네트워크 연결 없이 안전하게 접근할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "VPC",
      "Amazon RDS for MySQL",
      "데이터 액세스",
      "AWS PrivateLink",
      "Network Load Balancer"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "AWS PrivateLink",
      "Network Load Balancer (NLB)",
      "VPC Peering",
      "AWS Transit Gateway",
      "Client VPN",
      "Hosted Connection Direct Connect Program"
    ],
    "SelectA": "벤더가 AWS Hosted Connection Direct Connect 프로그램에 가입하도록 지시합니다. VPC 피어링을 사용하여 회사의 VPC와 벤더의 VPC를 연결합니다.",
    "SelectA_Commentary": "Direct Connect 연결을 새로 구성해야 하고, 이미 회사 VPC엔 Direct Connect가 없으므로 적합하지 않습니다.",
    "SelectB": "회사 VPC와 벤더 VPC 간 클라이언트 VPN 연결을 구성합니다. VPC 피어링을 사용하여 회사 VPC와 벤더 VPC를 연결합니다.",
    "SelectB_Commentary": "클라이언트 VPN 연결과 VPC 피어링에 의존해야 해 복잡하며, 간단한 PrivateLink 연결보다 구현이 어렵습니다.",
    "SelectC": "벤더에게 Network Load Balancer(NLB)를 생성하도록 지시합니다. Amazon RDS for MySQL 데이터베이스 앞에 NLB를 두고, AWS PrivateLink를 사용하여 회사 VPC와 벤더 VPC를 통합합니다.",
    "SelectC_Commentary": "AWS PrivateLink로 양측 VPC 간 안전하고 직접적인 연결을 구성할 수 있어, 추가 게이트웨이나 VPN 없이도 벤더 RDS에 접근 가능합니다. 정답입니다.",
    "SelectD": "AWS Transit Gateway를 사용하여 회사 VPC와 벤더 VPC를 통합합니다. VPC 피어링을 사용하여 회사 VPC와 벤더 VPC를 연결합니다.",
    "SelectD_Commentary": "Transit Gateway와 VPC 피어링을 결합하면 구성 복잡도가 올라가며, 인터넷 게이트웨이 없이 외부 계정 간 트래픽 전달에 제한이 있어 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q782",
      "Q451",
      "Q438",
      "Q61",
      "Q15"
    ],
    "SelectA_recommedations": [
      "Q810",
      "Q950",
      "Q15"
    ],
    "SelectB_recommedations": [
      "Q950",
      "Q15",
      "Q468"
    ],
    "SelectC_recommedations": [
      "Q928",
      "Q382",
      "Q282"
    ],
    "SelectD_recommedations": [
      "Q950",
      "Q135",
      "Q15"
    ]
  },
  {
    "Question_Number": "Q811",
    "Question_Description": "한 회사가 시각화 도구로 Amazon Managed Grafana를 설정하고자 합니다. 이 회사는 Amazon RDS 데이터베이스의 데이터를 하나의 데이터 소스로 사용하려고 합니다. 회사는 데이터가 인터넷에 노출되지 않도록 보안이 유지되는 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135697-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon Managed Grafana에서 데이터베이스를 안전하게 시각화하려면, VPC 내에서 private endpoint를 사용하여 트래픽을 인터넷에 노출하지 않는 구성이 필요합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Amazon Managed Grafana",
      "Amazon RDS",
      "private endpoint",
      "public endpoint",
      "VPC",
      "AWS PrivateLink"
    ],
    "Terms": [
      "Amazon Managed Grafana",
      "Amazon RDS",
      "VPC",
      "public endpoint",
      "private endpoint",
      "AWS PrivateLink"
    ],
    "SelectA": "VPC 없이 Amazon Managed Grafana workspace를 생성합니다. RDS의 public endpoint를 만들고 이를 Amazon Managed Grafana에서 데이터 소스로 설정합니다.",
    "SelectA_Commentary": "인터넷을 통해 연결하므로 데이터가 노출될 위험이 있어 안전 요구사항을 충족하지 못합니다.",
    "SelectB": "VPC 내 Amazon Managed Grafana workspace를 생성합니다. RDS의 private endpoint를 만들고 이를 Amazon Managed Grafana에서 데이터 소스로 설정합니다.",
    "SelectB_Commentary": "RDS로의 사설 경로를 구성하여 인터넷 노출 없이 보안성을 유지할 수 있는 정답입니다.",
    "SelectC": "VPC 없이 Amazon Managed Grafana workspace를 생성합니다. AWS PrivateLink endpoint를 만들어 Amazon Managed Grafana와 Amazon RDS 사이를 연결하고, RDS를 데이터 소스로 설정합니다.",
    "SelectC_Commentary": "VPC 없는 Managed Grafana workspace와 PrivateLink를 직접 연결하기 어려워 구조가 적절하지 않습니다.",
    "SelectD": "VPC 내 Amazon Managed Grafana workspace를 생성합니다. RDS의 public endpoint를 만들고 이를 데이터 소스로 설정합니다.",
    "SelectD_Commentary": "VPC 사용은 올바르지만 public endpoint는 인터넷 노출 위험이 있어 보안 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q742",
      "Q330",
      "Q847",
      "Q732",
      "Q61"
    ],
    "SelectA_recommedations": [
      "Q811",
      "Q847",
      "Q438"
    ],
    "SelectB_recommedations": [
      "Q811",
      "Q438",
      "Q847"
    ],
    "SelectC_recommedations": [
      "Q811",
      "Q810",
      "Q438"
    ],
    "SelectD_recommedations": [
      "Q811",
      "Q847",
      "Q438"
    ]
  },
  {
    "Question_Number": "Q812",
    "Question_Description": "한 회사가 Amazon S3에서 데이터 레이크(Data Lake)를 운영하고 있으며, Apache Parquet 형식의 다양한 데이터 소스에서 데이터를 수집합니다. 회사는 수집된 데이터를 준비하기 위해 이상치 필터링, 표준 날짜 및 시간 형식으로의 정상화, 분석을 위한 집계 데이터 생성 등의 여러 변환 단계를 수행합니다. 이 변환된 데이터는 데이터 분석가들이 접근할 수 있도록 S3 버킷에 저장해야 합니다. 또한 회사는 코드 작성이 필요 없는 사전 구성된 데이터 변환 솔루션이 필요하며, 데이터 라인이지(data lineage)와 데이터 프로파일링(data profiling)을 제공해야 합니다. 그리고 이러한 데이터 변환 단계를 회사 내 직원들과도 쉽게 공유해야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135265-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 Data Lake 환경에서 코드 작성 없이도 데이터 변환, 라인이지, 프로파일링까지 가능한 서비스를 찾는 상황입니다. AWS Glue DataBrew는 시각적 에디터와 레시피를 통해 누구나 쉽게 변환 단계를 정의·공유하고, 데이터 품질 분석 및 라인이지 관리 기능을 제공하므로 가장 적합한 답안입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "데이터 레이크",
      "Apache Parquet",
      "이상치 필터링",
      "정상화",
      "집계 데이터",
      "코드 필요 없는 솔루션",
      "데이터 라인이지",
      "데이터 프로파일링"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Glue Studio",
      "EMR Serverless",
      "AWS Glue DataBrew",
      "DataBrew recipes",
      "Amazon Athena",
      "SQL queries"
    ],
    "SelectA": "AWS Glue Studio 시각적 캔버스를 구성하여 데이터를 변환하고, AWS Glue jobs로 변환 단계를 공유합니다.",
    "SelectA_Commentary": "Glue Studio도 시각화 기능을 제공하지만 DataBrew처럼 간단히 데이터 프로파일링과 라인이지 추적을 제공하는 데는 제한적입니다.",
    "SelectB": "Amazon EMR Serverless를 구성하여 데이터를 변환하고, EMR Serverless jobs로 변환 단계를 공유합니다.",
    "SelectB_Commentary": "EMR Serverless는 확장성과 유연성은 뛰어나지만, 코드 없는 방식·직관적 레시피 공유·데이터 프로파일링 면에서 별도 구현이 필요합니다.",
    "SelectC": "AWS Glue DataBrew를 구성하여 데이터를 변환하고, DataBrew recipes로 변환 단계를 공유합니다.",
    "SelectC_Commentary": "코드가 필요 없고 시각적 방식으로 변환 작업을 수행하며, 데이터 라인이지와 프로파일링까지 제공해 요구사항을 모두 충족합니다.",
    "SelectD": "Amazon Athena 테이블을 생성한 후 Athena SQL 쿼리로 데이터를 변환하고, Athena SQL 쿼리를 공유합니다.",
    "SelectD_Commentary": "SQL 기반으로 변환을 수행하지만, 코드 작성이 필요하고 단계 공유 및 데이터 라인이지 관리 측면에서 번거롭습니다.",
    "Question_Description_recommedations": [
      "Q214",
      "Q687",
      "Q381",
      "Q804",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q103",
      "Q631"
    ],
    "SelectB_recommedations": [
      "Q603",
      "Q631",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q173",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q292",
      "Q886",
      "Q565"
    ]
  },
  {
    "Question_Number": "Q813",
    "Question_Description": "한 솔루션스 아키텍트가 Application Load Balancer(ALB) 뒤에 개별 Target Group으로 구성된 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있습니다. 사용자는 퍼블릭 웹사이트를 통해 애플리케이션에 접근할 수 있습니다. 솔루션스 아키텍트는 엔지니어들이 애플리케이션의 새로운 기능을 테스트하기 위해, 개발 버전 웹사이트를 사용하여 특정 개발용 EC2 인스턴스에 접근할 수 있도록 하고자 합니다. 솔루션스 아키텍트는 Amazon Route 53 Hosted Zone을 사용하여 해당 개발용 인스턴스에 접근할 수 있도록 구성하려고 합니다. 또한 이 솔루션은 개발용 인스턴스가 교체되더라도 자동으로 해당 인스턴스로 라우팅이 이루어져야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135726-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 개발용 EC2 인스턴스에 대한 트래픽을 자동으로 라우팅하려는 상황에서 ALB와 Route 53을 어떻게 연동해야 하는지를 묻습니다. ALB 뒤에 Target Group을 두고, Route 53에서 ALB를 가리키도록 구성하면 인스턴스가 교체되어도 Target Group을 통해 새 인스턴스로 연결할 수 있으므로 자동 라우팅이 보장됩니다. 따라서 ALB로 트래픽을 보내고, ALB Listener Rule에서 특정 호스트 이름(개발용 웹사이트)에 대한 요청을 해당 개발 인스턴스 Target Group으로 전달하도록 설정하는 방식이 올바른 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "개발용 EC2 인스턴스",
      "자동 라우팅",
      "Application Load Balancer",
      "Amazon Route 53 Hosted Zone"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "Target Group",
      "Amazon Route 53",
      "A Record",
      "Listener Rule",
      "Public IP"
    ],
    "SelectA": "개발용 웹사이트용 A Record를 ALB로 설정합니다. 그리고 ALB에서 개발용 웹사이트 요청을 개발용 인스턴스가 포함된 Target Group으로 포워딩하는 Listener Rule을 만듭니다.",
    "SelectA_Commentary": "ALB를 통해 트래픽을 전달함으로써 인스턴스 교체 시에도 Target Group만 업데이트하면 자동 라우팅이 가능하므로 운영이 단순화됩니다.",
    "SelectB": "개발용 인스턴스를 퍼블릭 IP 주소로 재생성합니다. 그리고 개발용 웹사이트용 A Record를 개발용 인스턴스의 퍼블릭 IP 주소로 설정합니다.",
    "SelectB_Commentary": "개발 인스턴스를 직접 가리키는 방식이며, 인스턴스가 교체될 때마다 A Record를 수정해야 하므로 자동 라우팅이 되지 않습니다.",
    "SelectC": "개발용 웹사이트용 A Record를 ALB로 설정합니다. 그리고 ALB Listener Rule에서 개발용 웹사이트 요청을 개발 인스턴스의 퍼블릭 IP 주소로 리다이렉트하도록 구성합니다.",
    "SelectC_Commentary": "리다이렉트 방식은 여전히 인스턴스의 IP 주소 변경 시 수동 업데이트가 필요하며, ALB의 Target Group을 활용하지 못해 자동 라우팅이 보장되지 않습니다.",
    "SelectD": "모든 인스턴스를 동일한 Target Group에 배치합니다. 그리고 개발용 웹사이트용 A Record를 ALB로 설정합니다. ALB Listener Rule에서 개발용 웹사이트 요청을 해당 Target Group으로 포워딩합니다.",
    "SelectD_Commentary": "개발 인스턴스만을 테스트 목적으로 분리하지 않고 모든 인스턴스가 같은 Target Group에 있으면, 개발 트래픽이 다른 인스턴스와 섞일 수 있어 원하는 테스트 환경을 구현하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q275",
      "Q545",
      "Q5",
      "Q639"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q187",
      "Q967"
    ],
    "SelectB_recommedations": [
      "Q567",
      "Q362",
      "Q627"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q987",
      "Q405"
    ],
    "SelectD_recommedations": [
      "Q362",
      "Q293",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q814",
    "Question_Description": "한 회사가 자사 데이터 센터의 Kubernetes 클러스터에서 컨테이너 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Advanced Message Queuing Protocol(AMQP)을 사용해 메시지 큐와 통신합니다. 데이터 센터는 회사의 확장 요구를 충족하기에 충분히 빠르게 확장할 수 없으므로, 회사는 워크로드를 AWS로 마이그레이션하려고 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135266-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Kubernetes 기반 컨테이너 애플리케이션에서 AMQP를 지원하는 메시지 큐를 사용하면서 클라우드로 이전해 확장성과 운영 편의성을 확보하는 방법을 묻고 있습니다. Amazon MQ는 AMQP 호환이 가능하며, 기존 Kubernetes 환경을 그대로 활용할 수 있는 Amazon EKS를 사용함으로써 운영 오버헤드를 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "Kubernetes 클러스터",
      "AMQP",
      "메시지 큐",
      "컨테이너 애플리케이션",
      "AWS 마이그레이션",
      "오버헤드 최소화"
    ],
    "Terms": [
      "Amazon ECS",
      "Amazon EKS",
      "Amazon MQ",
      "Amazon SQS",
      "AWS Lambda",
      "Amazon EC2"
    ],
    "SelectA": "컨테이너 애플리케이션을 Amazon Elastic Container Service(Amazon ECS)로 마이그레이션하고, Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 처리합니다.",
    "SelectA_Commentary": "SQS는 AMQP 프로토콜을 지원하지 않으므로 기존 애플리케이션 요구 사항을 충족하지 못합니다.",
    "SelectB": "컨테이너 애플리케이션을 Amazon Elastic Kubernetes Service(Amazon EKS)로 마이그레이션하고, Amazon MQ를 사용하여 메시지를 처리합니다.",
    "SelectB_Commentary": "Amazon MQ는 AMQP를 지원하며, Kubernetes 기반 애플리케이션을 EKS로 마이그레이션하면 기존 워크로드 확장과 운영 간소화를 동시에 달성할 수 있어 정답입니다.",
    "SelectC": "고가용성을 갖춘 Amazon EC2 인스턴스에서 애플리케이션을 실행하고, Amazon MQ를 사용하여 메시지를 처리합니다.",
    "SelectC_Commentary": "Amazon MQ로 AMQP 통신은 가능하지만, 직접 EC2 인프라를 관리해야 하므로 운영 오버헤드가 더 큽니다.",
    "SelectD": "AWS Lambda 함수를 사용하여 애플리케이션을 실행하고, Amazon Simple Queue Service(Amazon SQS)를 사용하여 메시지를 처리합니다.",
    "SelectD_Commentary": "Lambda는 AMQP 미지원인 SQS와 결합 시 애플리케이션 요구사항을 충족하기 어렵고, 함수 실행 시간 제한이 있어 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q198",
      "Q996",
      "Q775",
      "Q293",
      "Q720"
    ],
    "SelectA_recommedations": [
      "Q900",
      "Q944",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q563",
      "Q996",
      "Q775"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q584",
      "Q824"
    ],
    "SelectD_recommedations": [
      "Q636",
      "Q775",
      "Q98"
    ]
  },
  {
    "Question_Number": "Q815",
    "Question_Description": "한 온라인 게임 회사가 여러 AWS 리전에서 Network Load Balancer(NLB) 뒤에 Amazon EC2 인스턴스를 호스팅하고 있습니다. NLB는 인터넷을 통해 타겟으로 요청을 라우팅할 수 있습니다. 회사는 글로벌 사용자들의 끝에서 끝(End-to-End) 로드 시간을 줄여 게임 서비스 경험을 개선하고자 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135267-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 글로벌 사용자들에게 게임 서비스를 제공할 때 지연(latency)을 최소화하는 방법을 묻습니다. AWS Global Accelerator를 사용하면 글로벌 엣지 네트워크를 활용해 사용자와 서버 간의 트래픽 경로를 최적화하여 엔드-투-엔드 로드 시간을 대폭 단축할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "글로벌 사용자",
      "엔드-투-엔드 로드 시간",
      "Network Load Balancer",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "Amazon EC2",
      "Network Load Balancer(NLB)",
      "Application Load Balancer(ALB)",
      "Amazon Route 53",
      "AWS Global Accelerator"
    ],
    "SelectA": "각 리전에 Application Load Balancer(ALB)를 생성해 기존 NLB를 대체합니다. 각 ALB의 타겟으로 기존 EC2 인스턴스를 등록합니다.",
    "SelectA_Commentary": "ALB로 변경하더라도 글로벌 트래픽 가속 솔루션은 부족합니다. ALB 자체는 애플리케이션 계층 로드 밸런싱이지만 지연을 획기적으로 줄이는 데는 한계가 있습니다.",
    "SelectB": "Amazon Route 53을 구성해 각 리전의 NLB에 동일 가중치로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "Route 53의 균등 가중치 라우팅만으로는 글로벌 가속 기능을 제공하지 못하며, 사용자는 물리적으로 멀리 떨어진 지역에 접속할 수 있어 지연이 발생할 수 있습니다.",
    "SelectC": "추가적인 NLB와 EC2 인스턴스를 대규모 고객 기반이 있는 다른 리전에 생성합니다.",
    "SelectC_Commentary": "추가 리전에 인프라를 구축하는 것만으로는 트래픽 경로의 최적화나 글로벌 엣지 네트워크 활용이 불가능해, 지연을 근본적으로 줄이는 솔루션이 아닙니다.",
    "SelectD": "AWS Global Accelerator에서 표준 가속기를 생성하고, 기존 NLB들을 타겟 엔드포인트로 구성합니다.",
    "SelectD_Commentary": "AWS Global Accelerator는 글로벌 엣지 네트워크를 통해 사용자의 요청을 최적 경로로 라우팅하므로, 지연 시간을 크게 단축하고 글로벌 환경에서 최적의 성능을 보장합니다.",
    "Question_Description_recommedations": [
      "Q358",
      "Q141",
      "Q12",
      "Q530",
      "Q272"
    ],
    "SelectA_recommedations": [
      "Q815",
      "Q358",
      "Q12"
    ],
    "SelectB_recommedations": [
      "Q530",
      "Q38",
      "Q367"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q815",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q865",
      "Q143"
    ]
  },
  {
    "Question_Number": "Q816",
    "Question_Description": "한 회사는 온프레미스 환경에서 여러 공급업체의 재무 데이터를 SFTP를 통해 수집하는 애플리케이션을 사용하고 있습니다. 이 회사는 AWS Cloud로 마이그레이션을 진행하며, Amazon S3 API를 이용해 공급업체의 파일을 업로드하는 새로운 애플리케이션을 만들었습니다. 그러나 일부 공급업체는 레거시 애플리케이션을 사용하여 S3 API를 지원하지 않으므로, 이들은 계속해서 SFTP 기반 애플리케이션을 사용하기를 원합니다. 회사는 이러한 레거시 애플리케이션을 사용하는 공급업체를 위해 관리형 서비스를 활용하여 요구 사항을 충족시키고자 합니다. 가장 적은 운영 오버헤드로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135268-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 API를 직접 사용할 수 없는 레거시 애플리케이션 환경에서 안전하고 간편하게 파일을 전송하는 방안을 묻습니다. AWS Transfer Family는 완전관리형 서비스로 SFTP 업로드를 지원하고, 전달된 파일을 자동으로 Amazon S3에 저장하여 운영 오버헤드를 최소화합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "레거시 애플리케이션",
      "SFTP",
      "운영 오버헤드 최소화",
      "Amazon S3"
    ],
    "Terms": [
      "SFTP",
      "Amazon S3",
      "AWS Transfer Family",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon EC2",
      "Amazon S3 File Gateway",
      "SMB file share"
    ],
    "SelectA": "레거시 애플리케이션을 사용하는 공급업체 스토리지에서 Amazon S3로 데이터를 복제하기 위해 AWS Database Migration Service (AWS DMS) 인스턴스를 생성하고, 해당 인스턴스에 액세스할 자격 증명을 공급업체에 제공합니다.",
    "SelectA_Commentary": "AWS DMS는 데이터베이스 복제용 서비스이므로 파일 전송 목적에는 적합하지 않고, 공급업체가 직접 접근하기에도 설정이 복잡해 운영 부담이 큽니다.",
    "SelectB": "레거시 애플리케이션을 사용하는 공급업체를 위해 AWS Transfer Family endpoint를 생성합니다.",
    "SelectB_Commentary": "AWS Transfer Family는 SFTP를 지원하는 완전관리형 서비스로 설정이 쉽고 운영 오버헤드가 낮으며, 자동으로 S3에 파일을 저장해 요구 사항을 충족합니다.",
    "SelectC": "Amazon EC2 인스턴스에서 SFTP 서버를 구성합니다. 레거시 애플리케이션을 사용하는 공급업체에 SFTP 서버 사용을 안내합니다.",
    "SelectC_Commentary": "EC2 서버 운영, 패치, 보안 관리를 직접 해야 하므로 운영 오버헤드가 높고, 관리형 서비스 대비 비효율적입니다.",
    "SelectD": "Amazon S3 File Gateway를 구성하여 레거시 애플리케이션 공급업체가 SMB 파일 공유로 파일을 업로드하도록 설정합니다.",
    "SelectD_Commentary": "Amazon S3 File Gateway는 SMB 또는 NFS 기반 파일 공유용이므로 SFTP 환경과 맞지 않으며, 요구 사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q832",
      "Q109",
      "Q412",
      "Q638",
      "Q270"
    ],
    "SelectA_recommedations": [
      "Q270",
      "Q412",
      "Q638"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q965",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q453",
      "Q480",
      "Q612"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q412",
      "Q202"
    ]
  },
  {
    "Question_Number": "Q817",
    "Question_Description": "한 마케팅 팀이 다종목 스포츠 이벤트를 앞두고 캠페인을 구성하려고 합니다. 이 팀은 지난 5년간의 뉴스 기사를 PDF 형식으로 보유하고 있습니다. 이 뉴스 기사들의 내용과 감성에 대한 통찰을 추출할 수 있는 솔루션이 필요합니다. 반드시 Amazon Textract를 사용해 뉴스 기사를 처리해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135269-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 PDF 문서에서 텍스트를 추출한 후 감성 분석을 수행하여 내용과 감성을 파악해야 하는 시나리오입니다. Amazon Textract로 문서를 디지털 텍스트화하고, 감성 분석은 Amazon Comprehend를 활용해 추가적인 모델 구성 없이 바로 처리할 수 있어 운영 오버헤드가 가장 적습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "마케팅 팀",
      "PDF 뉴스 기사",
      "감성 분석",
      "데이터 추출",
      "Amazon Textract",
      "Amazon Comprehend"
    ],
    "Terms": [
      "Amazon Textract",
      "Amazon Athena",
      "Amazon DynamoDB",
      "Amazon SageMaker",
      "Amazon Comprehend",
      "Amazon S3",
      "Amazon QuickSight"
    ],
    "SelectA": "추출된 통찰을 Amazon Athena로 제공하여 분석하고, 분석 결과와 추출값을 Amazon S3 버킷에 저장합니다.",
    "SelectA_Commentary": "Athena는 SQL 기반 분석 툴로 감성 분석을 제공하지 않아, 별도 솔루션이 필요하기 때문에 운영 오버헤드가 더 높습니다.",
    "SelectB": "추출된 통찰을 Amazon DynamoDB 테이블에 저장하고 Amazon SageMaker로 감성 모델을 구축합니다.",
    "SelectB_Commentary": "SageMaker로 직접 감성 분석 모델을 만들면 관리 및 모델 훈련 부담이 크므로 오버헤드가 커집니다.",
    "SelectC": "추출된 텍스트를 Amazon Comprehend에 제공하여 분석하고, 분석 결과를 Amazon S3 버킷에 저장합니다.",
    "SelectC_Commentary": "Amazon Comprehend가 텍스트 분류와 감성 분석을 완비해 별도 모델 구성이 없어도 간편하게 분석이 가능합니다.",
    "SelectD": "추출된 통찰을 Amazon S3 버킷에 저장하고, Amazon QuickSight로 시각화 후 분석을 수행합니다.",
    "SelectD_Commentary": "QuickSight는 시각화엔 유용하지만 고급 감성 분석 기능이 없으므로 추가 작업이 필요해 오버헤드가 증가합니다.",
    "Question_Description_recommedations": [
      "Q915",
      "Q278",
      "Q158",
      "Q622",
      "Q506"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q43",
      "Q626"
    ],
    "SelectB_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q2",
      "Q626"
    ],
    "SelectD_recommedations": [
      "Q501",
      "Q292",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q818",
    "Question_Description": "한 회사의 애플리케이션이 여러 Availability Zone에 있는 Amazon EC2 인스턴스에서 실행되고 있습니다. 해당 애플리케이션은 서드파티 애플리케이션으로부터 실시간 데이터를 수집해야 합니다. 회사는 수집된 원시 데이터를 Amazon S3 버킷에 저장하는 데이터 수집 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135270-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서드파티 애플리케이션에서 생성되는 실시간 데이터를 Amazon S3 버킷에 빠르고 안정적으로 적재하기 위한 해결책을 찾는 것입니다. 정답인 Amazon Kinesis Data Streams와 Amazon Kinesis Data Firehose 조합을 사용하면 실시간으로 데이터를 받아서 바로 S3에 저장할 수 있어 높은 처리량과 확장성을 모두 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "실시간 데이터",
      "원시 데이터",
      "Amazon S3 버킷",
      "서드파티 애플리케이션",
      "여러 Availability Zone"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Amazon S3",
      "Amazon Kinesis Data Streams",
      "Amazon Kinesis Data Firehose",
      "AWS Database Migration Service (AWS DMS)",
      "AWS DataSync",
      "AWS Direct Connect"
    ],
    "SelectA": "Amazon Kinesis data streams를 사용해 데이터 수집을 설정합니다. 이후 Amazon Kinesis Data Firehose delivery streams를 생성하여 Kinesis data streams에서 데이터를 소비하도록 구성하고, 대상 S3 버킷을 지정합니다.",
    "SelectA_Commentary": "Kinesis를 통해 실시간으로 데이터를 수집하고, Kinesis Data Firehose가 S3로 바로 전달해 주어 간단하고 확장성 높은 실시간 데이터 파이프라인을 구성할 수 있습니다.",
    "SelectB": "AWS Database Migration Service(AWS DMS)에서 database migration tasks를 생성합니다. Amazon EC2 인스턴스를 소스 endpoint로, S3 버킷을 대상 endpoint로 지정합니다. 기존 데이터를 이관하고 계속 변경 사항을 복제하도록 설정합니다.",
    "SelectB_Commentary": "AWS DMS는 주로 데이터베이스 마이그레이션 및 변경 데이터 캡처에 적합하며, 실시간 스트리밍 목적보다는 데이터베이스 이동에 초점이 있어 적절하지 않습니다.",
    "SelectC": "Amazon EC2 인스턴스에 AWS DataSync agents를 생성 및 구성합니다. DataSync tasks를 설정하여 EC2 인스턴스에서 S3 버킷으로 데이터를 전송합니다.",
    "SelectC_Commentary": "DataSync는 대량파일 전송이나 정기 동기화에 적합하며, 실시간 이벤트 스트리밍에는 적절하지 않습니다.",
    "SelectD": "AWS Direct Connect를 애플리케이션에 연결하여 데이터 수집을 수행합니다. Amazon Kinesis Data Firehose delivery streams를 생성하여 direct PUT operations를 소비하도록 구성하고, 대상 S3 버킷을 지정합니다.",
    "SelectD_Commentary": "Direct Connect는 전용 회선 연결 방식으로, 서드파티 애플리케이션에서의 실시간 데이터 수집에 일반적으로 사용되지 않으며 구축과 운영이 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q976",
      "Q566",
      "Q938",
      "Q632",
      "Q20"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q155",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q386",
      "Q910",
      "Q834"
    ],
    "SelectC_recommedations": [
      "Q818",
      "Q910",
      "Q41"
    ],
    "SelectD_recommedations": [
      "Q402",
      "Q155",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q819",
    "Question_Description": "한 회사의 애플리케이션은 여러 데이터 소스로부터 데이터를 수신하고 있습니다. 데이터 크기는 다양하며 시간이 지남에 따라 증가할 것으로 예상됩니다. 현재 최대 데이터 크기는 700KB입니다. 더 많은 데이터 소스가 추가됨에 따라 데이터 볼륨과 데이터 크기는 계속 증가하고 있습니다. 회사는 애플리케이션의 기본 데이터베이스로 Amazon DynamoDB를 사용하기로 결정했습니다. Solutions Architect는 대용량 데이터 크기를 처리할 수 있는 솔루션을 찾아야 합니다. 가장 운영 효율적인 방식으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135302-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "DynamoDB에는 400KB의 아이템 크기 제한이 있으므로 700KB 이상의 데이터를 직접 저장하기 어렵습니다. 대용량 데이터를 Amazon S3에 저장하고, DynamoDB에는 해당 데이터의 S3 URL만 저장하면 데이터베이스 부담을 줄이면서 확장성과 운영 효율성을 모두 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.3"
    ],
    "Keywords": [
      "대용량 데이터 처리",
      "Amazon DynamoDB",
      "700KB",
      "운영 효율성",
      "데이터 볼륨 증가"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon DocumentDB(with MongoDB compatibility)",
      "Amazon S3",
      "DynamoDB Table",
      "BatchWriteItem",
      "gzip"
    ],
    "SelectA": "DynamoDB item 크기 제한을 초과하는 데이터를 필터링하기 위해 AWS Lambda 함수를 생성합니다. 더 큰 데이터는 Amazon DocumentDB(with MongoDB compatibility) 데이터베이스에 저장합니다.",
    "SelectA_Commentary": "DynamoDB와 DocumentDB를 동시에 운영해야 하므로 아키텍처가 복잡해지고 운영 부담이 늘어납니다.",
    "SelectB": "대용량 데이터를 Amazon S3 버킷의 객체로 저장합니다. DynamoDB 테이블에서는 해당 데이터의 S3 URL을 가리키는 속성을 가진 아이템을 생성합니다.",
    "SelectB_Commentary": "정답. DynamoDB의 아이템 크기 제한을 우회하기 위해 대용량 객체를 S3에 저장하고, DynamoDB에는 참조만 기록함으로써 가장 간단하고 효율적인 방식입니다.",
    "SelectC": "모든 대용량 데이터를 동일한 파티션 키를 가진 여러 아이템으로 분할합니다. BatchWriteItem API 작업을 사용하여 하나의 운영으로 DynamoDB 테이블에 데이터를 씁니다.",
    "SelectC_Commentary": "데이터를 여러 아이템으로 분할하면 관리가 복잡해지고 복원 시 추가 로직이 필요해 운영 효율성이 떨어집니다.",
    "SelectD": "AWS Lambda 함수를 생성하여, DynamoDB 테이블에 기록되는 대용량 객체를 gzip 압축하도록 합니다.",
    "SelectD_Commentary": "압축해도 400KB 이하로 항상 줄어든다는 보장이 없으며, Lambda 압축 처리 자체가 추가 오버헤드를 발생시킵니다.",
    "Question_Description_recommedations": [
      "Q561",
      "Q523",
      "Q192",
      "Q472",
      "Q177"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q292",
      "Q177",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectD_recommedations": [
      "Q523",
      "Q472",
      "Q177"
    ]
  },
  {
    "Question_Number": "Q820",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에서 AWS로 레거시 애플리케이션을 마이그레이션하고 있습니다. 이 애플리케이션은 하루 종일 다른 반복 스케줄로 1분에서 20분 사이로 동작하는 수백 개의 cron job에 의존합니다. 회사는 이러한 cron job을 최소한의 리팩터링으로 AWS에서 스케줄링하고 실행할 수 있는 솔루션을 원합니다. 또한 미래에 발생할 이벤트에 대응하여 cron job을 실행할 수 있는 기능도 필요합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/135271-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이번 문제는 다양한 스케줄(매일 여러 시간대)에 맞춰 여러 cron job을 실행해야 하는 레거시 애플리케이션을 AWS로 이전하는 상황입니다. 한 번에 최대 20분까지 동작해야 하므로 15분 시간 제한이 있는 AWS Lambda는 적합하지 않습니다. 대신 컨테이너를 기반으로AWS Fargate 환경에서 구동하고, Amazon EventBridge Scheduler를 활용해 원하는 스케줄 또는 이벤트에 따라 유연하게 작업을 실행하는 방법이 최적의 해법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "레거시 애플리케이션",
      "cron job",
      "스케줄링",
      "AWS Fargate",
      "이벤트 기반 실행"
    ],
    "Terms": [
      "Amazon EventBridge Scheduler",
      "AWS Batch",
      "Amazon ECS",
      "AWS Fargate",
      "AWS Step Functions",
      "Wait state",
      "RunTask"
    ],
    "SelectA": "cron job을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler로 반복 스케줄을 설정합니다. cron job 태스크를 AWS Lambda 함수로 실행합니다.",
    "SelectA_Commentary": "AWS Lambda는 최대 실행 시간이 15분이므로 20분이 걸리는 cron job을 처리하기 어렵습니다.",
    "SelectB": "cron job을 위한 컨테이너 이미지를 생성합니다. Amazon Elastic Container Service(Amazon ECS)에서 AWS Batch와 스케줄링 정책을 사용하여 cron job을 실행합니다.",
    "SelectB_Commentary": "AWS Batch는 대규모 배치 작업에 주로 사용되며, 단순 주기성 작업에는 상대적으로 오버엔지니어링일 수 있습니다.",
    "SelectC": "cron job을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler로 반복 스케줄을 생성합니다. cron job 태스크를 AWS Fargate에서 실행합니다.",
    "SelectC_Commentary": "Fargate 컨테이너는 20분 이상 실행 가능하여 cron job 요구사항에 부합합니다. EventBridge Scheduler를 통해 이벤트 기반 또는 반복 스케줄링이 간단히 가능합니다. 정답입니다.",
    "SelectD": "cron job을 위한 컨테이너 이미지를 생성합니다. 지정된 시간에 실행하기 위해 Wait 상태를 사용하는 AWS Step Functions 워크플로를 만듭니다. RunTask 액션을 사용해 AWS Fargate에서 cron job 태스크를 실행합니다.",
    "SelectD_Commentary": "Step Functions는 여러 단계의 복잡한 워크로드 오케스트레이션에 적합하나, 단순 cron job 스케줄링에는 과도하게 복잡합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q869",
      "Q519",
      "Q802",
      "Q8"
    ],
    "SelectA_recommedations": [
      "Q820",
      "Q785",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q820",
      "Q900",
      "Q775"
    ],
    "SelectC_recommedations": [
      "Q820",
      "Q194",
      "Q10"
    ],
    "SelectD_recommedations": [
      "Q820",
      "Q698",
      "Q10"
    ]
  },
  {
    "Question_Number": "Q821",
    "Question_Description": "어느 회사가 Salesforce를 사용 중입니다. 이 회사는 기존 데이터와 지속적으로 발생하는 데이터 변경 사항을 Amazon Redshift로 로드하여 분석하려고 합니다. 회사는 이 데이터가 퍼블릭 인터넷을 통해 전송되지 않도록 하길 원합니다. 가장 적은 개발 작업으로 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136993-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Salesforce와 Amazon Redshift 사이의 데이터 전송에서 퍼블릭 인터넷을 우회해 보안을 강화하는 방법을 묻습니다. PrivateLink로 Salesforce를 VPC 안으로 가져와서 Amazon AppFlow를 통해 쉽게 데이터를 전송하는 방식이 개발 및 운영 부담을 최소화하고 보안을 동시에 달성할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Salesforce",
      "기존 데이터",
      "지속적 데이터 변경",
      "Amazon Redshift",
      "퍼블릭 인터넷",
      "최소 개발 작업",
      "AWS PrivateLink",
      "Amazon AppFlow"
    ],
    "Terms": [
      "Salesforce",
      "Amazon Redshift",
      "AWS PrivateLink",
      "Amazon AppFlow",
      "AWS Glue DataBrew",
      "AWS Direct Connect",
      "VPN",
      "VPC",
      "VPC Peering"
    ],
    "SelectA": "VPC에서 Salesforce로 VPN 연결을 설정한 뒤, AWS Glue DataBrew를 사용하여 데이터를 전송합니다.",
    "SelectA_Commentary": "VPN은 사설 연결을 제공하지만, 구성과 운영 관리가 복잡해질 수 있고 Glue DataBrew로 실시간 연동 시 개발 노력이 더 듭니다.",
    "SelectB": "VPC에서 Salesforce로 AWS Direct Connect를 설정한 뒤, AWS Glue DataBrew를 사용하여 데이터를 전송합니다.",
    "SelectB_Commentary": "AWS Direct Connect는 전용 회선이지만 설정과 유지 비용이 높을 수 있고, Glue DataBrew로 데이터를 옮기는 과정에도 추가 구성이 필요합니다.",
    "SelectC": "VPC에서 Salesforce로 AWS PrivateLink 연결을 생성한 뒤, Amazon AppFlow를 사용하여 데이터를 전송합니다.",
    "SelectC_Commentary": "AWS PrivateLink로 퍼블릭 인터넷 없이 Salesforce를 VPC 안에서 직접 호출할 수 있고, Amazon AppFlow가 간편한 데이터 전송을 지원하므로 가장 적은 개발 작업으로 목표를 달성할 수 있는 정답입니다.",
    "SelectD": "VPC에서 Salesforce로 VPC Peering 연결을 생성한 뒤, Amazon AppFlow를 사용하여 데이터를 전송합니다.",
    "SelectD_Commentary": "VPC Peering은 동일한 소유자 또는 승인된 VPC 간의 연결에 적합하며, Salesforce 같은 외부 서비스에 직접 적용하기에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q548",
      "Q831",
      "Q922",
      "Q592",
      "Q313"
    ],
    "SelectA_recommedations": [
      "Q15",
      "Q950",
      "Q810"
    ],
    "SelectB_recommedations": [
      "Q451",
      "Q810",
      "Q15"
    ],
    "SelectC_recommedations": [
      "Q451",
      "Q15",
      "Q950"
    ],
    "SelectD_recommedations": [
      "Q950",
      "Q135",
      "Q15"
    ]
  },
  {
    "Question_Number": "Q822",
    "Question_Description": "한 회사가 최근 애플리케이션을 AWS로 마이그레이션했습니다. 이 애플리케이션은 여러 가용 영역에 걸쳐 Auto Scaling group에서 동작하는 Amazon EC2 Linux 인스턴스에서 실행됩니다. 애플리케이션은 Amazon EFS Standard-Infrequent Access를 사용하는 Amazon EFS 파일 시스템에 데이터를 저장하고 있습니다. 애플리케이션은 회사의 파일을 인덱싱하며, 그 인덱스는 Amazon RDS 데이터베이스에 저장되어 있습니다. 회사는 일부 애플리케이션 및 서비스를 변경하여 스토리지 비용을 최적화해야 합니다. 다음 중 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137046-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 Amazon EFS Standard-Infrequent Access를 사용하던 데이터를 더 저렴한 스토리지로 옮기면서, 애플리케이션 접근 방식을 변경하여 운영 비용을 절감하는 방안을 요구합니다. Amazon S3 Intelligent-Tiering은 데이터 액세스 패턴에 따라 자동으로 비용이 저렴한 스토리지 클래스로 전환해 주어, 빠른 액세스가 필요한 데이터와 거의 사용되지 않는 데이터를 효과적으로 관리할 수 있습니다. 게다가 EFS에서 S3로의 전환 시 애플리케이션이 S3 API를 사용하도록 업데이트하면 관리 오버헤드가 크게 줄어듭니다. 반면 다른 FSx 옵션은 주로 특정 파일 시스템 기능(Windows 혹은 OpenZFS)을 필요로 할 때 사용하며, S3 Glacier Flexible Retrieval은 매우 저렴하지만 빈번한 액세스에는 부적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "EC2 Linux 인스턴스",
      "Auto Scaling group",
      "Amazon EFS Standard-IA",
      "Amazon RDS",
      "스토리지 비용 최적화"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Availability Zone",
      "Amazon EFS",
      "EFS Standard-Infrequent Access",
      "Amazon RDS",
      "Amazon S3",
      "Intelligent-Tiering",
      "CIFS",
      "Amazon FSx for Windows File Server",
      "Amazon FSx for OpenZFS",
      "S3 Glacier Flexible Retrieval",
      "Standard Retrieval"
    ],
    "SelectA": "Amazon S3 버킷을 생성하고 Intelligent-Tiering 라이프사이클 정책을 사용합니다. 모든 파일을 이 S3 버킷으로 복사한 뒤, 애플리케이션을 Amazon S3 API로 파일을 저장하고 가져오도록 업데이트합니다.",
    "SelectA_Commentary": "자주 사용되는 데이터와 사용 빈도가 낮은 데이터를 Intelligent-Tiering으로 자동 분류할 수 있어, 비용과 접근성 간 균형을 최적화합니다.",
    "SelectB": "Amazon FSx for Windows File Server 파일 공유를 배포합니다. 파일을 저장하고 가져오기 위해 CIFS 프로토콜을 사용하도록 애플리케이션을 업데이트합니다.",
    "SelectB_Commentary": "Windows 기반 파일 서버 사용 사례에 적합하나, 기존 EFS보다 큰 비용 절감 효과가 제한적이며 Windows 파일 시스템 의존성이 없는 환경에서는 불필요한 옵션입니다.",
    "SelectC": "Amazon FSx for OpenZFS 파일 시스템 공유를 배포합니다. 새 마운트 지점을 사용하도록 애플리케이션을 업데이트해 파일을 저장하고 가져옵니다.",
    "SelectC_Commentary": "고성능, 고기능의 OpenZFS 환경이 필요할 때 적합하지만, EFS 대비 큰 비용 절감 효과가 없으므로 최적의 비용 절감 대안은 아닙니다.",
    "SelectD": "S3 Glacier Flexible Retrieval을 사용하는 Amazon S3 버킷을 생성합니다. 모든 파일을 해당 버킷으로 복사합니다. Amazon S3 API를 사용하여 파일을 표준 검색 방식으로 저장하고 가져오도록 애플리케이션을 업데이트합니다.",
    "SelectD_Commentary": "Glacier는 매우 저렴한 스토리지이지만, 정기적이거나 즉시 액세스가 필요한 경우 Retrieval 비용과 지연 시간이 누적되어 Overall 비용이 증가할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q277",
      "Q238",
      "Q719",
      "Q671",
      "Q505"
    ],
    "SelectA_recommedations": [
      "Q415",
      "Q498",
      "Q829"
    ],
    "SelectB_recommedations": [
      "Q719",
      "Q703",
      "Q277"
    ],
    "SelectC_recommedations": [
      "Q703",
      "Q806",
      "Q719"
    ],
    "SelectD_recommedations": [
      "Q912",
      "Q829",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q823",
    "Question_Description": "한 로보틱스 회사가 의료 수술을 위한 솔루션을 설계하고 있습니다. 이 로봇들은 고급 센서, 카메라, 그리고 AI 알고리즘을 사용하여 주변 환경을 인식하고 수술을 완료하게 됩니다. 이 회사는 AWS Cloud에서 퍼블릭 Load Balancer를 사용해 백엔드 서비스와 원활하게 통신해야 합니다. 또한 이 Load Balancer는 query string을 기반으로 트래픽을 서로 다른 Target Group으로 라우팅할 수 있어야 하며, 트래픽은 반드시 암호화되어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136955-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Application 레벨에서 query string을 확인해 트래픽을 라우팅하고, 암호화(HTTPS)를 위해 인증서를 적용해야 한다는 점이 핵심입니다. Network Load Balancer와 Gateway Load Balancer는 L4나 특정 트래픽 형태만 처리하므로, L7에서 세부 라우팅을 지원하는 Application Load Balancer가 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "퍼블릭 Load Balancer",
      "query string 기반 라우팅",
      "트래픽 암호화",
      "백엔드 서비스 통신",
      "Application Load Balancer",
      "AWS Certificate Manager"
    ],
    "Terms": [
      "Network Load Balancer",
      "AWS Certificate Manager (ACM)",
      "Gateway Load Balancer",
      "AWS Identity and Access Management (IAM)",
      "Application Load Balancer",
      "Query Parameter-based Routing",
      "HTTPS",
      "Target Group"
    ],
    "SelectA": "Network Load Balancer에 AWS Certificate Manager(ACM)의 인증서를 연결하고, query parameter-based routing을 사용합니다.",
    "SelectA_Commentary": "Network Load Balancer는 트래픽을 L4 레벨에서 처리하므로 query string을 판별할 수 없습니다.",
    "SelectB": "Gateway Load Balancer를 사용합니다. 생성한 인증서를 AWS Identity and Access Management(IAM)에 임포트하여 로드 밸런서에 연결하고, HTTP path-based routing을 사용합니다.",
    "SelectB_Commentary": "Gateway Load Balancer는 주로 서드파티 가상 어플라이언스 트래픽 관리를 위한 것으로, 세부적인 query parameter 라우팅을 지원하지 않습니다.",
    "SelectC": "Application Load Balancer에 AWS Certificate Manager(ACM)의 인증서를 연결하고, query parameter-based routing을 사용합니다.",
    "SelectC_Commentary": "Application Load Balancer는 L7에서 세부적으로 트래픽을 분산할 수 있으므로 query string 기반 라우팅이 가능하며, ACM 인증서를 통해 HTTPS 암호화도 지원합니다.",
    "SelectD": "Network Load Balancer를 사용합니다. 생성한 인증서를 AWS Identity and Access Management(IAM)에 임포트하여 로드 밸런서에 연결하고, query parameter-based routing을 사용합니다.",
    "SelectD_Commentary": "Network Load Balancer는 여전히 L4에서 트래픽을 처리하기 때문에 query string 정보를 판별해 라우팅할 수 없습니다.",
    "Question_Description_recommedations": [
      "Q631",
      "Q141",
      "Q687",
      "Q361",
      "Q192"
    ],
    "SelectA_recommedations": [
      "Q38",
      "Q266",
      "Q530"
    ],
    "SelectB_recommedations": [
      "Q597",
      "Q530",
      "Q266"
    ],
    "SelectC_recommedations": [
      "Q266",
      "Q141",
      "Q38"
    ],
    "SelectD_recommedations": [
      "Q530",
      "Q266",
      "Q815"
    ]
  },
  {
    "Question_Number": "Q824",
    "Question_Description": "어떤 회사에서 하나의 Amazon EC2 인스턴스에서 애플리케이션을 실행하고 있습니다. 해당 애플리케이션은 동일한 EC2 인스턴스에서 구동되는 MySQL 데이터베이스를 사용합니다. 회사는 증가하는 트래픽을 처리하기 위해 고가용성과 자동 확장 기능을 제공하는 솔루션이 필요합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136804-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 EC2 환경에서 동작하던 MySQL 기반 애플리케이션을, 트래픽 증가 시 자동으로 확장하고 동시에 높은 가용성을 확보할 수 있는 구조로 전환하는 시나리오입니다. Auto Scaling group과 Application Load Balancer를 통해 애플리케이션 레벨에서 탄력적으로 확장하고, 데이터베이스 계층에는 MySQL 호환성 및 자동 확장을 모두 제공하는 Amazon Aurora Serverless MySQL을 사용함으로써 요구사항을 충족할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "단일 Amazon EC2 인스턴스",
      "MySQL",
      "고가용성",
      "자동 확장",
      "증가하는 트래픽",
      "Amazon Aurora Serverless MySQL",
      "Auto Scaling group",
      "Application Load Balancer"
    ],
    "Terms": [
      "Amazon EC2",
      "MySQL",
      "Amazon Redshift",
      "Amazon RDS for MySQL",
      "Amazon Aurora Serverless MySQL",
      "Amazon ElastiCache for Redis",
      "Auto Scaling group",
      "Application Load Balancer",
      "Target group",
      "MySQL connector"
    ],
    "SelectA": "Application Load Balancer 뒤의 Auto Scaling group에서 애플리케이션을 실행하고, MySQL 호환 노드가 여러 개인 Amazon Redshift 클러스터를 생성합니다.",
    "SelectA_Commentary": "Amazon Redshift는 데이터 웨어하우징 서비스로, 운영 DB로서의 MySQL 대안이 아니므로 적합하지 않습니다.",
    "SelectB": "Application Load Balancer 뒤에 대상 그룹으로 구성된 EC2 인스턴스에 애플리케이션을 배포하고, 여러 인스턴스를 갖춘 Amazon RDS for MySQL 클러스터를 생성합니다.",
    "SelectB_Commentary": "RDS for MySQL은 고가용성을 구성할 수 있지만, 대상 그룹만으로는 EC2 인스턴스 자동 확장이 보장되지 않아 요구사항을 완전히 충족하기 어렵습니다.",
    "SelectC": "Application Load Balancer 뒤의 Auto Scaling group에서 애플리케이션을 실행하고, 데이터베이스 계층으로 Amazon Aurora Serverless MySQL 클러스터를 생성합니다.",
    "SelectC_Commentary": "Auto Scaling group으로 애플리케이션 레벨 자동 확장이 가능하며, Aurora Serverless MySQL로 DB 레벨 자동 확장과 고가용성을 모두 충족하므로 정답입니다.",
    "SelectD": "Application Load Balancer 뒤에 대상 그룹으로 구성된 EC2 인스턴스에 애플리케이션을 배포하고, MySQL 커넥터를 사용하는 Amazon ElastiCache for Redis 클러스터를 생성합니다.",
    "SelectD_Commentary": "ElastiCache for Redis는 캐싱 서비스로 MySQL DB를 대체하지 못하며, 마찬가지로 대상 그룹 구성만으로는 자동 확장이 보장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q584",
      "Q236",
      "Q182",
      "Q757",
      "Q244"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q537",
      "Q955"
    ],
    "SelectB_recommedations": [
      "Q298",
      "Q537",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q955",
      "Q69",
      "Q405"
    ],
    "SelectD_recommedations": [
      "Q537",
      "Q714",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q825",
    "Question_Description": "회사는 Amazon S3 버킷으로 데이터를 마이그레이션하려고 합니다. 저장 시점에서 데이터가 암호화되어야 하며, 암호화 키는 매년 자동으로 회전되어야 합니다. 또한 운영 오버헤드를 최소화해야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136805-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3에 저장되는 데이터를 연중 무휴로 안전하게 보호하고, 매년 자동으로 키를 회전해야 하며 운영 오버헤드를 최소화하는 시나리오입니다. SSE-S3 역시 자체 키 관리로 자동 회전을 제공하지만, 주어진 요구사항과 레퍼런스를 고려하면 고객이 직접 관리하는 KMS 키에 자동 회전을 활성화하여 사용함으로써 보안 요구사항을 더욱 명확히 충족할 수 있습니다. 따라서 고객 관리형 KMS 키를 사용해 자동 키 회전을 설정하면 매년 자동으로 키가 갱신되어 운영 부담이 가장 적은 솔루션이 됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "암호화",
      "AWS KMS",
      "자동 키 회전",
      "S3 버킷"
    ],
    "Terms": [
      "Amazon S3",
      "서버 사이드 암호화 (SSE-S3)",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key",
      "기본 암호화(Default Encryption)",
      "자동 키 회전(Auto Rotation)"
    ],
    "SelectA": "S3 버킷으로 데이터를 마이그레이션하고, Amazon S3 관리형 키(SSE-S3)로 서버 사이드 암호화를 사용합니다. SSE-S3 암호화 키의 기본적 키 회전 기능을 사용합니다.",
    "SelectA_Commentary": "SSE-S3는 자동으로 키를 관리하지만, 데이터 이전 시점에 암호화가 제대로 적용되지 않을 위험이 있으며 보안 요구사항 충족을 명확히 보장하지 못한다는 지적이 있습니다.",
    "SelectB": "AWS KMS에서 Customer Managed Key를 생성하고 자동 키 회전을 활성화합니다. S3 버킷의 기본 암호화를 이 KMS 키로 설정한 뒤 데이터를 마이그레이션합니다.",
    "SelectB_Commentary": "고객 관리형 KMS 키에 자동 키 회전을 설정하면 매년 키가 자동으로 갱신되어 운영 오버헤드가 매우 낮고, 데이터 보호 요구사항을 명확히 충족합니다. 정답입니다.",
    "SelectC": "AWS KMS에서 Customer Managed Key를 생성하고 S3 버킷의 기본 암호화를 이 KMS 키로 설정한 뒤 데이터를 마이그레이션합니다. 매년 KMS 키를 수동으로 회전합니다.",
    "SelectC_Commentary": "수동 회전을 직접 수행해야 하므로 운영 오버헤드가 증가합니다. 자동 회전 옵션이 있으므로 이 방식은 최적이 아닙니다.",
    "SelectD": "고객 키 자재로 데이터를 암호화한 뒤 S3 버킷으로 마이그레이션합니다. 이어서 키 자재 없이 KMS 키를 생성하고, 고객 키 자재를 가져와 자동 키 회전을 활성화합니다.",
    "SelectD_Commentary": "고객 키 자재를 사용해 직접 키를 관리하는 과정은 매우 복잡하며, 키 관리 전 과정에 대한 책임이 있어 운영 오버헤드가 큽니다.",
    "Question_Description_recommedations": [
      "Q44",
      "Q925",
      "Q154",
      "Q202",
      "Q696"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q862",
      "Q412"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q640",
      "Q36"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q36",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q825",
      "Q44",
      "Q106"
    ]
  },
  {
    "Question_Number": "Q826",
    "Question_Description": "한 회사가 자체적으로 관리하던 온프레미스 Microsoft Active Directory에서 AWS로 애플리케이션을 마이그레이션하고 있습니다. 해당 회사는 여러 AWS 계정에 애플리케이션을 배포했으며, AWS Organizations를 사용하여 계정을 중앙에서 관리하고 있습니다. 보안 팀은 모든 AWS 계정에 대해 단일 사인온(SSO) 솔루션을 요구하고 있고, 기존 온프레미스 Active Directory의 사용자와 그룹 관리는 계속 온프레미스에서 수행해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136806-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 온프레미스 Microsoft Active Directory의 사용자와 그룹을 유지하면서, 여러 AWS 계정에 대한 단일 사인온(SSO) 환경을 구현하는 방법을 묻습니다. 핵심은 AWS IAM Identity Center와 AWS Directory Service를 활용해 두 시스템 간 신뢰 관계를 설정함으로써, 중앙 집중적으로 사용자를 관리하면서도 각 계정에 대해 SSO를 제공하는 것입니다. 정답은 회사가 직접 운영 중인 온프레미스 AD를 그대로 유지하고, 필요 시 AWS IAM Identity Center와의 원활한 연동을 가능케 하는 B 옵션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "온프레미스 Active Directory",
      "단일 사인온",
      "여러 AWS 계정",
      "AWS Organizations",
      "사용자와 그룹 관리"
    ],
    "Terms": [
      "AWS IAM Identity Center",
      "Microsoft Active Directory",
      "AWS Directory Service",
      "two-way forest trust",
      "identity provider(IdP)"
    ],
    "SelectA": "AWS Directory Service for Microsoft Active Directory(Enterprise Edition)를 생성하고 이를 AWS IAM Identity Center의 identity source로 설정합니다.",
    "SelectA_Commentary": "새로운 AD를 AWS에 설치하고 이를 SSO로 사용하므로, 온프레미스의 사용자와 그룹을 동일하게 유지하기 어렵습니다. 온프레미스 AD를 그대로 사용해야 한다는 요구사항을 충족하지 못합니다.",
    "SelectB": "AWS IAM Identity Center를 활성화하고, AWS Directory Service for Microsoft Active Directory를 통해 온프레미스 AD와 two-way forest trust 관계를 설정하여 연동합니다.",
    "SelectB_Commentary": "온프레미스 Active Directory를 계속 관리하면서도 AWS IAM Identity Center를 통해 모든 AWS 계정에 대한 단일 사인온을 구현할 수 있는 전략적이고 단순화된 솔루션입니다. 정답입니다.",
    "SelectC": "AWS Directory Service를 사용하여 회사의 온프레미스 Active Directory와 two-way trust 관계를 설정합니다.",
    "SelectC_Commentary": "단일 사인온 요구사항을 만족시키기 위해서는 AWS IAM Identity Center가 필수적으로 필요합니다. 단순히 Directory Service만으로는 모든 AWS 계정에 대한 통합 SSO 구성이 어렵습니다.",
    "SelectD": "Amazon EC2 위에 IdP(Identity Provider)를 배포하고, 이를 AWS IAM Identity Center의 identity source로 연결합니다.",
    "SelectD_Commentary": "별도의 IdP를 직접 운영하려면 관리 복잡성이 커지고, 온프레미스의 Active Directory를 활용하려면 추가 설정이 필요해 요구사항을 간소화하기엔 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q28",
      "Q1018",
      "Q945",
      "Q624",
      "Q168"
    ],
    "SelectA_recommedations": [
      "Q826",
      "Q750",
      "Q761"
    ],
    "SelectB_recommedations": [
      "Q826",
      "Q688",
      "Q28"
    ],
    "SelectC_recommedations": [
      "Q826",
      "Q28",
      "Q1018"
    ],
    "SelectD_recommedations": [
      "Q96",
      "Q750",
      "Q457"
    ]
  },
  {
    "Question_Number": "Q827",
    "Question_Description": "한 회사가 Amazon Aurora PostgreSQL Serverless v2 클러스터에 애플리케이션을 배포할 계획입니다. 이 애플리케이션은 큰 폭의 트래픽을 수신할 예정입니다. 회사는 애플리케이션 부하가 증가함에 따라 클러스터의 스토리지 성능을 최적화하길 원하며, 이를 가장 비용 효율적으로 달성하고자 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트래픽이 크게 증가하는 애플리케이션을 위해 Amazon Aurora PostgreSQL Serverless v2 클러스터의 스토리지 성능을 높은 수준으로 유지하면서도 비용을 절감해야 하는 상황입니다. Aurora I/O-Optimized storage configuration은 I/O 요청당 과금이 없으므로 읽기/쓰기 횟수가 많은 환경에서 더 경제적입니다. 트래픽이 많을수록 추가적인 I/O 비용이 발생하지 않아 장기적으로 비용 효율성이 높습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon Aurora PostgreSQL Serverless v2",
      "Aurora Standard",
      "Provisioned IOPS",
      "General Purpose",
      "Aurora I/O-Optimized",
      "스토리지 성능",
      "트래픽 증가",
      "비용 효율"
    ],
    "Terms": [
      "Amazon Aurora PostgreSQL Serverless v2",
      "Aurora Standard storage configuration",
      "Aurora I/O-Optimized storage configuration",
      "Provisioned IOPS",
      "General Purpose"
    ],
    "SelectA": "클러스터를 Aurora Standard storage configuration으로 설정합니다.",
    "SelectA_Commentary": "Aurora Standard는 I/O에 대해 요청별 과금 방식으로, 높은 트래픽 환경에서는 I/O 비용이 크게 늘어날 수 있습니다.",
    "SelectB": "클러스터 스토리지 유형을 Provisioned IOPS로 설정합니다.",
    "SelectB_Commentary": "Provisioned IOPS는 강력한 성능을 제공하지만 트래픽 수준과는 무관하게 고정 비용이 발생하여 비효율적일 수 있습니다.",
    "SelectC": "클러스터 스토리지 유형을 General Purpose로 설정합니다.",
    "SelectC_Commentary": "General Purpose는 보통 범용 환경에 적합하지만, 트래픽이 크게 증가하면 IOPS나 처리량 측면에서 효율이 떨어질 수 있습니다.",
    "SelectD": "클러스터를 Aurora I/O-Optimized storage configuration으로 설정합니다.",
    "SelectD_Commentary": "대용량 트래픽에서 I/O 과금이 발생하지 않아, 트래픽이 증가할수록 더욱 비용 효율적인 방법입니다. 성능 최적화와 비용 절감을 모두 달성할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q671",
      "Q238",
      "Q436",
      "Q79",
      "Q579"
    ],
    "SelectA_recommedations": [
      "Q126",
      "Q943",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q307",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q997",
      "Q49",
      "Q656"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q828",
    "Question_Description": "AWS를 사용하는 한 금융 서비스 회사가 산업 표준인 NIST 및 PCI DSS를 충족하기 위해 보안 통제를 설계했습니다. 외부 감사 기관은 이 보안 통제가 올바르게 구현되고 정상적으로 작동하고 있음을 증명해야 합니다. 회사는 단일 AWS Organizations 조직에서 수백 개의 AWS 계정을 운영 중이며, 모든 계정에 대해 현재 보안 통제 상태를 모니터링해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136994-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 NIST, PCI DSS 등 산업 표준에 맞는 보안 통제 상태를 한 번에 확인해야 하는 상황입니다. AWS Security Hub를 사용하면 계정 전체의 보안 표준 준수 현황을 중앙에서 평가하고, 필요한 조치 사항을 통합적으로 추적할 수 있으므로 요구사항을 잘 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "보안 통제",
      "NIST",
      "PCI DSS",
      "AWS Organizations",
      "감사",
      "모니터링"
    ],
    "Terms": [
      "AWS Organizations",
      "Amazon Inspector",
      "Amazon GuardDuty",
      "AWS CloudTrail",
      "AWS Security Hub",
      "NIST",
      "PCI DSS"
    ],
    "SelectA": "Organizations 관리 계정에서 하나의 계정을 Amazon Inspector 위임 관리자 계정으로 지정하고, Inspector를 Organizations와 통합하여 모든 AWS 계정을 스캔합니다. Inspector에서 NIST 및 PCI DSS 산업 표준을 활성화합니다.",
    "SelectA_Commentary": "Amazon Inspector는 주로 취약점 검사와 악성 소프트웨어 탐지에 중점을 두며, 전반적인 규정 준수 상태를 종합적으로 모니터링하기에는 적합하지 않습니다.",
    "SelectB": "Organizations 관리 계정에서 하나의 계정을 Amazon GuardDuty 위임 관리자 계정으로 지정합니다. 지정된 GuardDuty 관리자 계정에서 모든 멤버 계정을 보호하도록 GuardDuty를 활성화하고, NIST 및 PCI DSS 산업 표준을 적용합니다.",
    "SelectB_Commentary": "Amazon GuardDuty는 위협 탐지 서비스로, 침투 시도를 모니터링하지만 산업 표준별 보안 체크리스트 준수 상황을 직접 제공하지 않습니다.",
    "SelectC": "Organizations 관리 계정에서 AWS CloudTrail 조직 트레일을 구성합니다. 하나의 계정을 컴플라이언스 계정으로 지정한 뒤 NIST 및 PCI DSS 표준을 이 계정에서 CloudTrail에 적용합니다.",
    "SelectC_Commentary": "AWS CloudTrail은 계정 활동 로깅과 감사에 유용하지만, 산업 표준별 세부 통제 사항 평가에 특화된 기능은 제공하지 않습니다.",
    "SelectD": "Organizations 관리 계정에서 하나의 계정을 AWS Security Hub 위임 관리자 계정으로 지정합니다. 해당 계정에서 모든 멤버 계정에 대해 Security Hub를 활성화하고, NIST 및 PCI DSS 표준을 적용합니다.",
    "SelectD_Commentary": "AWS Security Hub는 계정 전반의 보안 표준 준수 상황을 종합적으로 평가하고 보고할 수 있으므로 요구사항을 가장 효과적으로 충족합니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q1018",
      "Q787",
      "Q3"
    ],
    "SelectA_recommedations": [
      "Q828",
      "Q945",
      "Q168"
    ],
    "SelectB_recommedations": [
      "Q828",
      "Q945",
      "Q168"
    ],
    "SelectC_recommedations": [
      "Q828",
      "Q619",
      "Q942"
    ],
    "SelectD_recommedations": [
      "Q828",
      "Q168",
      "Q945"
    ]
  },
  {
    "Question_Number": "Q829",
    "Question_Description": "한 회사가 Amazon S3 버킷을 데이터 레이크 저장소 플랫폼으로 사용하고 있습니다. 이 S3 버킷에는 여러 팀과 수백 개의 애플리케이션이 임의로 액세스하는 대규모 데이터가 저장되어 있습니다. 회사는 S3 저장 비용을 절감하고, 자주 액세스되는 객체들에 대해 즉시 가용성을 보장하고자 합니다. 이러한 요구 사항을 만족하면서 가장 운영 효율적인 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136995-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 데이터를 S3에 저장하면서, 자주 요청되는 객체들이 즉시 액세스 가능하도록 유지하고 비용도 절감해야 하는 상황입니다. S3 Intelligent-Tiering은 접근 패턴에 따라 자동으로 객체를 적절한 계층으로 옮겨 운영 복잡도를 낮추고 비용을 효율적으로 관리해주는 최적의 선택입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "S3 저장 비용 절감",
      "자주 액세스 데이터",
      "운영 효율성",
      "즉시 가용성",
      "S3 Intelligent-Tiering"
    ],
    "Terms": [
      "S3 Lifecycle",
      "S3 Intelligent-Tiering",
      "Amazon S3 Glacier",
      "S3 Select",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 storage class analysis",
      "AWS Lambda"
    ],
    "SelectA": "S3 Intelligent-Tiering 스토리지 클래스로 객체를 이전하기 위한 S3 Lifecycle 규칙을 만듭니다.",
    "SelectA_Commentary": "S3 Intelligent-Tiering은 객체 액세스 패턴을 자동으로 모니터링한 뒤 빈도에 맞춰 적절한 계층으로 옮겨주어 관리 부담과 비용을 모두 줄입니다. 즉시 액세스도 보장됩니다.",
    "SelectB": "Amazon S3 Glacier에 객체를 저장하고, S3 Select를 사용해 애플리케이션에 데이터 접근을 제공합니다.",
    "SelectB_Commentary": "Amazon S3 Glacier는 장기 보관 용도로 최적화되었고 데이터 복원 지연이 있어 자주 액세스하는 경우 비효율적입니다.",
    "SelectC": "S3 storage class analysis 결과를 사용해 S3 Lifecycle 규칙을 작성하고, 객체를 S3 Standard-IA로 자동 전환합니다.",
    "SelectC_Commentary": "Standard-IA는 저렴하지만 자주 액세스되는 객체에 대한 즉시성 보장이 어렵고, 액세스 패턴이 변동될 때마다 재설정이 필요해 운영 부담이 큽니다.",
    "SelectD": "객체를 S3 Standard-IA로 전환하고, AWS Lambda 함수를 생성해 애플리케이션이 객체에 액세스할 때 S3 Standard로 다시 전환하도록 합니다.",
    "SelectD_Commentary": "Lambda를 통한 수동 전환은 관리가 복잡해지고 적시에 전환이 되지 않을 수 있어 자주 액세스 시 즉시성 보장이 어렵습니다.",
    "Question_Description_recommedations": [
      "Q498",
      "Q469",
      "Q769",
      "Q415",
      "Q993"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q486",
      "Q415"
    ],
    "SelectB_recommedations": [
      "Q285",
      "Q911",
      "Q1003"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q23",
      "Q356"
    ]
  },
  {
    "Question_Number": "Q830",
    "Question_Description": "한 회사가 5 TB 규모의 데이터를 보유하고 있습니다. 이 데이터세트는 100만 개의 사용자 프로필과 1천만 개의 커넥션으로 구성되어 있습니다. 사용자 프로필은 다대다 관계로 커넥션을 맺고 있습니다. 회사는 최대 5단계까지의 상호 커넥션을 성능 효율적으로 찾을 수 있는 방법이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136957-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "다대다 관계가 많은 대용량 데이터를 빠르게 탐색하기 위해서는 그래프 데이터베이스가 적합합니다. Amazon Neptune은 edges 및 vertices 구조를 활용해 복잡한 네트워크 관계를 효율적으로 쿼리할 수 있습니다. 따라서 상호 커넥션을 여러 단계에 걸쳐 신속하게 찾아야 하는 본 시나리오에 최적의 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "5 TB",
      "사용자 프로필",
      "커넥션",
      "다대다 관계",
      "5단계 상호 커넥션",
      "Amazon Neptune",
      "edges",
      "vertices"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Athena",
      "SQL JOIN",
      "Amazon Neptune",
      "edges",
      "vertices",
      "Amazon QuickSight",
      "Amazon RDS"
    ],
    "SelectA": "Amazon S3 버킷에 데이터를 저장합니다. Amazon Athena를 사용하여 SQL JOIN 쿼리를 통해 커넥션을 찾습니다.",
    "SelectA_Commentary": "Athena로 SQL JOIN을 수행하면 대규모 조인 시 성능 부담이 크고, 트리 구조의 다단계 탐색에 적합하지 않습니다.",
    "SelectB": "Amazon Neptune에 edges와 vertices로 데이터를 저장합니다. 커넥션을 찾기 위해 데이터를 쿼리합니다.",
    "SelectB_Commentary": "그래프 데이터베이스인 Neptune은 다단계의 많은 관계를 빠르고 유연하게 분석할 수 있어 요구사항에 가장 적합합니다.",
    "SelectC": "Amazon S3 버킷에 데이터를 저장합니다. Amazon QuickSight를 사용하여 커넥션을 시각화합니다.",
    "SelectC_Commentary": "시각화 도구인 QuickSight는 그래프 연산을 최적화하지 않으며, 다른 서비스가 필요해 운영 복잡도가 증가합니다.",
    "SelectD": "Amazon RDS에 여러 테이블로 데이터를 저장합니다. SQL JOIN 쿼리를 통해 커넥션을 찾습니다.",
    "SelectD_Commentary": "관계형 DB에서 다대다 관계를 깊게 탐색할 경우 반복 조인으로 인해 성능 문제가 발생하기 쉽습니다.",
    "Question_Description_recommedations": [
      "Q1000",
      "Q1",
      "Q113",
      "Q747",
      "Q397"
    ],
    "SelectA_recommedations": [
      "Q292",
      "Q672",
      "Q501"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q746",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q292",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q269",
      "Q661",
      "Q95"
    ]
  },
  {
    "Question_Number": "Q831",
    "Question_Description": "한 회사가 온프레미스 환경과 AWS 간에 안전한 연결을 구성해야 합니다. 이 연결은 높은 대역폭이 필요하지 않으며 적은 양의 트래픽을 처리할 예정입니다. 또한 빠른 설정이 가능해야 합니다. 이와 같은 유형의 연결을 가장 비용 효율적으로 구축하는 방법은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136997-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경과 AWS 사이의 네트워크 연결을 빠르고 안정적으로 구성하는 방법을 묻습니다. Site-to-Site VPN은 비교적 적은 대역폭 요구 사항에 대해 저렴하고 빠른 배포가 가능하며, 안전한 연결을 제공한다는 점에서 가장 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "안전한 연결",
      "온프레미스 환경",
      "소규모 트래픽",
      "빠른 설정",
      "비용 효율"
    ],
    "Terms": [
      "Client VPN",
      "AWS Direct Connect",
      "Bastion Host",
      "Amazon EC2",
      "AWS Site-to-Site VPN"
    ],
    "SelectA": "Client VPN을 구현합니다.",
    "SelectA_Commentary": "Client VPN은 개별 클라이언트 연결용으로, 사이트 간 연결에는 적합하지 않습니다.",
    "SelectB": "AWS Direct Connect를 구현합니다.",
    "SelectB_Commentary": "Direct Connect는 전용 회선으로 안정성과 높은 대역폭을 제공하지만 비용이 높고 설정에 시간이 많이 걸립니다.",
    "SelectC": "Amazon EC2에 bastion host를 구현합니다.",
    "SelectC_Commentary": "bastion host는 SSH나 RDP 접속을 위한 중간 서버로서, 온프레미스와 AWS 간 전체 트래픽을 안전하게 전송하는 솔루션이 아닙니다.",
    "SelectD": "AWS Site-to-Site VPN connection을 구현합니다.",
    "SelectD_Commentary": "Site-to-Site VPN은 구축이 빠르면서도 안전하고 비용 효율적인 연결 방식을 제공하므로 요구 사항에 가장 부합합니다.",
    "Question_Description_recommedations": [
      "Q922",
      "Q313",
      "Q592",
      "Q548",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q265",
      "Q803",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectC_recommedations": [
      "Q682",
      "Q73",
      "Q480"
    ],
    "SelectD_recommedations": [
      "Q782",
      "Q810",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q832",
    "Question_Description": "한 회사가 온프레미스 SFTP 파일 전송 솔루션을 운영하고 있습니다. 이 회사는 Amazon S3를 사용하여 파일 전송 솔루션을 확장하고 비용을 최적화하기 위해 AWS Cloud로 이전하려고 합니다. 회사 직원들은 온프레미스 Microsoft Active Directory(AD) 자격 증명을 사용해 새 솔루션에 액세스해야 하며, 현재의 인증 및 파일 접근 방식을 그대로 유지하기를 원합니다. 다음 중 어떤 솔루션이 최소한의 운영 오버헤드로 이러한 요구사항을 충족할 수 있습니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136998-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "온프레미스 AD 계정으로 SFTP 서비스를 유지하면서 효율적으로 확장하고 운영 부담을 줄이려면, AWS Transfer Family와 AD Connector를 통해 기존 인증체계를 활용하는 장점이 가장 큽니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "온프레미스 SFTP 파일 전송 솔루션",
      "Amazon S3",
      "비용 최적화",
      "Microsoft Active Directory(AD)",
      "현재 인증 및 파일 접근 방식",
      "최소한의 운영 오버헤드",
      "AWS Transfer Family",
      "SFTP 엔드포인트",
      "AWS Directory Service",
      "AD Connector"
    ],
    "Terms": [
      "S3 File Gateway",
      "SMB file share",
      "Amazon S3",
      "Microsoft Active Directory(AD)",
      "AWS Directory Service",
      "AD Connector",
      "AWS Transfer Family",
      "SFTP endpoint",
      "Auto Scaling group",
      "Amazon EC2"
    ],
    "SelectA": "S3 File Gateway를 구성하고, 기존 Active Directory를 이용해 인증하는 SMB 파일 공유를 설정합니다.",
    "SelectA_Commentary": "S3 File Gateway는 SMB 기반 파일 공유에 적합하지만 SFTP 전송과 연계해 기존 AD 인증 방식을 직접 적용하기에는 추가 구성이 많아 운영이 복잡합니다.",
    "SelectB": "Amazon EC2 인스턴스에서 SFTP 솔루션을 실행하는 Auto Scaling group을 구성하고, 60% CPU 이용률에서 스케일 업하도록 설정합니다.",
    "SelectB_Commentary": "EC2 기반으로 SFTP를 직접 운영하면 확장성은 확보되지만 서버 관리, 보안 패치 등 운영 부담이 높아지고, AD 연동도 직접 구현해야 해 복잡성이 큽니다.",
    "SelectC": "AWS Transfer Family 서버를 생성하고 SFTP 엔드포인트를 구성합니다. AWS Directory Service 옵션을 신원 공급자로 선택하고, AD Connector를 사용해 온프레미스 AD에 연결합니다.",
    "SelectC_Commentary": "AWS Transfer Family와 AD Connector 연동으로 온프레미스 AD를 그대로 사용하면서 SFTP를 제공해, 최소 운영 부담으로 기존 인증 방식을 유지할 수 있는 최적의 솔루션입니다.",
    "SelectD": "AWS Transfer Family SFTP 엔드포인트를 생성하고, AWS Directory Service 옵션을 사용해 기존 Active Directory에 직접 연결하도록 설정합니다.",
    "SelectD_Commentary": "AD Connector가 명시되지 않아 온프레미스 AD와의 직접 통합에 추가 구성이 필요합니다. 운영 오버헤드는 C보다 더 많이 발생할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q334",
      "Q816",
      "Q638",
      "Q109",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q334",
      "Q832",
      "Q965"
    ],
    "SelectB_recommedations": [
      "Q453",
      "Q480",
      "Q17"
    ],
    "SelectC_recommedations": [
      "Q832",
      "Q826",
      "Q451"
    ],
    "SelectD_recommedations": [
      "Q832",
      "Q334",
      "Q826"
    ]
  },
  {
    "Question_Number": "Q833",
    "Question_Description": "한 회사가 이벤트 기반(event-driven) 주문 처리 시스템을 설계하고 있습니다. 각 주문은 생성된 후 여러 단계의 검증 절차를 거쳐야 합니다. 각 검증 단계는 idempotent한 AWS Lambda 함수로 수행되며, 각 단계는 서로 독립적으로 동작합니다. 개별 검증 단계는 주문 이벤트 정보 중 필요한 서브셋만 사용하면 됩니다. 회사는 각 검증 단계 Lambda 함수가 해당 함수에 필요한 주문 이벤트 정보만 접근하도록 하고 싶습니다. 또한 향후 비즈니스 변경에 대비하기 위해 시스템 구성 요소들을 느슨하게 결합(loose coupling)하려고 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137000-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon EventBridge를 사용하면 각 검증 단계마다 이벤트 룰과 Input Transformer를 설정해 필요한 정보만 Lambda 함수에 전달할 수 있어, 시스템을 느슨하게 결합하고 유연하게 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "이벤트 기반 주문 처리",
      "검증 단계",
      "idempotent AWS Lambda",
      "느슨한 결합",
      "주문 이벤트 서브셋"
    ],
    "Terms": [
      "Amazon SQS",
      "Amazon SNS",
      "Amazon EventBridge",
      "AWS Lambda",
      "Message Body Filtering",
      "Event Bus",
      "Input Transformer"
    ],
    "SelectA": "각 검증 단계별로 Amazon SQS 큐를 생성합니다. 주문 데이터를 각 검증 단계에 맞는 형식으로 변환해 해당 SQS 큐에 메시지를 게시하는 새로운 Lambda 함수를 작성합니다. 각 검증 단계 Lambda 함수는 해당 큐에 구독시킵니다.",
    "SelectA_Commentary": "단계별로 여러 SQS 큐와 변환 함수를 구성해야 하므로 오버헤드가 증가하고, 향후 단계 변경 시 확장성이 떨어집니다.",
    "SelectB": "Amazon SNS 토픽을 생성합니다. 검증 단계 Lambda 함수들을 SNS 토픽에 구독시킵니다. 메시지 바디 필터링을 사용하여 각 구독된 Lambda 함수에 필요한 데이터만 전송합니다.",
    "SelectB_Commentary": "SNS의 메시지 필터링은 조건에 맞추어 전체 메시지를 전달하거나 버리는 방식이며, 메시지 내용 일부만 선별적으로 보내는 기능이 제한적입니다.",
    "SelectC": "Amazon EventBridge 이벤트 버스를 생성합니다. 각 검증 단계를 위한 이벤트 룰을 구성합니다. Input Transformer를 설정해 각 대상 검증 단계 Lambda 함수에 필요한 정보만 전달합니다.",
    "SelectC_Commentary": "이벤트 룰과 Input Transformer로 필요한 데이터만 추출해 각 Lambda 함수에 전달함으로써 시스템을 느슨하게 결합하고 기능별 독립성을 보장합니다.",
    "SelectD": "Amazon SQS 큐를 생성합니다. 새로운 Lambda 함수를 구독시켜 주문 데이터를 각 검증 단계에 맞게 변환합니다. 이 Lambda 함수에서 검증 단계 Lambda 함수를 개별 스레드로 동기 호출하여 병렬 실행합니다.",
    "SelectD_Commentary": "한 Lambda 함수가 다른 Lambda 함수를 동기식으로 호출하며, 별도의 병렬 처리 로직까지 필요해 구조가 복잡해지고 결합도가 높아집니다.",
    "Question_Description_recommedations": [
      "Q351",
      "Q18",
      "Q785",
      "Q720",
      "Q404"
    ],
    "SelectA_recommedations": [
      "Q785",
      "Q98",
      "Q112"
    ],
    "SelectB_recommedations": [
      "Q45",
      "Q785",
      "Q489"
    ],
    "SelectC_recommedations": [
      "Q569",
      "Q785",
      "Q739"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q404",
      "Q18"
    ]
  },
  {
    "Question_Number": "Q834",
    "Question_Description": "한 회사가 3티어 애플리케이션을 AWS로 마이그레이션하고자 합니다. 애플리케이션에는 MySQL 데이터베이스가 필요합니다. 과거에는 근무 시간 동안 사용자들이 다양한 실시간 리포트를 생성하면서, 새로운 항목을 생성할 때 애플리케이션 성능이 저하된 문제가 있었습니다. 이 애플리케이션을 AWS로 이전했을 때 성능을 개선하기 위한 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137842-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 읽기 쿼리(리포트 생성)와 쓰기 쿼리(새 항목 생성)가 동시에 발생할 때 발생하는 성능 저하를 해결하는 방법을 묻습니다. Read replica를 활용하면 대량 읽기 요청이 분산되어, 쓰기 작업이 수행되는 메인 데이터베이스의 부담을 줄일 수 있어 애플리케이션 전반적인 성능이 향상됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "3티어 애플리케이션",
      "MySQL 데이터베이스",
      "성능 문제",
      "실시간 리포트",
      "Amazon Aurora MySQL",
      "Multi-AZ DB 클러스터",
      "Read Replica"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "Provisioned capacity",
      "Compute optimized Amazon EC2",
      "Amazon Aurora MySQL Multi-AZ DB cluster",
      "Read replica",
      "Backup instance"
    ],
    "SelectA": "Amazon DynamoDB 테이블에 데이터를 임포트하고, 애플리케이션을 DynamoDB 리포트용으로 리팩터링합니다.",
    "SelectA_Commentary": "DB 종류를 변경하므로 기존 MySQL 기반 애플리케이션 수정이 크고, 즉각적인 성능 문제 해결에 비효율적입니다.",
    "SelectB": "Compute optimized Amazon EC2 인스턴스에서 DB를 생성하고, 온프레미스 DB보다 큰 컴퓨팅 리소스를 제공합니다.",
    "SelectB_Commentary": "단순히 CPU나 메모리를 늘리는 것만으로는 실시간 리포트 병목을 근본적으로 해결하기 어렵습니다.",
    "SelectC": "Amazon Aurora MySQL Multi-AZ DB 클러스터를 생성하고 여러 개의 read replica를 추가합니다. 애플리케이션이 리포트 시 reader endpoint를 사용하도록 구성합니다.",
    "SelectC_Commentary": "읽기 요청이 read replica로 분산되어 메인 DB의 쓰기 성능 저하를 방지하며, 실시간 리포트에도 적합한 최적의 솔루션입니다.",
    "SelectD": "Amazon Aurora MySQL Multi-AZ DB 클러스터를 생성한 뒤, 해당 클러스터의 백업 인스턴스를 리포트용 엔드포인트로 구성합니다.",
    "SelectD_Commentary": "백업 인스턴스는 읽기 전용 목적에 최적화되지 않으며, 정확한 실시간 데이터 조회가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q565",
      "Q229",
      "Q192",
      "Q292",
      "Q173"
    ],
    "SelectA_recommedations": [
      "Q177",
      "Q472",
      "Q578"
    ],
    "SelectB_recommedations": [
      "Q229",
      "Q857",
      "Q910"
    ],
    "SelectC_recommedations": [
      "Q247",
      "Q337",
      "Q946"
    ],
    "SelectD_recommedations": [
      "Q481",
      "Q886",
      "Q235"
    ]
  },
  {
    "Question_Number": "Q835",
    "Question_Description": "한 회사가 AWS Direct Connect connection을 사용해 보안 온프레미스 네트워크를 AWS Cloud로 확장하고 있습니다. 온프레미스 네트워크에는 직접 인터넷 액세스가 없습니다. 온프레미스 네트워크에서 실행되는 애플리케이션은 Amazon S3 bucket을 사용해야 합니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137001-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "온프레미스 환경에서 직접 인터넷에 연결할 수 없는 상황에서, 비용 효율적으로 Amazon S3를 사용하기 위해서는 VPC에 Amazon S3 interface endpoint를 구성하여 프라이빗 경로로 S3에 접근하는 방식이 가장 적합합니다. NAT gateway나 public VIF를 사용하면 불필요한 인터넷 트래픽이 발생하거나 추가 비용이 들 수 있고, VPC peering은 온프레미스와 직접 연결에 적합하지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "AWS Direct Connect",
      "Amazon S3",
      "비용 효율성",
      "온프레미스 네트워크",
      "인터넷 미제공",
      "VPC endpoint"
    ],
    "Terms": [
      "AWS Direct Connect",
      "VPC",
      "NAT gateway",
      "Amazon S3 interface endpoint",
      "public virtual interface (VIF)",
      "VPC peering connection"
    ],
    "SelectA": "Create a public virtual interface (VIF). Route the AWS traffic over the public VIF.",
    "SelectA_Commentary": "Public VIF 사용 시 인터넷 경로를 거치게 되어, 보안 및 비용 면에서 비효율적입니다.",
    "SelectB": "Create a VPC and a NAT gateway. Route the AWS traffic from the on-premises network to the NAT gateway.",
    "SelectB_Commentary": "NAT gateway는 외부 인터넷 경로가 필요하고, 데이터 전송 비용이 추가로 발생하여 가장 비용 효율적이지 않습니다.",
    "SelectC": "Create a VPC and an Amazon S3 interface endpoint. Route the AWS traffic from the on-premises network to the S3 interface endpoint.",
    "SelectC_Commentary": "직접 인터넷 없이도 VPC endpoint를 통해 안전하고 저렴하게 S3에 접근할 수 있는 최적의 솔루션입니다.",
    "SelectD": "Create a VPC peering connection between the on-premises network and Direct Connect. Route the AWS traffic over the peering connection.",
    "SelectD_Commentary": "VPC peering은 주로 VPC 간 연결을 위한 기능이며, 온프레미스 네트워크 연결에는 부적합하고 비용 효율성도 떨어집니다.",
    "Question_Description_recommedations": [
      "Q240",
      "Q205",
      "Q497",
      "Q960",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q860",
      "Q943",
      "Q238"
    ],
    "SelectB_recommedations": [
      "Q497",
      "Q860",
      "Q42"
    ],
    "SelectC_recommedations": [
      "Q497",
      "Q860",
      "Q471"
    ],
    "SelectD_recommedations": [
      "Q835",
      "Q240",
      "Q499"
    ]
  },
  {
    "Question_Number": "Q836",
    "Question_Description": "한 회사가 단일 AWS 리전에 Amazon EC2 Auto Scaling group을 사용하여 웹사이트를 운영하고 있습니다. 이 웹사이트는 데이터베이스를 필요로 하지 않습니다. 회사가 확장됨에 따라 엔지니어링 팀은 두 번째 리전에 웹사이트를 배포했습니다. 회사는 성장과 재해 복구(Disaster Recovery)를 위해 두 리전에 걸쳐 트래픽을 분산하기 원하며, 웹사이트가 비정상인 리전에서는 트래픽을 제공하지 않도록 해야 합니다. 이러한 요구 사항을 충족하기 위한 Amazon Route 53의 정책 혹은 리소스는 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137002-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 리전에 웹사이트를 배포하여 확장성과 재해 복구 기능을 확보하려는 시나리오입니다. 멀티 리전에 대한 트래픽 분산 시, 비정상 리전을 자동으로 제외하려면 Amazon Route 53의 Multivalue Answer Routing을 사용해 건강하지 않은 리소스를 걸러내는 것이 적절한 해결책입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Auto Scaling group",
      "Amazon EC2",
      "두 번째 리전 배포",
      "트래픽 분산",
      "재해 복구",
      "비정상 리전 제외",
      "Amazon Route 53 multivalue answer routing policy"
    ],
    "Terms": [
      "Amazon Route 53",
      "Simple Routing Policy",
      "Multivalue Answer Routing",
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon EC2",
      "IP addresses",
      "DNS health checks"
    ],
    "SelectA": "Amazon Route 53 simple routing policy",
    "SelectA_Commentary": "Simple routing policy는 단일 리소스로 트래픽을 분산하거나 무작위로 분배할 때 사용하므로 멀티 리전을 자동으로 헬스 체크 후 제외하기에는 충분하지 않습니다.",
    "SelectB": "Amazon Route 53 multivalue answer routing policy",
    "SelectB_Commentary": "멀티 리전으로 구성된 IP 주소나 리소스를 동시에 반환하면서 건강하지 않은 리전을 제외할 수 있어 요구 사항을 충족하는 최적의 선택지입니다.",
    "SelectC": "한 리전에 있는 Application Load Balancer와 양쪽 리전의 EC2 인스턴스 ID를 지정한 Target Group",
    "SelectC_Commentary": "단일 리전에 위치한 ALB는 다른 리전에 대한 엔드포인트를 직접적으로 관리하기 복잡하며, 리전 간 트래픽 분산 및 헬스 체크 처리도 제한적입니다.",
    "SelectD": "한 리전에 있는 Application Load Balancer와 양쪽 리전의 EC2 인스턴스 IP 주소를 지정한 Target Group",
    "SelectD_Commentary": "역시 ALB가 한 리전에만 존재하므로 다른 리전에 대한 직접적인 트래픽 분산이 번거롭고, 멀티 리전 헬스 체크나 재해 복구 구성에도 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q595",
      "Q581",
      "Q271",
      "Q1001",
      "Q691"
    ],
    "SelectA_recommedations": [
      "Q545",
      "Q869",
      "Q242"
    ],
    "SelectB_recommedations": [
      "Q869",
      "Q363",
      "Q584"
    ],
    "SelectC_recommedations": [
      "Q405",
      "Q813",
      "Q275"
    ],
    "SelectD_recommedations": [
      "Q405",
      "Q813",
      "Q275"
    ]
  },
  {
    "Question_Number": "Q837",
    "Question_Description": "한 회사는 Amazon EBS를 기반 스토리지로 사용하는 Amazon EC2 인스턴스에서 애플리케이션을 구동하고 있습니다. EC2 인스턴스는 최신 Amazon Linux를 사용하며, 25GB 이상의 파일을 저장하고 조회할 때 애플리케이션에 가용성 문제가 발생합니다. 또한 회사는 EC2 인스턴스 간에 파일을 전송하지 않아도 되며, 여러 EC2 인스턴스와 여러 가용 영역에 걸쳐 파일에 액세스할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137843-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대용량 파일(25GB 이상)을 여러 EC2 인스턴스와 여러 가용 영역에서 동시에 액세스해야 하는 상황에서 발생하는 가용성 문제를 해결하는 방법을 묻습니다. Amazon EFS는 다중 AZ 지원과 동시에 공유 파일 시스템을 제공하므로, 파일을 옮기지 않고도 여러 인스턴스가 실시간으로 동일 데이터를 읽고 쓸 수 있어 문제 해결에 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "Amazon EBS",
      "Amazon EC2 인스턴스",
      "25GB 이상의 파일",
      "가용성 문제",
      "여러 가용 영역",
      "Amazon EFS"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Amazon S3",
      "Amazon EFS",
      "Snapshot",
      "Amazon Machine Image (AMI)",
      "Instance Store Volume"
    ],
    "SelectA": "모든 파일을 Amazon S3 버킷으로 이전합니다. 회사 직원에게는 S3 버킷에서 파일을 액세스하도록 안내합니다.",
    "SelectA_Commentary": "S3는 객체 스토리지이므로 파일 시스템 인터페이스가 필요할 경우 추가적인 애플리케이션 변경이 필요하고, 파일 단위 접근이 번거로울 수 있습니다. 즉시 다중 인스턴스 공유보다는 EFS가 더 적합합니다.",
    "SelectB": "기존 EBS 볼륨의 스냅샷을 생성합니다. 그 스냅샷을 기반으로 EBS 볼륨을 마운트하여 EC2 인스턴스에서 파일을 액세스하도록 안내합니다.",
    "SelectB_Commentary": "EBS 스냅샷은 단일 AZ 범위로 멀티 AZ 접근이 쉽지 않습니다. 변경 사항이 발생할 때마다 스냅샷을 다시 생성해야 하며, 여러 인스턴스가 동시에 쓰기 작업을 공유하기도 어렵습니다.",
    "SelectC": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 모든 EC2 인스턴스에 마운트합니다. 회사 직원에게는 해당 EC2 인스턴스에서 파일을 액세스하도록 안내합니다.",
    "SelectC_Commentary": "EFS는 멀티 AZ 환경에서 동시에 접근 가능한 완전관리형 NFS 스토리지로, 대용량 파일을 여러 인스턴스가 동시에 공유하고 쓸 수 있어 가용성과 확장성 문제를 가장 효과적으로 해결합니다.",
    "SelectD": "기존 EC2 인스턴스로부터 Amazon Machine Image(AMI)를 생성합니다. 인스턴스 스토어 볼륨을 사용하는 신규 EC2 인스턴스를 구성한 후, 회사 직원에게 해당 인스턴스에서 파일을 액세스하도록 안내합니다.",
    "SelectD_Commentary": "Instance Store는 인스턴스가 중단되거나 재시작될 때 데이터가 사라질 수 있으며, 다중 AZ 간 공유도 불가능합니다. 따라서 고가용성과 공유 환경에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q602",
      "Q312",
      "Q986",
      "Q892",
      "Q5"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q110",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q602",
      "Q584",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q842",
      "Q102",
      "Q602"
    ],
    "SelectD_recommedations": [
      "Q762",
      "Q194",
      "Q892"
    ]
  },
  {
    "Question_Number": "Q838",
    "Question_Description": "한 회사가 Amazon EC2에서 매우 민감한 애플리케이션을 운영하고 있으며, Amazon RDS 데이터베이스를 백엔드로 사용하고 있습니다. 규정상 모든 개인 식별 정보(PII)는 저장 시 암호화되어야 합니다. 이 요구사항을 충족하기 위해, 인프라 변경을 최소화하면서 솔루션스 아키텍트가 권장해야 할 방법은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138289-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EC2와 Amazon RDS 모두에서 PII를 안전하게 암호화해 규정을 준수해야 하는 상황입니다. Amazon RDS는 내부적으로 Amazon EBS 스토리지를 사용하므로, EBS 암호화와 RDS 암호화를 함께 설정하면 데이터를 저장할 때 자동으로 암호화될 수 있습니다. 이는 인프라 변경을 최소화하면서 가장 간단하게 요건을 충족하는 방식입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 애플리케이션",
      "개인 식별 정보",
      "저장 시 암호화",
      "Amazon EC2",
      "Amazon RDS"
    ],
    "Terms": [
      "AWS Certificate Manager",
      "AWS CloudHSM",
      "AWS Key Management Service (AWS KMS)",
      "Amazon EBS 암호화",
      "Amazon RDS 암호화",
      "SSL Encryption"
    ],
    "SelectA": "AWS Certificate Manager를 배포하여 인증서를 생성하고, 해당 인증서를 사용해 데이터베이스 볼륨을 암호화합니다.",
    "SelectA_Commentary": "인증서는 전송 구간(TLS)에 주로 사용되며 저장 시 볼륨 암호화와 직접적인 연관이 없습니다. 요구사항 충족에 적합하지 않습니다.",
    "SelectB": "AWS CloudHSM을 배포하고, 암호화 키를 생성하여 데이터베이스 볼륨을 암호화합니다.",
    "SelectB_Commentary": "CloudHSM은 관리와 설정이 복잡하고 추가 인프라가 필요합니다. 변화가 크므로 최소 변경에 어긋납니다.",
    "SelectC": "AWS Key Management Service(AWS KMS) 키를 사용한 SSL 암호화를 구성하여 데이터베이스 볼륨을 암호화합니다.",
    "SelectC_Commentary": "SSL 암호화는 데이터 전송 시 보호를 의미하고, 저장 시 물리적 볼륨 암호화와는 다릅니다. 요구사항을 온전히 충족시키기 어렵습니다.",
    "SelectD": "Amazon Elastic Block Store(Amazon EBS) 암호화와 Amazon RDS 암호화를 AWS KMS 키로 설정하여 인스턴스와 데이터베이스 볼륨을 암호화합니다.",
    "SelectD_Commentary": "EBS와 RDS 모두에 KMS 키로 암호화를 적용해 저장되는 데이터를 자동으로 보호합니다. 최소 변경으로 규정 요건을 충족하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q61",
      "Q732",
      "Q295",
      "Q533",
      "Q480"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q898",
      "Q529"
    ],
    "SelectB_recommedations": [
      "Q893",
      "Q898",
      "Q592"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q451",
      "Q663"
    ]
  },
  {
    "Question_Number": "Q839",
    "Question_Description": "회사는 VPC의 private subnet에서 AWS Lambda 함수를 실행하고 있으며, 이 subnet들은 Amazon EC2 NAT instance를 통해 인터넷으로의 기본 라우팅을 갖고 있습니다. AWS Lambda 함수는 입력 데이터를 처리한 뒤 Amazon S3에 객체로 저장합니다. 하지만 NAT instance의 네트워크 트래픽이 포화되어 객체 업로드 도중 간헐적으로 타임아웃이 발생합니다. 회사는 인터넷을 통과하지 않고 Amazon S3에 액세스하고자 합니다. 어떤 솔루션이 이러한 요구사항을 충족시킬 수 있습니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137712-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부에서 AWS Lambda가 Amazon S3에 업로드할 때 NAT instance에 발생하는 병목 현상을 해결하기 위해, 인터넷 라우팅을 거치지 않는 방법을 찾는 상황입니다. Gateway Endpoint를 사용하면 NAT를 거치지 않고도 VPC 내에서 직접 Amazon S3에 접근이 가능해 트래픽 혼잡과 타임아웃 위험을 줄일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "인터넷 경로 없이 S3 접근",
      "NAT instance 포화",
      "Amazon S3",
      "Gateway Endpoint",
      "VPC",
      "AWS Lambda"
    ],
    "Terms": [
      "AWS Lambda function",
      "VPC",
      "Amazon EC2 NAT instance",
      "Amazon S3",
      "Gateway Endpoint for Amazon S3",
      "Transit Gateway",
      "AWS managed NAT Gateway"
    ],
    "SelectA": "VPC 내 EC2 NAT instance를 AWS managed NAT Gateway로 교체합니다.",
    "SelectA_Commentary": "AWS managed NAT Gateway로 교체하면 확장성과 관리 편의성은 향상되지만, 여전히 인터넷 라우팅을 거쳐야 하므로 VPC 내부 전용 트래픽 보장은 어렵습니다.",
    "SelectB": "VPC 내 EC2 NAT instance를 네트워크 최적화 인스턴스 타입으로 크기 조정합니다.",
    "SelectB_Commentary": "NAT instance 성능은 향상될 수 있지만, 여전히 인터넷을 거쳐 S3에 접근해야 하므로 근본적 문제인 인터넷 경로 회피가 해결되지 않습니다.",
    "SelectC": "VPC에서 Amazon S3에 대한 Gateway Endpoint를 프로비저닝하고, 해당 subnet의 라우팅 테이블을 업데이트합니다.",
    "SelectC_Commentary": "인터넷 경로 없이 VPC 내부에서 바로 S3에 연결할 수 있어 가장 안정적이며, NAT 인스턴스 병목을 제거해 타임아웃 문제를 해결합니다. 정답입니다.",
    "SelectD": "Transit Gateway를 프로비저닝하고, Lambda 함수가 실행되는 private subnet에 Transit Gateway attachment를 배치합니다.",
    "SelectD_Commentary": "Transit Gateway는 VPC 간 라우팅에 유용하지만, 단일 VPC에서 S3로의 사설 연결 문제는 해결하지 못하므로 불필요하게 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q875",
      "Q184",
      "Q289",
      "Q251",
      "Q403"
    ],
    "SelectA_recommedations": [
      "Q839",
      "Q232",
      "Q251"
    ],
    "SelectB_recommedations": [
      "Q839",
      "Q151",
      "Q232"
    ],
    "SelectC_recommedations": [
      "Q92",
      "Q91",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q936",
      "Q184",
      "Q159"
    ]
  },
  {
    "Question_Number": "Q840",
    "Question_Description": "한 뉴스 회사가 전 세계에 있는 기자들을 위해 AWS 상에서 방송 시스템을 운영하고 있습니다. 기자들은 방송 시스템에 실시간 방송을 전송합니다. 기자들은 휴대폰 소프트웨어를 사용하여 Real Time Messaging Protocol (RTMP)로 라이브 스트림을 전송합니다. 솔루션스 아키텍트는 기자들이 가장 높은 품질의 스트림을 전송할 수 있도록 해야 하며, 방송 시스템으로 돌아오는 TCP 연결도 가속화해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 사용해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/136812-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 기자들이 RTMP를 사용해 실시간 방송을 전송할 때 네트워크 가속을 통해 높은 품질과 빠른 연결을 제공하는 방법을 묻습니다. TCP 가속이 필요한 프로토콜이므로 Layer 4 기반 솔루션인 AWS Global Accelerator가 올바른 선택입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "전 세계 기자",
      "라이브 스트리밍",
      "RTMP",
      "TCP 가속",
      "고품질 스트림"
    ],
    "Terms": [
      "Real Time Messaging Protocol (RTMP)",
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "AWS Client VPN",
      "Amazon EC2",
      "Elastic IP addresses"
    ],
    "SelectA": "Amazon CloudFront",
    "SelectA_Commentary": "CloudFront는 주로 HTTP/HTTPS 트래픽 가속을 위한 서비스로, RTMP와 같은 기타 TCP 프로토콜 가속에는 적합하지 않습니다.",
    "SelectB": "AWS Global Accelerator",
    "SelectB_Commentary": "AWS Global Accelerator는 TCP/UDP의 글로벌 네트워크 경로를 최적화하여 지연을 줄이고 성능을 높여 RTMP 트래픽에도 적합한 최적의 솔루션입니다.",
    "SelectC": "AWS Client VPN",
    "SelectC_Commentary": "AWS Client VPN은 안전한 VPN 연결을 제공하지만, 라이브 스트림 전송 성능을 극대화하는 TCP 가속 기능 목적과는 거리가 있습니다.",
    "SelectD": "Amazon EC2 instances and AWS Elastic IP addresses",
    "SelectD_Commentary": "EC2 인스턴스와 Elastic IP 방식은 글로벌 네트워크 지연을 줄이는 전용 가속 기능이 없어서 과제의 요구 사항을 제대로 충족시키기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q352",
      "Q568",
      "Q443",
      "Q1015",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q361",
      "Q443"
    ],
    "SelectB_recommedations": [
      "Q361",
      "Q443",
      "Q631"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q443",
      "Q704"
    ],
    "SelectD_recommedations": [
      "Q594",
      "Q857",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q841",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스와 Amazon Elastic Block Store(Amazon EBS)를 사용하여 자체 관리형 데이터베이스를 운영하고 있습니다. 이 회사는 총 350TB의 데이터를 EBS 볼륨에 저장하고 있으며, 매일 EBS 스냅샷을 생성해 1개월간 보관하고 있습니다. 매일 EBS 볼륨의 5% 정도가 변경됩니다. 새로운 규정에 따라, 회사는 매월 생성되는 스냅샷을 7년간 보관해야 하며, 최소한의 관리 작업으로 데이터를 이용 가능하도록 하는 백업 전략이 필요합니다. 다음 중 가장 비용 효율적으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137844-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EBS 볼륨의 장기 스냅샷 보관과 신규 규정 준수를 동시에 만족하는 비용 효율적인 방법을 묻습니다. EBS Snapshot Archive 기능을 사용하면 기존 Incremental Snapshot 방식을 유지하면서, 월간 스냅샷을 장기간 보관하기 위한 저비용 스토리지로 손쉽게 이동할 수 있습니다. 따라서 최소한의 관리 작업으로 7년간 스냅샷을 유지하는 데 있어 가장 경제적인 대안이 됩니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "Amazon EBS",
      "스냅샷",
      "보관",
      "비용 효율",
      "장기 보관",
      "백업 전략",
      "규정 준수"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Elastic Block Store (Amazon EBS)",
      "EBS Snapshot",
      "Amazon EBS Snapshots Archive",
      "Amazon S3 Glacier Deep Archive",
      "EBS direct APIs",
      "Incremental Snapshot"
    ],
    "SelectA": "1개월 동안 EBS 스냅샷을 그대로 두고, 매월 스냅샷을 Amazon S3 Glacier Deep Archive로 복사하여 7년간 보관합니다.",
    "SelectA_Commentary": "스냅샷을 S3 Glacier Deep Archive로 직접 복사하려면 별도의 관리 작업이 필요하며, EBS와 Glacier 간 파일 복사 방식이 번거로워서 관리 효율이 떨어집니다.",
    "SelectB": "현재 EBS 스냅샷 정책을 유지하고, 월별 스냅샷을 Amazon EBS Snapshots Archive로 이동하는 새로운 정책을 추가하여 7년간 보관합니다.",
    "SelectB_Commentary": "EBS Snapshot Archive는 Incremental Snapshot 전략과 호환되며, 기존 스냅샷 정책을 그대로 유지하면서 장기 보관 비용을 절감할 수 있는 가장 효율적인 솔루션입니다.",
    "SelectC": "1개월 동안 EBS 스냅샷을 표준 티어에 두고, 월별 스냅샷도 7년간 표준 티어에 그대로 유지합니다. Incremental Snapshot을 사용합니다.",
    "SelectC_Commentary": "표준 티어에 7년간 보관하면 스냅샷 비용이 크게 증가하여 장기 보관에는 비효율적입니다.",
    "SelectD": "EBS 스냅샷을 표준 티어에 계속 두고, 매월 EBS 볼륨의 스냅샷을 EBS direct APIs로 Amazon S3 Infrequent Access에 7년 보관합니다.",
    "SelectD_Commentary": "S3로 직접 스냅샷을 복제하려면 추가 작업이 많고, EBS Snapshots Archive보다 관리 복잡도와 비용이 더 높아집니다.",
    "Question_Description_recommedations": [
      "Q425",
      "Q867",
      "Q662",
      "Q353",
      "Q937"
    ],
    "SelectA_recommedations": [
      "Q606",
      "Q285",
      "Q1003"
    ],
    "SelectB_recommedations": [
      "Q867",
      "Q552",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q673",
      "Q147",
      "Q485"
    ],
    "SelectD_recommedations": [
      "Q867",
      "Q841",
      "Q425"
    ]
  },
  {
    "Question_Number": "Q842",
    "Question_Description": "한 회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 실행하며, 해당 애플리케이션은 Amazon Elastic File System(Amazon EFS) 파일 시스템에 영구 데이터를 저장합니다. 회사는 AWS에서 제공하는 관리형 서비스 솔루션을 사용해 다른 AWS Region으로 데이터를 복제해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137845-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다른 Region으로 데이터를 복제해 재해 복구와 내결함성을 확보하기 위한 방법을 묻습니다. AWS Backup은 EFS 파일 시스템에 대해 자동화된 백업 생성과 cross-Region 복제를 지원하는 완전관리형 서비스로, 비용 및 운영 부담을 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "EC2",
      "EFS",
      "데이터 복제",
      "AWS Backup"
    ],
    "Terms": [
      "Amazon Elastic File System(Amazon EFS)",
      "AWS Backup",
      "S3 Cross-Region Replication",
      "cross-Region VPC peering",
      "rsync",
      "EFS-to-EFS backup solution"
    ],
    "SelectA": "EFS-to-EFS backup solution을 사용하여 다른 Region의 EFS 파일 시스템으로 데이터를 복제합니다.",
    "SelectA_Commentary": "EFS-to-EFS 백업은 기본적으로 같은 Region 내에서 사용하도록 설계되었으며, 다른 Region 복제 솔루션으로는 적합하지 않습니다.",
    "SelectB": "매일 스크립트를 실행해 EFS 파일 시스템의 데이터를 Amazon S3 버킷으로 복사하고, S3 Cross-Region Replication을 활성화합니다.",
    "SelectB_Commentary": "직접 스크립트를 작성해 관리해야 하므로 완전한 관리형 서비스가 아니며, 운영 오버헤드가 많습니다.",
    "SelectC": "다른 Region에 VPC를 생성하고, cross-Region VPC 피어를 설정한 뒤 매일 rsync로 원본 Region에서 새 Region으로 데이터를 복사합니다.",
    "SelectC_Commentary": "VPC 피어링과 rsync 설정은 사용자가 직접 구성해야 하므로 관리형 서비스로 보기 어렵고 유지보수가 번거롭습니다.",
    "SelectD": "AWS Backup으로 일일 백업을 생성하고 다른 Region으로 복제하는 백업 플랜을 설정합니다. 이 백업 플랜에 EFS 파일 시스템 리소스를 할당합니다.",
    "SelectD_Commentary": "AWS Backup은 완전관리형이며, EFS 데이터 백업 및 Region 간 복제를 자동화해 가장 비용 효율적인 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q312",
      "Q224",
      "Q456",
      "Q102",
      "Q47"
    ],
    "SelectA_recommedations": [
      "Q304",
      "Q842",
      "Q324"
    ],
    "SelectB_recommedations": [
      "Q842",
      "Q891",
      "Q224"
    ],
    "SelectC_recommedations": [
      "Q504",
      "Q758",
      "Q178"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q304",
      "Q224"
    ]
  },
  {
    "Question_Number": "Q843",
    "Question_Description": "한 전자상거래 회사가 온프레미스 워크로드(웹 애플리케이션 및 Microsoft SQL 데이터베이스)를 AWS 클라우드로 마이그레이션하려고 합니다. 회사는 프로모션 이벤트 시 매우 높은 트래픽이 예상되며, 새로운 AWS 클라우드 인프라는 고가용성과 확장성을 갖추고 관리 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138109-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 계층과 DB 계층 모두를 AWS에서 고가용성 및 확장성을 확보하며 운영 부담을 줄이는 방법을 묻습니다. 웹 애플리케이션은 Auto Scaling group과 Application Load Balancer(이하 ALB)로 확장성을 갖추고, 데이터베이스는 Amazon RDS Multi-AZ 배포를 통해 고가용성과 탄력적인 복구 기능을 확보하는 것이 핵심입니다. SelectC가 이러한 요건을 가장 적은 관리 오버헤드로 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "확장성",
      "AWS 클라우드",
      "Microsoft SQL Database",
      "전자상거래"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon RDS",
      "Multi-AZ",
      "Microsoft SQL Server",
      "read replicas",
      "Availability Zone"
    ],
    "SelectA": "웹 애플리케이션을 두 개의 Amazon EC2 인스턴스로 두 Availability Zone에 배치하고 Application Load Balancer 뒤에 둡니다. 데이터베이스는 Amazon RDS for Microsoft SQL Server로 마이그레이션하고, 두 Availability Zone에 read replica를 배포합니다.",
    "SelectA_Commentary": "RDS for Microsoft SQL Server의 read replica는 추가 유지보수가 필요하며, Multi-AZ 배포만큼 단순하고 효율적이지 않을 수 있습니다.",
    "SelectB": "웹 애플리케이션을 하나의 Amazon EC2 인스턴스로 운영하고 이를 Auto Scaling group으로 구성하여 두 Availability Zone에 걸쳐 Application Load Balancer 뒤에서 실행합니다. 데이터베이스는 서로 다른 두 AWS 리전에 EC2 인스턴스를 배치해 DB 복제를 구성합니다.",
    "SelectB_Commentary": "리전 간 DB 복제는 설정과 관리가 복잡해 오버헤드가 높아지며, 고가용성 환경을 간소하게 구축하기 어렵습니다.",
    "SelectC": "웹 애플리케이션을 Amazon EC2 인스턴스로 배포하고, 이를 Auto Scaling group으로 구성하여 두 Availability Zone에 걸쳐 Application Load Balancer 뒤에서 실행합니다. 데이터베이스는 Amazon RDS Multi-AZ 배포로 마이그레이션합니다.",
    "SelectC_Commentary": "Auto Scaling과 Multi-AZ 구성된 Amazon RDS로 손쉽게 확장성과 고가용성을 확보하고 관리 부담도 최소화할 수 있는 최적의 선택입니다.",
    "SelectD": "웹 애플리케이션을 세 개의 Amazon EC2 인스턴스로 구성하고 세 Availability Zone에 배치하여 Application Load Balancer 뒤에서 운영합니다. 데이터베이스는 세 개의 EC2 인스턴스를 각각 세 Availability Zone에 배치합니다.",
    "SelectD_Commentary": "EC2로 직접 DB를 다중 가용 영역에 구성하면 RDS Multi-AZ 대비 관리가 복잡해지고 운영 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q182",
      "Q194",
      "Q8",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q298",
      "Q275",
      "Q69"
    ],
    "SelectB_recommedations": [
      "Q69",
      "Q275",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q298",
      "Q390",
      "Q69"
    ],
    "SelectD_recommedations": [
      "Q275",
      "Q298",
      "Q639"
    ]
  },
  {
    "Question_Number": "Q844",
    "Question_Description": "한 회사에는 매일 수백 개의 파일을 생성하는 온프레미스 비즈니스 애플리케이션이 있습니다. 이 파일들은 SMB file share에 저장되며, 애플리케이션 서버와의 저지연(low-latency) 연결이 필요합니다. 새로운 회사 정책에 따르면 애플리케이션에서 생성되는 모든 파일은 AWS로 복사되어야 합니다. 이미 AWS로의 VPN 연결이 구성되어 있습니다. 애플리케이션 개발 팀은 애플리케이션을 AWS로 이전하기 위해 필요한 코드 수정 시간을 할애할 수 없습니다. 이 애플리케이션이 AWS로 파일을 복사할 수 있도록 솔루션스 아키텍트가 추천해야 하는 서비스는 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138083-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 SMB file share로 운영 중인 애플리케이션이 생성하는 파일을 AWS로 옮기는 간단하면서도 저지연을 만족하는 방안을 찾는 것입니다. 코드 수정 없이 계속 SMB 프로토콜을 사용해야 하므로, 온프레미스와 AWS 간에 파일을 투명하게 연동할 수 있는 서비스가 적절합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "온프레미스 파일",
      "SMB file share",
      "저지연 연결",
      "AWS로 파일 복사",
      "코드 수정 없음"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "SMB file share",
      "Amazon FSx for Windows File Server",
      "Amazon Elastic File System (Amazon EFS)",
      "AWS Snowball",
      "VPN"
    ],
    "SelectA": "Amazon Elastic File System (Amazon EFS)",
    "SelectA_Commentary": "EFS는 주로 Linux 기반 애플리케이션용 네트워크 파일 시스템으로, 온프레미스 Windows 환경의 SMB file share 사용에는 적합하지 않습니다.",
    "SelectB": "Amazon FSx for Windows File Server",
    "SelectB_Commentary": "FSx for Windows File Server는 완전관리형 Windows 파일 서버 서비스이지만, 온프레미스 애플리케이션을 그대로 사용하기 위해서는 네트워크 구성이 복잡해지고, VPN 지연 문제가 생길 수 있습니다.",
    "SelectC": "AWS Snowball",
    "SelectC_Commentary": "AWS Snowball은 물리 디바이스를 통한 데이터 이전 솔루션으로, 일상적으로 생성되는 데이터를 매일 실시간에 가깝게 전송하기에는 적합하지 않습니다.",
    "SelectD": "AWS Storage Gateway",
    "SelectD_Commentary": "AWS Storage Gateway(File Gateway)는 SMB file share를 그대로 사용하면서, 온프레미스 파일을 자동으로 AWS로 동기화할 수 있어 코드 수정 없이도 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q283",
      "Q1015",
      "Q895",
      "Q704",
      "Q528"
    ],
    "SelectA_recommedations": [
      "Q680",
      "Q695",
      "Q990"
    ],
    "SelectB_recommedations": [
      "Q301",
      "Q305",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q361",
      "Q620",
      "Q143"
    ],
    "SelectD_recommedations": [
      "Q361",
      "Q620",
      "Q305"
    ]
  },
  {
    "Question_Number": "Q845",
    "Question_Description": "한 회사에는 직원이 15명 있습니다. 이 회사는 직원의 입사일을 Amazon DynamoDB 테이블에 저장하고 있으며, 각 직원의 근무 기념일에 이메일을 발송하고자 합니다. 운영 측면에서 가장 효율적인 방법으로 이를 구현하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139191-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 직원 근무 기념일에 자동으로 이메일을 보내는 방법을 묻습니다. 서버를 직접 관리하는 EC2보다 서버리스인 AWS Lambda와 SNS를 사용하면 운영 오버헤드를 크게 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "직원의 근무 기념일",
      "자동 이메일 발송",
      "DynamoDB 스캔",
      "서버리스",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon EC2",
      "cron job"
    ],
    "SelectA": "Amazon EC2 인스턴스에서 크론 스크립트로 DynamoDB를 스캔하고 SNS로 이메일을 발송",
    "SelectA_Commentary": "EC2를 항상 실행하고 스크립트를 유지보수해야 하므로 운영 복잡도가 높고 모니터링도 필요해 비효율적입니다.",
    "SelectB": "Amazon EC2 인스턴스에서 크론 스크립트로 DynamoDB를 스캔하고 SQS로 이메일을 발송",
    "SelectB_Commentary": "SQS 자체로 이메일 전송이 불가능해 추가 프로세스가 필요합니다. 마찬가지로 EC2와 크론 스크립트 관리로 운영 부담이 큽니다.",
    "SelectC": "AWS Lambda 함수가 DynamoDB 테이블을 스캔해 필요 시 SNS를 통해 이메일을 발송",
    "SelectC_Commentary": "서버리스로 관리 부담이 없고 SNS를 통해 직접 이메일 전송이 가능해 운영 효율이 가장 높습니다. 정답입니다.",
    "SelectD": "AWS Lambda 함수가 DynamoDB 테이블을 스캔해 필요 시 SQS를 통해 이메일을 발송",
    "SelectD_Commentary": "SQS는 메시지 큐 서비스로 직접 이메일 전송이 어려우며 SNS보다 설정과 연계가 복잡합니다.",
    "Question_Description_recommedations": [
      "Q400",
      "Q1002",
      "Q78",
      "Q114",
      "Q768"
    ],
    "SelectA_recommedations": [
      "Q768",
      "Q194",
      "Q584"
    ],
    "SelectB_recommedations": [
      "Q768",
      "Q824",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q636",
      "Q45",
      "Q785"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q207",
      "Q1002"
    ]
  },
  {
    "Question_Number": "Q846",
    "Question_Description": "한 회사의 애플리케이션이 Elastic Load Balancing(ELB) 로드 밸런서 뒤의 Auto Scaling group에 속한 Amazon EC2 인스턴스에서 실행되고 있습니다. 애플리케이션의 이력에 따르면 매년 공휴일 동안 트래픽 급증이 발생할 것으로 예상됩니다. 솔루션스 아키텍트는 Auto Scaling group이 사전에 용량을 확충하여 애플리케이션 사용자의 성능 영향을 최소화하도록 전략을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139063-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 공휴일과 같은 특정 시점에 트래픽 급증이 예상될 때, Auto Scaling group을 사전에 조정하여 성능 저하를 최소화하려는 상황입니다. 트리거를 기반으로만 대응하면 이미 부하가 걸린 후에 확장하게 되므로 제한적일 수 있습니다. 스케줄링된 확장을 통해 예상 피크 시점 이전에 리소스를 미리 확보함으로써 안정적인 서비스를 보장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "트래픽 급증",
      "사전 용량 확충",
      "Auto Scaling group",
      "Elastic Load Balancing",
      "성능 영향 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Elastic Load Balancing (ELB)",
      "Amazon CloudWatch",
      "CPU utilization",
      "Amazon SNS",
      "Scheduled Action"
    ],
    "SelectA": "CPU 사용률이 90%를 초과하면 Amazon CloudWatch 알람을 생성하여 EC2 인스턴스를 확장합니다.",
    "SelectA_Commentary": "CPU 기준으로만 증설하는 방식은 이미 부하가 발생한 후에 확장하므로 '사전' 확장이 어려워 성능 저하가 발생할 수 있습니다.",
    "SelectB": "예상되는 최대 수요 시점 전에 Auto Scaling group을 확장하도록 반복 스케줄 액션을 생성합니다.",
    "SelectB_Commentary": "트래픽 폭주 전 미리 용량을 늘려 사전에 대비하는 방식으로, 예상되는 공휴일 트래픽을 효율적으로 처리하는 최적의 솔루션입니다.",
    "SelectC": "피크 기간 동안 Auto Scaling group의 최소 및 최대 Amazon EC2 인스턴스 수를 증가시킵니다.",
    "SelectC_Commentary": "단순히 최소·최대를 변화시키는 것은 기간별 자동 관리를 고려하지 않아, 일시적인 수요가 아닐 때도 인스턴스가 계속 확장될 수 있습니다.",
    "SelectD": "autoscaling:EC2_INSTANCE_LAUNCH 이벤트 발생 시 Amazon SNS 알림을 제공하도록 구성합니다.",
    "SelectD_Commentary": "이벤트 알림만 받을 뿐, 트래픽 급증 전에 용량 확충을 자동으로 수행하지 않으므로 사전 대비가 불가능합니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q581",
      "Q595",
      "Q333",
      "Q275"
    ],
    "SelectA_recommedations": [
      "Q923",
      "Q150",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q1001",
      "Q660"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q581",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q595",
      "Q1001"
    ]
  },
  {
    "Question_Number": "Q847",
    "Question_Description": "한 회사가 데이터 계층으로 Amazon RDS for PostgreSQL을 사용하고 있습니다. 회사는 데이터베이스에 대한 비밀번호 로테이션을 구현해야 합니다. 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138644-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS for PostgreSQL의 자격 증명(비밀번호)을 자동으로 로테이션하여 보안을 강화하고 운영 오버헤드를 줄이는 방법을 묻습니다. AWS Secrets Manager는 비밀번호 자동 로테이션을 기능적으로 지원하며, 별도의 사용자 정의 Lambda 코드 없이 손쉽게 설정할 수 있어 운영 단순성을 높여줍니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "비밀번호 로테이션",
      "Amazon RDS",
      "PostgreSQL",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "AWS Key Management Service (AWS KMS)",
      "Amazon RDS",
      "PostgreSQL",
      "AWS Lambda",
      "Password Rotation"
    ],
    "SelectA": "비밀번호를 AWS Secrets Manager에 저장하고, secret에 대해 automatic rotation을 활성화합니다.",
    "SelectA_Commentary": "Secrets Manager는 관리형 자동 로테이션을 기본 제공하므로 추가 Lambda 코딩 없이 간편하게 비밀번호를 주기적으로 갱신합니다. 오버헤드가 가장 낮습니다.",
    "SelectB": "비밀번호를 AWS Systems Manager Parameter Store에 저장하고, parameter에 대한 automatic rotation을 활성화합니다.",
    "SelectB_Commentary": "Parameter Store는 기본적으로 자동 로테이션 기능이 없으므로, 현재 자동 로테이션을 직접 지원하지 않는다는 제약이 있어 적절하지 않습니다.",
    "SelectC": "비밀번호를 AWS Systems Manager Parameter Store에 저장하고, AWS Lambda 함수를 작성해 비밀번호를 로테이션합니다.",
    "SelectC_Commentary": "Lambda 함수를 작성해 자체 로직으로 로테이션을 구현해야 하므로 운영 오버헤드가 상대적으로 높습니다.",
    "SelectD": "비밀번호를 AWS Key Management Service(AWS KMS)에 저장하고, 해당 KMS 키에 대한 automatic rotation을 활성화합니다.",
    "SelectD_Commentary": "KMS 키 로테이션은 암호화 키에 대한 로테이션이며, 데이터베이스 비밀번호 직접 로테이션 기능과는 다른 개념이므로 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q669",
      "Q330",
      "Q742",
      "Q732",
      "Q61"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q893",
      "Q645"
    ],
    "SelectB_recommedations": [
      "Q179",
      "Q893",
      "Q368"
    ],
    "SelectC_recommedations": [
      "Q289",
      "Q179",
      "Q936"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q848",
    "Question_Description": "한 회사가 Oracle Database Enterprise Edition으로 애플리케이션을 운영하고 있습니다. 이 회사는 애플리케이션과 데이터베이스를 AWS로 마이그레이션해야 합니다. 마이그레이션 중에 Bring Your Own License (BYOL) 모델을 사용할 수 있습니다. 애플리케이션에서는 privileged access가 필요한 타사 데이터베이스 기능(third-party database features)을 사용합니다. 솔루션스 아키텍트는 데이터베이스 마이그레이션 솔루션을 설계해야 합니다. 다음 중 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138645-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Oracle Database Enterprise Edition 환경을 AWS로 이전하면서, BYOL 모델과 부가 기능(특히 OS 수준 권한이 필요한 third-party 기능)을 지원해야 하는 상황입니다. Amazon RDS Custom for Oracle은 이러한 고급 권한 요구사항을 충족하면서도 Oracle 라이선스를 가져올 수 있어 비용 효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "비용 효율적",
      "BYOL",
      "privileged access",
      "third-party features",
      "Oracle Database Enterprise Edition",
      "Amazon RDS Custom for Oracle"
    ],
    "Terms": [
      "Oracle Database Enterprise Edition",
      "Bring Your Own License (BYOL)",
      "Amazon RDS for Oracle",
      "Amazon RDS Custom for Oracle",
      "Amazon DynamoDB",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon RDS for PostgreSQL",
      "AWS Lambda",
      "privileged access",
      "third-party database features"
    ],
    "SelectA": "Native 툴을 사용하여 Amazon RDS for Oracle로 데이터베이스를 마이그레이션합니다. third-party 기능을 AWS Lambda로 대체합니다.",
    "SelectA_Commentary": "AWS Lambda로 대체 시, 필요한 OS 권한을 제공하기 어렵고 애플리케이션 변경 부담이 커 비용 효율적이지 못합니다.",
    "SelectB": "Native 툴을 사용하여 Amazon RDS Custom for Oracle로 데이터베이스를 마이그레이션합니다. 신규 데이터베이스 설정을 맞춤 구성해 third-party 기능을 지원합니다.",
    "SelectB_Commentary": "RDS Custom for Oracle은 OS 수준 권한을 부여할 수 있어 third-party 기능 활용과 BYOL 모두 충족하는 최적의 비용 효율적 솔루션입니다.",
    "SelectC": "AWS Database Migration Service (AWS DMS)를 사용해 Amazon DynamoDB로 데이터베이스를 마이그레이션합니다. 신규 데이터베이스 설정을 맞춤 구성해 third-party 기능을 지원합니다.",
    "SelectC_Commentary": "DynamoDB로 전환 시 스키마와 기능 호환성 문제가 발생하며, OS 수준 권한을 제공하기 어려워 적절하지 않습니다.",
    "SelectD": "AWS Database Migration Service (AWS DMS)를 사용해 Amazon RDS for PostgreSQL로 데이터베이스를 마이그레이션합니다. third-party 기능 의존성을 제거하도록 애플리케이션 코드를 재작성합니다.",
    "SelectD_Commentary": "기존 Oracle DB용 third-party 기능을 전면적으로 재구현해야 하며, 마이그레이션 부담과 비용이 크게 증가하므로 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q449",
      "Q979",
      "Q383",
      "Q380",
      "Q598"
    ],
    "SelectA_recommedations": [
      "Q449",
      "Q948",
      "Q574"
    ],
    "SelectB_recommedations": [
      "Q948",
      "Q449",
      "Q574"
    ],
    "SelectC_recommedations": [
      "Q948",
      "Q670",
      "Q79"
    ],
    "SelectD_recommedations": [
      "Q948",
      "Q579",
      "Q436"
    ]
  },
  {
    "Question_Number": "Q850",
    "Question_Description": "한 회사는 IT 인프라 맵을 구축하여 보안 위험을 야기하는 리소스에 대한 정책을 식별하고 적용하려고 합니다. 회사의 보안 팀은 IT 인프라 맵에 있는 데이터를 쿼리하고 보안 위험을 신속하게 파악할 수 있어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137910-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IT 인프라 리소스 간의 관계를 체계적으로 표현하고, 이를 기반으로 보안 위험을 신속히 추출하기 위한 데이터베이스 선택에 관한 것입니다. Graph Database인 Amazon Neptune과 SPARQL은 복잡한 관계를 탐색하기에 적합하여 보안 정책 적용 시 발생하는 복잡도를 줄이고 빠르게 위험을 식별할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "IT 인프라 맵",
      "보안 위험 식별",
      "Amazon Neptune",
      "SPARQL",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon RDS",
      "Amazon Neptune",
      "Amazon Redshift",
      "Amazon DynamoDB",
      "SQL",
      "SPARQL",
      "PartiQL",
      "Graph Database"
    ],
    "SelectA": "Amazon RDS에 데이터를 저장하고, SQL을 사용하여 보안 위험을 식별하기 위해 데이터를 쿼리합니다.",
    "SelectA_Commentary": "관계형 데이터베이스는 기본적으로 그래프 관계를 표현하기에 비효율적이며, 복잡한 관계 탐색 시 쿼리 구성이 어렵고 오버헤드가 증가합니다.",
    "SelectB": "Amazon Neptune에 데이터를 저장하고, SPARQL을 사용하여 보안 위험을 식별하기 위해 데이터를 쿼리합니다.",
    "SelectB_Commentary": "그래프 기반 데이터베이스로, 복잡한 관계를 효율적으로 조회하고 보안 위험을 신속하게 파악할 수 있어 가장 적합한 솔루션입니다.",
    "SelectC": "Amazon Redshift에 데이터를 저장하고, SQL을 사용하여 보안 위험을 식별하기 위해 데이터를 쿼리합니다.",
    "SelectC_Commentary": "주로 대규모 데이터 웨어하우스 분석용으로 설계된 서비스로, 그래프 관계 탐색 및 즉각적인 위험 식별 용도로는 적합하지 않습니다.",
    "SelectD": "Amazon DynamoDB에 데이터를 저장하고, PartiQL을 사용하여 보안 위험을 식별하기 위해 데이터를 쿼리합니다.",
    "SelectD_Commentary": "Key-Value/NoSQL 기반으로 단순 조회에 강점이 있지만, 복잡한 그래프 구조를 다루는 데는 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q478",
      "Q57",
      "Q803",
      "Q665",
      "Q122"
    ],
    "SelectA_recommedations": [
      "Q330",
      "Q732",
      "Q742"
    ],
    "SelectB_recommedations": [
      "Q1007",
      "Q480",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q821",
      "Q901",
      "Q732"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q727",
      "Q176"
    ]
  },
  {
    "Question_Number": "Q851",
    "Question_Description": "한 대규모 기업이 전 세계에 분산된 개발자들에게 개발용으로 각각 제한된 크기의 관리형 PostgreSQL 데이터베이스를 제공하려고 합니다. 이 데이터베이스들은 처리량이 낮으며, 개발자들은 실제로 작업할 때만 데이터베이스가 필요합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139065-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "개발자가 일시적으로만 사용하는 소규모 PostgreSQL 데이터베이스를 제공해야 할 때, 사용량 기반으로 과금되는 Amazon Aurora Serverless가 가장 비용 효율적입니다. 작업이 없는 동안에는 Aurora Serverless가 자동으로 용량을 축소하거나 중지해 비용을 절감하고, 작업 시에는 자동으로 복원되어 편리합니다. 다른 옵션은 대부분 On-Demand 또는 Reserved Instances를 활용해야 하며, 유휴 시간에도 비용이 계속 발생하기 때문에 비효율적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "전 세계 개발자",
      "제한된 크기",
      "관리형 PostgreSQL",
      "비용 효율성",
      "Amazon Aurora Serverless"
    ],
    "Terms": [
      "Amazon Aurora",
      "Amazon Aurora Serverless",
      "AWS Service Catalog",
      "Amazon RDS",
      "AWS Trusted Advisor",
      "On-Demand",
      "PostgreSQL",
      "Reserved Instances"
    ],
    "SelectA": "개발자들이 각자 별도의 Amazon Aurora 인스턴스를 시작할 수 있도록 권한을 부여하고, 업무 종료 시점에 Aurora 인스턴스를 중지하고 다음 근무 시작 시점에 다시 시작하도록 설정합니다.",
    "SelectA_Commentary": "Aurora 인스턴스를 직접 중지하고 시작하는 것은 자동화가 어렵고 유휴 비용을 완전히 없애기 힘듭니다. Serverless만큼 비용 효율적이지 않습니다.",
    "SelectB": "AWS Service Catalog 제품을 개발하여 Amazon Aurora 인스턴스 시작 시 크기 제한을 강제합니다. 개발자들은 필요한 경우 해당 제품을 통해 개발용 데이터베이스를 시작할 수 있습니다.",
    "SelectB_Commentary": "인스턴스를 제한하는 것만으로는 유휴 상태 시 비용이 계속 발생할 수 있습니다. 완전 자동화된 스케일링이 아닌 단순 관리자 제어 방식입니다.",
    "SelectC": "Amazon Aurora Serverless 클러스터를 생성합니다. AWS Service Catalog 제품을 개발하여 기본 용량 설정으로 데이터베이스를 시작하도록 하고, 개발자들에게 이 제품에 대한 액세스를 부여합니다.",
    "SelectC_Commentary": "Serverless는 사용자가 작업 중일 때만 자동으로 용량을 확장·축소하고, 사용이 없으면 자동으로 중지되어 비용을 크게 절감할 수 있으므로 정답입니다.",
    "SelectD": "AWS Trusted Advisor에서 유휴 상태인 Amazon RDS 데이터베이스를 모니터링하고, 유휴 상태로 식별된 RDS 데이터베이스를 종료하는 프로세스를 구성합니다.",
    "SelectD_Commentary": "Trusted Advisor 모니터링으로 유휴 DB를 식별하더라도, 완전히 자동으로 용량을 조절해 비용을 줄이는 Serverless만큼의 효율성을 제공하지 못합니다.",
    "Question_Description_recommedations": [
      "Q511",
      "Q411",
      "Q348",
      "Q436",
      "Q79"
    ],
    "SelectA_recommedations": [
      "Q284",
      "Q728",
      "Q985"
    ],
    "SelectB_recommedations": [
      "Q238",
      "Q284",
      "Q541"
    ],
    "SelectC_recommedations": [
      "Q827",
      "Q128",
      "Q300"
    ],
    "SelectD_recommedations": [
      "Q959",
      "Q859",
      "Q579"
    ]
  },
  {
    "Question_Number": "Q852",
    "Question_Description": "한 회사에서 웹 애플리케이션을 구축하고 있으며, 여기에는 Content Management System(CMS)이 포함됩니다. 해당 CMS는 Application Load Balancer(ALB) 뒤에서 Amazon EC2 인스턴스가 동작하며, Auto Scaling group을 통해 여러 가용 영역(Availability Zone)에 걸쳐 인스턴스가 실행됩니다. 사용자들은 CMS에 파일, 블로그, 기타 웹사이트 자산을 지속적으로 추가 및 업데이트합니다. 솔루션스 아키텍트는 모든 EC2 인스턴스가 최신 웹사이트 콘텐츠를 최소한의 지연으로 공유할 수 있는 솔루션을 구현해야 합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139090-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다수의 EC2 인스턴스가 동시에 파일을 업데이트하고 변경된 웹사이트 자산을 곧바로 반영해야 하는 CMS 환경에서, 실시간에 가까운 공유 스토리지 구성을 어떻게 할지 묻습니다. 정답은 Amazon EFS를 사용하는 B입니다. EFS는 여러 인스턴스가 동일한 파일 시스템을 공유해 최소 지연으로 최신 자산을 접근할 수 있어 실시간 동기화에 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "웹 애플리케이션",
      "Content Management System (CMS)",
      "Auto Scaling group",
      "여러 가용 영역",
      "지연 시간 최소화",
      "Amazon EFS"
    ],
    "Terms": [
      "Application Load Balancer (ALB)",
      "Amazon EC2",
      "Auto Scaling",
      "Amazon EFS",
      "Amazon S3",
      "Amazon EBS",
      "Availability Zone",
      "User Data",
      "S3 sync",
      "EBS Snapshot"
    ],
    "SelectA": "Auto Scaling group lifecycle policy의 EC2 user data를 업데이트하여, 가장 최근에 실행된 EC2 인스턴스로부터 웹사이트 자산을 복사하도록 구성합니다. ALB가 웹사이트 자산 변경 작업을 가장 새로운 EC2 인스턴스에서만 수행하도록 구성합니다.",
    "SelectA_Commentary": "모든 변경을 한 인스턴스에만 적용하면 다른 인스턴스에는 즉각 반영되지 않아 지연이 발생하고 관리도 복잡해집니다.",
    "SelectB": "Amazon Elastic File System(Amazon EFS) 파일 시스템에 웹사이트 자산을 복사합니다. 각 EC2 인스턴스가 로컬로 EFS 파일 시스템을 마운트하도록 구성합니다. 웹사이트 호스팅 애플리케이션이 EFS 파일 시스템에 저장된 웹사이트 자산을 참조하도록 구성합니다.",
    "SelectB_Commentary": "Amazon EFS가 여러 인스턴스에 걸쳐 단일 파일 시스템을 공유하므로 지연이 거의 없이 최신 콘텐츠를 제공할 수 있는 최적의 방식입니다.",
    "SelectC": "Amazon S3 버킷에 웹사이트 자산을 복사합니다. 각 EC2 인스턴스가 해당 웹사이트 자산을 S3 버킷에서 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 다운로드하도록 설정합니다. 한 시간마다 S3 sync 명령을 실행해 파일을 최신 상태로 유지합니다.",
    "SelectC_Commentary": "주기적 S3 sync로는 실시간에 가까운 동기화가 어렵고, 매번 다운로드하는 절차 역시 오버헤드가 큽니다.",
    "SelectD": "웹사이트 자산이 포함된 Amazon Elastic Block Store(Amazon EBS) 스냅샷을 복원합니다. 새 EC2 인스턴스가 시작될 때 이 EBS 스냅샷을 보조 EBS 볼륨으로 연결합니다. 웹사이트 호스팅 애플리케이션이 보조 EBS 볼륨에 저장된 웹사이트 자산을 참조하도록 구성합니다.",
    "SelectD_Commentary": "새 인스턴스마다 EBS 스냅샷 복원 과정이 필요해 지연이 길고, 실시간 업데이트가 반영되기 어려운 구조입니다.",
    "Question_Description_recommedations": [
      "Q358",
      "Q261",
      "Q976",
      "Q41",
      "Q335"
    ],
    "SelectA_recommedations": [
      "Q335",
      "Q358",
      "Q141"
    ],
    "SelectB_recommedations": [
      "Q680",
      "Q695",
      "Q976"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q41",
      "Q690"
    ],
    "SelectD_recommedations": [
      "Q695",
      "Q910",
      "Q680"
    ]
  },
  {
    "Question_Number": "Q853",
    "Question_Description": "어떤 회사의 웹 애플리케이션은 VPC 내의 Application Load Balancer 뒤에서 실행되는 여러 Amazon EC2 인스턴스로 구성됩니다. 데이터는 Amazon RDS for MySQL DB 인스턴스에 저장되어 있습니다. 회사는 AWS 환경에서 의심스럽거나 예기치 않은 동작을 자동으로 탐지하고 대응할 수 있는 기능이 필요합니다. 이 회사는 이미 아키텍처에 AWS WAF를 추가했습니다. 위협으로부터 보호하려면 솔루션스 아키텍트가 다음에 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137862-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 환경 전반에서 의심스러운 활동을 자동으로 탐지·대응하는 방법을 묻습니다. Amazon GuardDuty는 악의적인 행위를 모니터링하고, Amazon EventBridge와 AWS Lambda를 통해 실시간으로 AWS WAF 규칙을 조정할 수 있어 능동적 보안 대응이 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon RDS for MySQL",
      "AWS WAF",
      "Amazon GuardDuty",
      "suspicious or unexpected behavior",
      "threat detection"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "VPC",
      "Amazon RDS for MySQL",
      "AWS WAF",
      "AWS WAF web ACL",
      "Amazon GuardDuty",
      "Amazon EventBridge",
      "AWS Lambda",
      "AWS Firewall Manager",
      "Amazon Inspector",
      "Amazon Macie",
      "VPC network ACL"
    ],
    "SelectA": "Amazon GuardDuty를 통해 위협 탐지를 수행하고, Amazon EventBridge를 설정해 GuardDuty 결과를 필터링한 뒤 AWS Lambda 함수를 호출하여 AWS WAF 규칙을 조정합니다.",
    "SelectA_Commentary": "정답: GuardDuty는 네트워크와 계정 활동에서 의심 행동을 실시간으로 파악하며, EventBridge와 Lambda로 자동 방어가 가능해 요구사항을 충족합니다.",
    "SelectB": "AWS Firewall Manager를 사용해 위협 탐지를 수행하고, EventBridge와 Lambda를 구성하여 AWS WAF web ACL을 조정합니다.",
    "SelectB_Commentary": "Firewall Manager는 여러 계정 및 리소스에 대한 WAF 정책 관리에 효과적이지만, GuardDuty처럼 실시간 위협 탐지를 제공하는 서비스가 아닙니다.",
    "SelectC": "Amazon Inspector를 사용해 위협 탐지를 수행하고 AWS WAF 규칙을 업데이트합니다. VPC network ACL을 추가로 구성합니다.",
    "SelectC_Commentary": "Inspector는 주로 인스턴스의 취약성 평가에 집중하므로, 네트워크 기반의 실시간 의심 활동 모니터링에는 적합하지 않습니다.",
    "SelectD": "Amazon Macie를 사용해 위협 탐지를 수행하고 AWS WAF 규칙을 업데이트합니다. VPC network ACL을 추가로 구성합니다.",
    "SelectD_Commentary": "Macie는 민감 데이터 검색 및 분류에 초점을 두어, 네트워크 및 계정 활동 전반의 침해 행위 탐지는 GuardDuty만큼 강력하지 않습니다.",
    "Question_Description_recommedations": [
      "Q810",
      "Q35",
      "Q927",
      "Q388",
      "Q749"
    ],
    "SelectA_recommedations": [
      "Q165",
      "Q159",
      "Q105"
    ],
    "SelectB_recommedations": [
      "Q165",
      "Q105",
      "Q853"
    ],
    "SelectC_recommedations": [
      "Q165",
      "Q853",
      "Q950"
    ],
    "SelectD_recommedations": [
      "Q165",
      "Q950",
      "Q15"
    ]
  },
  {
    "Question_Number": "Q854",
    "Question_Description": "한 회사가 Amazon Aurora 데이터베이스에 연결하는 Amazon EC2 인스턴스 그룹을 실행할 계획입니다. 이 회사는 EC2 인스턴스와 Aurora DB 클러스터를 배포하기 위해 AWS CloudFormation 템플릿을 구성했습니다. 회사는 인스턴스들이 데이터베이스에 안전하게 인증하도록 하길 원하며, 고정된(Static) 데이터베이스 자격 증명을 유지하고 싶지 않습니다. 운영 노력을 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139091-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스가 고정된 자격 증명 없이 Amazon Aurora DB에 안전하게 접속하도록 하는 방법을 묻습니다. 가장 단순하고 안전하며 운영 노력이 적은 방식은 IAM database authentication을 사용하여 EC2 인스턴스에 역할(Roles)을 연결하는 것입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Amazon Aurora",
      "Amazon EC2",
      "인증",
      "IAM database authentication",
      "운영 노력 최소화"
    ],
    "Terms": [
      "AWS CloudFormation",
      "Amazon EC2",
      "Amazon Aurora",
      "DB cluster",
      "IAM database authentication",
      "AWS Systems Manager Parameter Store"
    ],
    "SelectA": "DB 사용자 이름과 암호를 생성하고 CloudFormation 템플릿에서 매개변수로 받아 EC2 인스턴스가 이를 전달받도록 합니다.",
    "SelectA_Commentary": "CloudFormation 템플릿에 사용자 자격 증명을 하드코딩하면 보안 및 유지 관리가 불편하므로 권장되지 않습니다.",
    "SelectB": "DB 사용자 이름과 암호를 생성하고 이를 AWS Systems Manager Parameter Store에 저장합니다. EC2 인스턴스에서 Parameter Store를 통해 자격 증명을 조회합니다.",
    "SelectB_Commentary": "정적 자격 증명을 Parameter Store에 위임하는 방식이라 보안 관리는 어느 정도 간단해지지만, 여전히 암호를 주기적으로 업데이트해야 하며 완전한 무관리형은 아닙니다.",
    "SelectC": "IAM database authentication을 사용하도록 DB 클러스터를 구성하고, IAM 인증을 사용하는 DB 사용자를 생성합니다. EC2 인스턴스에 역할을 연결하여 DB 접근을 허용합니다.",
    "SelectC_Commentary": "IAM 역할과 IAM database authentication을 결합하면 고정 암호 없이 안전하게 DB에 액세스할 수 있어 운영 노력이 가장 적은 최적의 솔루션입니다.",
    "SelectD": "IAM user와 매칭되는 이름의 DB 사용자를 만들고, IAM user를 EC2 인스턴스에 연결하여 DB 접근을 허용합니다.",
    "SelectD_Commentary": "EC2에 IAM user 직접 연결은 비정상적인 방식이며, 매번 IAM user-DB user 매핑이 필요해 운영이 복잡해지므로 권장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q556",
      "Q176",
      "Q336",
      "Q994",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q176",
      "Q556",
      "Q682"
    ],
    "SelectB_recommedations": [
      "Q179",
      "Q176",
      "Q453"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q429"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q476",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q855",
    "Question_Description": "한 회사가 Amazon CloudFront distribution에서 SSL/TLS 인증서를 사용하고자 합니다. 이 회사는 배포에 대해 기본 도메인 이름이 아닌 다른 도메인 이름을 사용하려고 합니다. 추가 비용 없이 인증서를 배포하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137823-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudFront에서 커스텀 도메인으로 SSL/TLS를 설정할 때 비용 추가 없이 인증서를 발급받는 최적의 방법을 묻습니다. CloudFront에 커스텀 도메인 인증서를 연결하려면 us-east-1 리전에서 발급된 퍼블릭 인증서를 사용해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon CloudFront",
      "SSL/TLS 인증서",
      "커스텀 도메인",
      "AWS Certificate Manager",
      "us-east-1 리전",
      "퍼블릭 인증서"
    ],
    "Terms": [
      "Amazon CloudFront distribution",
      "SSL/TLS certificate",
      "AWS Certificate Manager (ACM)",
      "us-east-1 Region",
      "us-west-1 Region",
      "Amazon issued private certificate",
      "Amazon issued public certificate"
    ],
    "SelectA": "us-east-1 리전에서 AWS Certificate Manager (ACM)의 Amazon issued private certificate를 요청합니다.",
    "SelectA_Commentary": "Private certificate는 내부 서비스용으로 주로 사용됩니다. CloudFront용 커스텀 도메인에는 퍼블릭 인증서가 필요하므로 적절하지 않습니다.",
    "SelectB": "us-west-1 리전에서 AWS Certificate Manager (ACM)의 Amazon issued private certificate를 요청합니다.",
    "SelectB_Commentary": "인증서가 퍼블릭이 아니며, 또한 CloudFront에 사용하려면 반드시 us-east-1 리전에 있어야 하므로 올바르지 않습니다.",
    "SelectC": "us-east-1 리전에서 AWS Certificate Manager (ACM)의 Amazon issued public certificate를 요청합니다.",
    "SelectC_Commentary": "CloudFront에서 커스텀 도메인으로 SSL/TLS를 사용하려면 us-east-1 리전에 발급된 퍼블릭 인증서가 필요합니다. 추가 비용이 없으며 요구사항에 부합하는 정답입니다.",
    "SelectD": "us-west-1 리전에서 AWS Certificate Manager (ACM)의 Amazon issued public certificate를 요청합니다.",
    "SelectD_Commentary": "CloudFront는 배포에 사용할 인증서를 us-east-1 리전에 있어야만 정상적으로 적용할 수 있으므로 잘못된 선택입니다.",
    "Question_Description_recommedations": [
      "Q577",
      "Q172",
      "Q538",
      "Q542",
      "Q592"
    ],
    "SelectA_recommedations": [
      "Q855",
      "Q577",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q577",
      "Q855",
      "Q893"
    ],
    "SelectC_recommedations": [
      "Q855",
      "Q577",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q855",
      "Q577",
      "Q893"
    ]
  },
  {
    "Question_Number": "Q856",
    "Question_Description": "한 회사에서 운영 데이터를 Amazon S3 버킷에 저장하고 있습니다. 회사의 연간 감사에서 외부 컨설턴트가 S3 버킷에 저장된 연간 보고서에 접근해야 합니다. 외부 컨설턴트는 7일 동안 해당 보고서에만 접근할 수 있어야 합니다. 회사는 이 요구사항을 충족하기 위해 운영 효율성을 최대화할 수 있는 솔루션이 필요합니다. 어떤 솔루션이 가장 적합합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139092-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 외부 컨설턴트에게 S3 버킷의 특정 객체에만 7일 동안 제한적으로 접근을 허용해야 하는 상황입니다. 접근 범위와 기간을 엄격하게 제어하면서 관리 부담을 최소화하기 위해서는 Presigned URL을 생성해 공유하는 방법이 가장 효율적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "외부 컨설턴트 접근",
      "연간 보고서",
      "Amazon S3",
      "7일 간 접근",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon S3",
      "IAM user",
      "Presigned URL",
      "Static Website Hosting",
      "Public Access",
      "Sigv4 signature",
      "AWS Access Key"
    ],
    "SelectA": "Public static website를 호스팅하는 새 S3 버킷을 생성하고 운영 데이터를 옮긴 후, S3 웹사이트 URL을 공유합니다.",
    "SelectA_Commentary": "운영 데이터를 옮기는 과정과 Public Website 구성이 불필요하게 복잡하며, 보안 제어도 제한적입니다.",
    "SelectB": "7일 동안 S3 버킷에 대해 Public Access를 허용하고, 감사가 끝나면 접근을 제거합니다.",
    "SelectB_Commentary": "버킷 전체를 공개로 설정하는 것은 필요 이상의 접근 권한을 주며, 보안 위험이 큽니다.",
    "SelectC": "해당 보고서에만 접근 권한이 있는 IAM user를 생성하고 Access Key를 외부 컨설턴트에게 제공한 뒤, 7일 후 키를 폐기합니다.",
    "SelectC_Commentary": "IAM user 생성 및 키 관리가 필요해 운영 부담이 크며, 정확한 종료 시점 제어도 번거롭습니다.",
    "SelectD": "S3 버킷에 있는 보고서 위치에 접근 가능한 Presigned URL을 생성하여 외부 컨설턴트에게 공유합니다.",
    "SelectD_Commentary": "Presigned URL은 접근 기간과 범위를 간단히 제한할 수 있으며, 가장 적은 운영 오버헤드로 필요한 보안을 제공합니다.",
    "Question_Description_recommedations": [
      "Q202",
      "Q154",
      "Q44",
      "Q925",
      "Q825"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q678",
      "Q44"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q233"
    ],
    "SelectD_recommedations": [
      "Q44",
      "Q202",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q857",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 고성능 컴퓨팅(HPC) 워크로드를 실행하려고 합니다. 이 워크로드는 낮은 지연 시간의 네트워크 성능과 높은 네트워크 처리량, 그리고 노드 간에 긴밀하게 결합된 통신이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137826-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 HPC 워크로드 특성상 노드 간 통신 지연을 최소화하고 높은 네트워크 처리량을 요구합니다. 클러스터 배치 그룹을 통해 물리적으로 근접하게 인스턴스를 배치해 이러한 요구사항을 적절히 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.4"
    ],
    "Keywords": [
      "고성능 컴퓨팅(HPC)",
      "Amazon EC2 인스턴스",
      "낮은 지연 시간",
      "높은 네트워크 처리량",
      "긴밀한 노드 간 통신",
      "클러스터 배치 그룹"
    ],
    "Terms": [
      "High Performance Computing(HPC)",
      "Amazon EC2",
      "Cluster Placement Group",
      "Dedicated Instance Tenancy",
      "Spot Instances",
      "On-Demand Capacity Reservation",
      "Low-latency",
      "Network Throughput",
      "Node-to-node Communication"
    ],
    "SelectA": "EC2 인스턴스가 클러스터 배치 그룹에 속하도록 구성합니다.",
    "SelectA_Commentary": "클러스터 배치 그룹은 물리적으로 가까운 호스트에 인스턴스를 배치하여 낮은 지연 시간과 높은 처리량을 제공하므로 HPC 요구사항에 가장 적합합니다.",
    "SelectB": "EC2 인스턴스를 Dedicated Instance 테넌시로 시작합니다.",
    "SelectB_Commentary": "Dedicated Instance 테넌시는 물리적 호스트 단독 사용을 보장하지만, 노드 간 저지연 통신과 높은 처리량을 직접적으로 개선해주지 않습니다.",
    "SelectC": "EC2 인스턴스를 Spot Instances로 시작합니다.",
    "SelectC_Commentary": "Spot Instances는 비용 절감에는 유리하나, 중단 가능성이 있어 HPC 워크로드에 필요한 안정적인 저지연 환경을 보장하지 못합니다.",
    "SelectD": "EC2 인스턴스가 시작될 때 On-Demand Capacity Reservation을 구성합니다.",
    "SelectD_Commentary": "On-Demand Capacity Reservation은 인스턴스 용량 확보가 목적이며 노드 간 통신을 최적화하지 않으므로 HPC 환경 요구사항을 직접 해결하지 않습니다.",
    "Question_Description_recommedations": [
      "Q795",
      "Q646",
      "Q746",
      "Q369",
      "Q162"
    ],
    "SelectA_recommedations": [
      "Q746",
      "Q361",
      "Q857"
    ],
    "SelectB_recommedations": [
      "Q746",
      "Q361",
      "Q143"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q594",
      "Q690"
    ],
    "SelectD_recommedations": [
      "Q594",
      "Q857",
      "Q746"
    ]
  },
  {
    "Question_Number": "Q858",
    "Question_Description": "한 회사는 500마일(804.7km) 거리에 위치한 주 데이터 센터(primary data center)와 보조 데이터 센터(secondary data center)를 운영 중이며, 이 둘은 고속 광섬유 케이블로 연결되어 있습니다. 회사는 미션 크리티컬 워크로드를 위해 이들 데이터 센터와 AWS의 VPC 간에 고가용성과 보안을 갖춘 네트워크 연결이 필요합니다. 솔루션스 아키텍트는 최대한 높은 복원력(resiliency)을 제공하는 연결 솔루션을 선택해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/140682-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 물리적으로 떨어진 두 데이터 센터에서 AWS VPC로 연결할 때 고가용성과 복원력을 극대화하는 방안을 묻습니다. 여러 AWS Direct Connect 연결을 서로 다른 장비와 위치로 이중화하면 하나의 연결 또는 장치에 장애가 발생해도 네트워크 연결을 유지할 수 있으므로 최대한의 안정성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "보안 네트워크 연결",
      "미션 크리티컬",
      "복원력",
      "AWS Direct Connect"
    ],
    "Terms": [
      "AWS Direct Connect",
      "Direct Connect location",
      "VPC",
      "primary data center",
      "secondary data center"
    ],
    "SelectA": "주 데이터 센터에서만 2개의 AWS Direct Connect 연결을 사용하며, 2개의 다른 Direct Connect location의 각기 다른 장비에 연결합니다.",
    "SelectA_Commentary": "주 데이터 센터에만 이중 연결을 구성하므로 보조 데이터 센터가 독립적인 연결을 갖지 못해 장애 상황에서 완전한 복원력을 보장하기 어렵습니다.",
    "SelectB": "주 데이터 센터와 보조 데이터 센터 각각에서 단일 AWS Direct Connect 연결을 사용하며, 동일한 Direct Connect location의 동일 장비에 연결합니다.",
    "SelectB_Commentary": "각 데이터 센터에 한 개씩 연결은 있지만, 같은 장비를 공유하므로 장비 단일 장애에 취약해 전체 연결이 중단될 위험이 있습니다.",
    "SelectC": "주 데이터 센터와 보조 데이터 센터 각각에서 2개의 AWS Direct Connect 연결을 사용하며, 2개의 다른 Direct Connect location의 각기 다른 장비에 연결합니다.",
    "SelectC_Commentary": "각 데이터 센터마다 이중화된 연결이 서로 다른 위치와 장비로 구성되어 장애 가능성을 크게 줄이며, 최고의 복원력과 고가용성을 달성합니다.",
    "SelectD": "주 데이터 센터와 보조 데이터 센터 각각에서 단일 AWS Direct Connect 연결을 사용하고, 동일한 Direct Connect location에서 2개의 다른 장비에 연결합니다.",
    "SelectD_Commentary": "장비 이중화만 해결되지만 하나의 location에 의존하여 지리적 장애 상황에는 완전히 대응하지 못해 최적의 복원력을 제공하지 못합니다.",
    "Question_Description_recommedations": [
      "Q311",
      "Q68",
      "Q991",
      "Q720",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q68",
      "Q8",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q68",
      "Q869",
      "Q983"
    ],
    "SelectC_recommedations": [
      "Q68",
      "Q8",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q68",
      "Q194",
      "Q8"
    ]
  },
  {
    "Question_Number": "Q859",
    "Question_Description": "한 회사가 Amazon RDS for Oracle On-Demand DB instance들을 여러 개 운용하고 있으며, 이 인스턴스들은 매우 높은 사용률을 보입니다. 해당 RDS DB instance들은 AWS Organizations 내 멤버 계정들에서 실행되고 있습니다. 회사의 재무팀은 Organizations의 관리 계정과 멤버 계정에 모두 접근 권한이 있으며, AWS Trusted Advisor를 통해 비용 최적화 방안을 찾고자 합니다. 이러한 요구사항을 충족하려면 어떤 단계를 조합해야 합니까? (정답 2개 선택)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137827-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고사용량 On-Demand RDS 인스턴스의 비용을 효율적으로 줄이기 위해 AWS Trusted Advisor를 활용하는 방법을 묻습니다. 재무팀은 AWS Organizations 관리 계정과 멤버 계정에 모두 접근할 수 있으니, 관리 계정에서 Trusted Advisor 정보를 사용하고 RDS Reserved Instance 최적화 여부를 검토하는 것이 핵심입니다. 높은 사용률의 DB에는 Reserved Instance가 비용 절감에 효과적이므로, 이 두 가지 단계를 통해 요구사항을 충족할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS for Oracle",
      "On-Demand DB instance",
      "AWS Trusted Advisor",
      "비용 최적화",
      "AWS Organizations",
      "Amazon RDS Reserved Instance Optimization"
    ],
    "Terms": [
      "AWS Trusted Advisor",
      "Amazon RDS for Oracle",
      "On-Demand DB instance",
      "AWS Organizations",
      "Amazon RDS Reserved Instance Optimization",
      "Amazon RDS Idle DB Instances",
      "AWS Compute Optimizer"
    ],
    "SelectA": "관리 계정에서 AWS Trusted Advisor 권장 사항을 확인합니다.",
    "SelectA_Commentary": "관리 계정에서 Trusted Advisor를 확인하면 전체 Organizations 리소스 상태를 한 번에 파악할 수 있어 비용 최적화 작업이 간소화됩니다.",
    "SelectB": "RDS DB instance가 실행 중인 멤버 계정에서 AWS Trusted Advisor 권장 사항을 확인합니다.",
    "SelectB_Commentary": "멤버 계정에서도 Trusted Advisor 확인은 가능하지만, 해당 문제 요구사항에서는 조직 전체 관점이 필요하므로 단독으로는 충분하지 않습니다.",
    "SelectC": "Amazon RDS Reserved Instance Optimization에 대한 AWS Trusted Advisor 체크를 검토합니다.",
    "SelectC_Commentary": "높은 사용률의 DB 인스턴스는 Reserved Instance 구매로 상당한 비용 절감이 가능합니다. 따라서 RI 최적화 체크가 필수입니다.",
    "SelectD": "Amazon RDS Idle DB Instances에 대한 AWS Trusted Advisor 체크를 검토합니다.",
    "SelectD_Commentary": "문제에서 RDS가 '높은' 사용률이라고 했으므로 ‘Idle DB Instances’ 체크는 핵심 해결책이 되지 않습니다.",
    "SelectE": "컴퓨트 최적화 체크를 검토하고 AWS Compute Optimizer를 사용해 결과를 교차 검증합니다.",
    "SelectE_Commentary": "Compute Optimizer 자체는 EC2 등 주로 컴퓨팅 리소스에 초점을 맞추므로, RDS 비용 절감의 핵심 단서는 되기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q308",
      "Q948",
      "Q959",
      "Q574",
      "Q940"
    ],
    "SelectA_recommedations": [
      "Q728",
      "Q284",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q959",
      "Q859",
      "Q152"
    ],
    "SelectC_recommedations": [
      "Q308",
      "Q940",
      "Q859"
    ],
    "SelectD_recommedations": [
      "Q959",
      "Q380",
      "Q940"
    ],
    "SelectE_recommedations": [
      "Q728",
      "Q485",
      "Q284"
    ]
  },
  {
    "Question_Number": "Q860",
    "Question_Description": "한 솔루션스 아키텍트가 애플리케이션을 생성 중입니다. 이 애플리케이션은 VPC의 여러 가용 영역에 있는 private subnet의 Amazon EC2 인스턴스에서 실행됩니다. EC2 인스턴스는 기밀 정보를 포함하는 대용량 파일에 자주 액세스합니다. 이 파일들은 처리 목적으로 Amazon S3 버킷에 저장되어 있습니다. 솔루션스 아키텍트는 네트워크 아키텍처를 최적화하여 데이터 전송 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137828-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 private subnet의 EC2 인스턴스가 Amazon S3 버킷에 저장된 기밀 대용량 파일에 액세스할 때, 트래픽이 인터넷을 경유하지 않도록 해 비용을 절감하는 가장 적절한 방안을 찾는 것입니다. Gateway endpoint 를 사용하면 S3로의 트래픽이 VPC 밖으로 나가지 않아 NAT Gateway 비용 없이 안전하고 저렴하게 데이터를 전송할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "private subnet",
      "Amazon EC2",
      "Amazon S3",
      "데이터 전송 비용 최소화",
      "Gateway endpoint",
      "NAT Gateway",
      "AWS PrivateLink",
      "Interface endpoint"
    ],
    "Terms": [
      "Gateway endpoint for Amazon S3",
      "NAT Gateway",
      "AWS PrivateLink",
      "Interface endpoint",
      "Route Table",
      "Availability Zone"
    ],
    "SelectA": "VPC 내에 Amazon S3 용 Gateway endpoint를 생성합니다. private subnet의 라우트 테이블에 해당 Gateway endpoint로의 라우팅 항목을 추가합니다.",
    "SelectA_Commentary": "S3 접근 트래픽이 인터넷을 우회하지 않도록 하여 전송 비용을 줄이고, 추가 관리가 거의 필요 없어 운영이 간소합니다. 비용 효율적인 최적의 솔루션입니다.",
    "SelectB": "public subnet에 NAT Gateway를 하나 생성합니다. private subnet의 라우트 테이블에 NAT Gateway를 가리키는 기본 라우팅 항목을 추가합니다.",
    "SelectB_Commentary": "NAT Gateway를 통해 인터넷 연결을 사용하면 데이터 전송 비용이 증가합니다. 추가 요금이 들고 여전히 인터넷 경유 트래픽이 발생해 비효율적입니다.",
    "SelectC": "VPC에 AWS PrivateLink를 사용한 Amazon S3 Interface endpoint를 생성합니다. private subnet의 라우트 테이블에 이 Interface endpoint를 가리키는 항목을 추가합니다.",
    "SelectC_Commentary": "AWS PrivateLink의 Interface endpoint 방식은 주로 다른 AWS 서비스나 SaaS 접근에 주로 쓰이며, 대량의 S3 트래픽에는 Gateway endpoint가 더 적합하고 비용 효율적입니다.",
    "SelectD": "각 가용 영역의 public subnet마다 NAT Gateway를 생성합니다. 동일 가용 영역의 private subnet 라우트 테이블에 해당 NAT Gateway를 가리키는 기본 라우팅 항목을 추가합니다.",
    "SelectD_Commentary": "각 가용 영역마다 NAT Gateway를 배치하면 고가용성은 높을 수 있으나, NAT Gateway 비용이 중복 발생하여 전송 비용이 더욱 커집니다.",
    "Question_Description_recommedations": [
      "Q471",
      "Q993",
      "Q42",
      "Q238",
      "Q417"
    ],
    "SelectA_recommedations": [
      "Q860",
      "Q497",
      "Q471"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q943",
      "Q860"
    ],
    "SelectC_recommedations": [
      "Q860",
      "Q497",
      "Q471"
    ],
    "SelectD_recommedations": [
      "Q860",
      "Q497",
      "Q485"
    ]
  },
  {
    "Question_Number": "Q861",
    "Question_Description": "한 회사가 온프레미스 MySQL 데이터베이스를 AWS로 이전하고자 합니다. 이 데이터베이스는 고객이 사용하는 애플리케이션으로부터 정기적인 데이터 입력을 받으며, 이로 인해 매우 많은 쓰기 작업이 발생합니다. 회사는 이러한 높은 트래픽이 애플리케이션 내부에 성능 문제를 일으킬 수 있다고 우려하고 있습니다. Solutions Architect는 AWS에서 어떻게 아키텍처를 설계해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138185-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 높은 쓰기 트래픽을 처리할 수 있는 DB 성능 향상이 핵심입니다. Amazon RDS for MySQL에서 Provisioned IOPS SSD 스토리지와 CloudWatch 모니터링을 사용하면 충분한 쓰기 처리량과 성능을 유지할 수 있습니다. ElastiCache는 읽기 성능 개선에 적합하고, DocumentDB나 EFS는 기존 MySQL 구조와 맞지 않아 부적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "MySQL",
      "높은 쓰기 트래픽",
      "Amazon RDS",
      "Provisioned IOPS SSD",
      "성능 문제",
      "온프레미스 이전"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Provisioned IOPS SSD",
      "General Purpose SSD",
      "Amazon ElastiCache",
      "Amazon DocumentDB (with MongoDB compatibility)",
      "Amazon EFS",
      "Amazon CloudWatch"
    ],
    "SelectA": "Amazon RDS for MySQL DB 인스턴스에 Provisioned IOPS SSD 스토리지를 프로비저닝합니다. Amazon CloudWatch로 쓰기 작업 지표를 모니터링하고, 필요한 경우 프로비저닝된 IOPS를 조정합니다.",
    "SelectA_Commentary": "Provisioned IOPS SSD는 많은 쓰기 트래픽 처리에 적합하며, CloudWatch로 성능 지표를 모니터링해 IOPS를 유연하게 조정할 수 있어 정답입니다.",
    "SelectB": "Amazon RDS for MySQL DB 인스턴스에 General Purpose SSD 스토리지를 구성합니다. 그 앞에 Amazon ElastiCache 클러스터를 배치하고, 애플리케이션이 ElastiCache를 먼저 조회하도록 구성합니다.",
    "SelectB_Commentary": "ElastiCache는 읽기 성능 향상에 유리하나, 본 문제에서는 높은 쓰기 트래픽 처리 이슈가 핵심이므로 적절하지 않습니다.",
    "SelectC": "메모리 최적화 인스턴스 타입으로 Amazon DocumentDB(with MongoDB compatibility) 인스턴스를 프로비저닝합니다. Amazon CloudWatch에서 성능 관련 이슈를 모니터링하고, 필요한 경우 인스턴스 클래스를 변경합니다.",
    "SelectC_Commentary": "DocumentDB는 MongoDB 호환 DB로, MySQL 기반 애플리케이션에 직접적인 마이그레이션이 어렵고 요구사항에도 부합하지 않습니다.",
    "SelectD": "General Purpose 모드로 Amazon EFS 파일 시스템을 프로비저닝합니다. Amazon CloudWatch로 IOPS 병목현상을 모니터링하고, 필요하면 Provisioned Throughput 모드로 전환합니다.",
    "SelectD_Commentary": "Amazon EFS는 파일 스토리지로써 대규모 쓰기 처리량이 필요한 관계형 DB에 적합하지 않으며, DB 성능 이슈 해결책이 되기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q561",
      "Q268",
      "Q431",
      "Q565",
      "Q819"
    ],
    "SelectA_recommedations": [
      "Q394",
      "Q376",
      "Q386"
    ],
    "SelectB_recommedations": [
      "Q481",
      "Q386",
      "Q394"
    ],
    "SelectC_recommedations": [
      "Q33",
      "Q472",
      "Q177"
    ],
    "SelectD_recommedations": [
      "Q394",
      "Q305",
      "Q695"
    ]
  },
  {
    "Question_Number": "Q862",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 운영하여 민감한 보관용 데이터 파일을 생성하고 있습니다. 회사는 애플리케이션의 데이터 스토리지를 재설계하려고 하며, 데이터 파일을 암호화하고 AWS로 전송되기 전 제3자 접근을 차단하고자 합니다. 회사는 이미 Amazon S3 버킷을 만들어 두었습니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138010-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터를 업로드하기 전에 이미 암호화를 적용하여 전송 과정에서 제3자가 데이터를 열람할 수 없도록 하는 것이 핵심입니다. 따라서 Client-Side Encryption이 필수이며, 특히 AWS KMS를 사용해 키를 안전하게 관리하면 요구사항을 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 보관용 데이터 파일",
      "데이터 암호화",
      "제3자 접근 차단",
      "AWS 전송 전 암호화"
    ],
    "Terms": [
      "Client-Side Encryption",
      "AWS Key Management Service(AWS KMS)",
      "Server-Side Encryption",
      "SSE-KMS",
      "Amazon S3 managed encryption key",
      "Dual-Layer Server-Side Encryption"
    ],
    "SelectA": "S3 버킷에서 Amazon S3 managed encryption key를 사용하는 client-side encryption을 구성하고, 애플리케이션을 구성하여 보관 파일을 해당 S3 버킷에 저장합니다.",
    "SelectA_Commentary": "Amazon S3 managed encryption key는 서버 측에서 암호화를 관리하며, 실제로는 client-side encryption으로 완벽히 구동되지 않아 요구사항을 충족하기 어렵습니다.",
    "SelectB": "S3 버킷에서 서버 측 암호화(AWS KMS keys, SSE-KMS)를 구성하고, 애플리케이션을 구성하여 보관 파일을 해당 S3 버킷에 저장합니다.",
    "SelectB_Commentary": "서버 측 암호화를 적용하면 데이터가 AWS에 도달한 후에 암호화됩니다. 전송 중에는 데이터가 일반 텍스트 상태가 될 수 있어 제3자 노출 위험이 남습니다.",
    "SelectC": "S3 버킷에서 AWS KMS keys(SSE-KMS)를 사용하는 이중 레이어 서버 측 암호화를 구성하고, 애플리케이션을 구성하여 보관 파일을 해당 S3 버킷에 저장합니다.",
    "SelectC_Commentary": "이중 레이어라도 서버 측에서만 암호화가 수행되므로, AWS로 전송하기 이전에는 데이터가 암호화되지 않아 요구사항을 충족하지 못합니다.",
    "SelectD": "애플리케이션에서 AWS KMS에 저장된 키를 사용하여 client-side encryption을 활성화하고, 애플리케이션을 구성하여 보관 파일을 S3 버킷에 저장합니다.",
    "SelectD_Commentary": "애플리케이션 단계에서 미리 암호화하면 전송 전부터 데이터가 보호되어 제3자가 데이터를 볼 수 없으므로 요구사항을 완벽하게 충족합니다.",
    "Question_Description_recommedations": [
      "Q638",
      "Q109",
      "Q270",
      "Q965",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q965",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q1009",
      "Q793",
      "Q740"
    ],
    "SelectC_recommedations": [
      "Q1009",
      "Q793",
      "Q640"
    ],
    "SelectD_recommedations": [
      "Q1009",
      "Q916",
      "Q640"
    ]
  },
  {
    "Question_Number": "Q863",
    "Question_Description": "한 회사가 데이터베이스 계층을 위해 Amazon RDS의 기본 백업 설정을 사용하고 있습니다. 이 회사는 규제 요구 사항을 충족하기 위해 매일 데이터베이스 백업을 수행해야 하며, 해당 백업을 30일 동안 보관해야 합니다. 운영 오버헤드를 가장 적게 들이면서 이러한 요구 사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139172-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 규제 요구 사항을 충족하기 위해 매일 백업을 수행하고, 백업을 30일간 보관해야 하는 상황에서 자동화와 간편성을 모두 만족하는 방법을 찾는 것입니다. Amazon RDS는 기본적으로 Automated Backup 기능을 제공하며, 보관 기간(Retention Period)을 설정하면 매일 자동 백업이 수행됩니다. 이를 30일로 조정하는 것이 운영 오버헤드를 최소화하는 최적의 방법입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS",
      "일일 백업",
      "30일간 백업 보관",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon RDS",
      "Automated Backups",
      "AWS Lambda",
      "RDS Snapshot",
      "AWS Systems Manager Maintenance Windows",
      "AWS CLI",
      "Retention Period",
      "Manual Snapshot"
    ],
    "SelectA": "AWS Lambda 함수를 작성하여 매일 RDS 스냅샷을 생성합니다.",
    "SelectA_Commentary": "Lambda 함수로 수동 스냅샷을 생성하는 방식은 현재 RDS의 Automated Backup 기능보다 복잡하며 추가 코드 관리가 필요합니다.",
    "SelectB": "RDS 데이터베이스의 자동 백업 보관 기간을 30일로 설정합니다.",
    "SelectB_Commentary": "자동 백업 기능을 활용해 백업을 30일간 보관하면 운영상 간단하며 요구 사항을 쉽게 충족할 수 있는 최적의 솔루션입니다.",
    "SelectC": "AWS Systems Manager Maintenance Windows를 사용하여 RDS 백업 보관 기간을 수정합니다.",
    "SelectC_Commentary": "Maintenance Windows로 보관 기간을 설정하는 것은 불필요한 프로세스가 추가되어 오버헤드가 증가합니다.",
    "SelectD": "AWS CLI를 사용해 매일 매뉴얼 스냅샷을 생성하고, RDS 백업 보관 기간을 수정합니다.",
    "SelectD_Commentary": "매일 스냅샷을 수동으로 생성하는 것은 자동 백업에 비해 번거롭고 운영 오버헤드가 높아 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q108",
      "Q149",
      "Q259",
      "Q786",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q785",
      "Q108"
    ],
    "SelectB_recommedations": [
      "Q863",
      "Q108",
      "Q58"
    ],
    "SelectC_recommedations": [
      "Q518",
      "Q629",
      "Q259"
    ],
    "SelectD_recommedations": [
      "Q518",
      "Q944",
      "Q259"
    ]
  },
  {
    "Question_Number": "Q865",
    "Question_Description": "한 회사가 AWS에서 거의 실시간으로 동작하는 스트리밍 애플리케이션을 운영하고 있습니다. 데이터가 유입될 때마다 30분이 소요되는 작업이 실행됩니다. 유입되는 데이터가 많아지면서 자주 높은 지연 시간이 발생하고 있습니다. 이를 해결하기 위해 솔루션스 아키텍트는 확장 가능하고 서버리스한 솔루션을 설계하여 성능을 향상해야 합니다. 다음 중 어떤 단계를 조합해야 합니까? (2가지를 고르시오.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137829-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실시간에 가까운 대규모 스트리밍 데이터를 처리하면서, 30분이 걸리는 작업을 효율적이고 확장 가능한 서버리스 아키텍처로 구현하는 시나리오입니다. Lambda는 단일 함수로 15분을 넘길 수 없지만, Step Functions로 분할하거나, 보다 단순하게 Fargate를 통해 30분 이상의 작업도 서버리스로 구동할 수 있습니다. 데이터 수집에는 실시간 처리를 지원하는 Kinesis Data Firehose가 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "거의 실시간 스트리밍",
      "30분 작업",
      "높은 지연 시간",
      "확장 가능",
      "서버리스",
      "성능 향상"
    ],
    "Terms": [
      "Amazon Kinesis Data Firehose",
      "AWS Lambda",
      "AWS Step Functions",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon EC2",
      "AWS Fargate",
      "Amazon Elastic Container Service (Amazon ECS)"
    ],
    "SelectA": "Use Amazon Kinesis Data Firehose to ingest the data.",
    "SelectA_Commentary": "Kinesis Data Firehose는 서버리스 스트리밍 수집에 최적화되어 대규모 데이터 유입을 효율적으로 처리할 수 있습니다.",
    "SelectB": "Use AWS Lambda with AWS Step Functions to process the data.",
    "SelectB_Commentary": "Lambda는 단일 실행 제한이 15분이므로, 여러 함수를 Step Functions로 구성해야 하지만 구현이 다소 복잡할 수 있습니다.",
    "SelectC": "Use AWS Database Migration Service (AWS DMS) to ingest the data.",
    "SelectC_Commentary": "AWS DMS는 데이터베이스 간 마이그레이션에 주로 사용되므로, 스트리밍 처리에는 적합하지 않습니다.",
    "SelectD": "Use Amazon EC2 instances in an Auto Scaling group to process the data.",
    "SelectD_Commentary": "EC2 Auto Scaling은 서버 구성과 관리를 요구하므로 서버리스 구현 목표에 어긋납니다.",
    "SelectE": "Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data.",
    "SelectE_Commentary": "Fargate는 서버를 직접 관리하지 않고 30분 이상의 작업도 처리할 수 있어, 확장 가능하고 서버리스한 프로세싱에 적합합니다.",
    "Question_Description_recommedations": [
      "Q361",
      "Q443",
      "Q568",
      "Q738",
      "Q631"
    ],
    "SelectA_recommedations": [
      "Q414",
      "Q557",
      "Q2"
    ],
    "SelectB_recommedations": [
      "Q414",
      "Q557",
      "Q361"
    ],
    "SelectC_recommedations": [
      "Q414",
      "Q292",
      "Q177"
    ],
    "SelectD_recommedations": [
      "Q335",
      "Q461",
      "Q674"
    ],
    "SelectE_recommedations": [
      "Q704",
      "Q557",
      "Q515"
    ]
  },
  {
    "Question_Number": "Q866",
    "Question_Description": "한 회사가 VPC 내 여러 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 민감한 데이터를 Amazon S3 버킷에 기록해야 합니다. 해당 데이터는 퍼블릭 인터넷을 통해 전송될 수 없습니다. 이러한 요구사항을 충족하기 위한 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137855-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 VPC 내부에서 Amazon S3로 민감한 데이터를 전송할 때 퍼블릭 인터넷 노출 없이 안전하게 전달하는 방법을 묻습니다. Gateway VPC Endpoint를 사용하면 트래픽이 AWS 내부 네트워크를 통해서만 전송되어 보안을 강화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "민감한 데이터",
      "Amazon S3 버킷",
      "퍼블릭 인터넷 차단",
      "Gateway VPC Endpoint"
    ],
    "Terms": [
      "Amazon EC2",
      "VPC",
      "Amazon S3",
      "Gateway VPC Endpoint",
      "Network Load Balancer",
      "AWS Direct Connect"
    ],
    "SelectA": "Amazon S3에 대한 Gateway VPC Endpoint를 생성하고, VPC 라우트 테이블에 해당 엔드포인트로의 경로를 설정합니다.",
    "SelectA_Commentary": "Gateway VPC Endpoint를 사용하면 데이터가 퍼블릭 인터넷을 거치지 않고 안전하게 VPC 내부에서 S3로 전달되어 요구 사항을 충족합니다.",
    "SelectB": "내부 Network Load Balancer를 생성하고 Amazon S3 버킷을 대상으로 지정합니다.",
    "SelectB_Commentary": "Amazon S3 버킷을 Load Balancer의 직접 대상(Target)으로 사용하는 것은 불가능하며, 퍼블릭 인터넷을 우회하는 보안 경로 제공도 어렵습니다.",
    "SelectC": "VPC 내부에 S3 버킷을 배포하고, VPC 라우팅 테이블에 버킷으로의 경로를 생성합니다.",
    "SelectC_Commentary": "Amazon S3는 리전 단위로 관리되므로 VPC 안에 직접 배포할 수 없으며, 이 방식으로는 퍼블릭 인터넷 경로를 제거하기 어렵습니다.",
    "SelectD": "VPC와 S3 리전 엔드포인트 간에 AWS Direct Connect 연결을 만듭니다.",
    "SelectD_Commentary": "Direct Connect를 이용하면 전용 회선을 통해 연결이 가능하지만, 설정과 비용이 크며 Gateway VPC Endpoint 방식이 더 단순하고 효율적입니다.",
    "Question_Description_recommedations": [
      "Q92",
      "Q980",
      "Q91",
      "Q4",
      "Q612"
    ],
    "SelectA_recommedations": [
      "Q91",
      "Q92",
      "Q4"
    ],
    "SelectB_recommedations": [
      "Q170",
      "Q884",
      "Q616"
    ],
    "SelectC_recommedations": [
      "Q92",
      "Q866",
      "Q4"
    ],
    "SelectD_recommedations": [
      "Q92",
      "Q667",
      "Q866"
    ]
  },
  {
    "Question_Number": "Q867",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스와 Amazon EBS 볼륨에 프로덕션 워크로드를 운영하고 있습니다. 솔루션스 아키텍트는 현재 EBS 볼륨 비용을 분석하고 최적화를 위한 권장 사항을 제시해야 합니다. 이 권장 사항에는 월별 절감 기회 추정치가 포함되어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137854-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EBS 볼륨의 비용을 분석하여 비용 절감 방안을 제시해야 하는 상황입니다. AWS Compute Optimizer는 EC2 인스턴스, EBS 볼륨, ECS 서비스, AWS Lambda 함수를 대상으로 과도하거나 부족하게 프로비저닝된 리소스를 분석하고 자동화된 권장 사항과 추정 절감 금액을 제공합니다. 다른 서비스들은 보안 보고, 시스템 관리, 지표 모니터링 목적이 커서 직접적인 월별 절감 추정이 어렵습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "EBS 볼륨",
      "월별 절감 기회",
      "비용 최적화",
      "Amazon EC2",
      "AWS Compute Optimizer"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Elastic Block Store(Amazon EBS)",
      "AWS Compute Optimizer",
      "Amazon Inspector",
      "AWS Systems Manager",
      "Amazon CloudWatch"
    ],
    "SelectA": "Amazon Inspector 보고서를 사용하여 EBS 볼륨 최적화 권장 사항을 생성합니다.",
    "SelectA_Commentary": "Amazon Inspector는 보안 취약성 감지 도구로, 비용 절감 분석과 직접적 연관은 없어 오답입니다.",
    "SelectB": "AWS Systems Manager 보고서를 사용하여 EBS 볼륨 최적화 권장 사항을 확인합니다.",
    "SelectB_Commentary": "Systems Manager는 인스턴스 상태나 패치 관리 등 운영 관리를 지원하지만, EBS 비용 최적화와 월별 추정치 제공 기능은 제한적입니다.",
    "SelectC": "Amazon CloudWatch 지표 보고서를 사용하여 EBS 볼륨 최적화 권장 사항을 확인합니다.",
    "SelectC_Commentary": "CloudWatch는 지표 모니터링 서비스로, 사용률을 확인은 가능하지만 자동화된 최적화 권장과 절감 추정 기능은 제공하지 않습니다.",
    "SelectD": "AWS Compute Optimizer를 사용하여 EBS 볼륨 최적화 권장 사항을 생성합니다.",
    "SelectD_Commentary": "AWS Compute Optimizer는 리소스 활용도를 분석하여 볼륨 프로비저닝 과부족을 파악하고 월별 절감 추정까지 제공하므로 정답입니다.",
    "Question_Description_recommedations": [
      "Q238",
      "Q671",
      "Q167",
      "Q552",
      "Q993"
    ],
    "SelectA_recommedations": [
      "Q728",
      "Q284",
      "Q867"
    ],
    "SelectB_recommedations": [
      "Q867",
      "Q591",
      "Q662"
    ],
    "SelectC_recommedations": [
      "Q867",
      "Q591",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q937",
      "Q867",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q868",
    "Question_Description": "한 글로벌 회사가 AWS에서 워크로드를 운영하고 있습니다. 이 회사의 애플리케이션은 민감한 데이터 저장과 분석을 위해 여러 AWS Region에 걸쳐 Amazon S3 버킷을 사용합니다. 이 회사는 매일 수백만 개의 객체를 여러 S3 버킷에 저장합니다. 회사에서는 버전링(versioning)이 활성화되지 않은 모든 S3 버킷을 식별하고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137847-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다수의 Amazon S3 버킷 중 버전링이 활성화되지 않은 버킷을 빠르고 정확하게 파악하는 방법을 묻습니다. 버전링을 사용하면 데이터 변경·삭제 시 복구가 가능하기 때문에, 중요한 데이터를 보호하려는 보안 정책 측면에서 매우 중요합니다. S3 Storage Lens는 계정 전체의 S3 사용 현황을 분석하고, 버전링 상태까지 통합 리포트로 확인할 수 있으므로 적합한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "글로벌 회사",
      "AWS Region",
      "민감 데이터",
      "버전링 미활성화 식별",
      "수백만 객체"
    ],
    "Terms": [
      "Amazon S3",
      "Versioning",
      "Amazon S3 Storage Lens",
      "IAM Access Analyzer",
      "S3 Multi-Region Access Point"
    ],
    "SelectB": "Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.",
    "SelectB_Commentary": "Amazon S3 Storage Lens는 전체 S3 버킷의 메트릭과 분석 보고서를 제공해 버전링이 비활성화된 버킷을 손쉽게 찾아낼 수 있으므로 요구 사항을 충족합니다.",
    "SelectC": "Enable IAM Access Analyzer for S3 to identify all S3 buckets that are not versioning-enabled across Regions.",
    "SelectC_Commentary": "IAM Access Analyzer는 버킷 공유 정책 등을 분석해 외부 접근 통제를 파악하는 도구로, 버전링 설정 여부를 확인하는 주된 기능이 아니므로 적합하지 않습니다.",
    "SelectD": "Create an S3 Multi-Region Access Point to identify all S3 buckets that are not versioning-enabled across Regions.",
    "SelectD_Commentary": "S3 Multi-Region Access Point는 여러 Region에 걸쳐 단일 엔드포인트를 제공하는 기능이며, 버전링 미활성화 여부를 식별하는 목적에 맞지 않아 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q889",
      "Q134",
      "Q862",
      "Q109",
      "Q667"
    ],
    "SelectB_recommedations": [
      "Q868",
      "Q889",
      "Q216"
    ],
    "SelectC_recommedations": [
      "Q868",
      "Q982",
      "Q889"
    ],
    "SelectD_recommedations": [
      "Q868",
      "Q889",
      "Q542"
    ]
  },
  {
    "Question_Number": "Q869",
    "Question_Description": "한 회사가 AWS에 배포된 전자상거래 주문 처리 애플리케이션을 개선하려고 합니다. 해당 애플리케이션은 예측 불가능한 트래픽 급증 중에도 고객 경험에 영향을 주지 않으면서 각 주문을 정확히 한 번씩 처리해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138082-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 트래픽 급증 시에도 고객 경험에 영향을 주지 않고 각 주문을 정확히 한 번 처리해야 하는 요구사항을 다룹니다. Amazon SQS FIFO를 사용하면 메시지의 순서를 보장하고 중복을 방지해 정확히 한 번 처리가 가능하며, Lambda가 서버리스 형태로 확장성을 제공하여 가용성을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "정확히 한 번 처리",
      "전자상거래 주문",
      "예측 불가능한 트래픽",
      "고객 경험"
    ],
    "Terms": [
      "Amazon SQS FIFO",
      "AWS Lambda",
      "Amazon SNS",
      "Amazon AppFlow",
      "AWS X-Ray",
      "Amazon CloudWatch"
    ],
    "SelectA": "Amazon SQS FIFO 큐를 생성합니다. 모든 주문을 이 SQS 큐에 넣습니다. 주문 처리를 위해 AWS Lambda 함수를 대상(타깃)으로 설정합니다.",
    "SelectA_Commentary": "Amazon SQS FIFO 큐는 중복 없이 메시지 순서를 보장하며, AWS Lambda는 수요에 따라 자동 확장되므로 트래픽 급증에도 안정적으로 정확히 한 번 처리가 가능합니다.",
    "SelectB": "Amazon SNS standard topic을 생성합니다. 모든 주문을 SNS standard topic에 발행(publish)합니다. 알림 대상(타깃)으로 애플리케이션을 설정합니다.",
    "SelectB_Commentary": "SNS standard topic은 메시지 중복 가능성이 있어 '정확히 한 번'을 보장하기 어렵고, 특정 소비자가 같은 메시지를 여러 번 받을 수 있어 요구사항에 부합하지 않습니다.",
    "SelectC": "Amazon AppFlow를 사용하여 플로우(flow)를 만듭니다. 해당 플로우로 주문 데이터를 전송합니다. 주문 처리를 위해 AWS Lambda 함수를 대상(타깃)으로 설정합니다.",
    "SelectC_Commentary": "AppFlow는 SaaS 애플리케이션 간 데이터 전송 및 변환에 중점을 둡니다. 메시지 순서 및 정확히 한 번 처리 보장이 없어 요구사항을 충족하기 어렵습니다.",
    "SelectD": "애플리케이션에서 AWS X-Ray를 설정하여 주문 요청을 추적합니다. Amazon CloudWatch에서 주문 정보를 가져와(풀링) 애플리케이션이 처리하도록 구성합니다.",
    "SelectD_Commentary": "AWS X-Ray는 분산 추적, CloudWatch는 모니터링 용도이며, '정확히 한 번 처리'에 대한 보장이 없습니다. 큐 기반 솔루션보다 운영 복잡성이 증가합니다.",
    "Question_Description_recommedations": [
      "Q519",
      "Q802",
      "Q786",
      "Q8",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q293",
      "Q10",
      "Q401"
    ],
    "SelectB_recommedations": [
      "Q363",
      "Q8",
      "Q293"
    ],
    "SelectC_recommedations": [
      "Q351",
      "Q785",
      "Q775"
    ],
    "SelectD_recommedations": [
      "Q293",
      "Q902",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q870",
    "Question_Description": "한 회사는 Production 계정과 Development 계정, 총 두 개의 AWS 계정을 보유하고 있습니다. 회사는 Development 계정에서 Production 계정으로 코드 변경 사항을 푸시해야 합니다. 알파 단계에서는 개발 팀의 시니어 개발자 두 명만 Production 계정에 액세스해야 합니다. 베타 단계에서는 더 많은 개발자들이 테스트를 수행하기 위해 액세스가 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137848-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 두 개의 AWS 계정 간 교차 계정 액세스를 안전하고 올바르게 설정하는 방법을 묻습니다. 가장 효과적인 방법은 Production 계정에 IAM 역할을 생성하고 Development 계정을 트러스트 정책으로 지정해 필요한 개발자들이 해당 역할을 Assume하여 접근권을 얻는 것입니다. 이렇게 하면 알파 단계에서는 시니어 개발자 둘만 역할을 사용할 수 있도록 제어하고, 베타 단계에서는 필요에 따라 권한을 쉽게 확장할 수 있어 유연성과 보안 요건을 만족시킵니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Production 계정",
      "Development 계정",
      "IAM 역할",
      "트러스트 정책",
      "알파 단계",
      "베타 단계"
    ],
    "Terms": [
      "IAM role",
      "Cross-account Access",
      "Trust Policy",
      "AWS Management Console",
      "IAM group",
      "Policy Document"
    ],
    "SelectA": "각 계정에서 AWS Management Console을 사용하여 두 개의 정책 문서를 생성합니다. 액세스가 필요한 개발자에게 해당 정책을 할당합니다.",
    "SelectA_Commentary": "두 계정 모두에서 개별 정책을 생성해 할당하면 계정 간 권한 관리가 분산되고 복잡해집니다. 교차 계정 역할을 사용하는 것보다 권장되지 않는 방법입니다.",
    "SelectB": "Development 계정에 IAM 역할을 생성합니다. 해당 IAM 역할에 Production 계정에 대한 액세스를 부여합니다. 개발자들이 이 IAM 역할을 사용할 수 있도록 허용합니다.",
    "SelectB_Commentary": "관리가 쉽지 않고, 일반적으로 트러스트 정책은 리소스 소유 계정(Production)에 설정합니다. 또한 Production 리소스에 대한 권한 위임 구조가 맞지 않습니다.",
    "SelectC": "Production 계정에 IAM 역할을 생성합니다. 트러스트 정책에서 Development 계정을 지정합니다. 개발자들이 이 IAM 역할을 사용할 수 있도록 허용합니다.",
    "SelectC_Commentary": "가장 권장되는 교차 계정 액세스 방식입니다. Production 계정에 IAM 역할을 생성하고, Development 계정에 한해 역할을 Assume할 수 있도록 지정해 접근 범위를 안전하게 제어할 수 있습니다.",
    "SelectD": "Production 계정에 IAM 그룹을 생성합니다. 트러스트 정책에 Production 계정을 명시하여 이 그룹을 주체로 추가합니다. 개발자들을 이 그룹에 추가합니다.",
    "SelectD_Commentary": "IAM 그룹은 동일 계정 내 사용자 권한을 묶을 때 사용합니다. 다른 계정의 개발자를 위한 교차 계정 액세스 구현 방법으로는 적절치 않습니다.",
    "Question_Description_recommedations": [
      "Q592",
      "Q831",
      "Q922",
      "Q313",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q233",
      "Q831",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q870",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q870",
      "Q665"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q665",
      "Q122"
    ]
  },
  {
    "Question_Number": "Q871",
    "Question_Description": "한 회사가 웹 애플리케이션의 콘텐츠에 대한 접근을 제한하고자 합니다. 회사는 AWS에서 제공하는 권한 부여(authorization) 기술을 사용해 콘텐츠를 보호해야 합니다. 또한 인증(authentication)과 권한 부여를 위한 serverless 아키텍처를 구현하되, 로그인 지연(latency)이 낮아야 합니다. 솔루션은 웹 애플리케이션과 통합되어야 하며, 전 세계적으로 웹 콘텐츠를 제공해야 합니다. 현재 애플리케이션의 사용자는 적지만, 앞으로 사용자 수가 증가할 것으로 예상됩니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138553-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션 콘텐츠 접근을 제어하고, 글로벌 사용자에게 낮은 지연으로 서비스하기 위한 보안 및 배포 전략을 묻고 있습니다. AWS에서 제공하는 인증/권한 부여 서비스와 전 세계적인 콘텐츠 배포를 고려해야 합니다. Amazon Cognito와 Lambda@Edge를 함께 사용하면 서버리스 환경에서 낮은 지연으로 인증과 권한 부여를 처리하고, Amazon CloudFront를 통해 글로벌 서비스가 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "서버리스 아키텍처",
      "낮은 로그인 지연",
      "전 세계 웹 콘텐츠 제공",
      "접근 제한",
      "사용자 증가 대비"
    ],
    "Terms": [
      "Amazon Cognito",
      "Lambda@Edge",
      "AWS Directory Service for Microsoft Active Directory",
      "AWS Lambda",
      "Application Load Balancer",
      "Amazon CloudFront",
      "Amazon S3 Transfer Acceleration",
      "AWS Elastic Beanstalk"
    ],
    "SelectA": "Amazon Cognito를 인증에 사용하고, Lambda@Edge로 권한 부여를 구현합니다. 전 세계적으로 웹 애플리케이션을 제공하기 위해 Amazon CloudFront를 구성합니다.",
    "SelectA_Commentary": "Amazon Cognito와 Lambda@Edge가 결합되어 서버리스 환경에서 신속한 인증·권한 부여가 가능하며, CloudFront가 전 세계적으로 콘텐츠를 빠르게 전달해 요구사항에 가장 적합합니다.",
    "SelectB": "AWS Directory Service for Microsoft Active Directory를 인증에 사용하고, AWS Lambda로 권한 부여를 구현합니다. Application Load Balancer를 통해 전 세계적으로 웹 애플리케이션을 제공합니다.",
    "SelectB_Commentary": "Microsoft Active Directory는 온프레미스 환경 연동에 적합하지만, 규모 확장성과 전 세계 콘텐츠 제공 측면에서 CloudFront만큼 이점이 없어 요구사항과 맞지 않습니다.",
    "SelectC": "Amazon Cognito를 인증에 사용하고, AWS Lambda로 권한 부여를 구현합니다. Amazon S3 Transfer Acceleration을 통해 전 세계적으로 웹 애플리케이션을 제공합니다.",
    "SelectC_Commentary": "S3 Transfer Acceleration은 업로드 가속화에 집중된 기능이므로, 웹 콘텐츠 글로벌 전송을 위해서는 CloudFront처럼 Edge Location 기반의 콘텐츠 전송 기능이 더 적합합니다.",
    "SelectD": "AWS Directory Service for Microsoft Active Directory를 인증에 사용하고, Lambda@Edge로 권한 부여를 구현합니다. AWS Elastic Beanstalk를 통해 전 세계적으로 웹 애플리케이션을 제공합니다.",
    "SelectD_Commentary": "Elastic Beanstalk는 웹 애플리케이션 배포에 편리하지만, 글로벌 콘텐츠 전달 측면에서 CloudFront 기반의 확장성 및 낮은 지연을 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q893",
      "Q345",
      "Q592",
      "Q426",
      "Q34"
    ],
    "SelectA_recommedations": [
      "Q366",
      "Q200",
      "Q893"
    ],
    "SelectB_recommedations": [
      "Q211",
      "Q884",
      "Q927"
    ],
    "SelectC_recommedations": [
      "Q200",
      "Q366",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q451",
      "Q211",
      "Q826"
    ]
  },
  {
    "Question_Number": "Q872",
    "Question_Description": "한 개발 팀이 개발, 스테이징, 프로덕션 환경을 위해 여러 AWS 계정을 사용하고 있습니다. 팀원들은 충분히 활용되지 않는 대형 Amazon EC2 인스턴스를 계속 실행 중입니다. 한 Solutions Architect가 모든 계정에서 이러한 대형 인스턴스가 실행되지 못하도록 해야 합니다. 운영 오버헤드를 최소화하면서 이 요구 사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139180-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대형 Amazon EC2 인스턴스가 불필요하게 실행되어 비용 낭비가 발생하는 상황에서, 여러 계정을 한꺼번에 제어하여 인스턴스 실행을 제한하려는 시나리오입니다. AWS Organizations의 Service Control Policy (SCP)를 사용하면 중앙에서 간단히 모든 계정에 동일한 제한을 적용할 수 있으므로 운영 오버헤드를 최소화하고 정책 일관성을 유지할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS 계정",
      "대형 Amazon EC2 인스턴스",
      "Service Control Policy(SCP)",
      "AWS Organizations",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "IAM",
      "AWS Organizations",
      "AWS Resource Access Manager",
      "Service Control Policy (SCP)"
    ],
    "SelectA": "IAM 정책을 업데이트하여 대형 EC2 인스턴스 실행을 거부합니다. 이 정책을 모든 사용자에게 적용합니다.",
    "SelectA_Commentary": "각 계정과 사용자별로 정책을 관리해야 하므로 적용 누락 위험이 있고, 계정이 늘어날수록 운영 부담이 커집니다.",
    "SelectB": "AWS Resource Access Manager에서 대형 EC2 인스턴스 실행을 막는 리소스를 정의합니다.",
    "SelectB_Commentary": "AWS Resource Access Manager는 리소스 공유에 초점이 있으며, EC2 인스턴스 유형 제어 및 일괄 제한 용도로 적합하지 않습니다.",
    "SelectC": "각 계정에 대형 EC2 인스턴스 실행을 거부하는 IAM Role을 생성하고, 개발자 IAM Group에 이 Role 접근 권한을 부여합니다.",
    "SelectC_Commentary": "역할별 접근 제어를 계정마다 구축해야 해 반복 작업이 많아지고, 정책 누락 위험이 존재해 오버헤드가 큽니다.",
    "SelectD": "관리자 계정에서 AWS Organizations를 생성하고 기본 정책을 설정합니다. 대형 EC2 인스턴스 실행을 거부하는 SCP를 생성 후 AWS 계정들에 적용합니다.",
    "SelectD_Commentary": "SCP를 통해 모든 계정에 중앙 통제 정책을 즉시 적용할 수 있어, 운영 오버헤드를 가장 효과적으로 줄이는 올바른 해법입니다.",
    "Question_Description_recommedations": [
      "Q124",
      "Q643",
      "Q63",
      "Q309",
      "Q22"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q238",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q671"
    ],
    "SelectC_recommedations": [
      "Q238",
      "Q552",
      "Q290"
    ],
    "SelectD_recommedations": [
      "Q455",
      "Q552",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q873",
    "Question_Description": "한 회사가 수백 대의 온프레미스 가상 머신(VM)을 Amazon EC2 인스턴스로 마이그레이션했습니다. 이 인스턴스들은 여러 버전의 Windows Server와 다양한 Linux Distribution을 함께 사용합니다. 회사는 운영체제 인벤토리와 업데이트 작업을 자동화할 수 있는 솔루션을 원합니다. 또한 각 인스턴스의 공통 취약점을 정기적인(월간) 검토용으로 요약한 보고서를 받아보고 싶어 합니다. 이러한 요구사항을 충족하기 위해서는 어떤 솔루션을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137853-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 마이그레이션된 다수의 Amazon EC2 인스턴스 운영체제를 효율적으로 패치 관리하고, 각 인스턴스의 취약점을 정기적으로 확인하여 보고해야 하는 시나리오입니다. 가장 적합한 해법은 기반 운영체제를 간편하게 패치 관리할 수 있는 AWS Systems Manager Patch Manager와 보안 취약점을 분석·보고하는 Amazon Inspector를 결합하는 것입니다. 이를 통해 월간 리뷰용 취약점 정보를 자동으로 확보할 수 있으며, 운영체제 업데이트에도 일관성을 유지할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "운영체제 인벤토리",
      "자동화 업데이트",
      "common vulnerabilities",
      "monthly reviews",
      "AWS Systems Manager Patch Manager",
      "Amazon Inspector"
    ],
    "Terms": [
      "AWS Systems Manager Patch Manager",
      "AWS Security Hub",
      "Amazon Inspector",
      "AWS Shield Advanced",
      "AWS Config",
      "Amazon GuardDuty",
      "Amazon EC2"
    ],
    "SelectA": "모든 EC2 인스턴스를 관리하기 위해 AWS Systems Manager Patch Manager를 설정합니다. AWS Security Hub를 구성하여 월간 보고서를 생성합니다.",
    "SelectA_Commentary": "Security Hub는 보안 모범 사례 점검과 알림 집계를 제공하지만, 개별 인스턴스의 취약점 식별에 특화된 Amazon Inspector만큼 상세한 취약점 요약을 제공하지 않습니다.",
    "SelectB": "모든 EC2 인스턴스를 관리하기 위해 AWS Systems Manager Patch Manager를 설정합니다. Amazon Inspector를 배포하고 월간 보고서를 구성합니다.",
    "SelectB_Commentary": "운영체제 패치를 자동화하는 AWS Systems Manager Patch Manager와 취약점 스캔 및 리포트를 제공하는 Amazon Inspector를 결합한 최적의 선택지입니다. 자동 인벤토리와 취약점 정보를 모두 충족합니다.",
    "SelectC": "AWS Shield Advanced를 설정하고 월간 보고서를 구성합니다. AWS Config를 배포하여 EC2 인스턴스에 패치를 자동으로 설치합니다.",
    "SelectC_Commentary": "AWS Shield Advanced는 DDoS 방어만을 지원하며, 운영체제 취약점 스캔 기능이 없습니다. 또한 월간 취약점 요약 보고서를 제공하지 않습니다.",
    "SelectD": "해당 계정에 Amazon GuardDuty를 설정하여 모든 EC2 인스턴스를 모니터링합니다. AWS Config를 배포하여 EC2 인스턴스에 패치를 자동으로 설치합니다.",
    "SelectD_Commentary": "Amazon GuardDuty는 악성 활동 감지 서비스로, 운영체제 취약점 스캔 기능을 제공하지 않습니다. 월간 취약점 요약에도 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q480",
      "Q315",
      "Q100",
      "Q17",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q453",
      "Q612",
      "Q492"
    ],
    "SelectB_recommedations": [
      "Q492",
      "Q612",
      "Q682"
    ],
    "SelectC_recommedations": [
      "Q893",
      "Q492",
      "Q682"
    ],
    "SelectD_recommedations": [
      "Q682",
      "Q329",
      "Q453"
    ]
  },
  {
    "Question_Number": "Q874",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 Amazon EC2 Auto Scaling group에 속한 인스턴스에서 실행되며, Elastic Load Balancing(ELB) 뒤에 배치되어 있습니다. 애플리케이션은 Amazon DynamoDB 테이블에 연결됩니다. 재해 복구(DR) 목적으로, 회사는 다른 AWS Region에서도 최소한의 다운타임으로 애플리케이션 가용성을 보장하고 싶어 합니다. 다음 중 이러한 요구 사항을 가장 적은 다운타임으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137852-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 재해 발생 시 다른 Region으로 신속히 트래픽을 전환해 다운타임을 최소화하는 방법을 묻습니다. 이미 DR Region에 Auto Scaling group과 ELB를 구동하고 DynamoDB를 global table로 구성한다면 데이터 동기화와 서비스 전환이 빠르고 간단합니다. DNS failover를 통해 즉시 트래픽을 DR Region으로 넘길 수 있어 최소한의 다운타임을 보장합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "다운타임",
      "DR Region",
      "Auto Scaling group",
      "ELB",
      "Amazon DynamoDB",
      "global table",
      "DNS failover"
    ],
    "Terms": [
      "Auto Scaling group",
      "Elastic Load Balancing (ELB)",
      "Amazon DynamoDB",
      "global table",
      "DNS failover",
      "AWS CloudFormation template",
      "Amazon CloudWatch alarm",
      "AWS Lambda",
      "Amazon Route 53",
      "Amazon EC2"
    ],
    "SelectA": "DR Region에 Auto Scaling group과 ELB를 생성합니다. DynamoDB 테이블을 global table로 구성합니다. DNS failover를 구성하여 새로운 DR Region의 ELB를 가리키도록 합니다.",
    "SelectA_Commentary": "DR 환경이 사전에 준비되어 다운타임을 크게 줄이고, global table을 통해 데이터가 실시간 동기화되어 즉각적인 장애 대응이 가능합니다.",
    "SelectB": "AWS CloudFormation template을 생성하여 EC2 인스턴스, ELB, DynamoDB 테이블을 필요할 때 생성하도록 합니다. DNS failover를 구성하여 DR Region의 ELB를 가리키도록 합니다.",
    "SelectB_Commentary": "DR 시점에 인프라를 생성하므로 초기 프로비저닝 시간과 설정 시간이 필요해 다운타임이 길어질 수 있습니다.",
    "SelectC": "AWS CloudFormation template을 생성하여 EC2 인스턴스와 ELB를 필요할 때 생성하도록 합니다. DynamoDB 테이블은 global table로 구성합니다. DNS failover를 구성하여 DR Region의 ELB를 가리키도록 합니다.",
    "SelectC_Commentary": "EC2와 ELB를 DR 시점에 프로비저닝해야 하므로, 이미 global table이 있어도 준비 단계에서 추가 지연이 발생합니다.",
    "SelectD": "DR Region에 Auto Scaling group과 ELB를 생성합니다. DynamoDB 테이블을 global table로 구성합니다. Amazon CloudWatch alarm(평가 기간 10분)을 생성하여 AWS Lambda 함수를 호출하고, 이를 통해 Amazon Route 53을 DR Region의 ELB로 업데이트합니다.",
    "SelectD_Commentary": "알람 작동 통제 시간이 기본적으로 10분 이상 소요될 수 있어 다운타임이 길어질 위험이 있습니다.",
    "Question_Description_recommedations": [
      "Q209",
      "Q434",
      "Q944",
      "Q955",
      "Q537"
    ],
    "SelectA_recommedations": [
      "Q874",
      "Q585",
      "Q955"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q585",
      "Q955"
    ],
    "SelectC_recommedations": [
      "Q874",
      "Q955",
      "Q585"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q955",
      "Q585"
    ]
  },
  {
    "Question_Number": "Q875",
    "Question_Description": "한 회사가 Private Subnet에 있는 Amazon EC2 인스턴스에서 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Amazon S3 버킷에 데이터를 저장하고 조회해야 합니다. 규정에 따라, 해당 데이터가 Public Internet을 통해 전송되어서는 안 됩니다. 가장 비용 효율적인 방식으로 이 요구 사항을 충족하려면 어떻게 해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138140-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Private Subnet의 EC2 인스턴스가 S3에 안전하면서도 비용 효율적으로 접근하도록 설계하는 방법을 묻습니다. NAT Gateway나 Interface Endpoint는 추가 비용이 발생하거나 운영 부담이 더 큽니다. 반면, S3 Gateway Endpoint를 사용하면 트래픽이 퍼블릭 인터넷을 통하지 않고, 서비스 자체도 무료로 사용 가능하므로 가장 비용 효율적이고 보안 요건을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "Private Subnet",
      "Amazon EC2",
      "Amazon S3",
      "규제 준수",
      "Public Internet 비통과",
      "비용 효율적"
    ],
    "Terms": [
      "NAT Gateway",
      "AWS Storage Gateway",
      "S3 Interface Endpoint",
      "S3 Gateway Endpoint"
    ],
    "SelectA": "NAT Gateway를 배포하여 S3 버킷에 접근합니다.",
    "SelectA_Commentary": "NAT Gateway는 퍼블릭 인터넷 경유 가능성과 추가 비용 문제로 가장 비용 효율적이지 않습니다.",
    "SelectB": "AWS Storage Gateway를 배포하여 S3 버킷에 접근합니다.",
    "SelectB_Commentary": "AWS Storage Gateway는 온프레미스와 S3를 연동할 때 주로 사용하며, 여기서는 과도하고 추가 비용이 발생합니다.",
    "SelectC": "S3 Interface Endpoint를 배포하여 S3 버킷에 접근합니다.",
    "SelectC_Commentary": "S3 Interface Endpoint 역시 ENI 비용이 계속 청구되어, 요구 사항 대비 비용 효율이 떨어집니다.",
    "SelectD": "S3 Gateway Endpoint를 배포하여 S3 버킷에 접근합니다.",
    "SelectD_Commentary": "S3 Gateway Endpoint는 무료이며 Public Internet을 통하지 않아 보안 요구 사항을 충족하고, 가장 비용 효율적입니다.",
    "Question_Description_recommedations": [
      "Q115",
      "Q251",
      "Q610",
      "Q92",
      "Q1011"
    ],
    "SelectA_recommedations": [
      "Q678",
      "Q965",
      "Q106"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q862",
      "Q678"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q965",
      "Q202"
    ],
    "SelectD_recommedations": [
      "Q965",
      "Q678",
      "Q106"
    ]
  },
  {
    "Question_Number": "Q876",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 애플리케이션을 단일 Availability Zone에서 운영 중입니다. 이 애플리케이션은 OSI(Open Systems Interconnection) 모델의 전송 계층을 통해 액세스할 수 있습니다. 회사는 애플리케이션 아키텍처가 고가용성을 갖추길 원합니다. 다음 중 어떤 조합의 단계가 가장 비용 효율적으로 이 요구 사항을 충족할 수 있겠습니까? (2개를 선택하십시오.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137849-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 단일 Availability Zone에서 애플리케이션을 운영할 때 발생하는 가용성 리스크를 해결하기 위한 방안입니다. 고가용성을 위해서는 여러 AZ에 걸친 EC2 인스턴스와 적절한 로드 밸런서를 사용해야 합니다. 특히 트랜스포트 계층 레벨에서 액세스하는 애플리케이션이므로 Network Load Balancer를 사용하고, Auto Scaling group으로 인스턴스를 관리함으로써 장애 시 자동으로 새 인스턴스를 제공하여 다운타임을 최소화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "단일 Availability Zone",
      "비용 효율",
      "Network Load Balancer",
      "Auto Scaling group"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "Transport layer",
      "OSI model",
      "Amazon Route 53",
      "Network Load Balancer",
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon CloudWatch alarm"
    ],
    "SelectA": "새로운 EC2 인스턴스를 다른 Availability Zone에 구성합니다. Amazon Route 53을 사용하여 모든 인스턴스로 트래픽을 라우팅합니다.",
    "SelectA_Commentary": "Route 53을 이용해 도메인 이름을 라우팅할 수 있지만, 단순히 DNS만으로는 전송 계층을 효과적으로 로드 밸런싱하기 어렵고, 높은 가용성을 위해서는 로드 밸런서와 Auto Scaling이 추가로 필요합니다.",
    "SelectB": "EC2 인스턴스 앞단에 Network Load Balancer를 구성합니다.",
    "SelectB_Commentary": "Network Load Balancer는 전송 계층(TCP/UDP) 레벨에서 작동하며, 다양한 포트에서의 트래픽 처리가 가능해 이 문제에 적합합니다. 비용 효율적이며 고성능 로드 밸런싱을 제공합니다.",
    "SelectC": "인스턴스에 대한 TCP 트래픽을 위해 Network Load Balancer를 구성합니다. HTTP와 HTTPS 트래픽을 위해 Application Load Balancer를 구성합니다.",
    "SelectC_Commentary": "HTTP/HTTPS가 아닌 전송 계층으로 액세스할 경우 굳이 ALB를 함께 구성할 필요가 없어 복잡도와 비용이 증가합니다.",
    "SelectD": "EC2 인스턴스를 위한 Auto Scaling group을 생성합니다. Auto Scaling group을 여러 Availability Zone에서 동작하도록 구성합니다. 인스턴스에 대한 애플리케이션 헬스 체크를 수행하도록 설정합니다.",
    "SelectD_Commentary": "Auto Scaling group을 여러 AZ에 걸쳐 구성하면 특정 AZ 장애 시 다른 AZ에서 인스턴스가 대체되어 고가용성을 확보할 수 있습니다.",
    "SelectE": "Amazon CloudWatch alarm을 생성하고, 중지(stopped) 상태로 전환된 EC2 인스턴스를 재시작하도록 설정합니다.",
    "SelectE_Commentary": "인스턴스가 중지되었을 때 재시작하는 작업만으로는 다중 AZ 장애 대비나 자동 확장 기능을 제공하지 못해 고가용성 확보에 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q691",
      "Q639",
      "Q987",
      "Q570",
      "Q47"
    ],
    "SelectA_recommedations": [
      "Q47",
      "Q987",
      "Q570"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q357",
      "Q275"
    ],
    "SelectC_recommedations": [
      "Q545",
      "Q537",
      "Q357"
    ],
    "SelectD_recommedations": [
      "Q691",
      "Q595",
      "Q729"
    ],
    "SelectE_recommedations": [
      "Q923",
      "Q194",
      "Q584"
    ]
  },
  {
    "Question_Number": "Q877",
    "Question_Description": "한 회사가 Amazon S3를 이용해 정적 웹사이트를 호스팅하고 있습니다. 회사는 웹페이지에 Contact Form을 추가하여, 사용자가 이름, 이메일, 전화번호, 문의 내용을 입력할 수 있는 동적인 서버 측 컴포넌트를 구현하고자 합니다. 이 웹사이트의 월 방문 횟수는 100회 미만으로 예상되며, 문의 양식 작성 시 회사가 이메일 알림을 받을 수 있어야 합니다. 어떤 솔루션이 가장 비용 효율적으로 이러한 요구사항을 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139252-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 소규모 트래픽(월 100회 미만) 환경에서 동적인 Contact Form을 구현하고, 이메일 알림을 제공하는 가장 비용 효율적인 솔루션을 찾는 것입니다. 서버리스 구조를 활용하는 API Gateway + Lambda + SNS 조합은 사용량 기반 과금으로 필요 시점에만 비용이 발생하여 매우 경제적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "정적 웹사이트",
      "Contact Form",
      "비용 효율",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon SNS"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon Simple Email Service (Amazon SES)",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon Simple Notification Service (Amazon SNS)",
      "AWS Amplify Hosting",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon EC2",
      "Windows Server",
      "Internet Information Services (IIS)",
      "Amazon WorkMail"
    ],
    "SelectA": "Amazon Elastic Container Service(Amazon ECS)에 Contact Form을 호스팅하고, Amazon Simple Email Service(Amazon SES)를 이용해 서드파티 이메일 제공자와 연동합니다.",
    "SelectA_Commentary": "ECS는 클러스터 운영 비용이 추가되고 서버 유지가 복잡해, 매우 적은 트래픽 요구사항에 비해 과도하게 비용이 들 수 있습니다.",
    "SelectB": "Amazon API Gateway 엔드포인트를 생성하여 AWS Lambda 함수로 Contact Form을 반환합니다. 다른 Lambda 함수를 통해 API Gateway에서 Amazon Simple Notification Service(SNS) 토픽으로 메시지를 발행하도록 구성합니다.",
    "SelectB_Commentary": "서버리스 구조만 활용하므로 사용량이 적을 때 비용이 거의 발생하지 않아, 요구사항에 가장 비용 효율적인 솔루션입니다.",
    "SelectC": "정적 및 동적 콘텐츠를 AWS Amplify Hosting으로 호스팅하고, 서버 측 스크립팅을 활용해 Contact Form을 구성합니다. Amazon Simple Queue Service(SQS)를 통해 회사에 메시지를 전달합니다.",
    "SelectC_Commentary": "SQS만으로는 이메일 전송 기능이 없어 추가 구성이 필요하고, Amplify를 통한 서버 사이드 구현이 오버 엔지니어링이 될 수 있습니다.",
    "SelectD": "Amazon S3에서 Amazon EC2 Windows Server 인스턴스로 웹사이트를 마이그레이션하고, IIS(Internet Information Services)로 웹페이지를 호스팅합니다. 클라이언트 측 스크립팅으로 Contact Form을 구축하고, Amazon WorkMail과 연동합니다.",
    "SelectD_Commentary": "Windows Server 인스턴스 상시 운영으로 비용이 크고, 매우 적은 방문자 수에는 서버리스 대안 대비 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q285",
      "Q1003",
      "Q911",
      "Q606",
      "Q551"
    ],
    "SelectA_recommedations": [
      "Q300",
      "Q877",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q770",
      "Q877",
      "Q140"
    ],
    "SelectC_recommedations": [
      "Q300",
      "Q316",
      "Q167"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q877",
      "Q719"
    ]
  },
  {
    "Question_Number": "Q878",
    "Question_Description": "한 회사가 각 비즈니스 유닛을 위해 AWS Organizations에서 전용 AWS Account를 생성했습니다. 최근에 중요한 알림이 할당된 계정 소유자가 아닌 비즈니스 유닛 계정의 root user 이메일 주소로 전송되는 문제가 발생했습니다. 회사는 청구(billing), 운영(operations), 보안(security)의 알림 카테고리에 따라 다른 직원들에게 향후 모든 알림을 보낼 수 있도록 하길 원합니다. 이러한 요구사항을 가장 안전하게 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139746-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS Account에서 root user 관련 알림이 잘못 전송되는 위험을 줄이고, 청구·운영·보안 알림을 분류하여 적절한 담당자에게 안내하기 위해 어떻게 설정해야 하는지 묻습니다. 각 Account의 root user 이메일을 중앙으로 통합하고, alternate contacts를 별도의 배포 리스트로 설정함으로써 중요한 정보가 올바른 담당자에게 안전하게 전달되도록 구성하는 것이 핵심입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "root user",
      "AWS Organizations",
      "알림 카테고리",
      "billing",
      "operations",
      "security",
      "alternate contacts"
    ],
    "Terms": [
      "root user",
      "AWS Organizations",
      "alternate contacts",
      "email distribution list",
      "billing",
      "operations",
      "security",
      "email alias"
    ],
    "SelectA": "각 AWS Account가 공용 이메일 주소를 사용하도록 설정하고, 모든 계정 소유자가 해당 이메일 계정에 접근하도록 합니다. 그리고 각 AWS Account에 대해 alternate contacts를 설정하여, 해당 비즈니스 유닛의 billing, security, operations 팀 배포 리스트를 연결합니다.",
    "SelectA_Commentary": "공통 이메일을 사용하면 누가 어떤 알림을 받는지 구분하기 어렵고, root user 이메일이 안전하게 보호되지 않을 위험이 있습니다.",
    "SelectB": "각 AWS Account가 서로 다른 이메일 배포 리스트를 사용하도록 설정하고, 관리자 이메일 주소를 포함해 알림에 응답할 수 있도록 구성합니다. 이후 각 AWS Account에 대해 billing, security, operations 팀 배포 리스트를 alternate contacts로 설정합니다.",
    "SelectB_Commentary": "비즈니스 유닛별로 별도의 배포 리스트를 여러 개 운영하면 관리 오버헤드가 증가하고, root user 이메일의 안전한 보호와는 직접적으로 연결되지 않습니다.",
    "SelectC": "각 AWS Account root user 이메일 주소를 각 비즈니스 유닛 직원 한 명의 개인 회사 이메일로 설정합니다. 이후 billing, security, operations 팀 배포 리스트를 alternate contacts로 구성합니다.",
    "SelectC_Commentary": "특정 직원 개인 이메일 사용은 직원 퇴사·담당 변경 시 문제가 되며, root user 접근 권한이 개인에게 귀속돼 보안 취약점이 생길 수 있습니다.",
    "SelectD": "각 AWS Account root user에 이메일 alias를 설정하여 중앙화된 메일박스로 전달되도록 구성합니다. 그리고 각 AWS Account마다 billing, security, operations 팀용 배포 리스트를 alternate contacts로 설정합니다.",
    "SelectD_Commentary": "root user 이메일을 중앙에서 관리하므로 보안 리스크를 줄이고, 카테고리별로 설정된 alternate contacts를 통해 알림이 적절한 팀에 전달되어 가장 안전하고 효율적인 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q488",
      "Q137",
      "Q745",
      "Q945",
      "Q233"
    ],
    "SelectA_recommedations": [
      "Q780",
      "Q233",
      "Q745"
    ],
    "SelectB_recommedations": [
      "Q780",
      "Q233",
      "Q745"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q745",
      "Q878"
    ],
    "SelectD_recommedations": [
      "Q745",
      "Q233",
      "Q878"
    ]
  },
  {
    "Question_Number": "Q879",
    "Question_Description": "한 회사가 AWS에서 전자상거래 애플리케이션을 운영하고 있습니다. Amazon EC2 인스턴스가 구매를 처리하고, Amazon Aurora PostgreSQL DB cluster에 구매 내역을 저장합니다. 고객들은 사용량이 많은 피크 타임에 애플리케이션 타임아웃을 겪고 있습니다. 솔루션스 아키텍트는 애플리케이션을 다시 설계하여 피크 사용 수요를 충족할 수 있도록 확장성을 확보하면서 비용 효율성을 극대화하려고 합니다. 다음 중 어느 조합의 조치가 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? (두 가지를 선택)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139619-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션이 피크 사용량에서 타임아웃을 일으키므로, 처리를 분산하고 데이터베이스 연결을 효율화해 병목을 완화해야 한다는 점이 핵심입니다. 각 단계별로 확장이 가능하고 느슨하게 결합된 구조를 도입함으로써, 특히 DB 연결 과부하 및 요청 폭주에 대응하도록 설계해야 합니다. Amazon SQS를 통한 비동기 처리와 RDS Proxy를 통한 연결 풀링이 가장 대표적인 해결책입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "전자상거래 애플리케이션",
      "피크 타임",
      "애플리케이션 타임아웃",
      "확장성",
      "비용 효율"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Aurora PostgreSQL",
      "DB cluster",
      "Amazon RDS Proxy",
      "Amazon ElastiCache",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon API Gateway",
      "Auto Scaling group"
    ],
    "SelectA": "새로운 EC2 인스턴스의 Auto Scaling group을 구성하여 구매 처리를 재시도합니다. 애플리케이션이 Amazon RDS Proxy를 통해 DB cluster에 연결하도록 업데이트합니다.",
    "SelectA_Commentary": "Amazon RDS Proxy로 DB 연결을 효율화하고, Auto Scaling group으로 서버를 자동 확장해 피크 시점에도 안정적인 처리를 보장하는 방법입니다.",
    "SelectB": "애플리케이션이 Aurora PostgreSQL DB cluster 앞에 Amazon ElastiCache cluster를 사용하도록 구성합니다.",
    "SelectB_Commentary": "ElastiCache는 주로 읽기 부하를 줄이기 위한 캐싱 솔루션이지만, 현재 상황은 트랜잭션 요청 폭주로 인한 타임아웃 문제여서 직접적인 해결책이 되기 어렵습니다.",
    "SelectC": "애플리케이션을 업데이트하여 구매 요청을 Amazon SQS 큐로 전송하도록 합니다. SQS 큐를 처리하도록 새로운 EC2 인스턴스의 Auto Scaling group을 구성합니다.",
    "SelectC_Commentary": "SQS를 사용해 요청을 비동기 처리가 가능하도록 분리하면 과부하를 완화할 수 있습니다. Auto Scaling group과 연계해 수요에 맞춰 쉽게 확장할 수 있어 비용 효율적입니다.",
    "SelectD": "AWS Lambda 함수를 구성하여 티켓 구매를 재시도하도록 합니다.",
    "SelectD_Commentary": "Lambda 단독으로 구매 처리를 무한 재시도하는 구조는 과도한 호출 비용과 실행 시간 제약이 있어 대규모 트랜잭션 처리에는 적합하지 않습니다.",
    "SelectE": "Amazon API Gateway REST API에 사용량 계획(usage plan)을 구성합니다.",
    "SelectE_Commentary": "API Gateway 사용량 계획만으로는 애플리케이션의 확장 이슈를 직접 해결하기 어렵습니다. 트래픽 제한 정책이기는 하나, 백엔드 타임아웃을 완화하는 근본 대책이 되진 않습니다.",
    "Question_Description_recommedations": [
      "Q944",
      "Q790",
      "Q654",
      "Q114",
      "Q236"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q390",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q879",
      "Q955",
      "Q69"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q581",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q785",
      "Q8",
      "Q363"
    ],
    "SelectE_recommedations": [
      "Q10",
      "Q354",
      "Q75"
    ]
  },
  {
    "Question_Number": "Q880",
    "Question_Description": "한 회사가 AWS Organizations를 사용하여 30개의 서로 다른 AWS 계정에서 150개의 애플리케이션을 운영하고 있습니다. 이 회사는 관리 계정에서 AWS Cost and Usage Report를 사용해 새 리포트를 생성했고, Amazon S3 버킷으로 전달된 이 리포트는 데이터 수집용 계정에 있는 버킷으로 복제됩니다. 현재 달의 시작 시점부터 매일의 NAT gateway 비용을 보여주는 커스텀 대시보드를 경영진이 확인하길 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137926-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "NAT gateway 비용 모니터링을 위해서는 S3에 저장된 Cost and Usage Report를 분석한 후, 경영진이 손쉽게 볼 수 있는 대시보드를 제공해야 합니다. Amazon QuickSight는 시각화 기능이 뛰어나므로 경영진이 원하는 대시보드를 쉽게 공유할 수 있으며, Amazon Athena와 연동하면 S3의 보고서를 빠르고 간편하게 쿼리하여 원하는 비용 정보를 획득할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "NAT gateway 비용",
      "커스텀 대시보드",
      "AWS Cost and Usage Report",
      "Amazon QuickSight",
      "Amazon Athena",
      "Amazon CloudWatch",
      "AWS DataSync",
      "S3 버킷"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS Cost and Usage Report",
      "Amazon S3",
      "AWS DataSync",
      "Amazon Athena",
      "Amazon QuickSight",
      "Amazon CloudWatch",
      "NAT gateway"
    ],
    "SelectA": "Amazon QuickSight 대시보드를 공유하고, AWS DataSync로 새 리포트를 쿼리하도록 QuickSight를 구성합니다.",
    "SelectA_Commentary": "AWS DataSync는 주로 대용량 데이터를 S3로 전송하거나 동기화할 때 쓰이므로, 이미 S3에 있는 리포트를 분석하기에는 적합하지 않습니다.",
    "SelectB": "Amazon QuickSight 대시보드를 공유하고, Amazon Athena로 새 리포트를 쿼리하도록 QuickSight를 구성합니다.",
    "SelectB_Commentary": "Amazon Athena를 사용하면 S3에 있는 Cost and Usage Report를 손쉽게 분석할 수 있고, QuickSight로 시각화하여 경영진이 원하는 일자별 NAT gateway 비용을 바로 확인할 수 있습니다.",
    "SelectC": "Amazon CloudWatch 대시보드를 공유하고, AWS DataSync로 새 리포트를 쿼리하도록 CloudWatch를 구성합니다.",
    "SelectC_Commentary": "CloudWatch를 활용해도 데이터를 시각화할 수 있지만, NAT gateway 비용 분석용 사용자 정의 대시보드로는 QuickSight가 더 최적이며 DataSync는 이 경우 불필요한 단계입니다.",
    "SelectD": "Amazon CloudWatch 대시보드를 공유하고, Amazon Athena로 새 리포트를 쿼리하도록 CloudWatch를 구성합니다.",
    "SelectD_Commentary": "CloudWatch 대시보드는 주로 지표 및 로그 모니터링용으로 사용됩니다. 비용 분석과 시각화에는 QuickSight와 Athena의 조합이 훨씬 적합합니다.",
    "Question_Description_recommedations": [
      "Q641",
      "Q497",
      "Q455",
      "Q459",
      "Q559"
    ],
    "SelectA_recommedations": [
      "Q485",
      "Q943",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q485",
      "Q728",
      "Q284"
    ],
    "SelectC_recommedations": [
      "Q486",
      "Q485",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q485",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q881",
    "Question_Description": "한 회사가 Amazon S3로 고트래픽 정적 웹사이트를 호스팅하고 있으며, Amazon CloudFront 배포의 기본 TTL이 0초로 설정되어 있습니다. 회사는 웹사이트 성능 향상을 위해 캐싱을 구현하길 원하지만, 신규 배포 후 몇 분 이상 오랜 시간 동안 구 버전 콘텐츠가 제공되지 않도록 해야 합니다. 이러한 요구사항을 충족하기 위해 Solutions Architect는 어떤 캐싱 방법 조합을 구현해야 합니까? (2개를 선택하세요.)",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/137850-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "CloudFront에서 적절한 TTL을 설정하고, 새 배포 시 Invalidation을 통해 변경된 파일을 신속히 갱신하는 것이 핵심입니다. 각 객체에 Cache-Control max-age 지시자를 두고, 기본 TTL을 몇 분 정도로 설정하면 캐싱 효과와 최신 콘텐츠 제공을 균형 있게 달성할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "기본 TTL",
      "캐싱",
      "오래된(구) 콘텐츠 방지",
      "Amazon S3",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon CloudFront distribution",
      "TTL",
      "Cache-Control",
      "Expires",
      "Lambda@Edge",
      "Invalidation"
    ],
    "SelectA": "CloudFront 기본 TTL을 2분으로 설정합니다.",
    "SelectA_Commentary": "CloudFront의 기본 TTL을 짧게(2분) 설정하면 신규 배포 후 구버전 콘텐츠가 장시간 캐싱되지 않으면서도 적절한 캐싱 효과를 얻을 수 있습니다.",
    "SelectB": "S3 버킷에 기본 TTL을 2분으로 설정합니다.",
    "SelectB_Commentary": "S3 버킷 자체에는 직접 TTL을 설정할 수 없으며, 필요한 캐싱 정책은 CloudFront나 각 객체의 Cache-Control 헤더를 통해 제어해야 하므로 적절하지 않습니다.",
    "SelectC": "Amazon S3의 객체에 Cache-Control private 지시자를 추가합니다.",
    "SelectC_Commentary": "private 지시자는 공유 캐시가 아닌 브라우저 내부 캐시에만 적용되어, CloudFront와 같은 CDN 환경에서 효과적인 캐싱을 활용하기 어렵습니다.",
    "SelectD": "AWS Lambda@Edge 함수를 생성하여 HTTP 응답에 Expires 헤더를 추가하고, viewer response 이벤트에서 실행하도록 구성합니다.",
    "SelectD_Commentary": "Lambda@Edge를 통한 동적 헤더 조작은 가능하지만, 요구사항을 단순히 해결하기에는 과도한 접근이며, 더 간단한 Cache-Control 및 CloudFront 설정이 가능합니다.",
    "SelectE": "S3 객체에 Cache-Control max-age=24 hours 지시자를 추가하고, 배포 시 수정된 파일에 대해 CloudFront invalidation을 생성하여 엣지 캐시를 지웁니다.",
    "SelectE_Commentary": "사전 설정된 긴 캐싱 기간을 사용하되, 배포 시 Invalidation을 통해 변경된 파일을 빠르게 업데이트하여 캐싱 효과와 최신 콘텐츠 제공을 모두 만족시킵니다.",
    "Question_Description_recommedations": [
      "Q280",
      "Q38",
      "Q155",
      "Q173",
      "Q547"
    ],
    "SelectA_recommedations": [
      "Q865",
      "Q352",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q352",
      "Q1015"
    ],
    "SelectC_recommedations": [
      "Q501",
      "Q626",
      "Q243"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q361"
    ],
    "SelectE_recommedations": [
      "Q280",
      "Q501",
      "Q38"
    ]
  },
  {
    "Question_Number": "Q882",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스와 AWS Lambda 함수를 사용하여 애플리케이션을 운영하고 있습니다. EC2 인스턴스들은 VPC의 private subnet에서 실행되고 있습니다. Lambda 함수들은 애플리케이션이 정상적으로 동작하기 위해 EC2 인스턴스에 직접 네트워크로 접근해야 합니다. 애플리케이션은 1년 동안 실행될 예정이며, 1년 동안 사용되는 Lambda 함수의 수는 계속 증가할 예정입니다. 회사는 모든 애플리케이션 리소스에 대해 비용을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/138489-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스와 Lambda 함수를 동시에 사용하면서 1년간 운용 시 전체 컴퓨팅 비용을 최소화하는 방안을 묻습니다. EC2 Instance Savings Plan은 EC2에만 할인 혜택이 적용되지만, Lambda의 사용량이 늘어나면 Lambda 비용까지 커버할 수 없습니다. Compute Savings Plan은 EC2와 Lambda 모두를 할인 대상에 포함하므로 장기적으로 비용을 가장 효과적으로 절감합니다. 또한 Lambda 함수는 EC2 인스턴스가 위치한 private subnet에 배치되어야 직접 네트워크 통신이 가능합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "AWS Lambda 함수",
      "private subnet",
      "1년 운영",
      "Compute Savings Plan"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "VPC",
      "private subnet",
      "public subnet",
      "EC2 Instance Savings Plan",
      "Compute Savings Plan"
    ],
    "SelectA": "EC2 Instance Savings Plan을 구매합니다. Lambda 함수들을 EC2 인스턴스가 포함된 private subnet에 연결합니다.",
    "SelectA_Commentary": "EC2 인스턴스에 대한 비용은 절약 가능하지만, Lambda 비용 절감 효율이 떨어져 요구사항에 적합하지 않습니다.",
    "SelectB": "EC2 Instance Savings Plan을 구매합니다. Lambda 함수들을 동일 VPC의 새로운 public subnet에 연결합니다.",
    "SelectB_Commentary": "Lambda가 public subnet에 연결되면 EC2 인스턴스와 직접 통신을 위해 추가 설정이 필요하고, Lambda 비용에도 할인이 적용되지 않습니다.",
    "SelectC": "Compute Savings Plan을 구매합니다. Lambda 함수들을 EC2 인스턴스가 포함된 private subnet에 연결합니다.",
    "SelectC_Commentary": "EC2와 Lambda 모두 할인 적용이 가능하며, private subnet에서 직접 통신이 가능해 보안과 비용을 모두 충족하는 최적의 솔루션입니다.",
    "SelectD": "Compute Savings Plan을 구매합니다. Lambda 함수들을 Lambda service VPC에 그대로 둡니다.",
    "SelectD_Commentary": "Lambda service VPC에 두면 EC2 인스턴스에 대한 직접 네트워크 접근이 어려워지고, 추가 구성이 필요하므로 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q417",
      "Q770",
      "Q860",
      "Q140",
      "Q800"
    ],
    "SelectA_recommedations": [
      "Q882",
      "Q417",
      "Q860"
    ],
    "SelectB_recommedations": [
      "Q882",
      "Q417",
      "Q860"
    ],
    "SelectC_recommedations": [
      "Q882",
      "Q715",
      "Q417"
    ],
    "SelectD_recommedations": [
      "Q715",
      "Q885",
      "Q467"
    ]
  },
  {
    "Question_Number": "Q883",
    "Question_Description": "한 회사가 AWS Control Tower를 사용하여 멀티 계정 전략을 배포했습니다. 회사는 각 개발자에게 개별 AWS 계정을 제공했습니다. 회사는 개발자들이 사용하는 AWS 리소스 비용을 제한할 수 있는 통제를 구현하고자 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139799-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 개발자 계정에서 AWS 리소스 비용이 쌓이는 것을 최소한의 운영 오버헤드로 제어하려면, 사용자가 예산을 초과하는 시점에 자동으로 리소스 생성을 제한하는 기능이 필요합니다. AWS Budgets는 알림과 함께 정책을 적용할 수 있어, 예산 기준을 초과하면 추가 리소스 생성을 방지할 수 있습니다. 이는 관리 수준이 간단하면서도 강력하게 비용을 제어할 수 있는 방법입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "리소스 비용 제한",
      "운영 오버헤드 최소화",
      "AWS Control Tower",
      "개발자별 계정",
      "비용 통제"
    ],
    "Terms": [
      "AWS Control Tower",
      "AWS Budgets",
      "IAM Role",
      "AWS Lambda",
      "DenyAll Policy",
      "AWS Service Catalog",
      "AWS Config",
      "AWS Cost Explorer",
      "AWS Cost Anomaly Detection"
    ],
    "SelectA": "각 개발자 리소스에 CostCenter 태그(key=CostCenter, value=개발자 이름)를 지정하도록 하고, AWS Config 규칙(required-tags)을 설정합니다. 태그가 없는 리소스는 AWS Lambda로 종료하며, AWS Cost Explorer로 일일 보고서를 보냅니다.",
    "SelectA_Commentary": "태그 누락 시 자동 종료 방식은 어느 정도 비용 통제가 가능하지만, 모든 리소스에 태그를 강제하고 Lambda 함수를 운영하는 추가 관리가 필요해 오버헤드가 큽니다.",
    "SelectB": "각 개발자 계정에 대해 AWS Budgets를 사용해 예산을 설정합니다. 실제 비용과 예측 비용을 기준으로 경고를 보내 예산 한도를 초과하거나 예상 초과 시 통지합니다. 예산에 도달하면 DenyAll 정책을 개발자의 IAM Role에 적용합니다.",
    "SelectB_Commentary": "AWS Budgets는 예산 초과 시 자동으로 정책을 적용해 추가 리소스 생성을 막을 수 있어, 중앙에서 간단하게 비용 통제를 구현할 수 있는 최적의 솔루션입니다.",
    "SelectC": "AWS Cost Explorer로 각 개발자 계정의 비용을 모니터링하고 보고서를 생성해 일일 보고서를 발송합니다. AWS Cost Anomaly Detection으로 비정상적 지출을 감지해 알림을 제공합니다.",
    "SelectC_Commentary": "비용 모니터링과 알림만으로는 자동 제어가 어려워, 예산 초과 시 즉시 막기가 힘들고 추가 관리 작업이 필요합니다.",
    "SelectD": "AWS Service Catalog를 사용해 개발자들이 제한된 비용 범위 내에서 리소스를 실행하도록 허용합니다. 각 AWS 계정에 AWS Lambda 함수를 생성해 매일 업무 종료 시점에 리소스를 중지하고, 업무 시작 시점에 재개합니다.",
    "SelectD_Commentary": "리소스 동작 시간을 제한해 비용을 줄일 수 있지만, Service Catalog 구성과 Lambda 스케줄 관리 등 운영 작업이 증가해 오버헤드가 높습니다.",
    "Question_Description_recommedations": [
      "Q284",
      "Q728",
      "Q541",
      "Q525",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q31",
      "Q485",
      "Q943"
    ],
    "SelectB_recommedations": [
      "Q455",
      "Q284",
      "Q541"
    ],
    "SelectC_recommedations": [
      "Q641",
      "Q459",
      "Q715"
    ],
    "SelectD_recommedations": [
      "Q770",
      "Q807",
      "Q238"
    ]
  },
  {
    "Question_Number": "Q884",
    "Question_Description": "한 솔루션스 아키텍트가 인터넷 연결 Application Load Balancer(ALB)와, 프라이빗 서브넷에 있는 Amazon EC2 인스턴스로 구성된 웹 계층, 그리고 비즈니스 로직이 동작하는 애플리케이션 계층(EC2, 프라이빗 서브넷), Microsoft SQL Server 기반의 데이터베이스 계층(EC2, 프라이빗 서브넷)을 포함하는 3티어 웹 애플리케이션을 설계하고 있습니다. 회사는 보안을 최우선 순위로 두고 있습니다. 어떤 보안 그룹 구성을 조합해야 할까요? (3개를 선택하세요.)",
    "Answer": "A,C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139800-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 3티어 웹 애플리케이션에서 각 계층이 안전하게 통신하도록 보안 그룹을 어떻게 설정해야 하는지 묻습니다. Security Group은 상태 저장이므로, 필요한 Inbound 규칙만 제대로 구성하면 Outbound는 자동으로 허용됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "3티어 아키텍처",
      "보안 그룹",
      "프라이빗 서브넷",
      "Microsoft SQL Server",
      "HTTPS"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Private Subnet",
      "Security Group",
      "Microsoft SQL Server",
      "Inbound Rule",
      "Stateful"
    ],
    "SelectA": "웹 계층 보안 그룹에서 ALB 보안 그룹으로부터의 HTTPS Inbound를 허용합니다.",
    "SelectA_Commentary": "ALB에서 웹 계층으로 들어오는 HTTPS 트래픽을 반드시 열어야 하므로 필요합니다.",
    "SelectB": "웹 계층 보안 그룹에서 0.0.0.0/0로의 HTTPS Outbound를 허용합니다.",
    "SelectB_Commentary": "Outboud 트래픽은 기본적으로 허용되므로 별도의 설정이 꼭 필요하지 않습니다.",
    "SelectC": "데이터베이스 계층 보안 그룹에 애플리케이션 계층 보안 그룹으로부터의 Microsoft SQL Server Inbound를 허용합니다.",
    "SelectC_Commentary": "애플리케이션 계층이 DB에 연결하려면 MS SQL 포트(1433) 등의 Inbound가 필요합니다.",
    "SelectD": "데이터베이스 계층 보안 그룹에서 웹 계층 보안 그룹으로의 HTTPS 및 Microsoft SQL Server Outbound를 허용합니다.",
    "SelectD_Commentary": "DB → 웹 계층으로 직접 통신할 필요가 없으므로 불필요합니다.",
    "SelectE": "애플리케이션 계층 보안 그룹에 웹 계층 보안 그룹으로부터의 HTTPS Inbound를 허용합니다.",
    "SelectE_Commentary": "웹 계층에서 애플리케이션 계층으로 HTTPS 트래픽을 허용해야 하므로 필요합니다.",
    "SelectF": "애플리케이션 계층 보안 그룹에서 웹 계층 보안 그룹으로의 HTTPS 및 Microsoft SQL Server Outbound를 허용합니다.",
    "SelectF_Commentary": "애플리케이션 계층에서 웹 계층으로의 트래픽이 필요치 않아 불필요한 설정입니다.",
    "Question_Description_recommedations": [
      "Q707",
      "Q170",
      "Q234",
      "Q382",
      "Q927"
    ],
    "SelectA_recommedations": [
      "Q60",
      "Q169",
      "Q855"
    ],
    "SelectB_recommedations": [
      "Q265",
      "Q855",
      "Q774"
    ],
    "SelectC_recommedations": [
      "Q901",
      "Q898",
      "Q831"
    ],
    "SelectD_recommedations": [
      "Q901",
      "Q855",
      "Q172"
    ],
    "SelectE_recommedations": [
      "Q265",
      "Q855",
      "Q172"
    ],
    "SelectF_recommedations": [
      "Q901",
      "Q855",
      "Q172"
    ]
  },
  {
    "Question_Number": "Q885",
    "Question_Description": "어떤 회사가 프로덕션 애플리케이션의 새 버전을 출시했습니다. 이 회사의 워크로드는 Amazon EC2, AWS Lambda, AWS Fargate, Amazon SageMaker를 사용합니다. 현재 사용량이 안정된 상태로 접어들면서, 비용 최적화를 진행하려고 합니다. 가장 적은 수의 Savings Plans로 최대한 많은 서비스를 커버하고자 할 때, 다음 중 이러한 요구 사항을 충족하는 Savings Plans 조합은 무엇입니까? (2개를 선택하십시오.)",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139801-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 동일한 Savings Plans로 최대한 많은 서비스를 커버하여 비용을 절감하는 전략을 묻습니다. Compute Savings Plan은 Amazon EC2, AWS Lambda, AWS Fargate를 모두 지원하고, Amazon SageMaker 사용량은 별도의 SageMaker Savings Plan으로 커버하여 가장 적은 플랜으로 최대 서비스를 커버할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 최적화",
      "Savings Plans",
      "Amazon EC2",
      "AWS Lambda",
      "AWS Fargate",
      "Amazon SageMaker",
      "EC2 Instance Savings Plan",
      "Compute Savings Plan",
      "SageMaker Savings Plan"
    ],
    "Terms": [
      "EC2 Instance Savings Plan",
      "Compute Savings Plan",
      "SageMaker Savings Plan",
      "AWS Lambda",
      "Amazon EC2",
      "AWS Fargate",
      "Amazon SageMaker"
    ],
    "SelectA": "Amazon EC2와 Amazon SageMaker에 대해 EC2 Instance Savings Plan을 구매합니다.",
    "SelectA_Commentary": "EC2와 SageMaker만 커버되어 Lambda, Fargate 비용 절감을 놓치므로 요구 사항 충족이 어렵습니다.",
    "SelectB": "Amazon EC2, Lambda, SageMaker에 대해 Compute Savings Plan을 구매합니다.",
    "SelectB_Commentary": "Compute Savings Plan은 EC2, Lambda, Fargate를 대상으로 하며 SageMaker는 별도 플랜이 필요하므로 단독으로는 부족합니다.",
    "SelectC": "SageMaker Savings Plan을 구매합니다.",
    "SelectC_Commentary": "SageMaker 워크로드 비용을 절감할 수 있는 별도 플랜으로, Compute Savings Plan과 함께 사용해야 요구 사항을 맞출 수 있습니다.",
    "SelectD": "Lambda, Fargate, EC2에 대해 Compute Savings Plan을 구매합니다.",
    "SelectD_Commentary": "Compute Savings Plan은 EC2, Lambda, Fargate를 모두 커버하므로 필수적인 선택지입니다.",
    "SelectE": "Amazon EC2와 Fargate에 대해 EC2 Instance Savings Plan을 구매합니다.",
    "SelectE_Commentary": "EC2와 Fargate 일부를 커버하지만, Lambda와 SageMaker를 포함하지 않아 요구 사항에 부적합합니다.",
    "Question_Description_recommedations": [
      "Q715",
      "Q543",
      "Q140",
      "Q467",
      "Q541"
    ],
    "SelectA_recommedations": [
      "Q885",
      "Q543",
      "Q715"
    ],
    "SelectB_recommedations": [
      "Q885",
      "Q715",
      "Q543"
    ],
    "SelectC_recommedations": [
      "Q885",
      "Q997",
      "Q630"
    ],
    "SelectD_recommedations": [
      "Q715",
      "Q885",
      "Q543"
    ],
    "SelectE_recommedations": [
      "Q715",
      "Q926",
      "Q885"
    ]
  },
  {
    "Question_Number": "Q886",
    "Question_Description": "한 회사는 Microsoft SQL Server 데이터베이스를 사용하고 있으며, 회사의 애플리케이션들은 이 데이터베이스에 연결되어 있습니다. 회사는 애플리케이션 코드의 변경을 최소화하여 Amazon Aurora PostgreSQL 데이터베이스로 마이그레이션하고자 합니다. 이러한 요구사항을 충족하는 단계 조합은 무엇입니까? (두 가지를 선택하세요.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139802-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Microsoft SQL Server에서 Amazon Aurora PostgreSQL로 애플리케이션 코드를 거의 수정하지 않고 마이그레이션하는 방법을 묻습니다. Babelfish를 사용하면 SQL Server용으로 작성된 쿼리를 수정 없이 실행할 수 있고, AWS SCT와 AWS DMS를 통해 스키마와 데이터를 손쉽게 이전할 수 있습니다. 이를 통해 마이그레이션 과정에서 애플리케이션 변경을 최소화할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Microsoft SQL Server",
      "애플리케이션 코드 최소 변경",
      "Amazon Aurora PostgreSQL",
      "Babelfish",
      "AWS SCT",
      "AWS DMS"
    ],
    "Terms": [
      "Microsoft SQL Server",
      "Amazon Aurora PostgreSQL",
      "Babelfish",
      "AWS Schema Conversion Tool (AWS SCT)",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon RDS Proxy"
    ],
    "SelectA": "Use the AWS Schema Conversion Tool (AWS SCT) to rewrite the SQL queries in the applications.",
    "SelectA_Commentary": "애플리케이션 내 쿼리를 직접 재작성해야 하므로 변경 범위가 커집니다. 최소 변경 요구사항을 만족하지 못하므로 오답입니다.",
    "SelectB": "Enable Babelfish on Aurora PostgreSQL to run the SQL queries from the applications.",
    "SelectB_Commentary": "Babelfish는 SQL Server용으로 작성된 애플리케이션 쿼리를 그대로 실행하도록 지원하므로 애플리케이션 변경을 최소화할 수 있어 정답입니다.",
    "SelectC": "Migrate the database schema and data by using the AWS Schema Conversion Tool (AWS SCT) and AWS Database Migration Service (AWS DMS).",
    "SelectC_Commentary": "스키마와 데이터를 자동으로 변환·마이그레이션해 주므로 Aurora PostgreSQL로 쉽게 이전할 수 있어 정답입니다.",
    "SelectD": "Use Amazon RDS Proxy to connect the applications to Aurora PostgreSQL.",
    "SelectD_Commentary": "Amazon RDS Proxy는 데이터베이스 연결 관리에 도움을 주지만 SQL Server 쿼리 호환성 문제를 해결하지 못하므로 오답입니다.",
    "SelectE": "Use AWS Database Migration Service (AWS DMS) to rewrite the SQL queries in the applications.",
    "SelectE_Commentary": "AWS DMS는 데이터 마이그레이션 도구이며, 애플리케이션 쿼리를 재작성해 주는 기능은 제공하지 않으므로 오답입니다.",
    "Question_Description_recommedations": [
      "Q235",
      "Q554",
      "Q565",
      "Q287",
      "Q650"
    ],
    "SelectA_recommedations": [
      "Q317",
      "Q886",
      "Q292"
    ],
    "SelectB_recommedations": [
      "Q886",
      "Q235",
      "Q175"
    ],
    "SelectC_recommedations": [
      "Q386",
      "Q314",
      "Q886"
    ],
    "SelectD_recommedations": [
      "Q886",
      "Q771",
      "Q386"
    ],
    "SelectE_recommedations": [
      "Q386",
      "Q886",
      "Q314"
    ]
  },
  {
    "Question_Number": "Q887",
    "Question_Description": "한 회사가 Amazon EBS를 attached storage로 사용하는 Amazon EC2 인스턴스로 애플리케이션을 재호스팅(rehost)할 계획입니다. 솔루션스 아키텍트는 새로 생성되는 모든 Amazon EBS 볼륨이 기본적으로 암호화되도록 구성해야 합니다. 또한 암호화되지 않은 EBS 볼륨을 생성하지 못하도록 방지해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/140296-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 새로 생성되는 EBS 볼륨을 자동으로 암호화하고, 암호화되지 않은 볼륨이 생성되지 못하도록 제어하는 방안을 묻습니다. EC2 Account Attributes를 이용해 기본 암호화를 설정하면 운영 단순성과 보안을 모두 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "EBS 볼륨",
      "기본 암호화",
      "EC2 인스턴스",
      "암호화되지 않은 볼륨 방지"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "EC2 account attributes",
      "AWS Config",
      "AWS Key Management Service (AWS KMS)",
      "AWS Systems Manager",
      "AWS Migration Hub"
    ],
    "SelectA": "EC2 account attributes를 구성하여 항상 새로운 EBS 볼륨을 암호화하도록 설정합니다.",
    "SelectA_Commentary": "정답입니다. 리전별로 EC2 계정 속성에서 기본 EBS 암호화를 활성화하면 모든 새 볼륨이 자동으로 암호화되고, 암호화되지 않은 볼륨 생성을 효과적으로 차단할 수 있습니다.",
    "SelectB": "AWS Config를 사용합니다. encrypted-volumes 식별자를 구성하고 기본 AWS KMS 키를 적용합니다.",
    "SelectB_Commentary": "AWS Config로 리소스를 모니터링할 수 있지만, 기본 암호화 정책을 강제해 자동으로 암호화되지 않은 볼륨 생성을 막기는 어렵습니다.",
    "SelectC": "AWS Systems Manager를 구성하여 EBS 볼륨의 암호화된 복사본을 만들고, EC2 인스턴스를 재구성하여 암호화된 볼륨을 사용하도록 합니다.",
    "SelectC_Commentary": "별도의 복사본을 생성해야 하며, 새 볼륨이 처음부터 암호화되는 것이 아니므로 운영 복잡도가 증가합니다.",
    "SelectD": "AWS KMS에서 고객 관리 키를 생성합니다. 회사가 워크로드를 마이그레이션할 때 AWS Migration Hub가 해당 키를 사용하도록 구성합니다.",
    "SelectD_Commentary": "Migration Hub 설정만으로는 새 EBS 볼륨 생성 시 기본 암호화를 강제할 수 없어 요구사항을 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q675",
      "Q410",
      "Q998",
      "Q710",
      "Q329"
    ],
    "SelectA_recommedations": [
      "Q689",
      "Q675",
      "Q453"
    ],
    "SelectB_recommedations": [
      "Q916",
      "Q681",
      "Q371"
    ],
    "SelectC_recommedations": [
      "Q681",
      "Q675",
      "Q723"
    ],
    "SelectD_recommedations": [
      "Q916",
      "Q550",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q888",
    "Question_Description": "한 전자상거래 회사가 웹사이트의 사용자 클릭스트림 데이터를 실시간 분석을 위해 수집하려고 합니다. 웹사이트 트래픽은 하루 동안 급격히 변동합니다. 회사는 이러한 변동하는 트래픽 수준에 탄력적으로 대응할 수 있는 확장 가능한 솔루션이 필요합니다. 어떤 솔루션이 이 요구 사항을 충족할까요?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139803-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 변동이 큰 웹 트래픽을 처리하면서 실시간으로 클릭스트림을 분석할 수 있는 고성능 스트리밍 아키텍처를 찾는 상황입니다. Amazon Kinesis Data Streams를 on-demand 모드로 사용하면 트래픽 변화에 따라 자동으로 확장되고, AWS Lambda를 통해 실시간 처리가 가능하여 운영 복잡성을 낮출 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "클릭스트림 데이터",
      "실시간 분석",
      "Amazon Kinesis Data Streams",
      "On-demand mode",
      "AWS Lambda"
    ],
    "Terms": [
      "Amazon Kinesis Data Streams",
      "On-demand mode",
      "AWS Lambda",
      "Amazon Kinesis Data Firehose",
      "AWS Glue",
      "Amazon Kinesis Video Streams",
      "Amazon Managed Service for Apache Flink",
      "Amazon Kinesis Data Analytics"
    ],
    "SelectA": "Amazon Kinesis Data Streams를 on-demand 모드로 사용하여 클릭스트림 데이터를 캡처하고, AWS Lambda를 통해 실시간으로 처리합니다.",
    "SelectA_Commentary": "Kinesis Data Streams on-demand 모드는 트래픽 변동에 자동 대응하고 Lambda로 실시간 처리가 가능해 요구사항에 가장 부합합니다.",
    "SelectB": "Amazon Kinesis Data Firehose로 클릭스트림 데이터를 캡처하고, AWS Glue로 실시간 처리를 수행합니다.",
    "SelectB_Commentary": "Glue는 배치 중심 ETL에 적합해 밀리초 단위 실시간 처리는 어려우며, Firehose 자체도 완전한 실시간 대응에 제약이 있습니다.",
    "SelectC": "Amazon Kinesis Video Streams로 클릭스트림 데이터를 캡처하고, AWS Glue로 실시간 처리를 수행합니다.",
    "SelectC_Commentary": "Video Streams는 비디오나 미디어 데이터 대상이며, 클릭스트림 텍스트 데이터 수집용 서비스로는 적절하지 않습니다.",
    "SelectD": "Amazon Managed Service for Apache Flink(Amazon Kinesis Data Analytics)로 클릭스트림 데이터를 캡처하고, AWS Lambda로 실시간 처리를 수행합니다.",
    "SelectD_Commentary": "Apache Flink는 실시간 스트리밍 분석 도구이지만, 직접 데이터 캡처보다는 Kinesis Data Streams와 연계 사용이 일반적이어서 적절도가 떨어집니다.",
    "Question_Description_recommedations": [
      "Q158",
      "Q132",
      "Q506",
      "Q915",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q603",
      "Q33"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q402",
      "Q557"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q402",
      "Q173"
    ],
    "SelectD_recommedations": [
      "Q305",
      "Q603",
      "Q515"
    ]
  },
  {
    "Question_Number": "Q889",
    "Question_Description": "한 글로벌 회사가 AWS에서 워크로드를 운영하고 있습니다. 회사의 애플리케이션은 민감한 데이터를 저장하고 분석하기 위해 여러 AWS Region의 Amazon S3 버킷을 사용하고 있습니다. 회사는 매일 여러 S3 버킷에 수백만 개의 객체를 저장합니다. 회사는 버저닝이 활성화되지 않은 모든 S3 버킷을 식별하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139804-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 버킷에 버저닝이 활성화되지 않은 상태를 손쉽게 파악하여 데이터 보호 모범사례를 준수하기 위한 요구사항입니다. 정답인 S3 Storage Lens는 여러 AWS Region에 걸쳐 버저닝 상태를 한눈에 확인하고 모범사례 미준수 버킷을 식별할 수 있어 가장 적합한 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "글로벌 회사",
      "민감한 데이터",
      "버저닝 미활성화",
      "S3 Storage Lens"
    ],
    "Terms": [
      "Amazon S3",
      "버저닝(Versioning)",
      "AWS CloudTrail",
      "S3 Storage Lens",
      "IAM Access Analyzer",
      "S3 Multi-Region Access Point"
    ],
    "SelectA": "AWS CloudTrail 이벤트를 설정해 버저닝이 활성화되지 않은 모든 S3 버킷을 식별하도록 규칙을 구성합니다.",
    "SelectA_Commentary": "CloudTrail은 API 호출 추적에는 유용하지만, 버저닝 상태 모니터링에 직접 특화되지 않아 요구사항을 온전히 충족하기 어렵습니다.",
    "SelectB": "Amazon S3 Storage Lens를 사용하여 여러 Region에 걸쳐 버저닝이 활성화되지 않은 모든 S3 버킷을 식별합니다.",
    "SelectB_Commentary": "S3 Storage Lens는 버킷별 버저닝 상태와 모범사례 위반 사항을 손쉽게 파악하도록 메트릭과 권장사항을 제공하므로 가장 적합합니다.",
    "SelectC": "IAM Access Analyzer for S3를 활성화해 여러 Region에 걸쳐 버저닝이 활성화되지 않은 모든 S3 버킷을 식별합니다.",
    "SelectC_Commentary": "IAM Access Analyzer는 주로 퍼블릭 엑세스 및 권한 분석용으로, 버저닝 활성화 여부 확인에는 적절하지 않습니다.",
    "SelectD": "S3 Multi-Region Access Point를 생성해 여러 Region에 걸쳐 버저닝이 활성화되지 않은 모든 S3 버킷을 식별합니다.",
    "SelectD_Commentary": "Multi-Region Access Point는 전역 액세스 단일 엔드포인트 제공에 중점을 둔 기능으로, 버저닝 미활성화 버킷 식별에 최적화되어 있지 않습니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q412",
      "Q134",
      "Q667",
      "Q109"
    ],
    "SelectA_recommedations": [
      "Q942",
      "Q862",
      "Q270"
    ],
    "SelectB_recommedations": [
      "Q889",
      "Q134",
      "Q667"
    ],
    "SelectC_recommedations": [
      "Q889",
      "Q868",
      "Q982"
    ],
    "SelectD_recommedations": [
      "Q889",
      "Q667",
      "Q868"
    ]
  },
  {
    "Question_Number": "Q890",
    "Question_Description": "한 회사에서는 재생할 수 없는 다수의 파일을 Amazon S3 Standard 스토리지에 저장하고 있으며, 각 파일의 크기는 약 5MB입니다. 이 파일들은 4년간 보관 후 삭제가 가능해야 하며, 즉시 액세스가 가능해야 합니다. 생성 후 30일 이내에는 자주 액세스되지만, 30일 이후에는 드물게 액세스됩니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139805-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 4년 동안 삭제 불가능하고 즉시 조회가 필요한 객체를 가장 저렴하게 보관하는 방안을 찾는 것입니다. S3 Glacier Instant Retrieval은 S3 Standard-IA 대비 저렴하면서도 밀리초 단위로 액세스가 가능해 즉각 조회 요구 사항을 충족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "파일 즉시 액세스",
      "S3 스토리지 비용 최적화",
      "4년 보관",
      "드문 액세스",
      "S3 Glacier Instant Retrieval",
      "S3 Standard-IA"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Lifecycle policy",
      "S3 Glacier Instant Retrieval",
      "S3 One Zone-IA",
      "S3 Standard-IA",
      "S3 Glacier Flexible Retrieval"
    ],
    "SelectA": "객체 생성 후 30일 뒤에 S3 Glacier Instant Retrieval로 전환하고, 객체 생성 후 4년 뒤에 삭제하도록 S3 Lifecycle policy를 구성합니다.",
    "SelectA_Commentary": "S3 Glacier Instant Retrieval을 사용하면 낮은 스토리지 요금과 즉각적인 액세스를 모두 만족하며, 4년 이후에는 삭제하여 비용을 더욱 절감할 수 있습니다.",
    "SelectB": "객체 생성 후 30일 뒤에 S3 One Zone-Infrequent Access (S3 One Zone-IA)로 전환하고, 객체 생성 후 4년 뒤에 삭제하도록 S3 Lifecycle policy를 구성합니다.",
    "SelectB_Commentary": "One Zone-IA는 단일 AZ만 사용하기 때문에 재생할 수 없는 데이터를 안정적으로 보관하기엔 위험이 높으며, 다중 AZ 보호가 필수입니다.",
    "SelectC": "객체 생성 후 30일 뒤에 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환하고, 객체 생성 후 4년 뒤에 삭제하도록 S3 Lifecycle policy를 구성합니다.",
    "SelectC_Commentary": "Standard-IA는 즉시 액세스 요구 사항에 맞지만, Glacier Instant Retrieval보다 스토리지 비용이 더 높아 최적의 비용 효율을 달성하지 못합니다.",
    "SelectD": "객체 생성 후 30일 뒤에 S3 Standard-Infrequent Access (S3 Standard-IA)로 전환하고, 객체 생성 후 4년 뒤에 S3 Glacier Flexible Retrieval로 전환하도록 S3 Lifecycle policy를 구성합니다.",
    "SelectD_Commentary": "4년 후에는 데이터를 삭제할 수 있으므로 Glacier Flexible Retrieval로 옮기는 추가 단계가 불필요하며, 즉시 액세스도 보장되지 않습니다.",
    "Question_Description_recommedations": [
      "Q153",
      "Q126",
      "Q759",
      "Q66",
      "Q606"
    ],
    "SelectA_recommedations": [
      "Q606",
      "Q356",
      "Q285"
    ],
    "SelectB_recommedations": [
      "Q356",
      "Q415",
      "Q606"
    ],
    "SelectC_recommedations": [
      "Q356",
      "Q415",
      "Q890"
    ],
    "SelectD_recommedations": [
      "Q356",
      "Q415",
      "Q890"
    ]
  },
  {
    "Question_Number": "Q891",
    "Question_Description": "한 회사는 중요한 스토리지 애플리케이션을 AWS Cloud에서 운영하고 있습니다. 이 애플리케이션은 서로 다른 두 개의 AWS Region에 걸쳐 Amazon S3를 사용합니다. 이 회사는 원격 사용자 데이터를 퍼블릭 네트워크 혼잡 없이 가장 가까운 S3 버킷으로 전송하길 원합니다. 또한 Amazon S3 관리 부담을 최소화하면서 장애 조치(fail over)가 가능하기를 바랍니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139744-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 다중 Region에서 S3를 사용하는 애플리케이션이 원격 데이터를 가장 가까운 버킷으로 전송하고, 장애 시 최소한의 관리로 신속히 장애 조치하기 위한 구성을 묻습니다. S3 Multi-Region Access Points를 active-active로 설정하면 글로벌 엔드포인트에서 자동으로 가까운 리전으로 라우팅되고, S3 Cross-Region Replication을 통해 버킷들을 동기화하여 관리 부담 없이 높은 가용성과 성능을 제공할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "멀티 리전 액세스 포인트",
      "액티브-액티브 구성",
      "장애 조치",
      "퍼블릭 네트워크 혼잡 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "AWS Region",
      "S3 Multi-Region Access Points(MRAP)",
      "S3 Cross-Region Replication(CRR)",
      "Active-Active Configuration",
      "Active-Passive Configuration",
      "cross-account replication"
    ],
    "SelectA": "두 개의 Region 간에 active-active 구성을 구현합니다. 애플리케이션이 사용자에게 가장 가까운 해당 리전의 S3 엔드포인트를 사용하도록 구성합니다.",
    "SelectA_Commentary": "Multi-Region Access Points 없이 운영하면, 최적의 자동 라우팅이 불가능하고 관리가 복잡해집니다.",
    "SelectB": "S3 Multi-Region Access Points를 사용하여 active-passive 구성을 구성합니다. 각 Region마다 글로벌 엔드포인트를 생성합니다.",
    "SelectB_Commentary": "active-passive 구성으로선 사용자 트래픽 자동 라우팅이 제한적이며, Region별 글로벌 엔드포인트 관리가 번거롭습니다.",
    "SelectC": "사용자에게 가장 가까운 리전의 S3 엔드포인트로 사용자 데이터를 전송합니다. S3 cross-account replication 규칙을 구성하여 S3 버킷을 동기화 상태로 유지합니다.",
    "SelectC_Commentary": "cross-account replication만으로 다중 Region 트래픽 라우팅을 자동화하기 어렵고, 동기화 관리 부담이 큽니다.",
    "SelectD": "하나의 글로벌 엔드포인트를 사용해 Amazon S3에서 Multi-Region Access Points를 active-active 구성으로 설정합니다. S3 Cross-Region Replication을 구성합니다.",
    "SelectD_Commentary": "Multi-Region Access Points를 active-active로 설정하면, 트래픽을 자동 라우팅하고 CRR로 동기화를 보장해 최소한의 관리로 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q224",
      "Q636",
      "Q241",
      "Q585",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q8",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q68",
      "Q700",
      "Q891"
    ],
    "SelectC_recommedations": [
      "Q188",
      "Q891",
      "Q784"
    ],
    "SelectD_recommedations": [
      "Q891",
      "Q68",
      "Q700"
    ]
  },
  {
    "Question_Number": "Q892",
    "Question_Description": "한 회사가 온프레미스 위치에서 AWS로 데이터 센터를 마이그레이션하고 있습니다. 회사에는 개별 가상 서버에 호스팅되는 여러 레거시 애플리케이션이 있으며, 이 애플리케이션들의 설계를 변경할 수 없습니다. 현재 각각의 가상 서버는 자체 EC2 인스턴스로 실행되고 있습니다. 솔루션스 아키텍트는 AWS로 마이그레이션 후 애플리케이션의 안정성과 내결함성을 보장해야 하며, 애플리케이션은 Amazon EC2 인스턴스에서 구동될 예정입니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "레거시 애플리케이션을 변경할 수 없는 상황에서 승인된 방식으로 EC2 인스턴스를 자동 복구하고 고가용성을 확보해야 합니다. Auto Scaling group으로 인스턴스 장애 시 재생성하는 방식이 핵심 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "데이터 센터 마이그레이션",
      "레거시 애플리케이션",
      "Amazon EC2",
      "안정성",
      "내결함성"
    ],
    "Terms": [
      "On-premises",
      "EC2 instance",
      "Auto Scaling group",
      "Amazon Machine Image (AMI)",
      "Application Load Balancer",
      "AWS Backup",
      "Amazon S3",
      "Availability Zone",
      "Network Load Balancer",
      "AWS Mitigation Hub Refactor Spaces",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate"
    ],
    "SelectA": "하나의 Auto Scaling group을 최소 1, 최대 1로 구성합니다. 각 애플리케이션 인스턴스의 Amazon Machine Image(AMI)를 생성하여 Auto Scaling group에서 EC2 인스턴스를 실행하고, Application Load Balancer를 앞단에 구성합니다.",
    "SelectA_Commentary": "단일 인스턴스 상태를 유지하면서 장애가 발생하면 Auto Scaling group이 자동으로 동일한 AMI로 새 인스턴스를 생성해 내결함성을 보장하므로 요구 사항을 충족합니다.",
    "SelectB": "각 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 AWS Backup으로 매시간 백업을 생성하고, 다른 Availability Zone의 Amazon S3에 저장합니다. 가장 최근 백업에서 복원하는 재해 복구 프로세스를 구성합니다.",
    "SelectB_Commentary": "단순 백업 방식은 EC2 인스턴스 장애 발생 시 실제 복원까지 추가 작업이 필요해 자동화와 신속 복구 측면에서 한계가 있습니다.",
    "SelectC": "각 애플리케이션 인스턴스의 Amazon Machine Image(AMI)를 생성합니다. 해당 AMI로 새 EC2 인스턴스 두 개를 실행하고, 각각을 별도의 Availability Zone에 배치합니다. 두 인스턴스를 대상으로 하는 Network Load Balancer를 구성합니다.",
    "SelectC_Commentary": "두 인스턴스를 동시에 구동하는 활성-활성 구성은 애플리케이션 변경이 불가한 상황에서 세션 동기화나 데이터 일관성 문제가 발생할 수 있습니다.",
    "SelectD": "AWS Mitigation Hub Refactor Spaces를 사용해 각 애플리케이션을 EC2 인스턴스에서 마이그레이션합니다. 애플리케이션 기능을 개별 컴포넌트로 분해하고 AWS Fargate 유형의 Amazon Elastic Container Service(Amazon ECS)에 호스팅합니다.",
    "SelectD_Commentary": "레거시 애플리케이션 구조 자체를 리팩터링해야 하므로, 설계 변경이 불가능하다는 전제 조건에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q790",
      "Q194",
      "Q757",
      "Q244",
      "Q584"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q275",
      "Q595"
    ],
    "SelectB_recommedations": [
      "Q224",
      "Q47",
      "Q312"
    ],
    "SelectC_recommedations": [
      "Q762",
      "Q639",
      "Q275"
    ],
    "SelectD_recommedations": [
      "Q224",
      "Q842",
      "Q900"
    ]
  },
  {
    "Question_Number": "Q893",
    "Question_Description": "한 회사가 각 워크로드별로 AWS 계정을 생성하여 워크로드를 격리하고자 합니다. 또한 중앙에서 네트워킹 구성 요소를 관리해야 하며, 계정을 자동 보안 제어(가드레일)와 함께 생성할 수 있어야 합니다. 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139745-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 계정을 안전하고 간편하게 생성·관리하기 위한 방법을 묻습니다. Guardrails와 같은 자동 보안 통제가 필요한 경우 AWS Control Tower가 적합하며, 중앙 네트워킹과 계정 간 자원 공유에는 별도 네트워킹 계정과 AWS RAM 활용이 가장 효율적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "워크로드 격리",
      "중앙 네트워킹",
      "자동 보안 제어",
      "운영 오버헤드 최소화",
      "AWS Control Tower",
      "AWS Organizations"
    ],
    "Terms": [
      "AWS Control Tower",
      "Guardrails",
      "AWS Organizations",
      "AWS Resource Access Manager (AWS RAM)",
      "VPC",
      "Subnets",
      "Transit Gateway Attachment"
    ],
    "SelectA": "AWS Control Tower를 사용해 계정을 배포합니다. VPC 내에 퍼블릭 및 프라이빗 서브넷을 가진 네트워킹 전용 계정을 생성하고, AWS Resource Access Manager(AWS RAM)으로 각 워크로드 계정에 서브넷을 공유합니다.",
    "SelectA_Commentary": "AWS Control Tower로 생성 시 가드레일이 자동 적용되며, 네트워킹 계정을 통해 서브넷을 공유해 중앙서 관리가 가능합니다. 운영 부담이 가장 적은 방법입니다.",
    "SelectB": "AWS Organizations를 사용해 계정을 배포합니다. VPC 내에 퍼블릭 및 프라이빗 서브넷을 가진 네트워킹 전용 계정을 생성하고, AWS Resource Access Manager(AWS RAM)으로 각 워크로드 계정에 서브넷을 공유합니다.",
    "SelectB_Commentary": "Organizations만으로는 자동 보안 통제(가드레일)를 제공하지 않으므로, 별도 구성이나 정책 설정이 필요해 운영 오버헤드가 더 커집니다.",
    "SelectC": "AWS Control Tower를 사용해 계정을 배포합니다. 각 워크로드 계정에 VPC를 배포하고, Transit Gateway Attachment를 사용해 검사(Inspection) VPC를 경유하도록 라우팅을 구성합니다.",
    "SelectC_Commentary": "계정별 VPC를 관리해야 하며, 검사 VPC와 Transit Gateway 구성이 복잡해집니다. 중앙 집중적인 네트워크 관리 목적에 비해 오버헤드가 큽니다.",
    "SelectD": "AWS Organizations를 사용해 계정을 배포합니다. 각 워크로드 계정에 VPC를 배포하고, Transit Gateway Attachment를 사용해 검사(Inspection) VPC를 경유하도록 라우팅을 구성합니다.",
    "SelectD_Commentary": "이 방식도 가드레일이 자동 적용되지 않고, VPC를 계정별로 배포·운영해야 하므로 복잡성이 늘어납니다.",
    "Question_Description_recommedations": [
      "Q592",
      "Q922",
      "Q313",
      "Q831",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q688",
      "Q15",
      "Q950"
    ],
    "SelectB_recommedations": [
      "Q688",
      "Q945",
      "Q168"
    ],
    "SelectC_recommedations": [
      "Q688",
      "Q15",
      "Q151"
    ],
    "SelectD_recommedations": [
      "Q945",
      "Q168",
      "Q135"
    ]
  },
  {
    "Question_Number": "Q894",
    "Question_Description": "한 회사에서 Application Load Balancer (ALB) 뒤에 있는 Amazon EC2 인스턴스에서 웹사이트를 호스팅하고 있습니다. 이 웹사이트는 정적 콘텐츠를 제공하며, 증가하는 방문 트래픽으로 인해 웹사이트 호스팅 비용을 최소화하고 싶어 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139860-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 정적 웹사이트를 EC2 대신 Amazon S3와 Amazon CloudFront로 옮겨 호스팅 비용을 대폭 절감하는 방법을 묻습니다. S3는 정적 파일 호스팅에 적합하며 CloudFront를 통해 전 세계 사용자에게 빠르고 안정적으로 콘텐츠를 제공할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "정적 콘텐츠",
      "비용 최소화",
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon S3",
      "Amazon CloudFront"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer (ALB)",
      "Amazon S3",
      "Amazon CloudFront",
      "Amazon ElastiCache",
      "AWS Amplify"
    ],
    "SelectA": "웹사이트를 Amazon S3 버킷으로 이전합니다. Amazon CloudFront distribution을 S3 버킷에 구성합니다.",
    "SelectA_Commentary": "S3와 CloudFront를 결합하면 EC2 대신 정적 콘텐츠를 저비용에 고성능으로 제공할 수 있어 요구사항을 가장 효과적으로 충족합니다.",
    "SelectB": "웹사이트를 Amazon S3 버킷으로 이전합니다. Amazon ElastiCache cluster를 S3 버킷에 구성합니다.",
    "SelectB_Commentary": "ElastiCache는 인메모리 캐싱 서비스로, 정적 콘텐츠 호스팅 비용 절감에 직접적 이점이 적어 부적합합니다.",
    "SelectC": "웹사이트를 AWS Amplify로 이전합니다. Application Load Balancer가 Amplify 웹사이트를 resolve하도록 구성합니다.",
    "SelectC_Commentary": "Amplify는 프런트엔드 배포에 유용하지만, 현재 ALB를 그대로 사용하는 것은 비용 최소화 효과가 크지 않습니다.",
    "SelectD": "웹사이트를 AWS Amplify로 이전합니다. EC2 인스턴스에서 웹사이트를 캐싱하도록 구성합니다.",
    "SelectD_Commentary": "Amplify로 호스팅하면서 EC2에서 캐싱하는 방식은 불필요한 컴퓨팅 리소스를 사용하므로 비용 절감에 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q473",
      "Q245",
      "Q984",
      "Q146",
      "Q441"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q911",
      "Q1003"
    ],
    "SelectB_recommedations": [
      "Q993",
      "Q552",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q473",
      "Q146",
      "Q894"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q238",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q895",
    "Question_Description": "한 회사가 AWS에서 호스팅하는 미디어 애플리케이션을 위해 공유 스토리지 솔루션을 구현하려고 합니다. 회사는 SMB 클라이언트를 사용하여 저장된 데이터에 액세스할 수 있어야 합니다. 이 요구사항을 가장 적은 관리 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139861-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 SMB 프로토콜을 활용해야 하는 Windows 기반 파일 공유 환경에서 운영 부담을 최소화하려는 시나리오입니다. Amazon FSx for Windows File Server는 SMB를 기본 지원하고 완전관리형으로 제공되어 별도의 서버 설치 및 유지 관리가 필요 없고, 확장성과 성능이 우수하므로 정답으로 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "공유 스토리지",
      "미디어 애플리케이션",
      "SMB 클라이언트",
      "관리 오버헤드 최소화",
      "Amazon FSx for Windows File Server"
    ],
    "Terms": [
      "AWS Storage Gateway",
      "Volume Gateway",
      "Tape Gateway",
      "SMB 클라이언트",
      "Amazon EC2",
      "Windows File Share",
      "Amazon FSx for Windows File Server"
    ],
    "SelectA": "AWS Storage Gateway Volume Gateway를 생성하고, 필요한 클라이언트 프로토콜로 파일 공유를 만든 다음 애플리케이션 서버를 연결합니다.",
    "SelectA_Commentary": "Volume Gateway는 iSCSI 프로토콜 중점으로 SMB 지원에 적합하지 않으며, 관리 부담도 비교적 큰 편입니다.",
    "SelectB": "AWS Storage Gateway Tape Gateway를 생성하고, Amazon S3를 사용하는 테이프를 구성한 후 애플리케이션 서버를 Tape Gateway에 연결합니다.",
    "SelectB_Commentary": "Tape Gateway는 백업 및 아카이빙 목적에 최적화되어 있어 SMB 기반 데이터 액세스 용도로는 부적합합니다.",
    "SelectC": "Amazon EC2 Windows 인스턴스를 생성한 뒤 Windows file share 기능을 설치 및 구성하고, 애플리케이션 서버를 연결합니다.",
    "SelectC_Commentary": "Windows 인스턴스 운영, 보안 패치 등 관리 작업이 필요해 운영 부담이 높아집니다.",
    "SelectD": "Amazon FSx for Windows File Server 파일 시스템을 생성하고, 애플리케이션 서버를 해당 파일 시스템에 연결합니다.",
    "SelectD_Commentary": "SMB 프로토콜을 기본 지원하며, 완전관리형이므로 운영과 유지 보수 부담이 가장 적은 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q249",
      "Q361",
      "Q443",
      "Q747",
      "Q155"
    ],
    "SelectA_recommedations": [
      "Q957",
      "Q361",
      "Q597"
    ],
    "SelectB_recommedations": [
      "Q155",
      "Q38",
      "Q173"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q369",
      "Q283"
    ],
    "SelectD_recommedations": [
      "Q301",
      "Q361",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q896",
    "Question_Description": "한 회사가 프로덕션 애플리케이션의 재해 복구(DR) 전략을 설계하고 있습니다. 애플리케이션은 us-east-1 리전에 위치한 Amazon Aurora 클러스터의 MySQL 데이터베이스를 사용하고 있습니다. 회사는 DR 리전으로 us-west-1 리전을 선택했습니다. 목표 RPO는 5분, 목표 RTO는 20분이며, 구성 변경을 최소화하고자 합니다. 가장 운영 효율성이 높은 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139809-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Aurora MySQL 기반 애플리케이션을 다중 리전으로 구성하여 짧은 복구 목표치를 달성하고, 구성 변경을 최소화하는 방법을 묻습니다. Aurora Global Database를 사용하면 낮은 RPO와 RTO를 만족하면서 운영 효율을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DR 전략",
      "Aurora Global Database",
      "RPO 5분",
      "RTO 20분",
      "구성 변경 최소화"
    ],
    "Terms": [
      "Amazon Aurora",
      "Aurora MySQL",
      "Aurora cluster",
      "RPO",
      "RTO",
      "Aurora read replica",
      "Aurora Global Database",
      "Cross-Region Replication",
      "AWS Database Migration Service (AWS DMS)",
      "Region"
    ],
    "SelectA": "us-west-1 리전에 프로덕션 Aurora MySQL 클러스터의 writer 인스턴스와 유사한 크기의 Aurora read replica를 생성합니다.",
    "SelectA_Commentary": "리드 리플리카를 사용하는 방법은 DR 가능하지만, 자동 페일오버 구성이 복잡해 추가적인 운영 부담이 있고 RPO/RTO 보장이 까다롭습니다.",
    "SelectB": "Aurora 클러스터를 Aurora Global Database로 변환하고 관리형 페일오버를 구성합니다.",
    "SelectB_Commentary": "Aurora Global Database는 여러 리전에 걸쳐 데이터를 빠르게 동기화하고 자동 페일오버를 지원해 가장 낮은 운영 부담으로 목표 RPO/RTO를 충족시킵니다.",
    "SelectC": "us-west-1 리전에 새 Aurora 클러스터를 생성하고 Cross-Region Replication을 구성합니다.",
    "SelectC_Commentary": "Cross-Region Replication은 직접 설정과 모니터링이 필요해 운영이 복잡하며, 관리형 페일오버에 비해 RPO/RTO 보장이 용이하지 않습니다.",
    "SelectD": "us-west-1 리전에 새로운 Aurora 클러스터를 생성하고 AWS DMS를 사용해 두 클러스터를 동기화합니다.",
    "SelectD_Commentary": "AWS DMS는 실시간 동기화가 가능하지만, 별도의 설정 및 작업이 필요해 Aurora Global Database 대비 구성과 운영이 복잡합니다.",
    "Question_Description_recommedations": [
      "Q71",
      "Q343",
      "Q539",
      "Q955",
      "Q273"
    ],
    "SelectA_recommedations": [
      "Q755",
      "Q896",
      "Q526"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q363",
      "Q149"
    ],
    "SelectC_recommedations": [
      "Q896",
      "Q621",
      "Q570"
    ],
    "SelectD_recommedations": [
      "Q896",
      "Q621",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q897",
    "Question_Description": "한 회사가 매주 업무 시작 전 critical data analysis 작업을 실행합니다. 이 작업은 최소 1시간이 걸리며, 상태를 유지해야 하므로 중단을 허용할 수 없습니다. 이 작업을 AWS에서 실행하려고 할 때, 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/140209-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 최소 1시간 동안 중단 없이 실행되어야 하는 상태 유지를 필요로 하는 일괄 작업을 어떤 서비스로 운영할지 묻습니다. AWS Lambda는 시간 제한(15분)이 있고, EC2 Spot Instances는 언제든 중단될 수 있어 적합하지 않습니다. DataSync는 파일 이동·동기화 용도이므로 작업 실행에 부적합합니다. 반면, AWS Fargate를 통한 Amazon ECS 작업은 충분한 실행 시간과 중단 없이 안정적으로 수행 가능하며, Amazon EventBridge Scheduler를 통해 정기적으로 작업을 예약 실행할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "critical data analysis 작업",
      "1시간 이상 처리 시간",
      "중단 불가",
      "AWS Fargate",
      "Amazon ECS",
      "Amazon EventBridge Scheduler"
    ],
    "Terms": [
      "AWS Fargate",
      "Amazon ECS",
      "Amazon EventBridge Scheduler",
      "AWS Lambda",
      "Amazon EventBridge",
      "Auto Scaling group",
      "Amazon EC2 Spot Instances",
      "Amazon Linux",
      "AWS DataSync",
      "cron expression"
    ],
    "SelectA": "작업을 위한 container를 생성하고, Amazon EventBridge Scheduler를 사용하여 Amazon ECS(AWS Fargate) 클러스터에서 작업을 스케줄링합니다.",
    "SelectA_Commentary": "Fargate 기반 Amazon ECS 작업은 중단 없이 오랜 시간 실행 가능하며, EventBridge Scheduler로 간편하게 예약 가능합니다.",
    "SelectB": "AWS Lambda 함수를 구성하고, Amazon EventBridge에서 스케줄링 규칙을 생성하여 Lambda 함수를 호출합니다.",
    "SelectB_Commentary": "Lambda는 최대 15분으로 실행 시간이 제한되어 있어 1시간 이상 걸리는 작업을 처리할 수 없습니다.",
    "SelectC": "Amazon Linux를 실행하는 Amazon EC2 Spot Instances에 대한 Auto Scaling group을 구성하고, 인스턴스의 crontab에서 분석 작업을 실행합니다.",
    "SelectC_Commentary": "Spot Instance는 언제든 리소스 회수로 종료될 수 있어, 중단을 허용할 수 없는 작업에 적합하지 않습니다.",
    "SelectD": "AWS DataSync 작업을 구성하고, cron 표현식을 통해 스케줄에 따라 작업을 실행하도록 설정합니다.",
    "SelectD_Commentary": "DataSync는 데이터를 이동·복제하기 위한 서비스로, 장시간 상태 유지가 필요한 분석 작업 실행에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q8",
      "Q149",
      "Q363",
      "Q163"
    ],
    "SelectA_recommedations": [
      "Q900",
      "Q569",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q569",
      "Q785",
      "Q351"
    ],
    "SelectC_recommedations": [
      "Q660",
      "Q595",
      "Q581"
    ],
    "SelectD_recommedations": [
      "Q820",
      "Q8",
      "Q845"
    ]
  },
  {
    "Question_Number": "Q898",
    "Question_Description": "한 회사가 AWS Cloud에서 워크로드를 운영하고 있습니다. 이 회사는 전사 차원의 보안을 평가하고 워크로드 보호를 향상하기 위해 보안 데이터를 중앙에서 수집하고자 합니다. 개발 작업을 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139811-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전사적으로 보안 데이터를 중앙화하여 모니터링하고, 이를 통해 보안 상태를 한눈에 파악하며 워크로드 보호를 강화하는 방법을 묻습니다. 최소한의 개발 작업으로 자동화된 통합을 고려해야 합니다. Amazon Security Lake는 여러 AWS 서비스와의 통합을 통해 보안 이벤트를 자동으로 중앙화하고 분석하기 쉬운 형태로 관리하므로, 요구 사항을 가장 효율적으로 충족시킵니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "보안 데이터 중앙화",
      "워크로드 보호",
      "개발 작업 최소화",
      "Amazon Security Lake",
      "AWS Cloud"
    ],
    "Terms": [
      "AWS Lake Formation",
      "AWS Glue",
      "Amazon Security Lake",
      "AWS Lambda",
      "Amazon S3",
      "AWS Database Migration Service(AWS DMS)",
      "Amazon RDS"
    ],
    "SelectA": "AWS Lake Formation에서 데이터 레이크를 구성하고, AWS Glue 크롤러를 사용하여 보안 데이터를 데이터 레이크로 수집합니다.",
    "SelectA_Commentary": "AWS Lake Formation과 AWS Glue를 통한 접근 방식이지만, 보안 이벤트에 특화된 자동 중앙화 기능이 부족하여 추가 작업이 필요합니다.",
    "SelectB": "AWS Lambda 함수를 구성하여 보안 데이터를 .csv 형식으로 수집하고, Amazon S3 버킷에 업로드합니다.",
    "SelectB_Commentary": "Lambda 함수를 직접 작성하고 .csv 업로드 과정을 설계해야 하므로, 전사 규모로 자동화하고 통합하기엔 추가 개발 노력이 많이 듭니다.",
    "SelectC": "Amazon Security Lake에서 데이터 레이크를 구성하여 보안 데이터를 수집하고, 해당 데이터를 Amazon S3 버킷에 업로드합니다.",
    "SelectC_Commentary": "Amazon Security Lake는 AWS 환경 전반의 보안 이벤트를 자동으로 중앙화하여 살펴볼 수 있게 해주므로, 최소한의 개발 노력으로 요구 사항을 충족하는 가장 적절한 솔루션입니다.",
    "SelectD": "AWS Database Migration Service(AWS DMS) 복제 인스턴스를 구성하여 보안 데이터를 Amazon RDS 클러스터로 로드합니다.",
    "SelectD_Commentary": "AWS DMS는 주로 데이터베이스 간 이관에 적합하며, 보안 이벤트를 통합·분석할 수 있는 자동화된 기능을 제공하지 않아 적절하지 않습니다.",
    "Question_Description_recommedations": [
      "Q970",
      "Q529",
      "Q831",
      "Q313",
      "Q548"
    ],
    "SelectA_recommedations": [
      "Q442",
      "Q495",
      "Q609"
    ],
    "SelectB_recommedations": [
      "Q289",
      "Q936",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q965",
      "Q638",
      "Q825"
    ],
    "SelectD_recommedations": [
      "Q847",
      "Q330",
      "Q742"
    ]
  },
  {
    "Question_Number": "Q899",
    "Question_Description": "한 회사가 5개의 온프레미스 애플리케이션을 AWS Cloud의 VPC로 마이그레이션하려고 합니다. 현재 각 애플리케이션은 온프레미스에서 격리된 가상 네트워크에 배포되어 있으며, AWS Cloud에서도 동일하게 격리된 형태로 배포해야 합니다. 이 애플리케이션들은 shared services VPC에 연결해야 하며, 모든 애플리케이션들 간 상호 통신이 가능해야 합니다. 마이그레이션에 성공하면 동일한 작업을 100개 이상의 애플리케이션에 반복할 예정입니다. 가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/140211-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 많은 애플리케이션을 AWS Cloud로 마이그레이션할 때, 각 VPC를 독립적으로 유지하면서도 서로 및 shared services VPC와 쉽게 연결할 수 있는 방안을 찾는 것입니다. Transit Gateway를 사용하면 여러 VPC 간 라우팅을 단일 지점에서 관리할 수 있고, VPC 수가 늘어나더라도 운영 오버헤드를 최소화할 수 있습니다. 따라서 대규모 애플리케이션 마이그레이션 시에도 유연하고 확장성 있는 네트워크 구조를 손쉽게 구현할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "온프레미스 애플리케이션 마이그레이션",
      "VPC 격리",
      "shared services VPC",
      "상호 통신",
      "Transit Gateway"
    ],
    "Terms": [
      "VPC",
      "shared services VPC",
      "VPN tunnels",
      "VPC Peering",
      "AWS Direct Connect",
      "Transit Gateway"
    ],
    "SelectA": "application VPC들과 shared services VPC 간에 소프트웨어 VPN 터널을 배포합니다. application VPC들 서브넷에서 shared services VPC로 라우트를 추가합니다.",
    "SelectA_Commentary": "소프트웨어 VPN만으로 VPC 간 트래픽을 중계하면 설정과 관리가 복잡해집니다. VPC 및 애플리케이션 수가 늘어나면 VPN 터널 추가와 라우팅 관리 부담이 매우 커집니다.",
    "SelectB": "application VPC들과 shared services VPC 간에 VPC Peering 연결을 구성합니다. peering connection을 통해 application VPC들 서브넷에서 shared services VPC로 라우트를 추가합니다.",
    "SelectB_Commentary": "VPC Peering은 쌍방간 연결로 VPC가 늘어날수록 관리해야 할 피어링 연결이 급증합니다. 결국 규모가 커질수록 네트워크 관리가 복잡해집니다.",
    "SelectC": "application VPC들과 shared services VPC 간에 AWS Direct Connect 연결을 배포합니다. 각 application VPC 서브넷에서 shared services VPC 및 application VPC들 간 라우트를 추가합니다.",
    "SelectC_Commentary": "AWS Direct Connect는 온프레미스와 AWS 간 연결을 위한 서비스입니다. VPC 간 내부 통신을 간소화하기엔 부적합하며, 다수의 VPC를 연결하기엔 비효율적입니다.",
    "SelectD": "Transit Gateway를 생성하여 application VPC들과 shared services VPC를 연결합니다. Transit Gateway를 통해 application VPC들 서브넷에서 shared services VPC 및 다른 application VPC들로 라우트합니다.",
    "SelectD_Commentary": "Transit Gateway를 사용하면 여러 VPC를 중앙에서 일괄 관리하고 손쉽게 라우팅할 수 있어 확장성과 편의성을 모두 충족합니다. 대규모 애플리케이션 마이그레이션에도 적합한 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q790",
      "Q504",
      "Q487",
      "Q293",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q487",
      "Q899",
      "Q439"
    ],
    "SelectB_recommedations": [
      "Q448",
      "Q899",
      "Q439"
    ],
    "SelectC_recommedations": [
      "Q722",
      "Q448",
      "Q68"
    ],
    "SelectD_recommedations": [
      "Q899",
      "Q758",
      "Q504"
    ]
  },
  {
    "Question_Number": "Q900",
    "Question_Description": "한 회사가 온프레미스 환경에서 컨테이너로 동작 중인 애플리케이션을 하이브리드 환경으로 Amazon Elastic Container Service(Amazon ECS)를 사용해 실행하려고 합니다. 이 회사는 온프레미스, 하이브리드, 클라우드 환경 어디서든 확장 가능한 단일 컨테이너 솔루션이 필요합니다. 또한 신규 애플리케이션 컨테이너는 AWS Cloud에서 동작해야 하며, HTTP 트래픽을 처리하기 위한 로드 밸런서가 필요합니다. 아래 조합 중 어떤 것이 이러한 요구사항을 충족합니까? (2개 선택)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/140210-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스와 클라우드 환경을 하나의 컨테이너 솔루션으로 통합하고, HTTP 트래픽을 처리할 로드 밸런서를 구성하는 방법을 묻습니다. AWS Fargate는 클라우드 컨테이너 실행에 적합하며, Amazon ECS Anywhere를 사용하면 온프레미스 컨테이너도 함께 운영할 수 있습니다. HTTP 트래픽에 최적화된 로드 밸런서는 Application Load Balancer입니다. 따라서 A와 B 조합이 가장 적절한 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "하이브리드 환경",
      "온프레미스 컨테이너",
      "클라우드 확장",
      "AWS Fargate",
      "Application Load Balancer",
      "Amazon ECS Anywhere"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Fargate",
      "ECS cluster",
      "Amazon ECS Anywhere",
      "Application Load Balancer",
      "Network Load Balancer",
      "Amazon EC2"
    ],
    "SelectA": "클라우드 애플리케이션 컨테이너를 위해 AWS Fargate 런치 타입을 사용하는 ECS 클러스터를 구성합니다. 온프레미스 애플리케이션 컨테이너는 Amazon ECS Anywhere external launch type을 사용합니다.",
    "SelectA_Commentary": "AWS Fargate를 통해 클라우드 컨테이너를 간편하게 실행하고, ECS Anywhere로 온프레미스 컨테이너도 통합 관리할 수 있어 요구사항에 부합합니다.",
    "SelectB": "클라우드 ECS 서비스용 Application Load Balancer를 구성합니다.",
    "SelectB_Commentary": "HTTP 트래픽 처리를 위해 Application Load Balancer는 최적의 선택이며, 확장성 및 유연한 라우팅을 제공합니다.",
    "SelectC": "클라우드 ECS 서비스용 Network Load Balancer를 구성합니다.",
    "SelectC_Commentary": "Network Load Balancer는 TCP 수준의 트래픽 처리에 적합하지만, HTTP 트래픽 조정에는 Application Load Balancer가 더 적합합니다.",
    "SelectD": "AWS Fargate 런치 타입을 사용하는 ECS 클러스터를 구성합니다. 온프레미스 및 클라우드 애플리케이션 컨테이너 모두를 Fargate로 사용합니다.",
    "SelectD_Commentary": "AWS Fargate는 클라우드에서 유용하지만 온프레미스 환경에는 ECS Anywhere가 필요합니다. 온프레미스 Fargate는 지원되지 않습니다.",
    "SelectE": "클라우드 애플리케이션 컨테이너는 Amazon EC2 런치 타입을 사용하는 ECS 클러스터를 구성합니다. 온프레미스 애플리케이션 컨테이너는 AWS Fargate 런치 타입과 Amazon ECS Anywhere를 사용합니다.",
    "SelectE_Commentary": "클라우드는 Fargate로 간단히 확장할 수 있으므로 EC2 런치 타입보다는 Fargate 사용이 적합합니다. 또한 ECS Anywhere와 Fargate 혼용 구성은 요구사항을 만족시키지 못합니다.",
    "Question_Description_recommedations": [
      "Q775",
      "Q892",
      "Q790",
      "Q654",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q303",
      "Q698",
      "Q900"
    ],
    "SelectB_recommedations": [
      "Q575",
      "Q357",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q575",
      "Q357"
    ],
    "SelectD_recommedations": [
      "Q698",
      "Q303",
      "Q900"
    ],
    "SelectE_recommedations": [
      "Q698",
      "Q303",
      "Q224"
    ]
  },
  {
    "Question_Number": "Q901",
    "Question_Description": "한 회사가 AWS로 워크로드를 마이그레이션 중입니다. 회사는 온프레미스 SQL Server 인스턴스에서 실행되는 관계형 데이터베이스에 민감하고 중요한 데이터를 보유하고 있습니다. 회사는 AWS Cloud를 사용하여 데이터베이스의 보안을 강화하고 운영 오버헤드를 줄이고자 합니다. 어떤 솔루션이 이러한 요구사항을 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139853-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 SQL Server 데이터베이스를 AWS로 마이그레이션하여 보안을 높이고 운영 오버헤드를 줄이는 방법에 관한 것입니다. Multi-AZ Amazon RDS for SQL Server를 사용하면 관리가 용이하고 내장된 암호화(AWS KMS)를 쉽게 적용할 수 있어 요구사항을 모두 충족할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "SQL Server",
      "민감하고 중요한 데이터",
      "AWS Cloud",
      "보안 강화",
      "운영 오버헤드 감소",
      "Multi-AZ",
      "Amazon RDS for SQL Server",
      "AWS KMS"
    ],
    "Terms": [
      "AWS Key Management Service(AWS KMS)",
      "Amazon EC2",
      "Amazon RDS for SQL Server",
      "Multi-AZ",
      "Amazon S3",
      "Amazon Macie",
      "Amazon DynamoDB",
      "Amazon CloudWatch Logs"
    ],
    "SelectA": "데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하고 AWS KMS AWS Managed Key로 암호화합니다.",
    "SelectA_Commentary": "EC2에 직접 SQL Server를 설치하면 패치와 백업을 직접 관리해야 하므로 운영 오버헤드가 증가합니다.",
    "SelectB": "데이터베이스를 Multi-AZ Amazon RDS for SQL Server DB 인스턴스로 마이그레이션하고 AWS KMS AWS Managed Key로 암호화합니다.",
    "SelectB_Commentary": "RDS는 관리형 서비스로 백업, 패치, Multi-AZ 고가용성을 제공하며, KMS 암호화를 통해 민감 데이터를 안전하게 보호합니다.",
    "SelectC": "데이터를 Amazon S3 버킷으로 마이그레이션하고 Amazon Macie로 데이터 보안을 보장합니다.",
    "SelectC_Commentary": "S3로 구조적 SQL Server 데이터를 옮기면 관계형 기능을 잃게 되고, DB 워크로드 요구사항을 충족하지 못합니다.",
    "SelectD": "데이터베이스를 Amazon DynamoDB 테이블로 마이그레이션하고 Amazon CloudWatch Logs로 데이터 보안을 보장합니다.",
    "SelectD_Commentary": "DynamoDB는 NoSQL 서비스로 기존 SQL Server 관계형 기능을 대체하기 어렵고, 데이터베이스 운용이 달라집니다.",
    "Question_Description_recommedations": [
      "Q529",
      "Q970",
      "Q898",
      "Q548",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ],
    "SelectB_recommedations": [
      "Q743",
      "Q121",
      "Q86"
    ],
    "SelectC_recommedations": [
      "Q678",
      "Q106",
      "Q44"
    ],
    "SelectD_recommedations": [
      "Q279",
      "Q176",
      "Q727"
    ]
  },
  {
    "Question_Number": "Q902",
    "Question_Description": "한 회사가 애플리케이션을 AWS로 마이그레이션하려고 합니다. 이 회사는 현재 애플리케이션의 가용성을 높이고자 하며, 애플리케이션 아키텍처에 AWS WAF를 사용하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139856-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "애플리케이션 가용성을 높이기 위해서는 여러 Availability Zone에 분산된 Auto Scaling group과 ALB의 조합이 핵심이며, AWS WAF는 ALB에 연결해 웹 앱 레이어에서 보안을 제공합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "가용성",
      "AWS WAF",
      "Auto Scaling group",
      "Application Load Balancer",
      "Availability Zone"
    ],
    "Terms": [
      "AWS WAF",
      "Auto Scaling group",
      "Amazon EC2",
      "Application Load Balancer (ALB)",
      "Availability Zone",
      "Placement group"
    ],
    "SelectA": "여러 Amazon EC2 인스턴스가 두 개의 Availability Zone에 걸쳐 배포된 Auto Scaling group을 생성합니다. Application Load Balancer(ALB)를 구성하고 해당 Auto Scaling group을 대상으로 설정합니다. ALB에 AWS WAF를 연결합니다.",
    "SelectA_Commentary": "Auto Scaling group과 ALB를 이용해 가용성을 극대화하고, 트래픽 진입점인 ALB에 AWS WAF를 연결해 손쉽게 웹 보호 기능을 도입하는 올바른 솔루션입니다.",
    "SelectB": "하나의 cluster placement group 내 여러 Amazon EC2 인스턴스를 생성합니다. Application Load Balancer를 구성하고 EC2 인스턴스들을 타깃으로 설정합니다. placement group에 AWS WAF를 연결합니다.",
    "SelectB_Commentary": "placement group은 높은 내부 네트워크 대역폭을 위한 설계이며, 가용성 향상보다는 컴퓨팅 성능 목적에 가깝고, WAF를 ALB가 아닌 placement group에 연결하는 구성이 적절하지 않습니다.",
    "SelectC": "두 개의 Availability Zone에 걸쳐 각각 Amazon EC2 인스턴스를 생성합니다. 해당 EC2 인스턴스들을 Application Load Balancer(ALB)의 타깃으로 구성합니다. ALB에 AWS WAF를 연결합니다.",
    "SelectC_Commentary": "AZ 간 분산으로 어느 정도 가용성을 확보하지만 Auto Scaling 기능이 없어 부하 증가 시 확장이 어렵고, 요구사항에서 제시된 가용성 확대 목적에 충분하지 않습니다.",
    "SelectD": "두 개의 Availability Zone에 걸쳐 애플리케이션을 호스팅하는 여러 Amazon EC2 인스턴스를 포함하는 Auto Scaling group을 생성합니다. Application Load Balancer(ALB)를 구성하고 해당 Auto Scaling group을 대상으로 설정합니다. 이 Auto Scaling group에 AWS WAF를 연결합니다.",
    "SelectD_Commentary": "AWS WAF는 ALB에 연결해야 하며, Auto Scaling group에 직접 연결할 수 없습니다. 따라서 이 구성은 불가능합니다.",
    "Question_Description_recommedations": [
      "Q293",
      "Q8",
      "Q869",
      "Q363",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q174",
      "Q405",
      "Q275"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q275",
      "Q639"
    ],
    "SelectC_recommedations": [
      "Q246",
      "Q639",
      "Q174"
    ],
    "SelectD_recommedations": [
      "Q174",
      "Q275",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q903",
    "Question_Description": "회사는 한 Amazon S3 버킷에서 data lake를 운영하며, 여러 애플리케이션이 이를 액세스합니다. S3 버킷에는 각 애플리케이션별로 고유한 prefix가 있으며, 회사는 각 애플리케이션을 해당 prefix를 통해서만 접근하도록 제한하고 prefix 이하 객체에 대한 세분화된 제어를 원합니다. 이 요구사항을 최소한의 운영 오버헤드로 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139857-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "여러 애플리케이션이 공유 버킷을 사용할 때 각 prefix별로 접근 권한을 분리해야 합니다. S3 Access Point를 활용하면 필요한 접근 정책을 각 prefix 단위로 손쉽게 설정하고 운영 복잡도를 크게 낮출 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "data lake",
      "prefix 접근 제어",
      "최소 운영 오버헤드",
      "S3 Access Point"
    ],
    "Terms": [
      "S3 Access Point",
      "Access Point Policy",
      "S3 Batch Operations",
      "ACL",
      "Replication"
    ],
    "SelectA": "각 애플리케이션별로 전용 S3 Access Point를 생성하고, Access Point Policy를 설정합니다.",
    "SelectA_Commentary": "가장 직접적이고 간편한 방안입니다. prefix 단위 정책을 통해 접근 범위를 정확히 제어하고 운영 오버헤드를 최소화할 수 있습니다.",
    "SelectB": "S3 Batch Operations 작업을 통해 S3 버킷 내 각 객체의 ACL 권한을 일괄 설정합니다.",
    "SelectB_Commentary": "객체 단위 ACL 설정은 대규모 환경에서 관리가 복잡하며, 운영 면에서도 지속적인 업데이트가 비효율적입니다.",
    "SelectC": "S3 버킷의 객체를 애플리케이션별 새 S3 버킷으로 복제하고, prefix 기준으로 복제 규칙을 구성합니다.",
    "SelectC_Commentary": "여러 버킷 생성 및 복제를 관리해야 하므로, 운영 및 비용 측면에서 오버헤드가 증가합니다.",
    "SelectD": "S3 버킷의 객체를 애플리케이션별 새 S3 버킷으로 복제한 뒤, 전용 S3 Access Point를 생성합니다.",
    "SelectD_Commentary": "복제와 Access Point를 모두 적용하여 이중 설정이 필요하므로, 불필요한 복잡성과 운영 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q412",
      "Q202",
      "Q109",
      "Q889"
    ],
    "SelectA_recommedations": [
      "Q202",
      "Q965",
      "Q270"
    ],
    "SelectB_recommedations": [
      "Q270",
      "Q862",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q44",
      "Q825",
      "Q202"
    ],
    "SelectD_recommedations": [
      "Q202",
      "Q965",
      "Q678"
    ]
  },
  {
    "Question_Number": "Q904",
    "Question_Description": "한 회사는 고객이 Amazon S3 bucket에 이미지를 업로드하는 애플리케이션을 운영하고 있습니다. 매일 밤, 회사는 Amazon EC2 Spot Fleet을 구동하여 그날 업로드된 모든 이미지를 처리합니다. 각 이미지를 처리하는 데에는 2분이 소요되며 512MB 메모리가 필요합니다. 이제 솔루션스 아키텍트가 이미지를 업로드할 때 즉시 처리하도록 애플리케이션을 변경해야 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 방법은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/139858-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존에 EC2 Spot Fleet을 사용하던 이미지 처리 작업을, 업로드 시점에 즉각 처리하면서도 비용을 최소화해야 하는 상황입니다. 서버리스 방식을 활용하여 사용량만큼만 비용이 청구되는 Lambda가 가장 경제적이며, 자동 확장과 간단한 운영이 가능합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "이미지 업로드",
      "비용 효율성",
      "AWS Lambda",
      "Amazon SQS",
      "Amazon EC2 Spot Fleet",
      "S3 Event Notifications"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2 Spot Fleet",
      "S3 Event Notifications",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Elastic Container Service (Amazon ECS)",
      "AWS Elastic Beanstalk",
      "EC2 Reserved Instance"
    ],
    "SelectA": "S3 Event Notifications를 사용하여 이미지 정보를 포함한 메시지를 Amazon SQS 큐로 전송합니다. AWS Lambda 함수가 큐에서 메시지를 읽어 이미지를 처리하도록 구성합니다.",
    "SelectA_Commentary": "Lambda는 사용한 만큼만 과금되고 운영이 간단하므로 비용 효율적입니다. 메시지도 SQS가 처리량에 맞춰 큐잉하여 안정적으로 처리할 수 있습니다.",
    "SelectB": "S3 Event Notifications를 사용하여 이미지 정보를 포함한 메시지를 Amazon SQS 큐로 전송합니다. EC2 Reserved Instance를 구성하여 큐에서 메시지를 읽어 이미지를 처리합니다.",
    "SelectB_Commentary": "Reserved Instance는 항시 인스턴스 비용을 지불해야 하므로, 이미지를 올릴 때만 발생하는 처리 작업에는 비효율적입니다.",
    "SelectC": "S3 Event Notifications를 사용하여 이미지 정보를 포함한 메시지를 Amazon SNS 토픽으로 발행합니다. Amazon ECS의 컨테이너 인스턴스가 토픽을 구독하여 이미지를 처리하도록 구성합니다.",
    "SelectC_Commentary": "ECS를 사용하면 컨테이너 운영과 클러스터 관리에 대한 비용과 관리 부담이 증가할 수 있어 Lambda보다 덜 비용 효율적입니다.",
    "SelectD": "S3 Event Notifications를 사용하여 이미지 정보를 포함한 메시지를 Amazon SNS 토픽으로 발행합니다. AWS Elastic Beanstalk 애플리케이션이 토픽을 구독하여 이미지를 처리하도록 구성합니다.",
    "SelectD_Commentary": "Elastic Beanstalk는 서버 인스턴스를 지속적으로 운영해야 하므로, 이벤트 기반 처리에 즉시 대응하면서 비용을 최소화하기에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q993",
      "Q347",
      "Q552",
      "Q238",
      "Q167"
    ],
    "SelectA_recommedations": [
      "Q799",
      "Q167",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q380",
      "Q552",
      "Q1013"
    ],
    "SelectC_recommedations": [
      "Q993",
      "Q591",
      "Q167"
    ],
    "SelectD_recommedations": [
      "Q993",
      "Q591",
      "Q167"
    ]
  },
  {
    "Question_Number": "Q905",
    "Question_Description": "한 회사는 하이브리드 애플리케이션의 가용성과 성능을 향상시키고자 합니다. 이 애플리케이션은 서로 다른 AWS 리전의 Amazon EC2 인스턴스에서 호스팅되는 상태 저장(stateful) TCP 기반 워크로드와, 온프레미스에서 호스팅되는 상태 비저장(stateless) UDP 기반 워크로드로 구성됩니다. 가용성과 성능을 개선하기 위해 솔루션스 아키텍트가 수행해야 할 조합은 무엇입니까? (2개를 고르시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144916-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 상태 저장 TCP와 상태 비저장 UDP를 동시에 다루는 하이브리드 애플리케이션에 대해, 글로벌 영역에서의 가용성과 성능을 향상시키는 방법을 묻습니다. AWS Global Accelerator는 전 세계적으로 트래픽을 안정적이고 빠르게 전송하고, NLB는 레이어 4 수준에서 TCP 트래픽 처리에 유리합니다. UDP 트래픽 또한 Global Accelerator를 통해 적절히 분산 및 가속 처리할 수 있으므로, A와 D가 정답입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "하이브리드 애플리케이션",
      "가용성",
      "성능",
      "상태 저장 TCP",
      "상태 비저장 UDP",
      "AWS Global Accelerator",
      "Network Load Balancer"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Amazon CloudFront",
      "Amazon Route 53",
      "Application Load Balancer (ALB)",
      "Network Load Balancer (NLB)",
      "Amazon EC2",
      "TCP",
      "UDP"
    ],
    "SelectA": "AWS Global Accelerator를 사용하여 accelerator를 생성합니다. 로드 밸런서를 endpoint로 추가합니다.",
    "SelectA_Commentary": "정답 선지 중 하나입니다. TCP와 UDP 트래픽 모두에 대해 글로벌 네트워크 엣지를 활용해 지연 시간을 줄이고 가용성을 높일 수 있습니다.",
    "SelectB": "Amazon CloudFront 배포를 생성하고, 원본에 Amazon Route 53 지연 시간 기반 라우팅을 사용하여 로드 밸런서로 트래픽을 라우팅하도록 설정합니다.",
    "SelectB_Commentary": "CloudFront는 주로 HTTP/HTTPS 기반 콘텐츠 캐싱에 초점이 맞춰져 있어 TCP 및 UDP 하이브리드 워크로드 요구사항에 적합하지 않습니다.",
    "SelectC": "각 리전에 Application Load Balancer를 두 개씩 구성합니다. 첫 번째 ALB는 EC2 endpoint로, 두 번째 ALB는 온프레미스 endpoint로 트래픽을 라우팅합니다.",
    "SelectC_Commentary": "ALB는 HTTP/HTTPS 등 레이어 7 트래픽에 최적화되어 있어 TCP 및 UDP 트래픽을 동시에 처리하기에 적합하지 않습니다.",
    "SelectD": "각 리전에 Network Load Balancer를 구성하여 EC2 endpoint로 트래픽을 처리합니다. 그리고 온프레미스 endpoint로 트래픽을 라우팅하는 또 다른 Network Load Balancer를 각 리전에 구성합니다.",
    "SelectD_Commentary": "정답 선지 중 하나입니다. NLB는 TCP 트래픽 처리에 최적이며, UDP 트래픽 또한 Global Accelerator와 함께 유연하게 구성 가능합니다.",
    "SelectE": "각 리전에 Network Load Balancer를 구성하여 EC2 endpoint로 트래픽을 처리합니다. 그리고 각 리전에 Application Load Balancer를 구성하여 온프레미스 endpoint로 트래픽을 라우팅합니다.",
    "SelectE_Commentary": "Application Load Balancer는 UDP를 지원하지 않으므로 온프레미스 UDP 워크로드 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q704",
      "Q352",
      "Q600",
      "Q746",
      "Q910"
    ],
    "SelectA_recommedations": [
      "Q361",
      "Q704",
      "Q865"
    ],
    "SelectB_recommedations": [
      "Q582",
      "Q280",
      "Q367"
    ],
    "SelectC_recommedations": [
      "Q358",
      "Q141",
      "Q12"
    ],
    "SelectD_recommedations": [
      "Q815",
      "Q141",
      "Q530"
    ],
    "SelectE_recommedations": [
      "Q141",
      "Q815",
      "Q358"
    ]
  },
  {
    "Question_Number": "Q906",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스와 Amazon EBS 위에 직접 관리하는 Microsoft SQL Server를 운영하고 있습니다. 매일 EBS 볼륨의 스냅샷을 생성하기는 하지만, 최근 만료된 EBS 스냅샷을 삭제하는 스크립트를 실행하는 과정에서 모든 스냅샷이 실수로 삭제되었습니다. 솔루션스 아키텍트는 EBS 스냅샷을 무기한 보관하지 않으면서도 데이터 손실을 방지할 수 있도록 아키텍처를 변경해야 합니다. 다음 중 가장 적은 개발 노력을 들이면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144969-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실수로 삭제된 EBS 스냅샷 복구에 대한 요구사항을 다룹니다. Amazon EBS Recycle Bin 기능을 통해 스냅샷 삭제 후 일정 기간 복구할 수 있으므로 데이터 손실을 방지하면서 무기한 보관을 피할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "EBS 스냅샷",
      "데이터 손실 방지",
      "Recycle Bin",
      "스냅샷 만료",
      "Microsoft SQL Server"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Microsoft SQL Server",
      "IAM Policy",
      "AWS Region",
      "Recycle Bin",
      "Amazon S3 Standard-Infrequent Access (S3 Standard-IA)"
    ],
    "SelectA": "사용자의 IAM 정책을 변경하여 EBS 스냅샷 삭제를 거부합니다.",
    "SelectA_Commentary": "EBS 스냅샷을 전혀 삭제하지 못하게 하므로 무기한 보관 문제가 발생하고, 운영 유연성도 떨어져 적절한 해결책이 아닙니다.",
    "SelectB": "매일 스냅샷 생성 후 다른 AWS Region으로 스냅샷을 복사합니다.",
    "SelectB_Commentary": "Cross-Region 복사는 복원력을 높일 수 있지만, 스냅샷을 삭제했을 때 곧바로 복구되지 않고 추가 비용과 운영 복잡성이 늘어납니다.",
    "SelectC": "Recycle Bin에서 7일 EBS 스냅샷 보존 규칙을 생성하고 모든 스냅샷에 이 규칙을 적용합니다.",
    "SelectC_Commentary": "정해진 기간 동안 삭제된 스냅샷을 복구할 수 있어 실수로 인한 데이터 손실을 방지하며, 무기한 보관이 아닌 적절한 보존 기한을 설정하는 최적의 해결책입니다.",
    "SelectD": "EBS 스냅샷을 Amazon S3 Standard-IA로 복사합니다.",
    "SelectD_Commentary": "S3로 복사해 추가 백업을 할 수 있지만, 복구 절차가 복잡하고 관리 오버헤드도 증가합니다. 즉각적인 스냅샷 복구를 지원하는 Recycle Bin만큼 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q602",
      "Q312",
      "Q5",
      "Q837",
      "Q824"
    ],
    "SelectA_recommedations": [
      "Q362",
      "Q917",
      "Q58"
    ],
    "SelectB_recommedations": [
      "Q8",
      "Q869",
      "Q363"
    ],
    "SelectC_recommedations": [
      "Q362",
      "Q78",
      "Q615"
    ],
    "SelectD_recommedations": [
      "Q602",
      "Q194",
      "Q584"
    ]
  },
  {
    "Question_Number": "Q907",
    "Question_Description": "한 회사가 테스트 환경에서 애플리케이션을 배포하기 위해 AWS CloudFormation 스택을 사용하려고 합니다. 해당 회사는 CloudFormation 템플릿을 퍼블릭 액세스가 차단된 Amazon S3 버킷에 보관하고 있습니다. 회사는 특정 사용자가 테스트 환경을 생성하겠다고 요청할 때만, CloudFormation이 이 S3 버킷의 템플릿에 액세스할 수 있도록 하고자 합니다. 솔루션은 보안 모범 사례를 따라야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145006-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "보안 강화를 위해 S3 버킷의 퍼블릭 액세스를 막으면서도, 요청 시 CloudFormation이 템플릿에 접근할 수 있어야 합니다. 프리사인드 URL을 사용하면 필요 시점에만 템플릿을 안전하게 공유할 수 있어 보안 모범 사례에 부합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "CloudFormation 스택",
      "S3 템플릿 보안",
      "테스트 환경",
      "프리사인드 URL"
    ],
    "Terms": [
      "AWS CloudFormation",
      "Amazon S3",
      "Gateway VPC Endpoint",
      "Amazon API Gateway",
      "Presigned URL",
      "Block Public Access",
      "Security Best Practices"
    ],
    "SelectA": "Amazon S3에 대해 Gateway VPC Endpoint를 생성하고, CloudFormation 스택에 S3 객체 URL을 사용하도록 구성합니다.",
    "SelectA_Commentary": "CloudFormation이 VPC 내부에서만 템플릿을 접근하게 할 수 있으나, 생성 요청에 따른 제한적 접근 제어를 구현하기엔 직접적인 정책 설정이 더 복잡해질 수 있습니다.",
    "SelectB": "Amazon API Gateway REST API를 생성하여 S3 버킷을 대상으로 지정하고, CloudFormation 스택에 API Gateway URL을 사용하도록 구성합니다.",
    "SelectB_Commentary": "별도의 API Gateway 설정과 권한 제어 구성으로 복잡도가 높아지고, 단순히 템플릿을 전달하는 목적에는 과도한 방식입니다.",
    "SelectC": "템플릿 객체에 대해 Presigned URL을 생성하고, CloudFormation 스택에 해당 Presigned URL을 사용하도록 구성합니다.",
    "SelectC_Commentary": "필요할 때마다 제한된 시간 동안만 접근 가능한 URL을 발급해주므로, 민감한 템플릿을 안전하게 공유하고 운영도 간소화할 수 있는 최적의 솔루션입니다.",
    "SelectD": "S3 버킷의 템플릿 객체에 대해 퍼블릭 액세스를 허용하고, 테스트 환경 생성 후 퍼블릭 액세스를 차단합니다.",
    "SelectD_Commentary": "임시로라도 퍼블릭 액세스를 허용하면 보안 위험이 증가하므로 권장되지 않는 방식입니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q556",
      "Q412",
      "Q862",
      "Q109"
    ],
    "SelectA_recommedations": [
      "Q91",
      "Q4",
      "Q92"
    ],
    "SelectB_recommedations": [
      "Q185",
      "Q907",
      "Q532"
    ],
    "SelectC_recommedations": [
      "Q172",
      "Q893",
      "Q907"
    ],
    "SelectD_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ]
  },
  {
    "Question_Number": "Q908",
    "Question_Description": "한 회사가 AWS Organizations 내 조직에서 애플리케이션을 운영하고 있습니다. 이 회사는 애플리케이션 운영 지원을 외부 업체에 위탁하고 있으며, 외부 지원 엔지니어에게 보안을 해치지 않고 접근 권한을 제공해야 합니다. 외부 지원 엔지니어는 AWS Management Console에 대한 액세스와 사설 서브넷에서 Amazon Linux를 실행하는 Amazon EC2 인스턴스에 대한 운영 체제 수준 액세스가 필요합니다. 이러한 요구사항을 가장 안전하게 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145029-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 외부 지원 엔지니어를 위한 AWS Management Console 및 EC2 인스턴스 접근을 보안적으로 설계하는 상황입니다. Systems Manager Session Manager를 사용하면 SSH 포트 노출 없이 안전하고 감사 가능한 OS 수준 접근을 제공할 수 있고, IAM Identity Center를 통해 중앙 집중형 사용자 관리를 구현할 수 있어 보안성과 편의성이 높습니다. 따라서 SelectA가 가장 안전하고 효과적인 방법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "AWS Organizations",
      "외부 지원 엔지니어",
      "AWS Management Console",
      "Amazon EC2",
      "Amazon Linux",
      "사설 서브넷",
      "Systems Manager Session Manager",
      "IAM Identity Center",
      "보안"
    ],
    "Terms": [
      "AWS Organizations",
      "AWS Management Console",
      "Amazon EC2",
      "Amazon Linux",
      "Private Subnet",
      "Systems Manager Agent (SSM Agent)",
      "Instance Profile",
      "Systems Manager Session Manager",
      "AWS IAM Identity Center",
      "SSH",
      "Bastion Host",
      "IAM user credentials"
    ],
    "SelectA": "모든 인스턴스에 AWS Systems Manager Agent(SSM Agent)가 설치되어 있는지 확인하고, Systems Manager에 연결하기 위한 필요한 정책을 가진 인스턴스 프로파일을 할당합니다. AWS IAM Identity Center를 통해 외부 지원 엔지니어에게 콘솔 액세스를 제공하고, Systems Manager Session Manager에 필요한 권한을 부여합니다.",
    "SelectA_Commentary": "Session Manager와 IAM Identity Center를 함께 사용해 SSH 포트를 열지 않고 중앙에서 접근 권한을 제어할 수 있어 보안성과 운영 효율성이 가장 뛰어납니다.",
    "SelectB": "모든 인스턴스에 AWS Systems Manager Agent(SSM Agent)를 설치하고, Systems Manager에 연결하기 위한 필요한 정책을 가진 인스턴스 프로파일을 할당합니다. 이후 Systems Manager Session Manager를 사용해 로컬 IAM 사용자 자격 증명을 외부 지원 엔지니어에게 제공해 콘솔 액세스를 부여합니다.",
    "SelectB_Commentary": "로컬 IAM 계정을 사용하면 계정이 분산되어 관리가 복잡해지고, IAM Identity Center의 이점을 활용하지 못해 확장성과 보안 측면에서 다소 불리합니다.",
    "SelectC": "모든 인스턴스가 외부 지원 엔지니어의 소스 IP 범위에서만 SSH 접속을 허용하는 보안 그룹을 갖고 있는지 확인합니다. 각 AWS 계정에 로컬 IAM 사용자 자격 증명을 제공해 콘솔 접근을 부여하고, 외부 엔지니어마다 SSH 키 페어를 부여하여 애플리케이션 인스턴스에 로그인합니다.",
    "SelectC_Commentary": "SSH 포트 및 키 관리가 필요하고 네트워크 공격 표면이 커지며, IAM Identity Center를 사용하지 않아 확장성과 보안성이 떨어집니다.",
    "SelectD": "공개 서브넷에 베스천 호스트를 생성하고, 이 베스천 호스트 보안 그룹에서 외부 엔지니어의 IP 범위만 허용하도록 설정합니다. 모든 인스턴스가 베스천 호스트로부터 SSH 액세스를 허용하도록 보안 그룹을 구성합니다. 각 외부 지원 엔지니어에게 SSH 키 페어를 제공해 애플리케이션 인스턴스에 로그인하고, 로컬 IAM 사용자 자격 증명으로 콘솔 액세스를 제공합니다.",
    "SelectD_Commentary": "베스천 호스트 운영 및 SSH 관리로 운영 복잡성이 증가하고, 포트 노출로 인해 보안 위험이 커질 수 있으며 IAM Identity Center를 활용하지 않아 계정 관리가 번거롭습니다.",
    "Question_Description_recommedations": [
      "Q945",
      "Q168",
      "Q1018",
      "Q137",
      "Q3"
    ],
    "SelectA_recommedations": [
      "Q981",
      "Q517",
      "Q688"
    ],
    "SelectB_recommedations": [
      "Q517",
      "Q924",
      "Q222"
    ],
    "SelectC_recommedations": [
      "Q476",
      "Q222",
      "Q96"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q476",
      "Q429"
    ]
  },
  {
    "Question_Number": "Q909",
    "Question_Description": "한 회사는 us-east-1 리전에서 Amazon RDS for PostgreSQL을 사용해 애플리케이션을 운영하고 있습니다. 이 회사는 매년 매출을 예측하기 위해 기계학습(ML) 모델을 사용하며, 거의 실시간으로 생성되는 보고서를 통해 예측에 필요한 데이터를 얻습니다. 이 보고서들도 동일한 RDS for PostgreSQL 데이터베이스를 사용하여 생성됩니다. 이로 인해 업무 시간대에 데이터베이스 성능이 저하되고 있습니다. 회사는 이 성능 문제를 개선하고자 하며, 동시에 비용 효율적이어야 합니다. 이러한 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145030-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 RDS 인스턴스에 대한 읽기 부하를 분산해 성능 저하를 방지하고자 할 때, 비용 효율 방향에서 가장 적합한 방안을 찾는 것입니다. Read Replica를 사용하면 읽기 요청을 분산시켜 본 DB 인스턴스의 쓰기 및 트랜잭션 처리를 개선할 수 있고, 필요한 비용도 추가 인스턴스 정도로 최소화됩니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "데이터베이스 성능",
      "비즈니스 시간대",
      "비용 효율",
      "Amazon RDS for PostgreSQL",
      "Read Replica",
      "Multi-AZ",
      "AWS DMS"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "us-east-1",
      "기계학습(ML)",
      "Multi-AZ",
      "Cross-Region",
      "Read Replica",
      "AWS Data Migration Service (AWS DMS)"
    ],
    "SelectA": "Cross-Region Read Replica를 생성합니다. 보고서를 Read Replica에서 생성하도록 설정합니다.",
    "SelectA_Commentary": "Cross-Region Read Replica는 네트워크 비용과 지연 시간이 증가하여 비용이 더 들 수 있어, 가장 비용 효율적인 방법이 아닙니다.",
    "SelectB": "RDS for PostgreSQL에 Multi-AZ DB 인스턴스 배포를 활성화합니다. 보고서를 대기(standby) 데이터베이스에서 생성하도록 설정합니다.",
    "SelectB_Commentary": "Multi-AZ 구성은 고가용성을 제공하지만, 본질적으로 동기식 복제를 하기 때문에 비용과 쓰기 지연이 늘어날 수 있으며, 읽기 전용 처리는 지원하지 않아 보고서 생성을 분리할 수 없습니다.",
    "SelectC": "AWS Data Migration Service(AWS DMS)를 사용하여 새 데이터베이스로 논리적 복제를 수행합니다. 보고서를 새 데이터베이스에서 생성하도록 설정합니다.",
    "SelectC_Commentary": "별도의 데이터베이스를 운영해도 되지만 DMS 구성, 추가 운영 부담, 추가 DB 인스턴스 비용이 발생할 수 있어 단순히 Read Replica를 생성하는 것보다 비용 효율성이 떨어집니다.",
    "SelectD": "us-east-1 리전에 Read Replica를 생성합니다. 보고서를 Read Replica에서 생성하도록 설정합니다.",
    "SelectD_Commentary": "동일 리전에서 Read Replica를 사용하면 본 DB 인스턴스의 부하를 효과적으로 줄이고, 추가 비용도 Cross-Region 또는 Multi-AZ 대비 적게 드는 가장 비용 효율적인 방안입니다.",
    "Question_Description_recommedations": [
      "Q726",
      "Q376",
      "Q633",
      "Q776",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q622",
      "Q817",
      "Q158"
    ],
    "SelectB_recommedations": [
      "Q633",
      "Q481",
      "Q909"
    ],
    "SelectC_recommedations": [
      "Q305",
      "Q361",
      "Q249"
    ],
    "SelectD_recommedations": [
      "Q622",
      "Q158",
      "Q888"
    ]
  },
  {
    "Question_Number": "Q910",
    "Question_Description": "한 회사가 AWS Cloud에서 다중 계층의 공개 웹 애플리케이션을 호스팅하고 있습니다. 웹 애플리케이션은 Amazon EC2 인스턴스에서 실행되며, 데이터베이스는 Amazon RDS에서 동작합니다. 회사는 다가오는 휴일 주말 동안 큰 매출 증가를 예상하고 있습니다. 솔루션스 아키텍트는 2분 이하의 세분화로 웹 애플리케이션 성능을 분석할 솔루션을 구축해야 합니다. 이를 충족하기 위해서는 어떤 작업을 해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144971-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션 성능을 세분화(2분 이하)로 모니터링할 수 있는 방법을 묻고 있습니다. Amazon CloudWatch의 Detailed Monitoring 기능을 사용하면 1분 단위로 EC2 지표를 수집할 수 있어 요구 사항을 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Amazon RDS",
      "성능 분석",
      "2분 이내",
      "Detailed Monitoring"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon CloudWatch Logs",
      "Amazon CloudWatch metrics",
      "Amazon S3",
      "Amazon Redshift",
      "Amazon QuickSight",
      "AWS Lambda"
    ],
    "SelectA": "Amazon CloudWatch 로그를 Amazon Redshift로 전송합니다. Amazon QuickSight를 사용하여 추가 분석을 수행합니다.",
    "SelectA_Commentary": "CloudWatch Logs를 Redshift로 보내고 QuickSight로 분석하면 데이터 시각화에는 유리하지만, 실시간에 가까운 2분 이하 주기의 세분화 모니터링을 보장하기에는 적합하지 않습니다.",
    "SelectB": "모든 EC2 인스턴스에 대해 Detailed Monitoring을 활성화합니다. Amazon CloudWatch 지표를 사용하여 추가 분석을 수행합니다.",
    "SelectB_Commentary": "Detailed Monitoring은 1분 주기로 지표를 수집하므로 2분 이하 수준의 성능 모니터링 요구 사항을 충족할 수 있는 최적의 방법입니다.",
    "SelectC": "AWS Lambda 함수를 생성해 Amazon CloudWatch Logs에서 EC2 로그를 가져옵니다. Amazon CloudWatch 지표를 사용하여 추가 분석을 수행합니다.",
    "SelectC_Commentary": "Lambda로 로그를 주기적으로 호출해도 2분 이하의 정밀한 데이터 수집 주기를 보장하기 어렵고, 기본적인 Detailed Monitoring에 비해 구현이 복잡합니다.",
    "SelectD": "EC2 로그를 Amazon S3로 전송합니다. Amazon Redshift가 S3 버킷에서 로그를 가져온 뒤, Amazon QuickSight로 추가 분석을 진행합니다.",
    "SelectD_Commentary": "S3로 로그를 전송한 뒤 Redshift로 로드하는 과정은 실시간성이 떨어져 2분 이하 세분화 요구사항에 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q386",
      "Q193",
      "Q921",
      "Q192",
      "Q661"
    ],
    "SelectA_recommedations": [
      "Q515",
      "Q557",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q248",
      "Q746",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q117",
      "Q248",
      "Q597"
    ],
    "SelectD_recommedations": [
      "Q515",
      "Q910",
      "Q557"
    ]
  },
  {
    "Question_Number": "Q911",
    "Question_Description": "한 회사는 사진을 저장하고 공유하는 애플리케이션을 운영합니다. 사용자는 사진을 Amazon S3 버킷에 업로드합니다. 매일 약 150장의 사진이 업로드됩니다. 회사는 새로운 사진이 올라올 때마다 썸네일을 생성하고, 이 썸네일을 두 번째 S3 버킷에 저장하는 솔루션을 설계하고자 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144972-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매일 적은 수량의 사진에 대해 어떤 방식이 가장 비용 효율적인지 묻습니다. Amazon S3 이벤트 트리거와 AWS Lambda를 사용하면 서버 없이 필요할 때만 썸네일을 생성하므로 매우 경제적입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "사진 업로드",
      "썸네일 생성",
      "비용 효율",
      "Amazon S3",
      "AWS Lambda"
    ],
    "Terms": [
      "Amazon EMR",
      "Amazon EC2",
      "AWS Lambda",
      "S3 event notification",
      "S3 Storage Lens"
    ],
    "SelectA": "Amazon EventBridge 스케줄 규칙을 구성하여 매분 Amazon EMR 클러스터에서 스크립트를 호출합니다. 썸네일이 없는 사진을 찾아 썸네일을 생성하고, 결과를 두 번째 S3 버킷에 업로드합니다.",
    "SelectA_Commentary": "EMR 클러스터를 상시 유지해야 하므로 트래픽이 적은 환경에서는 유지 비용이 불필요하게 많이 듭니다.",
    "SelectB": "Amazon EventBridge 스케줄 규칙을 구성하여 항상 켜져 있는 메모리 최적화 Amazon EC2 인스턴스에서 매분 스크립트를 호출합니다. 썸네일을 생성하여 두 번째 S3 버킷에 업로드합니다.",
    "SelectB_Commentary": "EC2 인스턴스를 계속 구동해야 하므로 사용량이 적어도 비용이 계속 발생해 비효율적입니다.",
    "SelectC": "S3 event notification을 사용하여 새로운 사진이 업로드될 때마다 AWS Lambda를 호출합니다. Lambda 함수에서 썸네일을 생성하고 두 번째 S3 버킷에 업로드하도록 구성합니다.",
    "SelectC_Commentary": "서버리스 방식으로 요청이 있을 때만 실행되어 비용이 매우 절감되며, 실시간으로 썸네일을 자동 생성하는 데 적합한 최적의 해결책입니다.",
    "SelectD": "S3 Storage Lens를 사용하여 사진이 업로드될 때마다 AWS Lambda 함수를 호출합니다. Lambda 함수가 썸네일을 생성하여 두 번째 S3 버킷에 업로드합니다.",
    "SelectD_Commentary": "S3 Storage Lens는 스토리지 모니터링을 위한 기능이며, 실시간 이벤트 트리거로 활용하기에는 적절하지 않아 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q1003",
      "Q285",
      "Q769",
      "Q469",
      "Q606"
    ],
    "SelectA_recommedations": [
      "Q993",
      "Q167",
      "Q652"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q167"
    ],
    "SelectC_recommedations": [
      "Q498",
      "Q829",
      "Q415"
    ],
    "SelectD_recommedations": [
      "Q415",
      "Q829",
      "Q498"
    ]
  },
  {
    "Question_Number": "Q912",
    "Question_Description": "한 회사가 Amazon S3 Glacier Deep Archive 스토리지 클래스를 사용하여 여러 prefix에 걸쳐 수백만 개의 객체를 Amazon S3 버킷에 저장해 왔습니다. 이 회사는 3년 이상 된 데이터를 모두 삭제해야 하지만, 그중에서도 일부 반드시 보존해야 하는 데이터는 제외해야 합니다. 회사는 보존해야 할 데이터를 이미 식별했으며, 이를 서버리스(serverless) 방식으로 처리하기를 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145209-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 수백만 개의 객체 중에서 일부만 보존하고 나머지는 3년 이상 된 데이터를 삭제하는 방법을 찾는 것입니다. Glacier Deep Archive에 보관된 데이터를 대상으로 하므로, 운영 비용과 처리의 단순성을 모두 고려해야 합니다. 또한 서버리스 방식을 요구하기 때문에 EC2 기반 스크립트나 별도 인프라 구성 없이 처리할 수 있는 솔루션이 필요합니다. S3 Batch Operations와 S3 Inventory, 그리고 AWS Lambda를 조합하면 자동화되고 서버리스로 원하는 삭제 작업을 수행할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "S3 Glacier Deep Archive",
      "3년 이상 데이터 삭제",
      "서버리스 방식",
      "보존 데이터 제외",
      "S3 Inventory",
      "S3 Batch Operations"
    ],
    "Terms": [
      "Amazon S3",
      "S3 Glacier Deep Archive",
      "prefix",
      "S3 Inventory",
      "AWS CLI",
      "AWS Batch",
      "AWS Glue crawler",
      "AWS Lambda",
      "S3 Batch Operations",
      "Amazon EC2",
      "서버리스(serverless)",
      "스크립트(EC2/Python 등)"
    ],
    "SelectA": "S3 Inventory로 모든 객체 목록을 추출합니다. 그 후 AWS CLI를 사용하여 Amazon EC2 인스턴스에서 스크립트를 실행해 해당 목록의 객체를 삭제합니다.",
    "SelectA_Commentary": "EC2 인스턴스를 사용하기 때문에 서버리스 방식이 아니며, 유지 관리 부담이 큽니다. 요구사항에 부합하지 않습니다.",
    "SelectB": "AWS Batch를 사용하여 3년 이상 된 객체 중 반드시 보존해야 하는 데이터를 제외하고 나머지를 삭제합니다.",
    "SelectB_Commentary": "AWS Batch는 컨테이너 기반의 대규모 배치 작업에 주로 사용됩니다. S3 객체 삭제와 보존 처리에 대해 서버리스 기반으로 간단히 적용하기에는 적합하지 않습니다.",
    "SelectC": "AWS Glue 크롤러를 구성하여 3년 이상 된 객체를 쿼리합니다. 구 버전 객체의 매니페스트 파일을 저장하고, 스크립트를 통해 해당 매니페스트에 포함된 객체를 삭제합니다.",
    "SelectC_Commentary": "Glue 크롤러로 메타데이터를 수집하고 추가 스크립트를 사용하는 방식은 복잡도가 높고, 완전한 서버리스 방식이라고 보기 어렵습니다.",
    "SelectD": "S3 Inventory를 활성화합니다. 필터링 및 삭제 작업을 수행하는 AWS Lambda 함수를 생성합니다. 그런 다음 S3 Batch Operations를 사용하여 Inventory 리포트를 기반으로 Lambda 함수를 호출해 객체를 삭제합니다.",
    "SelectD_Commentary": "S3 Inventory와 Batch Operations, 그리고 Lambda의 조합으로 서버리스 아키텍처에서 간단하고 효율적으로 3년 이상 된 객체를 선별 삭제할 수 있어 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q829",
      "Q498",
      "Q285",
      "Q606",
      "Q415"
    ],
    "SelectA_recommedations": [
      "Q993",
      "Q552",
      "Q238"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q486",
      "Q485"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q485"
    ],
    "SelectD_recommedations": [
      "Q993",
      "Q829",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q913",
    "Question_Description": "한 회사가 AWS에서 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 여러 개의 AWS Lambda function을 사용하여 하나의 Amazon S3 버킷에서 민감 데이터를 가져와 처리합니다. 회사는 오직 권한이 부여된 Lambda function만이 해당 데이터를 액세스할 수 있도록 해야 합니다. 이 솔루션은 최소 권한 원칙(Principle of Least Privilege)에 부합해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145210-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 Amazon S3 버킷에서 민감 데이터를 가져오는 AWS Lambda function 각각에 대해 최소 권한만 부여하여 접근을 통제하는 것입니다. 개별 IAM role을 사용하면 권한을 세밀하게 관리할 수 있어, Principle of Least Privilege를 충족하며 민감 데이터의 보안을 강화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "민감 데이터",
      "AWS Lambda function",
      "Amazon S3 버킷",
      "최소 권한 원칙",
      "IAM role",
      "Lambda execution role"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon S3",
      "IAM role",
      "Bucket policy",
      "VPC endpoint",
      "Principle of Least Privilege",
      "Lambda function ARN",
      "Lambda execution role"
    ],
    "SelectA": "모든 Lambda function에 대해 공유 IAM role을 통해 S3 버킷에 대한 전체 권한을 부여합니다.",
    "SelectA_Commentary": "단일 공유 IAM role에 전체 권한을 부여하면, 최소 권한 원칙을 만족하지 못하고 필요 이상의 접근 권한을 허용하게 됩니다.",
    "SelectB": "Lambda function을 VPC 내에서 실행하고, Lambda function의 VPC endpoint IP 주소 기반으로 Bucket policy를 구성합니다.",
    "SelectB_Commentary": "IP 주소를 기준으로 접근을 제어하면 세밀한 권한 관리가 어렵고, IP 변경 등에 따라 접근 제어가 불안정해집니다.",
    "SelectC": "각 Lambda function마다 IAM role을 별도로 생성하고, 해당 IAM role에 S3 버킷 접근 권한을 부여한 뒤 각 Lambda function의 실행 역할로 할당합니다.",
    "SelectC_Commentary": "함수별로 필요한 권한만 부여하여 최소 권한 원칙을 만족하며 보안을 강화하는 최적의 방식입니다.",
    "SelectD": "Lambda function의 ARN을 기준으로 Bucket policy를 구성해 Lambda function에 접근 권한을 부여합니다.",
    "SelectD_Commentary": "Lambda function ARN을 활용한 버킷 정책도 가능하지만, 함수 ARN 변경 시 재구성이 필요해 운영이 복잡해질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q289",
      "Q387",
      "Q791",
      "Q936",
      "Q418"
    ],
    "SelectA_recommedations": [
      "Q403",
      "Q791",
      "Q289"
    ],
    "SelectB_recommedations": [
      "Q791",
      "Q135",
      "Q913"
    ],
    "SelectC_recommedations": [
      "Q403",
      "Q791",
      "Q289"
    ],
    "SelectD_recommedations": [
      "Q791",
      "Q913",
      "Q936"
    ]
  },
  {
    "Question_Number": "Q914",
    "Question_Description": "한 회사가 각 비즈니스 부서별로 구성된 여러 마이크로서비스로 이루어진 비생산용 애플리케이션을 개발했습니다. 모든 마이크로서비스는 단일 개발 팀에서 관리하고 있습니다. 현재 아키텍처는 정적 웹 프론트엔드와 애플리케이션 로직을 포함하는 Java 기반 백엔드를 사용하며, MySQL 데이터베이스는 Amazon EC2 인스턴스에서 호스팅되고 있습니다. 이 회사는 애플리케이션이 전 세계적으로 보안이 유지되고 가용해야 하며, 운영 오버헤드를 최소화할 필요가 있습니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145211-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계적으로 안전하고 가용한 애플리케이션 환경을 구축하면서, 운영 오버헤드를 최소화하려는 요구사항에 대한 최적의 아키텍처를 묻습니다. 정적 콘텐츠는 전 세계에 배포 가능한 S3 + CloudFront 조합이 효과적이며, 서버리스 기반의 AWS Lambda + Amazon API Gateway 구조가 운영 및 관리 부담을 낮출 수 있습니다. 데이터베이스는 Amazon RDS for MySQL로 이전하여 자동 패치, 백업 등 관리형 서비스를 활용함으로써 보안과 가용성을 높일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "마이크로서비스",
      "정적 웹 프론트엔드",
      "Java 기반 백엔드",
      "MySQL",
      "Amazon EC2",
      "보안",
      "글로벌 가용성",
      "운영 오버헤드 최소화",
      "Amazon CloudFront",
      "Amazon S3",
      "AWS Lambda",
      "Amazon API Gateway",
      "Amazon RDS for MySQL"
    ],
    "Terms": [
      "AWS Amplify",
      "Network Load Balancer",
      "Application Load Balancer",
      "Amazon EC2 Reserved Instance"
    ],
    "SelectA": "Amazon CloudFront와 AWS Amplify로 정적 웹 프론트엔드를 호스팅합니다. 마이크로서비스를 AWS Lambda로 리팩터링하고, Amazon API Gateway로 접근하도록 구성합니다. MySQL 데이터베이스는 Amazon EC2 Reserved Instance로 이전합니다.",
    "SelectA_Commentary": "AWS Amplify도 정적 웹 호스팅에 적합하지만, 데이터베이스를 EC2에 그대로 두는 것은 운영 부담이 계속 남습니다. 완전히 관리형 RDS로 이전했을 때보다 보안과 자동화 측면에서 이점이 적습니다.",
    "SelectB": "Amazon CloudFront와 Amazon S3로 정적 웹 프론트엔드를 호스팅합니다. 마이크로서비스를 AWS Lambda로 리팩터링하고, Amazon API Gateway로 접근하도록 구성합니다. MySQL 데이터베이스는 Amazon RDS for MySQL로 이전합니다.",
    "SelectB_Commentary": "S3 + CloudFront로 정적 콘텐츠를 안전하게 전 세계에 배포하고, Lambda + API Gateway로 운영 및 관리 부담을 크게 줄입니다. MySQL을 RDS로 이전해 관리형 데이터베이스 기능을 활용하여 보안과 가용성을 높이는 완전한 서버리스 구조로, 요구사항을 가장 적절히 충족합니다.",
    "SelectC": "Amazon CloudFront와 Amazon S3로 정적 웹 프론트엔드를 호스팅합니다. 마이크로서비스를 네트워크 로드 밸런서 뒤의 AWS Lambda로 리팩터링합니다. MySQL 데이터베이스는 Amazon RDS for MySQL로 이전합니다.",
    "SelectC_Commentary": "Lambda 함수를 Network Load Balancer 뒤에 배치하는 구성이 가능하지만 API Gateway를 활용하지 않으면 IAM 인증, 사용 편의성, 추가 기능 등을 놓치게 되어 운영 관리에 더 많은 작업이 필요합니다.",
    "SelectD": "Amazon S3로 정적 웹 프론트엔드를 호스팅합니다. 마이크로서비스를 애플리케이션 로드 밸런서 뒤의 AWS Lambda로 리팩터링합니다. MySQL 데이터베이스는 Amazon EC2 Reserved Instance로 이전합니다.",
    "SelectD_Commentary": "정적 호스팅은 가능하지만, 글로벌 배포를 위한 CloudFront 미활용으로 성능 및 보안 이점이 제한됩니다. 또한 데이터베이스를 RDS로 이전하지 않아 관리와 보안 측면에서 오버헤드가 여전히 큽니다.",
    "Question_Description_recommedations": [
      "Q190",
      "Q114",
      "Q252",
      "Q1014",
      "Q363"
    ],
    "SelectA_recommedations": [
      "Q354",
      "Q944",
      "Q935"
    ],
    "SelectB_recommedations": [
      "Q354",
      "Q944",
      "Q935"
    ],
    "SelectC_recommedations": [
      "Q354",
      "Q935",
      "Q944"
    ],
    "SelectD_recommedations": [
      "Q236",
      "Q935",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q915",
    "Question_Description": "한 비디오 게임 회사가 글로벌 사용자들에게 새 게임 애플리케이션을 배포하려고 합니다. 이 회사는 플레이어들의 리뷰와 순위를 실시간에 가까운 속도로 제공해 줄 수 있는 솔루션이 필요합니다. 솔루션 설계자는 빠른 데이터 액세스를 제공해야 하며, 애플리케이션이 재시작되더라도 데이터가 디스크에 지속되도록 해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145201-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 빠른 읽기·쓰기가 필요한 게임 데이터(리뷰, 순위)를 디스크에 안전하게 보존하면서, 운영 복잡도를 낮추는 최적의 캐싱 솔루션을 묻습니다. Amazon ElastiCache for Redis는 인메모리 캐싱과 함께 RDB 스냅샷 및 AOF로 디스크에 데이터를 보존하여 재시작 시 데이터 무손실이 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "글로벌 사용자",
      "실시간에 가까운 속도",
      "플레이어 리뷰와 순위",
      "데이터 디스크 지속",
      "운영 오버헤드 최소화",
      "Amazon ElastiCache for Redis 클러스터"
    ],
    "Terms": [
      "Amazon CloudFront",
      "Amazon S3",
      "Amazon EC2",
      "Amazon Route 53",
      "geolocation records",
      "Amazon ElastiCache for Redis",
      "Amazon ElastiCache for Memcached",
      "in-memory caching",
      "RDB snapshots",
      "AOF(Append Only File)"
    ],
    "SelectA": "Amazon CloudFront 배포를 구성하고 Amazon S3 버킷을 오리진으로 사용합니다. 플레이어 데이터를 S3 버킷에 저장합니다.",
    "SelectA_Commentary": "S3는 영구 저장에는 적합하지만 실시간 업데이트가 필요한 시나리오에선 지연이 크고, CloudFront 캐싱 갱신 문제로 실시간성 유지가 어렵습니다.",
    "SelectB": "여러 AWS Region에 Amazon EC2 인스턴스를 생성하고, 플레이어 데이터를 각 EC2 인스턴스에 저장합니다. Amazon Route 53 geolocation 레코드를 사용하여 사용자를 가장 가까운 EC2 인스턴스로 유도합니다.",
    "SelectB_Commentary": "다수의 EC2 인스턴스를 전 세계에 직접 운영하면 관리 오버헤드가 크고, 분산된 인스턴스 간 데이터 동기화가 복잡해집니다.",
    "SelectC": "Amazon ElastiCache for Redis 클러스터를 배포하고, 플레이어 데이터를 ElastiCache 클러스터에 저장합니다.",
    "SelectC_Commentary": "Redis는 인메모리 캐싱으로 매우 빠른 응답을 제공하며, RDB 스냅샷 및 AOF 기능으로 디스크에 데이터를 안전하게 보존하여 재시작 시에도 데이터가 유지됩니다.",
    "SelectD": "Amazon ElastiCache for Memcached 클러스터를 배포하고, 플레이어 데이터를 ElastiCache 클러스터에 저장합니다.",
    "SelectD_Commentary": "Memcached는 디스크 지속성 기능을 제공하지 않으므로 애플리케이션 재시작 시 데이터 손실 위험이 큽니다.",
    "Question_Description_recommedations": [
      "Q132",
      "Q506",
      "Q158",
      "Q888",
      "Q1005"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q501",
      "Q672"
    ],
    "SelectB_recommedations": [
      "Q976",
      "Q692",
      "Q582"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q557",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q229",
      "Q746",
      "Q704"
    ]
  },
  {
    "Question_Number": "Q916",
    "Question_Description": "한 회사가 AWS 상에서 민감한 데이터를 처리하는 애플리케이션을 설계하고 있습니다. 해당 애플리케이션은 여러 고객의 재무 데이터를 저장하고 처리합니다. 컴플라이언스 요구사항에 따라, 각 고객의 데이터는 안전하고 중앙화된 키 관리 솔루션을 사용하여 별도로 암호화되어야 합니다. 회사는 AWS Key Management Service(AWS KMS)를 활용해 암호화를 구현하고자 합니다. 가장 적은 운영 오버헤드를 사용하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145202-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서로 다른 고객의 민감한 데이터를 하나의 애플리케이션에서 처리할 때, 각 고객의 데이터를 안전하게 분리하고 암호화하는 방법을 묻습니다. 컴플라이언스 요구사항에 의해 고객별 독립된 키가 필요하며, 이를 AWS KMS로 중앙화된 방식으로 관리해야 합니다. 수동으로 키를 저장하거나 별도의 하드웨어 보안 장치를 배포하는 것은 오버헤드를 높이므로, 고객별 AWS KMS Key를 생성하고 세밀한 권한 관리와 감사 로깅을 활용하는 방식이 가장 효과적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "민감한 데이터",
      "고객별 별도 암호화",
      "재무 데이터",
      "운영 오버헤드 최소화",
      "AWS Key Management Service"
    ],
    "Terms": [
      "AWS KMS",
      "Hardware Security Appliance",
      "Amazon S3 Bucket",
      "Server-Side Encryption",
      "액세스 제어",
      "로그잉"
    ],
    "SelectA": "각 고객을 위한 고유 암호화 키를 생성하고, Amazon S3 버킷에 저장한 후 서버 사이드 암호화를 활성화합니다.",
    "SelectA_Commentary": "직접 키를 생성해 S3에 저장하는 것은 중앙화된 키 관리가 아니며, 키 관리와 업데이트 절차가 복잡해져 운영 오버헤드가 높아집니다.",
    "SelectB": "AWS 환경에 하드웨어 보안 어플라이언스(Hardware Security Appliance)를 배포하고, 고객이 제공하는 암호화 키를 안전하게 저장합니다. 해당 장치를 AWS KMS와 통합해 애플리케이션 내 민감 데이터를 암호화합니다.",
    "SelectB_Commentary": "하드웨어 보안 어플라이언스는 초기 도입 및 유지보수 비용이 크고, 관리가 복잡해져 오버헤드가 증가합니다.",
    "SelectC": "애플리케이션 전체 민감 데이터를 암호화하기 위해 단일 AWS KMS 키를 생성합니다.",
    "SelectC_Commentary": "고객별로 별도 키를 사용해야 하는 요구사항을 충족하지 못하며, 컴플라이언스 측면에서 부적합합니다.",
    "SelectD": "각 고객의 데이터에 대해 개별적인 AWS KMS 키를 생성하고, 세밀한 액세스 제어와 로깅을 활성화합니다.",
    "SelectD_Commentary": "고객별 키 분리와 중앙 집중형 키 관리를 모두 만족하며, AWS KMS에서 제공하는 감사 로깅으로 오버헤드를 최소화하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q681",
      "Q793",
      "Q550",
      "Q640",
      "Q371"
    ],
    "SelectA_recommedations": [
      "Q825",
      "Q44",
      "Q925"
    ],
    "SelectB_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q831",
      "Q592"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q831",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q917",
    "Question_Description": "한 회사가 고객 주문을 처리하기 위한 탄력적인 웹 애플리케이션을 설계해야 합니다. 이 웹 애플리케이션은 고객 경험에 영향을 주지 않고 고객 주문을 손실하지 않으면서, 웹 트래픽과 애플리케이션 사용량 증가를 자동으로 처리할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145212-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 트래픽 급증 시에도 주문이 손실되지 않도록 높은 가용성과 자동 확장 기능을 갖춘 아키텍처를 설계해야 합니다. 적절한 로드 밸런서, Auto Scaling, 메시징 큐, Multi-AZ 데이터베이스를 결합해 장애를 최소화하고 주문을 안정적으로 처리하는 것이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "탄력적인 웹 애플리케이션",
      "자동 확장",
      "고객 주문",
      "고객 경험",
      "주문 손실 방지",
      "Multi-AZ"
    ],
    "Terms": [
      "NAT Gateway",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Gateway Load Balancer (GWLB)",
      "Amazon EC2 Auto Scaling",
      "AWS Lambda",
      "Amazon Redshift",
      "Multi-AZ",
      "Amazon ECS",
      "Amazon DynamoDB",
      "Amazon SQS",
      "Amazon RDS"
    ],
    "SelectA": "NAT Gateway를 사용하여 웹 트래픽을 관리합니다. Amazon EC2 Auto Scaling 그룹으로 고객 주문을 수신, 처리, 저장하고, 처리되지 않은 주문은 AWS Lambda로 캡처하여 저장합니다.",
    "SelectA_Commentary": "NAT Gateway는 주로 아웃바운드 트래픽을 위한 것이므로 웹 트래픽 분산에 적합하지 않습니다. 처리되지 않은 주문을 Lambda로만 관리하는 것도 확장성 면에서 충분하지 않습니다.",
    "SelectB": "Network Load Balancer(NLB)를 사용하여 웹 트래픽을 관리합니다. Application Load Balancer로 NLB에서 받은 고객 주문을 전달하고, Amazon Redshift(Multi-AZ)에 미처리·처리 완료 주문을 저장합니다.",
    "SelectB_Commentary": "NLB와 ALB의 이중 구조는 가능하지만, Amazon Redshift는 데이터 웨어하우징용이라 트랜잭션 처리 및 확장성 면에서 적절하지 않아 주문 처리 워크로드와 맞지 않습니다.",
    "SelectC": "Gateway Load Balancer(GWLB)를 사용하여 웹 트래픽을 관리합니다. Amazon ECS로 고객 주문을 수신·처리하고, GWLB로 미처리 주문을 캡처해 저장하며, Amazon DynamoDB에 처리된 주문을 저장합니다.",
    "SelectC_Commentary": "GWLB는 네트워크 어플라이언스 트래픽 관리용으로 주로 쓰이며, 주문 큐 역할에 적합하지 않습니다. ECS와 DynamoDB 구성은 확장성 면에서 좋지만 전체 흐름이 비효율적입니다.",
    "SelectD": "Application Load Balancer(ALB)로 웹 트래픽을 관리합니다. Amazon EC2 Auto Scaling 그룹으로 고객 주문을 수신·처리하고, 미처리 주문은 Amazon SQS에 저장합니다. 처리된 주문은 Multi-AZ 구성 Amazon RDS에 저장합니다.",
    "SelectD_Commentary": "ALB는 HTTP/HTTPS 기반 트래픽 분산에 적합하며, SQS는 확실한 미처리 주문 저장 및 큐 기능을 제공합니다. Multi-AZ RDS로 고가용성과 확장성을 모두 확보해 요구사항을 충족합니다.",
    "Question_Description_recommedations": [
      "Q58",
      "Q255",
      "Q491",
      "Q735",
      "Q187"
    ],
    "SelectA_recommedations": [
      "Q708",
      "Q210",
      "Q1001"
    ],
    "SelectB_recommedations": [
      "Q545",
      "Q537",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q1012",
      "Q639",
      "Q537"
    ],
    "SelectD_recommedations": [
      "Q390",
      "Q405",
      "Q174"
    ]
  },
  {
    "Question_Number": "Q918",
    "Question_Description": "한 회사가 AWS DataSync를 사용해 온프레미스 시스템에서 AWS로 수백만 개의 파일을 마이그레이션 중입니다. 이 파일들은 평균적으로 크기가 10KB입니다. 회사는 이러한 파일을 Amazon S3에 저장하려고 합니다. 마이그레이션 후 첫 1년 동안 파일은 한두 번 정도 액세스되며 즉시 사용 가능해야 합니다. 1년 후에는 적어도 7년 동안 파일을 보관해야 합니다. 이 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145420-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "비용 최적화된 스토리지 아키텍처를 설계하는 문제입니다. 첫 해에는 즉시 접근을 위해 S3 Standard-IA가 적합하며, 이후 장기 보관은 S3 Deep Archive로 전환하여 비용 효율을 극대화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "파일 마이그레이션",
      "비용 효율",
      "S3 Standard-IA",
      "S3 Deep Archive",
      "라이프사이클 구성"
    ],
    "Terms": [
      "AWS DataSync",
      "Amazon S3",
      "S3 Glacier Instant Retrieval",
      "S3 Glacier Deep Archive",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 Glacier Flexible Retrieval",
      "Lifecycle Configuration",
      "Archive tool"
    ],
    "SelectA": "Archive tool을 사용하여 파일들을 큰 객체로 그룹화합니다. DataSync를 사용해 객체들을 마이그레이션합니다. 첫 1년 동안 S3 Glacier Instant Retrieval에 저장 후 1년 후 S3 Glacier Deep Archive로 전환하고 7년 보존 기간을 설정합니다.",
    "SelectA_Commentary": "별도의 Archive tool 사용으로 운영이 복잡해지며, 초기부터 S3 Glacier Instant Retrieval을 활용하는 구조는 더 높은 비용과 절차를 야기할 수 있습니다.",
    "SelectB": "Archive tool을 사용하여 파일들을 큰 객체로 그룹화합니다. DataSync로 객체를 S3 Standard-IA에 복사합니다. 1년 후 S3 Glacier Instant Retrieval로 전환하고 7년 보존 기간을 설정합니다.",
    "SelectB_Commentary": "Archive tool로 묶은 뒤 이동 과정을 여러 번 거쳐야 하므로 운영이 복잡해지고, 원하는 즉시 접근 요구 사항 충족도 효율적이지 않습니다.",
    "SelectC": "파일에 대한 대상 스토리지 클래스를 S3 Glacier Instant Retrieval로 설정합니다. 1년 후 라이프사이클 정책으로 S3 Glacier Flexible Retrieval로 전환하고 7년 보존 기간을 설정합니다.",
    "SelectC_Commentary": "초기부터 Glacier 계열을 사용하는 것은 즉시 액세스가 필요할 때 비효율적일 수 있으며 보관 정책도 탄력적 활용에 제약이 생길 수 있습니다.",
    "SelectD": "DataSync 태스크를 구성하여 파일을 S3 Standard-Infrequent Access(S3 Standard-IA)로 전송합니다. 1년 후 라이프사이클 구성을 사용하여 파일을 S3 Deep Archive로 전환하고 7년 보존 기간을 설정합니다.",
    "SelectD_Commentary": "필요한 즉시 접근은 S3 Standard-IA로 충족하고, 이후 장기 보관은 비용이 가장 저렴한 S3 Deep Archive로 전환하여 운영이 단순하고 경제적입니다.",
    "Question_Description_recommedations": [
      "Q212",
      "Q759",
      "Q285",
      "Q769",
      "Q829"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q912",
      "Q778"
    ],
    "SelectB_recommedations": [
      "Q126",
      "Q356",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q606",
      "Q126"
    ],
    "SelectD_recommedations": [
      "Q918",
      "Q356",
      "Q415"
    ]
  },
  {
    "Question_Number": "Q919",
    "Question_Description": "한 회사가 최근 온프레미스 Oracle 데이터베이스 워크로드를 Amazon EC2 메모리 최적화 Linux 인스턴스로 리프트 앤 시프트 마이그레이션했습니다. EC2 Linux 인스턴스는 64,000 IOPS가 할당된 1TB Provisioned IOPS SSD(io1) EBS 볼륨을 사용합니다. 마이그레이션 이후 데이터베이스 스토리지 성능은 온프레미스 데이터베이스 성능보다 느립니다. 스토리지 성능을 개선할 수 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145414-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Provisioned IOPS SSD(io1)의 최대 IOPS 한도와 스토리지 성능 병목을 해결하는 방법을 묻습니다. 하나의 io1 볼륨으로는 최대 64,000 IOPS만 제공되므로, 여러 io1 볼륨을 LVM 스트라이프로 구성하여 필요한 IOPS를 확장합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "Oracle 데이터베이스",
      "Amazon EC2",
      "Provisioned IOPS SSD(io1)",
      "스토리지 성능",
      "마이그레이션"
    ],
    "Terms": [
      "Oracle database",
      "Amazon EC2",
      "Provisioned IOPS SSD(io1) EBS volume",
      "Logical Volume Management (LVM)",
      "IOPS",
      "Storage optimized instance"
    ],
    "SelectA": "더 많은 Provisioned IOPS SSD(io1) EBS 볼륨을 추가하고, OS 명령으로 Logical Volume Management(LVM) 스트라이프를 구성합니다.",
    "SelectA_Commentary": "복수의 io1 볼륨을 병렬로 묶어 종합 IOPS를 높여 제한을 우회하며, 실제로 성능을 향상시키는 최적 해결책입니다.",
    "SelectB": "Provisioned IOPS SSD(io1) EBS 볼륨 IOPS를 64,000 이상으로 늘립니다.",
    "SelectB_Commentary": "io1 볼륨당 IOPS 최대값은 64,000이므로 이를 초과할 수 없어 성능 개선으로 이어지지 않습니다.",
    "SelectC": "Provisioned IOPS SSD(io1) EBS 볼륨 용량을 2TB로 늘립니다.",
    "SelectC_Commentary": "볼륨 크기 증대만으로 IOPS 최대값이 증가하지 않아 병목 문제가 해결되지 않습니다.",
    "SelectD": "EC2 Linux 인스턴스를 스토리지 최적화 인스턴스 유형으로 변경하고, Provisioned IOPS SSD(io1) EBS 볼륨은 변경하지 않습니다.",
    "SelectD_Commentary": "인스턴스만 변경해도 EBS 측 IOPS 제한은 그대로이므로 성능 문제가 해결되지 않습니다.",
    "Question_Description_recommedations": [
      "Q299",
      "Q369",
      "Q632",
      "Q857",
      "Q646"
    ],
    "SelectA_recommedations": [
      "Q919",
      "Q299",
      "Q305"
    ],
    "SelectB_recommedations": [
      "Q919",
      "Q299",
      "Q127"
    ],
    "SelectC_recommedations": [
      "Q919",
      "Q299",
      "Q127"
    ],
    "SelectD_recommedations": [
      "Q919",
      "Q299",
      "Q369"
    ]
  },
  {
    "Question_Number": "Q920",
    "Question_Description": "한 회사가 Amazon EC2에서 호스팅하던 웹 애플리케이션의 모놀리식 아키텍처를 서버리스 마이크로서비스 아키텍처로 마이그레이션하려고 합니다. 회사는 이벤트 기반(event-driven), 느슨하게 결합된 아키텍처를 지원하는 AWS 서비스를 사용하여 publish/subscribe(pub/sub) 패턴을 구현하고자 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145415-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 모놀리식 구조에서 서버리스 마이크로서비스로 전환하며, 이벤트 기반(pub/sub) 아키텍처를 최소 비용으로 구성하는 방법을 묻습니다. Amazon API Gateway에는 REST API와 HTTP API가 있는데, HTTP API가 더 단순하고 가격이 낮으며 SNS를 통해 손쉽게 pub/sub 패턴을 구현할 수 있어 비용 측면에서 가장 효율적입니다. 따라서 Amazon API Gateway HTTP API와 SNS를 사용하는 방식이 모놀리식에서 벗어나 느슨하게 결합된 이벤트 아키텍처를 구축하면서도 비용을 줄이기에 가장 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "이벤트 기반",
      "느슨한 결합",
      "서버리스 마이크로서비스",
      "비용 효율",
      "publish/subscribe"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Lambda",
      "Amazon API Gateway REST API",
      "Amazon API Gateway HTTP API",
      "Amazon Simple Notification Service (Amazon SNS)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Kinesis Data Streams",
      "enhanced fan-out"
    ],
    "SelectA": "Amazon API Gateway REST API를 구성해 AWS Lambda function을 호출하고, 해당 function이 Amazon SQS queue로 이벤트를 게시하도록 설정합니다. 하나 이상의 구독자를 구성해 SQS queue에서 이벤트를 읽게 합니다.",
    "SelectA_Commentary": "REST API는 기능이 풍부하지만 HTTP API 대비 비용이 더 높습니다. 또한 SQS는 pub/sub보다는 주로 메시지 큐 패턴에 적합해 요구사항과 약간 다릅니다.",
    "SelectB": "Amazon API Gateway REST API를 구성해 AWS Lambda function을 호출하고, 해당 function이 Amazon SNS topic으로 이벤트를 게시하도록 설정합니다. 하나 이상의 구독자를 구성해 SNS topic에서 이벤트를 수신하도록 합니다.",
    "SelectB_Commentary": "pub/sub 패턴 구현은 가능하나, REST API 방식으로 인한 추가 비용으로 인해 가장 비용 효율적이지는 않습니다.",
    "SelectC": "Amazon API Gateway WebSocket API를 구성해 Amazon Kinesis Data Streams(Enhanced fan-out 활성)로 데이터를 전송합니다. 하나 이상의 구독자를 구성해 데이터 스트림에서 이벤트를 수신하도록 합니다.",
    "SelectC_Commentary": "Kinesis Data Streams는 대규모 스트리밍 데이터에 유용하지만 SNS 기반보다 복잡하고 비용도 더 들 수 있어 단순 pub/sub 용도에 과한 솔루션입니다.",
    "SelectD": "Amazon API Gateway HTTP API를 구성해 AWS Lambda function을 호출하고, 해당 function이 Amazon SNS topic으로 이벤트를 게시하도록 설정합니다. 하나 이상의 구독자를 구성해 topic에서 이벤트를 수신하도록 합니다.",
    "SelectD_Commentary": "HTTP API는 REST API 대비 저비용이며, SNS를 통해 간단한 pub/sub 패턴을 구현해 느슨하게 결합된 이벤트 아키텍처를 가장 비용 효율적으로 구축할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q505",
      "Q167",
      "Q238",
      "Q316",
      "Q671"
    ],
    "SelectA_recommedations": [
      "Q220",
      "Q316",
      "Q140"
    ],
    "SelectB_recommedations": [
      "Q220",
      "Q770",
      "Q800"
    ],
    "SelectC_recommedations": [
      "Q591",
      "Q220",
      "Q373"
    ],
    "SelectD_recommedations": [
      "Q220",
      "Q770",
      "Q800"
    ]
  },
  {
    "Question_Number": "Q921",
    "Question_Description": "한 회사가 최근 모놀리식 애플리케이션을 Amazon EC2 인스턴스와 Amazon RDS로 마이그레이션했습니다. 애플리케이션은 모듈들이 긴밀하게 결합되어 있어 단일 EC2 인스턴스에서만 동작하도록 설계되었습니다. 회사는 피크 사용 시간에 EC2 인스턴스의 CPU 사용률이 높아지고, 이는 Amazon RDS의 읽기 요청 성능 저하로 이어지는 것을 관찰했습니다. 회사는 높은 CPU 사용률을 낮추고 읽기 요청 성능을 개선하고자 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145343-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "단일 인스턴스 구조로 인해 수평 확장이 어려우므로 EC2 인스턴스를 더 큰 사양으로 교체하고, 읽기 부하를 RDS Read Replica로 분산하여 성능 문제를 해결하는 것이 핵심입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.3"
    ],
    "Keywords": [
      "단일 EC2 인스턴스",
      "CPU 사용률",
      "Amazon RDS",
      "읽기 요청 성능",
      "모놀리식 애플리케이션",
      "RDS Read Replica"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "CPU Utilization",
      "Auto Scaling Group",
      "RDS Read Replica",
      "RDS DB Instance",
      "Monolithic Application"
    ],
    "SelectA": "EC2 인스턴스를 CPU 용량이 더 큰 타입으로 리사이징합니다. Auto Scaling 그룹은 최소값과 최대값을 1로 설정합니다. RDS Read Replica를 구성해 읽기 요청을 처리합니다.",
    "SelectA_Commentary": "단일 인스턴스 구조를 유지하면서도 더 큰 EC2 인스턴스와 RDS Read Replica로 읽기 부하를 분산해 CPU 사용률과 RDS 성능 문제를 효과적으로 해결합니다.",
    "SelectB": "EC2 인스턴스를 CPU 용량이 더 큰 타입으로 리사이징합니다. Auto Scaling 그룹은 최소값과 최대값을 1로 설정합니다. RDS Read Replica를 추가하고 모든 읽기/쓰기를 Replica로 리디렉션합니다.",
    "SelectB_Commentary": "RDS Read Replica는 읽기 전용이므로 쓰기 트래픽은 처리할 수 없습니다. 쓰기 요청은 여전히 기본 DB 인스턴스로 보내야 합니다.",
    "SelectC": "Auto Scaling 그룹을 최소 1, 최대 2로 설정합니다. RDS DB 인스턴스를 CPU 용량이 더 큰 인스턴스 타입으로 리사이징합니다.",
    "SelectC_Commentary": "모놀리식 구조로 인해 다중 인스턴스 실행이 어려우며, RDS를 리사이징해도 읽기 부하 분산 없이 CPU 문제와 읽기 성능 저하를 모두 해결하기엔 부족합니다.",
    "SelectD": "EC2 인스턴스를 CPU 용량이 더 큰 타입으로 리사이징합니다. Auto Scaling 그룹은 최소값과 최대값을 1로 설정합니다. RDS DB 인스턴스를 CPU 용량이 더 큰 인스턴스 타입으로 리사이징합니다.",
    "SelectD_Commentary": "EC2와 RDS 양쪽을 리사이징하지만, 여전히 읽기 부하를 단일 DB 인스턴스가 처리해야 하므로 효율적인 읽기 성능 분산에 한계가 있습니다.",
    "Question_Description_recommedations": [
      "Q193",
      "Q910",
      "Q386",
      "Q857",
      "Q746"
    ],
    "SelectA_recommedations": [
      "Q921",
      "Q910",
      "Q386"
    ],
    "SelectB_recommedations": [
      "Q921",
      "Q910",
      "Q386"
    ],
    "SelectC_recommedations": [
      "Q674",
      "Q386",
      "Q95"
    ],
    "SelectD_recommedations": [
      "Q921",
      "Q910",
      "Q386"
    ]
  },
  {
    "Question_Number": "Q922",
    "Question_Description": "한 회사가 개발자 팀에게 회사의 AWS 리소스에 대한 액세스 권한을 부여해야 합니다. 회사는 리소스에 대해 높은 수준의 보안을 유지해야 하며, 중요 데이터에 대한 무단 액세스를 방지할 수 있는 액세스 제어 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145676-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 개발자가 회사의 AWS 리소스에 접근할 때, 민감 데이터에 대한 무단 액세스를 방지하기 위해 가장 안전하면서도 유연한 권한 부여 방식을 찾는 것입니다. IAM roles를 활용하여 필요 최소 권한(principle of least privilege)을 부여하면, 개별 사용자마다 세분화된 권한을 정의할 수 있어 보안을 극대화할 수 있습니다. 이는 공유 자격 증명이나 단순 접근 키 사용보다 훨씬 안전하고 유지보수가 용이합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "개발자 팀",
      "민감 데이터",
      "principle of least privilege",
      "IAM role",
      "fine-grained permissions"
    ],
    "Terms": [
      "IAM user credentials",
      "IAM roles",
      "fine-grained permissions",
      "principle of least privilege",
      "IAM access keys",
      "AWS Cognito",
      "user pool",
      "programmatic access",
      "API calls"
    ],
    "SelectA": "각 개발자 팀 구성원의 IAM 사용자 자격 증명을 공유하여 액세스 관리를 단순화하고 개발 워크플로우를 간소화합니다.",
    "SelectA_Commentary": "자격 증명을 팀원 간 공유하면 보안 감사가 어려워지고 무단 액세스 위험이 높아집니다.",
    "SelectB": "원칙적으로 최소 권한(principle of least privilege)을 기반으로 세분화된 권한을 가진 IAM roles를 정의하고 각 개발자에게 IAM role을 할당합니다.",
    "SelectB_Commentary": "각 사용자가 필요한 권한만 부여받도록 해 민감 데이터 보호에 효과적이며, 역할 기반 접근으로 유지보수와 보안이 모두 향상됩니다.",
    "SelectC": "AWS 리소스에 대한 프로그래밍 방식의 액세스 권한을 부여하기 위해 IAM access keys를 생성합니다. 개발자만 이 access keys를 사용해 API 호출로 리소스에 접근하도록 허용합니다.",
    "SelectC_Commentary": "access key는 분실·유출 위험이 있으며, 최소 권한 적용 및 권한 모니터링에 제한적입니다.",
    "SelectD": "AWS Cognito user pool을 생성하고, 해당 user pool을 사용해 개발자에게 AWS 리소스 접근 권한을 부여합니다.",
    "SelectD_Commentary": "Cognito user pool은 주로 애플리케이션 최종 사용자 인증에 적합하며, 세밀한 권한 제어를 위해 IAM roles가 더 적합합니다.",
    "Question_Description_recommedations": [
      "Q313",
      "Q831",
      "Q592",
      "Q548",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q429",
      "Q122",
      "Q665"
    ],
    "SelectB_recommedations": [
      "Q387",
      "Q418",
      "Q477"
    ],
    "SelectC_recommedations": [
      "Q222",
      "Q780",
      "Q476"
    ],
    "SelectD_recommedations": [
      "Q1011",
      "Q366",
      "Q200"
    ]
  },
  {
    "Question_Number": "Q923",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 모놀리식 웹 애플리케이션을 호스팅하고 있습니다. 최근 특정 시간대에 애플리케이션 사용자가 성능 저하를 호소했으며, Amazon CloudWatch 지표 분석 결과 해당 시간대 CPU 사용률이 100%임을 확인했습니다. 회사는 이 성능 문제를 해결하고 애플리케이션 가용성을 개선하고자 합니다. 가장 비용 효율적인 방식으로 이 요구사항을 충족하기 위해 어떤 결합된 조치 두 가지를 취해야 할까요?",
    "Answer": "A,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145038-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제의 핵심은 과부하로 인해 CPU 사용률이 100%가 되어 성능이 저하되는 동시에, 애플리케이션 가용성(High Availability)까지 확보해야 한다는 점입니다. AWS Compute Optimizer를 통해 적절한 인스턴스 타입을 추천받아 새로 구성함으로써 과부하를 완화하고, Auto Scaling group과 ALB를 활용해 여러 인스턴스를 운영함으로써 가용성을 향상시키는 접근이 가장 비용 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "CPU 사용률 100%",
      "성능 문제",
      "가용성 개선",
      "비용 효율적"
    ],
    "Terms": [
      "Amazon EC2",
      "monolithic web application",
      "Amazon CloudWatch",
      "AWS Compute Optimizer",
      "instance type",
      "Auto Scaling group",
      "Application Load Balancer (ALB)",
      "AMI (Amazon Machine Image)"
    ],
    "SelectA": "Use AWS Compute Optimizer to obtain a recommendation for an instance type to scale vertically.",
    "SelectA_Commentary": "AWS Compute Optimizer는 현재 인스턴스의 사용 패턴을 분석하여 더 적절하고 비용 효율적인 인스턴스 타입을 추천해줍니다. CPU 부족 문제를 해결하기 위해 큰 인스턴스로 업그레이드할 수 있는 첫 단계가 됩니다.",
    "SelectB": "Create an Amazon Machine Image (AMI) from the web server. Reference the AMI in a new launch template.",
    "SelectB_Commentary": "기존 EC2 인스턴스를 기반으로 AMI를 생성하고 이를 Launch Template에 반영하면 새로운 인스턴스들을 동일한 환경으로 확장, 배포하는 데 유용합니다. 다만 이 단계만으로는 가용성 향상을 위한 Auto Scaling 처리가 언급되지 않습니다.",
    "SelectC": "Create an Auto Scaling group and an Application Load Balancer to scale vertically.",
    "SelectC_Commentary": "ASG와 ALB는 주로 수평적 확장(여러 개의 인스턴스 운영)을 위한 구성입니다. '수직적 스케일링(vertical scaling)'과는 맞지 않아 실제로 적용하기 어렵습니다.",
    "SelectD": "Use AWS Compute Optimizer to obtain a recommendation for an instance type to scale horizontally.",
    "SelectD_Commentary": "Compute Optimizer는 주로 현재 인스턴스 리소스 사용량을 기반으로 인스턴스 규모나 패밀리를 추천합니다. '수평적 확장' 개념 자체를 직접적으로 추천하기보다는 인스턴스 사이즈 조정에 초점을 두므로 문제 의도와는 조금 다릅니다.",
    "SelectE": "Create an Auto Scaling group and an Application Load Balancer to scale horizontally.",
    "SelectE_Commentary": "여러 인스턴스를 두고 ALB를 통해 트래픽을 분산하면 CPU 부하를 줄이고, 인스턴스 장애 시에도 다른 인스턴스가 서비스하므로 가용성이 크게 높아집니다.",
    "Question_Description_recommedations": [
      "Q150",
      "Q244",
      "Q757",
      "Q790",
      "Q892"
    ],
    "SelectA_recommedations": [
      "Q660",
      "Q595",
      "Q729"
    ],
    "SelectB_recommedations": [
      "Q762",
      "Q963",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q405",
      "Q595",
      "Q275"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q595",
      "Q405"
    ],
    "SelectE_recommedations": [
      "Q405",
      "Q275",
      "Q595"
    ]
  },
  {
    "Question_Number": "Q924",
    "Question_Description": "한 회사는 모든 비즈니스 애플리케이션을 AWS Cloud에서 운영하고 있습니다. 이 회사는 AWS Organizations를 사용하여 여러 개의 AWS 계정을 관리하고 있습니다. 한 Solutions Architect가 IAM 사용자에게 부여된 모든 권한을 검토하여, 필요한 것보다 많은 권한을 가진 IAM 사용자를 식별해야 합니다. 가장 적은 관리 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144976-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 IAM 사용자 권한에 대한 과도한 부여를 확인하고 최소 권한 원칙을 적용하는 방법을 묻습니다. IAM Access Analyzer를 사용하면 조직 전반의 리소스 및 계정 정책을 자동으로 분석해, 필요한 권한 이상으로 부여된 권한을 효율적으로 식별할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "AWS Cloud",
      "AWS Organizations",
      "IAM 사용자 권한",
      "관리 오버헤드 최소화"
    ],
    "Terms": [
      "IAM Access Analyzer",
      "AWS Cloud",
      "AWS Organizations",
      "IAM",
      "Network Access Analyzer",
      "AWS CloudWatch alarm",
      "Amazon Inspector"
    ],
    "SelectA": "Network Access Analyzer를 사용하여 회사의 모든 AWS 계정에서 액세스 권한을 검토합니다.",
    "SelectA_Commentary": "Network Access Analyzer는 네트워크 경로 분석 도구로, IAM 권한 초과 부여 식별과는 직접적인 관련이 없어 요구사항을 충족하기 어렵습니다.",
    "SelectB": "IAM 사용자가 AWS 계정 내 리소스를 생성 또는 수정할 때 활성화되는 AWS CloudWatch alarm을 생성합니다.",
    "SelectB_Commentary": "이 방법은 리소스 작업이 발생할 때마다 알림을 받을 수 있지만, 이미 부여된 과도한 권한을 식별해 제거하는 데에는 비효율적입니다.",
    "SelectC": "AWS Identity and Access Management (IAM) Access Analyzer를 사용하여 회사의 모든 리소스와 계정을 검토합니다.",
    "SelectC_Commentary": "IAM Access Analyzer는 조직 전반의 정책을 분석하여 필요 이상의 권한 부여를 빠르고 정확하게 파악할 수 있어, 최소한의 관리 오버헤드로 요구사항을 충족하는 최적의 솔루션입니다.",
    "SelectD": "Amazon Inspector를 사용하여 기존 IAM 정책의 취약점을 찾습니다.",
    "SelectD_Commentary": "Amazon Inspector는 주로 EC2 환경 취약성 점검에 특화되어 있으며, IAM 사용자의 과도한 권한 분석과는 직접적 연관성이 적습니다.",
    "Question_Description_recommedations": [
      "Q89",
      "Q82",
      "Q222",
      "Q476",
      "Q1018"
    ],
    "SelectA_recommedations": [
      "Q529",
      "Q426",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q27",
      "Q222",
      "Q780"
    ],
    "SelectC_recommedations": [
      "Q222",
      "Q476",
      "Q780"
    ],
    "SelectD_recommedations": [
      "Q429",
      "Q222",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q925",
    "Question_Description": "한 회사가 규제 준수를 위해 새로운 데이터 보존 정책을 구현해야 합니다. 이 정책의 일환으로, Amazon S3 버킷에 저장된 민감한 문서는 일정 기간 동안 삭제나 수정이 불가능하도록 보호되어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145213-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3 Object Lock을 통해 민감한 문서를 일정 기간 동안 절대 삭제할 수 없도록 설정해 규제 준수를 보장하는 방법을 묻습니다. compliance mode가 가장 엄격한 보존을 제공합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "규제 준수",
      "데이터 보존 정책",
      "민감한 문서",
      "삭제 수정 방지",
      "S3 Object Lock",
      "compliance mode"
    ],
    "Terms": [
      "S3 Object Lock",
      "Governance mode",
      "Compliance mode",
      "Versioning",
      "Lifecycle policy",
      "S3 Glacier Flexible Retrieval"
    ],
    "SelectA": "필요한 객체에서 S3 Object Lock을 활성화하고 governance mode를 설정합니다.",
    "SelectA_Commentary": "Governance mode는 루트 사용자 등 특정 권한이 있으면 잠금을 해제할 수 있으므로, 규제 준수에 요구되는 절대적 보호를 보장하지 못합니다.",
    "SelectB": "필요한 객체에서 S3 Object Lock을 활성화하고 compliance mode를 설정합니다.",
    "SelectB_Commentary": "compliance mode는 루트 계정조차 삭제나 수정을 할 수 없어 규정에 따른 엄격한 보존 요구사항을 만족시킵니다.",
    "SelectC": "S3 버킷에 버저닝을 활성화하고 라이프사이클 정책으로 지정된 기간 후 객체를 삭제하도록 설정합니다.",
    "SelectC_Commentary": "버저닝과 라이프사이클 정책만으로는 중간에 객체가 수정·삭제될 가능성을 완전히 막지 못해 규제 준수 요구사항을 충족하기 어렵습니다.",
    "SelectD": "S3 Lifecycle 정책을 통해 객체를 보존 기간 동안 S3 Glacier Flexible Retrieval로 전환하도록 구성합니다.",
    "SelectD_Commentary": "Glacier로 전환은 장기 보관에 유리하지만, 기간 중 삭제나 수정을 전면 금지하지 않으므로 규제 준수 목적에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q825",
      "Q696",
      "Q202",
      "Q154",
      "Q44"
    ],
    "SelectA_recommedations": [
      "Q202",
      "Q825",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q825",
      "Q202"
    ],
    "SelectC_recommedations": [
      "Q122",
      "Q665",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q202",
      "Q965",
      "Q740"
    ]
  },
  {
    "Question_Number": "Q926",
    "Question_Description": "어느 회사가 고객 대상 웹 애플리케이션을 컨테이너에서 실행하고 있습니다. 이 워크로드는 Amazon ECS on AWS Fargate를 사용하며, 애플리케이션은 자원 사용량이 많습니다. 고객에게 24시간 7일 동안 서비스를 제공해야 하며, 단기간에 갑작스럽게 높은 트래픽이 발생할 것으로 예상됩니다. 이 워크로드는 고가용성을 유지해야 합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144978-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 항상 가동되어야 하는 웹 애플리케이션을 가장 적절한 비용으로 운영하는 방법을 묻습니다. Spot 인스턴스는 중단될 위험이 있어 안정적 24/7 운영이 필요하면 권장되지 않습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "고객 대상 웹 애플리케이션",
      "Amazon ECS",
      "AWS Fargate",
      "Fargate Spot",
      "24시간 7일 운영",
      "고가용성",
      "비용 효율",
      "버스트 트래픽",
      "ECS capacity provider",
      "AWS Compute Optimizer",
      "rightsize"
    ],
    "Terms": [
      "Amazon ECS",
      "AWS Fargate",
      "Fargate Spot",
      "Amazon CloudWatch",
      "AWS Compute Optimizer",
      "ECS capacity provider"
    ],
    "SelectA": "ECS capacity provider를 Fargate로 설정하고, 서드파티 툴로 부하 테스트를 수행합니다. Amazon CloudWatch를 통해 Fargate 태스크를 적절히 사이징합니다.",
    "SelectA_Commentary": "부하 테스트와 적정 사이징은 중요하지만 Spot 사용이나 Compute Optimizer 활용이 없어 비용 절감 측면에서 최적이라고 보기 어렵습니다.",
    "SelectB": "안정적인 상태에는 Fargate를, 버스트 트래픽에는 Fargate Spot을 사용하는 ECS capacity provider를 설정합니다.",
    "SelectB_Commentary": "버스트 구간만 Spot에 의존해 비용을 줄일 수 있지만, Spot 중단 시 예상치 못한 트래픽 처리 실패 가능성이 있어 고가용성 유지가 위험할 수 있습니다.",
    "SelectC": "안정적인 상태에는 Fargate Spot을, 버스트 트래픽에는 Fargate를 사용하는 ECS capacity provider를 설정합니다.",
    "SelectC_Commentary": "항상 필요한 기본 용량에 Spot을 사용하면 중단 위험이 커 24/7 운영에 부적합합니다.",
    "SelectD": "ECS capacity provider를 Fargate로 설정합니다. AWS Compute Optimizer를 사용해 Fargate 태스크를 적절히 사이징합니다.",
    "SelectD_Commentary": "Spot을 사용하지 않아 중단 가능성이 없고, Compute Optimizer로 자원을 적절히 조정함으로써 안정성과 비용 효율을 동시에 달성해 정답입니다.",
    "Question_Description_recommedations": [
      "Q541",
      "Q485",
      "Q671",
      "Q728",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q926",
      "Q140",
      "Q591"
    ],
    "SelectB_recommedations": [
      "Q926",
      "Q552",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q926",
      "Q552",
      "Q943"
    ],
    "SelectD_recommedations": [
      "Q926",
      "Q715",
      "Q140"
    ]
  },
  {
    "Question_Number": "Q927",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 구축 중입니다. 이 애플리케이션은 Application Load Balancer(ALB) 뒤에 배포된 Amazon EC2 인스턴스에서 호스팅됩니다. 이 회사는 DNS로 Amazon Route 53을 사용하고 있습니다. 이 회사는 DDoS 공격에 대해 사전 대응이 가능한 매니지드 솔루션을 필요로 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145214-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DDoS 방어를 위해 사전 대처와 모니터링이 가능한 매니지드 솔루션을 찾는 것입니다. AWS Shield Advanced를 구독하면 24/7 전문가 지원과 사전 대응형 보호 기능을 통해 즉각적인 DDoS 탐지와 방어를 제공받을 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "DDoS",
      "AWS Shield Advanced",
      "Route 53",
      "ALB",
      "매니지드 솔루션",
      "사전 대응"
    ],
    "Terms": [
      "AWS Config",
      "AWS WAF",
      "Amazon Route 53",
      "AWS Shield Advanced",
      "Amazon EC2",
      "ALB",
      "Amazon S3",
      "Amazon GuardDuty"
    ],
    "SelectA": "AWS Config를 활성화하고, DDoS 공격을 탐지하는 AWS Config managed rule을 구성합니다.",
    "SelectA_Commentary": "AWS Config는 리소스 구성 변경 모니터링이 주 목적일 뿐, 실시간 DDoS 방어나 전문가 지원 기능은 제공하지 못해 요구사항을 충족하지 못합니다.",
    "SelectB": "AWS WAF를 ALB에 활성화한 뒤, DDoS 공격을 감지 및 차단하는 웹 ACL을 생성하여 ALB에 연결합니다.",
    "SelectB_Commentary": "AWS WAF는 주로 웹 애플리케이션 계층 보호와 규칙 기반 필터링에 집중하며, DDoS 전체 대응을 위한 사전 전문가 지원을 제공하는 매니지드 서비스는 아닙니다.",
    "SelectC": "ALB 액세스 로그를 Amazon S3에 저장하고, Amazon GuardDuty를 구성하여 DDoS 공격을 탐지하고 자동 예방 조치를 수행하도록 설정합니다.",
    "SelectC_Commentary": "Amazon GuardDuty는 위협 인텔리전스 분석에 중점을 두지만, DDoS 방어 전용 전문가 참여와 사전 보호 기능을 제공하지 않으므로 요구사항에 적합하지 않습니다.",
    "SelectD": "AWS Shield Advanced를 구독하고, Route 53에 호스티드 존을 구성한 뒤, ALB 리소스를 보호 대상으로 추가합니다.",
    "SelectD_Commentary": "AWS Shield Advanced는 24/7 전문가 팀의 사전 개입과 모범 사례 가이드를 통해 DDoS 공격 대응에 최적화된 매니지드 솔루션을 제공합니다.",
    "Question_Description_recommedations": [
      "Q35",
      "Q169",
      "Q701",
      "Q884",
      "Q60"
    ],
    "SelectA_recommedations": [
      "Q396",
      "Q893",
      "Q35"
    ],
    "SelectB_recommedations": [
      "Q749",
      "Q927",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q701",
      "Q927",
      "Q169"
    ],
    "SelectD_recommedations": [
      "Q927",
      "Q893",
      "Q451"
    ]
  },
  {
    "Question_Number": "Q928",
    "Question_Description": "한 회사가 VPC 내에 비디오 스트리밍 웹 애플리케이션을 호스팅하고 있습니다. 이 회사는 실시간 데이터 처리를 위해 TCP 트래픽을 다루는 Network Load Balancer(NLB)를 사용하고 있습니다. 최근 애플리케이션에 대한 무단 접근 시도가 발생했습니다. 회사는 애플리케이션 보안을 강화하고자 하며, 아키텍처의 변경을 최소화하여 무단 접근 시도를 방지하려고 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144979-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이미 운영 중인 Network Load Balancer(NLB)에 대해 무단 접근 시도를 차단하려는 보안 설계 문제입니다. NLB가 Security Group을 공식적으로 지원함에 따라, 재구성 혹은 업그레이드를 통해 NLB에 Security Group을 연결할 수 있습니다. 이 방식은 설정 변경만으로 접근 제어가 가능하므로 아키텍처 변경을 최소화하면서 효과적으로 무단 접근을 방어합니다. AWS WAF는 NLB에 직접 연동되지 않으며, 새로운 NLB를 병렬로 배포하거나 AWS Shield Advanced만으로는 세부 접근 통제를 구현하기 어렵습니다. 따라서 NLB에 Security Group을 적용해서 신뢰할 수 있는 IP 주소만 허용하는 방법이 가장 안전하고 간단합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "비디오 스트리밍 애플리케이션",
      "Network Load Balancer(NLB)",
      "무단 접근",
      "보안 그룹"
    ],
    "Terms": [
      "Network Load Balancer(NLB)",
      "TCP",
      "AWS WAF",
      "Security Group",
      "AWS Shield Advanced"
    ],
    "SelectA": "NLB에 직접 AWS WAF 규칙을 적용하여 무단 트래픽을 필터링합니다.",
    "SelectA_Commentary": "AWS WAF는 NLB에 직접 적용되지 않습니다. Application Load Balancer 또는 CloudFront와 통합할 수 있지만, NLB에는 적용할 수 없어 이 요구사항을 충족하지 못합니다.",
    "SelectB": "신뢰할 수 있는 IP 주소만 허용하도록 보안 그룹을 구성하고, 해당 Security Group을 사용하도록 NLB를 재구성합니다.",
    "SelectB_Commentary": "NLB가 Security Group을 지원하므로, 보안 그룹 규칙으로 원하는 IP 주소만 허용할 수 있습니다. 최소한의 아키텍처 변경으로 무단 접근을 효과적으로 차단하는 최적의 솔루션입니다.",
    "SelectC": "기존 NLB와 병렬로 두 번째 NLB를 배포하고, 엄격한 IP 주소 허용 목록을 구성합니다.",
    "SelectC_Commentary": "두 번째 NLB를 병렬로 배포하는 것은 아키텍처 복잡도가 크게 증가합니다. 기존 접근 경로와의 충돌 문제 등 운용 부담이 커지므로 비효율적입니다.",
    "SelectD": "AWS Shield Advanced를 사용하여 고급 DDoS 방어 기능을 적용하고 무단 접근 시도를 방지합니다.",
    "SelectD_Commentary": "AWS Shield Advanced는 주로 DDoS 공격 방어에 특화되어 있습니다. 특정 IP 기반의 무단 접근을 세밀하게 통제하기에는 추가적인 설정이 필요하며, 이 요구사항을 직접적으로 해결하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q382",
      "Q35",
      "Q1016",
      "Q707",
      "Q169"
    ],
    "SelectA_recommedations": [
      "Q893",
      "Q592",
      "Q313"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q169",
      "Q608"
    ],
    "SelectC_recommedations": [
      "Q803",
      "Q169",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q396",
      "Q970",
      "Q529"
    ]
  },
  {
    "Question_Number": "Q929",
    "Question_Description": "한 의료 회사가 암호화된 Amazon Simple Notification Service (Amazon SNS) 토픽으로 알림을 게시하는 AWS Lambda 함수를 개발하고 있습니다. 이 알림에는 PHI(Protected Health Information)가 포함됩니다. 해당 SNS 토픽은 AWS Key Management Service (AWS KMS) Customer Managed Key를 사용하여 암호화되고 있습니다. 회사는 애플리케이션이 SNS 토픽에 안전하게 메시지를 게시하기 위한 필요한 권한을 갖춰야 합니다. 다음 중 어떤 절차 조합이 이러한 요구 사항을 충족합니까? (3개를 고르시오.)",
    "Answer": "A,C,F",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144981-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS Lambda 함수가 PHI를 포함한 메시지를 Amazon SNS 토픽에 안전하게 게시하기 위해 필요한 권한과 암호화 설정을 어떻게 구상해야 하는지 묻습니다. SNS 토픽과 해당 KMS 키 모두에 대한 Resource Policy 설정과 Lambda IAM 역할 권한이 핵심입니다. A, C, F를 통해 Lambda가 필요한 KMS 권한을 확보하고, SNS 토픽에 안전하게 게시할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "PHI",
      "암호화",
      "Customer Managed Key",
      "Resource Policy",
      "AWS KMS",
      "Lambda",
      "SNS 토픽"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon SNS",
      "AWS Key Management Service (AWS KMS)",
      "Customer Managed Key",
      "Resource Policy",
      "IAM Permissions",
      "PHI",
      "Server-Side Encryption (SSE)"
    ],
    "SelectA": "SNS 토픽에 Lambda 함수가 메시지를 게시할 수 있도록 허용하는 Resource Policy를 생성한다.",
    "SelectA_Commentary": "SNS 토픽 자체에 대한 Resource Policy를 생성해야 Lambda 함수가 합법적으로 접근 가능합니다. 이는 메시지 게시 권한을 명시적으로 부여해주는 중요한 단계입니다.",
    "SelectB": "해당 SNS 토픽에 Customer Managed Key 대신 SSE-KMS 키를 사용하도록 설정한다.",
    "SelectB_Commentary": "이미 Customer Managed Key를 사용 중이므로 SSE-KMS로 전환할 필요가 없고, 요구 사항에도 부합하지 않습니다. 이 선택지는 문제 해결과 직접 관련이 없습니다.",
    "SelectC": "SNS 토픽에서 사용하는 암호화 키에 필요한 AWS KMS 권한을 부여하는 Resource Policy를 생성한다.",
    "SelectC_Commentary": "Lambda가 KMS 키에 접근하도록 Resource Policy를 구성해야 합니다. 키 사용 권한이 없으면 메시지 암호화 또는 복호화가 불가능하므로 필수적인 작업입니다.",
    "SelectD": "SNS 토픽의 Resource Policy 안에 Lambda 함수의 ARN을 명시한다.",
    "SelectD_Commentary": "Lambda 함수 ARNs를 리소스 정책에 명시할 수도 있지만, 문제의 요구사항에서는 Lambda 함수에 대한 직접 게시 권한과 KMS 키 사용 권한이 핵심입니다. 다른 선택지로 해결 가능합니다.",
    "SelectE": "Amazon API Gateway HTTP API를 SNS 토픽에 연결하고, API Gateway Resource Policy를 활용해 토픽에 대한 접근을 제어한다.",
    "SelectE_Commentary": "API Gateway를 거칠 필요는 없습니다. 직접적인 Lambda → SNS 게시 보안 권한이 요구되므로, 불필요하게 복잡해집니다.",
    "SelectF": "Lambda 실행 역할에 AWS KMS의 Customer Managed Key를 사용할 수 있는 IAM 권한을 구성한다.",
    "SelectF_Commentary": "Lambda 함수가 KMS 키를 사용하기 위해서는 해당 키에 대한 encrypt, decrypt, generateDataKey 등의 권한이 필요합니다. 이 선택지는 필수적인 설정입니다.",
    "Question_Description_recommedations": [
      "Q793",
      "Q640",
      "Q931",
      "Q916",
      "Q364"
    ],
    "SelectA_recommedations": [
      "Q936",
      "Q931",
      "Q791"
    ],
    "SelectB_recommedations": [
      "Q793",
      "Q740",
      "Q678"
    ],
    "SelectC_recommedations": [
      "Q793",
      "Q916",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q936",
      "Q791",
      "Q893"
    ],
    "SelectE_recommedations": [
      "Q1019",
      "Q34",
      "Q159"
    ],
    "SelectF_recommedations": [
      "Q640",
      "Q550",
      "Q916"
    ]
  },
  {
    "Question_Number": "Q930",
    "Question_Description": "한 회사에 직원용 웹 포털이 있습니다. 직원들은 이 포털에 로그인하여 급여 명세를 조회합니다. 회사는 직원들이 스캔한 문서를 업로드할 수 있는 새로운 시스템을 개발하고 있습니다. 업로드된 문서에서 텍스트 기반 데이터를 추출하고, 이 추출된 정보를 각 직원의 청구 ID에 연결하여 처리하려고 합니다. 웹 포털은 100% 가용성을 유지해야 하며, 문서 추출 프로그램은 하루에 필요할 때만 비정기적으로 실행됩니다. 또한 새로운 시스템은 확장 가능하고 비용 효율적이어야 하며, 기존 웹 포털에 대한 수정은 최소화되어야 합니다. 회사는 소스 코드 변경 없이 구현하기를 원합니다. 다음 중 이러한 요구 사항을 가장 적은 구현 노력으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145215-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 이미 운영 중인 웹 포털의 100% 가용성을 유지하면서, 문서 업로드 후 텍스트 추출 프로그램을 비용 효율적으로 확장하고자 하는 시나리오입니다. 변경 없이 기존 아키텍처를 활용하며, 언젠가 발생할 수 있는 컴퓨팅 부담에도 대비해야 합니다. Savings Plan을 통해 EC2 및 Lambda 같은 사용량 기반 서비스 비용을 절감할 수 있으며, 이를 활용해 웹 포털과 문서 추출을 같은 Auto Scaling group에서 처리하면 코드 변경 없이 안정적이고 확장 가능한 아키텍처를 구현할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 효율성",
      "100% 가용성",
      "확장 가능",
      "기존 웹 포털",
      "코드 변경 최소화",
      "문서 추출 프로그램"
    ],
    "Terms": [
      "Amazon EC2",
      "On-Demand Instances",
      "Spot Instances",
      "Auto Scaling group",
      "AWS Lambda",
      "Amazon S3",
      "Amazon API Gateway",
      "Savings Plan"
    ],
    "SelectA": "Amazon EC2 On-Demand Instances를 Auto Scaling group으로 웹 포털을 운영하고, AWS Lambda 함수를 사용하여 문서 추출 프로그램을 실행합니다. 새 문서가 업로드될 때 Lambda 함수를 호출합니다.",
    "SelectA_Commentary": "On-Demand Instances는 안정적이지만 미리 할인된 요금 없이 사용하면 장기적으로 비용이 높아질 수 있습니다. Lambda 트리거 구성을 위해 약간의 설정 변경이 필요하며, Savings Plan을 사용할 수 없는 점이 아쉽습니다.",
    "SelectB": "Amazon EC2 Spot Instances를 Auto Scaling group으로 웹 포털을 운영하고, 문서 추출 프로그램도 Spot Instances에서 실행합니다. 새 문서 업로드 시 문서 추출 프로그램 인스턴스를 시작합니다.",
    "SelectB_Commentary": "Spot Instances는 저렴하지만 언제든 종료될 수 있어 100% 가용성을 요구하는 웹 포털에는 적합하지 않습니다.",
    "SelectC": "웹 포털과 문서 추출 프로그램에 대해 Savings Plan을 구매하고, 이를 Auto Scaling group에서 함께 실행합니다.",
    "SelectC_Commentary": "기존 EC2 기반 웹 포털을 그대로 유지하면서 비용을 줄일 수 있고, 문서 추출 프로그램도 함께 돌릴 수 있습니다. 코드 변경 없이 확장성과 비용 효율을 모두 만족하므로 최적의 선택입니다.",
    "SelectD": "Amazon S3 버킷을 생성하여 웹 포털을 호스팅하고, Amazon API Gateway와 AWS Lambda를 통해 기존 기능을 구현합니다. 새 문서 업로드 API가 호출될 때 Lambda 함수를 통해 문서 추출 프로그램을 실행합니다.",
    "SelectD_Commentary": "이미 운영 중인 동적인 웹 포털을 단순 부분 수정이 아니라 S3 정적 웹 호스팅으로 완전히 옮겨야 하므로, 코드 및 아키텍처 변경 범위가 커집니다.",
    "Question_Description_recommedations": [
      "Q656",
      "Q794",
      "Q997",
      "Q49",
      "Q630"
    ],
    "SelectA_recommedations": [
      "Q290",
      "Q1013",
      "Q441"
    ],
    "SelectB_recommedations": [
      "Q290",
      "Q441",
      "Q937"
    ],
    "SelectC_recommedations": [
      "Q885",
      "Q543",
      "Q290"
    ],
    "SelectD_recommedations": [
      "Q993",
      "Q469",
      "Q140"
    ]
  },
  {
    "Question_Number": "Q931",
    "Question_Description": "한 미디어 회사가 us-east-1 리전에 다중 계정 AWS 환경을 보유하고 있습니다. 이 회사는 프로덕션 계정에 성능 지표를 발행하는 Amazon SNS 토픽을 가지고 있으며, 관리자 계정에서 로그 데이터를 처리하고 분석하기 위한 AWS Lambda 함수를 운영 중입니다. 중요한 지표가 보고될 때, 프로덕션 계정에 있는 SNS 토픽에서 관리자 계정의 Lambda 함수를 호출해야 합니다. 이러한 요구사항을 충족하기 위해서는 어떤 단계를 결합해야 합니까? (2개를 선택하세요.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145416-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프로덕션 계정의 SNS 토픽에서 출판되는 중요한 지표 정보를 관리자 계정의 Lambda 함수가 받아 처리하도록 구성하는 방법을 묻습니다. cross-account 구성에서는 Lambda 함수 측의 IAM 리소스 정책으로 Amazon SNS에서의 호출을 허용하고, 메시지를 안정적으로 전달하기 위해 Amazon SQS 큐를 사용하는 방안이 자주 활용됩니다. SNS 토픽 직접 구독을 위해서는 Lambda에 대한 허용 정책이 필요하고, SQS를 중간에 두어 메시지를 버퍼링할 수도 있습니다. EventBridge나 S3, Athena 방식은 각각 다른 목적 및 절차가 필요하므로 요구사항(신속한 Lambda 호출과 로그 분석)에는 적합하지 않습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "다중 계정 AWS 환경",
      "Amazon SNS 토픽",
      "AWS Lambda 함수",
      "cross-account",
      "IAM 리소스 정책",
      "SQS 버퍼링"
    ],
    "Terms": [
      "Amazon SNS",
      "AWS Lambda",
      "IAM 리소스 정책",
      "Amazon SQS",
      "Amazon EventBridge",
      "Amazon S3",
      "Amazon Athena",
      "Cross-Account"
    ],
    "SelectA": "Lambda 함수에 Amazon SNS가 함수를 호출할 수 있도록 허용하는 IAM 리소스 정책을 생성합니다.",
    "SelectA_Commentary": "SNS에서 Lambda로 직접 메시지를 전달하려면 Lambda 함수 측에 SNS 호출을 허용하는 리소스 기반 정책이 필요합니다. 이를 통해 cross-account에서 함수를 안전하게 호출할 수 있습니다.",
    "SelectB": "관리자 계정에 Amazon Simple Queue Service (Amazon SQS) 대기열을 구현해 프로덕션 계정의 SNS 토픽 메시지를 버퍼링하고, 해당 SQS 대기열이 Lambda 함수를 호출하도록 구성합니다.",
    "SelectB_Commentary": "SNS → SQS → Lambda 구조를 사용하면 메시지를 안정적으로 버퍼링하고, Lambda 호출 실패 시 재처리 등을 관리하기가 용이해집니다.",
    "SelectC": "SNS 토픽에 대한 IAM 정책을 생성하여 Lambda 함수가 해당 토픽을 구독할 수 있도록 허용합니다.",
    "SelectC_Commentary": "Lambda가 직접 토픽을 구독하기 위해서는 지시된 정책뿐 아니라 리소스 정책이 필요합니다. 하지만 문제에서 요구하는 cross-account 호출 보안을 위해서는 Lambda 함수 쪽에 SNS 호출을 허용하는 리소스 정책(A)과 메시지 버퍼링(B)가 핵심입니다.",
    "SelectD": "프로덕션 계정에서 Amazon EventBridge 규칙을 사용하여 SNS 토픽 알림을 캡처하고, 해당 규칙이 관리자 계정의 Lambda 함수로 알림을 전달하도록 구성합니다.",
    "SelectD_Commentary": "EventBridge를 통한 전달도 가능하지만 SNS 자체의 구독 설정 및 IAM 리소스 정책을 이용하는 것이 운영과 보안 측면에서 더 단순화된 접근이며, 문제 요구사항에 더 직접 부합합니다.",
    "SelectE": "프로덕션 계정의 Amazon S3 버킷에 성능 지표를 저장하고, 관리자 계정에서 Amazon Athena를 사용해 지표를 분석합니다.",
    "SelectE_Commentary": "이 방식은 SNS 이벤트 기반으로 즉각 Lambda를 호출하는 요구사항과 거리가 멉니다. 지표 확인 및 분석용으로는 유효하지만, 메시지를 이용한 실시간 처리 시나리오와는 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q289",
      "Q936",
      "Q638",
      "Q974",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q403",
      "Q289",
      "Q931"
    ],
    "SelectB_recommedations": [
      "Q765",
      "Q364",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q429",
      "Q476",
      "Q936"
    ],
    "SelectD_recommedations": [
      "Q931",
      "Q289",
      "Q159"
    ],
    "SelectE_recommedations": [
      "Q44",
      "Q825",
      "Q202"
    ]
  },
  {
    "Question_Number": "Q932",
    "Question_Description": "한 회사가 온프레미스 환경에서 Amazon Elastic Kubernetes Service(Amazon EKS)로 애플리케이션을 마이그레이션 중입니다. 이 회사는 요구사항에 따라 VPC 내의 Pods에 대해 Custom Subnet을 사용해야 합니다. 또한 Pods가 VPC 내에서 보안 통신을 할 수 있어야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145298-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS 환경에서 Pods가 회사의 VPC 내에서 안전하게 통신하도록, 필요한 네트워크 구성을 어떻게 할지 묻습니다. Amazon VPC CNI plugin은 Pods에 VPC 서브넷 기반 IP 주소를 할당해 기본 VPC 리소스처럼 동작하게 하므로 보안 통신 요구사항을 충족하고 Custom Subnet 사용을 지원합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "Amazon EKS",
      "VPC",
      "Pod",
      "Custom Subnet",
      "보안 통신"
    ],
    "Terms": [
      "AWS Transit Gateway",
      "AWS Direct Connect",
      "Amazon VPC CNI plugin",
      "Kubernetes Network Policy",
      "Pod Anti-Affinity",
      "Custom Subnet"
    ],
    "SelectA": "AWS Transit Gateway를 구성하여 Amazon EKS의 Pods에 대한 Custom Subnet 구성을 직접 관리하도록 합니다.",
    "SelectA_Commentary": "Transit Gateway는 VPC 간 연결에 활용되지만, EKS Pods에 직접 Subnet 구성을 부여해주지 않으므로 부적합합니다.",
    "SelectB": "회사의 온프레미스 IP 주소 범위에서 EKS Pods로 직접 연결을 위해 AWS Direct Connect를 생성합니다.",
    "SelectB_Commentary": "Direct Connect는 온프레미스와 AWS를 연결하는 전용 네트워크 서비스로, Pods에 맞는 서브넷 설정이나 VPC 내부 Pod 보안을 직접 해결하지 못합니다.",
    "SelectC": "Amazon VPC CNI plugin을 사용하고, Pods가 사용할 수 있도록 VPC 클러스터 내에 Custom Subnet을 정의합니다.",
    "SelectC_Commentary": "Amazon VPC CNI plugin을 통해 Pods에 VPC IP가 할당되어 VPC 내 보안 통신을 수행하므로 요구사항에 부합하는 최적의 솔루션입니다.",
    "SelectD": "특정 Custom Subnet 범위 내 노드에만 스케줄링되도록 Pod Anti-Affinity 규칙이 있는 Kubernetes Network Policy를 구현합니다.",
    "SelectD_Commentary": "단순 네트워크 정책이나 Anti-Affinity 규칙만으로는 VPC 커스텀 서브넷 구성 및 Pods 간 보안 통신 요구사항을 충분히 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q514",
      "Q805",
      "Q251",
      "Q613",
      "Q371"
    ],
    "SelectA_recommedations": [
      "Q932",
      "Q251",
      "Q514"
    ],
    "SelectB_recommedations": [
      "Q932",
      "Q451",
      "Q805"
    ],
    "SelectC_recommedations": [
      "Q932",
      "Q251",
      "Q875"
    ],
    "SelectD_recommedations": [
      "Q932",
      "Q251",
      "Q468"
    ]
  },
  {
    "Question_Number": "Q933",
    "Question_Description": "한 회사가 전자상거래 애플리케이션을 호스팅 중이며, 모든 데이터를 AWS가 완전관리형으로 운영하는 단일 Amazon RDS for MySQL DB instance에 저장하고 있습니다. 회사는 단일 실패 지점(Single Point of Failure)을 방지해야 합니다. 가장 적은 구현 노력을 들여 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145008-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL 단일 DB instance의 SPOF를 최소 구현 노력으로 해결하는 방법을 묻습니다. Multi-AZ로 변경하면 자동으로 장애 조치가 가능해 고가용성을 보장하고, 구성 변경이 매우 간단합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for MySQL",
      "Multi-AZ",
      "단일 실패 지점",
      "전자상거래",
      "최소 구현 노력"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "Multi-AZ deployment",
      "AWS Database Migration Service (AWS DMS)",
      "Amazon DynamoDB",
      "Amazon EC2 Auto Scaling",
      "Amazon Route 53",
      "Snapshot"
    ],
    "SelectA": "RDS DB instance를 Multi-AZ 배포로 수정하고, 다음 유지 보수 창에 변경을 적용합니다.",
    "SelectA_Commentary": "가장 간단한 방법이며, DB가 Multi-AZ 구조가 되어 장애 시 자동 장애 조치가 이루어집니다.",
    "SelectB": "현재 데이터베이스를 Amazon DynamoDB Multi-AZ 배포로 마이그레이션합니다. AWS DMS를 사용해 RDS DB instance를 DynamoDB 테이블로 이기종 마이그레이션합니다.",
    "SelectB_Commentary": "데이터 모델이 달라 재설계가 필요하며, 마이그레이션 절차가 복잡해 최소 구현 노력 목표에 부합하지 않습니다.",
    "SelectC": "새 RDS DB instance를 Multi-AZ 배포로 생성합니다. 기존 RDS DB instance에서 가장 최근 Snapshot을 수동으로 복원하여 데이터를 옮깁니다.",
    "SelectC_Commentary": "직접 새로운 인스턴스를 생성하고 스냅샷을 불러와야 하므로 추가 작업 및 중단이 필요합니다.",
    "SelectD": "DB instance를 Amazon EC2 Auto Scaling 그룹(최소 크기 3)으로 구성합니다. Amazon Route 53 단순 라우팅으로 모든 DB instance에 트래픽을 분산합니다.",
    "SelectD_Commentary": "RDS 대신 EC2에 직접 DB를 설치해야 하므로 관리 비용과 복잡성이 크게 증가합니다.",
    "Question_Description_recommedations": [
      "Q444",
      "Q518",
      "Q629",
      "Q464",
      "Q420"
    ],
    "SelectA_recommedations": [
      "Q958",
      "Q464",
      "Q466"
    ],
    "SelectB_recommedations": [
      "Q958",
      "Q518",
      "Q490"
    ],
    "SelectC_recommedations": [
      "Q989",
      "Q958",
      "Q466"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q545",
      "Q444"
    ]
  },
  {
    "Question_Number": "Q934",
    "Question_Description": "한 회사는 온프레미스 환경에서 Microsoft Windows SMB 파일 서버와 Linux NFS 파일 서버를 통해 파일 공유를 운영하고 있습니다. 회사의 AWS 마이그레이션 계획의 일환으로, 이러한 파일 서버들을 AWS Cloud에서 통합하고자 합니다. 회사는 NFS와 SMB 액세스를 모두 지원하는 관리형 AWS 스토리지 서비스가 필요하며, 프로토콜 간 공유가 가능해야 합니다. 또한 가용 영역(AZ) 수준에서 중복성을 제공해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145009-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Windows와 Linux 파일 서버를 단일화하면서, NFS와 SMB 모두가 필요하고 AZ 차원의 중복성까지 제공해야 하는 시나리오입니다. Amazon FSx for NetApp ONTAP은 멀티프로토콜 지원과 고가용성을 제공하여 이러한 요구사항을 모두 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "AWS 마이그레이션",
      "NFS와 SMB 동시 지원",
      "프로토콜 간 공유",
      "가용 영역 중복성",
      "AWS Cloud 통합",
      "관리형 스토리지"
    ],
    "Terms": [
      "Amazon FSx for NetApp ONTAP",
      "NFS",
      "SMB",
      "Amazon FSx for Lustre",
      "Amazon EC2",
      "Amazon S3 File Gateway",
      "가용 영역(AZ)",
      "멀티프로토콜"
    ],
    "SelectA": "Amazon FSx for NetApp ONTAP을 스토리지로 사용하고, 멀티프로토콜 액세스를 구성합니다.",
    "SelectA_Commentary": "NFS와 SMB를 동시에 지원하며, AZ 간 중복성과 고가용성을 제공하므로 요구사항을 모두 충족하는 올바른 해답입니다.",
    "SelectB": "두 개의 Amazon EC2 인스턴스를 생성합니다. 하나는 Windows SMB 파일 서버용, 다른 하나는 Linux NFS 파일 서버용으로 사용합니다.",
    "SelectB_Commentary": "분리된 환경으로 구성해야 하며, 멀티프로토콜 공유가 불가능하고 완전한 관리형 서비스가 아니므로 운영이 복잡합니다.",
    "SelectC": "SMB 액세스에는 Amazon FSx for NetApp ONTAP을, NFS 액세스에는 Amazon FSx for Lustre를 사용합니다.",
    "SelectC_Commentary": "멀티프로토콜을 단일 서비스에서 지원하지 않아 프로토콜 간 공유가 제한됩니다. 두 서비스 사용으로 관리 복잡성이 증가합니다.",
    "SelectD": "Amazon S3 스토리지를 사용하고, Amazon S3 File Gateway를 통해 접근합니다.",
    "SelectD_Commentary": "S3 File Gateway는 NFS 또는 SMB 중 하나씩만 활용하기에 멀티프로토콜 파일 공유로서 제한이 있으며, AZ 단위 redundancy를 제공하는 파일 시스템 운영과는 거리가 있습니다.",
    "Question_Description_recommedations": [
      "Q843",
      "Q293",
      "Q102",
      "Q944",
      "Q52"
    ],
    "SelectA_recommedations": [
      "Q635",
      "Q753",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q934",
      "Q110"
    ],
    "SelectC_recommedations": [
      "Q934",
      "Q635",
      "Q618"
    ],
    "SelectD_recommedations": [
      "Q188",
      "Q784",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q935",
    "Question_Description": "한 소프트웨어 회사가 크리티컬 웹 애플리케이션을 업그레이드해야 합니다. 현재 이 애플리케이션은 퍼블릭 서브넷의 단일 Amazon EC2 인스턴스에서 실행 중이며, 해당 EC2 인스턴스는 MySQL 데이터베이스를 구동하고 있습니다. 애플리케이션의 DNS 레코드는 Amazon Route 53 존에 게시되어 있습니다. 솔루션스 아키텍트는 애플리케이션이 확장 가능하고(highly scalable), 고가용성(HA)을 갖추도록 재구성해야 하며, MySQL 데이터베이스의 읽기 지연(레이턴시)을 줄여야 합니다. 다음 중 어떤 솔루션 조합이 이러한 요구사항을 충족합니까? (두 가지를 고르세요.)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144933-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션을 고가용성과 확장성을 모두 만족하도록 재설계하고, MySQL 읽기 성능을 높이기 위해 Aurora MySQL 기반의 멀티 AZ 구성을 고려하게 합니다. Auto Scaling group을 통해 여러 AZ에 분산 배포하여 애플리케이션 계층을 탄력적으로 확장하고, Aurora MySQL의 리더 인스턴스(또는 리드 레플리카) 구성을 통해 읽기 지연을 줄일 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "크리티컬 웹 애플리케이션",
      "퍼블릭 서브넷",
      "Amazon EC2 인스턴스",
      "MySQL 데이터베이스",
      "확장 가능",
      "고가용성",
      "MySQL 읽기 지연",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon Aurora MySQL"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon Route 53",
      "MySQL",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon Aurora MySQL",
      "Cross-Region read replicas"
    ],
    "SelectA": "두 번째 AWS Region에 EC2 인스턴스를 추가로 실행하고, Route 53 Failover 라우팅 정책을 사용하여 트래픽을 두 번째 인스턴스로 리다이렉트합니다.",
    "SelectA_Commentary": "Region 간 Failover만 구성하므로 멀티 AZ 수준의 확장성 효과가 부족하고, MySQL 읽기 지연 개선에도 직접적인 도움이 되지 않습니다.",
    "SelectB": "여러 가용 영역(Availability Zones)에 프라이빗 EC2 인스턴스를 실행하도록 Auto Scaling group을 생성하고 구성합니다. 새 Application Load Balancer 뒤의 타깃 그룹에 인스턴스들을 추가합니다.",
    "SelectB_Commentary": "멀티 AZ로 확장 가능한 인프라와 ALB를 구성해 고가용성과 확장성을 모두 달성할 수 있어 애플리케이션 계층 요구사항에 적합한 선택입니다.",
    "SelectC": "데이터베이스를 Amazon Aurora MySQL 클러스터로 마이그레이션합니다. 기본 DB 인스턴스와 리더 DB 인스턴스를 서로 다른 가용 영역에 구성합니다.",
    "SelectC_Commentary": "Aurora MySQL은 멀티 AZ 지원과 리더 인스턴스를 통해 읽기를 분산할 수 있어 MySQL 읽기 지연을 크게 줄이며 고가용성도 확보 가능합니다.",
    "SelectD": "여러 AWS Region에 프라이빗 EC2 인스턴스를 실행하도록 Auto Scaling group을 생성하고 구성합니다. 새 Application Load Balancer 뒤의 타깃 그룹에 인스턴스들을 추가합니다.",
    "SelectD_Commentary": "멀티리전을 고려하면 관리 복잡도가 높아지고, 지역 간 트래픽 라우팅 설정도 필요해 요구사항(단일 리전에서의 확장 및 HA)보다 과도한 구성입니다.",
    "SelectE": "데이터베이스를 교차 리전 읽기 레플리카가 있는 Amazon Aurora MySQL 클러스터로 마이그레이션합니다.",
    "SelectE_Commentary": "여러 Region에서 읽기 분산이 가능하지만, 문제의 요구는 단일 Region 내에서 빠른 읽기 지연과 고가용성 구성이므로 이보다 간단한 멀티 AZ 구성이 적합합니다.",
    "Question_Description_recommedations": [
      "Q236",
      "Q654",
      "Q768",
      "Q720",
      "Q944"
    ],
    "SelectA_recommedations": [
      "Q224",
      "Q585",
      "Q264"
    ],
    "SelectB_recommedations": [
      "Q275",
      "Q691",
      "Q174"
    ],
    "SelectC_recommedations": [
      "Q182",
      "Q462",
      "Q136"
    ],
    "SelectD_recommedations": [
      "Q275",
      "Q405",
      "Q69"
    ],
    "SelectE_recommedations": [
      "Q182",
      "Q824",
      "Q462"
    ]
  },
  {
    "Question_Number": "Q936",
    "Question_Description": "한 회사가 수천 개의 AWS Lambda 함수를 운영하고 있습니다. 회사는 모든 Lambda 함수가 사용하는 민감한 정보를 안전하게 저장해야 하며, 이 민감한 정보를 자동으로 로테이션해 줄 솔루션이 필요합니다. 이 요구사항을 만족하면서 운영 오버헤드를 최소화하려면, 어떤 조합의 단계들이 적합한가요? (2개를 선택하세요)",
    "Answer": "B,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145010-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Lambda 함수가 공유하는 민감 정보를 안전하게 관리하고 자동으로 로테이션하는 방법을 묻습니다. AWS Secrets Manager는 자동 로테이션을 제공해 수작업 부담을 줄이며, Lambda layer를 통해 공통 로직으로 쉽게 정보를 가져올 수 있어 운영이 단순해집니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "AWS Lambda",
      "민감한 정보",
      "자동 로테이션",
      "Secrets Manager",
      "Lambda layer",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Secrets Manager",
      "AWS Lambda",
      "Lambda layer",
      "자동 로테이션",
      "AWS Systems Manager Parameter Store",
      "Lambda@Edge",
      "Environment variables"
    ],
    "SelectA": "Lambda@Edge를 사용하여 HTTP 보안 헤더를 생성하고 민감 정보를 생성합니다.",
    "SelectA_Commentary": "Lambda@Edge는 보안 헤더 추가에는 유용하나, 민감 정보 자체를 안전하게 저장·로테이션하는 용도로 적합하지 않습니다.",
    "SelectB": "Lambda layer를 생성하여 민감 정보를 가져옵니다.",
    "SelectB_Commentary": "Lambda layer를 사용하면 여러 Lambda 함수가 동일한 로직으로 민감 정보를 손쉽게 호출하여 중복 코드를 줄이고 관리 효율을 높일 수 있습니다.",
    "SelectC": "민감 정보를 AWS Secrets Manager에 저장합니다.",
    "SelectC_Commentary": "AWS Secrets Manager는 민감 정보를 안전하게 저장하고 자동 로테이션 기능을 제공하여 오버헤드를 크게 줄여줍니다.",
    "SelectD": "민감 정보를 AWS Systems Manager Parameter Store에 저장합니다.",
    "SelectD_Commentary": "Parameter Store도 민감 정보 저장이 가능하지만, 자동 로테이션에 대한 지원 범위가 Secrets Manager만큼 간편하지 않습니다.",
    "SelectE": "민감 정보를 가져와 환경 변수를 생성하는 전용 처리량을 가진 Lambda consumer를 만듭니다.",
    "SelectE_Commentary": "별도 Lambda consumer 구성은 복잡성을 높이고 운영 오버헤드를 증가시키므로 최적 해법이 아닙니다.",
    "Question_Description_recommedations": [
      "Q791",
      "Q289",
      "Q484",
      "Q548",
      "Q831"
    ],
    "SelectA_recommedations": [
      "Q265",
      "Q159",
      "Q936"
    ],
    "SelectB_recommedations": [
      "Q936",
      "Q791",
      "Q122"
    ],
    "SelectC_recommedations": [
      "Q233",
      "Q893",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q179",
      "Q893",
      "Q965"
    ],
    "SelectE_recommedations": [
      "Q936",
      "Q791",
      "Q831"
    ]
  },
  {
    "Question_Number": "Q937",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스(Auto Scaling group을 사용)에 내부 애플리케이션을 운영하고 있습니다. 이 EC2 인스턴스들은 Compute Optimized 유형이며 Amazon EBS 볼륨을 사용합니다. 회사는 EC2 인스턴스, Auto Scaling group, 그리고 EBS 볼륨 전반에 걸쳐 비용 최적화를 찾고자 합니다. 가장 운영 효율성이 높은 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145011-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AWS Compute Optimizer는 EC2, Auto Scaling group, EBS 볼륨 모두에 대한 사용 패턴 분석과 구체적인 비용 최적화 권장 사항을 제공하여 운영 효율성을 극대화합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "Auto Scaling group",
      "Amazon EBS 볼륨",
      "비용 최적화",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Compute Optimized",
      "Amazon EBS",
      "AWS Cost and Usage Report",
      "Amazon CloudWatch billing alerts",
      "AWS Compute Optimizer"
    ],
    "SelectA": "새로운 AWS Cost and Usage Report를 생성합니다. 해당 리포트를 검색하여 EC2 인스턴스, Auto Scaling group, 그리고 EBS 볼륨에 대한 비용 권장 사항을 찾습니다.",
    "SelectA_Commentary": "자체 비용 정보를 확인하는 데는 도움이 되지만 구체적인 리소스별 최적화 권장 사항 제공이 제한적이어서 운영 효율성이 낮습니다.",
    "SelectB": "새로운 Amazon CloudWatch 청구 알림을 생성합니다. 청구 알림 상태를 확인하여 EC2 인스턴스, Auto Scaling group, EBS 볼륨에 대한 비용 권장 사항을 확인합니다.",
    "SelectB_Commentary": "비용 경고 발송만 가능하며, 자동화된 최적화 권장 사항을 제시하지 못해 문제 해결에 직접적인 도움이 부족합니다.",
    "SelectC": "EC2 인스턴스, Auto Scaling group, 그리고 EBS 볼륨에 대한 비용 권장 사항을 위해 AWS Compute Optimizer를 구성합니다.",
    "SelectC_Commentary": "AWS Compute Optimizer는 모든 대상 리소스에 대한 자동화된 사용량 분석과 구체적인 비용 최적화 제안을 제공하므로 가장 효율적입니다.",
    "SelectD": "EC2 인스턴스에 대한 비용 권장 사항을 위해 AWS Compute Optimizer를 구성합니다. 그런 다음 새로운 AWS Cost and Usage Report를 생성하고, 해당 리포트를 검색하여 Auto Scaling group과 EBS 볼륨에 대한 비용 권장 사항을 찾습니다.",
    "SelectD_Commentary": "분리된 방법으로 각각 분석하면 중복된 설정과 추가 단계가 필요해 운영 효율성이 떨어집니다. 한 번에 Compute Optimizer를 구성하는 것이 더 간단합니다.",
    "Question_Description_recommedations": [
      "Q290",
      "Q245",
      "Q867",
      "Q822",
      "Q505"
    ],
    "SelectA_recommedations": [
      "Q937",
      "Q641",
      "Q290"
    ],
    "SelectB_recommedations": [
      "Q290",
      "Q238",
      "Q552"
    ],
    "SelectC_recommedations": [
      "Q937",
      "Q290",
      "Q822"
    ],
    "SelectD_recommedations": [
      "Q937",
      "Q290",
      "Q822"
    ]
  },
  {
    "Question_Number": "Q938",
    "Question_Description": "한 회사가 단일 VPC 내 여러 Availability Zone에 걸쳐 분산된 여러 Amazon EC2 인스턴스에서 미디어 스토어를 운영하고 있습니다. 이 회사는 모든 EC2 인스턴스 간 데이터를 공유하기 위한 고성능 솔루션을 원하며, 데이터가 VPC 내부에만 머무르도록 선호합니다. 솔루션스 아키텍트는 어떤 것을 제안해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145679-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 EC2 인스턴스 간 빠르고 안정적인 파일 공유를 위한 스토리지 솔루션을 고르는 상황입니다. Amazon EFS는 서버리스이며 확장성이 뛰어나고, 단일 VPC 내에서 여러 인스턴스가 동시에 접근할 수 있으므로 요구 사항에 부합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "고성능 파일 공유",
      "단일 VPC",
      "Amazon EFS",
      "Amazon EC2",
      "Availability Zone"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Amazon EFS",
      "Amazon S3",
      "VPC",
      "Availability Zone"
    ],
    "SelectA": "Amazon S3 버킷을 생성하고 각 인스턴스의 애플리케이션에서 서비스 API를 호출합니다.",
    "SelectA_Commentary": "S3는 객체 스토리지로, 파일 시스템처럼 마운트해 쓰기에는 적합하지 않으며 고성능 공유 파일 시스템 요구사항을 충족하기 어렵습니다.",
    "SelectB": "Amazon S3 버킷을 생성하고 모든 인스턴스가 이를 마운트된 볼륨으로 액세스하도록 구성합니다.",
    "SelectB_Commentary": "S3를 직접 파일 시스템처럼 마운트하는 것은 공식적으로 지원되지 않으며, S3의 특성상 저지연 랜덤 I/O가 어려워 공유 파일 시스템으로 사용하기에 부적합합니다.",
    "SelectC": "Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성하고 이를 모든 인스턴스에서 마운트하도록 설정합니다.",
    "SelectC_Commentary": "EBS 볼륨은 단일 인스턴스에 연결하는 방식이 기본이며, 다중 인스턴스 공유 시 복잡하고 고가용성을 보장하기 어렵습니다.",
    "SelectD": "Amazon Elastic File System(Amazon EFS) 파일 시스템을 구성하고 모든 인스턴스에서 이를 마운트하도록 설정합니다.",
    "SelectD_Commentary": "EFS는 여러 인스턴스가 동시에 액세스 가능하며, 확장성과 고성능을 제공하므로 단일 VPC 내부 공유 스토리지 요구사항에 가장 적합합니다.",
    "Question_Description_recommedations": [
      "Q566",
      "Q818",
      "Q976",
      "Q686",
      "Q474"
    ],
    "SelectA_recommedations": [
      "Q501",
      "Q672",
      "Q155"
    ],
    "SelectB_recommedations": [
      "Q501",
      "Q43",
      "Q672"
    ],
    "SelectC_recommedations": [
      "Q746",
      "Q695",
      "Q501"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q695",
      "Q155"
    ]
  },
  {
    "Question_Number": "Q939",
    "Question_Description": "한 회사가 Amazon RDS for MySQL 인스턴스를 사용하고 있습니다. 연말 처리를 대비하여 회사는 reporting tool의 추가 read-only 쿼리를 처리하기 위해 read replica를 추가하였습니다. 연말 처리 중, read replica와 primary instance 모두 CPU 사용률이 각각 60%를 기록했습니다. 연말 처리 작업이 완료된 후, read replica의 CPU 사용률은 25%로 유지되고 있으며 primary instance는 여전히 60%로 유지되고 있습니다. 회사는 데이터베이스를 적절히 사이징하고, 향후 성장에도 충분한 성능을 제공하고자 합니다. 어떤 솔루션이 이 요구사항을 충족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145680-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for MySQL 환경에서 read replica를 통한 부하 분산과 인스턴스 리소스 사이징을 최적화하는 방법을 묻습니다. primary instance가 60%의 CPU 사용률로 안정적이므로, 상대적으로 여유가 많은 read replica만 소형화해도 충분한 성능을 유지하고 비용도 절감할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "RDS 인스턴스",
      "read replica",
      "CPU 사용률",
      "사이즈 조정",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon RDS for MySQL",
      "read replica",
      "CPU usage",
      "reporting tool",
      "primary instance"
    ],
    "SelectA": "read replica를 삭제합니다. primary instance에는 아무런 변경을 하지 않습니다.",
    "SelectA_Commentary": "read replica를 완전히 제거하면 현재 25%의 CPU 오프로드가 사라져, 향후 추가 read 요청에 대한 확장성이 부족해집니다.",
    "SelectB": "read replica를 더 작은 인스턴스로 리사이징합니다. primary instance에는 아무런 변경을 하지 않습니다.",
    "SelectB_Commentary": "read replica만 축소해 비용을 절감하면서도, primary 인스턴스의 60% CPU 사용률을 고려하면 추가 조정 없이도 향후 성장을 충분히 지원할 수 있습니다.",
    "SelectC": "read replica를 더 큰 인스턴스로 리사이징합니다. primary instance도 더 작은 인스턴스로 리사이징합니다.",
    "SelectC_Commentary": "read replica는 이미 여유가 있으므로 확장할 필요가 없고, primary instance를 축소하면 60% CPU 사용률 처리가 부담될 수 있어 적합하지 않습니다.",
    "SelectD": "read replica를 삭제합니다. primary instance를 더 큰 인스턴스로 리사이징합니다.",
    "SelectD_Commentary": "read replica 제거 시 확장성이 약화되고, primary 인스턴스를 키우는 것은 비용 측면에서 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q30",
      "Q574",
      "Q579",
      "Q730",
      "Q959"
    ],
    "SelectA_recommedations": [
      "Q767",
      "Q49",
      "Q728"
    ],
    "SelectB_recommedations": [
      "Q767",
      "Q49",
      "Q728"
    ],
    "SelectC_recommedations": [
      "Q767",
      "Q49",
      "Q728"
    ],
    "SelectD_recommedations": [
      "Q767",
      "Q49",
      "Q728"
    ]
  },
  {
    "Question_Number": "Q940",
    "Question_Description": "한 회사가 Amazon RDS for PostgreSQL로 데이터베이스를 마이그레이션하고 있습니다. 또한 애플리케이션을 Amazon EC2 인스턴스로 이전하고 있으며, 이 회사는 장기간 실행되는 워크로드에 대해 비용 최적화를 원합니다. 가장 비용 효율적으로 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144895-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for PostgreSQL와 Amazon EC2를 장기간 사용하면서 비용을 최소화하는 방안을 묻는 문제입니다. Reserved Instances와 Savings Plan은 장기간 사용 시에 On-Demand 대비 비용을 크게 절감할 수 있습니다. 특히 3년 All Upfront 옵션은 가장 높은 할인율을 제공하므로 장기 예측이 확실하고 선결제가 가능한 경우에 최적의 비용 절감 효과를 얻을 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS for PostgreSQL",
      "Amazon EC2",
      "장기간 실행되는 워크로드",
      "비용 최적화",
      "Reserved Instances",
      "Compute Savings Plan"
    ],
    "Terms": [
      "On-Demand Instances",
      "Reserved Instances",
      "1 year term",
      "3 year term",
      "No Upfront",
      "Partial Upfront",
      "All Upfront",
      "Compute Savings Plan",
      "EC2 Instance Savings Plan"
    ],
    "SelectA": "Amazon RDS for PostgreSQL 워크로드에 On-Demand Instances를 사용합니다. EC2 인스턴스에 대해서는 1년 기간의 Compute Savings Plan(No Upfront 옵션)을 구매합니다.",
    "SelectA_Commentary": "RDS에는 On-Demand를 사용하므로 장기 워크로드에 대한 할인 혜택을 충분히 누리기 어렵습니다.",
    "SelectB": "Amazon RDS for PostgreSQL 워크로드에 대해 1년 기간 No Upfront 옵션으로 Reserved Instances를 구매합니다. EC2 인스턴스에 대해서는 1년 기간의 EC2 Instance Savings Plan(No Upfront 옵션)을 구매합니다.",
    "SelectB_Commentary": "단기(1년) No Upfront로 일부 할인은 가능하지만, 3년 대비 할인 폭이 작습니다.",
    "SelectC": "Amazon RDS for PostgreSQL 워크로드에 대해 1년 기간 Partial Upfront 옵션으로 Reserved Instances를 구매합니다. EC2 인스턴스에 대해서는 1년 기간 Partial Upfront 옵션으로 EC2 Instance Savings Plan을 구매합니다.",
    "SelectC_Commentary": "1년 Partial Upfront로 중간 수준의 할인은 있지만, 3년에 비해 할인 폭이 충분히 크지 않습니다.",
    "SelectD": "Amazon RDS for PostgreSQL 워크로드에 대해 3년 기간 All Upfront 옵션으로 Reserved Instances를 구매합니다. EC2 인스턴스에 대해서는 3년 기간 All Upfront 옵션으로 EC2 Instance Savings Plan을 구매합니다.",
    "SelectD_Commentary": "3년 All Upfront의 경우 가장 높은 할인율을 제공하므로 장기 워크로드와 예산이 충분하다면 가장 비용 효율적인 선택입니다.",
    "Question_Description_recommedations": [
      "Q579",
      "Q436",
      "Q574",
      "Q959",
      "Q152"
    ],
    "SelectA_recommedations": [
      "Q940",
      "Q579",
      "Q436"
    ],
    "SelectB_recommedations": [
      "Q940",
      "Q885",
      "Q152"
    ],
    "SelectC_recommedations": [
      "Q940",
      "Q885",
      "Q436"
    ],
    "SelectD_recommedations": [
      "Q940",
      "Q152",
      "Q436"
    ]
  },
  {
    "Question_Number": "Q941",
    "Question_Description": "한 회사가 Amazon Elastic Kubernetes Service(Amazon EKS) 클러스터를 사용하고 있습니다. 회사는 EKS 클러스터 내 Kubernetes service accounts가 IAM roles for service accounts(IRSA)를 사용하여 특정 AWS 리소스에 대해서 안전하고 세분화된 액세스를 할 수 있도록 해야 합니다. 이러한 요구사항을 충족하는 솔루션 조합은 무엇입니까? (두 개를 선택하십시오.)",
    "Answer": "D,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145808-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS에서 Kubernetes service account별로 필요한 AWS 권한만 부여하려는 보안 설계 방식인 IRSA 구성에 대한 질문입니다. OIDC를 통해 외부에서 인증 정보를 받아와 IAM role에 매핑시키고, 각 service account에 필요한 권한 정책을 세분화하여 적용하면 됩니다. 정답인 D와 E를 통해 각 서비스 계정에 맞춤형 권한을 주고, OIDC 공급자와의 신뢰 관계를 설정해야 안전하고 세밀한 접근 제어가 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "EKS 클러스터",
      "Kubernetes service account",
      "IAM roles for service accounts",
      "OIDC",
      "IAM role",
      "ARN"
    ],
    "Terms": [
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Kubernetes service accounts",
      "IAM roles for service accounts (IRSA)",
      "OpenID Connect (OIDC)",
      "IAM policy",
      "IAM role",
      "Amazon Resource Name (ARN)",
      "EKS 노드",
      "network policies"
    ],
    "SelectA": "필요한 권한을 정의하는 IAM policy를 생성하고 이를 EKS 노드의 IAM role에 직접 연결합니다.",
    "SelectA_Commentary": "EKS 노드의 IAM role에만 정책을 연결하면 모든 service account에서 동일한 권한을 사용하게 되어 세분화된 권한 부여가 불가능합니다.",
    "SelectB": "EKS 클러스터 내에서 network policies를 구현하여 Kubernetes service accounts가 특정 AWS 서비스를 액세스하지 못하도록 합니다.",
    "SelectB_Commentary": "network policies는 트래픽 제한에 유리하지만, IAM 기반의 세밀한 AWS 리소스 권한 제어를 대체하지 못합니다.",
    "SelectC": "EKS 클러스터의 IAM role을 수정하여 각 Kubernetes service account에 대한 권한을 포함시킵니다. IAM role과 Kubernetes role 간 1대1 매핑을 보장합니다.",
    "SelectC_Commentary": "모든 권한을 클러스터 단의 단일 IAM role에 통합하면 역할 관리가 복잡해지고, 서비스 계정마다 세부 권한을 분리하기 어렵습니다.",
    "SelectD": "필요한 권한이 포함된 IAM role을 정의합니다. Kubernetes service account에 해당 IAM role의 Amazon Resource Name(ARN)을 애너테이션으로 추가합니다.",
    "SelectD_Commentary": "각 서비스 계정에 필요한 권한의 IAM role을 연결해 주어 세부적인 권한 부여가 가능합니다. IRSA의 핵심 설정입니다.",
    "SelectE": "Service account를 위한 IAM role과 OpenID Connect(OIDC) identity provider 간에 신뢰 관계를 설정합니다.",
    "SelectE_Commentary": "IRSA 구현에서는 OIDC 공급자와 IAM role 간의 trust 설정이 필수이며, 이를 통해 쿠버네티스 토큰에 대한 유효성 검증이 가능합니다.",
    "Question_Description_recommedations": [
      "Q613",
      "Q805",
      "Q1017",
      "Q371",
      "Q681"
    ],
    "SelectA_recommedations": [
      "Q423",
      "Q429",
      "Q476"
    ],
    "SelectB_recommedations": [
      "Q805",
      "Q535",
      "Q941"
    ],
    "SelectC_recommedations": [
      "Q941",
      "Q613",
      "Q535"
    ],
    "SelectD_recommedations": [
      "Q941",
      "Q233",
      "Q780"
    ],
    "SelectE_recommedations": [
      "Q780",
      "Q429",
      "Q750"
    ]
  },
  {
    "Question_Number": "Q942",
    "Question_Description": "회사는 분석을 위해 Amazon S3 버킷에 기밀 데이터를 정기적으로 업로드하고 있습니다. 보안 정책에 따라 객체는 저장 시점에서 암호화되어야 하며, 1년에 한 번씩 자동으로 암호화 키를 로테이션해야 합니다. 또한 AWS CloudTrail을 사용해 키 로테이션을 추적할 수 있어야 하고, 암호화 키 비용을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145418-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 저장 시점 암호화 설정과 연간 키 로테이션, CloudTrail 추적, 비용 최소화를 모두 만족해야 합니다. SSE-S3는 별도 월간 비용 없이 자동 키 로테이션을 지원하고 CloudTrail로 감사 가능해 요구사항을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "기밀 데이터",
      "자동 로테이션",
      "AWS CloudTrail",
      "비용 최소화"
    ],
    "Terms": [
      "Amazon S3",
      "SSE-C",
      "SSE-S3",
      "SSE-KMS",
      "AWS KMS",
      "Customer managed AWS KMS key",
      "AWS CloudTrail"
    ],
    "SelectA": "고객 제공 키(SSE-C)를 사용해 서버 측 암호화를 적용합니다.",
    "SelectA_Commentary": "고객이 직접 키를 관리하고 로테이션해야 해 운영이 복잡하고 자동 로테이션과 CloudTrail 기반 추적도 제한적입니다.",
    "SelectB": "Amazon S3가 관리하는 키(SSE-S3)를 사용해 서버 측 암호화를 적용합니다.",
    "SelectB_Commentary": "SSE-S3는 키를 자동으로 로테이션하며 추가 월간 요금 없이 CloudTrail로 키 활동을 추적할 수 있어 요구사항을 충족합니다.",
    "SelectC": "AWS KMS 키(SSE-KMS)를 사용해 서버 측 암호화를 적용합니다.",
    "SelectC_Commentary": "KMS를 이용해 키 로테이션과 CloudTrail 추적이 모두 가능하지만, KMS 사용 요금이 추가로 부과되어 비용 최소화 요구에 덜 적합합니다.",
    "SelectD": "사용자 관리 AWS KMS 키로 서버 측 암호화를 적용합니다.",
    "SelectD_Commentary": "고객이 직접 관리하는 KMS 키는 월별 키 요금과 사용량 기반 요금이 추가되어 비용이 상승하므로 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q109",
      "Q862",
      "Q270",
      "Q638",
      "Q412"
    ],
    "SelectA_recommedations": [
      "Q189",
      "Q665",
      "Q122"
    ],
    "SelectB_recommedations": [
      "Q678",
      "Q106",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q793",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q916",
      "Q831"
    ]
  },
  {
    "Question_Number": "Q943",
    "Question_Description": "한 회사가 지난 3개월 동안 여러 애플리케이션을 AWS로 마이그레이션했습니다. 회사는 각 애플리케이션별 비용 내역을 알고 싶어 하며, 이를 정기적으로 보고받기 원합니다. 가장 비용 효율적인 방법으로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145918-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 최근에 마이그레이션된 애플리케이션들에 대한 AWS 비용을 손쉽게, 그리고 정기적으로 확인하기 위해 어떠한 방식을 도입해야 가장 경제적인지 묻고 있습니다. 태그를 통해 자원을 분류하고, Cost Explorer를 사용하는 방식이 추가 인프라 비용 없이 원하는 정보를 빠르게 얻을 수 있어 비용 최적화에 유리합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "지난 3개월",
      "비용 효율적",
      "정기 보고",
      "애플리케이션별 비용"
    ],
    "Terms": [
      "AWS Budgets",
      "CSV",
      "Amazon RDS DB instance",
      "AWS Cost and Usage Reports",
      "SQL queries",
      "Tag",
      "Cost Explorer",
      "AWS Billing and Cost Management console",
      "Bill",
      "Cost Allocation Tags"
    ],
    "SelectA": "AWS Budgets를 사용해 지난 3개월간 데이터를 .csv 파일로 다운로드하고, 원하는 정보를 직접 확인합니다.",
    "SelectA_Commentary": "Budgets는 알림과 예산 감시에 유용하나, 자동화된 세분화 보고서나 태그별 분석 기능이 제한되어 효율적이지 않습니다.",
    "SelectB": "AWS Cost and Usage Reports를 Amazon RDS DB instance에 적재하고, SQL 쿼리를 실행해 필요한 정보를 가져옵니다.",
    "SelectB_Commentary": "직접 RDS를 운영하려면 DB 비용과 관리 오버헤드가 발생합니다. 작은 규모라도 장기적으로는 비효율적일 수 있습니다.",
    "SelectC": "모든 AWS 리소스에 cost라는 키와 애플리케이션 이름을 값으로 태그를 적용하고, Cost Allocation Tags를 활성화한 뒤 Cost Explorer를 사용해 필요한 정보를 확인합니다.",
    "SelectC_Commentary": "Cost Explorer는 태그별 비용을 손쉽게 분석하고, 주기적 보고 기능도 제공해 추가 인프라 없이 가장 비용 효율적인 솔루션입니다.",
    "SelectD": "모든 AWS 리소스에 cost 키와 애플리케이션 이름을 값으로 태그를 적용한 뒤, AWS Billing and Cost Management 콘솔에서 지난 3개월 간 청구서를 다운로드하여 직접 확인합니다.",
    "SelectD_Commentary": "청구서 자체는 비용 집계 정보를 제공하지만 세부 분석과 태그별 자동화 보고 기능이 없으므로 번거롭고 효율적이지 않습니다.",
    "Question_Description_recommedations": [
      "Q486",
      "Q541",
      "Q728",
      "Q485",
      "Q985"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q486",
      "Q455"
    ],
    "SelectB_recommedations": [
      "Q959",
      "Q380",
      "Q152"
    ],
    "SelectC_recommedations": [
      "Q459",
      "Q641",
      "Q31"
    ],
    "SelectD_recommedations": [
      "Q641",
      "Q459",
      "Q455"
    ]
  },
  {
    "Question_Number": "Q944",
    "Question_Description": "한 이커머스 회사가 고객들에게 지속적인 서비스를 제공하기 위해 AWS에 웹 애플리케이션을 배포하려고 합니다. 아키텍처는 Amazon EC2 인스턴스에서 호스팅되는 웹 애플리케이션, Amazon RDS의 관계형 데이터베이스, 그리고 Amazon S3에 저장된 정적 파일들로 구성됩니다. 회사는 애플리케이션을 위해 견고하고 복원력 있는 아키텍처를 설계하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145527-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 애플리케이션을 고가용성으로 운영하기 위해 멀티 AZ 구성과 Auto Scaling 등을 활용하는 방법을 묻습니다. 여러 AZ에 걸쳐 인프라를 분산 배치하고, 확장성과 내결함성을 동시에 달성하는지가 핵심 포인트입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "지속적인 서비스",
      "견고하고 복원력 있는 아키텍처",
      "고가용성",
      "Auto Scaling",
      "Multi-AZ",
      "정적 파일"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon RDS",
      "Amazon S3",
      "Availability Zone",
      "Auto Scaling group",
      "Multi-AZ RDS DB instance",
      "Amazon CloudFront",
      "AWS Lambda",
      "Amazon Aurora Serverless v2",
      "Amazon Elastic File System (Amazon EFS)",
      "One Zone-Infrequent Access (One Zone-IA)"
    ],
    "SelectA": "Amazon EC2 인스턴스를 단일 Availability Zone에 배포하고, 같은 Availability Zone에 RDS DB 인스턴스를 배포합니다. 정적 파일은 버전이 활성화된 Amazon S3를 사용합니다.",
    "SelectA_Commentary": "단일 AZ 구성은 장애 시 복원력이 낮아 서비스 연속성 보장이 어려우므로 적절하지 않습니다.",
    "SelectB": "Amazon EC2 인스턴스를 여러 Availability Zone에 걸친 Auto Scaling group에 배포하고, Multi-AZ RDS DB 인스턴스를 배포합니다. 정적 파일은 Amazon CloudFront로 배포합니다.",
    "SelectB_Commentary": "멀티 AZ와 Auto Scaling을 통해 고가용성과 확장성을 모두 충족하며, CloudFront로 정적 파일도 전 세계적으로 빠르고 안정적으로 제공합니다.",
    "SelectC": "Amazon EC2 인스턴스를 단일 Availability Zone에 배포하고, 다른 Availability Zone에 RDS DB 인스턴스를 배포합니다. 정적 파일은 EC2 인스턴스에서 직접 서빙합니다.",
    "SelectC_Commentary": "웹 서버와 데이터베이스를 따로 AZ에 두어도 웹 서버가 단일 AZ 실패 시 복원력이 부족하고, 정적 파일 제공도 비효율적입니다.",
    "SelectD": "AWS Lambda 함수를 사용해 웹 애플리케이션을 제공하고, 데이터베이스는 Amazon Aurora Serverless v2를 사용합니다. 정적 파일은 Amazon EFS One Zone-IA에 저장합니다.",
    "SelectD_Commentary": "Lambda와 Aurora Serverless는 서버리스 환경이지만, EFS One Zone-IA는 단일 AZ 스토리지로 복원력이 부족하며 정적 파일 배포에도 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q67",
      "Q892",
      "Q654",
      "Q194",
      "Q354"
    ],
    "SelectA_recommedations": [
      "Q444",
      "Q466",
      "Q298"
    ],
    "SelectB_recommedations": [
      "Q390",
      "Q298",
      "Q466"
    ],
    "SelectC_recommedations": [
      "Q466",
      "Q444",
      "Q298"
    ],
    "SelectD_recommedations": [
      "Q775",
      "Q194",
      "Q785"
    ]
  },
  {
    "Question_Number": "Q945",
    "Question_Description": "한 전자상거래 회사가 여러 개의 AWS 계정에서 여러 내부 애플리케이션을 운영하고 있습니다. 이 회사는 AWS Organizations를 사용하여 AWS 계정들을 관리합니다. 회사의 네트워킹 계정에 있는 보안 어플라이언스가 여러 AWS 계정에 걸쳐 애플리케이션 간 상호 작용을 검사해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145014-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 AWS 계정에서 발생하는 트래픽을 중앙 보안 어플라이언스에서 검사하는 방법을 묻습니다. Gateway Load Balancer(GWLB)를 네트워킹 계정에 배포하고, 다른 계정에서는 interface GWLB endpoint를 통해 트래픽을 GWLB로 전송하여 검사하는 구조가 가장 적합합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "전자상거래 회사",
      "여러 개의 AWS 계정",
      "AWS Organizations",
      "보안 어플라이언스",
      "네트워킹 계정",
      "애플리케이션 간 상호 작용 검사",
      "Gateway Load Balancer",
      "interface GWLB endpoint"
    ],
    "Terms": [
      "AWS Organizations",
      "Gateway Load Balancer (GWLB)",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "interface VPC endpoint",
      "interface GWLB endpoint",
      "보안 어플라이언스"
    ],
    "SelectA": "네트워킹 계정에 Network Load Balancer(NLB)를 배포해 트래픽을 보안 어플라이언스로 전송합니다. 애플리케이션 계정에서는 interface VPC endpoint를 사용해 NLB로 트래픽을 전송하도록 구성합니다.",
    "SelectA_Commentary": "NLB는 Layer4 로드 밸런싱만 가능하며, 다중 계정 트래픽검사 정책을 쉽게 구현하기 어렵습니다.",
    "SelectB": "애플리케이션 계정에 Application Load Balancer(ALB)를 배포하여 보안 어플라이언스로 직접 트래픽을 전송합니다.",
    "SelectB_Commentary": "ALB는 HTTP/HTTPS 기반 트래픽 처리에 주로 사용되며, 중앙 집중형 트래픽 검사를 위한 구조에 적합하지 않습니다.",
    "SelectC": "네트워킹 계정에 Gateway Load Balancer(GWLB)를 배포해 트래픽을 보안 어플라이언스로 전송합니다. 애플리케이션 계정에서는 interface GWLB endpoint를 사용해 GWLB로 트래픽을 전송하도록 구성합니다.",
    "SelectC_Commentary": "GWLB를 활용하면 중앙에서 트래픽을 검사할 수 있고, interface GWLB endpoint를 통해 다른 계정에서 쉽게 연동할 수 있어 요구사항을 충족합니다.",
    "SelectD": "애플리케이션 계정에 interface VPC endpoint를 배포해 트래픽을 보안 어플라이언스로 직접 전송합니다.",
    "SelectD_Commentary": "직접 전송 방식으로는 중앙화된 GWLB의 이점을 살릴 수 없으며, 다중 계정 간 트래픽 가시성 확보에 제약이 큽니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q1018",
      "Q3",
      "Q548",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q928",
      "Q382",
      "Q1016"
    ],
    "SelectB_recommedations": [
      "Q707",
      "Q169",
      "Q884"
    ],
    "SelectC_recommedations": [
      "Q707",
      "Q169",
      "Q625"
    ],
    "SelectD_recommedations": [
      "Q468",
      "Q135",
      "Q950"
    ]
  },
  {
    "Question_Number": "Q946",
    "Question_Description": "한 회사가 Amazon Aurora MySQL DB cluster를 운영 중이며, 이 클러스터에는 총 6개의 Aurora Replica가 있습니다. 이 회사는 한 부서에서 발생하는 실시간에 가까운 보고서 쿼리들을 3개의 Aurora Replica에 자동으로 분산시키고자 합니다. 이 3개의 Replica는 클러스터 내의 다른 Replica들과는 다른 컴퓨팅 및 메모리 사양을 가지고 있습니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145919-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "Amazon Aurora에서 Custom endpoint는 특정 Replica 그룹에만 트래픽을 유도할 수 있어, 서로 다른 사양의 Replica 3개에 보고서 쿼리를 자동 분산하기에 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "Amazon Aurora MySQL",
      "Aurora Replica",
      "실시간 보고서 쿼리",
      "다른 컴퓨팅 및 메모리"
    ],
    "Terms": [
      "Amazon Aurora MySQL DB cluster",
      "Aurora Replica",
      "Custom endpoint",
      "Reader endpoint",
      "Instance endpoint",
      "Compute",
      "Memory specification"
    ],
    "SelectA": "해당 워크로드 전용 Custom endpoint를 생성하고 사용합니다.",
    "SelectA_Commentary": "Custom endpoint를 사용하면 원하는 Replica들만 묶어서 트래픽을 자동으로 분산할 수 있어, 서로 다른 사양을 가진 3개 Replica를 효율적으로 활용할 수 있습니다.",
    "SelectB": "3 노드로 구성된 클러스터 복제본을 만들고 Reader endpoint를 사용합니다.",
    "SelectB_Commentary": "별도의 클러스터를 복제하면 배포와 데이터 동기화가 더 복잡해지고, 실시간에 가까운 보고 쿼리 요구사항을 충족하기에는 비효율적입니다.",
    "SelectC": "선택된 3개 노드의 Instance endpoint를 사용합니다.",
    "SelectC_Commentary": "개별 Instance endpoint를 직접 활용하는 것은 자동 분산 기능이 없으며, 모든 Replica를 통합적으로 관리·부하 분산하기 어렵습니다.",
    "SelectD": "Reader endpoint를 사용하여 읽기 전용 워크로드를 자동 분산합니다.",
    "SelectD_Commentary": "Reader endpoint는 모든 Read Replica로 트래픽을 분산하므로, 특정 3개 Replica만 지정해 분산하는 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q481",
      "Q834",
      "Q337",
      "Q247",
      "Q235"
    ],
    "SelectA_recommedations": [
      "Q77",
      "Q107",
      "Q516"
    ],
    "SelectB_recommedations": [
      "Q77",
      "Q352",
      "Q501"
    ],
    "SelectC_recommedations": [
      "Q77",
      "Q501",
      "Q352"
    ],
    "SelectD_recommedations": [
      "Q77",
      "Q888",
      "Q352"
    ]
  },
  {
    "Question_Number": "Q947",
    "Question_Description": "한 회사가 온프레미스 데이터 센터의 서버에서 Node.js 함수를 실행하고 있습니다. 이 데이터 센터는 PostgreSQL 데이터베이스에 데이터를 저장하고 있으며, 회사는 서버의 환경 변수에 포함된 연결 문자열을 통해 데이터베이스 자격 증명을 관리하고 있습니다. 회사는 애플리케이션을 AWS로 마이그레이션하여 Node.js 애플리케이션 서버를 AWS Lambda로 대체하고, Amazon RDS for PostgreSQL로 이전하면서 데이터베이스 자격 증명을 안전하게 관리하기를 원합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145920-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 환경에서 관리하던 데이터베이스 자격 증명을 AWS 환경으로 마이그레이션할 때, 가장 적은 운영 오버헤드로 안전하게 관리하기 위한 최적의 방법을 묻습니다. AWS Secrets Manager는 고가용성 환경에서 자격 증명을 쉽게 저장·갱신·회전할 수 있어, 보안 및 운영 간소화를 동시에 달성할 수 있는 솔루션입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "AWS Lambda",
      "Amazon RDS for PostgreSQL",
      "자동 회전",
      "보안 자격 증명",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "AWS Key Management Service (AWS KMS)",
      "Amazon RDS for PostgreSQL",
      "AWS Lambda",
      "Node.js",
      "PostgreSQL"
    ],
    "SelectA": "AWS Systems Manager Parameter Store에 데이터베이스 자격 증명을 파라미터로 저장합니다. 매 30일마다 자동으로 시크릿을 회전하도록 Parameter Store를 구성합니다. 그리고 Lambda 함수가 해당 파라미터에서 자격 증명을 가져오도록 업데이트합니다.",
    "SelectA_Commentary": "Parameter Store도 자격 증명 관리를 지원하나, Secrets Manager에 비해 자동 회전 및 보안 기능 사용이 다소 제한적이고 설정이 복잡해질 수 있습니다.",
    "SelectB": "AWS Secrets Manager에 데이터베이스 자격 증명을 시크릿으로 저장합니다. Secrets Manager에서 매 30일마다 자격 증명을 자동 회전하도록 설정합니다. 그리고 Lambda 함수가 해당 시크릿에서 자격 증명을 가져오도록 업데이트합니다.",
    "SelectB_Commentary": "AWS Secrets Manager는 데이터베이스 자격 증명을 안전하게 저장하고 쉽게 자동 회전할 수 있도록 디자인된 서비스이므로, 운영 오버헤드가 가장 낮고 보안성이 뛰어난 정답입니다.",
    "SelectC": "암호화된 Lambda 환경 변수로 데이터베이스 자격 증명을 저장합니다. 자격 증명을 회전하기 위한 커스텀 Lambda 함수를 작성하고, 이를 30일마다 실행하도록 스케줄링합니다.",
    "SelectC_Commentary": "커스텀 함수를 만들어 직접 회전 로직을 관리해야 해서 운영 오버헤드가 증가하며, 자동화 측면에서도 추가 관리가 필요합니다.",
    "SelectD": "AWS Key Management Service(AWS KMS)에 데이터베이스 자격 증명을 키로 저장합니다. 해당 키에 대해 자동 회전을 설정합니다. 그리고 Lambda 함수가 KMS 키에서 자격 증명을 가져오도록 업데이트합니다.",
    "SelectD_Commentary": "AWS KMS는 암호화 키 관리 서비스로, 데이터베이스 접속 자격 증명을 직접 저장·회전하기에는 적합하지 않습니다. 자동 회전 범위도 주로 암호화 키에 한정되므로 요구 사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q847",
      "Q1007",
      "Q16",
      "Q732",
      "Q61"
    ],
    "SelectA_recommedations": [
      "Q179",
      "Q936",
      "Q289"
    ],
    "SelectB_recommedations": [
      "Q936",
      "Q640",
      "Q289"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectD_recommedations": [
      "Q640",
      "Q916",
      "Q550"
    ]
  },
  {
    "Question_Number": "Q948",
    "Question_Description": "한 회사가 온프레미스 Oracle 데이터베이스에서 Amazon RDS for Oracle로 기존 및 진행 중인 데이터 변경 사항을 복제하고자 합니다. 매일 복제해야 하는 데이터 양은 시간대에 따라 달라집니다. 회사는 AWS Database Migration Service(AWS DMS)를 사용해 데이터 복제를 구현하려고 합니다. 솔루션은 복제 인스턴스가 필요한 용량만 할당해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144936-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Oracle 데이터베이스에서 Amazon RDS for Oracle로 데이터를 전송할 때, 복제 트래픽의 변동에 맞춰 필요한 용량만 사용하여 비용 효율성을 극대화함이 핵심입니다. AWS DMS Serverless를 사용하면 자동으로 복제 작업에 필요한 컴퓨팅 및 메모리 리소스를 할당하고 관리하여, 복제 인스턴스가 요구하는 만큼만 용량을 사용하므로 비용 효율과 운영 편의성을 동시에 충족할 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "AWS Database Migration Service",
      "Oracle",
      "Amazon RDS for Oracle",
      "Serverless",
      "데이터 복제",
      "자동 용량 할당"
    ],
    "Terms": [
      "AWS Database Migration Service(AWS DMS)",
      "Oracle",
      "Amazon RDS for Oracle",
      "AWS DMS Serverless",
      "Amazon EC2 Auto Scaling",
      "Amazon ECS",
      "AWS Fargate"
    ],
    "SelectA": "복제 인스턴스를 Multi-AZ 배포로 구성하여 여러 가용 영역에 걸쳐 인스턴스를 프로비저닝합니다.",
    "SelectA_Commentary": "Multi-AZ 배포는 고가용성을 위해 유용하나, 자동으로 필요한 용량만큼만 할당해주지는 않습니다.",
    "SelectB": "AWS DMS Serverless 복제 태스크를 생성하여 데이터를 분석하고 복제하면서 필요한 용량을 프로비저닝합니다.",
    "SelectB_Commentary": "AWS DMS Serverless는 복제 워크로드에 따라 용량을 자동으로 조정하여 필요한 만큼만 사용하므로 최적의 비용 효율을 제공합니다.",
    "SelectC": "Amazon EC2 Auto Scaling을 이용하여 복제해야 할 데이터 양을 기준으로 AWS DMS 복제 인스턴스 크기를 상하로 조정합니다.",
    "SelectC_Commentary": "EC2 Auto Scaling으로 인스턴스를 자동 조정할 수 있지만, DMS 전용 Serverless 옵션처럼 세밀하게 용량을 관리하기 어렵고 설정이 복잡합니다.",
    "SelectD": "Amazon Elastic Container Service(Amazon ECS)를 사용하고 AWS Fargate 런치 타입으로 AWS DMS 복제 용량을 프로비저닝하여 데이터를 분석하고 복제합니다.",
    "SelectD_Commentary": "ECS와 Fargate를 조합하면 컨테이너 단위로 확장이 가능하지만, DMS Serverless만큼 간단히 자동 용량 할당을 제공하지 않으며 추가 설정이 필요합니다.",
    "Question_Description_recommedations": [
      "Q959",
      "Q574",
      "Q449",
      "Q579",
      "Q436"
    ],
    "SelectA_recommedations": [
      "Q997",
      "Q630",
      "Q656"
    ],
    "SelectB_recommedations": [
      "Q128",
      "Q300",
      "Q284"
    ],
    "SelectC_recommedations": [
      "Q290",
      "Q505",
      "Q822"
    ],
    "SelectD_recommedations": [
      "Q926",
      "Q591",
      "Q800"
    ]
  },
  {
    "Question_Number": "Q949",
    "Question_Description": "한 회사가 다중 계층 웹 애플리케이션을 운영 중이며, 애플리케이션의 내부 서비스 컴포넌트는 Amazon EC2 인스턴스에 배포되어 있습니다. 이 내부 서비스 컴포넌트들은 AWS 상에서 호스팅되는 서드파티 소프트웨어형 서비스(SaaS) API에 액세스해야 합니다. 회사는 애플리케이션 내부 서비스와 이 서드파티 SaaS 애플리케이션 간에 보안적이고 사설적인 연결을 제공해야 하며, 퍼블릭 인터넷 노출을 최소화해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144937-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 상에서 제공되는 서드파티 SaaS API와 사설 경로로 통신해야 할 때, 가장 안전하고 퍼블릭 인터넷 노출을 최소화하는 방법을 묻습니다. AWS PrivateLink는 VPC 엔드포인트를 통해 내부 트래픽이 사설 IP로만 SaaS에 연결되도록 하여, 인터넷을 거치지 않는 안전하고 사적인 연결을 제공합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "내부 서비스 컴포넌트",
      "서드파티 SaaS",
      "퍼블릭 인터넷 노출 최소화",
      "AWS PrivateLink"
    ],
    "Terms": [
      "Amazon EC2",
      "AWS Site-to-Site VPN",
      "AWS Transit Gateway",
      "AWS PrivateLink",
      "VPC",
      "SaaS",
      "TCP",
      "보안 연결"
    ],
    "SelectA": "서드파티 SaaS 제공 업체와의 보안 연결을 위해 AWS Site-to-Site VPN을 구성합니다.",
    "SelectA_Commentary": "Site-to-Site VPN은 인터넷을 활용하므로 퍼블릭 노출을 완전히 제외하기 어렵고, VPN 터널 설정 및 관리로 운영 복잡도가 상대적으로 높습니다.",
    "SelectB": "AWS Transit Gateway를 배포하여 애플리케이션의 VPC와 서드파티 SaaS 제공 업체 간 트래픽을 관리하고 라우팅합니다.",
    "SelectB_Commentary": "Transit Gateway는 다수의 VPC와 온프레미스를 연결하는 데 유용하지만, SaaS 사용 시에 퍼블릭 엔드포인트를 거쳐야 할 수 있어 퍼블릭 노출을 완전히 방지하기가 어렵습니다.",
    "SelectC": "VPC에서 아웃바운드 트래픽만 허용하도록 AWS PrivateLink를 구성하되, 서드파티 SaaS 제공 업체가 연결을 설정하지 못하도록 제한합니다.",
    "SelectC_Commentary": "PrivateLink 자체가 단방향 통신을 지원하지만, 이 설정만으로는 SaaS 쪽에서 서비스를 제공받기 위한 완전한 사설 연결 구성이 보장되지 않습니다.",
    "SelectD": "애플리케이션의 VPC와 서드파티 SaaS 제공 업체 간 프라이빗 연결을 위해 AWS PrivateLink를 사용합니다.",
    "SelectD_Commentary": "AWS PrivateLink를 통해 트래픽이 사설 IP를 통해서만 전달되므로 퍼블릭 인터넷 노출을 효과적으로 차단하며, 보안과 사설성을 모두 충족하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q492",
      "Q480",
      "Q315",
      "Q17",
      "Q34"
    ],
    "SelectA_recommedations": [
      "Q782",
      "Q810",
      "Q970"
    ],
    "SelectB_recommedations": [
      "Q15",
      "Q159",
      "Q950"
    ],
    "SelectC_recommedations": [
      "Q15",
      "Q950",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q15",
      "Q950",
      "Q135"
    ]
  },
  {
    "Question_Number": "Q950",
    "Question_Description": "한 솔루션스 아키텍트가 회사의 온프레미스 네트워크를 VPC와 연결하여 온프레미스 환경에서 AWS 리소스에 접근해야 합니다. 이 솔루션은 회사 네트워크와 VPC 간의 모든 트래픽을 네트워크 계층과 세션 계층에서 암호화해야 합니다. 또한 AWS와 온프레미스 시스템 간 무제한 접근을 방지하기 위한 보안 제어가 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144938-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스와 AWS 간 트래픽을 네트워크 및 세션 계층에서 암호화하고, 보안 제어를 통해 접근을 제한해야 하는 상황입니다. VPN을 통한 IPsec 터널링이 대표적인 해결책이며, 보안 그룹과 NACL을 사용해 트래픽을 제한합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "네트워크 계층 암호화",
      "세션 계층 암호화",
      "보안 제어",
      "온프레미스",
      "AWS Site-to-Site VPN",
      "AWS 리소스 접근"
    ],
    "Terms": [
      "AWS Direct Connect",
      "AWS Site-to-Site VPN",
      "AWS Transit Gateway",
      "VPC",
      "암호화",
      "네트워크 계층",
      "세션 계층",
      "Security Group",
      "Network ACL"
    ],
    "SelectA": "AWS Direct Connect를 구성하여 VPC에 연결합니다. 필요한 경우 AWS와 온프레미스 간 트래픽을 허용하거나 거부하도록 VPC 라우트 테이블을 구성합니다.",
    "SelectA_Commentary": "AWS Direct Connect 자체로는 네트워크 계층 암호화를 제공하지 않으므로 요구사항을 충족하지 못합니다.",
    "SelectB": "IAM 정책을 만들어 사내 IP 주소 범위에서만 AWS Management Console에 접근을 허용합니다. IAM 정책과 역할을 사용하여 직무별로 사용자 접근을 제한합니다.",
    "SelectB_Commentary": "IAM 정책과 역할은 콘솔 접근 제어에는 유용하지만 VPN 연결을 통한 네트워크 계층 암호화를 제공하지 못하므로 요구사항을 만족시키지 못합니다.",
    "SelectC": "AWS Site-to-Site VPN을 구성해 VPC에 연결합니다. 라우트 테이블에 온프레미스 트래픽이 VPC로 가도록 설정합니다. 인스턴스 Security Group과 Network ACL을 구성해 필요한 트래픽만 허용합니다.",
    "SelectC_Commentary": "Site-to-Site VPN은 IPsec 터널로 네트워크 레벨 암호화를 제공하며, SG와 NACL로 접근을 제한해 보안 요구사항을 만족합니다. 정답입니다.",
    "SelectD": "AWS Transit Gateway를 구성하여 VPC에 연결합니다. 라우트 테이블을 구성해 온프레미스 트래픽을 VPC로 보내도록 하고, 인스턴스 Security Group과 Network ACL을 통해 필요한 트래픽만 허용합니다.",
    "SelectD_Commentary": "Transit Gateway 자체는 암호화를 보장하지 않으며, 추가로 VPN을 구성해야 네트워크 계층 암호화를 구현할 수 있으므로 요구사항을 직접적으로 충족하지 않습니다.",
    "Question_Description_recommedations": [
      "Q15",
      "Q151",
      "Q19",
      "Q866",
      "Q92"
    ],
    "SelectA_recommedations": [
      "Q950",
      "Q15",
      "Q810"
    ],
    "SelectB_recommedations": [
      "Q96",
      "Q222",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q782",
      "Q712",
      "Q950"
    ],
    "SelectD_recommedations": [
      "Q950",
      "Q135",
      "Q19"
    ]
  },
  {
    "Question_Number": "Q951",
    "Question_Description": "회사는 Amazon RDS for MySQL DB cluster에서 정보를 조회하는 커스텀 애플리케이션을 운영 중이며, 현재 애플리케이션 코드 안에 자격 증명이 내장되어 있습니다. 회사는 최소한의 프로그래밍 노력으로 보안을 강화하기 위해, 이미 RDS for MySQL 데이터베이스에 애플리케이션 사용자 자격 증명을 생성해 두었습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145017-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 애플리케이션 코드 내부의 자격 증명을 안전하고 효율적으로 관리할 방법을 묻고 있습니다. 직접 하드코딩하지 않고 쉽고 빠르게 자격 증명을 연동할 수 있으며 자동 로테이션이 가능한 AWS Secrets Manager가 최적의 선택입니다. 따라서 SelectC가 정답입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "자격 증명",
      "보안",
      "Amazon RDS for MySQL",
      "AWS Secrets Manager",
      "자동 로테이션"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "RDS for MySQL",
      "AWS Lambda",
      "Credentials Rotation"
    ],
    "SelectA": "AWS Key Management Service (AWS KMS)에 자격 증명을 저장하고, 키를 생성한 뒤 애플리케이션이 해당 키를 통해 데이터베이스 자격 증명을 불러오도록 구성합니다. 자동 키 로테이션을 활성화합니다.",
    "SelectA_Commentary": "KMS는 암호화 키 관리를 주로 담당하며, 자격 증명을 직접 로테이션하는 기능이 없습니다. 따로 로직을 구현해야 하므로 프로그래밍 노력이 더 필요합니다.",
    "SelectB": "로컬에 암호화된 스토리지를 두고 애플리케이션이 거기서 자격 증명을 불러오도록 구성합니다. cron 작업을 통해 자격 증명 로테이션 일정을 설정합니다.",
    "SelectB_Commentary": "로컬 스토리지 사용은 운영 부담이 크고, 자체적으로 로테이션 스크립트를 구성해야 하므로 보안 유지와 자동화 측면에서 비효율적입니다.",
    "SelectC": "AWS Secrets Manager에 자격 증명을 저장하고, 애플리케이션이 Secrets Manager에서 자격 증명을 불러오도록 구성합니다. AWS Lambda 함수를 이용하여 자격 증명 로테이션 스케줄을 설정합니다.",
    "SelectC_Commentary": "AWS Secrets Manager는 자격 증명 저장 및 자동 로테이션을 지원하므로 보안 강화와 자동화 구현 모두 간편합니다. 추가 코딩 작업이 적어 요구 사항을 효과적으로 충족합니다.",
    "SelectD": "AWS Systems Manager Parameter Store에 자격 증명을 저장하고, 애플리케이션이 Parameter Store에서 자격 증명을 불러오도록 구성합니다. Parameter Store를 통해 RDS for MySQL에서 자격 증명 로테이션 스케줄을 설정합니다.",
    "SelectD_Commentary": "Parameter Store는 보안을 제공하지만, Secrets Manager처럼 DB 자격 증명 자동 로테이션을 간단히 설정하는 기능은 제한적입니다. 추가 작업이 더 필요합니다.",
    "Question_Description_recommedations": [
      "Q13",
      "Q86",
      "Q992",
      "Q330",
      "Q742"
    ],
    "SelectA_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectB_recommedations": [
      "Q665",
      "Q122",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q791",
      "Q936",
      "Q289"
    ],
    "SelectD_recommedations": [
      "Q179",
      "Q847",
      "Q977"
    ]
  },
  {
    "Question_Number": "Q952",
    "Question_Description": "한 회사가 어플리케이션을 서버리스(Serverless) 솔루션으로 이전하려고 합니다. 이 서버리스 솔루션은 기존 데이터와 신규 데이터를 SQL을 통해 분석해야 합니다. 회사는 데이터를 Amazon S3 버킷에 저장하고 있으며, 저장 중 암호화가 적용되어야 하고 다른 AWS Region으로 복제되어야 합니다. 이러한 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144939-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 서버리스 환경에서 Amazon S3의 데이터를 안전하고 간편하게 분석하기 위한 방법을 묻습니다. 저장 중 암호화와 리전 간 복제가 필요하며, SQL 분석 도구로는 서버리스인 Amazon Athena가 적합합니다. AWS KMS multi-Region 키를 사용하면 복제되는 데이터도 동일하게 보호받을 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "서버리스 솔루션",
      "SQL 분석",
      "Amazon S3 버킷",
      "암호화",
      "크로스 리전 복제",
      "AWS KMS multi-Region keys"
    ],
    "Terms": [
      "Amazon S3",
      "AWS KMS multi-Region keys (SSE-KMS)",
      "Amazon S3 managed keys (SSE-S3)",
      "Cross-Region Replication (CRR)",
      "Amazon Athena",
      "Amazon RDS",
      "Serverless"
    ],
    "SelectA": "AWS KMS multi-Region keys (SSE-KMS)로 서버 사이드 암호화가 적용된 새로운 S3 버킷을 생성하고, Cross-Region Replication을 구성합니다. 해당 버킷에 데이터를 적재한 뒤, Amazon Athena로 데이터를 쿼리합니다.",
    "SelectA_Commentary": "포괄적인 암호화와 자동 복제, 그리고 Athena를 이용한 서버리스 SQL 분석으로 운영 오버헤드가 가장 적고 요구사항을 모두 만족합니다.",
    "SelectB": "Amazon S3 managed keys (SSE-S3)를 사용하는 새로운 S3 버킷을 생성하고, Cross-Region Replication을 구성합니다. 해당 버킷에 데이터를 적재한 뒤, Amazon RDS로 데이터를 쿼리합니다.",
    "SelectB_Commentary": "Amazon RDS는 서버리스가 아니므로 운영 오버헤드가 큽니다. 또한 SSE-S3는 복제에는 문제가 없지만, SSE-KMS multi-Region 키에 비해 유연성이 떨어집니다.",
    "SelectC": "기존 S3 버킷에서 Cross-Region Replication을 구성하고, Amazon S3 managed keys (SSE-S3)를 사용합니다. 기존 버킷의 데이터를 Amazon Athena로 쿼리합니다.",
    "SelectC_Commentary": "데이터 암호화와 복제는 가능하지만, 기존 버킷 설정과 CRR 적용에 따른 관리가 필요합니다. SSE-S3 사용 시 다중 리전 키의 이점을 활용하지 못합니다.",
    "SelectD": "기존 S3 버킷에서 S3 Cross-Region Replication을 구성하고, AWS KMS multi-Region keys (SSE-KMS)를 사용합니다. Amazon RDS로 데이터를 쿼리합니다.",
    "SelectD_Commentary": "암호화와 복제는 적절하게 구성되지만, RDS 운영이 추가되어 서버리스 요건을 만족하지 못하고 관리 부담도 늘어납니다.",
    "Question_Description_recommedations": [
      "Q1007",
      "Q965",
      "Q134",
      "Q480",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q36",
      "Q1009",
      "Q916"
    ],
    "SelectB_recommedations": [
      "Q868",
      "Q740",
      "Q889"
    ],
    "SelectC_recommedations": [
      "Q868",
      "Q889",
      "Q740"
    ],
    "SelectD_recommedations": [
      "Q36",
      "Q663",
      "Q681"
    ]
  },
  {
    "Question_Number": "Q953",
    "Question_Description": "한 회사에 웹 애플리케이션이 있으며 수천 명의 사용자가 있습니다. 이 애플리케이션은 사용자가 업로드한 8~10장의 이미지를 사용해 AI 이미지를 생성합니다. 일반 사용자는 생성된 AI 이미지를 6시간에 한 번씩 다운로드할 수 있고, 프리미엄 사용자는 언제든지 다운로드가 가능합니다. 이 회사는 업로드된 이미지를 연 2회 AI 모델 학습에 활용합니다. 이미지를 저장하기 위한 스토리지 솔루션이 필요하며, 가장 비용 효율적인 방안을 원합니다. 어떤 스토리지 솔루션이 이 요구사항을 가장 잘 충족합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145540-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사용자 업로드 이미지를 저빈도 사용 패턴에 맞춰 저렴하게 보관하고, 생성된 AI 이미지는 접근 빈도에 따라 적절한 S3 스토리지 클래스를 선택해 비용을 절감하는 데 초점을 둡니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "이미지 저장",
      "AI 모델 학습",
      "프리미엄 사용자",
      "일반 사용자",
      "다운로드 빈도",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3 Glacier Deep Archive",
      "S3 Standard",
      "S3 Standard-Infrequent Access (S3 Standard-IA)",
      "S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "S3 Glacier Flexible Retrieval"
    ],
    "SelectA": "업로드 이미지를 Amazon S3 Glacier Deep Archive로 옮기고, 프리미엄 사용자가 생성한 AI 이미지는 S3 Standard로, 일반 사용자가 생성한 AI 이미지는 S3 Standard-IA로 옮깁니다.",
    "SelectA_Commentary": "연 2회만 사용되는 원본 이미지는 Deep Archive로 최소 비용에 보관하고, 다운로드 빈도가 높은 프리미엄 사용자 이미지는 S3 Standard, 상대적으로 적은 일반 사용자 이미지는 S3 Standard-IA가 적합합니다.",
    "SelectB": "업로드 이미지를 Amazon S3 Glacier Deep Archive로 옮기고, 생성된 모든 AI 이미지를 S3 Glacier Flexible Retrieval로 옮깁니다.",
    "SelectB_Commentary": "생성된 AI 이미지는 자주 액세스되므로 Glacier Flexible Retrieval는 너무 느리고 Retrieval 비용도 발생해 요구사항에 부적합합니다.",
    "SelectC": "업로드 이미지를 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)로 옮기고, 프리미엄 사용자 생성 AI 이미지는 S3 Standard, 일반 사용자 생성 AI 이미지는 S3 Standard-IA로 옮깁니다.",
    "SelectC_Commentary": "One Zone-IA는 단일 가용 영역만 사용해 내구성 측면에서 위험이 크고, 연 2회 접근 이미지는 Deep Archive가 더 저렴합니다.",
    "SelectD": "업로드 이미지를 Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)로 옮기고, 생성된 모든 AI 이미지를 S3 Glacier Flexible Retrieval로 옮깁니다.",
    "SelectD_Commentary": "원본 이미지를 One Zone-IA에 보관하는 것은 Deep Archive 대비 비용 이점이 작고, 모든 AI 이미지를 Glacier Flexible Retrieval에 저장하면 자주 다운로드 시 매우 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q49",
      "Q630",
      "Q794",
      "Q930",
      "Q656"
    ],
    "SelectA_recommedations": [
      "Q912",
      "Q126",
      "Q356"
    ],
    "SelectB_recommedations": [
      "Q912",
      "Q285",
      "Q943"
    ],
    "SelectC_recommedations": [
      "Q415",
      "Q356",
      "Q23"
    ],
    "SelectD_recommedations": [
      "Q912",
      "Q943",
      "Q486"
    ]
  },
  {
    "Question_Number": "Q954",
    "Question_Description": "회사는 AWS에서 Machine Learning(ML) 모델을 개발 중입니다. 이 모델들을 독립된 microservice로 개발하고 있으며, 각 microservice는 시작 시 Amazon S3에서 약 1GB 정도의 모델 데이터를 가져와 메모리에 로드합니다. 사용자는 비동기 API를 통해 ML 모델에 접근하며, 단일 요청뿐 아니라 배치 요청도 가능합니다. 회사는 수백 명의 사용자에게 ML 모델을 제공하고 있는데, 모델별 사용 패턴이 불규칙하여 며칠 혹은 몇 주간 전혀 사용되지 않는 경우도 있고, 한 번에 수천 건의 대량 요청이 들어오는 경우도 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145943-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 매우 불규칙한 트래픽 패턴을 처리하고, 대기 중에는 리소스 사용을 최소화하며, 대규모 요청이 몰릴 때 신속히 확장할 수 있는 구조를 설계하는 것입니다. Amazon SQS를 통해 요청을 큐잉하고, Amazon ECS 서비스로 데이터를 처리하면서 Auto Scaling을 통해 클러스터 용량과 서비스 개수를 유연하게 확장하는 SelectD가 최적의 해법입니다. 큐를 이용하면 로드가 급증하는 순간에도 메시지 손실 없이 안정적으로 처리할 수 있고, 사용량이 낮을 때는 리소스를 줄여 비용을 절감할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "ML 모델",
      "비동기 API",
      "Amazon S3",
      "1GB 로드",
      "불규칙한 사용 패턴",
      "배치 요청",
      "auto scaling"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon SQD (오타가 아닌지 확인 필요: 이 문제에서 SQS로 언급. 정정 필요)",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Network Load Balancer (NLB)",
      "Application Load Balancer (ALB)",
      "Auto Scaling",
      "vCPU",
      "ECS cluster"
    ],
    "SelectA": "API에서 오는 요청을 Network Load Balancer(NLB)로 전달합니다. ML 모델들은 AWS Lambda 함수로 배포되고, NLB 트래픽에 따라 Lambda 함수를 auto scaling으로 확장합니다.",
    "SelectA_Commentary": "Lambda 함수는 cold start가 빈번해질 수 있고, 1GB 이상의 모델 로드 시 시작 시간이 길어질 수 있습니다. 또한 NLB 호출 구성은 비동기 요청의 대량 배치 처리에 적합하지 않아 비효율적입니다.",
    "SelectB": "API에서 오는 요청을 Application Load Balancer(ALB)로 전달합니다. ML 모델들은 Amazon ECS 서비스로 배포되고, ALB 트래픽에 따라 ECS 클러스터 인스턴스를 auto scaling으로 확장합니다.",
    "SelectB_Commentary": "ALB는 HTTP(S) 트래픽을 처리하는 데 적합하지만, 불규칙한 배치 트래픽을 효율적으로 버퍼링하지 못하므로 트래픽이 급격히 몰릴 경우 서비스 지연이 발생할 수 있습니다.",
    "SelectC": "API 요청을 Amazon SQS 큐로 전달합니다. ML 모델들은 AWS Lambda 함수로 배포되고, SQS 큐 크기에 따라 Lambda 함수의 vCPU를 auto scaling으로 증가시킵니다.",
    "SelectC_Commentary": "Lambda 함수는 기본적으로 vCPU 개념이 아니라 동시 실행 수로 확장됩니다. 1GB 이상의 모델을 로드하는 Lambda 함수는 시작 지연이 커질 가능성이 커서 대량 트래픽 처리에 부담이 있습니다.",
    "SelectD": "API 요청을 Amazon SQS 큐로 전달합니다. ML 모델들은 Amazon ECS 서비스로 배포되고, 서비스가 SQS 큐에서 메시지를 읽도록 구성합니다. Amazon ECS auto scaling을 통해 큐 크기에 따라 클러스터 용량과 서비스 개수를 조정합니다.",
    "SelectD_Commentary": "비동기 처리를 위해 SQS를 통해 요청을 버퍼링하고, Amazon ECS가 컨테이너를 확장해 모델을 처리하므로 불규칙하고 대규모의 트래픽도 안정적으로 처리 가능합니다. 따라서 요구 사항을 가장 잘 충족하는 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q422",
      "Q52",
      "Q721",
      "Q18",
      "Q114"
    ],
    "SelectA_recommedations": [
      "Q70",
      "Q405",
      "Q545"
    ],
    "SelectB_recommedations": [
      "Q405",
      "Q174",
      "Q589"
    ],
    "SelectC_recommedations": [
      "Q351",
      "Q422",
      "Q954"
    ],
    "SelectD_recommedations": [
      "Q422",
      "Q210",
      "Q954"
    ]
  },
  {
    "Question_Number": "Q955",
    "Question_Description": "한 회사가 Application Load Balancer(ALB) 뒤에 있는 Auto Scaling group의 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있습니다. 애플리케이션은 Amazon Aurora MySQL DB cluster에 데이터를 저장합니다. 회사는 재해 복구(DR) 솔루션을 구축해야 하며, 허용 가능한 복구 시간(RTO)은 최대 30분입니다. 주 인프라가 정상 동작할 때에는 DR 솔루션이 고객 사용을 지원할 필요가 없습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146208-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 30분 이내에 복구가 가능한 DR 아키텍처를 설계하는 상황입니다. 정상 시엔 사용되지 않는 상태(워ーム 스탠바이)로 두고, 장애 시 빠르게 활성화할 수 있어야 합니다. Aurora global database로 데이터를 실시간 복제하고, ALB와 Auto Scaling group의 용량을 최소로 두어 RTO 요구사항을 충족하는 구성이 핵심입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DR 솔루션",
      "복구 시간(RTO) 30분",
      "warm standby",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon Aurora MySQL DB cluster",
      "Aurora global database",
      "active-passive",
      "Amazon Route 53"
    ],
    "Terms": [
      "DR",
      "RTO",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Amazon Aurora MySQL",
      "Aurora global database",
      "Amazon Route 53",
      "AWS Backup",
      "active-active failover",
      "active-passive failover"
    ],
    "SelectA": "두 번째 AWS Region에 ALB와 Auto Scaling group으로 DR 인프라를 배포합니다. Auto Scaling group의 desired capacity와 maximum capacity를 최소값으로 설정합니다. Aurora MySQL DB cluster를 Aurora global database로 변환합니다. Amazon Route 53을 사용하여 ALB 엔드포인트로 active-passive failover를 구성합니다.",
    "SelectA_Commentary": "워ーム 스탠바이 방식으로, 최소 리소스만 항상 준비해 두었다가 장애 시 빠르게 확장할 수 있어 30분 내 RTO를 만족합니다. Aurora global database로 실시간 데이터 복제가 가능하므로 DR 요구사항에 부합합니다.",
    "SelectB": "두 번째 AWS Region에 DR 인프라를 ALB와 함께 배포합니다. Auto Scaling group을 업데이트하여 두 번째 Region의 EC2 인스턴스를 포함하도록 합니다. Amazon Route 53을 사용하여 active-active failover를 구성합니다. Aurora MySQL DB cluster를 Aurora global database로 변환합니다.",
    "SelectB_Commentary": "active-active 구성은 양쪽 리전을 모두 운영해야 하므로 DR 솔루션이 주 인프라가 정상일 때 사용되지 않아도 된다는 요구사항에 부합하지 않습니다.",
    "SelectC": "AWS Backup을 사용하여 Aurora MySQL DB cluster 데이터를 백업합니다. 두 번째 AWS Region에 ALB로 DR 인프라를 배포합니다. Auto Scaling group을 업데이트하여 두 번째 Region의 EC2 인스턴스를 포함하도록 합니다. Amazon Route 53을 사용하여 active-active failover를 구성합니다. 두 번째 Region에서 Aurora MySQL DB cluster를 생성하고 백업에서 데이터를 복원합니다.",
    "SelectC_Commentary": "백업 및 복원 절차는 시간이 많이 소요되어 30분 이내 RTO 보장이 어렵고, active-active로 구성하는 점 역시 요구사항과 맞지 않습니다.",
    "SelectD": "AWS Backup을 사용하여 인프라 구성을 백업합니다. 백업을 사용하여 두 번째 AWS Region에 필요한 인프라를 생성합니다. Auto Scaling group의 desired capacity를 0으로 설정합니다. Amazon Route 53을 사용하여 active-passive failover를 구성합니다. Aurora MySQL DB cluster를 Aurora global database로 변환합니다.",
    "SelectD_Commentary": "인프라 구성을 백업에서 새로 생성하는 과정은 시간이 걸려 RTO를 맞추기 어렵습니다. Aurora global database 전환 자체는 유용하지만, 인프라 전반을 백업으로 재생성하는 접근은 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q390",
      "Q874",
      "Q405",
      "Q217",
      "Q69"
    ],
    "SelectA_recommedations": [
      "Q955",
      "Q874",
      "Q527"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q955",
      "Q527"
    ],
    "SelectC_recommedations": [
      "Q955",
      "Q338",
      "Q874"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q955",
      "Q527"
    ]
  },
  {
    "Question_Number": "Q956",
    "Question_Description": "한 회사가 Data Processing Application을 AWS Cloud로 마이그레이션하고 있습니다. 이 Application은 중단될 수 없는 단기간 Batch Jobs들을 처리합니다. 각 Batch Job이 완료될 때마다 Data가 생성되며, 이 Data는 30일 동안 액세스되고 2년 동안 보관됩니다. 회사는 AWS Cloud에서 애플리케이션을 운영하는 비용을 최대한 절감하고 싶어합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145012-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 중단이 허용되지 않는 Batch Jobs 환경에서, 30일 동안 자주 액세스되는 데이터를 이후 2년간 장기 보관하기 위한 비용 최적화 전략을 묻습니다. Spot Instances는 중단 가능성이 있으므로 적합하지 않고, 스토리지 계층화로 표준 스토리지와 장기 아카이브를 적절히 사용해야 합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1",
      "4.2"
    ],
    "Keywords": [
      "Data Processing Application",
      "Batch Jobs",
      "중단 불가",
      "비용 절감",
      "Amazon EC2 On-Demand Instances",
      "Amazon S3 Standard",
      "Amazon S3 Glacier Deep Archive",
      "2년 보관"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instances",
      "Amazon EC2 Spot Instances",
      "Amazon S3 Standard",
      "Amazon S3 Glacier Instant Retrieval",
      "Amazon S3 Glacier Flexible Retrieval",
      "Amazon S3 Glacier Deep Archive",
      "Expiration"
    ],
    "SelectA": "Data Processing Application을 Amazon EC2 Spot Instances로 마이그레이션합니다. Data를 Amazon S3 Standard에 저장합니다. 30일 후 Amazon S3 Glacier Instant Retrieval로 이동합니다. 2년 후 Data를 삭제하도록 Expiration을 설정합니다.",
    "SelectA_Commentary": "Spot Instances는 중단 위험이 있어 Batch Jobs가 중단될 수 있으므로 부적합합니다. 또한 Glacier Instant Retrieval은 2년간 보관 시에는 더 저렴한 Glacier Deep Archive가 적합합니다.",
    "SelectB": "Data Processing Application을 Amazon EC2 On-Demand Instances로 마이그레이션합니다. Data를 Amazon S3 Glacier Instant Retrieval에 저장합니다. 30일 후 S3 Glacier Deep Archive로 이동합니다. 2년 후 Data를 삭제하도록 Expiration을 설정합니다.",
    "SelectB_Commentary": "초기 30일간은 잦은 액세스를 위해 S3 Standard가 적합합니다. 초기부터 Glacier Instant Retrieval을 사용하면 즉시 액세스 비용이 비효율적일 수 있습니다.",
    "SelectC": "Batch Jobs를 Amazon EC2 Spot Instances에서 구동합니다. Data를 Amazon S3 Standard에 저장합니다. 30일 후 Amazon S3 Glacier Flexible Retrieval로 이동합니다. 2년 후 Data를 삭제하도록 Expiration을 설정합니다.",
    "SelectC_Commentary": "Spot Instances는 중단될 수 있어 요구사항을 만족하지 못합니다. 또한 Glacier Flexible Retrieval은 Deep Archive에 비해 장기 보관 비용효율이 낮습니다.",
    "SelectD": "Batch Jobs를 Amazon EC2 On-Demand Instances에서 구동합니다. Data를 Amazon S3 Standard에 저장합니다. 30일 후 Amazon S3 Glacier Deep Archive로 이동합니다. 2년 후 Data를 삭제하도록 Expiration을 설정합니다.",
    "SelectD_Commentary": "중단될 수 없는 Batch Jobs는 On-Demand Instances가 적합하고, 처음 30일은 S3 Standard로 빠른 액세스를 제공하며, 이후 2년 장기 보관 시 Glacier Deep Archive로 전환해 비용을 절감합니다. 정답입니다.",
    "Question_Description_recommedations": [
      "Q160",
      "Q449",
      "Q380",
      "Q979",
      "Q128"
    ],
    "SelectA_recommedations": [
      "Q956",
      "Q552",
      "Q904"
    ],
    "SelectB_recommedations": [
      "Q956",
      "Q1008",
      "Q505"
    ],
    "SelectC_recommedations": [
      "Q956",
      "Q904",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q956",
      "Q160",
      "Q943"
    ]
  },
  {
    "Question_Number": "Q957",
    "Question_Description": "한 회사가 하이브리드 네트워크 아키텍처를 설계해야 합니다. 이 회사의 워크로드는 현재 AWS Cloud와 온프레미스 데이터 센터에 저장되어 있으며, 통신 시 한 자리(ms) 수준의 지연 시간이 필요합니다. 회사는 여러 VPC를 연결하기 위해 AWS Transit Gateway를 사용합니다. 가장 비용 효율적으로 이러한 요구 사항을 충족하기 위해 선택해야 할 단계 조합은 무엇입니까? (2개를 고르시오.)",
    "Answer": "B,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145777-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "온프레미스와 AWS 간에 낮은 지연 시간(싱글 디짓)을 달성하기 위해서는 전용 회선인 AWS Direct Connect를 활용하는 것이 핵심입니다. 또한 AWS Transit Gateway와 Direct Connect gateway를 함께 사용하면 여러 VPC를 단일 네트워크로 통합하여 효율적이고 일관된 연결 및 비용 절감을 이룰 수 있습니다. 따라서 B와 D 조합이 최적의 해법입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "하이브리드 네트워크",
      "single-digit latency",
      "비용 효율",
      "AWS Transit Gateway",
      "Direct Connect gateway"
    ],
    "Terms": [
      "AWS Transit Gateway",
      "VPC",
      "AWS Direct Connect",
      "AWS Direct Connect gateway",
      "AWS Site-to-Site VPN"
    ],
    "SelectA": "각 VPC에 대해 AWS Site-to-Site VPN 연결을 설정합니다.",
    "SelectA_Commentary": "VPC마다 VPN이 필요해 관리 및 비용이 크게 증가하며, 안정적으로 단일 자리 레이턴시를 보장하기 어려우므로 적합하지 않습니다.",
    "SelectB": "Transit Gateway가 연결된 VPC에 AWS Direct Connect gateway를 연결(Associate)합니다.",
    "SelectB_Commentary": "Transit Gateway와 Direct Connect gateway를 연동해 여러 VPC에 대해 저지연 전용 네트워크 경로를 제공하므로 성능과 비용 효율 모두에 유리합니다.",
    "SelectC": "AWS Direct Connect gateway에 AWS Site-to-Site VPN 연결을 설정합니다.",
    "SelectC_Commentary": "Direct Connect와 VPN을 동시에 사용해 복잡도가 높아지며, 전용 회선의 장점을 온전히 활용하기 어렵습니다.",
    "SelectD": "AWS Direct Connect 연결을 설정합니다. Direct Connect gateway에 transit VIF를 생성합니다.",
    "SelectD_Commentary": "전용 회선을 통해 온프레미스와 AWS 간 안정적인 연결과 낮은 지연 시간을 확보하고, transit VIF로 여러 VPC를 간단히 확장할 수 있어 가장 적절합니다.",
    "SelectE": "AWS Site-to-Site VPN 연결을 Transit Gateway에 연결(Associate)합니다.",
    "SelectE_Commentary": "VPN 기반 연결은 지연 시간이 높고 일관되지 않아 단일 자리 지연을 달성하기 어렵고, 비용 효율성도 떨어집니다.",
    "Question_Description_recommedations": [
      "Q686",
      "Q600",
      "Q361",
      "Q865",
      "Q687"
    ],
    "SelectA_recommedations": [
      "Q659",
      "Q686",
      "Q474"
    ],
    "SelectB_recommedations": [
      "Q957",
      "Q734",
      "Q686"
    ],
    "SelectC_recommedations": [
      "Q659",
      "Q734",
      "Q844"
    ],
    "SelectD_recommedations": [
      "Q734",
      "Q957",
      "Q361"
    ],
    "SelectE_recommedations": [
      "Q659",
      "Q957",
      "Q844"
    ]
  },
  {
    "Question_Number": "Q958",
    "Question_Description": "한 글로벌 전자상거래 회사가 AWS에서 핵심 워크로드를 운영하고 있으며, Amazon RDS for PostgreSQL DB 인스턴스를 Multi-AZ 배포로 구성해 사용하고 있습니다. 데이터베이스 장애 조치(failover) 시 고객들이 애플리케이션 타임아웃을 보고하고 있습니다. 회사는 장애 조치 시간을 단축하기 위해 복원력이 뛰어난 솔루션이 필요합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145957-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 장애 조치(failover) 시 애플리케이션 중단을 최소화하는 방법을 묻고 있습니다. Amazon RDS Proxy는 연결을 유지하고 장애 조치 시 투명하게 대체 인스턴스로 라우팅해, 장애 조치 시간을 대폭 줄일 수 있습니다. 따라서 RDS Proxy를 사용하는 것이 가장 효과적인 솔루션입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DB 장애 조치",
      "애플리케이션 타임아웃",
      "RDS Proxy",
      "복원력",
      "Multi-AZ 배포"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ deployment",
      "Amazon RDS Proxy",
      "read replica",
      "Performance Insights",
      "AWS Regions"
    ],
    "SelectA": "Amazon RDS Proxy를 생성하고, 해당 DB 인스턴스에 프록시를 할당합니다.",
    "SelectA_Commentary": "RDS Proxy가 연결을 관리해 장애 조치 시에도 연결을 빠르게 변환해주므로 타임아웃 감소에 효과적입니다.",
    "SelectB": "DB 인스턴스의 리드 리플리카를 생성하고, 리드 트래픽을 리드 리플리카로 이동합니다.",
    "SelectB_Commentary": "리드 리플리카는 읽기 성능 개선에 유리하지만, 장애 조치 시간을 단축하는 직접적인 솔루션은 아닙니다.",
    "SelectC": "Performance Insights를 활성화하고 CPU 부하를 모니터링하여 타임아웃 원인을 파악합니다.",
    "SelectC_Commentary": "모니터링 도구일 뿐이며 장애 조치 자체 시간을 줄이는 직접적인 해결책은 아닙니다.",
    "SelectD": "정기적인 자동 스냅샷을 생성하고, 이를 여러 AWS Region에 복사합니다.",
    "SelectD_Commentary": "스냅샷 복제는 재해 복구에 도움을 주지만, 즉각적인 장애 조치 시간 단축에는 직접적인 효과가 없습니다.",
    "Question_Description_recommedations": [
      "Q989",
      "Q420",
      "Q464",
      "Q536",
      "Q601"
    ],
    "SelectA_recommedations": [
      "Q518",
      "Q259",
      "Q228"
    ],
    "SelectB_recommedations": [
      "Q917",
      "Q187",
      "Q58"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q752"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q869",
      "Q293"
    ]
  },
  {
    "Question_Number": "Q959",
    "Question_Description": "한 회사가 여러 Amazon RDS DB 인스턴스를 개발 AWS 계정에서 운영하고 있습니다. 모든 인스턴스에는 개발 리소스임을 나타내는 태그가 있습니다. 회사는 이 개발 DB 인스턴스들이 업무 시간 중에만 작동하도록 스케줄을 설정해야 합니다. 운영 오버헤드를 최소화하면서 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145438-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 개발 환경의 Amazon RDS 인스턴스를 업무 시간 중에만 자동으로 가동해 비용을 절감하고 운영 오버헤드를 줄이는 방법을 묻고 있습니다. 가장 간단한 접근은 EventBridge를 활용하여 태그로 구분된 DB 인스턴스를 원하는 시간에 자동으로 시작, 중지하는 것입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "Amazon RDS",
      "태그",
      "업무 시간",
      "스케줄 설정",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon RDS",
      "AWS 계정",
      "Tags",
      "업무 시간",
      "CloudWatch Alarm",
      "AWS Lambda",
      "AWS Trusted Advisor",
      "AWS Systems Manager State Manager",
      "Amazon EventBridge"
    ],
    "SelectA": "Amazon CloudWatch Alarm을 생성하여 중지해야 할 RDS 인스턴스를 식별하고, AWS Lambda 함수를 사용해 RDS 인스턴스를 시작/중지합니다.",
    "SelectA_Commentary": "CloudWatch Alarm은 지표 기반으로 동작하므로 단순 스케줄링용으로는 설정이 까다로우며, 추가 설정이 많이 필요해 운영 오버헤드가 비교적 큽니다.",
    "SelectB": "AWS Trusted Advisor 보고서를 생성하여 시작 또는 중지해야 할 RDS 인스턴스를 식별하고, AWS Lambda 함수를 사용해 RDS 인스턴스를 시작/중지합니다.",
    "SelectB_Commentary": "Trusted Advisor는 비용 절감 제안 등 다양한 리소스를 점검하지만, 직접적인 스케줄링 기능이 없어 설정이 복잡하고 실시간 대응에 적합하지 않습니다.",
    "SelectC": "AWS Systems Manager State Manager association을 생성하여 RDS 인스턴스를 시작/중지합니다.",
    "SelectC_Commentary": "State Manager를 이용해 리소스 구성을 관리할 수 있지만, 스케줄링 단순화 측면에서는 설정이 복잡해질 수 있어 오버헤드가 커집니다.",
    "SelectD": "Amazon EventBridge 규칙을 생성하여 RDS 인스턴스를 시작/중지하는 AWS Lambda 함수를 트리거합니다.",
    "SelectD_Commentary": "EventBridge로 정기 스케줄을 설정해 태그로 구분된 RDS 인스턴스를 자동으로 시작/중지할 수 있어 가장 간단하고 운영 오버헤드가 적은 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q574",
      "Q579",
      "Q436",
      "Q940",
      "Q152"
    ],
    "SelectA_recommedations": [
      "Q959",
      "Q574",
      "Q579"
    ],
    "SelectB_recommedations": [
      "Q959",
      "Q574",
      "Q579"
    ],
    "SelectC_recommedations": [
      "Q579",
      "Q574",
      "Q152"
    ],
    "SelectD_recommedations": [
      "Q31",
      "Q959",
      "Q579"
    ]
  },
  {
    "Question_Number": "Q960",
    "Question_Description": "한 소비자 설문조사 회사가 특정 지역에서 여러 해 동안 데이터를 수집해왔습니다. 이 회사는 해당 데이터를 AWS Region에 있는 Amazon S3 버킷에 저장하고 있습니다. 이 회사는 새로운 지역에 있는 마케팅 회사와 이 데이터를 공유하기 시작했습니다. 이 회사는 마케팅 회사의 AWS 계정에 이 S3 버킷에 대한 액세스 권한을 부여했습니다. 마케팅 회사가 S3 버킷에서 데이터를 요청할 때 데이터 전송 비용을 최소화하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145552-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 S3를 통해 데이터를 공유할 때 데이터 전송 비용을 어떻게 최소화할 수 있는지 묻고 있습니다. Requester Pays 기능을 사용하면 데이터를 요청하는 측이 전송 비용을 부담하게 되어, 데이터를 제공하는 회사가 비용을 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 전송 비용",
      "마케팅 회사",
      "Requester Pays"
    ],
    "Terms": [
      "Amazon S3",
      "Requester Pays",
      "S3 Cross-Region Replication (CRR)",
      "AWS Resource Access Manager",
      "S3 Intelligent-Tiering"
    ],
    "SelectA": "회사의 S3 버킷에서 Requester Pays 기능을 활성화합니다.",
    "SelectA_Commentary": "Requester Pays를 활성화하면 데이터를 요청하는 마케팅 회사가 전송 비용을 부담하므로 비용 절감 요구사항을 만족합니다.",
    "SelectB": "회사의 S3 버킷에서 마케팅 회사의 S3 버킷으로 S3 Cross-Region Replication(CRR)을 구성합니다.",
    "SelectB_Commentary": "CRR 구성 시 복제 트래픽 비용은 여전히 회사가 부담해야 하므로 회사 입장에서는 비용 절감 효과가 미흡합니다.",
    "SelectC": "AWS Resource Access Manager를 구성하여 마케팅 회사 AWS 계정과 S3 버킷을 공유합니다.",
    "SelectC_Commentary": "버킷 공유를 하더라도 요청 시 발생하는 데이터 전송 비용 구조가 바뀌지 않아, 요구사항을 충족하지 못합니다.",
    "SelectD": "회사의 S3 버킷을 S3 Intelligent-Tiering으로 설정하고, 마케팅 회사의 S3 버킷과 동기화합니다.",
    "SelectD_Commentary": "S3 Intelligent-Tiering은 스토리지 계층 비용 절감에 주안점이 있어, 데이터 전송 비용 자체를 최소화하기에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q72",
      "Q498",
      "Q829",
      "Q469",
      "Q415"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q285",
      "Q486"
    ],
    "SelectB_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ],
    "SelectC_recommedations": [
      "Q943",
      "Q486",
      "Q993"
    ],
    "SelectD_recommedations": [
      "Q943",
      "Q486",
      "Q285"
    ]
  },
  {
    "Question_Number": "Q961",
    "Question_Description": "한 회사는 AWS를 사용하여 공개 전자상거래 웹사이트를 호스팅하고 있습니다. 이 웹사이트는 인터넷에서 들어오는 트래픽을 위해 AWS Global Accelerator accelerator를 사용합니다. Global Accelerator accelerator는 트래픽을 Auto Scaling 그룹에 연결되는 Application Load Balancer(ALB)로 전달합니다. 회사는 최근 웹사이트에 대한 DDoS 공격을 식별했으며, 향후 공격을 완화해야 합니다. 최소한의 구현 노력을 통해 이 요구사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145442-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DDoS 공격을 최소 노력으로 완화하기 위한 AWS 보안 서비스 사용 방안을 묻습니다. AWS WAF는 ALB와 직접 연동해 트래픽을 필터링할 수 있습니다. Global Accelerator에는 직접 WAF를 설정할 수 없으므로, ALB에 WAF를 적용하여 rate-based rules로 공격 트래픽을 차단하는 것이 가장 간단하고 효율적인 접근입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2"
    ],
    "Keywords": [
      "DDoS 공격",
      "AWS Global Accelerator",
      "Application Load Balancer",
      "AWS WAF",
      "rate-based rules"
    ],
    "Terms": [
      "AWS Global Accelerator",
      "Application Load Balancer (ALB)",
      "AWS WAF",
      "rate-based rules",
      "AWS Lambda",
      "VPC network ACL",
      "Amazon CloudFront"
    ],
    "SelectA": "AWS WAF 웹 ACL을 Global Accelerator accelerator에 구성하여 rate-based rules로 트래픽을 차단합니다.",
    "SelectA_Commentary": "Global Accelerator에 AWS WAF를 직접 설정할 수 없으므로 구현이 불가능합니다.",
    "SelectB": "AWS Lambda 함수를 구성하여 ALB 지표를 읽고 VPC network ACL을 업데이트해 공격을 차단합니다.",
    "SelectB_Commentary": "지표 분석 후 ACL 업데이트 방식으로 구현 복잡도가 높고 실시간 대처가 까다롭습니다.",
    "SelectC": "ALB에 AWS WAF 웹 ACL을 구성하여 rate-based rules로 트래픽을 차단합니다.",
    "SelectC_Commentary": "ALB에서 바로 WAF를 적용해 공격 트래픽을 차단할 수 있어 구현이 간단하고 효율적입니다.",
    "SelectD": "Global Accelerator accelerator 앞에 Amazon CloudFront 배포를 구성합니다.",
    "SelectD_Commentary": "CloudFront 추가 구성은 구현 단계가 많고 비용 및 복잡성이 증가합니다.",
    "Question_Description_recommedations": [
      "Q396",
      "Q927",
      "Q169",
      "Q35",
      "Q701"
    ],
    "SelectA_recommedations": [
      "Q961",
      "Q165",
      "Q871"
    ],
    "SelectB_recommedations": [
      "Q282",
      "Q1016",
      "Q60"
    ],
    "SelectC_recommedations": [
      "Q60",
      "Q169",
      "Q893"
    ],
    "SelectD_recommedations": [
      "Q961",
      "Q538",
      "Q855"
    ]
  },
  {
    "Question_Number": "Q962",
    "Question_Description": "한 회사는 Amazon DynamoDB 테이블을 사용하여 디바이스에서 수신한 데이터를 저장하고 있습니다. 이 DynamoDB 테이블은 고객 디바이스의 최신 활동을 표시하기 위한 고객 대면 웹사이트를 지원합니다. 해당 테이블에는 쓰기 및 읽기에 대해 프로비저닝된 처리량이 설정되어 있습니다. 회사는 고객 디바이스 데이터에 대한 성능 지표를 매일 산출하고자 하는데, 이 작업이 테이블의 프로비저닝된 읽기 및 쓰기 용량에 최소한의 영향을 미쳐야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146188-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "DynamoDB 테이블의 프로비저닝된 용량을 보호하려면 직접 쿼리를 최소화하고, 테이블 데이터를 외부로 내보낸 뒤 계산하는 방식이 적합합니다. AWS Glue DynamoDB export connector는 테이블의 읽기/쓰기를 직접 소모하지 않아 요구사항을 충족합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3",
      "3.5"
    ],
    "Keywords": [
      "DynamoDB 테이블",
      "프로비저닝된 처리량",
      "성능 지표",
      "최소 영향",
      "매일 계산"
    ],
    "Terms": [
      "Amazon DynamoDB",
      "AWS Glue DynamoDB Export Connector",
      "Amazon Athena DynamoDB Connector",
      "Amazon Redshift COPY",
      "Amazon EMR",
      "Apache Hive External Table"
    ],
    "SelectA": "Amazon Athena의 Amazon Athena DynamoDB Connector를 사용하여 정기 스케줄로 SQL 쿼리를 실행해 성능 지표를 계산합니다.",
    "SelectA_Commentary": "Athena에서 DynamoDB를 직접 조회하므로 읽기 용량이 소모되어 요구사항에 부합하지 않습니다.",
    "SelectB": "AWS Glue DynamoDB export connector를 사용하는 AWS Glue 작업을 정기 스케줄로 실행해 성능 지표를 계산합니다.",
    "SelectB_Commentary": "DynamoDB 데이터를 스냅샷 형태로 S3로 내보낸 뒤 처리하므로 DynamoDB의 프로비저닝된 용량에 거의 영향을 주지 않습니다.",
    "SelectC": "Amazon Redshift COPY 명령을 사용하여 정기 스케줄로 성능 지표를 계산합니다.",
    "SelectC_Commentary": "DynamoDB로부터 직접 데이터를 가져오거나 추가 작업이 필요해 DynamoDB의 읽기 용량을 소비할 수 있습니다.",
    "SelectD": "Amazon EMR의 Apache Hive 외부 테이블을 사용하여 정기 스케줄로 성능 지표를 계산합니다.",
    "SelectD_Commentary": "EMR에서 Hive를 통해 DynamoDB 데이터를 직접 조회하거나 외부 소스 연동 시 읽기 부하가 발생하여 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q731",
      "Q578",
      "Q177",
      "Q472",
      "Q523"
    ],
    "SelectA_recommedations": [
      "Q578",
      "Q472",
      "Q177"
    ],
    "SelectB_recommedations": [
      "Q177",
      "Q578",
      "Q472"
    ],
    "SelectC_recommedations": [
      "Q515",
      "Q557",
      "Q361"
    ],
    "SelectD_recommedations": [
      "Q229",
      "Q235",
      "Q565"
    ]
  },
  {
    "Question_Number": "Q963",
    "Question_Description": "한 솔루션스 아키텍트가 AWS에 배포될 새로운 무상태(stateless) 애플리케이션의 클라우드 아키텍처를 설계하고 있습니다. 솔루션스 아키텍트는 이 애플리케이션을 위해 Amazon Machine Image(AMI)와 Launch Template을 생성했습니다. 처리해야 하는 작업(job)의 수에 따라, 필요에 따라 Amazon EC2 인스턴스를 추가하고 제거하면서 병렬로 처리해야 합니다. 애플리케이션은 느슨하게 결합(loosely coupled)되어야 하며, 작업 항목(job items)은 내구성 있게 저장되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146180-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 무상태 애플리케이션이 작업량에 따라 자동으로 확장 및 축소되어야 하며, 작업 항목은 실패 없이 안전하게 저장되어야 함을 요구하고 있습니다. SNS는 주로 게시-구독(pub/sub) 모델로 실시간 알림에 적합하지만, 내구성 있게 메시지를 보관하려면 SQS가 유리합니다. 또한 애플리케이션 인스턴스 수를 SQS 큐의 메시지 수에 따라 스케일링함으로써 실제 처리량과 밀접하게 맞출 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "무상태 애플리케이션",
      "느슨한 결합",
      "내구성 있는 메시지 스토리지",
      "Amazon EC2 오토 스케일링",
      "Amazon SQS"
    ],
    "Terms": [
      "Amazon Machine Image (AMI)",
      "Launch Template",
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon Simple Queue Service (SQS)",
      "Amazon Simple Notification Service (SNS)",
      "CPU usage",
      "Network usage",
      "Number of items in SQS queue",
      "Stateless application",
      "Durable storage"
    ],
    "SelectA": "처리해야 할 작업(job)을 전달하기 위해 Amazon SNS 토픽을 생성하고, Launch Template을 사용해 CPU 사용량을 기준으로 EC2 인스턴스를 추가·제거하는 Auto Scaling group을 구성합니다.",
    "SelectA_Commentary": "SNS는 주로 실시간 알림 용도로 적합하며, CPU 사용률은 실제 작업량과 직결되지 않아 확장이 정확하지 않습니다.",
    "SelectB": "처리해야 할 작업(job)을 보관하기 위해 Amazon SQS 큐를 생성하고, Launch Template을 사용해 네트워크 사용량을 기준으로 EC2 인스턴스를 추가·제거하는 Auto Scaling group을 구성합니다.",
    "SelectB_Commentary": "SQS는 내구성 있는 메시지 보관에는 적합하지만, 네트워크 사용량은 큐에 쌓인 작업량을 제대로 반영하지 않아 스케일링이 부정확할 수 있습니다.",
    "SelectC": "처리해야 할 작업(job)을 보관하기 위해 Amazon SQS 큐를 생성하고, Launch Template을 사용해 SQS 큐 내 항목 수를 기준으로 EC2 인스턴스를 추가·제거하는 Auto Scaling group을 구성합니다.",
    "SelectC_Commentary": "SQS를 통한 내구성 있는 메시지 저장과 큐 메시지 수 기반 스케일링으로 작업 처리량에 정확히 맞출 수 있어 가장 적합한 솔루션입니다.",
    "SelectD": "처리해야 할 작업(job)을 전달하기 위해 Amazon SNS 토픽을 생성하고, Launch Template을 사용해 SNS 토픽에 게시되는 메시지 수를 기준으로 EC2 인스턴스를 추가·제거하는 Auto Scaling group을 구성합니다.",
    "SelectD_Commentary": "SNS는 메시지를 일시적으로 전달하는 데 최적화된 서비스라 큐잉이 아닌 게시-구독 방식이며, 메시지를 내구성 있게 저장하기엔 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q81",
      "Q18",
      "Q351",
      "Q762",
      "Q720"
    ],
    "SelectA_recommedations": [
      "Q1001",
      "Q963",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q1001",
      "Q963",
      "Q595"
    ],
    "SelectC_recommedations": [
      "Q1001",
      "Q963",
      "Q595"
    ],
    "SelectD_recommedations": [
      "Q1001",
      "Q963",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q964",
    "Question_Description": "글로벌 전자상거래 회사가 현재 monolithic 아키텍처를 사용하고 있습니다. 증가하는 상품 데이터 볼륨을 처리하기 위해 확장 가능하고 모듈화된 서비스 아키텍처가 필요합니다. 또한 기존의 structured database schema를 유지해야 하며, 상품 데이터와 상품 이미지를 저장할 스토리지 솔루션도 필요합니다. 이 모든 요구사항을 충족하면서 운영 오버헤드를 최소화하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146026-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 monolithic 아키텍처에서 벗어나 확장성과 모듈성을 갖춘 서비스 아키텍처로 전환하고자 할 때의 최적 방안을 묻습니다. 동시에 관계형 DB 구조(Structured Schema)를 유지하면서 상품 이미지도 별도로 저장해야 합니다. Amazon ECS를 AWS Fargate로 구성하면 서버 관리를 최소화할 수 있고, Amazon RDS Multi-AZ로 가용성과 안정성을 높일 수 있으며, 이미지 파일은 Amazon S3에 저장하여 확장성과 운영 편의성을 동시에 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "monolithic 아키텍처",
      "확장 가능",
      "모듈화된 서비스 아키텍처",
      "structured database schema",
      "운영 오버헤드 최소화",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon RDS",
      "Amazon S3"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "Amazon RDS",
      "Amazon S3",
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon SNS",
      "Amazon EKS",
      "Amazon Aurora",
      "AWS Step Functions",
      "Amazon S3 Glacier Deep Archive",
      "Amazon ECS",
      "AWS Fargate",
      "Multi-AZ"
    ],
    "SelectA": "Amazon EC2 인스턴스를 Auto Scaling group으로 구성하여 컨테이너 기반 애플리케이션을 배포합니다. Application Load Balancer로 웹 트래픽을 분산하고, Amazon RDS DB 인스턴스에 상품 데이터와 이미지를 저장합니다.",
    "SelectA_Commentary": "EC2 인스턴스 관리를 직접 해야 하므로 운영 오버헤드가 높아지고, 이미지도 DB에 같이 저장하면 확장성 측면에서 비효율적입니다.",
    "SelectB": "기존 monolithic 애플리케이션을 AWS Lambda 함수로 관리합니다. Amazon DynamoDB에 상품 데이터와 이미지를 저장하고, Lambda 간 이벤트 전송은 Amazon SNS로 처리합니다.",
    "SelectB_Commentary": "Lambda로 monolithic 애플리케이션을 운영하기에는 구조가 맞지 않고, 기존 관계형 스키마를 활용하기 어렵습니다.",
    "SelectC": "Amazon Elastic Kubernetes Service(Amazon EKS)를 Amazon EC2로 구성하여 컨테이너 기반 애플리케이션을 배포합니다. Amazon Aurora 클러스터에 상품 데이터를 저장하고, AWS Step Functions로 워크플로를 관리합니다. 상품 이미지는 Amazon S3 Glacier Deep Archive에 저장합니다.",
    "SelectC_Commentary": "EKS 클러스터와 EC2 노드를 직접 운영해야 하며, 이미지 저장소로 Glacier Deep Archive를 사용하면 이미지 접근 시 지연이 커집니다.",
    "SelectD": "Amazon Elastic Container Service(Amazon ECS)와 AWS Fargate를 사용해 컨테이너 기반 애플리케이션을 배포합니다. Amazon RDS Multi-AZ를 사용하여 상품 데이터를 저장하고, 상품 이미지는 Amazon S3 버킷에 저장합니다.",
    "SelectD_Commentary": "서버리스 컨테이너 오케스트레이션으로 운영 부담이 낮고, Multi-AZ RDS로 가용성과 성능을 보장하며, 이미지 저장은 S3를 활용해 확장성과 접근성이 뛰어납니다.",
    "Question_Description_recommedations": [
      "Q129",
      "Q914",
      "Q400",
      "Q114",
      "Q198"
    ],
    "SelectA_recommedations": [
      "Q405",
      "Q874",
      "Q390"
    ],
    "SelectB_recommedations": [
      "Q351",
      "Q354",
      "Q833"
    ],
    "SelectC_recommedations": [
      "Q874",
      "Q944",
      "Q775"
    ],
    "SelectD_recommedations": [
      "Q599",
      "Q944",
      "Q354"
    ]
  },
  {
    "Question_Number": "Q965",
    "Question_Description": "한 회사가 온프레미스 환경에서 AWS로 애플리케이션을 마이그레이션하고 있습니다. 이 애플리케이션은 민감한 데이터를 Amazon S3에 저장할 예정입니다. 회사는 Amazon S3에 데이터를 저장하기 전에 데이터를 암호화해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144898-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon S3에 민감한 데이터를 저장하기 전에 반드시 암호화가 이뤄져야 하는 상황을 다룹니다. '데이터를 S3에 업로드하기 전에 암호화'라는 요구사항은 Client-Side Encryption을 의미합니다. 특히 회사에서 직접 키를 관리해야 한다면, Customer Managed Keys 방식을 통해 완전한 제어권을 유지할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "온프레미스 환경",
      "민감한 데이터",
      "Amazon S3",
      "데이터 암호화",
      "사전 암호화"
    ],
    "Terms": [
      "Client-Side Encryption",
      "Server-Side Encryption",
      "Customer Managed Keys",
      "AWS KMS Keys (SSE-KMS)",
      "SSE-C",
      "Amazon S3 Managed Keys"
    ],
    "SelectA": "Client-Side Encryption으로 Customer Managed Keys를 사용하여 데이터를 암호화합니다.",
    "SelectA_Commentary": "업로드 전 데이터를 직접 암호화하고, 키를 직접 관리하기에 요구사항 충족에 가장 적합합니다.",
    "SelectB": "Server-Side Encryption으로 AWS KMS Keys(SSE-KMS)를 사용하여 데이터를 암호화합니다.",
    "SelectB_Commentary": "S3가 서버 측에서 암호화를 처리하므로 업로드 전 암호화 요구를 만족하지 못합니다.",
    "SelectC": "Server-Side Encryption으로 Customer-Provided Keys(SSE-C)를 사용하여 데이터를 암호화합니다.",
    "SelectC_Commentary": "S3에 업로드하기 전이 아닌, 서버 측에서 암호화가 진행되어 요구사항과 다릅니다.",
    "SelectD": "Client-Side Encryption으로 Amazon S3 Managed Keys를 사용하여 데이터를 암호화합니다.",
    "SelectD_Commentary": "S3가 관리하는 키는 실제로 서버 측 암호화에 사용되는 키이므로 업로드 전 암호화와는 거리가 있습니다.",
    "Question_Description_recommedations": [
      "Q696",
      "Q202",
      "Q412",
      "Q109",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q571",
      "Q898"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q916",
      "Q793"
    ],
    "SelectC_recommedations": [
      "Q740",
      "Q571",
      "Q265"
    ],
    "SelectD_recommedations": [
      "Q740",
      "Q825",
      "Q965"
    ]
  },
  {
    "Question_Number": "Q966",
    "Question_Description": "한 회사가 여러 팀에서 사용할 Amazon EMR 클러스터를 생성하고자 합니다. 회사는 각 팀의 빅데이터 워크로드가 필요한 AWS 서비스만 액세스하도록 하기를 원합니다. 또한 클러스터의 기반이 되는 EC2 인스턴스의 Instance Metadata Service Version 2(IMDSv2)에 대한 액세스를 허용하지 않으려 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146028-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EMR 환경에서 팀별로 필요한 AWS 서비스에만 접근하게 하면서, IMDSv2를 사용하지 못하도록 제한해야 하는 보안 시나리오입니다. EMR Runtime Role을 사용하면 각 워크로드가 EC2 Instance Profile 대신 해당 Role로만 권한을 받아, 불필요한 서비스나 IMDSv2 접근을 효과적으로 제한할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "Amazon EMR 클러스터",
      "여러 팀",
      "빅데이터 워크로드",
      "IMDSv2",
      "EMR Runtime Role"
    ],
    "Terms": [
      "Amazon EMR",
      "EMR Runtime Role",
      "IMDSv2",
      "EC2 IAM Instance Profile",
      "EMR Security Configuration",
      "Interface VPC Endpoint"
    ],
    "SelectA": "각 팀이 필요로 하는 AWS 서비스별로 interface VPC endpoint를 구성하십시오. 필요한 interface VPC endpoint를 사용하여 빅데이터 워크로드를 제출하십시오.",
    "SelectA_Commentary": "interface VPC endpoint는 트래픽을 프라이빗으로 유지하지만, IMDSv2 자체를 차단하진 못하고 팀별 세분화가 복잡해질 수 있습니다.",
    "SelectB": "EMR runtime role을 생성하십시오. 클러스터가 이 runtime role을 사용하도록 구성하십시오. 해당 runtime role을 사용하여 빅데이터 워크로드를 제출하십시오.",
    "SelectB_Commentary": "EMR Runtime Role을 사용하면 각 스텝이 EC2 인스턴스 프로파일 대신 정의된 Role 권한만 사용하도록 제한되어 IMDSv2 접근을 막고 팀별 맞춤 권한 설정이 가능합니다.",
    "SelectC": "각 팀에 필요한 권한이 포함된 EC2 IAM instance profile을 생성하십시오. 그 instance profile을 사용하여 빅데이터 워크로드를 제출하십시오.",
    "SelectC_Commentary": "EC2 IAM instance profile은 인스턴스 전체에 권한이 적용되어, 팀별 권한 분리가 제한적이며 IMDSv2 차단도 보장되지 않습니다.",
    "SelectD": "EnableApplicationScopedIAMRole 옵션을 false로 설정한 EMR 보안 구성을 생성하십시오. 해당 보안 구성을 사용하여 빅데이터 워크로드를 제출하십시오.",
    "SelectD_Commentary": "EMR Security Configuration만으로는 IMDSv2 접근 완전 차단이 어렵고, 워크로드별로 분리된 권한 부여 역시 충분히 달성하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q783",
      "Q329",
      "Q492",
      "Q176",
      "Q675"
    ],
    "SelectA_recommedations": [
      "Q135",
      "Q950",
      "Q151"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q893",
      "Q564"
    ],
    "SelectC_recommedations": [
      "Q780",
      "Q96",
      "Q476"
    ],
    "SelectD_recommedations": [
      "Q966",
      "Q429",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q967",
    "Question_Description": "한 솔루션스 아키텍트가 사용자가 신청 양식을 작성하고 제출하는 애플리케이션을 설계하고 있습니다. 솔루션스 아키텍트는 웹 애플리케이션 서버 계층과 워커 계층으로 구성된 2티어 아키텍처를 사용하려고 합니다. 애플리케이션은 제출된 양식을 빠르게 처리해야 하며, 각 양식은 정확히 한 번만 처리되어야 합니다. 또한 어떤 데이터도 손실되지 않도록 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144928-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 웹 서버와 워커를 느슨하게 결합하여 양식 데이터를 신속하고 안정적으로 처리하는 방안을 찾는 것입니다. ‘정확히 한 번’ 처리와 ‘데이터 손실 방지’ 요건을 만족하기 위해서는 메시지 순서와 중복 제거가 보장되는 Amazon SQS FIFO queue를 사용하는 것이 적합합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "빠르게 처리",
      "정확히 한 번",
      "데이터 손실 없음",
      "2티어 아키텍처",
      "SQS FIFO"
    ],
    "Terms": [
      "Amazon Simple Queue Service (Amazon SQS) FIFO",
      "Amazon API Gateway",
      "Amazon Simple Queue Service (Amazon SQS) standard",
      "AWS Step Functions",
      "웹 애플리케이션 서버 계층",
      "워커 계층"
    ],
    "SelectA": "웹 애플리케이션 서버 계층과 워커 계층 사이에서 Amazon Simple Queue Service (Amazon SQS) FIFO queue를 사용하여 양식 데이터를 저장하고 전달합니다.",
    "SelectA_Commentary": "SQS FIFO queue는 메시지 순서를 유지하며 중복을 방지하므로, 한 번만 처리되고 데이터 손실 없이 안전하게 전달하는 데 최적의 솔루션입니다.",
    "SelectB": "웹 애플리케이션 서버 계층과 워커 계층 사이에 Amazon API Gateway HTTP API를 사용하여 양식 데이터를 저장하고 전달합니다.",
    "SelectB_Commentary": "API Gateway는 큐잉 기능을 제공하지 않으므로, 정확히 한 번 처리 및 메시지 순서 보장 측면에서 적합하지 않습니다.",
    "SelectC": "웹 애플리케이션 서버 계층과 워커 계층 사이에서 Amazon Simple Queue Service (Amazon SQS) standard queue를 사용하여 양식 데이터를 저장하고 전달합니다.",
    "SelectC_Commentary": "SQS standard queue는 중복 메시지가 발생할 수 있어 ‘정확히 한 번’ 보장이 어렵습니다.",
    "SelectD": "AWS Step Functions 워크플로를 사용합니다. 웹 애플리케이션 서버 계층과 워커 계층 사이에 동기 워크플로를 구성하여 양식 데이터를 저장하고 전달합니다.",
    "SelectD_Commentary": "Step Functions는 상태 관리는 편리하지만 큐 기반의 메시지 처리에 비해 구현이 복잡하고, 정확히 한 번 처리 보장에 부합하기 위해서는 추가 구성이 필요합니다.",
    "Question_Description_recommedations": [
      "Q255",
      "Q58",
      "Q917",
      "Q735",
      "Q491"
    ],
    "SelectA_recommedations": [
      "Q203",
      "Q344",
      "Q98"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q513",
      "Q869"
    ],
    "SelectC_recommedations": [
      "Q203",
      "Q344",
      "Q67"
    ],
    "SelectD_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ]
  },
  {
    "Question_Number": "Q968",
    "Question_Description": "한 금융 회사가 여러 생산자로부터 streaming data를 수집하기 위해 on-premises search application을 사용하고 있습니다. 이 어플리케이션은 검색과 시각화 기능에 실시간 업데이트를 제공합니다. 이 회사는 AWS로 마이그레이션을 진행하려고 하며, AWS-native 솔루션을 활용하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144929-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 실시간 스트리밍 데이터를 수집하고 검색하며, 시각화까지 제공해야 하는 요구사항을 만족시키는 AWS 기반 솔루션을 결정하는 것입니다. Amazon Kinesis Data Streams로 실시간 데이터 수집을 처리하고, Amazon OpenSearch Service에서 검색 및 인덱싱을 수행한 뒤, Amazon QuickSight로 시각화를 제공할 수 있는 구성이 가장 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.5"
    ],
    "Keywords": [
      "금융 회사",
      "streaming data",
      "실시간 업데이트",
      "search",
      "시각화",
      "AWS-native 솔루션",
      "Amazon Kinesis Data Streams",
      "Amazon OpenSearch Service",
      "Amazon QuickSight"
    ],
    "Terms": [
      "on-premises search application",
      "streaming data",
      "AWS-native solution",
      "Amazon EC2",
      "Amazon S3",
      "Amazon Athena",
      "Amazon Managed Grafana",
      "Amazon EMR",
      "Amazon Redshift",
      "Amazon Redshift Spectrum",
      "Amazon Elastic Kubernetes Service (Amazon EKS)",
      "Amazon DynamoDB",
      "Amazon CloudWatch",
      "Amazon Kinesis Data Streams",
      "Amazon OpenSearch Service",
      "Amazon QuickSight"
    ],
    "SelectA": "Amazon EC2 인스턴스를 사용해 data streams를 처리하여 Amazon S3 버킷에 저장합니다. Amazon Athena로 데이터를 검색하고, Amazon Managed Grafana로 시각화를 생성합니다.",
    "SelectA_Commentary": "EC2에서 직접 스트리밍 처리를 구현하면 관리 부담이 크고, 실시간 검색 기능을 별도로 구성해야 하므로 요구사항을 완전히 충족하기 어렵습니다.",
    "SelectB": "Amazon EMR을 사용해 data streams를 처리하고 Amazon Redshift에 저장합니다. Amazon Redshift Spectrum으로 데이터를 검색하고 Amazon QuickSight로 시각화를 생성합니다.",
    "SelectB_Commentary": "EMR과 Amazon Redshift는 대규모 배치 처리나 분석에 적합하지만, 실시간 검색 기능을 제공하기 위해 추가 구성이 필요하여 요구사항에 최적화되지 않습니다.",
    "SelectC": "Amazon Elastic Kubernetes Service (Amazon EKS)를 사용해 data streams를 처리하고 Amazon DynamoDB에 저장합니다. Amazon CloudWatch로 대시보드를 생성하여 data를 검색하고 시각화합니다.",
    "SelectC_Commentary": "EKS와 DynamoDB 조합만으로는 실시간 검색 및 분석 기능을 구현하기 어렵고, CloudWatch 대시보드는 고급 시각화에 제한적입니다.",
    "SelectD": "Amazon Kinesis Data Streams를 사용해 data streams를 처리하고 Amazon OpenSearch Service에 저장합니다. OpenSearch Service를 통해 데이터를 검색하고 Amazon QuickSight로 시각화를 생성합니다.",
    "SelectD_Commentary": "Kinesis Data Streams를 통한 실시간 데이터 수집, OpenSearch Service를 통한 검색, QuickSight 시각화가 모두 충족되어 요구사항을 가장 간단하고 효과적으로 해결하는 AWS-native 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q718",
      "Q314",
      "Q33",
      "Q83",
      "Q990"
    ],
    "SelectA_recommedations": [
      "Q402",
      "Q910",
      "Q41"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q557",
      "Q386"
    ],
    "SelectC_recommedations": [
      "Q695",
      "Q402",
      "Q394"
    ],
    "SelectD_recommedations": [
      "Q117",
      "Q402",
      "Q968"
    ]
  },
  {
    "Question_Number": "Q969",
    "Question_Description": "한 회사가 현재 사내에서 ASP.NET을 사용하고 있는 Linux 기반 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 리소스를 많이 사용하며, 고객에게 직접 서비스를 제공합니다. 회사는 이 애플리케이션을 .NET으로 현대화하고 컨테이너에서 실행하면서, Amazon CloudWatch 지표를 기준으로 스케일링할 수 있도록 만들고자 합니다. 또한 운영 유지보수에 소요되는 시간을 줄이고 싶어 합니다. 가장 적은 오퍼레이셔널 오버헤드(operational overhead)로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146029-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 ASP.NET Linux 애플리케이션을 .NET 컨테이너로 전환하고, 최소한의 인프라 관리를 통해 자동 스케일링을 구현하고자 하는 상황입니다. 서버리스에 가까운 방식(ECS on Fargate)은 직접 서버를 관리하지 않으므로 오퍼레이셔널 오버헤드가 크게 줄어듭니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      ".NET",
      "AWS Fargate",
      "오퍼레이셔널 오버헤드 감소",
      "스케일링",
      "Amazon ECS"
    ],
    "Terms": [
      "AWS App2Container",
      "ASP.NET",
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon EC2",
      "AWS Fargate",
      "Amazon CloudWatch metrics",
      "AWS App Runner",
      "Amazon Elastic Kubernetes Service (Amazon EKS)"
    ],
    "SelectA": "AWS App2Container를 사용해 애플리케이션을 컨테이너화합니다. AWS CloudFormation 템플릿을 사용해 애플리케이션을 Amazon Elastic Container Service(Amazon ECS) on AWS Fargate에 배포합니다.",
    "SelectA_Commentary": "AWS Fargate는 EC2 인스턴스를 직접 관리할 필요가 없어 운영 부담이 적습니다. App2Container로 컨테이너화하면 기존 애플리케이션을 쉽게 이전할 수 있어 요구사항을 가장 간단히 충족합니다.",
    "SelectB": "AWS App2Container를 사용해 애플리케이션을 컨테이너화합니다. AWS CloudFormation 템플릿을 사용해 애플리케이션을 Amazon Elastic Container Service(Amazon ECS) on Amazon EC2 인스턴스에 배포합니다.",
    "SelectB_Commentary": "EC2 인스턴스를 직접 관리해야 하므로 운영 유지보수 부담이 늘어납니다. 가장 적은 오퍼레이셔널 오버헤드를 요구하는 요건과는 거리가 있습니다.",
    "SelectC": "AWS App Runner를 사용해 애플리케이션을 컨테이너화합니다. App Runner를 사용해 애플리케이션을 Amazon Elastic Container Service(Amazon ECS) on AWS Fargate에 배포합니다.",
    "SelectC_Commentary": "App Runner는 자체 호스팅 기능이 있으나, ECS Fargate와 결합해 사용하는 방식으로는 구성 요소가 복잡해집니다. 단순성과 오퍼레이셔널 오버헤드 측면에서 A보다 덜 적합합니다.",
    "SelectD": "AWS App Runner를 사용해 애플리케이션을 컨테이너화합니다. App Runner를 사용해 애플리케이션을 Amazon Elastic Kubernetes Service(Amazon EKS) on Amazon EC2 인스턴스에 배포합니다.",
    "SelectD_Commentary": "EKS 환경에서 EC2 인스턴스를 관리해야 하므로 운영 복잡도가 매우 높아집니다. 최소 오퍼레이셔널 오버헤드 요구와 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q664",
      "Q720",
      "Q351",
      "Q114",
      "Q197"
    ],
    "SelectA_recommedations": [
      "Q900",
      "Q775",
      "Q698"
    ],
    "SelectB_recommedations": [
      "Q900",
      "Q772",
      "Q775"
    ],
    "SelectC_recommedations": [
      "Q900",
      "Q775",
      "Q698"
    ],
    "SelectD_recommedations": [
      "Q563",
      "Q775",
      "Q724"
    ]
  },
  {
    "Question_Number": "Q970",
    "Question_Description": "한 회사가 AWS Cloud에서 새로운 내부 웹 애플리케이션을 설계 중입니다. 이 신규 애플리케이션은 여러 직원의 사용자 이름과 비밀번호를 AWS에서 관리하는 서비스에서 안전하게 가져오고 저장해야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/147459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS 관리 서비스 중 어디에 자격 증명을 저장하고, 어떻게 웹 애플리케이션이 이를 안전하게 가져올지 묻습니다. 불필요한 구성 요소를 줄여 운영 오버헤드를 최소화하는 것이 핵심입니다. AWS Secrets Manager와 BatchGetSecretValue API를 사용하면 손쉽게 자격 증명을 중앙화하여 관리할 수 있어, 보안과 단순성을 모두 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "내부 웹 애플리케이션",
      "직원 자격 증명",
      "운영 오버헤드",
      "AWS Secrets Manager",
      "BatchGetSecretValue API"
    ],
    "Terms": [
      "AWS Systems Manager Parameter Store",
      "AWS Secrets Manager",
      "AWS CloudFormation",
      "AWS Batch",
      "BatchGetSecretValue API"
    ],
    "SelectA": "직원 자격 증명을 AWS Systems Manager Parameter Store에 저장합니다. AWS CloudFormation과 BatchGetSecretValue API를 사용해 Parameter Store에서 사용자 이름과 비밀번호를 가져옵니다.",
    "SelectA_Commentary": "Parameter Store 사용 시에는 GetParameter API를 주로 활용합니다. BatchGetSecretValue API는 Secrets Manager용이므로 맞지 않으며, 불필요한 복잡성이 생길 수 있습니다.",
    "SelectB": "직원 자격 증명을 AWS Secrets Manager에 저장합니다. AWS CloudFormation과 AWS Batch, 그리고 BatchGetSecretValue API를 사용해 Secrets Manager에서 사용자 이름과 비밀번호를 가져옵니다.",
    "SelectB_Commentary": "AWS Batch는 대량 일괄 작업 시 유용하지만 여기서는 필요 없으므로 오버헤드가 증가합니다. 웹 애플리케이션을 위한 단순 비밀 조회에 Batch는 부적합합니다.",
    "SelectC": "직원 자격 증명을 AWS Systems Manager Parameter Store에 저장합니다. AWS CloudFormation과 AWS Batch, 그리고 BatchGetSecretValue API를 사용해 Parameter Store에서 사용자 이름과 비밀번호를 가져옵니다.",
    "SelectC_Commentary": "Parameter Store에는 BatchGetSecretValue API가 아닌 다른 호출 방식을 사용해야 하며, Batch 역시 불필요한 구성 요소입니다. 보안과 단순성 면에서 비효율적입니다.",
    "SelectD": "직원 자격 증명을 AWS Secrets Manager에 저장합니다. AWS CloudFormation과 BatchGetSecretValue API를 사용해 Secrets Manager에서 사용자 이름과 비밀번호를 가져옵니다.",
    "SelectD_Commentary": "Secrets Manager에 자격 증명을 저장하고 직접 API 호출로 가져오는 구성이 가장 단순합니다. 불필요한 서비스 사용 없이 운영 오버헤드를 최소화하고 보안 요건도 충족합니다.",
    "Question_Description_recommedations": [
      "Q529",
      "Q898",
      "Q548",
      "Q313",
      "Q484"
    ],
    "SelectA_recommedations": [
      "Q517",
      "Q681",
      "Q645"
    ],
    "SelectB_recommedations": [
      "Q645",
      "Q916",
      "Q681"
    ],
    "SelectC_recommedations": [
      "Q681",
      "Q517",
      "Q916"
    ],
    "SelectD_recommedations": [
      "Q645",
      "Q916",
      "Q793"
    ]
  },
  {
    "Question_Number": "Q971",
    "Question_Description": "한 회사가 ap-northeast-1 리전에 있으며, 전 세계 원격지에 배치된 수천 대의 AWS Outposts 서버를 보유하고 있습니다. 이 회사는 정기적으로 100개의 파일로 구성된 신규 소프트웨어 버전을 다운로드받습니다. 모든 서버가 신규 소프트웨어 버전을 실행하기 전까지 상당한 지연(latency)이 발생합니다. 회사는 신규 소프트웨어 버전의 배포 지연을 줄여야 하며, 가장 적은 운영 오버헤드(operational overhead)로 요구사항을 충족해야 합니다. 어떤 솔루션이 이러한 요구사항을 만족합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145371-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 원격지에 배치된 서버들의 소프트웨어 버전 배포 지연을 줄이기 위해, 글로벌 Edge Location을 활용하는지 또는 S3 Transfer Acceleration만 활용하는지 등을 평가합니다. CloudFront를 통한 전 세계적인 콘텐츠 캐싱은 각 Outposts 서버 근처에서 데이터를 받아 올 수 있게 해 지연을 크게 줄여주며, 운영 오버헤드도 낮습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "AWS Outposts 서버",
      "원격지 배포",
      "배포 지연",
      "소프트웨어 버전",
      "CloudFront",
      "S3"
    ],
    "Terms": [
      "AWS Outposts",
      "Amazon S3",
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "Signed URL",
      "Origin",
      "Edge Location",
      "Latency"
    ],
    "SelectA": "ap-northeast-1 리전에 Amazon S3 버킷을 생성합니다. ap-northeast-1에서 CachingDisabled 캐시 정책을 포함하는 Amazon CloudFront 배포를 설정하고, S3 버킷을 오리진으로 구성합니다. Signed URL을 사용하여 소프트웨어를 다운로드합니다.",
    "SelectA_Commentary": "CachingDisabled 정책은 캐싱 효과가 거의 없으므로 원격지 서버의 다운로드 속도 개선에 제한적입니다. CloudFront 인프라는 있지만 캐시를 활용하지 못해 지연이 크게 줄지 않습니다.",
    "SelectB": "ap-northeast-1 리전에 Amazon S3 버킷을 생성하고, us-east-1 리전에도 두 번째 S3 버킷을 생성합니다. 두 버킷 간 복제를 설정하고, ap-northeast-1을 기본 오리진으로, us-east-1을 보조 오리진으로 하는 CloudFront 배포를 구성합니다. Signed URL로 소프트웨어를 다운로드합니다.",
    "SelectB_Commentary": "복제 설정과 다중 오리진 구성은 추가 설정이 필요하며 운영 복잡도가 높아집니다. 리전 간 복제로 인한 지연 또한 크게 단축되지 않을 수 있습니다.",
    "SelectC": "ap-northeast-1 리전에 Amazon S3 버킷을 생성하고, Amazon S3 Transfer Acceleration을 활성화합니다. S3 Transfer Acceleration 엔드포인트를 사용하여 소프트웨어를 다운로드합니다.",
    "SelectC_Commentary": "S3 Transfer Acceleration은 업로드 속도 향상에 유리하지만, 멀리 떨어진 다수의 원격지 서버에서 동시에 빠르게 받는 데에는 CloudFront만큼의 전 세계 캐싱 이점이 부족합니다.",
    "SelectD": "ap-northeast-1 리전에 Amazon S3 버킷을 생성합니다. Amazon CloudFront 배포를 설정하고, S3 버킷을 오리진으로 구성합니다. Signed URL을 사용하여 소프트웨어를 다운로드합니다.",
    "SelectD_Commentary": "CloudFront를 통해 글로벌 Edge Location에서 콘텐츠를 캐싱하므로, 원격지 Outposts 서버가 가까운 엣지 로케이션에서 데이터를 받아올 수 있어 배포 지연이 크게 감소하고 운영도 간단합니다.",
    "Question_Description_recommedations": [
      "Q266",
      "Q738",
      "Q684",
      "Q737",
      "Q865"
    ],
    "SelectA_recommedations": [
      "Q737",
      "Q280",
      "Q38"
    ],
    "SelectB_recommedations": [
      "Q737",
      "Q280",
      "Q684"
    ],
    "SelectC_recommedations": [
      "Q38",
      "Q737",
      "Q971"
    ],
    "SelectD_recommedations": [
      "Q280",
      "Q737",
      "Q672"
    ]
  },
  {
    "Question_Number": "Q972",
    "Question_Description": "한 회사가 Microsoft Windows Server로 구동되는 온프레미스 주식 거래 애플리케이션을 운영 중이며, 이를 AWS Cloud로 마이그레이션하려고 합니다. 이 회사는 여러 가용 영역에 걸쳐 저지연 block storage에 액세스를 제공하면서도 고가용성을 갖춘 솔루션을 설계해야 합니다. 가장 적은 구현 노력으로 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146061-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 Windows 기반 애플리케이션을 AWS로 이전하면서, 여러 AZ에 걸쳐 고가용성과 저지연 블록 스토리지를 구현하는 방법을 묻습니다. FSx for NetApp ONTAP Multi-AZ 파일시스템은 iSCSI 블록 스토리지 제공과 Multi-AZ 고가용성을 간편하게 지원하므로 가장 적은 구현 노력이 필요합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "고가용성",
      "저지연",
      "block storage",
      "Windows Server",
      "Multi-AZ",
      "마이그레이션"
    ],
    "Terms": [
      "Windows Server 클러스터",
      "Amazon EC2",
      "Amazon FSx for Windows File Server",
      "Amazon EBS (gp3)",
      "Amazon FSx for NetApp ONTAP",
      "iSCSI",
      "Amazon EBS Provisioned IOPS SSD (io2)"
    ],
    "SelectA": "Amazon EC2 인스턴스에 걸쳐 두 개의 가용 영역을 포함하는 Windows Server 클러스터를 구성합니다. 두 클러스터 노드에 애플리케이션을 설치합니다. 공유 스토리지로 Amazon FSx for Windows File Server를 사용합니다.",
    "SelectA_Commentary": "FSx for Windows File Server는 파일 공유용으로 설계되어 있으며, 블록 스토리지 용도로는 적합하지 않아 요구 사항에 부합하지 않습니다.",
    "SelectB": "Amazon EC2 인스턴스에 걸쳐 두 개의 가용 영역을 포함하는 Windows Server 클러스터를 구성합니다. 두 클러스터 노드에 애플리케이션을 설치합니다. EC2 인스턴스에 연결된 Amazon EBS General Purpose SSD(gp3) 볼륨을 스토리지로 사용합니다. 첫 번째 가용 영역의 EBS 볼륨에서 두 번째 가용 영역의 EBS 볼륨으로 데이터를 동기화하기 위해 애플리케이션 수준 복제를 설정합니다.",
    "SelectB_Commentary": "gp3 볼륨 간 애플리케이션 수준 복제는 직접 설정과 운용이 복잡해, 최소 구현 노력 요건에 부합하지 않습니다.",
    "SelectC": "두 개의 가용 영역에 Amazon EC2 인스턴스를 배포합니다. 하나의 EC2 인스턴스를 활성(Active)으로, 다른 한 인스턴스를 대기(Standby)로 구성합니다. Amazon FSx for NetApp ONTAP Multi-AZ 파일 시스템을 사용하여 Internet Small Computer Systems Interface(iSCSI) 프로토콜로 데이터를 액세스합니다.",
    "SelectC_Commentary": "FSx for NetApp ONTAP는 iSCSI 블록 스토리지와 Multi-AZ 구성으로 저지연과 고가용성을 간소하게 달성하므로 요구 사항과 최소 구현 노력 요건을 모두 충족합니다.",
    "SelectD": "두 개의 가용 영역에 Amazon EC2 인스턴스를 배포합니다. 하나의 EC2 인스턴스를 활성(Active)으로, 다른 한 인스턴스를 대기(Standby)로 구성합니다. EC2 인스턴스에 연결된 Amazon EBS Provisioned IOPS SSD(io2) 볼륨을 스토리지로 사용합니다. 첫 번째 가용 영역에 있는 io2 볼륨을 두 번째 가용 영역에 있는 io2 볼륨으로 동기화하기 위해 Amazon EBS 레벨 복제를 설정합니다.",
    "SelectD_Commentary": "io2 볼륨 간 복제 구성을 직접 설정하고 관리하는 것은 복잡도가 높아, 최소 구현 노력을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q513",
      "Q843",
      "Q1014",
      "Q790",
      "Q357"
    ],
    "SelectA_recommedations": [
      "Q54",
      "Q186",
      "Q618"
    ],
    "SelectB_recommedations": [
      "Q986",
      "Q602",
      "Q837"
    ],
    "SelectC_recommedations": [
      "Q635",
      "Q842",
      "Q934"
    ],
    "SelectD_recommedations": [
      "Q892",
      "Q602",
      "Q312"
    ]
  },
  {
    "Question_Number": "Q973",
    "Question_Description": "한 회사가 인터넷 연결이 가능한 Application Load Balancer(ALB)를 사용하여 웹 애플리케이션을 설계하고 있습니다. ALB는 퍼블릭 인터넷으로부터 443 포트(HTTPS)로 트래픽을 받아야 하며, Amazon EC2 인스턴스에 호스팅된 웹 애플리케이션 서버로는 오직 443 포트(HTTPS)로 트래픽을 전달해야 합니다. 또한, ALB는 8443 포트(HTTPS)를 통해 웹 애플리케이션 서버의 Health Check를 수행해야 합니다. 이 요구사항을 만족하기 위해 ALB에 연동되는 Security Group은 어떤 구성이어야 합니까? (3개를 선택하세요.)",
    "Answer": "A,C,E",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146030-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB에 대한 올바른 Security Group 설정으로 외부 443 포트로 들어오는 HTTPS 트래픽을 받아 EC2 인스턴스로 전달하고, 8443 포트로 Health Check를 수행하는 시나리오를 묻습니다. 정답은 A, C, E로서, 퍼블릭 인터넷에서 ALB로의 443 인바운드 허용, 인스턴스에 대한 443 아웃바운드 허용, 그리고 8443 Health Check 아웃바운드를 허용해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "웹 애플리케이션",
      "Application Load Balancer(ALB)",
      "HTTPS",
      "퍼블릭 인터넷",
      "Amazon EC2 인스턴스",
      "Security Group",
      "건강 체크",
      "443 포트",
      "8443 포트"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "Amazon EC2",
      "Security Group",
      "HTTPS",
      "Health Check",
      "port 443",
      "port 8443"
    ],
    "SelectA": "Allow HTTPS inbound traffic from 0.0.0.0/0 for port 443.",
    "SelectA_Commentary": "퍼블릭 인터넷에서 ALB로 들어올 수 있도록 443 포트 인바운드를 허용하는 필수 규칙입니다.",
    "SelectB": "Allow all outbound traffic to 0.0.0.0/0 for port 443.",
    "SelectB_Commentary": "모든 대상(0.0.0.0/0)으로 443 포트를 허용할 필요는 없어 불필요하며, 세분화된 규칙을 쓰는 것이 더 안전합니다.",
    "SelectC": "Allow HTTPS outbound traffic to the web application instances for port 443.",
    "SelectC_Commentary": "ALB가 EC2 인스턴스에 443 포트(HTTPS)로 트래픽을 전달하기 위해 반드시 필요한 아웃바운드 규칙입니다.",
    "SelectD": "Allow HTTPS inbound traffic from the web application instances for port 443.",
    "SelectD_Commentary": "EC2 인스턴스에서 ALB로 443 포트를 인바운드로 허용할 필요는 없습니다. ALB는 요청을 받아 인스턴스로 전달하는 역할입니다.",
    "SelectE": "Allow HTTPS outbound traffic to the web application instances for the health check on port 8443.",
    "SelectE_Commentary": "ALB가 8443 포트로 EC2를 헬스체크하기 위해 필수적인 아웃바운드 규칙입니다.",
    "SelectF": "Allow HTTPS inbound traffic from the web application instances for the health check on port 8443.",
    "SelectF_Commentary": "ALB가 인스턴스로 헬스체크를 보내므로, EC2 인스턴스가 ALB로 8443을 인바운드로 보낼 필요는 없습니다.",
    "Question_Description_recommedations": [
      "Q60",
      "Q884",
      "Q749",
      "Q437",
      "Q701"
    ],
    "SelectA_recommedations": [
      "Q774",
      "Q855",
      "Q571"
    ],
    "SelectB_recommedations": [
      "Q774",
      "Q233",
      "Q169"
    ],
    "SelectC_recommedations": [
      "Q855",
      "Q644",
      "Q608"
    ],
    "SelectD_recommedations": [
      "Q855",
      "Q644",
      "Q608"
    ],
    "SelectE_recommedations": [
      "Q855",
      "Q973",
      "Q644"
    ],
    "SelectF_recommedations": [
      "Q644",
      "Q855",
      "Q60"
    ]
  },
  {
    "Question_Number": "Q974",
    "Question_Description": "한 회사가 AWS에 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 사용자가 사진을 업로드하고 Amazon S3 버킷에 저장할 수 있는 기능을 제공합니다. 해당 회사는 Amazon CloudFront와 커스텀 도메인 이름을 사용하여 eu-west-1 리전에 있는 S3 버킷으로 사진 파일을 업로드하고자 합니다. 어떤 솔루션이 이러한 요구 사항을 충족할까요? (2개를 선택하세요.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/144941-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 CloudFront와 커스텀 도메인을 사용하여 S3로 안전하게 사진을 업로드해야 하는 상황입니다. CloudFront에서 커스텀 도메인을 사용하려면 us-east-1 리전에서 발급된 인증서가 필요하며, OAC를 통해 S3 버킷에 대한 보안 액세스를 설정해 접근 제어를 강화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "CloudFront",
      "커스텀 도메인",
      "SSL/TLS 인증서",
      "us-east-1",
      "Origin Access Control(OAC)",
      "S3 업로드",
      "보안 업로드",
      "Amazon S3",
      "eu-west-1"
    ],
    "Terms": [
      "CloudFront",
      "custom domain name",
      "AWS Certificate Manager (ACM)",
      "us-east-1",
      "S3 Transfer Acceleration",
      "Origin Access Control (OAC)",
      "Amazon S3 website endpoint"
    ],
    "SelectA": "us-east-1 리전에서 AWS Certificate Manager (ACM)을 사용해 public certificate를 생성합니다. 이 certificate를 CloudFront에서 사용합니다.",
    "SelectA_Commentary": "CloudFront에서 커스텀 도메인으로 HTTPS를 사용하기 위해서는 us-east-1에서 발급된 인증서만 적용할 수 있습니다. 정확한 접근 경로를 보장하기 위한 필수 조건입니다. (정답)",
    "SelectB": "eu-west-1 리전에서 AWS Certificate Manager (ACM)을 사용해 public certificate를 생성합니다. 이 certificate를 CloudFront에서 사용합니다.",
    "SelectB_Commentary": "CloudFront가 커스텀 도메인을 사용하기 위해서는 반드시 us-east-1에서 발급된 인증서가 필요합니다. eu-west-1에서 발급된 인증서는 사용할 수 없습니다.",
    "SelectC": "Amazon S3에서 CloudFront 업로드를 허용하도록 구성합니다. S3 Transfer Acceleration을 구성합니다.",
    "SelectC_Commentary": "S3 Transfer Acceleration은 업로드 속도 개선에 도움이 되지만, HTTPS 커스텀 도메인 설정과 OAC 기반 보안 액세스를 확보하는 중요한 요구사항을 충족하지 못합니다.",
    "SelectD": "Amazon S3에서 CloudFront origin access control (OAC) 업로드를 허용하도록 구성합니다.",
    "SelectD_Commentary": "Origin Access Control(OAC)은 CloudFront가 S3 버킷에 안전하게 업로드할 수 있도록 하는 기능입니다. 직접 접근을 차단해 보안을 크게 강화할 수 있습니다. (정답)",
    "SelectE": "Amazon S3에서 CloudFront 업로드를 허용하도록 구성합니다. Amazon S3 웹사이트 엔드포인트를 구성합니다.",
    "SelectE_Commentary": "S3 웹사이트 엔드포인트는 정적 웹사이트 호스팅용이며, HTTPS 및 CloudFront와의 안전한 업로드 요구사항을 충족하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q291",
      "Q889",
      "Q131",
      "Q862",
      "Q216"
    ],
    "SelectA_recommedations": [
      "Q577",
      "Q855",
      "Q172"
    ],
    "SelectB_recommedations": [
      "Q974",
      "Q577",
      "Q855"
    ],
    "SelectC_recommedations": [
      "Q974",
      "Q678",
      "Q965"
    ],
    "SelectD_recommedations": [
      "Q542",
      "Q974",
      "Q855"
    ],
    "SelectE_recommedations": [
      "Q678",
      "Q106",
      "Q825"
    ]
  },
  {
    "Question_Number": "Q975",
    "Question_Description": "한 기상 예보 회사가 여러 센서로부터 온도 측정값을 지속적으로 수집하고 있습니다. 기존 데이터 수집 프로세스는 측정값을 수집하여 Apache Parquet 파일로 집계한 뒤, KMS managed keys(CSE-KMS)를 사용해 클라이언트 측에서 파일을 암호화합니다. 마지막으로 각 달력 일자별로 구분된 prefix에 맞춰 Amazon S3 버킷에 파일을 저장합니다. 회사는 특정 날짜에 대한 샘플 이동 평균을 계산하기 위해 가끔 SQL 쿼리를 실행하려고 합니다. 이 요구사항을 가장 비용 효율적으로 충족시키는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145367-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 클라이언트 측에서 암호화된 데이터를 Amazon S3에 저장한 뒤, 가끔씩 SQL 분석을 수행하는 가장 비용 효율적인 방안을 묻는 문제입니다. 가끔 발생하는 분석 workload에는 일부러 대규모 데이터 웨어하우스를 구성하기보다, 서버리스 기반으로 즉시 쿼리가 가능한 Amazon Athena가 비용과 운영상 이점을 제공합니다. S3 Select는 점점 사용이 줄고 있으며(또는 일부에서는 지원되지 않음), Amazon Redshift나 EMR Serverless는 주기적이거나 대규모 워크로드에 더 적합하므로 비용이 더 많이 들 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "가끔 실행되는 SQL 쿼리",
      "샘플 이동 평균",
      "Apache Parquet",
      "CSE-KMS",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3",
      "Apache Parquet",
      "KMS managed keys",
      "CSE-KMS",
      "Amazon Athena",
      "S3 Select",
      "Amazon Redshift",
      "Redshift Spectrum",
      "Apache SparkSQL",
      "Amazon EMR Serverless"
    ],
    "SelectA": "Amazon Athena에서 암호화된 파일을 읽도록 구성한 후, Amazon S3에서 직접 SQL 쿼리를 실행합니다.",
    "SelectA_Commentary": "가끔 실행되는 쿼리에 대해 서버리스인 Athena가 가장 경제적이며, 운영 복잡도를 낮춥니다. Parquet 형식과 Athena의 호환성도 뛰어납니다.",
    "SelectB": "Amazon S3 Select를 사용해 Amazon S3에서 직접 SQL 쿼리를 실행합니다.",
    "SelectB_Commentary": "S3 Select 기능은 최근에 잘 사용되지 않거나 일부 서비스에서 제한적이며, Athena 대비 기능과 호환성이 부족합니다.",
    "SelectC": "Amazon Redshift를 설정하여 암호화된 파일을 읽고, Redshift Spectrum과 Redshift query editor v2를 사용해 Amazon S3에서 직접 SQL 쿼리를 실행합니다.",
    "SelectC_Commentary": "Redshift는 규모가 큰 정기적 분석에 유리하지만, 가끔 실행되는 쿼리 용도에는 과도한 비용이 들 수 있습니다.",
    "SelectD": "Amazon EMR Serverless를 구성하여 암호화된 파일을 읽고, Apache SparkSQL을 사용해 Amazon S3에서 직접 SQL 쿼리를 실행합니다.",
    "SelectD_Commentary": "EMR Serverless는 규모가 크거나 복잡한 배치 처리에 적합하나, 단발성 분석 작업에는 엔진 구성 및 관리 비용이 비교적 큽니다.",
    "Question_Description_recommedations": [
      "Q788",
      "Q167",
      "Q126",
      "Q993",
      "Q23"
    ],
    "SelectA_recommedations": [
      "Q449",
      "Q788",
      "Q993"
    ],
    "SelectB_recommedations": [
      "Q788",
      "Q415",
      "Q31"
    ],
    "SelectC_recommedations": [
      "Q31",
      "Q167",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q128",
      "Q300",
      "Q449"
    ]
  },
  {
    "Question_Number": "Q976",
    "Question_Description": "한 회사가 AWS에서 새로운 애플리케이션을 구현하려고 합니다. 이 애플리케이션은 여러 AWS Region 내 여러 가용 영역(Availability Zone)에 걸쳐 다수의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션은 인터넷을 통해 액세스 가능하며, 전 세계 사용자들이 접근할 예정입니다. 회사는 각 사용자가 지리적으로 가장 가까운 EC2 인스턴스로 연결되도록 설정하고자 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145571-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 사용자들이 지리적으로 가장 가까운 Region에 위치한 EC2 인스턴스로 라우팅되도록 구성하는 방법을 묻습니다. Amazon Route 53의 지리 기반 라우팅 중에서도 geoproximity가 물리적으로 가까운 리소스를 선택하므로 요구사항에 부합합니다. 이를 통해 사용자별 위치에 따라 최적의 성능을 얻을 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "사용자 위치",
      "가장 가까운 EC2 인스턴스",
      "Route 53",
      "글로벌 트래픽 분산"
    ],
    "Terms": [
      "Amazon Route 53 geolocation routing policy",
      "Amazon Route 53 geoproximity routing policy",
      "Amazon Route 53 multivalue answer routing policy",
      "Amazon Route 53 weighted routing policy",
      "Application Load Balancer",
      "Network Load Balancer",
      "Availability Zone",
      "Region",
      "Amazon EC2"
    ],
    "SelectA": "Amazon Route 53 geolocation 라우팅 정책을 구현합니다. 인터넷 액세스용 Application Load Balancer를 사용하여 동일한 Region 내 모든 가용 영역으로 트래픽을 분산합니다.",
    "SelectA_Commentary": "geolocation 라우팅은 국가 단위 또는 특정 위치 기반으로 트래픽을 라우팅하지만 가장 가까운 리전을 자동으로 선택해주지는 않아 요구사항에 적합하지 않습니다.",
    "SelectB": "Amazon Route 53 geoproximity 라우팅 정책을 구현합니다. 인터넷 액세스용 Network Load Balancer를 사용하여 동일한 Region 내 모든 가용 영역으로 트래픽을 분산합니다.",
    "SelectB_Commentary": "지리적 근접도(geoproximity)를 기준으로 트래픽을 분산하여 각 사용자에게 가장 가까운 EC2 인스턴스를 연결해 주므로 요구사항을 충족합니다.",
    "SelectC": "Amazon Route 53 multivalue answer 라우팅 정책을 구현합니다. 인터넷 액세스용 Application Load Balancer를 사용하여 동일한 Region 내 모든 가용 영역으로 트래픽을 분산합니다.",
    "SelectC_Commentary": "multivalue answer 라우팅은 여러 IP 주소를 반환할 수 있지만, 사용자의 실제 거리(근접도)를 고려하지 않아 지리적으로 가장 가까운 리전을 보장하기 어렵습니다.",
    "SelectD": "Amazon Route 53 weighted 라우팅 정책을 구현합니다. 인터넷 액세스용 Network Load Balancer를 사용하여 동일한 Region 내 모든 가용 영역으로 트래픽을 분산합니다.",
    "SelectD_Commentary": "weighted 라우팅은 가중치 기반 분산만 제어할 수 있어, 사용자 위치별로 가장 가까운 리전을 선택하는 요구사항과 맞지 않습니다.",
    "Question_Description_recommedations": [
      "Q818",
      "Q632",
      "Q20",
      "Q566",
      "Q938"
    ],
    "SelectA_recommedations": [
      "Q692",
      "Q530",
      "Q582"
    ],
    "SelectB_recommedations": [
      "Q692",
      "Q530",
      "Q582"
    ],
    "SelectC_recommedations": [
      "Q692",
      "Q530",
      "Q582"
    ],
    "SelectD_recommedations": [
      "Q692",
      "Q530",
      "Q582"
    ]
  },
  {
    "Question_Number": "Q977",
    "Question_Description": "한 금융 서비스 회사가 민감한 금융 거래를 처리하기 위해 새로운 애플리케이션을 AWS에 배포하려고 합니다. 애플리케이션은 Amazon EC2 인스턴스에서 구동되며, 데이터베이스로 Amazon RDS for MySQL을 사용할 예정입니다. 회사의 보안 정책상 데이터는 저장 시(At Rest)와 전송 시(In Transit) 모두 암호화되어야 합니다. 가장 적은 운영 부담으로 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146035-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 금융 데이터를 다루는 RDS 데이터베이스와 애플리케이션 간 전송 구간 및 저장 구간에서 모두 암호화를 적용하기 위한 최적의 방안을 묻습니다. AWS KMS를 사용한 암호화는 키 관리와 로테이션을 자동화하여 운영 부담을 줄이고, ACM에서 제공하는 SSL/TLS 인증서는 연결 구간 암호화를 간단히 설정하고 관리할 수 있어 효율적입니다. 따라서 정답에서 제시한 방식이 가장 적은 운영 오버헤드로 보안 요구사항을 충족합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.2",
      "1.3"
    ],
    "Keywords": [
      "민감한 금융 거래",
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "AWS KMS",
      "AWS Certificate Manager",
      "SSL/TLS",
      "운영 부담 최소화"
    ],
    "Terms": [
      "AWS KMS managed keys",
      "AWS Certificate Manager (ACM)",
      "SSL/TLS",
      "IPsec",
      "VPN",
      "Amazon EC2",
      "Amazon RDS for MySQL"
    ],
    "SelectA": "AWS KMS managed keys를 사용해 Amazon RDS for MySQL의 암호화를 구성하고, AWS Certificate Manager (ACM) SSL/TLS 인증서를 사용해 전송 구간 암호화를 설정합니다.",
    "SelectA_Commentary": "RDS 생성 시 간단히 KMS로 암호화 설정 후 ACM 인증서로 SSL/TLS를 적용하면 운영 부담이 최소화되며, 보안 요구사항을 완벽히 충족합니다.",
    "SelectB": "AWS KMS managed keys를 사용해 Amazon RDS for MySQL의 암호화를 구성하고, 전송 구간 암호화를 위해 IPsec 터널을 설정합니다.",
    "SelectB_Commentary": "IPsec 터널 설정은 추가 관리와 구성 부담이 크고, SSL/TLS만으로도 안전한 전송 구간 암호화가 가능하므로 비효율적입니다.",
    "SelectC": "Amazon RDS for MySQL에 저장하기 전에 서드파티 애플리케이션 레벨 데이터 암호화를 구현하고, AWS Certificate Manager (ACM) SSL/TLS 인증서를 설정합니다.",
    "SelectC_Commentary": "서드파티 암호화 솔루션 적용은 관리 복잡도를 높이고, RDS 측의 자동화 이점도 크게 활용하지 못해 운영 부담이 증가합니다.",
    "SelectD": "AWS KMS managed keys를 사용해 Amazon RDS for MySQL의 암호화를 구성하고, VPN 연결을 통해 전용 연결을 사용해 전송 구간을 암호화합니다.",
    "SelectD_Commentary": "VPN 연결 설정과 유지 관리에 드는 노력이 크고, SSL/TLS 대비 운영 부담이 높아 요구사항을 만족하지만 효율성이 낮습니다.",
    "Question_Description_recommedations": [
      "Q61",
      "Q801",
      "Q732",
      "Q234",
      "Q364"
    ],
    "SelectA_recommedations": [
      "Q681",
      "Q916",
      "Q743"
    ],
    "SelectB_recommedations": [
      "Q743",
      "Q681",
      "Q916"
    ],
    "SelectC_recommedations": [
      "Q810",
      "Q663",
      "Q451"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q916",
      "Q810"
    ]
  },
  {
    "Question_Number": "Q978",
    "Question_Description": "한 회사가 온프레미스 Oracle 데이터베이스를 Amazon RDS for Oracle로 마이그레이션하고 있습니다. 규정 요구 사항을 충족하기 위해 데이터를 90일 동안 보관해야 하며, 또한 최대 14일 전 시점으로 복원할 수 있어야 합니다. 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145565-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon RDS for Oracle에서 긴 보존 기간(90일)과 시점 복원(최대 14일)을 동시에 충족해야 하는 상황입니다. 자동 백업은 기본적으로 35일까지 가능하므로 90일까지 유지가 어렵습니다. 매일 수동 스냅샷을 생성하는 방법은 오버헤드가 커지고, Aurora Clone 기능은 Oracle에 적용할 수 없습니다. AWS Backup을 사용하면 원하는 기간(90일) 동안 백업을 보관하면서 자동화된 방식으로 시점 복원 기능도 충족시킬 수 있으므로 정답은 D입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon RDS for Oracle",
      "데이터 보관 90일",
      "시점 복원 14일",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon RDS automated backups",
      "AWS Backup",
      "Manual snapshot",
      "Point-in-time restore",
      "Retention period"
    ],
    "SelectA": "Amazon RDS automated backups를 생성하고 보존 기간을 90일로 설정합니다.",
    "SelectA_Commentary": "자동 백업은 최대 35일까지 설정 가능하므로 90일 보관 요구 사항을 충족하지 못합니다.",
    "SelectB": "매일 Amazon RDS manual snapshot을 생성하고, 90일이 지난 snapshot을 삭제합니다.",
    "SelectB_Commentary": "매일 수동 스냅샷을 생성해야 하므로 운영 오버헤드가 높고 시점 복원을 유연하게 지원하기 어렵습니다.",
    "SelectC": "Amazon Aurora Clone for Oracle 기능을 사용해 Point-in-Time Restore를 만들고, 90일이 지난 클론을 삭제합니다.",
    "SelectC_Commentary": "Oracle 데이터베이스에는 Aurora Clone 기능을 적용할 수 없으며, 제시된 요구 사항과 맞지 않습니다.",
    "SelectD": "AWS Backup for Amazon RDS를 사용해 보존 기간을 90일로 설정한 백업 플랜을 생성합니다.",
    "SelectD_Commentary": "백업 생성이 자동화되며 14일 시점 복원과 90일 보관 모두 충족하므로 운영 오버헤드가 최소화됩니다.",
    "Question_Description_recommedations": [
      "Q629",
      "Q259",
      "Q108",
      "Q195",
      "Q518"
    ],
    "SelectA_recommedations": [
      "Q978",
      "Q845",
      "Q863"
    ],
    "SelectB_recommedations": [
      "Q978",
      "Q311",
      "Q863"
    ],
    "SelectC_recommedations": [
      "Q133",
      "Q764",
      "Q978"
    ],
    "SelectD_recommedations": [
      "Q978",
      "Q518",
      "Q259"
    ]
  },
  {
    "Question_Number": "Q979",
    "Question_Description": "한 회사가 새로운 애플리케이션을 개발 중이며, 이 애플리케이션은 user data와 애플리케이션 설정을 저장하기 위해 관계형 데이터베이스를 사용합니다. 회사는 사용자가 꾸준히 증가할 것으로 예상하며, 데이터베이스 접근은 가변적이고 읽기(read)가 많으며 간헐적으로 쓰기(write)가 발생할 것으로 예상됩니다. 회사는 비용을 최적화하면서 필요한 성능을 제공하는 AWS managed database 솔루션을 원합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/146062-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 관계형 데이터베이스를 사용하면서, 읽기 위주의 가변적인 트래픽에 대해 비용을 절감하고자 하는 시나리오를 묻습니다. Amazon Aurora Serverless는 서버리스 모드로 트래픽에 따라 오토스케일링이 가능하며, 사용한 만큼만 과금되어 가변적이고 읽기 집중적인 워크로드에 가장 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "관계형 데이터베이스",
      "가변 워크로드",
      "비용 최적화",
      "읽기 집중(READ-HEAVY)"
    ],
    "Terms": [
      "Amazon RDS",
      "Provisioned IOPS SSD",
      "Amazon Aurora Serverless",
      "Amazon DynamoDB",
      "On-demand capacity mode",
      "Magnetic storage",
      "Read replicas"
    ],
    "SelectA": "Amazon RDS에 데이터베이스를 배포하고, Provisioned IOPS SSD 스토리지를 사용하여 읽기와 쓰기 모두 일관된 성능을 보장합니다.",
    "SelectA_Commentary": "Provisioned IOPS SSD는 고성능을 보장하지만, 항상 동일한 IOPS를 예약하기 때문에 규모가 달라져도 비용이 일정 수준으로 유지되어 가변 워크로드에 비해 비용 효율이 떨어집니다.",
    "SelectB": "Amazon Aurora Serverless로 데이터베이스를 배포하여 실제 사용량에 따라 자동으로 데이터베이스 용량을 스케일링하여 워크로드를 처리합니다.",
    "SelectB_Commentary": "서버리스 환경에서 사용량만큼만 비용을 지불하므로, 읽기 중심의 가변적인 트래픽에 뛰어난 확장성과 비용 효율을 모두 만족합니다.",
    "SelectC": "Amazon DynamoDB에 데이터베이스를 배포하고, On-demand capacity mode를 사용하여 워크로드에 맞춰 처리량을 자동으로 스케일링합니다.",
    "SelectC_Commentary": "DynamoDB는 NoSQL 서비스로, 관계형 모델이 필요한 경우 적합하지 않으며, 스키마가 복잡하거나 조인이 많은 환경에서는 관리가 어렵습니다.",
    "SelectD": "Amazon RDS에 데이터베이스를 배포하고, Magnetic 스토리지를 사용한 뒤, read replicas를 사용하여 워크로드를 처리합니다.",
    "SelectD_Commentary": "Magnetic 스토리지는 저렴할 수 있지만 I/O 성능이 떨어지고, read replicas로 확장하더라도 가변 워크로드에 맞춰 비용을 유연하게 조절하기가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q411",
      "Q348",
      "Q79",
      "Q670",
      "Q449"
    ],
    "SelectA_recommedations": [
      "Q579",
      "Q940",
      "Q959"
    ],
    "SelectB_recommedations": [
      "Q827",
      "Q128",
      "Q284"
    ],
    "SelectC_recommedations": [
      "Q670",
      "Q348",
      "Q79"
    ],
    "SelectD_recommedations": [
      "Q300",
      "Q285",
      "Q574"
    ]
  },
  {
    "Question_Number": "Q980",
    "Question_Description": "한 회사가 VPC 내 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅하고 있습니다. 회사는 고객마다 전용 Amazon S3 버킷을 생성하여 관련 정보를 Amazon S3에 저장합니다. 회사는 EC2 인스턴스에서 실행되는 애플리케이션이 회사의 AWS 계정에 속한 S3 버킷만 안전하게 액세스하도록 보장하고 싶어 합니다. 운영 오버헤드를 최소화하면서 이를 달성하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/147313-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 회사 계정에 속한 Amazon S3 버킷들만 EC2 인스턴스에서 접근 가능하도록 만드는 보안 구성을 묻습니다. 각 고객마다 생성되는 버킷이 많으므로, 모든 버킷을 직접 나열하기가 어렵습니다. VPC에 Gateway Endpoint를 설정하고 IAM 정책에서 회사 계정만 허용하는 조건을 두면 버킷 생성 시마다 별도의 추가 정책 설정 없이 간단히 적용 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "EC2 인스턴스",
      "VPC",
      "S3 버킷",
      "운영 오버헤드 최소화",
      "전용 버킷"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "VPC",
      "NAT Gateway",
      "IAM Instance Profile",
      "Gateway Endpoint",
      "Bucket Policy",
      "Deny Action",
      "Condition Key"
    ],
    "SelectA": "VPC에 Amazon S3 용 Gateway Endpoint를 생성하고, IAM Instance Profile 정책에서 필요한 버킷만 허용하도록 설정합니다.",
    "SelectA_Commentary": "버킷 이름을 직접 지정해야 하므로 만약 버킷 수가 계속 늘어난다면 정책 관리가 번거롭습니다. 동적으로 증가하는 버킷에 대해 매번 정책 업데이트가 필요해 운영 오버헤드가 큽니다.",
    "SelectB": "퍼블릭 서브넷에 NAT Gateway를 만들고, 해당 보안 그룹에서 Amazon S3로의 액세스만 허용합니다. 라우트 테이블을 NAT Gateway로 업데이트합니다.",
    "SelectB_Commentary": "NAT Gateway를 통한 인터넷 경유 방법은 불필요한 비용과 설정 복잡도를 야기합니다. 또한 버킷에 대한 세부 접근 제어가 아닌 단순 인터넷 접근 통제로는 보안이 제한적입니다.",
    "SelectC": "VPC에 Amazon S3 용 Gateway Endpoint를 생성합니다. 그리고 IAM Instance Profile 정책에 Deny 액션과 회사 계정이 아닌 경우를 거부하는 Condition Key를 추가합니다.",
    "SelectC_Commentary": "회사의 계정 ID만 허용하는 정책 설정으로, 동적으로 생성되는 모든 S3 버킷에 자동 적용됩니다. NAT Gateway 등 추가 비용이 없고 버킷 증대에도 대응이 쉬워 운영 오버헤드가 최소화됩니다.",
    "SelectD": "퍼블릭 서브넷에 NAT Gateway를 만들고, 라우트 테이블을 NAT Gateway로 업데이트합니다. 모든 버킷 정책에 Deny 액션과 Condition Key를 지정합니다.",
    "SelectD_Commentary": "각 버킷마다 정책을 수정해야 하므로 관리가 복잡하고, NAT Gateway 비용 또한 발생합니다. 필요 이상의 오버헤드가 크며 동적 버킷 증가에 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q4",
      "Q866",
      "Q92",
      "Q91",
      "Q610"
    ],
    "SelectA_recommedations": [
      "Q91",
      "Q92",
      "Q866"
    ],
    "SelectB_recommedations": [
      "Q965",
      "Q678",
      "Q44"
    ],
    "SelectC_recommedations": [
      "Q494",
      "Q91",
      "Q92"
    ],
    "SelectD_recommedations": [
      "Q774",
      "Q644",
      "Q468"
    ]
  },
  {
    "Question_Number": "Q981",
    "Question_Description": "한 회사가 AWS 상에서 민감한 고객 데이터를 처리하는 클라우드 기반 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 Amazon RDS(데이터베이스)와 Amazon S3(객체 스토리지)를 사용하고, S3 Event Notifications를 통해 AWS Lambda를 호출하여 서버리스 처리를 수행합니다. 이 회사는 AWS IAM Identity Center로 사용자 자격 증명을 관리하고 있으며, 개발, 테스트, 운영 팀이 Amazon RDS와 Amazon S3에 안전하게 액세스하면서 민감한 고객 데이터의 기밀성을 유지해야 합니다. 솔루션은 최소 권한 원칙을 준수해야 하며, 운영 오버헤드를 최소화해야 합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/145821-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 팀별로 민감한 데이터를 안전하게 다루면서, IAM Identity Center를 활용해 최소 권한을 부여하는 방법을 묻습니다. 운영 복잡도를 최소화하려면 중앙 집중적 자격 증명 관리와 권한 세트를 사용하는 방안이 효과적입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "민감한 데이터",
      "최소 권한 원칙",
      "운영 오버헤드 최소화",
      "RDS 접근 권한",
      "S3 접근 권한"
    ],
    "Terms": [
      "Amazon RDS",
      "Amazon S3",
      "AWS Lambda",
      "S3 Event Notifications",
      "AWS IAM Identity Center",
      "AWS IAM Access Analyzer",
      "AWS Organizations",
      "Least Privilege"
    ],
    "SelectA": "IAM 역할로 최소 권한을 부여하고, 각 팀별로 맞춤형 IAM 정책을 할당하여 Amazon RDS와 S3에 필요한 권한만 부여합니다.",
    "SelectA_Commentary": "각 팀별로 세부 정책을 직접 관리해야 하므로 운영 부담이 늘어납니다. IAM Identity Center를 사용하지 않아 기업 전체 계정 관리를 간소화하기 어렵습니다.",
    "SelectB": "IAM Identity Center에서 Identity Center 디렉터리를 활성화하고, RDS와 S3에 대한 세분화된 접근 권한을 갖는 Permission Set을 생성해 그룹에 할당합니다.",
    "SelectB_Commentary": "IAM Identity Center와 Permission Set으로 중앙에서 계정을 관리하고 최소 권한을 유지할 수 있어 운영 오버헤드가 가장 낮고 요구사항을 충족하는 최적 해법입니다.",
    "SelectC": "모든 팀원의 IAM User를 각각 생성하고, 사전에 정의된 RDS·S3 접근용 IAM 역할을 사용자 필요에 따라 할당합니다. IAM Access Analyzer로 주기적으로 자격 증명을 점검합니다.",
    "SelectC_Commentary": "개별 사용자 계정을 일일이 관리해야 하므로 관리 부담이 큽니다. IAM Identity Center 활용보다 오버헤드가 높습니다.",
    "SelectD": "AWS Organizations에서 팀별 별도 계정을 생성하고, 교차 계정 IAM 역할로 최소 권한을 부여합니다. 팀별 역할과 책임에 따라 RDS와 S3에 권한을 설정합니다.",
    "SelectD_Commentary": "별도 계정 생성과 교차 계정 롤 관리 방식은 설정이 복잡하고 오버헤드가 증가합니다. 중앙 집중 관리를 위한 Identity Center 사용보다 비효율적입니다.",
    "Question_Description_recommedations": [
      "Q982",
      "Q211",
      "Q688",
      "Q663",
      "Q222"
    ],
    "SelectA_recommedations": [
      "Q476",
      "Q222",
      "Q429"
    ],
    "SelectB_recommedations": [
      "Q981",
      "Q982",
      "Q476"
    ],
    "SelectC_recommedations": [
      "Q981",
      "Q476",
      "Q222"
    ],
    "SelectD_recommedations": [
      "Q3",
      "Q945",
      "Q653"
    ]
  },
  {
    "Question_Number": "Q982",
    "Question_Description": "한 회사에는 민감한 데이터 파일이 저장된 Amazon S3 버킷이 있습니다. 이 회사의 애플리케이션은 온프레미스 데이터 센터의 가상 머신에서 실행되며, 현재 AWS IAM Identity Center를 사용하고 있습니다. 애플리케이션은 S3 버킷에 있는 파일에 대한 임시 액세스가 필요합니다. 회사는 S3 버킷에 대해 안전한 액세스를 부여하고자 합니다. 다음 중 어떤 솔루션이 이러한 요구 사항을 충족합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148505-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 외부(온프레미스) 환경에서 S3에 민감한 데이터를 안전하게 접근할 수 있는 임시 자격 증명 방안을 묻습니다. IAM Roles Anywhere를 사용하면 애플리케이션이 장기 키를 사용하지 않고도 임시 권한을 획득해 더 안전하고 유연하게 접근 가능합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "민감 데이터",
      "S3 버킷",
      "임시 액세스",
      "on-premises 데이터 센터",
      "AWS IAM Identity Center",
      "IAM Roles Anywhere"
    ],
    "Terms": [
      "S3 bucket policy",
      "IAM Roles Anywhere",
      "AWS CLI",
      "AWS Secrets Manager",
      "AWS IAM Identity Center",
      "Access key",
      "Secret key",
      "IAM user",
      "Public IP address range"
    ],
    "SelectA": "회사의 온프레미스 데이터 센터의 공인 IP 주소 범위에서 버킷에 대한 액세스를 허용하도록 S3 bucket policy를 생성합니다.",
    "SelectA_Commentary": "IP 기반 정책은 노출 범위가 크고 접근 제어가 제한적이므로 민감 데이터에 대한 안전한 임시 액세스로 적합하지 않습니다.",
    "SelectB": "IAM Roles Anywhere를 사용하여 IAM Identity Center에서 S3 버킷에 대한 권한을 얻습니다. AWS CLI를 통해 가상 머신이 역할을 Assume하도록 설정합니다.",
    "SelectB_Commentary": "IAM Roles Anywhere는 온프레미스 환경에서도 임시 보안 자격 증명을 안전하게 사용할 수 있어 민감 데이터 보호에 가장 적합합니다.",
    "SelectC": "AWS CLI를 가상 머신에 설치하고, S3 버킷에 대한 액세스 권한이 있는 IAM user의 Access key와 Secret key를 설정합니다.",
    "SelectC_Commentary": "고정 키를 직접 설정하는 방식은 유출 위험이 높고 장기 자격 증명 관리 부담이 크므로 권장되지 않습니다.",
    "SelectD": "버킷에 대한 액세스를 허가하는 IAM user와 정책을 생성합니다. 이 IAM user의 Access key와 Secret key를 AWS Secrets Manager에 저장하고, 애플리케이션이 시작 시 이를 가져오도록 구성합니다.",
    "SelectD_Commentary": "장기 자격 증명을 저장하는 방식으로, 키 로테이션 및 유출 위험 관리가 복잡해 보안 모범 사례에 어긋납니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q412",
      "Q109",
      "Q889",
      "Q202"
    ],
    "SelectA_recommedations": [
      "Q256",
      "Q965",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q982",
      "Q403",
      "Q981"
    ],
    "SelectC_recommedations": [
      "Q982",
      "Q403",
      "Q270"
    ],
    "SelectD_recommedations": [
      "Q233",
      "Q780",
      "Q476"
    ]
  },
  {
    "Question_Number": "Q983",
    "Question_Description": "한 회사가 디렉터리 서비스와 DNS를 포함한 핵심 네트워크 서비스를 온프레미스 데이터 센터에서 호스팅하고 있습니다. 이 데이터 센터는 AWS Direct Connect(DX)를 통해 AWS Cloud와 연결되어 있습니다. 회사는 추가로 여러 AWS 계정을 계획하고 있으며, 이 계정들도 이러한 네트워크 서비스에 빠르고 비용 효율적이며 일관적으로 액세스하기를 원합니다. 솔루션은 최소한의 운영 오버헤드로 이 요구 사항을 충족해야 합니다. 어떤 솔루션을 구현해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148506-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "추가 AWS 계정을 간편하고 효율적으로 온프레미스 네트워크 서비스에 연결하기 위해서는 트래픽을 중앙화하는 AWS Transit Gateway가 가장 적합합니다. 최소한의 오버헤드로 확장성과 안정성을 확보할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "DX",
      "AWS Transit Gateway",
      "온프레미스 데이터 센터",
      "네트워크 서비스",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Direct Connect(DX)",
      "AWS Transit Gateway",
      "VPC Endpoint",
      "VPN 연결",
      "온프레미스 데이터 센터",
      "DNS",
      "디렉터리 서비스"
    ],
    "SelectA": "각 새 계정마다 별도의 DX 연결을 생성하고 온프레미스 서버로 트래픽을 라우팅합니다.",
    "SelectA_Commentary": "모든 새 계정에 각각 DX를 연결하면 비용과 운영 부담이 크게 늘어나므로 비효율적입니다.",
    "SelectB": "모든 필요한 서비스에 대해 DX VPC에서 VPC Endpoint를 구성하고 온프레미스 서버로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "VPC Endpoint는 AWS 서비스에 대한 프라이빗 액세스를 제공하지만, 온프레미스 네트워크 서비스와 직접 연결하기에는 적합하지 않습니다.",
    "SelectC": "각 새 계정과 DX VPC 간에 VPN 연결을 생성하고 온프레미스 서버로 트래픽을 라우팅합니다.",
    "SelectC_Commentary": "VPN 연결은 계정마다 별도 터널 구성이 필요해 운영 오버헤드가 높으며, DX 직접 연결 대비 이점이 적습니다.",
    "SelectD": "계정들 간에 AWS Transit Gateway를 구성하고 DX를 Transit Gateway에 연결한 뒤 온프레미스 서버로 네트워크 트래픽을 라우팅합니다.",
    "SelectD_Commentary": "Transit Gateway를 통한 중앙집중형 연결은 새 계정 추가 시 확장이 쉽고, 운영이 단순하여 오버헤드를 최소화하는 최적의 솔루션입니다.",
    "Question_Description_recommedations": [
      "Q68",
      "Q627",
      "Q741",
      "Q722",
      "Q545"
    ],
    "SelectA_recommedations": [
      "Q58",
      "Q917",
      "Q491"
    ],
    "SelectB_recommedations": [
      "Q194",
      "Q439",
      "Q8"
    ],
    "SelectC_recommedations": [
      "Q487",
      "Q439",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q10",
      "Q983",
      "Q354"
    ]
  },
  {
    "Question_Number": "Q984",
    "Question_Description": "한 회사가 하나의 AWS Region 내 여러 Availability Zones에 걸쳐 주요 공개 웹 애플리케이션을 호스팅하고 있습니다. 해당 애플리케이션은 Amazon EC2 Auto Scaling group과 Application Load Balancer(ALB)를 사용합니다. 웹 개발 팀은 수백만 명의 전 세계 고객에게 동적 콘텐츠를 제공하는 능력을 향상시키기 위해 비용 효율적인 컴퓨팅 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148507-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 수백만 고객에게 동적 콘텐츠를 빠르고 비용 효율적으로 제공하기 위한 방안을 묻습니다. CloudFront는 글로벌 엣지 로케이션을 통해 콘텐츠를 캐싱하고 최적화하며, 기존 ALB를 오리진으로 설정해 동적 데이터를 빠르게 전달합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2",
      "4.4"
    ],
    "Keywords": [
      "AWS Region",
      "EC2 Auto Scaling group",
      "Application Load Balancer",
      "비용 효율적 컴퓨팅",
      "전 세계 동적 콘텐츠 제공"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer",
      "Availability Zones",
      "Amazon CloudFront",
      "Amazon Route 53",
      "Amazon S3",
      "AWS Direct Connect",
      "Origin",
      "Website Hosting"
    ],
    "SelectA": "Amazon CloudFront distribution을 생성하고 기존 ALB를 origin으로 구성합니다.",
    "SelectA_Commentary": "CloudFront를 사용하면 글로벌 엣지 로케이션을 통해 콘텐츠를 빠르고 효과적으로 배포하며 비용도 절감할 수 있어 요구 사항에 부합합니다.",
    "SelectB": "Amazon Route 53를 사용하여 각 고객의 지리적 위치에 따라 ALB와 EC2 instances로 트래픽을 라우팅합니다.",
    "SelectB_Commentary": "지리적 위치 기반 라우팅만으로는 캐싱 및 전송 최적화 혜택이 제한적이므로, 전 세계 동적 콘텐츠 제공에 충분치 않습니다.",
    "SelectC": "public read access가 활성화된 Amazon S3 bucket을 생성하고 웹 애플리케이션을 마이그레이션한 뒤 website hosting을 구성합니다.",
    "SelectC_Commentary": "S3는 정적 콘텐츠 호스팅에 적합하지만, 동적 웹 애플리케이션에 필요한 서버 로직을 직접 처리하기에는 부적합합니다.",
    "SelectD": "AWS Direct Connect를 사용하여 웹 애플리케이션에서 각 고객 위치로 콘텐츠를 직접 서비스합니다.",
    "SelectD_Commentary": "Direct Connect는 전용 네트워크 연결로 비용이 크고 구축이 복잡하여, 대규모 글로벌 서비스에 적합한 저비용 구조가 아닙니다.",
    "Question_Description_recommedations": [
      "Q441",
      "Q245",
      "Q559",
      "Q473",
      "Q894"
    ],
    "SelectA_recommedations": [
      "Q943",
      "Q486",
      "Q485"
    ],
    "SelectB_recommedations": [
      "Q473",
      "Q380",
      "Q238"
    ],
    "SelectC_recommedations": [
      "Q300",
      "Q877",
      "Q1003"
    ],
    "SelectD_recommedations": [
      "Q499",
      "Q835",
      "Q240"
    ]
  },
  {
    "Question_Number": "Q985",
    "Question_Description": "한 회사가 AWS에 사용자 데이터를 저장하고 있습니다. 이 데이터는 업무 시간대에 집중적으로 사용되며, 상시로 접근됩니다. 접근 패턴은 다양하여 몇몇 데이터는 몇 달 동안 전혀 사용되지 않을 수 있습니다. 솔루션스 아키텍트는 높은 가용성과 최고 수준의 내구성을 유지하면서도 비용 효율적인 스토리지 솔루션을 선택해야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148508-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터 사용 빈도가 들쑥날쑥하며, 일부는 장기간 미사용이지만 업무 시간대에는 자주 접근되는 데이터를 위한 스토리지 클래스를 찾는 것입니다. 비용을 최소화하면서도 S3의 높은 내구성과 가용성을 유지해야 하므로, 자동 계층화 기능이 있는 Amazon S3 Intelligent-Tiering이 적합합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "비용 효율적",
      "높은 내구성",
      "높은 가용성",
      "S3 Intelligent-Tiering"
    ],
    "Terms": [
      "Amazon S3 Standard",
      "Amazon S3 Intelligent-Tiering",
      "Amazon S3 Glacier Deep Archive",
      "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)",
      "Durability",
      "Availability"
    ],
    "SelectA": "Amazon S3 Standard",
    "SelectA_Commentary": "S3 Standard는 높은 내구성과 가용성을 제공하지만, 장기간 사용되지 않는 데이터에도 동일 비용이 적용되어 최적의 비용 효율을 보장하기 어렵습니다.",
    "SelectB": "Amazon S3 Intelligent-Tiering",
    "SelectB_Commentary": "데이터 액세스 패턴을 자동으로 분석해 적절한 스토리지 클래스로 옮겨주므로, 비용 효율과 높은 가용성을 동시에 만족시키는 최적의 선택입니다.",
    "SelectC": "Amazon S3 Glacier Deep Archive",
    "SelectC_Commentary": "장기 아카이빙용으로 매우 저렴하지만, 데이터 복원 시간이 오래 걸려 상시로 데이터에 접근해야 하는 요구사항에 부합하지 않습니다.",
    "SelectD": "Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)",
    "SelectD_Commentary": "단일 AZ에만 저장되어 재해 시 위험이 크며, 전체 데이터의 내구성과 가용성을 보장하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q728",
      "Q284",
      "Q541",
      "Q525",
      "Q485"
    ],
    "SelectA_recommedations": [
      "Q23",
      "Q415",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q943",
      "Q486"
    ],
    "SelectC_recommedations": [
      "Q285",
      "Q943",
      "Q552"
    ],
    "SelectD_recommedations": [
      "Q552",
      "Q943",
      "Q829"
    ]
  },
  {
    "Question_Number": "Q986",
    "Question_Description": "한 회사가 Amazon EC2 Linux 인스턴스에서 실행되는 애플리케이션을 테스트하고 있습니다. 이 EC2 인스턴스에는 단일 500 GB 용량의 Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp2) 볼륨이 연결되어 있습니다. 회사는 이 애플리케이션을 여러 EC2 인스턴스로 구성된 Auto Scaling group에서 배포할 예정입니다. 모든 인스턴스가 이 EBS 볼륨에 저장된 데이터를 액세스할 수 있어야 합니다. 회사는 애플리케이션 코드에 큰 변경을 가하지 않으면서도 높은 가용성과 복원력을 제공하는 솔루션이 필요합니다. 이 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148509-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 여러 EC2 인스턴스에서 동일한 데이터를 동시에 액세스해야 하고, 애플리케이션 코드 변경을 최소화해야 하는 상황입니다. Amazon EFS는 다중 인스턴스 마운트를 지원하며 고가용성과 복원력을 제공해 요구사항을 충족합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Amazon EBS",
      "Auto Scaling group",
      "고가용성",
      "복원력",
      "애플리케이션 코드 변경 최소화",
      "Amazon EFS",
      "Amazon FSx for Windows File Server",
      "NFS server software"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "General Purpose SSD (gp2)",
      "Auto Scaling group",
      "NFS server software",
      "Amazon FSx for Windows File Server",
      "SMB",
      "Amazon Elastic File System (Amazon EFS)",
      "General Purpose performance mode",
      "Provisioned IOPS SSD"
    ],
    "SelectA": "EC2 인스턴스를 하나 프로비저닝하고 NFS server software를 구성한 뒤, 500 GB gp2 EBS 볼륨을 연결합니다.",
    "SelectA_Commentary": "단일 EC2 인스턴스와 EBS에 의존하면 인스턴스 장애 시 전체 서비스에 영향이 커서 고가용성을 보장하지 못합니다.",
    "SelectB": "Amazon FSx for Windows File Server 파일 시스템을 프로비저닝하고, 단일 가용 영역에서 SMB 파일 스토어로 구성합니다.",
    "SelectB_Commentary": "단일 AZ에만 존재하므로 AZ 장애 시 서비스 중단 가능성이 높고 Windows 환경 중심의 구성이어서 변경 부담이 있을 수 있습니다.",
    "SelectC": "EC2 인스턴스를 프로비저닝한 뒤, 두 개의 250 GB Provisioned IOPS SSD EBS 볼륨을 연결합니다.",
    "SelectC_Commentary": "EBS 볼륨은 동시에 여러 인스턴스에서 장착하여 쓰기가 불가능하므로 공유 스토리지로 적합하지 않습니다.",
    "SelectD": "Amazon Elastic File System (Amazon EFS) 파일 시스템을 프로비저닝하고 General Purpose performance mode로 구성합니다.",
    "SelectD_Commentary": "EFS는 여러 AZ에서 접근 가능하며 동시 마운트를 지원하여 고가용성과 데이터 공유가 필요한 환경에 최적입니다.",
    "Question_Description_recommedations": [
      "Q837",
      "Q581",
      "Q602",
      "Q312",
      "Q271"
    ],
    "SelectA_recommedations": [
      "Q102",
      "Q986",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q618",
      "Q934",
      "Q753"
    ],
    "SelectC_recommedations": [
      "Q584",
      "Q194",
      "Q244"
    ],
    "SelectD_recommedations": [
      "Q842",
      "Q102",
      "Q303"
    ]
  },
  {
    "Question_Number": "Q987",
    "Question_Description": "한 회사가 최근 새로운 애플리케이션을 출시했습니다. 애플리케이션은 두 개의 Availability Zone에 걸쳐 여러 Amazon EC2 인스턴스에서 동작합니다. 최종 사용자는 TCP를 사용해 애플리케이션과 통신합니다. 이 애플리케이션은 높은 가용성을 유지하면서, 사용자 수가 증가할 때 자동으로 확장되어야 합니다. 가장 비용 효율적이면서 이러한 요구사항을 충족하는 조합은 무엇입니까? (2개를 고르시오)",
    "Answer": "A,B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148519-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 TCP 기반 애플리케이션을 비용 효율적으로 고가용성과 확장성을 달성하도록 로드 밸런서와 자동 스케일링 전략을 결정하는 상황입니다. Network Load Balancer와 Auto Scaling group을 함께 사용하면 TCP 레벨 트래픽 처리와 자동 확장이 모두 가능해 가장 효과적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "TCP 통신",
      "높은 가용성",
      "자동 확장",
      "Network Load Balancer",
      "Auto Scaling group"
    ],
    "Terms": [
      "Amazon EC2",
      "Availability Zone",
      "TCP",
      "Network Load Balancer",
      "Application Load Balancer",
      "Gateway Load Balancer",
      "Auto Scaling group"
    ],
    "SelectA": "Amazon EC2 인스턴스 앞단에 Network Load Balancer를 추가합니다.",
    "SelectA_Commentary": "TCP 계층에서 로드 밸런싱을 제공해 낮은 지연 시간으로 안정적인 연결을 지원하고, 고가용성을 구현하기에 적합합니다.",
    "SelectB": "EC2 인스턴스를 위한 Auto Scaling group을 구성합니다.",
    "SelectB_Commentary": "트래픽 증가 시 인스턴스를 자동으로 늘리고, 감소 시 줄여 운영 비용을 절감하면서도 확장성과 고가용성을 보장합니다.",
    "SelectC": "Amazon EC2 인스턴스 앞단에 Application Load Balancer를 추가합니다.",
    "SelectC_Commentary": "ALB는 주로 HTTP/HTTPS(L7)를 위한 것으로, TCP 기반 애플리케이션에는 NLB가 더 적합하므로 최적의 선택이 아닙니다.",
    "SelectD": "애플리케이션을 위한 EC2 인스턴스를 수동으로 추가합니다.",
    "SelectD_Commentary": "수동 스케일링은 자동 확장 요구사항을 충족하지 못하며 운영의 복잡성과 비용이 증가합니다.",
    "SelectE": "Amazon EC2 인스턴스 앞단에 Gateway Load Balancer를 추가합니다.",
    "SelectE_Commentary": "Gateway Load Balancer는 서드파티 가상 어플라이언스 삽입 등에 특화되어 있어 애플리케이션의 TCP 트래픽 로드 밸런싱에는 적합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q570",
      "Q700",
      "Q757",
      "Q194",
      "Q584"
    ],
    "SelectA_recommedations": [
      "Q357",
      "Q405",
      "Q275"
    ],
    "SelectB_recommedations": [
      "Q595",
      "Q660",
      "Q581"
    ],
    "SelectC_recommedations": [
      "Q405",
      "Q714",
      "Q357"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q584",
      "Q252"
    ],
    "SelectE_recommedations": [
      "Q194",
      "Q357",
      "Q405"
    ]
  },
  {
    "Question_Number": "Q988",
    "Question_Description": "한 회사가 AWS Cloud를 사용하는 새 모바일 앱의 아키텍처를 설계 중입니다. 이 회사는 AWS Organizations에서 조직 단위(OU)를 사용해 계정을 관리합니다. 회사는 Amazon EC2 인스턴스에 'sensitive'와 'nonsensitive' 값을 사용하여 데이터 민감도를 태그로 지정하고자 합니다. 또한 IAM 주체가 태그를 삭제하거나 태그 없이 인스턴스를 생성할 수 없도록 해야 합니다. 이 요구사항을 만족시키기 위해 필요한 단계의 조합은 무엇입니까? (2개를 선택하십시오.)",
    "Answer": "A,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148803-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "데이터 민감도 태그를 강제 적용하고 무단 삭제를 방지하려면 service control policy(SCP)를 활용해 태그가 없는 인스턴스 생성과 태그 삭제를 직접 거부해야 합니다. tag policy만으로는 태그 강제 적용이 불가능하므로 주의해야 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "데이터 민감도",
      "태그 삭제 방지",
      "인스턴스 생성 제한",
      "AWS Organizations",
      "service control policy",
      "tag policy"
    ],
    "Terms": [
      "AWS Cloud",
      "Amazon EC2",
      "AWS Organizations",
      "organizational units (OUs)",
      "data sensitivity",
      "sensitive",
      "nonsensitive",
      "IAM",
      "tag policy",
      "service control policy (SCP)",
      "AWS Config",
      "AWS Lambda"
    ],
    "SelectA": "AWS Organizations에서 새로운 tag policy를 생성하여 data sensitivity 태그 키와 필요한 값을 지정하고, 이를 EC2 인스턴스에 적용되도록 설정한 뒤 OU에 연결합니다.",
    "SelectA_Commentary": "tag policy는 태그 표준화에 도움이 되지만 인스턴스 생성이나 태그 삭제를 직접 차단하지 못하므로 요구사항을 충족하지 않습니다.",
    "SelectB": "AWS Organizations에서 새로운 service control policy(SCP)를 생성하여 data sensitivity 태그 키와 필요한 태그 값을 지정하고, 이를 EC2 인스턴스에 적용되도록 설정한 뒤 OU에 연결합니다.",
    "SelectB_Commentary": "SCP는 인스턴스 생성 시 특정 태그와 값이 없으면 거부하도록 구성할 수 있어 요구사항 충족에 유리합니다. 그러나 태그 삭제 방지는 별도 정책이 필요합니다.",
    "SelectC": "태그 키가 없을 경우 인스턴스를 실행하지 못하도록 하는 tag policy와, 태그 삭제를 방지하는 또 다른 tag policy를 모두 OU에 연결합니다.",
    "SelectC_Commentary": "tag policy 자체는 태그 유효성 검사를 돕지만, 동작을 거부(Deny)하는 기능이 없어 보안 요구사항을 만족시키기 어렵습니다.",
    "SelectD": "태그 키가 없을 경우 인스턴스 생성을 거부하는 SCP를 생성하고, 태그 삭제를 방지하는 또 다른 SCP를 생성하여 OU에 연결합니다.",
    "SelectD_Commentary": "SCP로 리소스 생성 및 태그 삭제를 직접 거부할 수 있어 요구사항에 부합합니다. 태그 누락과 삭제 모두 차단하므로 필수 조합입니다.",
    "SelectE": "EC2 인스턴스가 data sensitivity 태그와 지정된 값을 사용하는지 검사하는 AWS Config 규칙을 만들고, 비준수 리소스를 삭제하는 AWS Lambda 함수를 구성합니다.",
    "SelectE_Commentary": "사후 검증으로 인스턴스 생성 자체를 사전에 막지 못해, IAM 주체가 먼저 리소스를 생성하고 이후에 삭제하는 방식이라 즉각적인 제어가 어렵습니다.",
    "Question_Description_recommedations": [
      "Q560",
      "Q945",
      "Q3",
      "Q777",
      "Q168"
    ],
    "SelectA_recommedations": [
      "Q988",
      "Q433",
      "Q560"
    ],
    "SelectB_recommedations": [
      "Q709",
      "Q988",
      "Q3"
    ],
    "SelectC_recommedations": [
      "Q665",
      "Q478",
      "Q122"
    ],
    "SelectD_recommedations": [
      "Q189",
      "Q122",
      "Q665"
    ],
    "SelectE_recommedations": [
      "Q453",
      "Q682",
      "Q492"
    ]
  },
  {
    "Question_Number": "Q989",
    "Question_Description": "어떤 회사가 고객 포털의 백엔드로 사용되는 AWS 상의 데이터베이스 워크로드를 운영하고 있습니다. 이 회사는 Amazon RDS for PostgreSQL을 사용하여 Multi-AZ database cluster를 운영하고 있습니다. 회사는 30일 백업 보존 정책을 도입해야 합니다. 현재 이 회사는 자동 RDS backup과 수동 RDS backup을 모두 사용하고 있습니다. 회사는 30일 미만인 자동 및 수동 RDS backup을 모두 유지하길 원합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148459-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 데이터베이스 백업 보존 전략을 최소 비용으로 달성하는 방법을 묻습니다. AWS Backup을 사용하면 자동화 편의성은 높지만 추가 비용이 들 수 있습니다. 따라서 자동 백업 보존 기간을 30일로 설정하고, 30일 초과 수동 백업을 수동으로 삭제하는 전략이 가장 비용 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "Multi-AZ database cluster",
      "30일 백업 보존 정책",
      "자동 RDS backup",
      "수동 RDS backup",
      "비용 효율"
    ],
    "Terms": [
      "Amazon RDS for PostgreSQL",
      "Multi-AZ",
      "Backup Retention Policy",
      "AWS Backup",
      "Automated Backup",
      "Manual Backup",
      "AWS CloudFormation"
    ],
    "SelectA": "AWS Backup을 사용하여 자동 백업의 백업 보존 정책을 30일로 설정합니다. 30일이 지난 수동 백업은 수동으로 삭제합니다.",
    "SelectA_Commentary": "AWS Backup은 별도의 비용이 발생하므로 가장 비용 효율적인 방법은 아닙니다.",
    "SelectB": "RDS 자동 백업을 비활성화합니다. 30일이 지난 자동 및 수동 백업을 모두 삭제합니다. 자동 백업 보존 정책을 30일로 설정합니다.",
    "SelectB_Commentary": "자동 백업을 끄는 것은 30일 이내 백업 유지 목표와 어긋나며, 작업 과정도 불필요하게 복잡합니다.",
    "SelectC": "자동 백업 보존 정책을 30일로 설정합니다. 30일이 지난 수동 백업은 수동으로 삭제합니다.",
    "SelectC_Commentary": "RDS 자체 기능으로 자동 백업을 관리하고, 수동 백업만 직접 정리하여 추가 비용 없이 간편하면서도 요구사항을 충족합니다.",
    "SelectD": "RDS 자동 백업을 비활성화합니다. AWS CloudFormation을 사용해 30일이 지난 자동 및 수동 백업을 자동으로 삭제합니다. 자동 백업 보존 정책을 30일로 설정합니다.",
    "SelectD_Commentary": "자동 백업을 해제하는 접근은 복원력 측면에서 부적절하며, CloudFormation으로 백업을 삭제하는 것은 불필요하게 절차가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q958",
      "Q420",
      "Q464",
      "Q536",
      "Q601"
    ],
    "SelectA_recommedations": [
      "Q311",
      "Q293",
      "Q8"
    ],
    "SelectB_recommedations": [
      "Q863",
      "Q967",
      "Q7"
    ],
    "SelectC_recommedations": [
      "Q967",
      "Q7",
      "Q187"
    ],
    "SelectD_recommedations": [
      "Q863",
      "Q108",
      "Q629"
    ]
  },
  {
    "Question_Number": "Q990",
    "Question_Description": "한 회사가 레거시 애플리케이션을 AWS로 마이그레이션하려고 합니다. 해당 애플리케이션은 현재 on-premises 스토리지 솔루션과 통신하기 위해 NFS를 사용하여 애플리케이션 데이터를 저장합니다. 이 목적을 위해 NFS 이외의 다른 통신 프로토콜은 사용할 수 없도록 애플리케이션을 수정할 수 없습니다. 마이그레이션 후 사용을 위해 솔루션스 아키텍트가 권장해야 하는 스토리지 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148460-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 기존 NFS를 사용하는 레거시 애플리케이션을 AWS로 이전할 때 어떤 스토리지 솔루션이 적합한지 묻습니다. Amazon EFS는 NFS 프로토콜을 지원하고, 탄력적으로 확장 가능하며 다중 AZ에서 고가용성을 제공하므로 적합합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "레거시 애플리케이션",
      "NFS",
      "AWS 마이그레이션",
      "스토리지 솔루션"
    ],
    "Terms": [
      "NFS",
      "AWS DataSync",
      "Amazon EBS",
      "Amazon EFS",
      "Amazon EMRFS"
    ],
    "SelectA": "AWS DataSync",
    "SelectA_Commentary": "AWS DataSync는 데이터를 전송·동기화하는 서비스이지만, 지속적으로 애플리케이션 데이터를 저장하는 NFS 호환 스토리지 솔루션이 아닙니다.",
    "SelectB": "Amazon Elastic Block Store (Amazon EBS)",
    "SelectB_Commentary": "Amazon EBS는 블록 스토리지로, 단일 인스턴스 연결을 전제로 하며 NFS 프로토콜 동시 접속을 위한 기본 기능을 제공하지 않습니다.",
    "SelectC": "Amazon Elastic File System (Amazon EFS)",
    "SelectC_Commentary": "EFS는 NFS를 지원하며 탄력적으로 확장 가능한 완전관리형 파일 스토리지로, 애플리케이션 수정 없이 사용 가능합니다. 정답입니다.",
    "SelectD": "Amazon EMR File System (Amazon EMRFS)",
    "SelectD_Commentary": "EMRFS는 Amazon EMR과 S3 간 통합을 위한 파일 시스템 인터페이스로, 일반적인 NFS 지원 스토리지로는 활용하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q283",
      "Q496",
      "Q83",
      "Q173",
      "Q155"
    ],
    "SelectA_recommedations": [
      "Q472",
      "Q578",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q695",
      "Q620",
      "Q746"
    ],
    "SelectC_recommedations": [
      "Q680",
      "Q695",
      "Q990"
    ],
    "SelectD_recommedations": [
      "Q680",
      "Q361",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q991",
    "Question_Description": "한 회사가 수천 마리의 바다거북 이동 경로를 기록하기 위해 GPS 트래커를 사용하고 있습니다. 트래커는 5분마다 거북이가 100야드(약 91.4미터) 이상 이동했는지를 확인합니다. 만약 이동했다면 새 좌표를 단일 리전에 있는 여러 가용 영역의 Amazon EC2 인스턴스 세 대에서 동작하는 웹 애플리케이션으로 전송합니다. 최근 예기치 못한 대량의 트래커 데이터가 유입되어 웹 애플리케이션이 과부하되었고, 데이터를 유실하면서 이벤트를 재생할 수 없었습니다. 솔루션스 아키텍트는 이러한 상황이 다시 발생하지 않도록 해야 하며, 운영 오버헤드를 최소화해야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148885-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "트래커로부터 오는 대규모 데이터를 안정적으로 수집하고 처리하기 위해서는 느슨한 결합과 메시지 큐를 통한 유실 방지가 중요합니다. Amazon SQS를 사용하면 자동으로 확장되며, 메시지를 안전하게 보관해 웹 애플리케이션이 처리 가능한 속도로 가져올 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "GPS 트래커",
      "대규모 데이터 처리",
      "데이터 손실 방지",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon S3",
      "Amazon API Gateway",
      "AWS Lambda",
      "Amazon SQS",
      "Amazon DynamoDB",
      "TTL(Time To Live)"
    ],
    "SelectA": "Amazon S3 버킷을 생성하여 데이터를 저장하고, 애플리케이션이 새로운 데이터를 처리하기 위해 버킷을 스캔하도록 설정합니다.",
    "SelectA_Commentary": "S3는 대규모 파일 보관이 유리하지만 이벤트 흐름을 제어하는 메시지 큐와 달리 즉각적인 처리를 위한 큐잉 기능이 없어 실시간 데이터 처리에는 적합하지 않습니다.",
    "SelectB": "Amazon API Gateway 엔드포인트를 만들어 위치 좌표를 수신합니다. AWS Lambda 함수를 사용해 각 아이템을 동시에 처리합니다.",
    "SelectB_Commentary": "API Gateway와 Lambda로 마이크로서비스 구성을 할 수 있지만, 트래픽 폭주 시 Lambda 호출 비용 및 동시성 제한이 발생할 수 있고, 메시지 유실을 막는 별도 버퍼링이 없습니다.",
    "SelectC": "Amazon SQS 큐를 생성해 들어오는 데이터를 저장합니다. 애플리케이션이 새 메시지를 폴링하여 처리하도록 구성합니다.",
    "SelectC_Commentary": "SQS는 완전관리형 메시지 큐로 확장성과 내결함성이 뛰어나며, 메시지를 안전하게 보관해 놓기 때문에 데이터 손실 없이 안정적으로 처리 가능합니다.",
    "SelectD": "전송된 위치 좌표를 저장할 Amazon DynamoDB 테이블을 생성합니다. 애플리케이션이 테이블을 쿼리해 새 데이터를 처리하도록 설정하고, TTL로 처리된 데이터를 제거합니다.",
    "SelectD_Commentary": "DynamoDB는 고성능 NoSQL DB지만, 메시지 큐 기능보다 구축 및 운영이 복잡하며, 일시적 데이터를 처리하는 데에는 필요 이상으로 관리 포인트가 많습니다.",
    "Question_Description_recommedations": [
      "Q413",
      "Q252",
      "Q110",
      "Q163",
      "Q149"
    ],
    "SelectA_recommedations": [
      "Q784",
      "Q110",
      "Q363"
    ],
    "SelectB_recommedations": [
      "Q10",
      "Q354",
      "Q207"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q869"
    ],
    "SelectD_recommedations": [
      "Q845",
      "Q1002",
      "Q768"
    ]
  },
  {
    "Question_Number": "Q992",
    "Question_Description": "한 회사의 소프트웨어 개발 팀은 Amazon RDS Multi-AZ cluster가 필요합니다. 이 RDS cluster는 온프레미스에서 배포된 데스크톱 클라이언트의 백엔드로 동작합니다. 이 데스크톱 클라이언트는 RDS cluster에 직접 연결해야 합니다. 회사는 개발 팀이 사무실에 있을 때 클라이언트를 통해 클러스터에 연결할 수 있는 능력을 제공해야 합니다. 가장 안전하게 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148461-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스에서 배포된 데스크톱 클라이언트가 Amazon RDS Multi-AZ cluster에 안전하게 연결하도록 하는 설계를 묻습니다. Public Subnet 대신 Private Subnet에 RDS를 배치하고, AWS Site-to-Site VPN을 연결해 사무실 환경에서만 안전하게 액세스 가능하도록 설정하는 방안이 가장 적절합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon RDS Multi-AZ",
      "데스크톱 클라이언트",
      "온프레미스",
      "보안 연결",
      "사무실 접속"
    ],
    "Terms": [
      "Amazon RDS Multi-AZ",
      "VPC",
      "Public Subnet",
      "Private Subnet",
      "AWS Site-to-Site VPN",
      "Customer Gateway",
      "RDS Security Group"
    ],
    "SelectA": "VPC와 두 개의 Public Subnet을 생성하고, 해당 Public Subnet에 RDS cluster를 생성합니다. 회사 사무실의 Customer Gateway를 사용해 AWS Site-to-Site VPN을 구성합니다.",
    "SelectA_Commentary": "RDS가 Public Subnet에 있으면 인터넷에서 직접 노출될 수 있으므로, 사무실 VPN 연결만으로 충분히 안전하지 않습니다.",
    "SelectB": "VPC와 두 개의 Private Subnet을 생성하고, 해당 Private Subnet에 RDS cluster를 생성합니다. 회사 사무실의 Customer Gateway를 사용해 AWS Site-to-Site VPN을 구성합니다.",
    "SelectB_Commentary": "Private Subnet에 RDS를 배치하면 인터넷에 노출되지 않으며, Site-to-Site VPN을 통해 사무실에서만 안전하게 DB에 접근 가능합니다. 가장 보안에 적합한 선택입니다.",
    "SelectC": "VPC와 두 개의 Private Subnet을 생성하고, 해당 Private Subnet에 RDS cluster를 생성합니다. RDS Security Group을 사용해 사무실 IP 대역이 클러스터에 접근하도록 허용합니다.",
    "SelectC_Commentary": "VPN 없이 직접 IP 대역 제어만 적용하면 데이터 전송이 암호화되지 않아 보안 측면에서 취약할 수 있습니다.",
    "SelectD": "VPC와 두 개의 Public Subnet을 생성하고, 해당 Public Subnet에 RDS cluster를 생성합니다. 개발자별로 클러스터 사용자를 만들고 RDS Security Group을 사용해 접근을 허용합니다.",
    "SelectD_Commentary": "Public Subnet에 RDS를 두면 인터넷에서 직접 노출되어 보안 위험이 큽니다. 사무실 내부 연결만 허용하기에도 취약합니다.",
    "Question_Description_recommedations": [
      "Q86",
      "Q951",
      "Q121",
      "Q742",
      "Q330"
    ],
    "SelectA_recommedations": [
      "Q810",
      "Q55",
      "Q438"
    ],
    "SelectB_recommedations": [
      "Q438",
      "Q810",
      "Q712"
    ],
    "SelectC_recommedations": [
      "Q438",
      "Q55",
      "Q251"
    ],
    "SelectD_recommedations": [
      "Q438",
      "Q55",
      "Q385"
    ]
  },
  {
    "Question_Number": "Q993",
    "Question_Description": "한 솔루션스 아키텍트가 대량 데이터를 배치 처리하는 애플리케이션을 설계하고 있습니다. 입력 데이터는 Amazon S3에 저장되고, 출력 데이터는 다른 S3 버킷에 보관될 예정입니다. 처리 과정에서 애플리케이션은 여러 Amazon EC2 인스턴스 간에 네트워크를 통해 데이터를 전송합니다. 전체 데이터 전송 비용을 줄이기 위해서는 무엇을 해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148462-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 간 데이터 전송에 따른 비용 최적화 방법을 묻습니다. 같은 Availability Zone에 두면 내부 데이터 전송이 무료이므로 비용을 크게 절감할 수 있습니다.(약 96자)",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.4"
    ],
    "Keywords": [
      "데이터 전송 비용",
      "같은 Availability Zone",
      "Amazon S3",
      "Amazon EC2"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon EC2",
      "Availability Zone",
      "Auto Scaling group",
      "AWS Region",
      "private subnet",
      "데이터 전송 비용"
    ],
    "SelectA": "모든 EC2 인스턴스를 Auto Scaling group에 배치합니다.",
    "SelectA_Commentary": "Auto Scaling group으로 자동 확장은 가능하지만, 같은 AZ에 인스턴스를 둬야 하는 조건을 충족하는 것은 아니므로 전송 비용을 확실히 줄이지 못합니다.",
    "SelectB": "모든 EC2 인스턴스를 같은 AWS Region에 배치합니다.",
    "SelectB_Commentary": "같은 리전에 있는 것만으로는 AZ가 달라질 수 있어, AZ 간 전송 비용이 발생할 수 있습니다.",
    "SelectC": "모든 EC2 인스턴스를 같은 Availability Zone에 배치합니다.",
    "SelectC_Commentary": "같은 AZ 내 인스턴스 간 전송은 비용이 부과되지 않아, 전송 비용을 최소화할 수 있는 최적의 선택입니다.",
    "SelectD": "모든 EC2 인스턴스를 여러 Availability Zone에 있는 private subnet에 배치합니다.",
    "SelectD_Commentary": "여러 AZ 간 전송은 비용이 발생하므로 오히려 전송 비용이 증가할 수 있습니다.",
    "Question_Description_recommedations": [
      "Q469",
      "Q167",
      "Q238",
      "Q671",
      "Q347"
    ],
    "SelectA_recommedations": [
      "Q290",
      "Q937",
      "Q552"
    ],
    "SelectB_recommedations": [
      "Q552",
      "Q238",
      "Q773"
    ],
    "SelectC_recommedations": [
      "Q773",
      "Q552",
      "Q238"
    ],
    "SelectD_recommedations": [
      "Q773",
      "Q860",
      "Q552"
    ]
  },
  {
    "Question_Number": "Q994",
    "Question_Description": "한 회사가 Amazon Aurora MySQL DB cluster를 스토리지로 사용하는 다중 계층 웹 애플리케이션을 호스팅하고 있습니다. 애플리케이션 계층은 Amazon EC2 인스턴스에서 호스팅됩니다. 회사의 IT 보안 지침에 따라 데이터베이스 자격 증명을 암호화하고 14일마다 교체해야 합니다. 운영 노력을 최소화하면서 이 요구 사항을 충족하기 위해 솔루션스 아키텍트는 무엇을 해야 합니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148463-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "문제의 핵심은 데이터베이스 자격 증명을 자동으로 암호화하고 주기적으로 교체하는 방법입니다. AWS Secrets Manager는 Aurora DB와 연동하여 손쉽게 자격 증명을 저장 및 회전할 수 있으며, 14일 간격의 자동 회전을 설정하면 운영 부담을 최소화할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "Amazon Aurora MySQL DB cluster",
      "데이터베이스 자격 증명",
      "14일 교체",
      "운영 노력을 최소화",
      "암호화"
    ],
    "Terms": [
      "AWS Key Management Service (AWS KMS)",
      "AWS Secrets Manager",
      "AWS Systems Manager Parameter Store",
      "SecureString",
      "AWS Lambda",
      "Amazon Elastic File System (Amazon EFS)",
      "Amazon S3"
    ],
    "SelectA": "새로운 AWS KMS 키를 생성합니다. AWS Secrets Manager를 사용해 해당 KMS 키로 암호화된 새 Secret을 만들고 적절한 자격 증명을 설정합니다. 이를 Aurora DB cluster와 연결하고, 14일 맞춤 회전 주기를 구성합니다.",
    "SelectA_Commentary": "AWS Secrets Manager를 이용하면 자격 증명 자동 회전과 암호화를 간단히 처리할 수 있어 운영 노력이 가장 적습니다.",
    "SelectB": "AWS Systems Manager Parameter Store에 사용자 이름(일반 문자열)과 비밀번호(SecureString)를 각각 생성하고, 비밀번호에는 AWS KMS 암호화를 적용한 뒤 애플리케이션에서 로드합니다. 매 14일마다 비밀번호를 갱신하도록 AWS Lambda 함수를 구현합니다.",
    "SelectB_Commentary": "수동으로 Lambda 함수를 구현해야 하므로 관리가 더 복잡하며, Secrets Manager의 간편한 자격 증명 관리 기능보다 운영 부담이 큽니다.",
    "SelectC": "AWS KMS로 암호화된 Amazon EFS 파일 시스템에 자격 증명을 담은 파일을 저장하고, 애플리케이션 계층 EC2 인스턴스에서 EFS를 마운트합니다. 매 14일마다 Lambda 함수를 통해 Aurora 자격 증명을 변경하고 새 정보를 파일에 업데이트합니다.",
    "SelectC_Commentary": "EFS 파일을 사용하는 방식은 설정과 관리가 복잡하고, Lambda 함수를 통해 직접 자격 증명을 자주 변경해야 하므로 운영 노력이 큽니다.",
    "SelectD": "자격 증명을 담은 파일을 AWS KMS로 암호화한 Amazon S3 버킷에 저장하고, 애플리케이션은 해당 버킷에서 파일을 주기적으로 다운로드해 사용합니다. 14일마다 Lambda 함수를 통해 Aurora 자격 증명을 회전하고 새 정보를 S3 파일에 업로드합니다.",
    "SelectD_Commentary": "S3 파일 다운로드와 업데이트 과정을 직접 구현해야 하므로 관리가 복잡하며, Secrets Manager를 사용하는 것에 비해 운영 부담이 큽니다.",
    "Question_Description_recommedations": [
      "Q336",
      "Q854",
      "Q176",
      "Q733",
      "Q492"
    ],
    "SelectA_recommedations": [
      "Q916",
      "Q681",
      "Q793"
    ],
    "SelectB_recommedations": [
      "Q640",
      "Q550",
      "Q916"
    ],
    "SelectC_recommedations": [
      "Q550",
      "Q371",
      "Q681"
    ],
    "SelectD_recommedations": [
      "Q550",
      "Q640",
      "Q1009"
    ]
  },
  {
    "Question_Number": "Q995",
    "Question_Description": "한 스트리밍 미디어 회사가 사용자들이 매일 소비하는 비디오 콘텐츠 수요 증가에 대응하기 위해 인프라를 재구축하고 있습니다. 이 회사는 비디오 내 특정 콘텐츠를 차단하기 위해 테라바이트(TB)급 비디오를 처리해야 합니다. 비디오 처리는 최대 20분까지 소요될 수 있습니다. 회사는 수요에 따라 확장 가능하고 비용 효율적인 솔루션을 원합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148465-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 TB급 비디오를 처리할 수 있는 확장성과 비용 효율을 동시에 달성하는 방안을 묻습니다. Lambda는 15분 한계로 20분이 걸리는 작업에 적합하지 않고, EC2 기반 방식은 관리 및 비용 부담이 큽니다. Amazon ECS와 AWS Fargate를 통해 마이크로서비스로 구성하면 처리 시간이 긴 작업도 유연하게 확장 가능하며, Amazon S3 Intelligent-Tiering을 통해 대용량 비디오를 비용 효율적으로 저장할 수 있습니다. Amazon Aurora는 비디오 메타데이터 처리를 위한 고성능 DB 역할을 합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1",
      "3.2"
    ],
    "Keywords": [
      "비디오 처리",
      "확장성",
      "비용 효율",
      "마이크로서비스",
      "테라바이트 규모",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon S3 Intelligent-Tiering",
      "Amazon Aurora"
    ],
    "Terms": [
      "AWS Lambda",
      "Amazon DynamoDB",
      "Amazon ECS",
      "AWS Fargate",
      "Amazon Aurora",
      "Amazon S3 Intelligent-Tiering",
      "Amazon EC2",
      "Auto Scaling group",
      "Application Load Balancer(ALB)",
      "Amazon S3 Standard",
      "Amazon SQS",
      "Amazon EKS",
      "Amazon RDS",
      "Amazon S3 Glacier Deep Archive"
    ],
    "SelectA": "비디오 처리를 위해 AWS Lambda 함수를 사용합니다. 비디오 메타데이터는 Amazon DynamoDB에, 비디오 콘텐츠는 Amazon S3 Intelligent-Tiering에 저장합니다.",
    "SelectA_Commentary": "AWS Lambda는 최대 15분까지 실행 가능하므로 20분 처리에는 적합하지 않습니다.",
    "SelectB": "Amazon ECS와 AWS Fargate로 마이크로서비스를 구현해 비디오를 처리합니다. 비디오 메타데이터는 Amazon Aurora에 저장하고, 비디오 콘텐츠는 Amazon S3 Intelligent-Tiering에 저장합니다.",
    "SelectB_Commentary": "ECS Fargate는 장시간 처리에 제약이 없고 자동 확장에 유리하며, S3 Intelligent-Tiering으로 대용량 비디오를 비용 효율적으로 저장할 수 있어 적합한 솔루션입니다.",
    "SelectC": "Application Load Balancer 뒤의 Auto Scaling 그룹 내 Amazon EC2 인스턴스로 비디오를 처리합니다. 비디오 콘텐츠는 Amazon S3 Standard에 저장하고, 큐잉 및 디커플링을 위해 Amazon SQS를 사용합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 직접 관리해야 하며, S3 Standard 장기 저장 시 비용이 더 클 수 있으므로 비용 효율 면에서 부족합니다.",
    "SelectD": "Amazon EC2에서 Amazon Elastic Kubernetes Service(Amazon EKS)를 사용해 컨테이너형 비디오 처리 애플리케이션을 배포합니다. 단일 AZ의 Amazon RDS에 메타데이터를 저장하고, 비디오 콘텐츠는 Amazon S3 Glacier Deep Archive에 저장합니다.",
    "SelectD_Commentary": "S3 Glacier Deep Archive는 검색에 상당한 지연이 있어 일상적인 비디오 처리에 부적합하며, 단일 AZ RDS 구성은 고가용성 면에서도 취약합니다.",
    "Question_Description_recommedations": [
      "Q622",
      "Q1005",
      "Q506",
      "Q915",
      "Q132"
    ],
    "SelectA_recommedations": [
      "Q33",
      "Q834",
      "Q603"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q695",
      "Q857"
    ],
    "SelectC_recommedations": [
      "Q358",
      "Q12",
      "Q141"
    ],
    "SelectD_recommedations": [
      "Q910",
      "Q386",
      "Q695"
    ]
  },
  {
    "Question_Number": "Q996",
    "Question_Description": "한 회사는 온프레미스 Kubernetes 클러스터에서 애플리케이션을 운영하고 있습니다. 최근 회사는 수백만 명의 신규 고객을 확보했으며, 기존 온프레미스 인프라는 많은 수의 신규 고객을 처리할 수 없는 상황입니다. 회사는 온프레미스 애플리케이션을 AWS Cloud로 마이그레이션해야 합니다. 회사는 이를 Amazon EKS 클러스터로 옮길 것이며, AWS에서 새로운 아키텍처의 기저 컴퓨팅 인프라를 직접 관리하고 싶지 않습니다. 최소한의 운영 오버헤드로 이러한 요구사항을 충족할 수 있는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148468-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 대규모 사용자 증가로 인해 온프레미스 인프라가 한계를 맞은 상황에서 운영 오버헤드를 최소화하며 AWS로 마이그레이션하는 방법을 묻습니다. AWS Fargate를 사용하면 Amazon EKS 환경에서 서버 관리가 필요 없으므로 가장 적은 운영 부담으로 빠르게 확장할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "온프레미스 애플리케이션",
      "Kubernetes 클러스터",
      "Amazon EKS",
      "AWS Cloud로 마이그레이션",
      "AWS Fargate",
      "운영 오버헤드 최소화",
      "Fargate profile"
    ],
    "Terms": [
      "Kubernetes",
      "Amazon EKS",
      "AWS Fargate",
      "Fargate profile",
      "Managed node groups",
      "self-managed node",
      "Karpenter"
    ],
    "SelectA": "self-managed 노드를 사용하여 컴퓨팅 용량을 제공합니다. 새로운 EKS 클러스터에 애플리케이션을 배포합니다.",
    "SelectA_Commentary": "self-managed 노드는 워커 노드 관리를 직접 수행해야 하므로 운영 오버헤드가 큽니다.",
    "SelectB": "Managed node groups를 사용하여 컴퓨팅 용량을 제공합니다. 새로운 EKS 클러스터에 애플리케이션을 배포합니다.",
    "SelectB_Commentary": "Managed node groups로 노드 관리가 어느 정도 자동화되지만, 여전히 Amazon EC2 인프라 관리는 남아 있습니다.",
    "SelectC": "AWS Fargate를 사용하여 컴퓨팅 용량을 제공합니다. Fargate profile을 생성하고 이를 사용해 애플리케이션을 배포합니다.",
    "SelectC_Commentary": "서버 관리를 전혀 하지 않아도 되므로 운영 오버헤드를 현저히 줄일 수 있어 정답입니다.",
    "SelectD": "Managed node groups와 Karpenter를 함께 사용하여 컴퓨팅 용량을 제공합니다. 새로운 EKS 클러스터에 애플리케이션을 배포합니다.",
    "SelectD_Commentary": "Karpenter로 노드 프로비저닝을 자동화해도 관리 요소가 남아 있어, Fargate보다 운영 오버헤드가 더 큽니다.",
    "Question_Description_recommedations": [
      "Q563",
      "Q198",
      "Q892",
      "Q790",
      "Q775"
    ],
    "SelectA_recommedations": [
      "Q615",
      "Q363",
      "Q917"
    ],
    "SelectB_recommedations": [
      "Q996",
      "Q563",
      "Q1001"
    ],
    "SelectC_recommedations": [
      "Q698",
      "Q10",
      "Q8"
    ],
    "SelectD_recommedations": [
      "Q563",
      "Q996",
      "Q660"
    ]
  },
  {
    "Question_Number": "Q997",
    "Question_Description": "한 회사가 사용자 프로필, 애플리케이션 설정, 트랜잭션 데이터를 저장하기 위한 구조화된 데이터베이스가 필요한 새로운 애플리케이션을 출시하려고 합니다. 이 데이터베이스는 애플리케이션 트래픽 변화에 따라 확장 가능해야 하며, 백업 기능을 제공해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148469-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 구조화된 데이터베이스를 저비용으로 운영하면서 트래픽에 맞춰 확장하고 백업도 수행해야 하는 상황입니다. Amazon Aurora Serverless는 서버리스 환경에서 자동으로 용량을 조정하여 사용량에 맞춰 비용을 지불하며, 백업도 자동으로 지원하므로 요구사항을 가장 비용 효율적으로 충족합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.3"
    ],
    "Keywords": [
      "구조화된 데이터베이스",
      "확장 가능",
      "백업",
      "비용 효율적",
      "Amazon Aurora Serverless"
    ],
    "Terms": [
      "Amazon EC2",
      "Spot Instances",
      "Amazon S3",
      "Amazon RDS",
      "On-demand capacity mode",
      "General Purpose SSD",
      "Amazon Aurora Serverless",
      "NoSQL",
      "Reserved Instances",
      "S3 Glacier Flexible Retrieval"
    ],
    "SelectA": "오픈 소스 소프트웨어로 Amazon EC2 인스턴스에 직접 데이터베이스를 설치하고, Spot Instances를 사용해 비용을 최적화합니다. 자동 백업을 Amazon S3로 구성합니다.",
    "SelectA_Commentary": "직접 DB를 관리하면 인스턴스 운영 부담이 크고, 스케일링도 직접 구성해야 하므로 운영 복잡도가 높습니다.",
    "SelectB": "Amazon RDS를 사용합니다. 데이터베이스에 On-demand capacity mode와 General Purpose SSD를 적용합니다. 7일 보존 기간으로 자동 백업을 구성합니다.",
    "SelectB_Commentary": "Amazon RDS는 간편하지만, 서버 프로비저닝 비용이 계속 발생하므로 사용량 변동에 따른 유연성이 Aurora Serverless만큼 뛰어나지 않습니다.",
    "SelectC": "Amazon Aurora Serverless를 사용합니다. 서버리스 용량 확장을 적용하고, 자동 백업을 Amazon S3에 구성합니다.",
    "SelectC_Commentary": "서버리스 방식으로 사용량에 따른 비용 지불과 자동 확장이 가능해 가장 비용 효율적이며, 백업까지 자동으로 지원하므로 요구사항을 만족합니다.",
    "SelectD": "Amazon EC2 인스턴스에 직접 NoSQL 데이터베이스를 설치합니다. 비용 최적화를 위해 Reserved Instances를 사용하고, 백업을 S3 Glacier Flexible Retrieval로 직접 구성합니다.",
    "SelectD_Commentary": "NoSQL은 구조화된 데이터베이스 요구와 맞지 않으며, 자체 운영 및 백업 유지 비용과 관리 복잡도가 큽니다.",
    "Question_Description_recommedations": [
      "Q656",
      "Q794",
      "Q630",
      "Q49",
      "Q930"
    ],
    "SelectA_recommedations": [
      "Q552",
      "Q993",
      "Q1013"
    ],
    "SelectB_recommedations": [
      "Q940",
      "Q579",
      "Q152"
    ],
    "SelectC_recommedations": [
      "Q128",
      "Q300",
      "Q285"
    ],
    "SelectD_recommedations": [
      "Q1008",
      "Q552",
      "Q505"
    ]
  },
  {
    "Question_Number": "Q998",
    "Question_Description": "한 회사가 AWS에서 레거시 웹 애플리케이션을 운영하고 있습니다. 이 웹 애플리케이션 서버는 VPC의 퍼블릭 서브넷에 위치한 Amazon EC2 인스턴스에서 구동되며, 고객의 이미지를 수집하여 로컬에 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. 이 이미지 파일들은 매일 밤 백업을 위해 Amazon S3 버킷으로 업로드됩니다. 그런데 솔루션스 아키텍트가 확인한 결과, 이미지 파일들이 퍼블릭 엔드포인트를 통해 Amazon S3로 업로드되고 있었습니다. 솔루션스 아키텍트는 Amazon S3로 향하는 트래픽이 퍼블릭 엔드포인트를 사용하지 않도록 해야 합니다. 이러한 요구 사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148806-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스에서 생성된 데이터를 Amazon S3로 안전하게 업로드하기 위한 방법을 묻습니다. 퍼블릭 엔드포인트를 거치지 않으려면 VPC Endpoint를 사용해 VPC 내부에서 직접 S3에 연결해야 합니다. Gateway VPC Endpoint는 S3·DynamoDB 등 특정 서비스에 대해 프라이빗 경로를 제공하며, 서브넷 라우팅을 설정해 트래픽이 인터넷을 거치지 않고 S3에 연결될 수 있도록 합니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "S3 업로드",
      "퍼블릭 엔드포인트 차단",
      "VPC Endpoint",
      "프라이빗 연결"
    ],
    "Terms": [
      "Amazon EC2",
      "Amazon EBS",
      "Amazon S3",
      "퍼블릭 서브넷",
      "VPC",
      "Gateway VPC Endpoint",
      "S3 Access Point",
      "AWS Direct Connect",
      "서브넷 라우트 테이블",
      "인터넷 게이트웨이",
      "NAT 게이트웨이"
    ],
    "SelectA": "해당 VPC에 필요한 권한을 가진 S3용 Gateway VPC Endpoint를 생성하고, 서브넷 라우트 테이블을 Gateway VPC Endpoint를 통해 트래픽이 전달되도록 구성합니다.",
    "SelectA_Commentary": "S3에 대한 프라이빗 경로를 제공하는 Gateway VPC Endpoint를 사용하면 퍼블릭 엔드포인트 경유 없이 안전하게 데이터를 전송할 수 있습니다.",
    "SelectB": "S3 버킷을 VPC 내부로 옮기고, 서브넷 라우트 테이블을 통하여 S3 버킷을 프라이빗 IP 주소를 통해 접근하도록 구성합니다.",
    "SelectB_Commentary": "S3를 ‘VPC 내부’로 직접 옮기는 방식은 존재하지 않으며, S3는 AWS 서비스이므로 VPC에 물리적으로 배치할 수 없습니다.",
    "SelectC": "VPC 내부의 Amazon EC2 인스턴스에 대해 Amazon S3 Access Point를 생성하고, 웹 애플리케이션이 해당 S3 Access Point를 사용하도록 업로드를 설정합니다.",
    "SelectC_Commentary": "Access Point는 정책 관리에 유용하지만, 퍼블릭 엔드포인트를 피하기 위해선 여전히 VPC Endpoint를 설정해야 하므로 요구 사항을 완전히 충족시키지 못합니다.",
    "SelectD": "Amazon EC2 인스턴스가 있는 VPC와 Amazon S3 사이에 AWS Direct Connect를 구성하여 전용 네트워크 경로를 제공합니다.",
    "SelectD_Commentary": "Direct Connect는 온프레미스와 AWS 간 전용 연결을 제공하는 솔루션으로, VPC 내부에서 S3로 직접 연결하려는 이 요구 사항에 비해 과도하며 비용이 큽니다.",
    "Question_Description_recommedations": [
      "Q980",
      "Q92",
      "Q675",
      "Q4",
      "Q866"
    ],
    "SelectA_recommedations": [
      "Q92",
      "Q866",
      "Q91"
    ],
    "SelectB_recommedations": [
      "Q92",
      "Q866",
      "Q91"
    ],
    "SelectC_recommedations": [
      "Q4",
      "Q91",
      "Q92"
    ],
    "SelectD_recommedations": [
      "Q866",
      "Q451",
      "Q92"
    ]
  },
  {
    "Question_Number": "Q999",
    "Question_Description": "한 회사가 AWS에서 전자상거래 웹사이트 프로토타입을 만들고 있습니다. 이 웹사이트는 Application Load Balancer, 웹 서버용 Amazon EC2 인스턴스로 구성된 Auto Scaling group, 그리고 Single-AZ 구성으로 동작하는 Amazon RDS for MySQL DB instance로 구성됩니다. 웹사이트는 제품 카탈로그를 검색할 때 응답이 느립니다. 제품 카탈로그는 회사가 자주 업데이트하지 않는 MySQL 데이터베이스의 테이블 그룹입니다. 솔루션스 아키텍트는 제품 카탈로그 검색 시 DB instance의 CPU 사용률이 높다는 사실을 확인했습니다. 제품 카탈로그 검색 시 웹사이트 성능을 향상하기 위해 솔루션스 아키텍트는 무엇을 권장해야 합니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148470-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 제품 카탈로그를 검색할 때 DB CPU 부하가 올라가느라 성능이 저하되는 상황입니다. Amazon ElastiCache for Redis를 사용해 자주 변하지 않는 데이터를 캐싱하면, DB에 대한 읽기 부하를 줄이고 검색 속도를 크게 개선할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.3"
    ],
    "Keywords": [
      "제품 카탈로그",
      "검색 성능",
      "Amazon ElastiCache",
      "Redis",
      "CPU 사용률"
    ],
    "Terms": [
      "Application Load Balancer",
      "Auto Scaling group",
      "Amazon EC2",
      "Amazon RDS for MySQL",
      "Single-AZ configuration",
      "Amazon Redshift",
      "COPY command",
      "Amazon ElastiCache for Redis",
      "lazy loading",
      "Multi-AZ configuration"
    ],
    "SelectA": "제품 카탈로그를 Amazon Redshift 데이터베이스로 마이그레이션합니다. COPY 명령을 사용하여 제품 카탈로그 테이블을 로드합니다.",
    "SelectA_Commentary": "Redshift는 대규모 데이터 분석에 적합하지만, 단순 캐싱 요구에는 과도하며 마이그레이션 비용이 큽니다.",
    "SelectB": "Amazon ElastiCache for Redis 클러스터를 구현하여 제품 카탈로그를 캐싱합니다. lazy loading을 사용하여 캐시를 미리 채웁니다.",
    "SelectB_Commentary": "DB 부하를 크게 줄이고 검색 속도를 높이는 최적의 방안으로, 자주 변경되지 않는 데이터에 대한 캐싱이 효과적입니다.",
    "SelectC": "데이터베이스 응답이 느릴 때 추가적인 EC2 인스턴스를 시작하도록 Auto Scaling group에 추가적인 스케일링 정책을 추가합니다.",
    "SelectC_Commentary": "EC2 인스턴스를 늘려도 DB의 CPU 병목은 해결되지 않아 검색 성능 개선에 직접적 효과가 없습니다.",
    "SelectD": "DB instance의 Multi-AZ 구성을 활성화합니다. 데이터베이스로 전송되는 제품 카탈로그 쿼리를 제한하도록 EC2 인스턴스를 구성합니다.",
    "SelectD_Commentary": "Multi-AZ는 가용성을 높이지만, 성능 부하 자체를 해결하지 못하며 쿼리 제한은 사용자 경험을 저하시킵니다.",
    "Question_Description_recommedations": [
      "Q386",
      "Q394",
      "Q481",
      "Q910",
      "Q95"
    ],
    "SelectA_recommedations": [
      "Q557",
      "Q515",
      "Q361"
    ],
    "SelectB_recommedations": [
      "Q515",
      "Q746",
      "Q1015"
    ],
    "SelectC_recommedations": [
      "Q335",
      "Q461",
      "Q746"
    ],
    "SelectD_recommedations": [
      "Q633",
      "Q481",
      "Q834"
    ]
  },
  {
    "Question_Number": "Q1000",
    "Question_Description": "한 회사는 현재 온프레미스 블록 스토리지 시스템에 5TB의 데이터를 저장하고 있습니다. 기존 스토리지 솔루션은 추가 데이터를 저장할 공간이 제한적입니다. 회사는 온프레미스에서 애플리케이션을 운영하며, 자주 액세스되는 데이터에 대해 낮은 지연 시간으로 데이터를 조회할 수 있어야 합니다. 이 회사는 클라우드 기반 스토리지 솔루션을 요구하고 있습니다. 이 요구사항을 가장 높은 운영 효율성으로 충족할 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148471-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스 블록 스토리지를 AWS와 연동하여, 자주 액세스되는 데이터에 대해 낮은 지연 시간을 유지하면서 부족한 스토리지를 확장하는 방법을 찾는 것입니다. Volume Gateway(cached volumes)를 사용하면 빈번히 참조되는 데이터를 로컬에 캐싱하여 빠른 조회를 제공하고, 전체 데이터는 Amazon S3에 저장되어 확장성과 운영 효율성을 모두 확보할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.1"
    ],
    "Keywords": [
      "클라우드 기반 스토리지",
      "낮은 지연 시간",
      "자주 액세스되는 데이터",
      "운영 효율성"
    ],
    "Terms": [
      "Amazon S3 File Gateway",
      "AWS Storage Gateway Volume Gateway",
      "iSCSI targets",
      "AWS Storage Gateway Tape Gateway",
      "SMB file system",
      "cached volumes",
      "stored volumes",
      "virtual tapes"
    ],
    "SelectA": "Amazon S3 File Gateway를 사용합니다. SMB 파일 시스템을 통해 Amazon S3 File Gateway를 온프레미스 애플리케이션에 통합하여 파일을 저장하고 직접 조회합니다.",
    "SelectA_Commentary": "File Gateway는 파일 인터페이스를 제공하는 솔루션이므로, 블록 단위 접근(iSCSI)이 필요한 시나리오에는 적합하지 않습니다.",
    "SelectB": "AWS Storage Gateway Volume Gateway를 cached volumes 모드로 구성하고, 이를 iSCSI 타깃으로 설정합니다.",
    "SelectB_Commentary": "cached volumes는 자주 액세스되는 데이터를 로컬 캐시로 빠르게 제공하면서 전체 데이터는 Amazon S3에 저장하므로 요구 사항에 가장 적합합니다.",
    "SelectC": "AWS Storage Gateway Volume Gateway를 stored volumes 모드로 구성하고, 이를 iSCSI 타깃으로 설정합니다.",
    "SelectC_Commentary": "stored volumes는 전체 데이터를 로컬에 보유하여 클라우드 백업만 수행하므로, 온프레미스 공간 한계를 해결하기 어려우며 운영 효율면에서도 불리합니다.",
    "SelectD": "AWS Storage Gateway Tape Gateway를 사용합니다. Tape Gateway를 온프레미스 애플리케이션과 통합하여 Amazon S3에 가상 테이프를 저장합니다.",
    "SelectD_Commentary": "Tape Gateway는 주로 백업이나 아카이빙 용도에 적합하며, 빈번한 데이터 접근 요구사항 및 저지연 접근에는 부적합합니다.",
    "Question_Description_recommedations": [
      "Q830",
      "Q1",
      "Q113",
      "Q626",
      "Q506"
    ],
    "SelectA_recommedations": [
      "Q895",
      "Q844",
      "Q249"
    ],
    "SelectB_recommedations": [
      "Q605",
      "Q305",
      "Q127"
    ],
    "SelectC_recommedations": [
      "Q605",
      "Q305",
      "Q957"
    ],
    "SelectD_recommedations": [
      "Q155",
      "Q38",
      "Q173"
    ]
  },
  {
    "Question_Number": "Q1001",
    "Question_Description": "한 회사가 음식 배달 서비스를 운영하고 있습니다. 최근 성장으로 인해 주문 처리 시스템이 피크 트래픽 시간대에 확장성 문제를 겪고 있습니다. 현재 아키텍처는 애플리케이션에서 주문을 수집하는 Amazon EC2 인스턴스(Auto Scaling group)와, 주문을 처리하는 또 다른 Amazon EC2 인스턴스(Auto Scaling group)로 구성되어 있습니다. 주문 수집 프로세스는 비교적 빠르게 이루어지지만, 주문 처리 프로세스는 시간이 더 오래 걸릴 수 있습니다. 확장 이벤트로 인해 데이터가 손실되어서는 안 됩니다. 솔루션스 아키텍트는 피크 트래픽 시간대에도 주문 수집과 주문 처리 프로세스가 모두 적절하게 확장되도록 해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148807-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제에서는 주문 수집과 주문 처리 단계를 분리하고, 데이터가 유실되지 않도록 안정적인 확장을 구현하는 방법을 묻고 있습니다. Amazon SQS를 사용해 두 프로세스를 느슨하게 결합하면 확장 이벤트에서 메시지가 안전하게 보관되므로 데이터 손실을 방지할 수 있습니다. 특히 SQS 큐의 메시지 수를 지표로 하여 Auto Scaling을 설정하면 피크 트래픽이 발생해도 적절히 확장하여 처리 지연이나 데이터 유실 없이 안정적인 운영이 가능합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1",
      "2.2"
    ],
    "Keywords": [
      "주문 처리 시스템",
      "피크 트래픽",
      "확장성 문제",
      "데이터 손실 방지",
      "Amazon SQS",
      "Auto Scaling"
    ],
    "Terms": [
      "Amazon EC2",
      "Auto Scaling group",
      "Amazon CloudWatch",
      "CPUUtilization",
      "Amazon SNS",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Scaling event"
    ],
    "SelectA": "Amazon CloudWatch로 두 Auto Scaling group 각각의 인스턴스 CPUUtilization을 모니터링하고, 피크 워크로드 값에 맞춰 각 그룹의 최소 용량을 설정합니다.",
    "SelectA_Commentary": "피크 용량에 맞춰 고정으로 유지해 비용이 높아질 수 있고, CPU만으로는 주문 처리 지연을 정확히 측정하기 어렵습니다.",
    "SelectB": "Amazon CloudWatch로 각 인스턴스 CPUUtilization을 모니터링합니다. CloudWatch 알람이 Amazon SNS 토픽을 호출하여 필요 시 추가 Auto Scaling group을 생성하도록 구성합니다.",
    "SelectB_Commentary": "새로운 Auto Scaling group을 동적으로 생성하는 방식은 일반적이지 않으며, 큐 기반 확장을 고려하지 않아 주문 처리 지연이 발생할 수 있습니다.",
    "SelectC": "Amazon SQS 큐를 두 개 프로비저닝하여 하나는 주문 수집용, 다른 하나는 주문 처리용으로 사용합니다. 각 EC2 인스턴스에서 해당 큐를 폴링하도록 구성합니다. 큐에서 전송하는 알림을 바탕으로 Auto Scaling group을 확장합니다.",
    "SelectC_Commentary": "SQS를 통한 비동기 처리 방향은 적절하나, 일반적으로 큐 알림만으로 확장 제어를 하기는 복잡하며 표준적인 방식이 아닙니다.",
    "SelectD": "Amazon SQS 큐를 두 개 프로비저닝하여 하나는 주문 수집용, 다른 하나는 주문 처리용으로 사용합니다. 각 EC2 인스턴스에서 해당 큐를 폴링하도록 구성합니다. 각 큐의 메시지 수에 따라 Auto Scaling group을 확장합니다.",
    "SelectD_Commentary": "SQS 큐의 메시지 수를 기반으로 확장하면 피크 트래픽에서 메시지가 적체되지 않고, 데이터 유실이나 과도한 지연 없이 안정적으로 처리 가능합니다.",
    "Question_Description_recommedations": [
      "Q210",
      "Q595",
      "Q271",
      "Q194",
      "Q660"
    ],
    "SelectA_recommedations": [
      "Q342",
      "Q595",
      "Q660"
    ],
    "SelectB_recommedations": [
      "Q660",
      "Q595",
      "Q342"
    ],
    "SelectC_recommedations": [
      "Q595",
      "Q581",
      "Q1001"
    ],
    "SelectD_recommedations": [
      "Q595",
      "Q581",
      "Q271"
    ]
  },
  {
    "Question_Number": "Q1002",
    "Question_Description": "한 온라인 게임 회사가 증가하는 사용자 수요를 지원하기 위해 사용자 데이터를 Amazon DynamoDB로 이전하려고 합니다. 현재 아키텍처는 사용자 프로필, 업적, 게임 내 거래를 저장하는 DynamoDB 테이블을 포함합니다. 회사는 사용자의 끊김 없는 게임 경험을 유지하기 위해 지속적으로 가용하고 복원력이 뛰어난 DynamoDB 아키텍처를 설계해야 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148808-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 DynamoDB를 여러 리전에 걸쳐 고가용성과 연속성을 유지하면서 비용을 절감할 수 있는 방안을 묻습니다. 글로벌 테이블은 자동으로 데이터를 다중 리전에 복제하므로 장애 발생 시에도 서비스가 중단 없이 제공됩니다. 트래픽 예측이 가능한 경우 Provisioned Capacity Mode와 Auto Scaling을 결합해 불필요한 과금 없이 탄력적으로 확장할 수 있어 가장 비용 효율적입니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "DynamoDB",
      "글로벌 테이블",
      "다중 리전 복제",
      "고가용성",
      "비용 효율성"
    ],
    "Terms": [
      "DynamoDB",
      "DynamoDB Accelerator (DAX)",
      "Global Tables",
      "On-demand Capacity Mode",
      "Provisioned Capacity Mode",
      "DynamoDB Streams",
      "Auto Scaling"
    ],
    "SelectA": "한 개의 AWS Region에 DynamoDB 테이블을 생성하고 On-demand Capacity Mode를 사용합니다. Global Tables로 데이터를 여러 Region에 복제합니다.",
    "SelectA_Commentary": "한 리전에 테이블을 두고 Global Tables만 적용하면 Region 장애 시 가용성이 낮으며, 트래픽이 지속적이면 On-demand 모드는 비용이 증가할 수 있습니다.",
    "SelectB": "DynamoDB Accelerator(DAX)를 사용해 자주 조회되는 데이터를 캐시하고, 테이블은 한 개의 AWS Region에 배포 후 Auto Scaling을 활성화합니다. 추가 Region에는 수동으로 Cross-Region Replication을 구성합니다.",
    "SelectB_Commentary": "DAX는 읽기 지연을 줄이는 데 유용하지만, 다중 리전 장애 대비나 자동 복제 설정이 미흡해 장애 시 가용성이 떨어지고 운영 복잡성이 커집니다.",
    "SelectC": "여러 AWS Region에 DynamoDB 테이블을 생성하고, On-demand Capacity Mode를 사용합니다. DynamoDB Streams를 통해 리전 간 Cross-Region Replication을 설정합니다.",
    "SelectC_Commentary": "Streams를 활용한 수동 복제는 설정이 복잡하고 대규모 트래픽 시 On-demand 모드로 비용이 높아질 수 있으며, 글로벌 테이블만큼 자동화되지 않습니다.",
    "SelectD": "DynamoDB Global Tables를 사용하여 자동 다중 리전 복제를 활성화합니다. 여러 AWS Region에 테이블을 배포하고, Provisioned Capacity Mode를 사용하며 Auto Scaling을 활성화합니다.",
    "SelectD_Commentary": "Global Tables가 자동으로 데이터 동기화를 제공해 고가용성과 장애 복원이 뛰어나며, 예측 가능한 트래픽에는 Provisioned 모드가 비용 효율적이고 Auto Scaling으로 스케일 조정이 수월합니다.",
    "Question_Description_recommedations": [
      "Q400",
      "Q845",
      "Q114",
      "Q78",
      "Q768"
    ],
    "SelectA_recommedations": [
      "Q178",
      "Q241",
      "Q343"
    ],
    "SelectB_recommedations": [
      "Q874",
      "Q343",
      "Q585"
    ],
    "SelectC_recommedations": [
      "Q874",
      "Q585",
      "Q241"
    ],
    "SelectD_recommedations": [
      "Q874",
      "Q241",
      "Q1002"
    ]
  },
  {
    "Question_Number": "Q1003",
    "Question_Description": "회사는 사내에서 미디어 렌더링 애플리케이션을 실행하고 있습니다. 스토리지 비용을 절감하기 위해 모든 데이터를 Amazon S3로 이전했지만, 사내 렌더링 애플리케이션은 스토리지에 대해 저지연 접근이 필요합니다. 회사는 애플리케이션 성능을 유지하면서도 비용 효율적인 스토리지 솔루션을 설계해야 합니다. 어떤 스토리지 솔루션이 이 요구사항을 가장 효과적으로 충족할 수 있습니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148809-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 사내 환경에서 저지연을 유지하면서 Amazon S3를 활용해 비용을 절감하는 방법을 묻습니다. Amazon S3 File Gateway는 로컬 캐싱을 제공하므로 사내 액세스 지연을 줄이고, S3를 기반으로 하여 비용 효율적인 스토리지 구성을 가능하게 합니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.1"
    ],
    "Keywords": [
      "미디어 렌더링 애플리케이션",
      "스토리지 비용 절감",
      "저지연 접근",
      "Amazon S3로 이전",
      "비용 효율성"
    ],
    "Terms": [
      "Amazon S3",
      "Mountpoint for Amazon S3",
      "Amazon S3 File Gateway",
      "Amazon FSx for Windows File Server",
      "Amazon FSx File Gateway",
      "On-premises file server",
      "S3 API"
    ],
    "SelectA": "사내 애플리케이션이 Amazon S3에 접속하기 위해 Mountpoint for Amazon S3를 사용합니다.",
    "SelectA_Commentary": "Mountpoint for Amazon S3는 클라우드 환경에서 사용하기 적합하여 사내 환경에서 저지연 요구사항을 충족하기 어렵습니다. 로컬 캐싱 기능도 부재합니다.",
    "SelectB": "Amazon S3 File Gateway를 구성하여 사내 애플리케이션에 스토리지를 제공합니다.",
    "SelectB_Commentary": "Amazon S3 File Gateway는 자주 액세스되는 데이터를 로컬에 캐싱해 저지연 접근을 보장하고, 실제 데이터는 S3에 저장되어 비용 효율적입니다.",
    "SelectC": "Amazon FSx for Windows File Server로 데이터를 복사한 뒤, Amazon FSx File Gateway를 구성해 사내 애플리케이션에 스토리지를 제공합니다.",
    "SelectC_Commentary": "FSx 스토리지는 비용이 S3보다 높고, 게이트웨이 구성이 중복되어 복잡도가 증가합니다. 불필요한 비용과 관리가 추가됩니다.",
    "SelectD": "사내 파일 서버를 구성하고 Amazon S3 API를 통해 S3 스토리지에 연결합니다. 애플리케이션은 사내 파일 서버를 통해 스토리지에 액세스합니다.",
    "SelectD_Commentary": "사내 파일 서버에 단순히 S3 API로 연결하면 로컬 캐싱이 없어 지연이 발생하고, 관리 부담이 증가해 요구사항에 부합하기 어렵습니다.",
    "Question_Description_recommedations": [
      "Q769",
      "Q911",
      "Q606",
      "Q469",
      "Q285"
    ],
    "SelectA_recommedations": [
      "Q285",
      "Q993",
      "Q911"
    ],
    "SelectB_recommedations": [
      "Q285",
      "Q769",
      "Q23"
    ],
    "SelectC_recommedations": [
      "Q719",
      "Q926",
      "Q703"
    ],
    "SelectD_recommedations": [
      "Q469",
      "Q829",
      "Q769"
    ]
  },
  {
    "Question_Number": "Q1004",
    "Question_Description": "한 회사가 us-east-1 리전에 ERP(enterprise resource planning) 시스템을 Amazon EC2 인스턴스에서 호스팅하고 있습니다. 고객들은 공용 API를 통해 ERP 시스템과 정보를 교환하고 있는데, 국제 고객들은 자신들의 데이터 센터에서 API 응답 시간이 느리다고 보고합니다. 국제 고객들의 응답 시간을 가장 비용 효율적으로 개선하려면 어떤 솔루션을 사용해야 합니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148810-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 국제적으로 분산된 고객들이 API에 액세스할 때 지연(latency)을 줄이고 비용을 최소화하려는 시나리오입니다. AWS Global Accelerator를 사용하면 전 세계 AWS 글로벌 네트워크를 활용해 트래픽 경로를 최적화하여 지연을 크게 줄일 수 있고, 동적 콘텐츠 환경에도 쉽게 적용 가능합니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "국제 고객",
      "응답 시간",
      "비용 효율적",
      "Amazon EC2",
      "ERP 시스템",
      "us-east-1",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "AWS Direct Connect",
      "public virtual interface (VIF)",
      "Direct Connect gateway",
      "Amazon CloudFront",
      "CachingOptimized managed cache policy",
      "AWS Global Accelerator",
      "Site-to-Site VPN",
      "Amazon EC2"
    ],
    "SelectA": "각 고객 데이터 센터에서 us-east-1까지 연결하기 위해 공용 VIF가 있는 AWS Direct Connect 연결을 생성합니다. Direct Connect gateway를 사용해 고객의 API 요청을 ERP 시스템 API로 라우팅합니다.",
    "SelectA_Commentary": "Direct Connect는 전용 선로로 안정적이지만, 위치마다 연결을 구축해야 해 비용이 많이 들고 다양한 지역 환경에서 확장성이 떨어질 수 있습니다.",
    "SelectB": "API 앞단에 Amazon CloudFront 배포를 설정합니다. 캐시 효율을 높이기 위해 CachingOptimized 관리형 캐시 정책을 구성합니다.",
    "SelectB_Commentary": "CloudFront는 캐싱에 효과적이나, 동적으로 변경되는 API 트래픽에선 큰 이점을 얻기 어려울 수 있어 국제 고객의 응답 시간 개선에 한계가 있습니다.",
    "SelectC": "AWS Global Accelerator를 설정합니다. 필요한 포트에 대한 리스너를 구성하고, 트래픽을 분산할 적절한 리전에 대해 엔드포인트 그룹을 구성합니다. 해당 그룹에 API 엔드포인트를 생성합니다.",
    "SelectC_Commentary": "AWS 글로벌 네트워크를 통해 최적의 경로로 트래픽을 전달해 지연을 줄이고, 동적 콘텐츠에도 효과적이며 구축 비용 대비 성능 향상이 큽니다.",
    "SelectD": "AWS Site-to-Site VPN을 이용해 각 리전과 고객 네트워크 간에 전용 VPN 터널을 구성합니다. 이 VPN 연결을 통해 API로 트래픽을 라우팅합니다.",
    "SelectD_Commentary": "VPN 터널 구성은 리소스와 운영 비용이 추가로 들고, 국제적으로 다수의 고객을 지원하기에는 유지보수가 복잡해질 수 있습니다.",
    "Question_Description_recommedations": [
      "Q41",
      "Q910",
      "Q226",
      "Q320",
      "Q596"
    ],
    "SelectA_recommedations": [
      "Q734",
      "Q1004",
      "Q686"
    ],
    "SelectB_recommedations": [
      "Q280",
      "Q2",
      "Q704"
    ],
    "SelectC_recommedations": [
      "Q77",
      "Q361",
      "Q631"
    ],
    "SelectD_recommedations": [
      "Q659",
      "Q64",
      "Q771"
    ]
  },
  {
    "Question_Number": "Q1005",
    "Question_Description": "한 회사는 웹사이트에서 호스팅되는 설문조사를 통해 고객 만족도를 추적하고 있습니다. 매시간 수천 명의 고객이 설문에 참여할 수 있으며, 현재 설문 결과는 이메일로 회사에 전송되어 직원들이 수동으로 결과를 검토하고 고객 감정을 파악하고 있습니다. 회사는 이 설문조사 프로세스를 자동화하기 원하며, 설문 결과는 과거 12개월치가 조회 가능해야 합니다. 가장 확장성 있는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148811-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "설문 데이터가 단기간에 대량으로 유입되는 상황에서, Amazon SQS와 AWS Lambda를 결합해 확장성 높은 비동기 데이터 처리를 수행하고, Amazon Comprehend로 텍스트 감정 분석 후 DynamoDB에 TTL을 적용하여 데이터를 12개월 보관할 수 있는 방법이 가장 효율적입니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.2",
      "3.5"
    ],
    "Keywords": [
      "설문조사 자동화",
      "고객 만족도",
      "확장성",
      "감정 분석",
      "12개월 보관"
    ],
    "Terms": [
      "Amazon API Gateway",
      "Amazon Simple Queue Service (Amazon SQS)",
      "AWS Lambda",
      "Amazon Comprehend",
      "Amazon DynamoDB",
      "TTL",
      "Amazon EC2",
      "Amazon S3",
      "Amazon Rekognition",
      "Amazon Lex",
      "S3 lifecycle policies"
    ],
    "SelectA": "Amazon API Gateway 엔드포인트를 Amazon SQS 큐에 연결하여 설문 결과 데이터를 전송합니다. AWS Lambda 함수를 사용해 SQS 큐를 폴링하고 Amazon Comprehend로 감정 분석을 수행한 뒤, 결과를 Amazon DynamoDB 테이블에 저장합니다. 모든 레코드의 TTL은 365일로 설정합니다.",
    "SelectA_Commentary": "Amazon SQS와 Lambda 구조는 고도로 확장 가능하며, Comprehend는 텍스트 감정 분석을 위한 서비스입니다. DynamoDB에 TTL을 설정해 12개월 보관 요구사항도 충족하므로 가장 적합한 솔루션입니다.",
    "SelectB": "Amazon EC2 인스턴스에서 동작하는 API로 설문 결과 데이터를 전송합니다. 이 API는 결과를 Amazon DynamoDB 테이블에 저장하고, Amazon Comprehend로 감정 분석을 수행한 다음 또 다른 DynamoDB 테이블에 결과를 저장합니다. 모든 레코드의 TTL은 365일로 설정합니다.",
    "SelectB_Commentary": "EC2 기반 API는 추가 관리 부담과 확장성 문제가 발생할 수 있습니다. Lambda를 사용하는 비동기 방식보다 운영 복잡성이 높습니다.",
    "SelectC": "설문 결과 데이터를 Amazon S3 버킷에 기록하고, S3 Event Notifications로 AWS Lambda를 호출하여 데이터를 읽은 뒤 Amazon Rekognition으로 감정 분석을 수행합니다. 분석 결과를 별도 S3 버킷에 저장하고, 각 버킷에 S3 lifecycle policies를 적용해 365일 후 객체를 만료시킵니다.",
    "SelectC_Commentary": "Amazon Rekognition은 이미지·영상 분석 서비스로 텍스트 감정 분석에는 적합하지 않습니다. Comprehend를 사용해야 정확한 감정 분석이 가능합니다.",
    "SelectD": "Amazon API Gateway 엔드포인트를 Amazon SQS 큐에 연결하고, 해당 SQS 큐가 AWS Lambda 함수를 호출하여 Amazon Lex로 감정 분석을 수행한 뒤 결과를 Amazon DynamoDB 테이블에 저장합니다. 모든 레코드의 TTL은 365일로 설정합니다.",
    "SelectD_Commentary": "Amazon Lex는 챗봇 솔루션으로 감정 분석 기능에는 적합하지 않습니다. 설문 텍스트의 감정 분석은 Amazon Comprehend를 사용해야 합니다.",
    "Question_Description_recommedations": [
      "Q506",
      "Q915",
      "Q132",
      "Q888",
      "Q158"
    ],
    "SelectA_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ],
    "SelectB_recommedations": [
      "Q320",
      "Q910",
      "Q226"
    ],
    "SelectC_recommedations": [
      "Q603",
      "Q402",
      "Q680"
    ],
    "SelectD_recommedations": [
      "Q597",
      "Q576",
      "Q379"
    ]
  },
  {
    "Question_Number": "Q1006",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에 대한 정기적인 관리 및 패치를 위해 AWS Systems Manager를 사용하고 있습니다. 이 EC2 인스턴스들은 Application Load Balancer(ALB) 뒤의 IP address type 타깃 그룹에 속해 있습니다. 새 보안 규정에 따라, 패치 시에는 인스턴스를 서비스에서 제거해야 합니다. 그러나 보안 규정 준수를 위해 패치 작업을 진행하려 하자, 패치 윈도우 동안 오류가 발생했습니다. 이러한 오류를 해결하기 위해 어떤 두 가지 해결 방안을 조합해서 사용해야 합니까?",
    "Answer": "C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148812-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 ALB 뒤에서 트래픽을 처리 중인 EC2 인스턴스를 패치할 때, 서비스 중단 없이 안전하게 인스턴스를 제거하고 복원하는 방법을 묻습니다. 선택 항목에서 IP address type 타깃 그룹에 맞는 문서를 활용하여 패치 시 자동으로 인스턴스를 서비스에서 제거(알맞게 등록 해제)하고, 패치 후 다시 정상 등록해 주는 방안이 요구됩니다. 또한 Maintenance Windows 기능을 사용해 패치를 주기적으로 자동화할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.2"
    ],
    "Keywords": [
      "AWS Systems Manager",
      "EC2 인스턴스",
      "IP address type 타깃 그룹",
      "Application Load Balancer",
      "패치",
      "오류 해결"
    ],
    "Terms": [
      "AWS Systems Manager",
      "Amazon EC2",
      "Application Load Balancer(ALB)",
      "IP address type target group",
      "AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation document",
      "Systems Manager Maintenance Windows",
      "Systems Manager State Manager"
    ],
    "SelectA": "타깃 그룹 타입을 IP address type에서 instance type으로 변경합니다.",
    "SelectA_Commentary": "기존 IP address type 환경을 굳이 instance type으로 바꿀 필요는 없습니다. 문제의 핵심은 ALB와 연동된 인스턴스를 패치 기간 동안 안전하게 제거하는 과정이므로, 타입 변경 자체는 오류를 해결하지 못합니다.",
    "SelectB": "기존 Systems Manager 문서를 변경 없이 사용합니다. 이미 ALB 뒤의 IP address type 타깃 그룹 인스턴스에 최적화되어 있습니다.",
    "SelectB_Commentary": "기존 문서만으로는 IP address type 타깃 그룹을 대상으로 한 패치 시 오류를 방지하기 어렵습니다. 문제에서 이미 오류가 발생했으므로 다른 해결책이 필요합니다.",
    "SelectC": "AWSEC2-PatchLoadBalanacerInstance Systems Manager Automation 문서를 사용하여 패치 프로세스를 관리합니다.",
    "SelectC_Commentary": "이 문서는 패치 중 ALB에서 인스턴스를 제거하고, 패치 완료 후 재등록하여 운용 중단을 최소화합니다. ALB 뒤 인스턴스 패치 작업을 자동화해 오류를 방지할 수 있는 올바른 솔루션입니다.",
    "SelectD": "Systems Manager Maintenance Windows를 사용해 인스턴스를 서비스에서 자동으로 제거하고 패치 작업을 진행합니다.",
    "SelectD_Commentary": "Maintenance Windows는 특정 시간에 작업을 스케줄링하고, 패치 시 인스턴스를 제거해 트래픽이 전달되지 않도록 하므로 안정적인 패치를 지원하며 ALB에 재등록 시점을 제어합니다.",
    "SelectE": "Systems Manager State Manager를 구성하여 인스턴스를 서비스에서 제거하고 패치 스케줄을 관리합니다. ALB 헬스 체크로 트래픽을 재라우팅합니다.",
    "SelectE_Commentary": "State Manager만으로는 패치 시 인스턴스의 등록 해제 및 재등록 과정을 완전히 자동화하기에 제한적입니다. 문제에서 요구하는 패치 윈도우 중 발생하는 오류를 근본적으로 해소하기는 어렵습니다.",
    "Question_Description_recommedations": [
      "Q405",
      "Q5",
      "Q357",
      "Q639",
      "Q333"
    ],
    "SelectA_recommedations": [
      "Q230",
      "Q439",
      "Q48"
    ],
    "SelectB_recommedations": [
      "Q1006",
      "Q545",
      "Q405"
    ],
    "SelectC_recommedations": [
      "Q194",
      "Q660",
      "Q584"
    ],
    "SelectD_recommedations": [
      "Q752",
      "Q97",
      "Q129"
    ],
    "SelectE_recommedations": [
      "Q405",
      "Q363",
      "Q540"
    ]
  },
  {
    "Question_Number": "Q1007",
    "Question_Description": "한 메디컬 회사가 여러 고객으로부터 유입되는 대규모 임상시험 데이터를 변환하려고 합니다. 이 회사는 고객 데이터가 들어 있는 relational database에서 먼저 데이터를 추출해야 합니다. 이후 복잡한 규칙에 따라 데이터를 변환한 뒤, 변환이 끝나면 해당 데이터를 Amazon S3에 로드할 예정입니다. 모든 데이터는 Amazon S3에 저장하기 전에 처리되는 위치에서 암호화되어야 하며, 고객별 키를 사용하여 암호화가 이뤄져야 합니다. 가장 적은 운영 노력을 통해 이 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148544-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 고객별 키를 사용하여 데이터를 처리 단계에서 암호화해야 하는 시나리오를 다룹니다. 즉, Amazon S3에 저장하기 전에 이미 암호화가 완료되어 있어야 하며, 동시에 운영 부담이 최소화되어야 합니다. AWS Glue를 사용하면 매번 새로운 클러스터를 띄우고 관리하는 복잡도를 줄이고, 필요한 만큼의 서버리스 방식으로 변환 작업을 수행할 수 있습니다. 또한 client-side encryption 방식으로 AWS KMS를 이용하면 고객별로 키를 할당하여 맞춤형 보안 정책을 수립할 수 있으므로 요구사항을 충족시키는 가장 효율적인 방법입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "임상시험 데이터",
      "relational database",
      "AWS Glue",
      "Amazon S3",
      "client-side encryption",
      "AWS KMS",
      "고객별 키",
      "데이터 변환"
    ],
    "Terms": [
      "AWS Glue job",
      "Amazon EMR",
      "Server-Side Encryption (SSE)",
      "Client-Side Encryption (CSE)",
      "AWS KMS",
      "SSE-KMS",
      "CSE-KMS",
      "SSE-S3",
      "CSE-Custom"
    ],
    "SelectA": "각 고객마다 하나의 AWS Glue job을 생성하고, job에 SSE-S3를 사용하는 security configuration을 연결하여 데이터를 암호화합니다.",
    "SelectA_Commentary": "SSE-S3는 Amazon S3에서 서버 측 암호화를 수행하지만, 고객별 키를 활용하기 어렵고 처리 단계에서 이미 암호화되어 있어야 한다는 요구사항을 만족시키지 못합니다.",
    "SelectB": "각 고객마다 하나의 Amazon EMR 클러스터를 생성하고, client-side encryption(CSE-Custom)을 사용하는 security configuration을 연결하여 데이터를 암호화합니다.",
    "SelectB_Commentary": "고객별 키 사용 자체는 가능하나, 고객마다 별도 EMR 클러스터를 운영하므로 운영 부담이 매우 커집니다.",
    "SelectC": "각 고객마다 하나의 AWS Glue job을 생성하고, client-side encryption(CSE-KMS)을 사용하는 security configuration을 연결하여 데이터를 암호화합니다.",
    "SelectC_Commentary": "AWS Glue는 서버리스로 관리가 용이하며, client-side encryption으로 고객별 KMS 키를 사용해 처리가 완료되기 전에 암호화를 적용할 수 있어 요구사항과 운영 효율성을 모두 충족합니다.",
    "SelectD": "각 고객마다 하나의 Amazon EMR 클러스터를 생성하고, 서버 측 암호화(SSE-KMS)를 사용하는 security configuration을 연결하여 데이터를 암호화합니다.",
    "SelectD_Commentary": "SSE-KMS는 서버 측 암호화 방식으로, 처리 단계에서 이미 암호화가 되어야 한다는 요구사항을 만족시키기 어렵고, 각 클러스터 관리로 운영 부담이 커집니다.",
    "Question_Description_recommedations": [
      "Q696",
      "Q925",
      "Q965",
      "Q154",
      "Q202"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q270",
      "Q862"
    ],
    "SelectB_recommedations": [
      "Q410",
      "Q681",
      "Q966"
    ],
    "SelectC_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ]
  },
  {
    "Question_Number": "Q1008",
    "Question_Description": "한 회사가 웹사이트 분석 애플리케이션을 단일 Amazon EC2 On-Demand Instance에서 호스팅하고 있습니다. 이 분석 애플리케이션은 높은 내구성을 가지며, 무상태(stateless) 모드로 실행되도록 설계되었습니다. 회사는 애플리케이션이 사용량이 많은 시간대에 성능 저하와 5xx 에러를 보이는 것을 발견했습니다. 회사는 애플리케이션이 부하에 맞춰 원활하게 스케일링되고, 비용 효율적이어야 한다고 요구합니다. 이러한 요구 사항을 가장 비용 효과적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148813-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 무상태 애플리케이션을 확장하면서 비용을 절감하는 전략을 묻습니다. Auto Scaling group에 Spot Fleet을 사용하면 부하가 낮을 때 자동으로 축소되어 비용을 절감할 수 있으며, Application Load Balancer를 통해 트래픽을 효과적으로 분산해 5xx 에러를 줄일 수 있습니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "Amazon EC2",
      "On-Demand Instance",
      "stateless",
      "5xx 에러",
      "Auto Scaling group",
      "Spot Fleet",
      "Application Load Balancer"
    ],
    "Terms": [
      "Amazon EC2 On-Demand Instance",
      "Amazon Machine Image (AMI)",
      "Application Load Balancer",
      "Amazon Route 53 Weighted Routing",
      "AWS Lambda",
      "Amazon CloudWatch",
      "CPU utilization",
      "Spot Fleet",
      "Auto Scaling group",
      "launch template"
    ],
    "SelectA": "웹 애플리케이션의 AMI를 생성하고, 이를 사용해 두 번째 EC2 On-Demand Instance를 시작합니다. Application Load Balancer를 사용해 두 EC2 인스턴스 간 부하를 분산합니다.",
    "SelectA_Commentary": "인스턴스 두 대로만 스케일링하며 On-Demand 비용이 그대로 발생합니다. Auto Scaling group이 없어 자동 축소가 불가능해 장기적으로 비용 최적화에 불리합니다.",
    "SelectB": "웹 애플리케이션의 AMI를 생성하고, 이를 사용해 두 번째 EC2 On-Demand Instance를 시작합니다. Amazon Route 53의 가중치 라우팅(Weighted Routing)을 사용해 두 EC2 인스턴스 간 부하를 분산합니다.",
    "SelectB_Commentary": "Route 53 라우팅 정책만으로는 인스턴스 수요에 따라 자동 확장·축소가 불가능합니다. 수동으로 인스턴스 추가·삭제가 필요해 운영 부담과 비용이 증가합니다.",
    "SelectC": "AWS Lambda 함수를 생성해 EC2 인스턴스를 중지하고 인스턴스 타입을 변경하도록 합니다. CPU 사용률이 75%를 초과할 경우 Lambda 함수를 호출하도록 Amazon CloudWatch Alarm을 설정합니다.",
    "SelectC_Commentary": "수직 확장 방식으로, 트래픽이 급격히 증가하면 단순히 인스턴스 타입 변경만으로 부족할 수 있고 무중단 확장이 어려워 안정적인 확장 및 비용 최적화 측면에서 비효율적입니다.",
    "SelectD": "웹 애플리케이션의 AMI를 생성하고, 이를 launch template에 적용합니다. 이 launch template을 포함하는 Auto Scaling group을 생성합니다. launch template에서 Spot Fleet을 사용하도록 구성합니다. Application Load Balancer를 Auto Scaling group에 연결합니다.",
    "SelectD_Commentary": "Spot Fleet으로 인스턴스 비용을 절감하며, Auto Scaling group을 통해 부하에 따라 자동으로 확장·축소할 수 있습니다. Application Load Balancer가 트래픽 분산을 담당해 안정성과 비용 효율성 모두를 충족합니다.",
    "Question_Description_recommedations": [
      "Q1013",
      "Q505",
      "Q424",
      "Q347",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q146",
      "Q473",
      "Q441"
    ],
    "SelectB_recommedations": [
      "Q1008",
      "Q146",
      "Q1013"
    ],
    "SelectC_recommedations": [
      "Q807",
      "Q882",
      "Q770"
    ],
    "SelectD_recommedations": [
      "Q245",
      "Q441",
      "Q984"
    ]
  },
  {
    "Question_Number": "Q1009",
    "Question_Description": "한 회사에서 Amazon S3 버킷에 데이터를 저장하고 있으며, 해당 객체는 하루 종일 자주 액세스됩니다. 회사는 S3 버킷에 저장되는 데이터에 대해 엄격한 암호화 요구 사항을 가지고 있고, 현재 AWS KMS를 사용하여 데이터를 암호화하고 있습니다. 추가적인 AWS KMS 호출 없이 S3 객체 암호화에 따른 비용을 최적화하고자 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148814-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 AWS KMS를 이용해 데이터를 암호화하면서, KMS 호출 횟수를 줄여 비용을 낮추고자 할 때 어떤 방식을 쓰는 것이 최적일지를 묻습니다. S3 Bucket Key를 사용하면 반복적인 KMS 호출을 효과적으로 줄일 수 있어 SSE-KMS 환경에서도 비용을 절감할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.3"
    ],
    "Keywords": [
      "자주 액세스",
      "엄격한 암호화 요구 사항",
      "AWS KMS 추가 호출",
      "비용 최적화",
      "S3 객체 암호화"
    ],
    "Terms": [
      "Amazon S3",
      "AWS KMS",
      "SSE-S3",
      "S3 Bucket Key",
      "SSE-KMS",
      "Client-side encryption",
      "SSE-C"
    ],
    "SelectA": "Server-side encryption with Amazon S3 managed keys (SSE-S3)를 사용합니다.",
    "SelectA_Commentary": "SSE-S3는 KMS를 직접 사용하지 않아 비용이 저렴할 수 있으나, 엄격한 암호화 요건으로 인해 KMS를 사용해야 하는 경우에는 요구사항을 충족하지 못할 수 있습니다.",
    "SelectB": "새로운 객체에 대해 S3 Bucket Key를 사용하는 server-side encryption with AWS KMS keys (SSE-KMS)를 구성합니다.",
    "SelectB_Commentary": "S3 Bucket Key는 SSE-KMS 사용 시 KMS 호출 횟수를 줄여 비용을 절감합니다. 엄격한 KMS 기반 암호화 요건을 유지하면서도 비용을 최적화하는 올바른 접근입니다.",
    "SelectC": "AWS KMS customer managed keys를 사용하는 client-side encryption을 적용합니다.",
    "SelectC_Commentary": "클라이언트 측에서 암호화 로직을 직접 구현해야 하므로 운영 복잡도가 높아질 수 있으며, 여전히 KMS 호출 부분이 늘어날 가능성이 있습니다.",
    "SelectD": "AWS KMS에 저장된 customer-provided keys를 사용하는 server-side encryption (SSE-C)을 구성합니다.",
    "SelectD_Commentary": "SSE-C를 사용하면 키 관리를 직접 해야 하고, AWS KMS 호출을 피하기 어렵습니다. 운영 부담과 호출 비용 절감 측면에서도 최적이 아닙니다.",
    "Question_Description_recommedations": [
      "Q270",
      "Q412",
      "Q109",
      "Q640",
      "Q916"
    ],
    "SelectA_recommedations": [
      "Q740",
      "Q965",
      "Q678"
    ],
    "SelectB_recommedations": [
      "Q681",
      "Q793",
      "Q916"
    ],
    "SelectC_recommedations": [
      "Q916",
      "Q681",
      "Q371"
    ],
    "SelectD_recommedations": [
      "Q681",
      "Q916",
      "Q371"
    ]
  },
  {
    "Question_Number": "Q1010",
    "Question_Description": "한 회사가 온프레미스 데이터 센터에서 virtual machines(VMs)로 여러 워크로드를 운영하고 있습니다. 회사는 빠르게 확장 중이나 온프레미스 데이터 센터로는 비즈니스 요구사항을 빠르게 충족하기 어려워졌습니다. 회사는 이러한 워크로드를 AWS로 마이그레이션하려고 하며, 마이그레이션은 시간에 매우 민감합니다. 회사는 중요하지 않은 워크로드에 대해 lift-and-shift 전략을 사용하고자 합니다. 다음 단계들 중 어떤 조합이 이 요구사항을 충족합니까? (3개를 선택하십시오.)",
    "Answer": "B,C,D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148815-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 온프레미스에 있던 VMs를 빠르게 AWS로 이전하는 형태의 lift-and-shift 마이그레이션 전략을 묻습니다. 기본적으로 AWS Application Migration Service를 사용하여 VM 이미지를 자동 복제·동기화하고 테스트 인스턴스 실행 후 실제 cutover를 진행하는 방식을 따릅니다. 비즈니스 보안이나 중요 데이터베이스 스키마 변환이 아닌, 단순한 VM 이전이므로 SCT나 DMS가 아니라 Application Migration Service가 핵심 솔루션이며, 테스트 후에 소스 운영 정지를 거쳐 cutover를 실시합니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "lift-and-shift",
      "AWS Application Migration Service",
      "VM 마이그레이션",
      "온프레미스",
      "time sensitive"
    ],
    "Terms": [
      "AWS Schema Conversion Tool(AWS SCT)",
      "AWS Application Migration Service",
      "AWS Replication Agent",
      "AWS Database Migration Service(AWS DMS)",
      "AWS App2Container(A2C)",
      "cutover"
    ],
    "SelectA": "Use the AWS Schema Conversion Tool (AWS SCT) to collect data about the VMs.",
    "SelectA_Commentary": "AWS SCT는 주로 데이터베이스 스키마 변환 용도이므로 VM 정보를 수집하거나 마이그레이션을 수행하기에는 부적합합니다.",
    "SelectB": "Use AWS Application Migration Service. Install the AWS Replication Agent on the VMs.",
    "SelectB_Commentary": "AWS Application Migration Service로 VM 복제를 시작하고, AWS Replication Agent 설치로 자동화 및 동기화를 진행할 수 있어 필수 단계입니다.",
    "SelectC": "Complete the initial replication of the VMs. Launch test instances to perform acceptance tests on the VMs.",
    "SelectC_Commentary": "처음 복제가 끝나면 테스트를 위한 인스턴스를 띄워 정상 동작 여부를 확인해야 하므로 중요한 검증 단계입니다.",
    "SelectD": "Stop all operations on the VMs. Launch a cutover instance.",
    "SelectD_Commentary": "수용 테스트 후 소스 VM의 운영을 중단하며, 새 환경으로 전환하는 최종 cutover 과정을 거쳐야 합니다.",
    "SelectE": "Use AWS App2Container (A2C) to collect data about the VMs.",
    "SelectE_Commentary": "App2Container(A2C)는 컨테이너화 작업에 주로 사용되므로 단순 VM lift-and-shift 마이그레이션에는 적합하지 않습니다.",
    "SelectF": "Use AWS Database Migration Service (AWS DMS) to migrate the VMs.",
    "SelectF_Commentary": "AWS DMS는 데이터베이스 마이그레이션용 서비스이며, VM 자체 마이그레이션에는 사용되지 않습니다.",
    "Question_Description_recommedations": [
      "Q752",
      "Q790",
      "Q487",
      "Q293",
      "Q194"
    ],
    "SelectA_recommedations": [
      "Q1010",
      "Q194",
      "Q897"
    ],
    "SelectB_recommedations": [
      "Q1010",
      "Q545",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q1010",
      "Q545",
      "Q660"
    ],
    "SelectD_recommedations": [
      "Q1010",
      "Q660",
      "Q584"
    ],
    "SelectE_recommedations": [
      "Q194",
      "Q1010",
      "Q584"
    ],
    "SelectF_recommedations": [
      "Q1010",
      "Q843",
      "Q194"
    ]
  },
  {
    "Question_Number": "Q1011",
    "Question_Description": "한 회사에서 private subnet에 애플리케이션을 호스팅하고 있습니다. 이 회사는 이미 Amazon Cognito와 애플리케이션을 통합했습니다. 회사는 Amazon Cognito user pool을 사용하여 사용자를 인증합니다. 회사는 애플리케이션을 수정하여 Amazon S3 버킷에 사용자 문서를 안전하게 저장할 수 있도록 해야 합니다. 어떤 조합의 단계가 애플리케이션을 Amazon S3와 안전하게 통합할 수 있습니까? (2개를 선택하십시오.)",
    "Answer": "A,C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148817-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon Cognito user pool과 Amazon S3를 연동해 사용자 별로 안전하게 문서를 저장하는 방법을 묻습니다. Identity pool로 임시 크레덴셜을 발급하고, private subnet 환경에서 S3 VPC endpoint를 사용해 보안성과 접근성을 높일 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.2"
    ],
    "Keywords": [
      "private subnet",
      "Amazon Cognito user pool",
      "Amazon Cognito identity pool",
      "Amazon S3 VPC endpoint",
      "안전한 통합"
    ],
    "Terms": [
      "Amazon Cognito user pool",
      "Amazon Cognito identity pool",
      "Amazon S3",
      "VPC endpoint",
      "NAT gateway",
      "bucket policy"
    ],
    "SelectA": "사용자가 로그인에 성공하면 Amazon Cognito identity pool을 생성하여 Amazon S3에 대한 안전한 액세스 토큰을 발급합니다.",
    "SelectA_Commentary": "Identity pool을 통해 사용자에게 임시 권한을 부여하고, 세분화된 S3 액세스를 가능하게 하므로 올바른 접근 방식입니다.",
    "SelectB": "기존 Amazon Cognito user pool을 사용하여 사용자가 로그인에 성공하면 Amazon S3 액세스 토큰을 발급합니다.",
    "SelectB_Commentary": "User pool 자체는 인증 용도로만 사용 가능하며, 임시 S3 액세스 권한 부여에는 적합하지 않으므로 오답입니다.",
    "SelectC": "회사가 애플리케이션을 호스팅하고 있는 동일한 VPC에 Amazon S3 VPC endpoint를 생성합니다.",
    "SelectC_Commentary": "private subnet 내부에서 public 인터넷을 거치지 않고 안전하게 S3에 연결할 수 있어 보안과 성능을 모두 충족하므로 정답입니다.",
    "SelectD": "애플리케이션이 호스팅된 VPC에 NAT gateway를 생성하고, Amazon Cognito가 아닌 요청을 거부하도록 S3 버킷에 정책을 할당합니다.",
    "SelectD_Commentary": "NAT gateway로 트래픽을 우회하는 방식은 비용이 높고, Cognito가 아닌 요청 식별도 어렵기 때문에 적절한 해결책이 아닙니다.",
    "SelectE": "S3 버킷에 사용자들의 IP 주소에서만 액세스할 수 있도록 허용하는 정책을 부착합니다.",
    "SelectE_Commentary": "IP 주소 기반의 접근 제한은 동적으로 변하는 사용자 환경을 고려하기 어렵고, 세분화된 권한 관리에도 한계가 있어 부적절합니다.",
    "Question_Description_recommedations": [
      "Q875",
      "Q115",
      "Q889",
      "Q325",
      "Q862"
    ],
    "SelectA_recommedations": [
      "Q1011",
      "Q965",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q1011",
      "Q325",
      "Q965"
    ],
    "SelectC_recommedations": [
      "Q91",
      "Q92",
      "Q866"
    ],
    "SelectD_recommedations": [
      "Q1011",
      "Q1016",
      "Q92"
    ],
    "SelectE_recommedations": [
      "Q825",
      "Q44",
      "Q202"
    ]
  },
  {
    "Question_Number": "Q1012",
    "Question_Description": "한 회사가 고객 주문을 처리하는 3계층 웹 애플리케이션을 운영하고 있습니다. 웹 계층은 Application Load Balancer 뒤의 Amazon EC2 인스턴스들로 구성되어 있으며, 처리 계층은 Amazon EC2 인스턴스로 구성되고 Amazon Simple Queue Service (Amazon SQS)를 사용하여 웹 계층과 분리되어 있습니다. 스토리지 계층으로는 Amazon DynamoDB를 사용합니다. 최대 부하 시점에 일부 사용자들은 주문 처리 지연 및 중단을 겪고 있고, 해당 시점에 EC2 인스턴스의 CPU 사용률이 100%에 달하며 SQS 큐가 가득 차는 현상을 관찰했습니다. 최대 부하 시점은 일정하지 않고 예측하기 어렵습니다. 애플리케이션의 성능을 개선하기 위해 어떤 솔루션을 적용해야 합니까?",
    "Answer": "D",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148818-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "처리 계층이 병목이므로, 수요가 변동될 때 자동으로 확장하는 것이 핵심입니다. EC2 Auto Scaling의target tracking 정책을 활용하여 SQS 메시지 양에 따라 처리 계층을 확장하면 성능 문제를 해결할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "3계층 웹 애플리케이션",
      "주문 처리 지연",
      "CPU 사용률 100%",
      "SQS 큐 적체",
      "성능 개선",
      "EC2 Auto Scaling target tracking"
    ],
    "Terms": [
      "Amazon EC2",
      "Application Load Balancer",
      "Amazon SQS",
      "Amazon DynamoDB",
      "Amazon ElastiCache for Redis",
      "Amazon CloudFront",
      "EC2 Auto Scaling",
      "ApproximateNumberOfMessages"
    ],
    "SelectA": "Amazon EC2 Auto Scaling에 대한 Scheduled Scaling을 사용하여 처리 계층 인스턴스를 피크 시간 동안 확장하고, CPU Utilization 지표를 기준으로 스케일링을 결정합니다.",
    "SelectA_Commentary": "피크 시간이 일정하지 않고 예측하기 어려우므로 스케줄 기반 확장은 적합하지 않습니다.",
    "SelectB": "Amazon DynamoDB 백엔드 앞단에 Amazon ElastiCache for Redis를 구성하고, Target Utilization 지표를 기준으로 확장 여부를 결정합니다.",
    "SelectB_Commentary": "레이턴시가 주로 DB가 아닌 처리 계층에서 발생하므로, 캐시를 추가해도 CPU 사용률 문제를 해결하기 어렵습니다.",
    "SelectC": "웹 계층에 대한 응답을 캐시하기 위해 Amazon CloudFront 배포를 추가하고, HTTP 지연 시간 지표를 기반으로 스케일링을 결정합니다.",
    "SelectC_Commentary": "정적 컨텐츠 캐싱은 웹 계층 부하를 줄이는 데 도움 되지만, 실제 병목은 처리 계층에 있으므로 해결책이 되지 못합니다.",
    "SelectD": "Amazon EC2 Auto Scaling Target Tracking Policy를 사용하여 처리 계층 인스턴스를 확장하고, ApproximateNumberOfMessages 속성을 활용해 스케일 아웃 시점을 결정합니다.",
    "SelectD_Commentary": "SQS 큐 적체량에 따라 처리 계층이 자동으로 확장되므로 피크 시점에 발생하는 CPU 과부하와 지연 문제를 효과적으로 해결할 수 있는 최적의 방법입니다.",
    "Question_Description_recommedations": [
      "Q537",
      "Q203",
      "Q405",
      "Q275",
      "Q357"
    ],
    "SelectA_recommedations": [
      "Q595",
      "Q581",
      "Q210"
    ],
    "SelectB_recommedations": [
      "Q768",
      "Q593",
      "Q78"
    ],
    "SelectC_recommedations": [
      "Q8",
      "Q363",
      "Q194"
    ],
    "SelectD_recommedations": [
      "Q660",
      "Q642",
      "Q595"
    ]
  },
  {
    "Question_Number": "Q1013",
    "Question_Description": "한 회사의 프로덕션 환경은 월요일부터 토요일까지 상시 실행되는 Amazon EC2 On-Demand Instances로 구성되어 있습니다. 인스턴스는 일요일에는 단 12시간만 실행되어야 하며 중단을 허용할 수 없습니다. 회사는 프로덕션 환경을 비용 최적화하기를 원합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148819-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 EC2 인스턴스를 두 가지 용도로 나누어, 장기간(월~토)과 단시간(일요일 12시간)에 대해 중단 없는 상태를 유지하면서 비용을 최대한 절감해야 하는 시나리오입니다. Standard Reserved Instances는 다른 유형보다 단가가 낮아 상시 실행되는 인스턴스에 가장 적합하며, 일요일 12시간만 운영하는 인스턴스에 대해서는 Scheduled Reserved Instances를 구매하여 정해진 시간대에만 실행하도록 해 비용을 최소화할 수 있습니다. Spot Instances는 중단 가능성이 있으므로 중단을 허용할 수 없는 워크로드에는 적합하지 않습니다. Convertible Reserved Instances는 유연성은 높지만 요금이 더 비싸므로, 이 시나리오에서 가장 비용 효율적인 조합은 표준 예약 인스턴스와 스케줄 예약 인스턴스를 함께 사용하는 것입니다.",
    "Domain": "비용에 최적화된 아키텍처 설계",
    "Tasks": [
      "4.2"
    ],
    "Keywords": [
      "비용 최적화",
      "Amazon EC2 On-Demand Instances",
      "Scheduled Reserved Instances",
      "Standard Reserved Instances",
      "Convertible Reserved Instances",
      "Spot Instances",
      "일요일 12시간",
      "중단 불가"
    ],
    "Terms": [
      "EC2 On-Demand Instances",
      "Scheduled Reserved Instances",
      "Standard Reserved Instances",
      "Convertible Reserved Instances",
      "Spot Instances"
    ],
    "SelectA": "일요일에 12시간만 실행되는 EC2 인스턴스에는 Scheduled Reserved Instances를 구매하고, 월요일부터 토요일까지 상시 실행되는 EC2 인스턴스에는 Standard Reserved Instances를 구매합니다.",
    "SelectA_Commentary": "일요일 단시간 워크로드에는 스케줄 예약, 상시 워크로드에는 표준 예약으로 비용 효율을 극대화합니다.",
    "SelectB": "일요일에 12시간만 실행되는 EC2 인스턴스에는 Convertible Reserved Instances를 구매하고, 월요일부터 토요일까지 상시 실행되는 EC2 인스턴스에는 Standard Reserved Instances를 구매합니다.",
    "SelectB_Commentary": "일요일 워크로드에는 중단이 없지만 Convertible Reserved Instances는 표준 예약보다 비싸므로 최적이 아닙니다.",
    "SelectC": "일요일에 12시간만 실행되는 EC2 인스턴스에는 Spot Instances를 사용하고, 월요일부터 토요일까지 상시 실행되는 EC2 인스턴스에는 Standard Reserved Instances를 구매합니다.",
    "SelectC_Commentary": "Spot Instances는 중단 가능성이 있어 일요일 워크로드가 중단을 허용하지 않는 요구사항에 맞지 않습니다.",
    "SelectD": "일요일에 12시간만 실행되는 EC2 인스턴스에는 Spot Instances를 사용하고, 월요일부터 토요일까지 상시 실행되는 EC2 인스턴스에는 Convertible Reserved Instances를 구매합니다.",
    "SelectD_Commentary": "일요일 워크로드에 Spot Instances는 중단 위험이 있으며, Convertible Reserved Instances도 비용 면에서 최적이 아닙니다.",
    "Question_Description_recommedations": [
      "Q1008",
      "Q505",
      "Q347",
      "Q238",
      "Q552"
    ],
    "SelectA_recommedations": [
      "Q1013",
      "Q552",
      "Q1008"
    ],
    "SelectB_recommedations": [
      "Q1013",
      "Q552",
      "Q1008"
    ],
    "SelectC_recommedations": [
      "Q1013",
      "Q552",
      "Q1008"
    ],
    "SelectD_recommedations": [
      "Q1013",
      "Q552",
      "Q1008"
    ]
  },
  {
    "Question_Number": "Q1014",
    "Question_Description": "한 디지털 이미지 처리 회사가 온프레미스 모놀리식 애플리케이션을 AWS Cloud로 마이그레이션하려고 합니다. 이 회사는 수천 개의 이미지를 처리하고, 처리 과정에서 대규모 파일을 생성합니다. 이 회사는 급증하는 이미지 처리 작업을 효율적으로 관리해야 하며, 수작업을 줄여 자동화된 워크플로우를 구현하길 원합니다. 또한 솔루션의 기본 인프라를 직접 관리하고 싶지 않으며, 가능한 한 운영 오버헤드를 최소화해야 합니다. 이 요구사항을 가장 적은 운영 오버헤드로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148820-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 많은 이미지를 처리하고 대규모 파일을 생성하면서도 인프라 운영을 최소화해야 하는 요구사항에 대한 해법을 묻습니다. AWS Batch와 AWS Step Functions를 함께 사용하면 대규모 배치 처리를 자동화하고 처리 흐름을 간소화할 수 있습니다. 특히 서버를 직접 관리할 필요가 없어서 운영 오버헤드를 크게 줄일 수 있으며, 처리가 끝난 파일을 Amazon S3에 저장하면 확장성과 내구성을 동시에 달성할 수 있습니다.",
    "Domain": "복원력을 갖춘 아키텍처 설계",
    "Tasks": [
      "2.1"
    ],
    "Keywords": [
      "온프레미스 모놀리식 애플리케이션",
      "이미지 처리",
      "AWS Cloud 마이그레이션",
      "자동화된 워크플로우",
      "운영 오버헤드 최소화",
      "AWS Batch",
      "AWS Step Functions",
      "Amazon S3 버킷"
    ],
    "Terms": [
      "Amazon Elastic Container Service (Amazon ECS)",
      "Amazon EC2 Spot Instances",
      "Amazon Simple Queue Service (Amazon SQS)",
      "Amazon Elastic File System (Amazon EFS)",
      "AWS Batch",
      "AWS Step Functions",
      "Amazon S3",
      "AWS Lambda",
      "Amazon FSx",
      "Amazon EC2",
      "Amazon Elastic Block Store (Amazon EBS)"
    ],
    "SelectA": "Amazon ECS를 Amazon EC2 Spot Instances와 함께 사용하여 이미지를 처리합니다. Amazon SQS를 사용해 워크플로우를 오케스트레이션하고, 처리된 파일은 Amazon EFS에 저장합니다.",
    "SelectA_Commentary": "컨테이너 오케스트레이션과 Spot Instances를 활용하지만, 여전히 Amazon ECS 클러스터를 직접 운영해야 하므로 운영 오버헤드가 높습니다.",
    "SelectB": "AWS Batch 작업을 사용하여 이미지를 처리합니다. AWS Step Functions로 워크플로우를 오케스트레이션합니다. 처리된 파일은 Amazon S3 버킷에 저장합니다.",
    "SelectB_Commentary": "완전관리형 배치 서비스 AWS Batch와 Step Functions로 오케스트레이션을 자동화해 운영 부담을 줄이고, S3를 사용해 확장성과 내구성을 확보하는 최적의 솔루션입니다.",
    "SelectC": "AWS Lambda 함수와 Amazon EC2 Spot Instances를 함께 사용하여 이미지를 처리합니다. 처리된 파일은 Amazon FSx에 저장합니다.",
    "SelectC_Commentary": "서버리스인 Lambda와 EC2 Spot을 혼합해 관리해야 하므로 오버헤드가 증가하며, FSx 사용 역시 별도의 파일 시스템 관리를 동반합니다.",
    "SelectD": "Amazon EC2 인스턴스 그룹을 배포하여 이미지를 처리합니다. AWS Step Functions로 워크플로우를 오케스트레이션합니다. 처리된 파일은 Amazon EBS 볼륨에 저장합니다.",
    "SelectD_Commentary": "EC2 인스턴스를 유지·관리해야 하고, EBS는 인스턴스 수명 주기에 종속되므로 운영 관리가 복잡해집니다.",
    "Question_Description_recommedations": [
      "Q513",
      "Q802",
      "Q149",
      "Q112",
      "Q363"
    ],
    "SelectA_recommedations": [
      "Q67",
      "Q944",
      "Q194"
    ],
    "SelectB_recommedations": [
      "Q18",
      "Q809",
      "Q194"
    ],
    "SelectC_recommedations": [
      "Q785",
      "Q194",
      "Q775"
    ],
    "SelectD_recommedations": [
      "Q194",
      "Q944",
      "Q602"
    ]
  },
  {
    "Question_Number": "Q1015",
    "Question_Description": "한 기업의 이미지 호스팅 웹사이트는 전 세계 사용자들이 모바일 기기를 통해 이미지를 업로드, 보기, 다운로드할 수 있는 기능을 제공합니다. 현재 정적 웹사이트는 Amazon S3 버킷에 호스팅 중입니다. 웹사이트의 인기가 높아짐에 따라 성능이 저하되어, 사용자들이 이미지를 업로드하고 다운로드할 때 지연(latency) 문제가 보고되었습니다. 회사는 웹사이트의 성능을 개선해야 합니다. 가장 적은 구현 노력으로 요구 사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "A",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148821-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 전 세계 사용자들에게 빠른 업로드와 다운로드를 제공하기 위한 최적의 방법을 찾는 문제입니다. CloudFront는 글로벌 에지 로케이션을 통한 다운로드 가속을 제공하고, S3 Transfer Acceleration은 여러 지점에서 데이터를 빠르게 업로드할 수 있게 해줍니다. 별도의 복잡한 서버 구성 없이 구현이 용이하므로 가장 적은 노력으로 성능 문제를 해결할 수 있습니다.",
    "Domain": "고성능 아키텍처 설계",
    "Tasks": [
      "3.4"
    ],
    "Keywords": [
      "이미지 호스팅",
      "Amazon S3",
      "성능 개선",
      "지연 문제",
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "AWS Global Accelerator"
    ],
    "Terms": [
      "Amazon S3",
      "Amazon CloudFront",
      "S3 Transfer Acceleration",
      "Amazon EC2",
      "Application Load Balancer",
      "AWS Global Accelerator",
      "S3 버킷 복제"
    ],
    "SelectA": "Amazon CloudFront 배포를 구성하여 S3 버킷의 다운로드 성능을 개선합니다. 업로드 성능을 개선하기 위해 S3 Transfer Acceleration을 활성화합니다.",
    "SelectA_Commentary": "CloudFront와 S3 Transfer Acceleration은 각각 다운로드와 업로드를 가속화하므로, 간단하게 성능 문제를 해결할 수 있는 최적의 방법입니다.",
    "SelectB": "여러 AWS 리전에서 적절한 크기의 Amazon EC2 인스턴스를 구성합니다. 웹사이트를 이 인스턴스들로 마이그레이션합니다. Application Load Balancer로 트래픽을 분산하고, AWS Global Accelerator로 지연을 낮춥니다.",
    "SelectB_Commentary": "EC2 인스턴스 설정과 마이그레이션, 로드 밸런서 구성 등 구현 부담이 높아 최소 노력 요건에 부합하지 않습니다.",
    "SelectC": "S3 버킷을 원본으로 하는 Amazon CloudFront 배포를 구성하여 다운로드 속도를 개선합니다. 업로드에도 CloudFront를 사용하도록 애플리케이션을 구성합니다. 여러 리전에 S3 버킷을 만들고, 버킷 복제 규칙을 설정해 위치에 따라 데이터를 복제합니다. 사용자 위치에 가장 가까운 S3 버킷으로 다운로드를 리디렉션합니다.",
    "SelectC_Commentary": "여러 S3 버킷, 복제 규칙, 리디렉션 로직 구성 등 많은 추가 설정이 필요해 과도하게 복잡해집니다.",
    "SelectD": "S3 버킷에 대해 AWS Global Accelerator를 구성하여 네트워크 성능을 개선합니다. 애플리케이션이 S3 버킷 대신 Global Accelerator를 사용하도록 엔드포인트를 만듭니다.",
    "SelectD_Commentary": "S3 버킷을 직접 가속하기 위한 Global Accelerator 구성은 단순하지 않으며, CloudFront나 S3 Transfer Acceleration 대비 구현 이점이 적습니다.",
    "Question_Description_recommedations": [
      "Q626",
      "Q501",
      "Q173",
      "Q547",
      "Q302"
    ],
    "SelectA_recommedations": [
      "Q280",
      "Q38",
      "Q680"
    ],
    "SelectB_recommedations": [
      "Q358",
      "Q266",
      "Q910"
    ],
    "SelectC_recommedations": [
      "Q280",
      "Q672",
      "Q155"
    ],
    "SelectD_recommedations": [
      "Q687",
      "Q155",
      "Q501"
    ]
  },
  {
    "Question_Number": "Q1016",
    "Question_Description": "한 회사가 VPC 내부에 있는 Application Load Balancer(ALB) 뒤의 프라이빗 서브넷에서 애플리케이션을 운영하고 있습니다. 해당 VPC에는 NAT Gateway와 Internet Gateway가 구성되어 있습니다. 이 애플리케이션은 Amazon S3 API를 호출하여 객체를 저장합니다. 회사 보안 정책상 애플리케이션 트래픽이 인터넷을 통해 전송되지 않도록 해야 합니다. 이 요구사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148824-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 프라이빗 서브넷에서 Amazon S3로 데이터를 전송할 때 인터넷을 거치지 않도록 보안을 유지하면서, 동시에 가장 비용 효율적인 연결 방식을 결정하는 상황입니다. S3 Gateway Endpoint는 시간 단위 과금 없이 VPC 내부 경로를 통해 S3와 통신하도록 하여, 인터넷 트래픽을 발생시키지 않으면서도 비용을 낮출 수 있어 정답이 됩니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1",
      "1.3"
    ],
    "Keywords": [
      "프라이빗 서브넷",
      "트래픽 비인터넷 경로",
      "Amazon S3",
      "비용 효율성",
      "S3 Gateway Endpoint"
    ],
    "Terms": [
      "Application Load Balancer(ALB)",
      "VPC",
      "Amazon S3",
      "NAT Gateway",
      "Internet Gateway",
      "S3 Interface Endpoint",
      "S3 Gateway Endpoint",
      "Security Group",
      "Bucket Policy",
      "VPC Route Table"
    ],
    "SelectA": "S3 Interface Endpoint를 구성하고, Amazon S3로의 아웃바운드 트래픽을 허용하는 Security Group을 생성합니다.",
    "SelectA_Commentary": "인터페이스 엔드포인트는 별도의 시간당 비용이 발생하므로, 가장 비용 효율적인 솔루션이 아닙니다. 또한 트래픽은 VPC 내로 제한할 수 있지만, 운영 비용 면에서는 Gateway Endpoint가 더 경제적입니다.",
    "SelectB": "S3 Gateway Endpoint를 구성하고, VPC 라우트 테이블을 해당 엔드포인트를 사용하도록 업데이트합니다.",
    "SelectB_Commentary": "정답입니다. S3 Gateway Endpoint는 추가 시간 과금 없이 VPC 내부 경로로 S3에 접근하도록 하며, NAT Gateway를 거치지 않으므로 인터넷 구간을 사용하지도 않고 비용 효율성도 높습니다.",
    "SelectC": "NAT Gateway에 할당된 Elastic IP 주소에서 트래픽을 허용하도록 S3 Bucket Policy를 구성합니다.",
    "SelectC_Commentary": "버킷 정책으로 특정 IP를 허용해도, 실제 트래픽 경로는 인터넷을 통할 수 있습니다. 결과적으로 애플리케이션 트래픽이 완전히 프라이빗 경로를 유지하지 못하며 정책 요구사항을 온전히 충족하기 어렵습니다.",
    "SelectD": "레거시 애플리케이션이 배포된 동일 서브넷에 두 번째 NAT Gateway를 생성하고, VPC 라우트 테이블을 두 번째 NAT Gateway로 업데이트합니다.",
    "SelectD_Commentary": "추가 NAT Gateway를 생성하면 비용이 더 많이 들고, 여전히 트래픽은 인터넷 게이트웨이 경로를 통할 수 있습니다. 인터넷 구간을 배제하려는 목표와 비용 효율성 모두 충족하지 못합니다.",
    "Question_Description_recommedations": [
      "Q927",
      "Q884",
      "Q60",
      "Q676",
      "Q91"
    ],
    "SelectA_recommedations": [
      "Q965",
      "Q270",
      "Q202"
    ],
    "SelectB_recommedations": [
      "Q92",
      "Q91",
      "Q4"
    ],
    "SelectC_recommedations": [
      "Q1016",
      "Q256",
      "Q616"
    ],
    "SelectD_recommedations": [
      "Q468",
      "Q151",
      "Q950"
    ]
  },
  {
    "Question_Number": "Q1017",
    "Question_Description": "한 회사가 Amazon EC2 인스턴스에서 동작하는 Amazon EKS 클러스터에서 애플리케이션을 실행하고 있습니다. 이 애플리케이션에는 UI와 데이터 서비스가 있으며, UI는 Amazon DynamoDB를 사용하고 데이터 서비스는 Amazon S3를 사용합니다. 회사는 UI용 EKS Pod가 Amazon DynamoDB에만 액세스하고, 데이터 서비스용 EKS Pod가 Amazon S3에만 액세스하도록 해야 합니다. 또한 회사는 AWS Identity and Access Management(IAM)를 사용합니다. 이러한 요구사항을 만족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148825-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon EKS 환경에서 워크로드마다 필요한 AWS 리소스에만 접근할 수 있도록 IAM 역할을 분리하는 방법을 묻습니다. EKS Pod 별로 다른 IAM Role을 할당해줘야만 UI Pod는 Amazon DynamoDB에만, 데이터 서비스 Pod는 Amazon S3에만 접근하도록 제한할 수 있습니다. 특히 IAM Role for Service Accounts(IRSA)를 활용하면 Kubernetes Service Account와 IAM Role을 매핑하여 세분화된 권한 관리를 손쉽게 구현할 수 있습니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon EKS",
      "Amazon EC2",
      "UI Pod",
      "Data Service Pod",
      "Amazon DynamoDB",
      "Amazon S3",
      "IAM",
      "권한 분리"
    ],
    "Terms": [
      "IAM Role for Service Accounts (IRSA)",
      "Kubernetes Service Account",
      "RBAC (Role-Based Access Control)",
      "AmazonDynamoDBFullAccess",
      "AmazonS3FullAccess",
      "IAM Policy",
      "EC2 Instance Profile"
    ],
    "SelectA": "Amazon S3와 Amazon DynamoDB에 대한 별도 IAM 정책을 생성하고, 이 둘을 EC2 인스턴스 프로파일에 연결합니다. 그런 다음 RBAC를 활용해 각 EKS Pod의 Amazon S3 또는 Amazon DynamoDB 접근을 제어합니다.",
    "SelectA_Commentary": "EC2 인스턴스 프로파일에 모든 권한을 부여하면 Pod 간 권한이 격리되지 않으므로, 요구사항을 충족하기 어렵습니다.",
    "SelectB": "필요한 권한이 있는 Amazon S3와 Amazon DynamoDB용 별도 IAM 정책을 생성합니다. 그리고 Amazon S3 IAM 정책은 데이터 서비스 Pod에, Amazon DynamoDB IAM 정책은 UI Pod에 직접 연결합니다.",
    "SelectB_Commentary": "IAM 정책을 Pod에 직접 붙이는 기능은 기본적으로 지원되지 않습니다. 적절한 메커니즘(IRSA 등)이 없으므로 완전한 분리가 어렵습니다.",
    "SelectC": "UI와 데이터 서비스 각각에 대해 별도의 Kubernetes Service Account를 만들고, 해당 Service Account가 IAM Role을 사용할 수 있도록 설정합니다. 데이터 서비스에는 AmazonS3FullAccess 정책을, UI에는 AmazonDynamoDBFullAccess 정책을 연결합니다.",
    "SelectC_Commentary": "Pod마다 서로 다른 Service Account로 각각 필요한 리소스에만 접근할 수 있게 IAM Role을 구성하는 올바른 방법입니다. IAM Role for Service Accounts(IRSA)를 사용해 세분화된 권한을 부여하므로, 요구사항을 충족합니다.",
    "SelectD": "UI와 데이터 서비스를 위한 별도 Kubernetes Service Account를 만들고, 해당 Service Account가 IAM Role을 사용할 수 있도록 설정합니다. IRSA를 사용하여 UI Pod에 Amazon S3, 데이터 서비스 Pod에 Amazon DynamoDB에 대한 접근 권한을 부여합니다.",
    "SelectD_Commentary": "UI Pod에는 DynamoDB, 데이터 서비스 Pod에는 S3 권한만 부여해야 하나, 이 선택지는 그 반대로 적용하여 요구사항에 부합하지 않습니다.",
    "Question_Description_recommedations": [
      "Q681",
      "Q211",
      "Q998",
      "Q451",
      "Q981"
    ],
    "SelectA_recommedations": [
      "Q1017",
      "Q681",
      "Q998"
    ],
    "SelectB_recommedations": [
      "Q1017",
      "Q403",
      "Q981"
    ],
    "SelectC_recommedations": [
      "Q1017",
      "Q233",
      "Q135"
    ],
    "SelectD_recommedations": [
      "Q941",
      "Q1017",
      "Q780"
    ]
  },
  {
    "Question_Number": "Q1018",
    "Question_Description": "한 회사는 전 세계에 분산된 개발 팀이 회사의 AWS 리소스에 대해 보안 정책을 준수하면서 안전하게 액세스하기를 원합니다. 회사는 현재 사내 인증을 위해 온프레미스 Active Directory를 사용 중이며, AWS Organizations로 관리되는 여러 AWS 계정을 다양한 프로젝트에 활용하고 있습니다. 기존 인프라와 연동하여 중앙에서 신원 관리와 액세스 제어를 제공하면서도 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 다음 중 이러한 요구 사항을 가장 적은 운영 부담으로 충족하는 솔루션은 무엇입니까?",
    "Answer": "C",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148826-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "AWS Managed Microsoft AD를 사용하면 여러 AWS 계정 간 공유가 가능하고, 온프레미스와 트러스트 관계를 설정해 중앙에서 권한을 관리할 수 있어 운영 오버헤드가 크게 줄어듭니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "온프레미스 Active Directory",
      "중앙화된 신원 관리",
      "AWS Organizations",
      "운영 오버헤드 최소화"
    ],
    "Terms": [
      "AWS Directory Service",
      "AWS Managed Microsoft Active Directory",
      "AD Connector",
      "IAM Identity Center",
      "IAM roles",
      "Multi-Factor Authentication (MFA)",
      "Amazon Cognito",
      "Access tokens",
      "Trust relationship"
    ],
    "SelectA": "AWS Directory Service로 AWS Managed Microsoft AD를 생성하고 온프레미스 Active Directory와 트러스트 관계를 설정합니다. Active Directory 그룹에 할당된 IAM 역할을 사용해 AWS 계정에 액세스합니다.",
    "SelectA_Commentary": "AWS Managed Microsoft AD는 여러 AWS 계정에 대해 쉽게 공유가 가능하고 트러스트로 온프레미스 AD와 연동되어 중앙 통합 관리를 제공하므로 운영 오버헤드가 낮습니다.",
    "SelectB": "각 개발자마다 개별 IAM 사용자를 생성하고, 프로젝트별로 권한을 직접 관리합니다. 보안 강화를 위해 추가적으로 MFA를 적용합니다.",
    "SelectB_Commentary": "IAM 사용자와 권한을 직접 관리하는 방식은 프로젝트와 인원이 늘어날수록 관리 부담이 급격히 증가해 비효율적입니다.",
    "SelectC": "AWS Directory Service의 AD Connector를 통해 온프레미스 Active Directory와 연결합니다. AD Connector를 AWS IAM Identity Center와 통합하고, 각 AD 그룹에 대해 특정 AWS 계정 및 리소스에 대한 권한 세트를 구성합니다.",
    "SelectC_Commentary": "AD Connector는 여러 AWS 계정에서 공유 사용이 어렵고, VPC 제약으로 인해 관리가 복잡해져 운영 오버헤드가 증가합니다.",
    "SelectD": "Amazon Cognito를 사용해 아이덴티티 페더레이션 솔루션을 배포하고 온프레미스 Active Directory와 연동합니다. Amazon Cognito로부터 발급된 액세스 토큰을 사용해 개발자가 AWS 계정 및 리소스에 액세스하도록 합니다.",
    "SelectD_Commentary": "Amazon Cognito는 주로 고객 또는 앱 사용자를 위한 인증 시나리오에 적합하며, 내부 임직원용으로는 설정 및 운영 부담이 더 클 수 있습니다.",
    "Question_Description_recommedations": [
      "Q168",
      "Q945",
      "Q826",
      "Q28",
      "Q521"
    ],
    "SelectA_recommedations": [
      "Q826",
      "Q28",
      "Q1018"
    ],
    "SelectB_recommedations": [
      "Q429",
      "Q665",
      "Q478"
    ],
    "SelectC_recommedations": [
      "Q826",
      "Q28",
      "Q761"
    ],
    "SelectD_recommedations": [
      "Q200",
      "Q826",
      "Q1018"
    ]
  },
  {
    "Question_Number": "Q1019",
    "Question_Description": "한 회사가 AWS Cloud에서 애플리케이션을 개발 중입니다. 애플리케이션의 HTTP API에는 Amazon API Gateway에서 게시되는 중요한 정보가 포함되어 있습니다. 이 중요한 정보는 회사 내부 네트워크에 속한 제한된 신뢰할 수 있는 IP 주소에서만 접근 가능해야 합니다. 이러한 요구사항을 충족하는 솔루션은 무엇입니까?",
    "Answer": "B",
    "Link": "https://www.examtopics.com/discussions/amazon/view/148827-exam-aws-certified-solutions-architect-associate-saa-c03/",
    "AnswerDescription": "이 문제는 Amazon API Gateway 리소스에 대한 액세스를 특정 IP 주소 범위로 제한하는 방법을 묻습니다. Amazon API Gateway의 Resource Policy를 사용하면 원하는 IP 주소를 명확히 지정하여 접근을 제어할 수 있습니다. API Gateway 서비스 자체에는 보안 그룹을 직접 적용할 수 없고, Private Integration만으로는 외부 IP 주소 제한을 간단히 설정하기 어렵기 때문에 Resource Policy가 가장 효과적인 해결책입니다.",
    "Domain": "보안 아키텍처 설계",
    "Tasks": [
      "1.1"
    ],
    "Keywords": [
      "Amazon API Gateway",
      "HTTP API",
      "회사 내부 네트워크",
      "IP 주소 제한",
      "Resource Policy"
    ],
    "Terms": [
      "Amazon API Gateway",
      "Resource Policy",
      "Security Group",
      "Network ACL",
      "Private Integration"
    ],
    "SelectA": "API Gateway에 Private Integration을 설정하고 사전에 정의된 IP 주소 목록으로 액세스를 제한합니다.",
    "SelectA_Commentary": "Private Integration은 보통 VPC 내부 리소스에 연결하기 위한 방식이며, 단일 API Gateway 수준에서 임의의 외부 IP 제한을 구현하기가 까다롭습니다.",
    "SelectB": "API에 Resource Policy를 생성하여 명시적으로 허용되지 않은 모든 IP 주소에 대한 액세스를 거부합니다.",
    "SelectB_Commentary": "정책에서 특정 IP 주소 범위만 허용하고 나머지를 모두 거부할 수 있으므로 가장 간단하고 직접적인 솔루션입니다. 정답입니다.",
    "SelectC": "API를 사설 서브넷에 직접 배포하고, Network ACL을 생성하여 특정 IP 주소에서의 트래픽만 허용하도록 설정합니다.",
    "SelectC_Commentary": "API Gateway를 사설 서브넷에서 직접 배포하는 것은 일반적인 설정이 아니며, 네트워크 ACL만으로는 외부 API 접근 제어에 제한이 있습니다.",
    "SelectD": "API Gateway에 연결된 Security Group을 수정하여 신뢰할 수 있는 IP 주소에서만 인바운드 트래픽을 허용합니다.",
    "SelectD_Commentary": "Amazon API Gateway는 서비스 형태로 동작하므로 애플리케이션 로직처럼 직접 Security Group을 할당해 설정해야 하는 방식이 아닙니다.",
    "Question_Description_recommedations": [
      "Q34",
      "Q532",
      "Q970",
      "Q15",
      "Q529"
    ],
    "SelectA_recommedations": [
      "Q1019",
      "Q468",
      "Q571"
    ],
    "SelectB_recommedations": [
      "Q468",
      "Q1019",
      "Q803"
    ],
    "SelectC_recommedations": [
      "Q468",
      "Q571",
      "Q1019"
    ],
    "SelectD_recommedations": [
      "Q1019",
      "Q774",
      "Q468"
    ]
  }
]